           Fake News and False Corroboration: Interactivity in Rumor Networks
                                           Michael J. Spivey (spivey@ucmerced.edu)
                                                Cognitive and Information Sciences
                                                 University of California, Merced
                                                      Merced, CA 95340 USA
                             Abstract                               Fowler, 2003; M. Richardson, Marsh & Schmidt, 2005),
  Rumors inundate every social network. Some of them are            their eye movements (D. Richardson, Dale & Kirkham,
  true, but many of them are false. On rare occasions, a false      2007), their gestures (Paxton & Dale, 2013), and their
  rumor is exposed as the lie that it is. But more commonly,        language use (Louwerse, Dale, Bard, & Jeuniaux, 2012). It
  false rumors have a habit of obtaining apparent verification,     has even been shown that behavioral and neural responses
  by corroboration from what seems to be a second independent       of two participants cooperating on a task exhibit the
  source.     However, in complex social networks, the              signatures of competition between the two subtasks, even
  connectivity is such that a putative second source is almost      though each person is in charge of only one of those
  never actually independent of the original source. In the         subtasks (Sebanz, Knoblich, Prinz, & Wascher, 2006).
  present work, rumor network simulations demonstrate how
                                                                    Essentially, each person is doing some of the thinking for
  remarkably easy it is for a node in the network to be fooled
  into thinking it has received independent verification of a       the other person. When these mechanisms of coordination
  false rumor, when in fact that “second source” can be traced      are optimized between two people, they can even perform a
  back to the original source. By developing a theoretical          joint perceptual task at a level that is better than either of
  understanding of the circumstances under which the spread of      them alone (Fusaroli et al., 2012).
  false rumors, “alternative facts,” and fake news can be                When people share information with each other, they
  controlled, perhaps the field can help prevent them from          tend to self-organize into a larger cognitive system
  ruining elections and ruining entire nations.                     (Goldstone & Gureckis, 2009). Much like how cognition
                                                                    may be an emergent property of billions of neurons
 Keywords: Networks, Social Networks, Interaction
                                                                    interacting with one another in a brain (Kello, Beltz, Holden
                                                                    & Van Orden, 2007), group cognition may also be an
                           Introduction                             emergent property of multiple people interacting with one
     The interactivity that exists among the subsystems that        another in a shared context (Thiener, Allen, & Goldstone,
form a cognitive system has powerful and lasting                    2010). Due to the continuous fluid flow of information
consequences. In the human brain, the interactivity among           throughout the network, every node (be it a neuron or
the neural subsystems that form the language                        person) is richly interdependent with every other node, at
comprehension network is what allows phonetics to                   least indirectly. Not only can positive influences spread
influence syntactic processing (Farmer, Christiansen, &             throughout such a network, as when two brains show
Monaghan, 2006) and semantics to influence speech                   improved performance on a shared perceptual task (Fusaroli
perception (Gow & Olson, 2015; Spivey, 2016). In the                et al., 2012), but negative influences can also spread
human brain, the interactivity among the neural subsystems          throughout the network and infect nearly every component.
that form the visual perception network is what allows depth        Network simulations of rumor-spreading have recently
perception to influence motion discrimination (Trueswell &          begun to analyze this process of false information infecting
Hayhoe, 1995) and attention to influence visual perception          a social network (Roshani and Naimi, 2012).
(Gandhi, Heeger, & Boynton, 1999; Spivey & Spirn, 2000).                 Traditional studies of rumor transmission tended to
In the human brain, the interactivity between the language          focus on linear sequential transfer of a rumor, and how the
comprehension network and the visual perception network             content can often become accidentally modified after
is what allows visual context to influence spoken word              several transmissions (Allport & Postman, 1947).
recognition (Allopenna, Magnuson & Tanenhaus, 1998;                 Sometimes this is referred to as the “telephone game.”
Spivey-Knowlton, 1996), and linguistic input to influence           However, more recent studies of rumor transmission have
visual perception (Lupyan & Spivey, 2010; Lupyan &                  used network theory to examine how non-linear
Ward, 2013). These examples form just a tiny subset of the          transmission of rumors happens in complex social networks
many consequences of interactivity in the human brain.              that are richly interconnected (Del Vicario et al., 2016). For
     Outside the human brain, interactivity in a social             example, when the network has islands of homogeneity,
network has powerful consequences for group behavior.               tight-knit like-minded enclaves that connect mostly just to
When two people cooperate on a shared task, or even just            their own group, these subnetworks can become “echo
have a conversation, they often exhibit real-time motor             chambers” that reinforce false narratives and conspiracy
coordination in their postural sway (Shockley, Santana, &           theories within their walls. Alternatively, when the
                                                                3229

connectivity of a social network is scale-free (neither           rape of white women to depopulate the white race.” Some
random nor homogenous) – much like the brain’s                    people believed this false rumor so strongly that they made
connectivity (Kello, 2013; Sporns, 2010) – then almost any        threats on Zakaria’s life, and frightening phone calls to his
rumor can be expected to spread throughout the entire             daughters in the middle of the night (Zakaria, 2016).
network, irrespective of whether it is true or false (Nekovee,         Similarly, in the fall of 2016, fake news reports were
Moreno, Bianconi, Marsili, 2007). What has not been               disseminated widely on Facebook about presidential
explored yet in this small cottage industry of research is        candidate Hillary Clinton being involved in a child sex-
how easily a false rumor can obtain independent verification      trafficking ring based at a particular pizza shop in
via an apparent second source, even when that “second             Washington, D. C. One man believed that false rumor so
source” actually has the original source as its origin.           strongly that he felt compelled to travel across state lines to
     When an interactive system (be it a brain or a group of      visit that pizza shop with an assault rifle in his hands and
people) spends any amount of time sending signals back and        fire a shot to let them know he was there to save the
forth among its subcomponents, it quickly becomes difficult       children. The U. S. Department of National Intelligence has
to trace the source of a signal and determine whether a given     recently determined that many such fake news stories about
signal is afferent (recently coming from an external source)      Hillary Clinton were fabricated and disseminated via social
or efferent (better described as generated endogenously).         networks specifically with the intent of influencing the
Under these circumstances, following the trail of a rumor in      results of the 2016 U. S. election (DNI Report, 2017).
a social network is extremely difficult. The journalistic              In Del Vicario et al.’s (2016) computational analysis of
practice of “corroborating the story” can become quite            conspiracy theories on the internet, they concluded that,
complicated. A common method of fact-checking is to find          “many mechanisms cause false information to gain
a second source for the same story. If the second source is       acceptance, which in turn generates false beliefs that, once
independent of the first source, and says essentially the         adopted by an individual, are highly resistant to correction.”
same thing, then it adds veracity to the report. Even naïve       In the following rumor network simulations, the results
experimental participants tend to use this tactic (Kim et al.,    suggest that false corroboration may be one of those many
2008). However, in an interconnected network of people            mechanisms.
sharing information, almost no one is actually independent
of anyone else. Frequently, an apparent second source,                      Random Rumor-Net Simulations
which gets used as verification of the rumor, actually
acquired its information indirectly from the original source.          In this first group of simulations, a 100-node network
     One concrete real-world example of such false                was constructed and given random placement of bi-
corroboration is the U.S. Pentagon’s case for Saddam              directional connections, excluding self-connections. In one
Hussein stockpiling weapons of mass destruction (WMD) at          set of 100 simulations, the network was given 10%
the beginning of the 21st century. It has now been well-          connectivity, such that each node on average was connected
established that U.S. leaders were proactively seeking            to about 10 of the possible 99 other nodes (i.e., average
justification for a pre-existing plan to invade Iraq and          node degree=10). The average clustering coefficient for this
depose its leader (Dreyfuss & Vest, 2004; Ryan, 2006). It         network (which shows how interconnected each node’s
turned out to be all too easy for information gatherers to        friends are) was .10. Another set of 100 simulations used a
fool themselves into thinking they had corroborated reports       clustering coefficient of .33, and Figure 1 shows an example
of WMD, when in fact the corroboration was actually a             degree distribution from one of those networks. Another set
duplicate of the original false rumor. The CIA, British           of 100 simulations used a clustering coefficient of .5, and a
intelligence services, and the New York Times all collected       fourth set used a clustering coefficient of .67.
reports of WMD in Iraq, and carefully sought independent
verification. Each of these entities received fallacious
reports from the same Iraqi defector, codenamed
“Curveball” by the CIA. And what’s more, each of them
used un-sourced reports from one another as corroboration
of their own report. What they each did not realize at the
time was that the “second source” to corroborate their report
from Curveball was actually just someone else’s report from
Curveball (Bamford, 2005; Prados, 2004).
     False rumors, “alternative facts,” and fake news have
become an everyday occurrence recently, where too many
people obtain their news reports on social network sites and
blogs, where “news” is provided that has not been vetted by
policies of ethical journalism. For example, in January of
                                                                     Figure 1: Degree distribution from a 100-node random
2016, journalist and author, Fareed Zakaria, was “trolled”
                                                                     network in which, on average, most nodes are
on the internet with a fake report of him calling for “jihad
                                                                     connected to about 33 other nodes.
                                                              3230

     To begin a simulation, node #1 was infected with a                  With 200 nodes and 200 rumor transmissions (or 500
rumor by flipping its state from zero to 1.0. This is the one-      nodes and 500 rumor transmissions), again about one-
and-only origination of the rumor in this network. It could         quarter of the nodes obtain false corroboration – irrespective
be true or false, but for the purpose of testing its evolution      of how densely or sparsely connected the network is. With
into “fake news,” the rumor is treated as false. For every          half as many transmissions as there are nodes, about 10% of
instance of transmitting the rumor, a randomly chosen               the nodes obtain false corroboration. And with twice as
infected node would select randomly among its connections           many transmissions as nodes, about 60% of the nodes obtain
to spread the rumor with one other node. After spreading,           false corroboration. Based on these initial simulations, it
that bidirectional connection was erased in the network to          appears that false corroboration of a rumor may be
prevent it from being used again in the future. (The                remarkably easy to obtain in a social network.
simulation assumes that if the same rumor were shared
again between the same two people, it would not count as a                   Scale-Free Rumor-Net Simulations
transmission.) For that very first transmission, this
obviously involved node #1 sharing the rumor with one of                 Most real-world networks, including social networks,
the nodes connected to it. At which point there would then          are not at all random in their connectivity. Instead, social
be two nodes that have been exposed to the rumor. Then one          networks tend to have a scale-free pattern of connectivity,
of those nodes was randomly selected to spread the rumor            meaning that most nodes have a smallish number of
again. After 100 transmissions of the false rumor, some of          connections (node degree), while a few nodes have a very
the nodes had still never been exposed, some had been               large number of connections. Using a version of Barabasi
exposed once, and some had heard the rumor from two or              and Albert’s (1999) preferential attachment process, a group
more different connections. This latter case counts as              of scale-free rumor networks were designed that show a
people who had heard the rumor corroborated by what                 power-law in their degree distribution (Figure 2).
would seem to be a second source. However, the simulation
actually has only one source of the rumor: node #1. For
example, node #1 might spread the rumor to node #47, who
then spreads the rumor to node #23. Next, node #47 might
share the rumor again, this time with node #87, who shares
it with node #18, who then shares the rumor with node #23.
In that scenario, node #23 could easily be fooled into
believing that it had received independent corroboration
(from node #18) of the rumor it first heard from node #47.
     In this first group of simulations, the number of nodes
that received this false corroboration was recorded for low-,
medium-, high- and very high-connectivity networks (i.e.,
clustering coefficients of .1, .33, .5, and .67). Interestingly,
after 100 transmissions of the rumor, there were no
differences across these four different types of random
networks (results averaged across the 100 simulations in
each case). In all simulations, irrespective of how densely
interconnected the network was, around 26 of the 100 nodes
had heard the rumor from two or more sources (Table 1).
This insensitivity to network density is likely due to the fact
that a rumor-spreader is randomly selected each time
(among nodes that know the rumor), and its relative
likelihood of spreading the rumor to a knowing node or an
unknowing node is unchanged by how well-connected it is.
   Table 1: Random networks with different numbers of
   connections show about the same number of nodes
   hearing false corroboration of the rumor (2+ times).
  Avg Node        Clustering    Never     Heard     Heard 2+           Figure 2: (A) Degree distribution from a 100-node
    Degree       Coefficient    Heard      Once        times           scale-free network where the mean number of
      10             .10         33.6      40.1         26.3           connections per node is 33, but most nodes have <25
      33             .33         34.6      38.8         26.6           connections and a few nodes have >75 connections. (B)
      50             .50         34.8      38.4         26.8           On log-log coordinates, the degree distribution forms a
      67             .67         34.9      38.4         26.7           relatively straight line with a slope of -1.3.
                                                                3231

     By contrast to a scale-free network, in a random                When a False Rumor Becomes Fake News
network the proportion of connections each node has
generally corresponds to the clustering coefficient as well.           Based on all these simulations, when there are as many
That is, if each node in a random network has about 10% of       rumor-transmissions as there are nodes, then almost 2/3 of
the possible connections, then the clustering coefficient        them will hear the rumor, and about 1/4 of them will obtain
(showing what proportion of each node’s friends are              a false corroboration of the rumor – even though it never
connected to each other) will also tend to be around .10.        actually had any independent secondary source. This is true
However, in a scale-free network, the clustering coefficient     for both random rumor networks and for scale-free rumor
(.62, in Figure 2) tends to be substantially higher than the     networks. However, when one of the people in the network
average proportion of connections the nodes have (.33, in        is a reporter for a news agency, who will broadcast the story
Figure 2). That is, in a scale-free network, most nodes have     to everyone if they obtain apparent corroboration, then it
relatively few friends, but a sizeable proportion of those       turns out that the type of connectivity does, in fact, matter.
friends know each other.                                         If one assumes that the reporter is among the most widely-
     In these next simulations, a hundred 100-node scale-        connected people in the network, then the different degree
free networks were designed that had an average of 10            distributions for random networks and for scale-free
connections per node, along with another hundred networks        networks (Figures 1 and 2) make for substantially different
that had an average of 17 connections per node, then another     reporters. In a random network, the most-connected node
hundred with 25, and another hundred with 33 connections         (i.e., the reporter) will have a number of connections that is
per node. (In a scale-free network, when the average             greatly influenced by the density of the network’s
number of connections approaches 50% of the possible             connectivity (its average node degree). However, in a scale-
connections, its degree distribution can become bimodal and      free network, the most-connected node is often connected to
no longer adheres to a scale-free power law. Therefore, the      >85% of the other nodes, irrespective of the average node
highest node degree used here was 33.)                           degree. Therefore, a reporter in a random network will only
     Each rumor-spreading simulation with these scale-free       occasionally obtain a false corroboration, and thus publish
networks was carried out in a fashion similar to those with      the story (Table 3). However, in a scale-free network, a
the random networks, except that the first rumor-infected        reporter (who is massively well-connected) will almost
node could not be an arbitrary choice because some nodes         always obtain false corroboration, and therefore publish the
were substantially more connected than others. To test the       rumor (Table 4). If that rumor is false, then its publication
limiting case, the least-connected node in each scale-free       qualifies as fake news.
network was selected as the first node to spread the rumor.         Table 3: In random rumor-nets, false corroboration
After that starting point, 100 transmissions of the rumor           sometimes leads to the publication of fake news.
took place exactly as it did with the random networks.
                                                                    Node Degree          Clustering        Reporter-node
   Table 2: Scale-free networks with different numbers of                                Coefficient    Publishes Fake News
   connections show about the same number of nodes                         10                .10                58%
   hearing false corroboration of the rumor (2+ times).                    33                .33                42%
                                                                           50                .50                38%
   Node      Cluster    loglog    Never    Heard     Heard
  Degree     Coeff.      slope    Heard    Once     2+ times               67                .67                35%
    10         .22       -0.71     40.1     34.6      25.3
    17         .39       -1.05     40.4     34.3      25.3          Table 4: In scale-free rumor-nets, false corroboration
    25         .56       -1.25     40.8     33.9      25.3          almost always leads to the publication of fake news.
    33         .68       -1.27     40.8     33.6      25.6           Node       Clustering      loglog     Reporter-node
                                                                    Degree      Coefficient      slope  Publishes Fake News
     In these scale-free rumor networks, a slightly larger             10            .22         -.071          92%
proportion of the people never hear the rumor (about 40%)              17            .39         -1.05          93%
compared to that in the random networks (about 35%).                   25            .56         -1.25          93%
However, remarkably, approximately the same number of                  33            .68         -1.27          87%
false corroborations is observed (~25) as that seen with the
random networks (compare Tables 1 & 2). As was tested                  Surprisingly,     with    random    networks,    denser
with the random networks, this 25% false corroboration rate      connectivity leads to a reduced likelihood of the reporter-
replicates for scale-free networks with 200 nodes and 200        node obtaining false corroboration and publishing the
rumor-transmissions. When there are 3-4 times as many            rumor. Upon closer examination, this makes sense given
transmissions as nodes, almost every node will have heard        the parameters of the simulation. In a random network with
the rumor, and about ¾ of them will have heard it more than      a small average node degree (sparse connectivity),
once (irrespective of network density). Not surprisingly, in     whenever a rumor-infected node is about to spread the
these scale-free networks, it is usually the well-connected      rumor, it has a small number of friends to choose among. If
nodes that first obtain these false corroborations.
                                                             3232

one of them happens to be the reporter, which is somewhat               One potential solution to this problem is for reporters to
likely since the reporter is the most connected node, then the    make better efforts at tracing the lineage of a report, so that
reporter might hear the rumor. And if that happens a second       two reports from the same source might be identified as
time, then a (false) corroboration has taken place, and the       such. A more reliable solution would be for journalism
story gets broadcasted. By contrast, in a random network          practices to avoid using secondary-source corroboration on
with a large average node degree (dense connectivity),            its own as sufficient evidence to disseminate a story. These
whenever a rumor-infected node is about to spread the             rumor network simulations demonstrate that it is simply too
rumor, it has a large number of friends to choose among.          easy to obtain such corroboration in a fraudulent manner.
One of them is probably the reporter, but a random selection      Instead, the criterion for publication of a story might ought
of to whom the rumor will be spread leaves the reporter with      to include evidence that cannot easily be faked, such as
a slim chance. In many of these random rumor-net                  photos, video, audio recordings, and documents whose
simulations, the reporter never even heard the rumor once.        source can be reliably determined. For example, if the
     The situation is very different in a scale-free network.     report is that a public figure made sexist comments, or
In a scale-free rumor-net, most nodes have fewer                  mocked a disabled person, or told the public a brazen lie,
connections than they would in a comparable random                simply relying on two seemingly-independent sources to
network.      Therefore, when a rumor-infected node is            publish such a story may be insufficient. If the comments or
randomly selected to spread the rumor, it is usually one that     mocking are evident in a video clip of the public figure, or if
has a smallish number of friends to choose among, and one         the lie is present in a verifiably-sourced tweet from the
of them is almost certainly the well-connected reporter (see      public figure, then those pieces of evidence should be what
also Doerr, Fouz, & Friedrich, 2012). Thus, almost every          are repeatedly disseminated in reporting the story. Reports
time the rumor is transmitted, the reporter has a reasonable      without such concrete evidence should be taken with a grain
chance of being its recipient. As a result, the reporter-node     of salt, or perhaps not published in the first place.
in such a network is highly likely to hear the rumor, and               It has been proven time and time again in everyday life,
also highly likely to obtain a false corroboration of this        as well as in high-stakes politics, that the dissemination of
rumor, even though the rumor actually has only one source.        false rumors can ruin lives, ruin elections, and even ruin
                                                                  entire nations. Understanding the mechanisms that allow,
                        Conclusion                                and exacerbate, the spread of misinformation in a social
                                                                  network of any kind may help with efforts to curtail and
     Interactivity in a network is usually a good thing.          minimize the damage that can be done. The present
Ambiguities or uncertainties present in one part of the           simulations of a false rumor spreading throughout a network
network will often be resolved by strongly biasing                show convincingly that, even in a sparsely connected
information present in another part of the network (e.g.,         network, the “apparent corroboration” of a story often
Kawamoto, 1993; MacDonald, Pearlmutter, and Seidenberg,           comes from a source whose own source can be traced back
1994; McRae, Spivey-Knowlton, & Tanenhaus, 1998).                 to the originator of the story, and thus should not actually
However, when that strongly biasing information is                count as independent corroboration. To quote Fareed
objectively false, the interactivity within a network can         Zakaria, “No matter how passionate people are, no matter
compromise its ability to align itself with reality.              how cleverly they can blog or tweet or troll, no matter how
     The present network simulations do not specifically          viral things get, lies are still lies.”
distinguish between objectively false rumors and true
rumors, but a recent analysis of 330 rumor threads on
Twitter does. For a false rumor, the time between rumor                                     References
onset and debunking can be as much as seven times longer          Allopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K.
than the time between rumor onset and verification for a             (1998). Tracking the time course of spoken word
true rumor (Zubiaga, Liakata, Procter, Hoi, & Tolmie,                recognition using eye movements: Evidence for
2016). That is, it takes much longer to debunk a false rumor         continuous mapping models. Journal of Memory and
than it does to verify a true rumor. Therefore, if a long-           Language, 38(4), 419-439.
standing uncertain rumor has not been verified as true, then      Allport, G. W. & Postman, L. (1947). The psychology of
the odds are steadily increasing every day that it is a false        rumor. NY: Holt & Co.
rumor (that just hasn’t been debunked yet). Most true             Bamford, J. (2005). A pretext for war: 9/11, Iraq, and the
rumors get verified very quickly.                                    abuse of America's intelligence agencies. Anchor
     However, the nature of this verification process comes          Publishing.
into question when considering the present rumor                  Barabási, A. L., & Albert, R. (1999). Emergence of scaling
simulations. If the apparent verification comes in the form          in random networks. Science, 286(5439), 509-512.
of a seemingly independent source that corroborates the           Del Vicario, M., et al. (2016). The spreading of
original rumor, it may be illusory. The interactivity inherent       misinformation online. Proceedings of the National
in social networks can all too easily make a false                   Academy of Sciences, 113(3), 554-559.
corroboration (i.e., an echo from the echo chamber) appear        DNI report (2017). Background to “Assessing Russian
as genuine independent corroboration.                                Activities and Intentions in Recent US Elections”: The
                                                              3233

  Analytic Process and Cyber Incident Attribution.                networks. Physica A: Statistical Mechanics and its
  https://www.dni.gov/ files/documents/ICA_2017_01.pdf            Applications, 374(1), 457-470.
Doerr, B., Fouz, M., & Friedrich, T. (2012). Why rumors         Paxton, A., & Dale, R. (2013). Frame-differencing methods
  spread so quickly in social networks. Communications of         for measuring bodily synchrony in conversation. Behavior
  the ACM, 55(6), 70-75.                                          Research Methods, 45(2), 329-343.
Dreyfuss, R. & Vest, J. (2004, February). The lie factory.      Prados, J. (2004). Hoodwinked: The documents that reveal
  Mother Jones, pp. 34–41.                                        how Bush sold us a war. New Press.
Farmer, T. A., Christiansen, M. H., & Monaghan, P. (2006).      Richardson, D. C., Dale, R., & Kirkham, N. Z. (2007). The
  Phonological typicality influences on-line sentence             art of conversation is coordination common ground and
  comprehension. Proceedings of the National Academy of           the coupling of eye movements during dialogue.
  Sciences, 103(32), 12203-12208.                                 Psychological Science, 18(5), 407-413.
Fusaroli, R., Bahrami, B., Olsen, K., Roepstorff, A., Rees,     Richardson, M. J., Marsh, K. L., & Schmidt, R. C. (2005).
  G., Frith, C., & Tylén, K. (2012). Coming to terms              Effects of visual and verbal interaction on unintentional
  quantifying the benefits of linguistic coordination.            interpersonal coordination. Journal of Experimental
  Psychological Science, 23(8), 931-939.                          Psychology: Human Perception and Performance, 31(1),
Gandhi, S. P., Heeger, D. J., & Boynton, G. M. (1999).            62-79.
  Spatial attention affects brain activity in human primary     Roshani, F., & Naimi, Y. (2012). Effects of degree-biased
  visual cortex. Proceedings of the National Academy of           transmission rate and nonlinear infectivity on rumor
  Sciences, 96(6), 3314-3319.                                     spreading in complex social networks. Physical Review E,
Goldstone, R. L., & Gureckis, T. M. (2009). Collective            85(3), 036109.
  behavior. Topics in Cognitive Science, 1(3), 412-438.         Ryan, M. (2006). Filling in the ‘unknowns’: Hypothesis-
Gow Jr, D. W., & Olson, B. B. (2015). Sentential influences       based intelligence and the Rumsfeld commission.
  on acoustic-phonetic processing: A Granger causality            Intelligence and National Security, 21(2), 286-315.
  analysis of multimodal imaging data. Language,                Sebanz, N., Knoblich, G., Prinz, W., & Wascher, E. (2006).
  Cognition and Neuroscience, 31(7), 841-855.                     Twin peaks: An ERP study of action planning and control
Kawamoto, A. H. (1993). Nonlinear dynamics in the                 in coacting individuals. Journal of Cognitive
  resolution of lexical ambiguity: A parallel distributed         Neuroscience, 18(5), 859-870.
  processing account. Journal of Memory and Language,           Shockley, K., Santana, M. V., & Fowler, C. A. (2003).
  32(4), 474-516.                                                 Mutual interpersonal postural constraints are involved in
Kello, C. T. (2013). Critical branching neural networks.          cooperative conversation. Journal of Experimental
  Psychological Review, 120(1), 230-245.                          Psychology: Human Perception and Performance, 29(2),
Kello, C. T., Beltz, B., Holden, J., & Van Orden, G. (2007).      326-332.
  The emergent coordination of cognitive function. Journal      Spivey, M. J. (2016). Semantics influences speech
  of Experimental Psychology: General, 136(4), 551-568.           perception. Language, Cognition, and Neuroscience, 31,
Kim, N. S., Yopchick, J. E. E., & De Kwaadsteniet, L.             856-859.
  (2008). Causal diversity effects in information               Spivey, M. J., & Spirn, M. J. (2000). Selective visual
  seeking. Psychonomic Bulletin & Review, 15(1), 81-88.           attention modulates the direct tilt aftereffect. Perception
Louwerse, M. M., Dale, R., Bard, E. G., & Jeuniaux, P.            & Psychophysics, 62(8), 1525-1533.
  (2012). Behavior matching in multimodal communication         Spivey-Knowlton, M. J. (1996). Integration of visual and
  is synchronized. Cognitive Science, 36(8), 1404-1426.           linguistic information: Human data and model
Lupyan, G., & Spivey, M. J. (2010). Making the invisible          simulations. PhD Dissertation, U. Rochester.
  visible: Verbal but not visual cues enhance visual            Sporns, O. (2010). Networks of the Brain. MIT press.
  detection. PLoS One, 5(7), e11452.                            Sunstein, C. R. (2016). How Facebook makes us dumber.
Lupyan, G., & Ward, E. J. (2013). Language can boost              Bloomberg View, Jan. 8.
  otherwise unseen objects into visual awareness.               Theiner, G., Allen, C., & Goldstone, R. L. (2010).
  Proceedings of the National Academy of Sciences,                  Recognizing group cognition. Cognitive Systems
  110(35), 14196-14201.                                             Research, 11(4), 378-395.
MacDonald, M. C., Pearlmutter, N. J., & Seidenberg, M. S.       Trueswell, J. C., & Hayhoe, M. M. (1993). Surface
  (1994). The lexical nature of syntactic ambiguity                 segmentation mechanisms and motion perception. Vision
  resolution. Psychological Review, 101(4), 676-703.                Research, 33(3), 313-328.
McRae, K., Spivey-Knowlton, M., & Tanenhaus, M. (1998).         Zakaria, F. (2016). Bile, venom and lies: How I was trolled
  Modeling the effects of thematic fit (and other                 on the internet. The Washington Post, Jan. 14.
  constraints) in on-line sentence comprehension. Journal       Zubiaga, A., Liakata, M., Procter, R., Hoi, G. W. S., &
  of Memory and Language, 37, 283-312.                            Tolmie, P. (2016). Analysing how people orient to and
Nekovee, M., Moreno, Y., Bianconi, G., & Marsili, M.              spread rumours in social media by looking at
  (2007). Theory of rumour spreading in complex social            conversational threads. PLoS One, 11(3), e0150989.
                                                            3234

