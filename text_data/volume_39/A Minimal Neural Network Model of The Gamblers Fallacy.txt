                     A Minimal Neural Network Model of The Gambler’s Fallacy
                                                   Yanlong Sun (ysun@tamhsc.edu)
                                                 Hongbin Wang (hwang@tamhsc.edu)
                           Center for Biomedical Informatics, Texas A&M University Health Science Center
                                                          Houston, TX 77030 USA
                               Abstract                                 Tweney, & Wang, 2010). Particularly, we have argued that
                                                                        without a predefined hypothesis structure, biases underpinning
   The gambler’s fallacy has been a notorious showcase of human
   irrationality in probabilistic reasoning. Recent studies suggest     the gambler’s fallacy can emerge by simply capturing the tem-
   the neural basis of this fallacy might have originated from the      poral relations between patterns as a random process unfolds
   predictive learning by neuron populations over the latent tem-       over time (Sun & Wang, 2010a, 2010b, 2012, 2015). With a
   poral structures of random sequences, particularly due to the
   statistics of pattern times and the precedence odds between          biologically realistic simple recurrent model that learns to re-
   patterns. Here we present a biologically-motivated minimal           encode sequential binary data through unsupervised learning,
   neural network model with only eight neurons. Through unsu-          we show that dissociation of random patterns can naturally
   pervised training, the model naturally develops a bias toward
   alternation patterns over repetition patterns, even when both        emerge as the consequence of inhibitory competition between
   patterns are equally likely presented to the model. Our analyses     overlapped representations (Sun et al., 2015). Our findings
   suggest that the way the neocortex integrates information over       indicate that cognitive biases in overt behavior can emerge
   time makes the neuron populations not only sensitive to the
   frequency signals but also relational structures embedded over       early and locally at the level of sensory processing, and neu-
   time. Moreover, we offer an explanation for how higher-level         rons’ sensitivity to the temporal structures in the learning
   cognitive biases may have an early start at the level of sensory     environment is the key in bridging the gap between neurons
   processing.
                                                                        and behavior.
   Keywords: gambler’s fallacy; alternation bias; waiting time;
   temporal integration; predictive learning.                              In the following, we first introduce some basic normative
                                                                        measures on the time of random patterns. Then, based on
                           Introduction                                 the neural model we reported earlier, we present a minimal
The gambler’s fallacy—a belief that chance is a self-correcting         neural network model with only eight units. We will show that
process where a deviation in one direction would induce a devi-         this minimal model can mostly replicate our previous findings
ation in the opposite direction—has been a notorious showcase           and provide new insights regarding the neural encodings of
of human irrationality in probabilistic reasoning (Tversky &            sequential patterns.
Kahneman, 1974). For decades, this fallacy is thought to have                    Temporal Distance between Patterns
originated from a cognitive bias called the “representativeness
heuristic”, which is attributed to the belief of the “law of small      In sequences generated by a random process, there can be
numbers” that small samples are highly representative of the            fundamentally different types of statistical structures regarding
populations from which they are drawn (Gilovich, Vallone, &             how often a pattern occurs and when a pattern is to occur. Our
Tversky, 1985; Tversky & Kahneman, 1974).                               previous works have been focusing on the distinction between
   Recent development in neuroscience and computational                 the mean time statistic that measures how often the pattern
models suggests that the human mind develops structured prob-           occurs in a global sequence, and the waiting time statistic that
abilistic representations about the world and performs near-            measures when a pattern will first occur since the beginning
optimal Bayesian inferences (Pouget, Beck, Ma, & Latham,                of the observation. Here we introduce a more compact yet
2013; Tenenbaum, Kemp, Griffiths, & Goodman, 2011). For                 more comprehensive framework that incorporates not only
example, representativeness has been defined with a Bayesian            both types of statistics for individual patterns but also the
belief-updating structure in which different hypotheses are             statistics depicting the relational structures between different
evaluated based on different sets of the input data (Gigerenzer         patterns.
& Hoffrage, 1995; Griffiths & Tenenbaum, 2001). However,                   To compute the temporal distances between different pat-
it remains elusive how the structured hypothesis space has              terns with different initial states, we use the first-order de-
originated in the first place, and how cognitive biases can arise       pendent Markov chains parameterized by the probability of
from normative probabilistic models.                                    alternation (pA ) between consecutive trials and the correspond-
   On the topic of randomness perception, there has been a              ing generating functions (Figure 1). 1 Define E[T j|i ] as the
growing speculation that people’s intuition about random pro-           expected number of transitions from the initial state i until the
cess, also known as the subjective randomness, is biased by                 1 The method of generating functions by Markov chains also ap-
the statistical structures in the learning environment (Budescu,        plies to independent Bernoulli trials parameterized the probabilities
1987; Falk & Konold, 1997; Hahn & Warren, 2009; Lopes &                 of single elements (e.g., the probability of heads or tails), and it
                                                                        also generates higher-moment statistics such as variance (e.g., Sun
Oden, 1987; Nickerson, 2002; Oppenheimer & Monin, 2009;                 & Wang, 2015). Here we only present the main results and the exact
Oskarsson, Van Boven, McClelland, & Hastie, 2009; Sun,                  generating functions are omitted.
                                                                    3279

              A           SHH|∅                       SHT|∅
                                                                                 When the initial state i is exactly the desired pattern j,
                                                                              E[T j|i ] denotes the expected number of transitions between any
                             R                            A
                     H                            H           R               two consecutive occurrences of the pattern j, and is referred
              ∅            MH              ∅           MH
                                                                              to as the mean time of pattern j. Since the first-order Markov
                         A     A                     A                        chain is memoryless between consecutive transitions, we have
                     T            R               T           R
                           MT                          MT                     relations such as E[THH|HH ] = E[THH|H ], and E[THT|HT ] = E[THT|T ].
                                                                              Therefore, the mean times for the patterns HH and HT are
   B         SHH|H                                                            respectively,
         R
                R                 A     SHT|H               A     ST|H
                                                                                                            2                     2
    H         MH             H             A           H             A                       E[THH|H ] =        ,   E[THT|T ] =     .          (3)
                                                R                      R                                 1 − pA                  pA
            A      A               R     MH                 R     MH
         A            R                                                       At pA = 1/2, we have E[THH|H ] = E[THT|T ] = 4. The inverse of
              MT
                                                                              mean time is frequency. For example, E[THH|H ] = 4 means that
                        C             1:1                                     we expect to see the pattern HH once in every 4 tosses of an
                                HH          TT                                fair coin.
                                      1:3                                        Among these different measures, the most striking distinc-
                             1:1               1:1
                                      1:1
                                                                              tion is that at pA = 1/2, we have E[THH|H ] = 4 but E[THT|H ] = 2,
                                HT          TH                                in spite of the fact that given an H, the next digit is equally
                                                                              likely to be either an H or a T. This is because a reoccurrence
                                                                              of the pattern HH can “reuse” the ending elements from its
Figure 1: Markov chains for generating the waiting times                      previous occurrence, but a reoccurrence of the pattern HT must
E[THH|∅ ] and E[THT|∅ ] given the initial empty state ∅ (Fig-                 always start anew. This statistical property of faster transition
ure A), and the additional times E[THH|H ], E[THT|H ], and E[TT|H ],          times when starting anew is known as new better than used
given the same initial state H (Figure B). In each chain, states              (NBU) (Ross, 2007). Essentially, the NBU property is due to
S j|i represent all possible sequences that start from the pattern            the overlap between a pattern and a shifted copy of itself or be-
i (i = ∅ means starting anew) and end with the first arrival                  tween different patterns. For example, as shown in Figure 1B,
of the pattern j. States Mk represent all possible sequences                  pattern HH overlaps with its shifted copy by one element H,
that end with the pattern k but do not contain the expected                   but pattern HT does not. Then, towards the destination state
pattern j. Transitions between nonempty states are labeled                    SHH|H , anytime things go astray (i.e., the process ends in state
as either repetition (R) or alternation (A). Figure C: Pairwise               MT ), the waiting for HH has to start all over. In contrast, the
precedence odds between patterns when the probability of                      waiting for HT is always on average two flip away from the
alternation pA = 1/2, for example, the odds are 3 to 1 that one               state MH . As a result, the transition to SHH|H is “delayed” than
is to first encounter TH than to first encounter HH.                          the transition to SHT|H . This overlap also explains the pairwise
                                                                              precedence relation shown in Figure 1C. For example, in the
first arrival of the pattern j. When the initial state is empty               competition between the patterns HH and TH, the former reuses
i = ∅ (i.e., the counting process starts anew), E[T j|∅ ] is re-              the last element of the latter but the latter starts anew. As a
ferred to as the waiting time of pattern j. For example, from                 result, if we toss a fair coin repeatedly (i.e., pA = 1/2), the odds
Figure 1A, the waiting times for the patterns HH and HT are                   are 3 to 1 that we first encounter TH than first encounter HH.
respectively,
                                                                                   A Neural Model of Temporal Integration
                                         1          2                         The NBU property of pattern times has fundamental impli-
                   E[THH|∅ ] = 1 +            +          ,                    cations in neural encoding of pattern events. As shown in
                                       2pA 1 − pA
                                                                       (1)    Figure 1, different measures of waiting time, additional time,
                                         1        1
                   E[THT|∅ ] = 1 +            + .                             mean time and pairwise precedence odds are all due to the
                                       2pA pA
                                                                              overlap between temporal patterns. Recent developments in
When pA = 1/2 (namely, independent Bernoulli trials with a                    neuroscience and computational models suggest that neural
fair coin where repetitions and alternations are equally likely),             encodings of events and values are always overlapped, and it is
we have E[THH|∅ ] = 6 and E[THT|∅ ] = 4.                                      the encoding of neural populations that give rise to higher-level
    When the initial state is not empty, E[T j|i ] is referred to as          and more abstract representations (Adolphs, 2015; Dehaene &
the additional time for pattern j given the initial state i. For              Brannon, 2010; Pouget et al., 2013). In the domain of temporal
example, from Figure 1B, we have                                              integration, probabilistic encoding must consider the overlap
                                                                              between representations at different times, namely, recurrent
                           2                                    1             processing (Elman, 1990). Then, we would immediately con-
          E[THH|H ] =           ,    E[THT|H ] = E[TT|H ] =        .   (2)    jecture that via merely encoding the random sequences that un-
                        1 − pA                                 pA
                                                                              fold over time, populations of neurons would naturally capture
At pA = 1/2, we have E[THH|H ] = 4 and E[THT|H ] = E[TT|H ] = 2.              the temporal structures depicted by the pattern times statistics.
                                                                          3280

   A                                                B                                                                  as the model’s internal representation of its experienced pA ,
                                 Temporal Context
                  Internal                                                                                                                                    1
                                                        Detector Ratio (R:A)
                                                                                2                                                                      A
                 Prediction                                                                                                                  p0A =        =        ≈ 0.59.
                                                                               1.5
                                                                                                                                                     R + A 1 + R/A
                                                                                1                                      This p0A value was consistent with the value from empirical
        Input     H      H    Input
                                                                                                                       findings. From a comprehensive review of previous studies
                                                                               0.5
       (t−1)      T      T     (t)                                                                                     (Falk & Konold, 1997), a unanimous finding was that people
                                                                                     1   ⁄3   3   ⁄7   ⁄2
                                                                                                       1    ⁄7
                                                                                                            4          perceived or generated random sequences with a p0A value
       Data     · · · H T H H T· · ·                                             Probability of Alternation (pA )      around 0.58 ∼ 0.63. Moreover, we found that this p0A value
                                                                                                                       directly produces the besting-fitting bias-gain parameter in an
                                                                                                                       existing Bayesian model for subjective randomness of longer
Figure 2: A neural network model of temporal integration                                                               patterns (Goodfellow, 1938; Griffiths & Tenenbaum, 2001).
(figures adopted from Sun et al., 2015). Figure A: A two-unit
input layer scans a sequence of binary digits one digit at a time                                                      A Minimal Neural Network Model
(“online” input at time t), while its temporal context represen-                                                       The model presented in Figure 2 has a prediction layer of 100
tation keeps a copy of the previous input (“context” at time                                                           units, and its temporal context representation is equivalent
t − 1). A 100-unit internal prediction layer attempts to predict                                                       to another 100 units as in a recurrent neural network. Then,
the next input, while its temporal context representation keeps                                                        an immediate question is, how many neurons are required to
a copy of the model’s prediction at time t − 1. Figure B: Af-                                                          produce the minimal effect of the alternation bias? Apparently,
ter unsupervised training, the model shows fewer repetition                                                            to differentiate repetition versus alternation patterns, we need
detectors than alternation detectors (R : A ratio < 1) when the                                                        at least two types of detectors. However, we also notice that
actual probability of alternation is greater than 3/7.                                                                 if patterns are aggregated too “early”, namely, combining HH
                                                                                                                       with TT and combining HT with TH before counting each of the
                                                                                                                       four detectors, the alternation bias would be “washed out” (see
   We have recently reported a biologically-motivated neural
                                                                                                                       the supplementary material by Sun et al., 2015). In addition,
model that behaves consistently in accord with the pattern time
                                                                                                                       the pairwise precedence odds shown in Figure 1C indicates
statistics (Sun et al., 2015). The architecture of the model and
                                                                                                                       that to differentiate all patterns of length two, we need at least
the main result are shown in Figure 2. The model employs a
                                                                                                                       four detector neurons.
recently developed neural algorithm for temporal integration
(O’Reilly, Wyatte, & Rohrlich, 2014). At the sensory level, a                                                              Detectors   HH        TT
2-unit input layer scans non-overlapping signals of heads (H)                                                                                                                   Context    Online
versus tails (T) one digit at a time from sequences generated                                                              Context                     Online     Input units   T H        T H
                                                                                                                                       T H      T H
by the first-order dependent Markov trials. Then, a 100-unit                                                                (t−1)                       (t)
internal prediction layer attempts to predict the next input,                                                                                              0.3
                                                                                                                                                                 Data Stream      H T H H T
                                                                                                                           Detectors   HT        TH
with the benefit of a prior temporal context representation.                                                                                               0.7                      (t−1) (t)
The bidirectional activation dynamics between the input layer
and the internal prediction layer allow us to use a single input                                                       Figure 3: An eight-unit neural network model of temporal
layer for both providing inputs and receiving predictions.                                                             integration. A two-unit input layer scans a sequence of binary
   Through unsupervised learning, the model was trained with                                                           digits one digit at a time (“online” input at time t), while its
binary sequences generated at various levels of probability of                                                         temporal context representation keeps a copy of the previous
alternation (pA ). After training, the model was tested with a                                                         input (“context” at time t − 1). The prediction layer has four
sequence generated at the same pA level. By activation-based                                                           units for detecting each of the four binary patterns of length
receptive field analysis, we decoded the representations on                                                            two. The status of each detector is determined by the projec-
the internal prediction layer and classified its units as either                                                       tion weights from the input units. For example, detectors HH
repetition detectors (whose activations are significantly cor-                                                         and HT receive the same projection weights from the context
related with the input pattern either HH or TT), or alternation                                                        input units, but detector HH receives a stronger weight from
detectors (activations correlated with either HT or TH). We then                                                       the online input unit H, and detector HT receives a stronger
counted the numbers of detectors and used the R/A ratio (rep-                                                          weight from the online input unit T.
etition over alternation) to measure the model’s performance
(Figure 2B).                                                                                                             Figure 3 shows the structure of an eight-unit model for tem-
   Most interestingly, at pA = 1/2 (i.e., flipping a fair coin                                                         poral integration. The model is called “minimal” as it uses
independently), despite the same training frequency of the                                                             the least number of neurons to produce the minimal effect of
patterns (i.e., the same mean time, see, Equation 3), the model                                                        the alternation bias in the gambler’s fallacy. Its input layer is
consistently produced fewer repetition detectors than alterna-                                                         identical to the bigger model in Figure 2, with two units for
tion detectors at a ratio of R/A ≈ .70. We then used this R/A                                                          scanning the “online” input at time t and two units for keep-
ratio to compute the subjective probability of alternation, p0A ,                                                      ing a copy of the “context” input at time t − 1. However, its
                                                                                                                    3281

prediction layer has only four units without explicit temporal                        aged activations of detectors were significantly lower when
context representation. Also different from the bigger model                          the current inputs were repetition patterns (HH or TT) than al-
where the initial status of detectors was set by random weights,                      ternation patterns (HT or TH). That is, in spite of the initially
the detectors in the eight-unit model are initially set by dis-                       unbiased representations of all patterns and the equal training
tinctive projection weights from the input units. For example,                        frequency (i.e., the mean time is the same for all patterns at
detectors HH and HT receive the same projection weights from                          pA = 1/2), repetition patterns eventually were significantly
the context input units, but detector HH receives a stronger                          under-represented than alternation patterns.
weight from the online input unit H, and detector HT receives a
stronger weight from the online input unit T. In other words,
given the same initial state H, detector HH tends to predict a                                                                  pA = 1/6                   pA = 1/3
repetition and detector HT tends to predict an alternation.
   Crucially, the controlled weights allow a more precisely con-                                                 0.7
trolled experiment by eliminating variations produced by ran-                                                    0.5
dom weights. In the bigger model, different detectors would
                                                                                            Projection Weights
                                                                                                                 0.3
“naturally” emerge by a random initialization of weights. How-
ever, this may produce a disparity in the number of detec-
tor types at the initial stage (e.g., more HT detectors than HH                                                                 pA = 1/2                   pA = 2/3
detectors), and such a disparity has to be accounted for by
                                                                                                                 0.7
averaging multiple simulations with different random initial-
izations. This disparity is eliminated in the eight-unit model,                                                  0.5
such that the model as a whole is initially unbiased toward any
                                                                                                                 0.3
of the four patterns. (We have implemented different sets of
controlled weights, e.g., 0.2 versus 0.8, or 0.4 versus 0.6, and
                                                                                                                       0   50     100 150 200 0       50     100 150 200
find that they all produce the same results.)
                                                                                                                                           Trial Number
                                                                                            Projections:                    H → HH           T → HH       H → TH      T → TH
                                        pA = 1/6                    pA = 1/3
                             1.00
                             0.95                                                     Figure 5: The updating trajectories of projection weights from
                             0.90                                                     context input units to detector units HH and TH during the train-
                                                                                      ing phase. The initial weight values are marked by the circles
      Detector Activations
                             0.85
                                                                                      at the first trial. For example, at pA = 1/2, the unit initially
                             0.80                                                     designated as the HH detector became an TH detector after ap-
                                        pA = 1/2                    pA = 2/3          proximately 200 trials, as all its weight values from the context
                             1.00
                                                                                      units switched to the opposite side of 0.5, whereas the unit
                             0.95                                                     initially designated as the TH detector remained stable. The
                             0.90                                                     same trend was also observed between TT and HT detectors.
                                                                                      The projection weights from the online input units remained
                             0.85
                                                                                      about the same thus are not plotted here.
                             0.80
                                    HT, TH    HH, TT         HT, TH       HH, TT         To locate the source of the alternation bias, we found that
                                                   Input Patterns                     during the training phase, the projection weights from the
                                                                                      context input units to each detector underwent a dramatic
Figure 4: Pattern dissociation at different levels of the proba-                      remapping (Figure 5), whereas the projection weights from
bility of alternation pA after training. The repetition detectors                     the online input units remained about the same.
HH and TT only showed higher activations when the model                                  Specifically, at pA = 1/2, the detector unit HH initially re-
was trained with sequences generated by pA < 1/3. Box plots                           ceived a weight of 0.7 from the context input unit H and a
represent distribution quantile.                                                      weight of 0.3 from the context input unit T (hence its initially
                                                                                      designated detecting status). After about 200 trials, these
   The eight-unit model was trained and tested in the same way                        two weights switched to the opposite sides of 0.5, effectively
as the bigger model, and the only difference is the analyses of                       “switching” the HH detector into a TH detector (but not a HT
the test results. Instead of counting the number of detectors,                        detector). Similarly, the TT detector switched to an HT detec-
we directly measure the activations of each detector given dif-                       tor (but not a TH detector). The directions of these switches
ferent input patterns. Figure 4 shows the main result. We first                       corresponded exactly to the pairwise precedence relationship
notice that after being trained with truly random sequences                           depicted in Figure 1C. At pA = 2/3, the switch was even more
(i.e., pA = 1/2 in independent fair coin tossing), the aver-                          obvious. At pA = 1/6, it was the alternation detectors’ turn to
                                                                                   3282

be under-represented and switched to the repetition detectors.         model, detector neurons “reoriented attention” to the past in-
Finally at pA = 1/3, all projection weights from the context           formation (i.e., remapping the projection weights from the
units approached then stabilized around 0.5, so that the model         context units), and the driving force behind such reorientation
eventually learned to be indifferent to the contextual informa-        was more of the waiting time rather than of the mean time of
tion, resulting in unbiased activations for all patterns as shown      patterns. As for the model with more neurons we reported
in Figure 4.                                                           earlier, the specialization of neurons would be more diversi-
   Moreover, we also tested models with only a subset of               fied thus would enable the model to develop sensitivity to both
particular detectors (e.g., HH versus TH only). When pA = 1/2,         types of pattern time statistics.
regardless of the initial pattern preference set by the projection         The observation that both models exhibited the alternation
weights, the model would eventually react indifferently to all         bias is consistent with the representativeness bias underpinning
patterns. This result indicates that in order to capture different     the gambler’s fallacy (Gilovich et al., 1985; Tversky & Kah-
pattern time statistics or the pairwise precedence odds between        neman, 1974). For example, Figure 4 show that at pA = 1/2,
patterns of length two (Figure 1), the inhibitory competition          the model had higher activations for alternation patterns than
between at least four types of detectors is required. When we          repetition patterns, in spite of the sequential independence of
tested models with only online input units, the model showed           events. Critically, such bias emerged through unsupervised
the same indifference at pA = 1/2. This indicates that predictive      training without any pre-defined hypothesis structures, since
learning, namely, predicting what will happen next based on            both models were initially symmetrically structured, and were
the historical context, is critical in producing the alternation       not provided with any prior knowledge on how different pA
bias. Together, these observations confirmed our hypothesis            levels would affect the occurrences of different patterns.
that this eight-unit model is a minimal model to produce the               Given the simplicity of our models, one far-reaching impli-
alternation bias in the gambler’s fallacy.                             cation is that cognitive biases and structured abstractions can
   In comparison, the alternation bias exhibited by the minimal        emerge early and locally at the level of sensory processing.
eight-unit model in Figure 3 is in the same direction as that          Nevertheless, it should be noted that our models only address
exhibited by the bigger model in Figure 2. However, the equi-          purely bottom-up learning mechanisms without implementing
librium point (the pA level where the model was indifferent to         any top-down learning or higher-level representations such as
all patterns) was different (compare Figure 2 with Figure 4).          beliefs or goals. For the early and locally developed biases
Specifically, the equilibrium point was pA = 1/3 for the eight-        to be maintained and utilized in later and global processes,
unit model but pA = 3/7 for the bigger model. This indicates           higher-level representations and top-down structures must also
that the minimal model was more sensitive to the waiting time          be involved through a hierarchical structure of abstractions
(delay) than to the mean time (frequency) of pattern occur-            (Munakata et al., 2011; Tenenbaum et al., 2011).
rences, because by Equations 1 and 3, all patterns have the                Lastly, probabilistic thinking has to consider the conse-
same waiting time but different mean times at pA = 1/3,                quence of time (Buchanan, 2013; Hawkins & Blakeslee, 2004).
                                                                       Our findings suggest that rich semantics in the learning envi-
  E[THH|∅ ] = E[THT|∅ ] = 11/2,    E[THH|H ] = 3,  E[THT|T ] = 6.      ronment can be extracted by neuron populations in predictive
                                                                       learning through temporal integration. This learning over time
In contrast, the bigger model was more “balanced” toward
                                                                       would lead to the structured hypothesis spaces such as those
both statistics, because at pA = 3/7,
                                                                       required by Bayesian inference thus provide essential building
       E[THH|∅ ] + E[THH|H ] = E[THT|∅ ] + E[THT|T ] = 55/6.           blocks in bridging the gap between neural computations and
                                                                       overt behavior.
One particular reason for such difference is that the competi-
tion would be stronger among fewer detectors due to the home-                               Acknowledgments
ostatic mechanism implemented in the network. This mecha-              This work was supported by the Air Force Office of Scien-
nism keeps individual neurons from firing too much or too lit-         tific Research (AFOSR) grant number FA9550-12-1-0457, the
tle over time, which is essentially a normalization mechanism          Office of Naval Research (ONR) grant number N00014-16-1-
in self-organizing learning at long time scales (Bienenstock,          2111.
Cooper, & Munro, 1982; Cooper, 2000; Hebb, 1949; O’Reilly,
Munakata, Frank, Hazy, & Contributors, 2012). As a conse-                                        References
quence, the bigger model with more neurons would be more               Adolphs, R. (2015). The unsolved problems of neuro-
likely to maintain diversity in the specialization of neurons             science. Trends in Cognitive Sciences, 19(4), 173–175.
thus its equilibrium point could be determined by both waiting            doi: 10.1016/j.tics.2015.01.007
time and mean time statistics.                                         Bienenstock, E. L., Cooper, L. N., & Munro, P. W. (1982).
                                                                          Theory for the development of neuron selectivity: Orien-
                          Conclusion                                      tation specificity and binocular interaction in visual cortex.
Overall, our results from both models suggest that pattern dis-           The Journal of Neuroscience, 2(1), 32–48.
sociation can naturally emerge from temporal reconstructions           Buchanan, M. (2013). Gamble with time. Nature Physics,
of the input data. Particularly with the minimal eight-neuron             9(1), 3. doi: 10.1038/nphys2520
                                                                   3283

Budescu, D. V. (1987). A Markov model for generation of           O’Reilly, R. C., Munakata, Y., Frank, M. J., Hazy,
  random binary sequences. Journal of Experimental Psychol-         T. E., & Contributors. (2012). Computational cog-
  ogy: Human Perception and Performance, 13(1), 25–39.              nitive neuroscience. Wiki Book, 1st Edition, URL:
  doi: 10.1037/0096-1523.13.1.25                                    http://ccnbook.colorado.edu.
Cooper, L. N. (2000). Memories and memory: A                      O’Reilly, R. C., Wyatte, D., & Rohrlich, J. (2014). Learn-
  physicist’s approach to the brain. International Jour-            ing through time in the thalamocortical loops. Preprint at:
  nal of Modern Physics A, 15(26), 4069–4082. doi:                  http://arxiv.org/abs/1407.3432.
  10.1142/S0217751X0000272X                                       Oskarsson, A. T., Van Boven, L., McClelland, G. H., & Hastie,
Dehaene, S., & Brannon, E. M. (2010). Space, time, and              R. (2009). What’s next? Judging sequences of binary
  number: A Kantian research program. Trends in Cognitive           events. Psychological Bulletin, 135(2), 262–285. doi:
  Sciences, 14(12), 517–519. doi: 10.1016/j.tics.2010.09.009        10.1037/a0014821
Elman, J. L. (1990). Finding structure in time. Cognitive Sci-    Pouget, A., Beck, J. M., Ma, W. J., & Latham, P. E. (2013).
  ence, 14(2), 179–211. doi: 10.1207/s15516709cog1402 1             Probabilistic brains: Knowns and unknowns. Nature Neuro-
Falk, R., & Konold, C. (1997). Making sense of randomness:          science, 16(9), 1170–1178. doi: 10.1038/nn.3495
  Implicit encoding as a basis for judgment. Psychological Re-    Ross, S. M. (2007). Introduction to probability models (9th
  view, 104(2), 301–318. doi: 10.1037/0033-295x.104.2.301           ed.). San Diego, CA: Academic Press.
Gigerenzer, G., & Hoffrage, U. (1995). How to improve             Sun, Y., OReilly, R. C., Bhattacharyya, R., Smith, J. W., Liu,
  Bayesian reasoning without instruction: Frequency formats.        X., & Wang, H. (2015). Latent structure in random se-
  Psychological Review, 102(4), 684–704. doi: 10.1037/0033-         quences drives neural learning toward a rational bias. Pro-
  295x.102.4.684                                                    ceedings of the National Academy of Sciences, 112(12),
Gilovich, T., Vallone, R., & Tversky, A. (1985). The hot hand       3788–3792. doi: 10.1073/pnas.1422036112
  in basketball: On the misperception of random sequences.        Sun, Y., Tweney, R. D., & Wang, H. (2010). Occurrence and
  Cognitive Psychology, 17(3), 295–314. doi: 10.1016/0010-          nonoccurrence of random sequences: Comment on Hahn
  0285(85)90010-6                                                   and Warren (2009). Psychological Review, 117(2), 697–703.
Goodfellow, L. D. (1938). A psychological interpretation            doi: 10.1037/a0018994
  of the results of the zenith radio experiments in telepathy.    Sun, Y., & Wang, H. (2010a). Gambler’s fallacy, hot hand
  Journal of Experimental Psychology, 23(6), 601–632. doi:          belief, and time of patterns. Judgment and Decision Making,
  10.1037/h0058392                                                  5(2), 124–132.
                                                                  Sun, Y., & Wang, H. (2010b). Perception of randomness: On
Griffiths, T. L., & Tenenbaum, J. B. (2001). Randomness and
                                                                    the time of streaks. Cognitive Psychology, 61(4), 333–342.
  coincidences: Reconciling intuition and probability theory.
                                                                    doi: 10.1016/j.cogpsych.2010.07.001
  In J. D. Moore & K. Stenning (Eds.), Proceedings of the
                                                                  Sun, Y., & Wang, H. (2012). Perception of randomness: Sub-
  23rd annual conference of the cognitive science society (pp.
                                                                    jective probability of alternation. In N. Miyake, D. Peebles,
  370–375). Mahwah, NJ: Lawrence Erlbaum Associates.
                                                                    & R. P. Cooper (Eds.), Proceedings of the 34th annual con-
Hahn, U., & Warren, P. A. (2009). Perceptions of randomness:
                                                                    ference of the cognitive science society (pp. 1024–1029).
  Why three heads are better than four. Psychological Review,
                                                                    Austin, TX: Cognitive Science Society.
  116(2), 454–461. doi: 10.1037/a0015241
                                                                  Sun, Y., & Wang, H. (2015). Generating functions in neural
Hawkins, J., & Blakeslee, S. (2004). On intelligence. New
                                                                    learning of sequential structures. In D. C. Noelle et al. (Eds.),
  York: Henry Holt.
                                                                    Proceedings of the 37th annual conference of the cognitive
Hebb, D. O. (1949). The organization of behavior. New York:         science society (pp. 2302–2307). Austin, TX: Cognitive
  Wiley.                                                            Science Society.
Lopes, L. L., & Oden, G. C. (1987). Distinguishing between        Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
  random and nonrandom events. Journal of Experimental              N. D. (2011). How to grow a mind: Statistics, struc-
  Psychology: Learning Memory and Cognition, 13(3), 392–            ture, and abstraction. Science, 331(6022), 1279–1285. doi:
  400. doi: 10.1037/0278-7393.13.3.392                              10.1126/science.1192788
Munakata, Y., Herd, S. A., Chatham, C. H., Depue, B. E.,          Tversky, A., & Kahneman, D. (1974). Judgment under un-
  Banich, M. T., & OReilly, R. C. (2011). A unified frame-          certainty: Heuristics and biases. Science, 185(4157), 1124–
  work for inhibitory control. Trends in Cognitive Sciences,        1131. doi: 10.1126/science.185.4157.1124
  15(10), 453-459. doi: 10.1016/j.tics.2011.07.011
Nickerson, R. S. (2002). The production and perception of
  randomness. Psychological Review, 109(2), 330–357. doi:
  10.1037//0033-295X.109.2.330
Oppenheimer, D. M., & Monin, B. (2009). The retrospective
  gambler’s fallacy: Unlikely events, constructing the past,
  and multiple universes. Judgment and Decision Making,
  4(5), 326–334.
                                                              3284

