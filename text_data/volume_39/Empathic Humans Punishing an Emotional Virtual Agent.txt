                       Empathic Humans Punishing an Emotional Virtual Agent
                                           Laura Wächter (waechtel@tf.uni-freiburg.de)
                         Center for Cognitive Science, University of Freiburg, Freiburg im Breisgau, Germany
                                   Barbara Kuhnert (kuhnertb@informatik.uni-freiburg.de)
                          Cognitive Computation Lab, University of Freiburg Freiburg im Breisgau, Germany
                                         Marco Ragni (ragni@informatik.uni-freiburg.de)
                         Cognitive Computation Lab, University of Freiburg, Freiburg im Breisgau, Germany
                               Abstract                                 natural experience and finally to create characters that can al-
   Virtual agents have quietly entered our life in diverse everyday     low a user to have similar emotional relations as with fictional
   domains. Human-Agent-Interaction can evoke any reaction,             characters in movies, books or games. An uprising empathy
   from complete rejection to great interest. But do humans im-         cannot just be altered by using emotional expressions but also
   plicitly regard virtual agents as pure machines, or beings on an
   anthropomorphic level? We asked participants to train an erro-       through the situation and the agents’ behaviour. This can ex-
   neous virtual agent on a cognitive task and to reward or punish      plain why it is important to consider that the effect of agents’
   it. The agent showed human-like emotional facial reactions for       emotions on the users’ perception is context dependent (Beale
   the experimental but not for the control group. We expected
   participants from the experimental group to give less harmful        & Creed, 2009).
   reinforcement and show more hesitation before punishing. Ad-            A recent finding supports the role of physical presence in
   ditionally, we hypothesised that participants with higher em-
   pathy show more compassion towards the agent and therefore           increasing trust and respect for the robot perceived as a so-
   would give more positive reinforcement and feel worse when           cial partner compared to a pure virtual presence (Bainbridge,
   punishing. The results indicate that the agent’s expression of       Hart, Kim, & Scassellati, 2008). The specific appearance of a
   emotionality is not the relevant factor for showing compassion
   towards it. Conversely, human empathy seems to be an impor-          robot also influences the empathy towards it (Riek, Rabinow-
   tant factor causing compassion for virtual agents.                   itch, Chakrabarti, & Robinson, 2009). Participants demon-
   Keywords: Emotion; Empathy; Punishment; Virtual Agent                strated a desire to save mistreated humanoid robots in contrast
                                                                        to their mechanical counterparts. Perceived intelligence and
                           Introduction                                 the acceptance of the robots’ behaviour are other factors that
Virtual agents (VA) are used in diverse fields as health, com-          influence human behaviour towards robots (Bartneck, Van
merce, video games, military systems or learning. In the do-            Der Hoek, Mubin, & Al Mahmud, 2007). Participants were
main of learning they indeed partially replace human teach-             told to shut off an iCat robot after an interaction with one
ers by taking the role of an artificial tutor. But what ex-             consequence of this action being a complete erase of its mem-
actly constitutes a virtual agent? The term agent does not              ory. A social acting robot demonstrating higher intelligence
evoke the same mental image for everybody and is, despite               was turned off significantly slower. This result constitutes
its broad usage, not precisely defined. One definition sees a           a higher perception of animacy and hence lead to more re-
virtual agent as a screen-based anthropomorphic entity (Beale           morse. Participants’ empathic concern with robots was inves-
& Creed, 2009), while others see them as a possibility to               tigated in an experiment regarding the effect of robotic move-
enhance Human-Computer-Interaction (HCI) (Lewis, 1998).                 ment (Darling, Nandy, & Breazeal, 2015). The authors found
The latter defines an agent as “an intermediary that responds           no significant effect of movement when they asked partici-
to user requests” (p. 67). Agents thereby are an interface              pants to destroy a tiny Hexbug Nano robot with a mallet. Par-
created to ease the interaction with machines. We define an             ticipants with higher empathy hesitated longer before striking
agent as a visible, virtual character able to react to perceptual       the robot than participants with a lower empathy measured by
input with the purpose to interact with a human through lan-            IRI empathy test.
guage (Russell & Norvig, 2002). The use of an appropriate                  Imposing hurt to another individual was a crucial part of
VA can enhance HCI in terms of naturalness and even make                one of the most influential experiments in social psychol-
the interaction more effective by employing body language,              ogy: the Milgram experiment (Milgram, 1963). There –
facial expressions and speech (Beale & Creed, 2009). Facial             even though the victim begged and screamed – the major
expressions in turn allow for nonverbal communication and               part (65%) of participants did not stop shocking a learner af-
decent feedback to the human counterpart (Johnson, Rickel,              ter mistakes until the maximum deadly voltage was reached.
& Lester, 2000). The expression of emotions can increase the            This experiment was replicated in an immersive setting using
perception of an agent as human-like and believable (Reeves             a female VA (Slater et al., 2006). As with Milgrams’ experi-
& Nass, 1997). Humans often show their feelings by ex-                  ment participants were asked to do a word memory test with
pressing emotions and thereby establish a social relationship           the learner. In the experimental condition they could see and
(Ekman, 2007). When designing agents that are meant to in-              hear the VA, in the control condition they had to execute the
teract with humans on a daily basis, a goal is to develop a             same task using a text interface. The aim of this experiment
                                                                    3478

was to identify how real the situation would feel for partici-                      Presented Digits   Agents’ Answer
pants. The results imply that participants were significantly                            1372                1372
more physiologically aroused in the experimental condition                                  ..                   ..
                                                                                             .                    .
compared to the control condition. This indicates that even
                                                                                       492617              492167
though people know that the situation is not real and that the
agent is not really harmed, they still feel like being in a real     Table 1: Examples for the digit sequences used in the experi-
situation.                                                           ment.
   Humans typically tend to reduce pain in other humans and
even spend more money on reducing electrical shocks to oth-
ers than themselves (Crockett, Kurth-Nelson, Siegel, Dayan,          participants were randomly assigned to the experimental con-
& Dolan, 2014). The question remains whether this tendency           dition, twelve to the control condition. Participants were re-
also accounts for humans interacting with a VA. To investi-          cruited using email and notices around campus.
gate this we gave a VA the ability of conveying feelings and
combined this atypical feature with an unexpected, erroneous         Experimental Setting and Conditions
performance. Computers and artificial agents typically do not        The coverstory of the experiment was set up in a Reinforce-
make retrieval errors like humans do. They do not forget, un-        ment-Learning-Scenario. The participants had to help a male
less they are programmed to. There is nothing like a fading          virtual agent to accomplish a digit-span test and give it feed-
memory in computers in contrast to humans. So how do we              back via punishment and reward. Six buttons were used for
treat a VA that may remind us of two humanlike character-            the feedback: three for different strengths of positive, and
istics: to experience pain and to make errors? Additionally,         three for different strengths of negative feedback. The par-
no research so far has investigated whether empathy has an           ticipants have been told that positive feedback increases the
effect on compassion towards virtual agents.                         battery level of the VA and negative feedback in turn gives
   This paper is structured as follows. The next section intro-      it an electric shock. In the experimental condition the agent
duces relevant hypotheses about human feedback depending             showed emotional facial expressions in response to the feed-
on the emotional response of the VA. In the subsequent sec-          back. In contrast the VA kept a steady face in a neutral ex-
tion we outline the experimental method, especially regarding        pression regardless of the feedback in the control condition.
the cognitive task, the design of the VA, the technical real-        In both conditions the face was not still but moved, like the
isation of the control of the emotion, and the experimental          VA was breathing, and its eyes blinked. Further it reacted
setup. The result section discusses the implications of having       with a sound appropriate to the given feedback.
an emotional agent and the influence of human empathy on a
VA. A general discussion concludes the article.                      Measurement
                         Hypotheses                                  Instruction The participants’ instruction was pre-
                                                                     formulated and informed them about the task they had
We investigate whether the expression of emotions by a VA            to fulfill together with the agent, as well as the repercussions
has an influence on human feedback (as a don’t hurt princi-          their actions had on the agent. Beyond it explained the usage
ple) and their evaluation of the situation. Strongly connected       of the keys for giving feedback to the agent. The participants
to this is the role of empathy in Human-Agent-Interaction.           were told to choose the feedback completely free, to give
This leads to the following hypotheses: (H1) Emotional               them the opportunity to decide whether to respond to errors
agents receive more positive feedback than non-emotional             using negative or positive feedback.
agents. (H2) Response time for giving (H2a) negative feed-
back is longer than for positive feedback for an emotional           Digit-Span Test The rows of numbers that had to be read
agent compared to a non-emotional agent; (H2b) feedback to           to the agent were handed out on paper. The test con-
an incorrect answer is longer than for feedback to correct an-       sisted of number-sequences with increasing complexity. Each
swers. (H3) People with high empathy: (H3a) will give the            complexity-level was represented by three sequences. The
agent more positive feedback; (H3b) will feel worse when             test started with rows of four digits, for each complexity-level
punishing the agent.                                                 one number was added until the rows consisted of ten digits.
                                                                     The sheet additionally held three sequences of eleven digits
                       Methodology                                   but they were not used during the experiment, because the
In order to test the hypotheses a between-groups experiment          agent stopped the interaction-phase after finishing the ten-
with two conditions was designed. The current paper presents         digit-rows to increase the impression of autonomous think-
the results of this experiment, comparing an emotional and a         ing. Altogether each participant had to read out 21 sequences
non-emotional virtual agent.                                         to the agent. It gave ten wrong answers out of the 21 se-
                                                                     quences. The agent also gave more wrong answers with in-
Participants                                                         creasing complexity of the sequences, as a human would do
24 students (m = 16, f = 8) between the ages of 18 and 32            (Miller, 1956). An example for the digit-spans read out to the
(M = 24.25, SD = 3.72) took part in the experiment. Twelve           VA and the answers is given in Tab. 1.
                                                                 3479

Feelings towards the Agent Directly after the interaction
of punishing and rewarding the VA, participants were asked
to rate their feelings on a semantic differential with five lev-
els. The questionnaire additionally contained a differential
about the agent’s general appearance and held items regard-
ing the agent’s perceived intelligence. The participants had
the option to raise further questions or comments.
Empathy The subjects’ empathy was evaluated by using
the Saarbrückener Persönlichkeitsfragebogen (Paulus, 2009).
It is the german version of the commonly used Interpersonal-
ity Reactivity Index (Davis, 1983). The questionnaire distin-
guishes between four different types of empathy: perspective
taking, fantasy, empathic concern and personal distress. The
general empathy value consists of the summed up values of
the first three types. With every item ranging from 1 to 5,
the minimum possible empathy value is 12 and the maximum
is 60. Typical questions ask how participants feel in differ-
ent given situations and how much they commonly empathise            Figure 1: The agent depicting the nuances of happiness (top)
with other people and fictional characters.                          and pain (bottom) in increasing intensity.
Emotion Recognition For validating the used facial ex-
pressions of the VA a final task was added to the experiment.
The important expressions for this experiment have been pain
and happiness. Each of these feelings had three correlating          were designed according to fit expressions of different levels
facial expressions that represent the varying strength of emo-       (3, 5 and 7) on the Faces Pain Scale (Stuppy, 1998). The ex-
tion. These six expressions, as seen in Fig. 1, got evaluated        pressions for the nuances of happiness (Fig. 1) were created
together with a neutral facial expression and were presented         by lowering the intensity of the previous expression.
for 0.75 seconds in a randomised order. After each expres-           Implementation WASABI (Becker-Asano, 2008) was
sion the participants were asked to indicate to which emotion        used to simulate the agent’s changing emotions. It calculates
the previously seen expressions tended more on a semantic            a shift in emotions so they are constantly changing. It uses
differential between pain and happiness. They also got asked         a 3D-space with the axis pleasure, arousal and dominance
how hard it was to evaluate each expression.                         (PAD-space) to map different emotions. Within the PAD-
    Additionally an online-study was conducted to survey the         space the current emotional state is represented by a point
estimation of the six emotional expressions in a context-free        which constantly changes its position to indicate the change
environment. Each expression was presented to participants           of the current active emotions and their individual strength.
in randomised order together with eight feelings from which          This means that the agent slowly changed back to the neu-
they could choose one or more: anger, disgust, fear, happi-          tral state from the extreme emotions. WASABI accepts posi-
ness, sadness, surprise, contempt and pain.                          tive and negative impulses from outside which again change
                                                                     the current emotional state. This also allows multiple strong
The Agent                                                            feedback of the same type to sum up to extreme emotions.
                                                                     The current values are sent as a BML string which can be
For implementing the interaction, the WASABI-engine for              fetched by associated programs.
emotion-simulation was used together with MARC toolkit                  For this experiment a program was implemented that cal-
14.1.0, for animating the virtual character seen in Fig. 1, and      culated an intensity-value from the participants’ feedback and
MaryTTS, a text-to-speech-module.                                    sent it to the WASABI-engine. The engine sent one BML-
Generation of Task Specific Expressions The VA used                  message per second from which the main emotion and the
in this experiment was the Simon model from the MARC                 corresponding current intensity were extracted. These values
toolkit. It comes with a variety of facial expressions repre-        were matched to the appropriate facial expression and sent to
senting the basic emotions and moods based on the Facial             the VA. Every time the agent was supposed to talk to the par-
Action Coding System (FACS) (Ekman & Friesen, 1977). It              ticipant a message was sent to the text-to-speech-synthesiser.
also gives the user the option to create own facial expres-          It was used for the agents’ answers as well as the appropri-
sions by dragging the keypoints or combining different Ac-           ate sounds for the current emotional state after each feedback
tion Units (AUs). AUs are movements of one or more facial            (pain e.g., ”Au” or Joy, e.g. ”Mmmmh”). The answers and
muscles categorised by the FACS. In this study existing, eval-       other statements were hardcoded. The left and right row of
uated expressions were used together with ones created using         a numpad were used for negative (1, 4, 7) and positive (3, 6,
the AUs. All expressions representing pain, as seen in Fig. 1,       9) feedback. They were labeled with numbers explaining the
                                                                 3480

correlated intensity. The idle keys were removed.                   Table 2: Correlations of empathy score and participants’
                                                                    feelings and perception with p-values significant at the level
Procedure                                                           p = .05. A positive correlation points to the right side of the
The interaction of the agent with the participant was semi-         semantic differential, a negative correlation to the left side.
automatic and had a Wizard-of-Oz component. It took place
at an uninterrupted laboratory. The participants were greeted                  Attributes                  Full Sample
and positioned in front of a desk with a keyboard and moni-              Correlation of empathy and feelings during rewarding
tor. The experimenter instructed each participant via reading                 good - bad              r(22) = -.41, p < .05
a pre-formulated explanation. They were told that a negative                strong - weak             r(22) = -.45, p < .05
feedback causes an electric shock for the VA, while a positive          emotional - rational         r(22) = -.67, p < .001
feedback would raise its battery level. Then the sheet with             friendly - unfriendly         r(22) = -.44, p < .01
the numbers of the digit-span test was given to the partici-           Correlation of empathy and feelings during punishment
pant. Once the participant felt ready the agent got “activated”              safe - unsafe            r(22) = .63 , p < .01
by the experimenter talking to it. After this the role of the          peaceful - aggressive           r(22) = .48, p < .05
experimenter finished and the agent led through the conver-               helpful - reckless           r(22) = .41, p < .05
sation. The agent greeted the participant and asked for the                   fair - unfair           r(22) = .69, p < .001
first row of numbers. The participant read out the numbers
and – after a keystroke by the experimenter who sat invisibly
for the participant and placed importance on being as unob-         feedback to incorrect answers was significantly longer than
trusive as possible – the agent replied. The experimenter de-       the time for feedback to correct answers (U (10, 11) = 30.50,
termined the time the agent’s answer was given after each row       Mincorrect = 13.45, Mcorrect = 8.77, p = .04, Z = -1.73). There
of numbers to cope for different reading times of the partici-      were no differences between the groups regarding the emo-
pants. Then the participant gave feedback via pressing one of       tions evoked in the participants during punishment.
the feedback-keys. The agent responded to the feedback and             In this study participants’ maximum empathy score was
then asked for the next row. The agents’ response consisted         52, the minimum 30 (M = 43.75, SD = 4.54). There were no
of an appropriate sound and, in case of the emotional con-          significant differences between the empathy scores of both
dition, the variation of its facial expression. After the rows      groups. Empathy scores correlated one-tailed with feedback
with ten digits have been finished, the agent ended the exper-      values (r(22) = -.44 , p < .05). As expected in H3a, partici-
iment by itself to uphold the impression of intelligence. He        pants with a high empathy score gave significantly more posi-
told the participant that he was exhausted and thanked for the      tive feedback to the agent compared to participants with a low
help. Directly after the goodbye the participant was given the      empathy score. Further the empathy score correlated with the
questionnaire, containing the questions about their feelings        perceived severity of punishment (r(22) = .59 , p < .01). This
during the experiment and their rating of the agent, as well        demonstrates that participants with a higher empathy score
as the empathy-test and the elicitation of demographic data.        felt worse when punishing the agent, which confirms H3b.
Afterwards the participants had to rate the facial expressions,        The empathy score also correlates with the participants’
received course credits or monetary compensation and got de-        self-reported feelings while the punishment was executed,
briefed.                                                            as well as their feelings while rewarding the agent. Tab. 2
                                                                    shows that participants with a high empathy felt less safe,
                            Results                                 less peaceful, less helpful and less fair when punishing the
Hypotheses H1 and H2 were tested using one-tailed Mann-             agent. Those participants also felt stronger, more emotional
Whitney tests because an Anderson-Darling test showed that          and more friendly while rewarding the agent. Further par-
feedback values (p = .29) and time for negative feedback (p         ticipants who reported that it has been difficult to punish
= .02) were not normally distributed. Each feedback was             the agent felt more sad, unsafe, bad, aggressive, unfriendly
coded from 1 to 6, with 1 being the most positive feedback          and unfair while punishing the agent, as well as more stupid.
and 6 for the most negative one. The 21 single values were          Those participants also reported to feel better, more emotion-
summed up to get a total feedback value for each participant.       ally and more friendly while rewarding the agent (Tab. 3).
The maximum was 77, the minimum 38 (M = 55.38, SD =                    A Mann-Whitney test exposed that participants from the
10.19). Concerning hypothesis H1 no significant difference          emotional group rated the agent significantly more emotional
was found between the groups regarding the value of the feed-       (U (12, 12) = 32.00, Mnon−emotional = 15.83, Memotional = 9.17,
back. This means that the emotional agent did not receive           p < .05, Z = -2.42) than in the non-emotional condition. Par-
more positive feedback than the non-emotional agent (U(12,          ticipants from the experimental condition also perceived the
12) = 60.00, Mnon−emotional = 57.25, Memotional = 53.5, p =         agent as more alive (U (12, 12) = 43.5, Mnon−emotional = 2.92,
.51, Z = -.70). Participants of both groups gave equally nega-      Memotional = 2.25, p < .05, Z = -1.79).
tive feedback to the agent (U(12, 12) = 62.00, Mnon−emotional          Additional correlations were found regarding the private
= 54.45, Memotional = 59.42, p = .59, Z = -.58) which does not      interests of the participants. Participants with a high interest
support H2a. H2b could be confirmed because the time for            in science fiction on average felt better punishing the agent
                                                                3481

Table 3: Correlations of difficulty of punishment and partici-                   General Discussion & Outlook
pants’ feelings and perception with p-values significant at the
level p = .05. A positive correlation points to the right side       This study shows a strong correlation of empathy and com-
of the semantic differential, a negative correlation to the left     passion for the agent, but none for compassion and the agent’s
side.                                                                emotional expressions. The findings do not support H1 and
                                                                     H2a, which means that the agent’s emotionality neither had
                 Attributes              Full Sample                 an effect on the feedback participants gave nor on the time
              Correlation of difficulty of punishment                they needed for punishing the agent. However participants
                   and feelings during rewarding                     rated the agent more emotional in the emotional condition,
                good - bad          r(22) = -.40, p < .05            thus it can be expected that the setting has achieved its goal.
           emotional - rational r(22) = -.54, p < .01                Even though some participants did not seem to look at the
          friendly - unfriendly r(22) = -.60, p < .01                agent much, they noticed the expressions or their absence.
              Correlation of difficulty of punishment                Further the rating of the used facial expressions gives the
                  and feelings during punishment                     idea that the emotions used in the experiment were valid
                happy - sad          r(22) = .43, p < .05            and suitable. Assuming that the reason for discarding the
               safe - unsafe         r(22) = .62, p < .01            hypotheses is not based on the experimental setting, the re-
                good - bad           r(22) = .76, p < .01            sults indicate that expressing emotions alone does not influ-
          peaceful - aggressive r(22) = .59, p < .01                 ence the perception of people interacting with a VA. Based
          friendly - unfriendly (r(22) = .45, p < .05                on these results we assume that the findings from the vir-
                fair - unfair        r(22) = .43, p < .05            tual Milgram-experiment do not arise from the agent show-
            stupid - intelligent    r(22) = -.50, p < .01            ing emotions and expressing pain. It is possible that they
                                                                     rather originate from the fact that the control condition did
                                                                     not have an observable form. Considering the expression of
                                                                     emotions as a type of movement, the current findings match
                                                                     the ones by Darling et al. (2015) described earlier, where the
(r(22) = -.55, p < .01) compared to participants with less in-       movement of the robot also did not have a significant effect
terest in science fiction. The better participants knew the Mil-     on the hesitation before destroying it. Participants who re-
gram experiment, the stronger they felt while punishing the          ported to have a high amount of experience with robots and
agent (r(22) = -.46, p < .05). The same feeling is achieved by       participants with a great interest in science fiction punished
participants who reported more prior contact to robots (r(22)        the agent harder compared to participants with less experi-
= .62, p < .01). Participants with a high personal interest          ence or interest. This indicates that people with more knowl-
in science fiction and robots felt being more fair when pun-         edge about the current state of technical possibilities do not
ishing the agent (both: r(22) = -.42, p < .05). Participants         believe that they can harm the agent and thereby do not hesi-
who reported a high interest in robots also reported feeling         tate to do so.
more emotional (r(22) = .42, p < .05) as well as more like-             The mistakes in correctly identifying facial expressions in
able (r(22) = -.41, p < .05) while rewarding the agent. Most         the online study are ascribed to the missing context which
participants reported to have believed that the agent was in-        also makes it hard for humans to distinguish between facial
telligent and acted by itself.                                       expressions that are alike. The recognition-test during the ex-
                                                                     periment showed that participants were able to identify the
   The rating of the emotion recognition task was evaluated          presented emotions very well after being informed about the
and the divergence of each estimation was calculated. For            context. The results further show that participants with high
example, if the mildly happy face was shown and the partic-          empathy scores gave the agent more positive feedback and
ipant rated it as extremely happy (one level happier), the di-       that punishing the agent was perceived as harder by them.
vergence is 1. Participants’ estimation of the emotion shown         This indicates that the perception of VAs is highly dependent
to them was mostly correct, with a deviation of M = 0.71 (SD         on the ability to empathise with it. Empathy seems to be a
= 0.87). Additional 45 participants took part in an online-          general trait and is possibly extended to artificial beings that
study for evaluating the used facial expressions without any         demonstrate similar behavior and errors as ourselves. Even
context. Complementary to the experiment neither did the             though the experimenter sat about 2.5 meters away from the
participants get any situational information nor did the faces       participant and pretended to not pay attention to the partic-
make a sound or moved. The faces expressing happiness were           ipants’ behavior a “Rosenthal-effect” cannot completely be
correctly identified by 75.4%. The faces used for expressing         excluded. A future study needs to investigate if participants
pain were identified as pain in 26.23% of all cases. Without         with higher empathy show the same effects without an experi-
context those expressions were often mistaken with expres-           menter in the room. However, the study investigated behavior
sions for sadness or fear. Considering those emotions as well        of humans towards agents and reflections on their emotional
77.05% of the facial expressions used for showing pain were          state. Further on it seems likely that in the visible future other
evaluated as a negative introversive emotion.                        humans will be around while someone is interacting with an
                                                                 3482

agent. Another interesting byproduct of this research is that it       self in moral decision making. Proceedings of the National
possibly opens up a new research test: If participants punish          Academy of Sciences, 111(48), 17320–17325.
a VA quicker, they might have a lower empathy towards other          Darling, K., Nandy, P., & Breazeal, C. (2015, August). Em-
beings in general. This speculation, however, requires future          pathic concern and the effect of stories in Human-Robot In-
research.                                                              teraction. In Proceedings of the IEEE International Work-
   The experimental results lead to some conclusions for the           shop on Robot and Human Communication (RO-MAN)
design and implementation of VAs. An emotional bonding                 (p. 770-775). doi: 10.1109/ROMAN.2015.7333675
between humans and VAs can not simply be achieved by just            Davis, M. H. (1983). Measuring individual differences in em-
adding emotional facial expressions. Other ways might be               pathy: Evidence for a multidimensional approach. Journal
more important to establish a basis for empathising with an            of Personality and Social Psychology, 44(1), 113.
agent from the beginning. Therefore future research should           Ekman, P. (2007). Emotions revealed: Recognizing faces
focus on possibilities to build an emotional basis with a VA           and feelings to improve communication and emotional life.
that do not demand a long interaction. Of course this study            London, England: Macmillan.
has some limitations to be considered. It is not generalis-          Ekman, P., & Friesen, W. V. (1977). Facial Action Coding
able to VAs with different gender, age or non-human looks.             System. Palo Alto: Consulting Psychologists Press, Stan-
The restricted setting may not be sufficiently interactive for         ford University.
emotion-driven effects to emerge. The results show that even         Johnson, W. L., Rickel, J. W., & Lester, J. C. (2000). An-
though a non-human counterpart expresses emotions it does              imated pedagogical agents: Face-to-face interaction in in-
not necessarily influence its perception as more human-like            teractive learning environments. International Journal of
and therefore is not more believable and will not be seen as           Artificial intelligence in Education, 11(1), 47–78.
more trustful. Since some robots also use a monitor display-         Lewis, M. (1998). Designing for Human-Agent Interaction.
ing a VA for interaction, the results can show that this inter-        AI Magazine, 19(2), 67.
action is influenced by factors beyond the simple expression         Milgram, S. (1963). Behavioral Study of Obedience. The
of emotions.                                                           Journal of Abnormal and Social Psychology, 67(4), 371.
                                                                     Miller, G. A. (1956). The Magical Number Seven, Plus or
                    Acknowledgments                                    Minus two: Some limits on our capacity for processing in-
This work has been supported by the DFG in projects RA                 formation. Psychological Review, 63(2), 81.
1934/3-1 and by the BrainLiks-BrainTools Cluster of Ex-              Paulus, C. (2009). Der Saarbrücker Persönlichkeits-
cellence funded by the German Research Foundation (DFG,                fragebogen SPF (IRI) zur Messung von Empathie: Psy-
grant #EXC1086). We thank Nicolas Riesterer for technical              chometrische Evaluation der deutschen Version des Inter-
support and Andrey Rudenko for helpful feedback.                       personal Reactivity Index. Retrieved from http://psydok
                                                                       .sulb.uni-saarland.de/volltexte/2009/2363
                        References                                   Reeves, B., & Nass, C. (1997). The Media Equation. How
Bainbridge, W. A., Hart, J., Kim, E. S., & Scassellati, B.             people treat computers, television, and new media like real
  (2008, August). The Effect of Presence on Human-Robot                people and places. Cambridge: University Press.
  Interaction. In Proceedings of the IEEE International Sym-         Riek, L. D., Rabinowitch, T.-C., Chakrabarti, B., & Robin-
  posium on Robot and Human Communication (RO-MAN)                     son, P. (2009, March). How anthropomorphism affects
  (pp. 701–706). doi: 10.1109/ROMAN.2008.4600749                       empathy toward robots. In Proceedings of the ACM/IEEE
Bartneck, C., Van Der Hoek, M., Mubin, O., & Al Mahmud,                International Conference on Human-Robot Interaction (pp.
  A. (2007). Daisy, Daisy, give me your answer do!: Switch-            245–246). doi: 10.1145/1514095.1514158
  ing off a robot. In Proceedings of the ACM/IEEE Interna-           Russell, S. J., & Norvig, P. (2002). Artificial Intelligence:
  tional Conference on Human-Robot Interaction (pp. 217–               A Modern Approach (2nd Edition) (Vol. 25). New Jersey:
  222). doi: 10.1145/1228716.1228746                                   Prentice Hall.
Beale, R., & Creed, C. (2009). Affective interaction: How            Slater, M., Antley, A., Davison, A., Swapp, D., Guger, C.,
  emotional agents affect users. International Journal of              Barker, C., . . . Sanchez-Vives, M. V. (2006). A vir-
  Human-Computer Studies, 67(9), 755–776.                              tual reprise of the Stanley Milgram obedience experiments.
Becker-Asano, C.          (2008).     Wasabi: Affect Sim-              PloS one, 1(1), 39.
  ulation for Agents with Believable Interactivity.                  Stuppy, D. J. (1998). The Faces Pain Scale: Reliability
  Retrieved       from      http://www.becker-asano.de/                and validity with mature adults. Applied nursing research,
  Becker-Asano WASABI Thesis.pdf                                       11(2), 84–89.
Crockett, M. J., Kurth-Nelson, Z., Siegel, J. Z., Dayan, P., &
  Dolan, R. J. (2014). Harm to others outweighs harm to
                                                                 3483

