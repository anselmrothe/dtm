   Learning to Learn Visual Object Categories by Integrating Deep Learning with
                                                          Hierarchical Bayes
                                                  Andres Campero (campero@mit.edu)
                                                    Andrew Francl (francl@mit.edu)
                                                  Joshua B. Tenenbaum (jbt@mit.edu)
                                                  Department of Brain and Cognitive Sciences
                                           Massachusetts Institute of Technology, MA 02139 USA
                               Abstract                                    as strong constraints to learn and generalize names for objects
                                                                           from just one or a few examples.
   Humans are capable of generalizing and learning new concepts
   after very little experience. They have the ability to create se-          Previous attempts to capture these abilities in computa-
   mantic structures from concepts they acquire, they can learn            tional models have had some success, but not with mod-
   appropriate inductive biases that are later used as priors for dif-     els that are “image-computable” on the same stimuli that
   ferent tasks, and they can learn novel categories from very few
   examples. While recent advances in neural networks and other            people see. These earlier models have used either adult
   machine learning methods are beginning to approach human-               similarity judgments (Xu & Tenenbaum, 2007) or highly
   level capabilities in several tasks, building computational mod-        simplified, idealized feature representations (Kemp, Perfors,
   els that replicate these abilities has proven difficult. We pro-
   pose a model that combines powerful features extracted from             & Tenenbaum, 2007) to build their category hierarchies.
   a deep neural network with a semantic structure inferred using          Here we show that a computational framework can come
   probabilistic Hierarchical Bayes. We test and demonstrate the           close to capturing abilities (1-3) by combining two powerful
   capabilities of our model in three different tasks: learning a
   new concept from a single example of a novel category, learn-           representation-learning techniques: deep learning for feature
   ing new categories from few examples of different categories,           construction and Hierarchical Bayes for unsupervised taxon-
   and learning the semantic tree from an unlabeled set of novel           omy construction.
   objects.
                                                                              We build on work by Salakhutdinov, Tenenbaum, and Tor-
   Keywords: hierarchical bayes; one-shot learning; inductive              ralba (2012) who build a Hierarchical Bayesian model that
   bias; neural networks; unsupervised learning
                                                                           “learns to learn” by incorporating information from past ex-
                                                                           perience into a prior when inferring statistical properties of a
                           Introduction
                                                                           novel category. In particular, when presented with a few im-
Recent advances in neural networks and other machine learn-                age examples of a new category, the model infers a supercat-
ing methods have led to computer vision object-recognition                 egory and uses the higher-order knowledge abstracted from
systems that are beginning to approach human-level perfor-                 previous categories to identify the relevant features and allow
mance. Trained on thousands of object categories, with thou-               generalization (Figure 1).
sands of labeled examples for each, deep convolutional net-
works can tell if a new image contains a familiar category al-
most as well as human adults can in a brief glance. Yet, even
young children have abilities to learn and generalize that go
beyond what current machine vision systems can do. Here
we focus on three such abilities:
   (1) By age 3, children can learn new object categories from
just a single example. Furthermore, children generalize in dif-
ferent ways as appropriate for different kinds of categories:
labels for artifacts with functionally relevant shapes are pref-
erentially generalized according to those shapes, while labels
for non solid substances or arbitrarily shaped objects are more
likely to be generalized according to material properties.
   (2) Children can learn to learn appropriate inductive biases,
such as the shape and material biases described above, from
experience with just a few examples each of a small number                 Figure 1: Learning a similarity metric for a new category. The
of categories that exemplify these biases in a consistent way.             goal is to identify the correct supercategory and estimate an
The shape-bias training studies of Smith and colleagues are                appropriate similarity metric.
the best known examples (Smith, Jones, Landau, Gershkoff-
Stowe, & Samuelson, 2002).                                                    That work was extended by the same authors, who har-
   (3) Children can, in a completely unsupervised way, sort                nessed a two layer Deep-Boltzmann Machine to generate low
novel objects into categories and supercategories in a mean-               level feature representations of the images while learning a
ingful way, and then use these hierarchical category structures            prior using a hierarchical Dirichlet process. (Salakhutdinov,
                                                                       1715

Tenenbaum, & Torralba, 2013). Their experimental data                 vious experience. These taxonomies can then be used as a
showed that using this prior in combination with more pow-            prior to identify the relevant features for learning a new cat-
erful features gave them a distinct advantage over other meth-        egory from one or a few examples based on the distribution
ods of classification. This progression of work suggests that         of other similar categories. We create various versions of our
building a model that combines complex feature spaces with            model to compare combinations of feature spaces extracted
a hierarchical semantic structure may lead to further increases       from different architectures with variants of the Hierarchical
in performance.                                                       Bayesian component.
   Building on this line of work, we contribute a model that             Learning begins by constructing a 2-level tree of categories
combines the two components: powerful image represen-                 and supercategories that best explains the training observa-
tations extracted from Deep Neural Networks (DNNs) and                tions under a Bayesian framework. The model learns struc-
a Hierarchical semantic structure that works as a Bayesian            ture in the observations by first generating useful general fea-
prior. We show how the combination of these two compo-                tures from a DNN and then developing hierarchical priors that
nents can “learn to learn” in ways that resemble some aspects         allow previous similar experiences to bias the learning of new
of child cognition. Additionally, we explore how this model’s         concepts and categories. The priors are constructed by infer-
performance is affected as we vary different aspects of the           ring the means and variances that define the most relevant
model architecture and the structure of the training data.            dimensions from the DNN feature representations for each
   Other approaches to combine probabilistic graphical mod-           category and supercategory (Figure 1).
els and DNNs have recently been proposed that focus on
                                                                      Deep Network Features
building unsupervised clustering algorithms (Dilokthanakul
et al., 2016; Johnson et al. 2016). Instead, the focus of our         We use features extracted from DNNs pretrained for object
model is to capture certain aspects of human cognition. This          classification on ImageNet. We obtain a representation from
leads to some notable differences. First, representations in          each image by passing it through a network and extracting the
our model are a fixed set of visual relevant features instead         response from the penultimate layer consisting of 4096 real-
of being learned for the inference task at hand. In addition,         valued dimensions. In the regular deep network classification
our model’s generative component is limited to a hierarchical         scheme, this response is then passed through a linear weight-
structure that aims to recover the semantic relations between         ing and a generalized logistic regression layer. This layer
concepts in a useful and meaningful way while other models            maps this representation onto probabilities for each class in
are fully generative but tend to have graphs with simpler se-         the specific classification task for which the network was
mantic structures. We therefore propose a relatively simple           trained.
model that is not intended for general unsupervised learning             We compare the performance of the different versions of
but that instead focuses on traits of human object and cate-          our model on features extracted from two different DNN
gory learning.                                                        architectures: Alexnet (Krizhevsky, Sutskever, & Hinton,
   More specifically, we test our model’s capacity to capture         2012), which was the first implemented Deep Learning
the previously discussed human abilities (1-3) in an image            Model that significantly improved object classification on im-
recognition framework. First, we evaluate the ability of our          ages; and VGG-16 (Simonyan & Zisserman, 2014), a more
model to learn novel categories from only one or a few ex-            recent architecture with 16 layers that achieves above 90%
amples. To address this we allow the model to construct a se-         top 5 classification performance on ImageNet.
mantic structure from labeled examples in a data set and then         Generative Semantic Organization
judge the model’s performance on a one-shot learning task.
                                                                      After obtaining a useful general image representation from
Second, we assess the models capability to construct induc-
                                                                      the DNN, the Hierarchical Bayesian Model’s parameters are
tive biases in low data environments. We test this ability by
                                                                      inferred by approximating the posterior via Markov Chain
repeating the first task but limiting the training data available
                                                                      Monte Carlo methods in the following way.
to the model when it constructs the semantic tree. Finally, in
                                                                         Consider a two-level hierarchy where N observed inputs
a third task, we test the model’s ability to learn a hierarchi-
                                                                      are partitioned into C basic-level categories, these categories
cal semantic structure of novel objects in a completely unsu-
                                                                      are in turn partitioned into K supercategories. In this hier-
pervised manner. Results suggest that this approach may be
                                                                      archy of observations, categories, and supercategories, the
suitable for modeling certain aspects of cognition.
                                                                      higher levels determine a prior over the distribution of the
                                                                      lower levels. In particular, the distribution over observations
            Model and Learning to Learn
                                                                      (feature vector representations of images in our case) of each
Our model combines two Machine Learning approaches that               of the different basic level categories are assumed to be multi-
have recently been successful at a range of differing tasks. On       variate Gaussian with a category specific mean Mc and with
one hand, powerful deep networks construct feature spaces             precision terms τdc that are assumed to be independent across
that enable rapid and accurate classification. On the other,          the D dimensions of the feature space. These precision terms
Hierarchical Bayesian Models have proven successful in cre-           constitute a similarity metric by determining the relative im-
ating taxonomies of the different concepts learned from pre-          portance of each of the features. In turn, we place a conjugate
                                                                  1716

 Table 1: Performance results using the area under the ROC curve (AUROC) on the MSR dataset in the one-shot learning task
                                                                # Examples from Withheld Class
                                                                Alexnet                         VGG
                                                       1ex   2ex 4ex 20ex 1ex 2ex 4ex                      20ex
                                      Oracle           .99     1      1       1
                                    HB-Full            .91    .96 .98        .99     .92 .97 .98            .99
                               One Supercategory       .87    .94 .97        .99     .88 .95 .98            .99
                                   NearestN            .84    .86 .87        .90     .89 .90 .92            .95
                                     T of T*           .76    .80 .84        .87
                                                                                                               nk
                                                                                                           (
Normal-Gamma prior over {Mc , τc }, this prior is determined                                                 n−1+γ if nk > 0
by the supercategory specific level-2 parameters Mk , τk , αk ,             P(zn = k|z1 , z2 ..., zn−1 ) =      γ
                                                                                                             n−1+γ if k is new
where Mk and τk constitute the expected values of the lower
level parameters and αk controls the variability of τc around
its mean. Finally, for the conjugate priors over the level-2 pa-            Where nk is the number of previous integers assigned to
rameters, we respectively assume Normal, Exponential and                 set k and γ is a concentration parameter sampled from a
Inverse-Gamma distributions that are further shaped by pa-               Gamma(1, 1) distribution.
rameters α0 and γ0 . The full generative model is given in
Figure 2 (Salakhutdinov et al., 2012).                                      In an unsupervised setting where the categories of the ob-
                                                                         servations are also unknown, the model utilizes a similar
                                                                         strategy to assign observations to categories as is used when
                                                                         assigning categories to supercategories. The model iterates
                                                                         through the observations and assigns each either to an exist-
                                                                         ing or to a newly created category based on the prior and like-
                                                                         lihood. By utilizing the CRP prior, the model can create an
                                                                         unbounded number of categories and supercategories. This
                                                                         entire process constitutes a Gibbs sampling procedure where
                                                                         both the tree structure and all of the parameters are simulta-
                                                                         neously learned.
                                                                                                 Tests and Results
                  Figure 2: Hierarchical Model
                                                                         We test the model in scenarios that attempt to capture aspects
                                                                         of human cognition related to learning from limited data.
   Given a set of observations, the model iteratively performs
                                                                         First we measure the model’s ability to generalize previous
Bayesian inference by alternating between sampling the pa-
                                                                         knowledge to learn novel categories from only a few exam-
rameters and inferring the category assignments. When learn-
                                                                         ples. Next, we assess the model on this task when the training
ing the distributions at each step of the iteration, the supercat-
                                                                         data for all of the categories is also limited to only a few ex-
egory membership is fixed and the parameters are sampled
                                                                         amples. Finally, we exploit the model’s full hierarchy in a
from posteriors that are analytically computed using the con-
                                                                         completely unsupervised setting by exploring how the model
jugate priors1 . The supercategory membership for each cate-
                                                                         recovers the underlying semantic structure.
gory is learned in a similar way by fixing the currrent param-
eters and the rest of the hierarchical structure. Every category         One-Shot Learning on MSR
can be assigned to any of the existing supercategories or to a
                                                                         In the first task, we test the model’s ability to learn new cate-
newly created one. The posterior probability of belonging to
                                                                         gories form one or a few examples. First, we select a category
a supercategory is computed as a combination the likelihood
                                                                         that will be held-out for testing. Labeled observations for
that the parameters of the category come from the parame-
                                                                         all other basic-level categories are provided for training. The
ters of the supercategory and a Chinese Restaurant Process
                                                                         model learns the semantic structure of the training set by clus-
(CRP) prior (Griffiths & Tenenbaum, 2004). This nonpara-
                                                                         tering the basic categories into supercategories and inferring
metric prior is a distribution over a partition on integers in
                                                                         the relevant parameters at all levels of the Bayesian Hierar-
which the nth number is assigned to set k with probability:
                                                                         chy. The challenge is then to generalize the learned structure
    1 For the case of α , the conditional posterior cannot be com-       to the held-out category from only one or a few examples.
                        k
puted analytically and the parameter is sampled with the Metropolis-        To do this, the model first infers the best supercategory
Hastings rule (Yildirim, 2012).                                          from one or a few examples of the withheld category by
                                                                     1717

  Table 2: Performance results using the area under the ROC curve (AUROC) on the MSR dataset with limited training data.
                                                              # Examples from Withheld Class
                                                            Alexnet                         VGG
                                                    1 ex  2 ex 4 ex 20 ex 1 ex 2 ex 4 ex               20 ex
                             # Training Examples
                                       1 ex          .87  .87     .88      .89    .90    .90    .90     .92
                                       4 ex          .92  .96     .99      .99    .93    .97    .98     .99
                                      10 ex          .92  .96     .99      .99    .92    .96    .98     .99
                                      18 ex          .92  .95     .98      .99    .91    .96    .98     .99
                                 All examples        .91  .96     .98      .99    .92    .97    .98     .99
marginalizing over the category level parameters. Next, the
model uses the supercategory priors and training examples
to estimate the category similarity metric and mean for each
dimension in the feature space.
   We evaluate different versions of our model on the MSR
Cambridge dataset (Kohli et al., 2005), which consists of 24
categories with varying numbers of images in each category.
In total this dataset contains roughly 800 images. Figure 3
shows a typical partition over all the categories discovered by
the full model. To quantify the models accuracy, a testset with        Figure 3: MSR semantic tree discovered by the Full Model
unlabeled data from all categories is classified.
                                                                         The results show that the model performs best when using
   We repeatedly trained the model withholding one of the             the full hierarchy in combination with the feature space ex-
categories at a time and then inferred the withheld category          tracted from VGG. HB-Full considerably outperforms alter-
parameters and supercategory membership using one or a                natives under both feature spaces, particularly for trials with
few images. Next, we calculated the posterior probability for         one example from the withheld dataset. As more examples
each testset image belonging to each category and variated a          become available, the performance difference decreases re-
threshold to classify images as belonging to the heldout cat-         flecting the importance of the prior when little data is avail-
egory or to any of the other categories. This created true and        able. The importance of the learned features is highlighted
false positive rates for each point along our threshold which         when comparing with the T of T∗ feature space where per-
traced out a Receiver Operating Characteristic curve (ROC)            formance is considerably lower. It is interesting to note that
for classifying objects from the withheld vs. all the other cat-      the VGG representation improves most over Alexnet when in
egories. The reported results are calculated by averaging the         combination with NearestN, but the effect is mitigated when
Area Under the ROC curve (AUROC) for the model trained                the hierarchy is used.
with each of the 24 categories withheld (Table 1).
                                                                      Limited training data regimes
   Performance is compared for each combination of an Infer-
                                                                      In a second task, we test the capability of our model to extract
ence Model and a Network Architecture. HB-Full is the full
                                                                      inductive biases from experience with just a few examples.
version of the model described above. One Supercategory
                                                                      To evaluative this capability, our full model was limited to
places all the categories in the same single supercategory.
                                                                      only 1, 4, 10 or 18 examples of each category used for train-
NearestN classifies new points with the label of the nearest
                                                                      ing. The number of examples from the withheld category was
neighbor of its feature vector in euclidean distance. Texture
                                                                      varied separately. Table 2 shows the average AUROC for the
of Textures (T of T)∗ replaces our DNN features with the set
                                                                      same “one vs. all” metric used in the previous task3 . For com-
of responses from a three layer convolutional neural network
                                                                      parison, the full model performance from the previous table
that uses precomputed weights that resemble Gabor filters2 .
                                                                      is included and labeled as “All examples”4 .
Finally, the Oracle is the same than our full model, but uses
                                                                         We can see that the largest jump in performance happens
the true empirical mean and variances from the whole pop-
                                                                      when moving from 1 to 4 training examples. This likely
ulation (including testset). Table 1 shows the results for the
                                                                      reflects the fact that a single example provides information
two different feature spaces used.
                                                                      about the mean of the category but not about the variance or
                                                                      similarity metric, which has to be inferred completely from
                                                                          3 Averages across 10 random repetitions and all categories are
                                                                      reported.
   2 Taken from Salakhutdinov et al. (2012)                               4 Each category contains a varying number of examples
                                                                 1718

the prior. However, 4 examples provide adequate information         learning inductive biases, and constructing semantic struc-
about the variance to allow the model to appropriately infer        tures. We show results for three tasks involving limited data
the parameters for new categories. As the number of training        availability. The model is able to learn relevant semantic
examples continues to increase, there are no further gains in       structures from just a few examples of novel objects and ef-
performance. This is consistent with literature showing that        fectively transfer appropriate similarity metrics from learned
children need at least two examples to learn inductive biases       categories in the form of a prior. In all tasks, the compu-
in certain contexts (Smith et al., 2002).                           tational framework comes close to capturing human abilities
                                                                    that other, more complex, machine vision systems struggle to
Unsupervised Learning on Gazoobian Objects                          reproduce.
Humans and children can sort new objects into categories and
supercategories in a semantically meaningful way. While our
model is also able to of recover meaningful structure from la-                                References
beled examples (Figure 3), real situations often demand learn-      Dilokthanakul, N., Mediano, P. A., Garnelo, M., Lee, M. C.,
ing where labels are completely absent. Schmidt (2009) ex-             Salimbeni, H., Arulkumaran, K., & Shanahan, M. (2016).
plores this human capability with a dataset composed of 45             Deep unsupervised clustering with gaussian mixture varia-
novel objects that were generated using a modeling software            tional autoencoders. arXiv preprint arXiv:1611.02648.
to simulate a specific taxonomic structure. The dataset con-        Griffiths, T., & Tenenbaum, J. B. (2004). Hierarchical topic
sists of three supercategories supposed to be alien equivalents        models and the nested chinese restaurant process. Ad-
of plants, tools and snails from the planet “Gazoob”. The ob-          vances in neural information processing systems, 16, 17.
jects in each supercategory are further organized into a struc-     Johnson, M., Duvenaud, D. K., Wiltschko, A., Adams, R. P.,
ture that can be approximated by basic-level categories (gray          & Datta, S. R. (2016). Composing graphical models with
box in Figure 4).                                                      neural networks for structured representations and fast in-
   Our model has the ability to infer both categories and su-          ference. In Advances in neural information processing sys-
percategories in an unsupervised manner from observations.             tems (pp. 2946–2954).
Schmidt (2009) shows that a model based on agglomerative            Kemp, C., Perfors, A., & Tenenbaum, J. B. (2007). Learning
clustering that uses adult similarity judgments is able to re-         overhypotheses with hierarchical bayesian models. Devel-
cover the taxonomic tree (Figure 4). Here our model is tested          opmental science, 10(3), 307–321.
with the harder task of recovering the taxonomic tree directly      Kohli, P., Sharp, T., Minka, T., Winn, J., Shotton, J., & Cri-
from the same images that people saw. The model accom-                 minisi, A. (2005). Microsoft research in cambridge image
plishes this task in a fully unsupervised manner using a single        dataset.
image of each object.                                               Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Im-
   This “image-computable” model is able, although with                agenet classification with deep convolutional neural net-
some mistakes, to recover the three supercategories and most           works. In Advances in neural information processing sys-
of the basic-level category structure (Figure 5). Other un-            tems (pp. 1097–1105).
supervised clustering algorithms were also able to capture          Salakhutdinov, R., Tenenbaum, J. B., & Torralba, A.
some of the semantic structure, but the hierarchy between cat-         (2012). One-shot learning with a hierarchical nonpara-
egories and supercategories was not evident.                           metric bayesian model. In Icml unsupervised and transfer
                                                                       learning (pp. 195–206).
                           Discussion                               Salakhutdinov, R., Tenenbaum, J. B., & Torralba, A. (2013).
One can think of the task of concept learning as consisting of         Learning with hierarchical-deep models. IEEE transac-
two elements. The first involves obtaining relevant features           tions on pattern analysis and machine intelligence, 35(8),
to represent the objects and categories commonly observed in           1958–1971.
the world. The second involves constructing a semantic hier-        Schmidt, L. A. (2009). Meaning and compositionality as
archical structure with links between categories that humans           statistical induction of categories and constraints. Unpub-
can use to navigate and perform tasks. While recent results            lished doctoral dissertation, Citeseer.
demonstrate the capabilities of DNNs to classify categories         Simonyan, K., & Zisserman, A. (2014). Very deep convo-
provided a large number of training examples, they strug-              lutional networks for large-scale image recognition. arXiv
gle to perform tasks that require understanding the seman-             preprint arXiv:1409.1556.
tic relationships between classes. The ability of Hierarchical      Smith, L. B., Jones, S. S., Landau, B., Gershkoff-Stowe, L.,
Bayesian Models to build these semantic structures can fur-            & Samuelson, L. (2002). Object name learning provides
ther help with understanding and classifying new categories.           on-the-job training for attention. Psychological Science,
   We demonstrate how these two approaches can comple-                 13(1), 13–19.
ment one another by combining them in a computational               Xu, F., & Tenenbaum, J. B. (2007). Word learning as
model. We tested the model’s abilities tasks designed to               bayesian inference. Psychological review, 114(2), 245.
approximate human capabilities that are currently difficult         Yildirim, I. (2012). Bayesian inference: Metropolis-hastings
for computer vision systems such as concept generalization,            sampling. University of Rochester, NY.
                                                                1719

Figure 4: Ground Truth Tree of Gazoobian Objects as Generated from Human Similarity Judgments. Each of the three branches
at the top of the tree denotes a supercategoy. The gray box in the lower left hand of the figure denotes a basic-level category.
Figure 5: Model’s Inferred Semantic Hierarchy of Gazoobian Objects. Outer boxes denote supercategories inferred by the
model. Dashed lines separate model generated categories within each supercategory. Colored boxes around each object denote
the ground truth supercategories as shown above.
                                                              1720

