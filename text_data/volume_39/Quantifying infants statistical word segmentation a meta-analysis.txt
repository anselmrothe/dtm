              Quantifying Infants' Statistical Word Segmentation: A Meta-Analysis
                                              Alexis Black (akblack2g@gmail.com)
                                               Department of Linguistics, 2613 West Mall
                                                    Vancouver, BC, Canada V6T 1Z4
                                         Christina Bergmann (chbergma@gmail.com)
                           Laboratoire des Sciences Cognitives, Ecole Normale Supérieure, 29, rue d'Ulm
                                                            75005 Paris, France
                             Abstract                                   analysis that examined natural speech word segmentation
                                                                        (not determined by TPs) revealed a significant, but small
   Theories of language acquisition and perceptual learning
   increasingly rely on statistical learning mechanisms. The            effect (Bergmann & Cristia, 2016), leading to concerns
   current meta-analysis aims to clarify the robustness of this         about the robustness of infants’ word segmentation in the
   capacity in infancy within the word segmentation literature.         absence of TPs.
   Our analysis reveals a significant, small effect size for               In the current paper, we use meta-analysis to quantify and
   conceptual replications of Saffran, Aslin, & Newport (1996),         contextualize infants' ability to detect regularities in a
   and a nonsignificant effect across all studies that incorporate      continuous speech stream. To this end, we have aggregated
   transitional probabilities to segment words. In both                 all available evidence from the published record and present
   conceptual replications and the broader literature, however,         a meta-analysis of infant SL word segmentation studies. A
   statistical learning is moderated by whether stimuli are
                                                                        meta-analytic approach helps establish the magnitude of an
   naturally produced or synthesized. These findings invite
   deeper questions about the complex factors that influence            underlying effect, something single experiments are not
   statistical learning, and the role of statistical learning in        equipped to do – and thus has the potential to impact future
   language acquisition.                                                theory- and model-building. On the practical side, effect
                                                                        sizes are crucial for determining power of future studies,
   Keywords: language acquisition; statistical learning; word
                                                                        thus increasing the replicability of a line of inquiry and
   segmentation; meta-analysis
                                                                        reducing the cost (failed studies, or testing too many
                                                                        participants) for single researchers.
                          Introduction                                     We also take several steps beyond quantifying the
Statistical learning (SL), the ability to extract statistical           underlying effect: Aggregating over studies allows for the
patterns from a continuous stream of perceptual                         identification of moderator variables, which also contributes
experiences, is of fundamental theoretical importance. The              to theory building and may guide future research. We
first evidence that infants can extract statistical information         examine three potential moderators that are relevant to the
from speech and use it to group syllables was provided by               intersection of theories of infant cognition and statistical
Saffran, Aslin, and Newport in 1996. This seminal paper has             learning: (1) age, (2) stimulus naturalness, and (3) non-TP
since accrued thousands of citations, and spurred a rich                cues. The justification for investigating these particular
literature invoking SL as one foundation for language                   moderators is described in brief. (1) All studies in the
acquisition (see Newport, 2016) as well as perceptual                   current meta-analysis use looking-time preferences. The
learning more broadly (see Aslin, 2017). SL mechanisms                  direction of preference (to novel or familiar items) is
have furthermore been successfully implemented in a range               commonly thought to relate to infant age and/or stimulus
of computational models (e.g., Pearl, Goldwater, &                      complexity (e.g., Hunter & Ames, 1988). We therefore
Steyvers, 2010; Lloyd-Kelly, Gobet, & Lane, 2016). In                   predicted that developmental change might be reflected in a
short, statistical learning abilities are of fundamental, cross-        shift of preference (e.g., from a preference for words to one
disciplinary importance to better understand the                        for non-words), or in a stronger effect over time. (2) Given
computational foundations of cognition.                                 the familiarity preference found in a previous meta-analysis
   While many would accept some role for SL mechanisms,                 on natural speech (Bergmann & Cristia, 2016), we
the nature and extent of this role remains contested. The               hypothesized that it might be that the predominant novelty
more abstract the level of analysis, the more vigorous the              preference established for SL studies since Saffran et al.
debate (e.g., can SL yield syntactic ‘rules’?) – but                    (1996) is grounded in methodological choices. The primary
inconsistencies emerge even at the level of tracking                    difference between these two datasets is in the nature of the
transitional probabilities (TPs) as a means of word                     stimuli: naturally produced vs highly artificial speech
segmentation. For example, the original effect has failed to            stimuli. Even within the literature of the current dataset,
replicate under certain conditions (e.g., variable word                 however, stimuli differ along this dimension. We therefore
length: Johnson & Tyler, 2010; Lew-Williams & Saffran,                  compare SL studies with natural and artificial stimuli. (3)
2012) or showed a developmental shift in cue-weighting                  Finally, a number of studies pitted alternative cues (e.g.,
(e.g., Thiessen & Saffran, 2003). Finally, a recent meta-               word-level stress) against TPs. It is therefore important to
                                                                   124

examine the impact of these conflicting cues on SL                          We computed Hedges’ g (Morris, 2010), a variant of
performance compared to no conflict.                                     Cohen's d (Cohen, 1988) that is preferred in the case of
   We also assess publication bias in the literature; a current          small sample sizes. Effect sizes were calculated based on
topic that is especially important for infant research,                  reported test statistics: for 50 samples we could use means
considering the high cost of testing participants and the                and standard deviations of test trials; for 17 samples t-values
consequent use of small samples (Frank et al., 2017).                    for the main comparison were available. To ensure
                                                                         consistency in the direction of the effect, we re-coded t-
                             Methods                                     values as positive when infants listened longer to statistical
                                                                         non-words and as negative otherwise. We used standard
To collect data, we complemented expert lists with two
                                                                         formulae for effect size calculation in within-participant
google scholar searches. We first surveyed papers citing
                                                                         designs (Lipsey & Wilson, 2001, when means and standard
Saffran, Aslin, & Newport (1996) with the word
                                                                         deviations were available; Dunlap et al., 1996, for effect
“infant/infancy”, but not “visual” in the title. The second
                                                                         sizes based on t-values). One paper reported between-
search aimed to cast a wider net; search terms were now
                                                                         participant results and we computed effect sizes and
“month/s” and not “infant/infancy” or “visual”. These two
                                                                         variances from means and standard deviations accordingly
strategies yielded a total of 314 unique papers, which were
                                                                         (Lipsey & Wilson, 2001). When the same infants
then screened for inclusion. The criteria were: (1) contains
                                                                         contributed to multiple effect sizes, we computed the
data on infants from (2) behavioral experiments which
                                                                         median of all critical values to ensure independent samples
exposed infants to a familiarization phase of continuous,
                                                                         (here, 4 effect sizes were derived from 8 non-independent
artificial speech and which measured (3) reactions (typically
                                                                         samples). We could not compute effect sizes for 6 additional
looking times to unrelated visual stimuli) to both statistical
                                                                         experiments, due to lack of information.
words and non-words (this definition includes part-words).
                                                                            Only one of the 20 papers included reported correlations
   The final sample encompassed 20 papers (10 containing
                                                                         between test trials, which capture the dependency between
conceptual replications1) yielding 68 (17 replication) effect
                                                                         the two data points stemming from the same participants
sizes. Note that one paper often contains several
                                                                         and are necessary for t-value based effect size and general
experiments (henceforth: samples) that can yield effect
                                                                         effect size variance calculation. We imputed random values
sizes, for example when testing different age groups. In
                                                                         based on the distribution of correlations reported in a similar
total, we are reporting on experiments testing 1,454 infants
                                                                         meta-analysis (Bergmann & Cristia, 2016; updated data
between 4.5 and 11.1 months. Children were tested in the
                                                                         available via metalab.stanford.edu).4
headturn preference procedure (Kemler Nelson, et al., 1995;
59 samples) or the central fixation paradigm (Graf-Estes &
Lew-Williams, 2015; 9 samples).                                          Meta-Analysis
                                                                         To establish the size and variance of the effect, we fitted a
Effect Size Calculation                                                  multivariate random effects model using the R (R core team,
                                                                         2016) package metafor (Viechtbauer, 2010). Random
All scripts and raw data are available on github.2 The effect
                                                                         effects models assume that all effect sizes are sampled from
size we report here is a standardized mean difference of
                                                                         a distribution of effect sizes and try to estimate the mean
infants' looking behavior when listening to statistical words
                                                                         and variance of this distribution. In the multivariate model,
versus non-words. Since a preference for non-words
                                                                         the interdependence between effect sizes from the same
(novelty preference) is dominant in the literature, positive
                                                                         paper is taken into account, yielding a more robust measure
values reflect this direction of the effect. The larger the
effect size, the bigger the observed standardized mean
difference between the two types of test trials. In turn,                preference is explicitly predicted. We address these cues and their
negative values indicate that infants demonstrated a                     impact in the Complete Literature section of the paper. We would
familiarity preference, i.e. they listened longer to statistical         also like to address the general idea of absolute values in meta-
                                                                         analysis, and point to why this method may not be appropriate: 1)
words over non-words 3.                                                  Theories of infant cognition and language acquisition have long
                                                                         sought to motivate the direction of looking-time preference; meta-
   1
     A conceptual replication was defined as a study that did not        analysis offers the potential power to test those theories and
introduce an additional, non TP-based cue, and did not differ from       generate new possibilities when the theory is found to be
the original study protocol in a significant way. For example,           inadequate. 2) Two opposing outcomes should reflect two
studies that included a priming phase pre-familiarization, or a test     underlying effects. Using raw effect sizes and testing the value of
phase involving carrier phrases were not included. See Github            proposed moderators is a much more powerful use of meta-
repository for a full list of included papers and the subset of          analytic techniques. Furthermore, it is important to recognize that
conceptual replications.                                                 allowing for two opposing outcomes, without the ability to predict
   2
     https://github.com/christinabergmann/StatLearnDB                    those outcomes, increases the risk for false positives and might
   3                                                                     violate basic assumptions of sampling and null hypothesis
     Given that infant looking-time studies generally accept either
familiarity or novelty preferences, one might argue that we should       significance testing.
                                                                            4
instead use the absolute value of looking-time difference as                  To assess the impact of this imputation, we re-ran our analysis
dependent measure. Indeed, in the studies reported here that pit         with imputations based on varying means and verified that our
statistical learning against other cues, a switch in looking-time        conclusions about key findings do not change.
                                                                     125

of the true effect. To investigate the impact of additional
variables, we introduce moderators to this model.
Bias
We tested for bias in the published literature by assessing
funnel plot asymmetry, which is significant when a portion
of the expected distribution of effect sizes around the
weighted mean is missing, yielding an over-representation
of a part of the underlying effect size distribution. We test
for asymmetry using the rank correlation test (implemented
in metafor; Viechtbauer, 2010).
  To further investigate biases, we make use of p-curves to
test whether there is an excess in p-values just below the
significance threshold of .05 and if the distribution of p-
values indicates an underlying real effect (Simonsohn,                Figure 1: Funnel plot (code adapted from Sakaluk, 2016)
Nelson, & Simmons, 2014). To this end, we enter all exact             showing standard error of the effect size as a function of
t-values that were reported (n = 48 for the whole dataset).            effect size for 17 conceptual replications. The solid line
                                                                     marks zero, the dashed line the effect estimate, and the grey
                           Results                                             line indicates the funnel plot asymmetry.
Original Paper
                                                                       Overall, the moderator test is significant (Q(1) = 5, p =
We first calculated the effect size and its variance for the
                                                                    .023) with a negative estimate (β = -0.35, SE = 0.16, 95%
two experiments reported by Saffran, Aslin, and Newport
                                                                    CI [-0.66, -0.05]), indicating that infants tend to show less
(1996). Hedges’ g was 0.4 (SE = 0.040) for experiment 1
                                                                    of a novelty preference with stimuli produced by human
and 0.38 (SE = 0.041) for experiment 2. According to
                                                                    speakers.
Cohen's (1988) criteria this is a small to medium effect.
                                                                      Follow-up analyses focusing on subsets revealed that
   If experimenters base their sample size decisions on this
                                                                    synthetically produced stimuli lead to a significant positive
effect size, they would have to test 53 infants in a paired
                                                                    effect (Hedges’ g = 0.32, SE = 0.05, 95% CI [0.2, 0.4], p <
samples design to achieve 80% power (computed with the R
                                                                    .001), while those replications relying on naturally-produced
package pwr; Champely, 2016). The median sample size in
                                                                    speech yield an effect size not different from zero (Hedges’
our dataset is 22 participants, which would mean a 42%
                                                                    g = 0.02, SE = 0.2, 95% CI [-0.36, 0.41], p = .9).
probability of obtaining a significant result, assuming the
effect is of the size reported in the initial study; inversely,
                                                                    Publication Bias The funnel plot shown in Figure 1
58% of attempts to replicate this finding should fail.
                                                                    displays a greater density of large effect sizes that are of
                                                                    low-precision (lower right quadrant) and some effect sizes
Conceptual Replications                                             that are of high precision but outside the expected
First, we report on the experiments that were identified as         distribution (upper left quadrant), which is illustrated further
replications of the original report (Saffran et al., 1996).         by the linear regression line in grey. This line should be
Seventeen experiments could be included in these analyses.          horizontal in the case of an even distribution around the
                                                                    median effect. Nonetheless, asymmetry is not significant
Meta-Analytic Effect The variance-weighted effect size              with Kendall's 𝜏 = .26, p = .15.
Hedges’ g is 0.21 (SE = 0.1), which is significantly different        The p-curve analysis based on the 6 significant t-values
from zero (95% CI [0.02, 0.4], p = .03) and indicates a             available in this dataset indicates a flat distribution of p-
preference for statistical non-words. Note that this effect is      values, as would be expected when there is no underlying
smaller than the original report, and typical power is thus         effect (Z = -0.43; p = .33). However, these 6 t-values might
only 16% with 22 participants. Heterogeneity is significant,        not be representative of the 17 studies analyzed here.
indicating variance in the data that is not explained by
random measurement error (Q(16) = 71, p < .001).                    Complete Literature
                                                                    Meta-Analytic Effect When taking into account all 68
Moderator Analysis: Age We find no significant effect of
                                                                    independent effect sizes, the meta-analytic effect size
the moderator centered age in days (Q(1) = 0.6, β = -0.001,
                                                                    Hedges’ g is 0.09 (SE = 0.05), which is not significantly
SE = 0.0015, 95% CI [-0.004, 0.018], p = .5).
                                                                    different from zero (CI [-0.02, 0.19], p = .1). This dataset,
                                                                    however, includes a number of samples that explicitly pit
Moderator Analysis: Stimuli Naturalness Studies on SL
                                                                    TPs against other segmentation cues, and thus may be
differ in the stimuli; in this dataset, 11 effect sizes came
                                                                    expected to lead to different effects represented within the
from experiments with synthetically generated speech, 6
                                                                    same data. Indeed, heterogeneity is significant (Q(67) =
were based on experiments with naturally produced speech.
                                                                    334, p < .001). We thus analyze each of our moderators.
                                                                126

   Figure 2: Effect size by participant age for all samples;               Figure 3: Funnel plot of all samples. For details see
point size is inverse variance. Black refers to synthetic, grey                                 Figure 1.
       to natural speech. The dashed line indicates zero.
                                                                       A moderator analysis restricted to samples with additional
Moderator Analysis: Age As described in the introduction,           stress-based segmentation cues fails to confirm this
more mature infants might show a different direction of             prediction (Q(1) = 0.7, p = .4; Cue conflict [iambic stress]: β
preference or larger effect. However, we find no (linear)           = -0.07, SE = 0.08, 95% CI [-0.23, 0.09]).
effect of age (Q(1) = 0.3, p = .6). Follow-up analyses
introducing a quadratic term for age confirmed this finding.        Publication Bias Figure 3 shows an even distribution of
                                                                    effect sizes around the estimated median, the large spread
Moderator Analysis: Stimuli Naturalness In the full                 illustrating the unexplained heterogeneity. The ranktest
dataset, the use of artificial and natural speech is fairly         indicates no significant asymmetry (Kendall's 𝜏 = -.01, p =
balanced, with 38 instances of computer-generated stimuli           .9; see also grey linear regression line in Figure 3).
and 30 of human speakers. The moderator test is significant            The p-curve based on 34 significant t-values indicates that
(Q(1) = 11, p < .001), and the results mirror our findings in       the data contain evidential value (Z = -2.47; p = .007 for the
the conceptual replication dataset. Figure 2 displays all           full p-curve) and there is no excess of "just significant" p-
samples, with color encoding natural (grey) vs artificial           values. Power based on the p-curve is estimated to be 25%.
(black) stimuli. The meta-analytic effect for experiments
with artificial stimuli is significantly above zero (Hedges’ g                                Discussion
= 0.23, SE = 0.06, 95% CI [0.11, 0.35], p < .001). In               In the present paper, we examine infants’ ability to track
contrast, natural speech yields an effect not different from        transitional probabilities (TPs) in continuous streams of
zero (Hedges’ g = -0.05, 95% CI [-0.2, 0.06], p = .4).              speech. Experiments replicating the original Saffran et al.
                                                                    (1996) paradigm reveal a significant and reliable effect
Moderator Analysis: Cue conflict Cues can either be                 (Hedges’ g = .21) that is on par with the effect found in the
absent (n = 20), congruent with TPs (32), or in conflict with       meta-analysis of natural speech segmentation (Hedges’ g =
statistical information (16). Those cues encompass word             .22; Bergmann & Cristia, 2016), albeit in the opposite
stress (8), sentence level prosody (3), duration (2), intensity     direction of preference. An analysis of the whole literature
(2), and co-articulation (1). We predicted that cues that           fails to find a significant aggregated effect, but is reliably
coincide with TPs might strengthen the effect, while those          influenced by naturally vs. synthetically produced speech.
that conflict with TPs may reveal a different, possibly even        There was no evidence for a developmental shift in or
opposing effect. We therefore introduced a three-leveled            strengthening/weakening of preference, nor for a consistent
moderator. This analysis revealed no significant moderator          and reliable role of additional cues. Finally, there is no clear
effect (Q(2) = 1.9, p = .4).                                        evidence for publication bias. Taken together, these results
   Of the 48 samples that involve additional cues, 24 are           invite deeper consideration of several issues in the future
based on the effect of a correlate of word-level stress on          study of SL and theories of language acquisition, discussed
segmentation. These studies propose that infants will be            in turns below.
driven to segment speech using a trochaic stress pattern, in
line with their native language. Artificial languages with          One Mechanism Among Many
trochaic stress are therefore congruent with TP cues, and are
predicted to lead (as a whole) to novelty preferences; those        The data presented here confirm that infants can track
with iambic stress conflict with TPs, and are predicted to          statistically defined patterns and use that information to
lead (as a whole) to null or familiarity preferences.               segment a stream of speech into word-like units. The
                                                                    strength of this capacity, however, may be more fragile than
                                                                    expected. How are we to understand these findings, as we
                                                                127

continue to examine the import of statistical learning in             Practical Implications
language acquisition?                                                    There are several points to take into account when
   When aggregating across different studies, we put to the           planning future SL word segmentation studies. First,
test the idea that researchers can predict the direction of           assuming an effect size of Hedges’ g = .21, the power of a
infant looking-time preferences. Most popular theories of             typical 22 sample design is a meagre 16% (note that the p-
infant preference (e.g. Hunter & Ames, 1988; Kidd, Aslin &            curve analysis indicates an overall power level of 25% in
Piantadosi, 2012; 2014) predict an interplay between                  the significant portion of the studies). A well-powered study
stimulus complexity and infant readiness to encode this               (80%) would require a sample of 180 infants (142 if the
complexity. In the case of TP-based word segmentation, we             direction of the preference can be predicted). This is
therefore expected a linear (or quadratic) shift from                 impractical in the current state of infant research which
familiarity to novelty preferences as infants age. We instead         relies on single labs conducting such studies (but see the
find a consistent novelty preference. On the other hand,              alternative collaborative approach outlined by Frank et al.,
there is a significant effect of stimuli naturalness: While           2017). We do not intend to suggest that SL is not worth
studies using synthesized speech yield reliable novelty               investigating – but it does call into question the methods
preferences, studies using naturally produced speech fail to          with which we choose to investigate it. Power might, for
find reliable effects. It is likely that natural speech, even         example, be increased with more robust methods, calling for
when altered to be largely monotonic and lacking syllable             infant researchers to improve extant paradigms. At this
co-articulation, is more acoustically complex than synthetic          point, we are only beginning to have sufficient power to
speech. This is supported by the consistent familiarity               fully understand the role of methods, stimuli, and test set-up
preference across age groups found by Bergmann & Cristia              (see e.g., Frank et al., 2017). One possibility lies in adopting
(2016). Infants may thus be more likely to show a                     more implicit measures of SL such as through
familiarity preference to natural speech because it may take          neuroimaging, which may be less susceptible to factors
more time to process (and hence habituate to/learn from)              affecting the direction of infant looking-preference.
this complex signal. There is some evidence in the SL
literature to support this idea: some studies find alternating
                                                                      Limitations
patterns of looking preference by block (e.g. Graf-Estes &
Lew-Williams, 2015). This, however, is rarely reported.               Any meta-analysis is limited by a number of factors, one of
Future investigations based on the meta-analytic data                 which is that the analysis is only as good as the data it
presented here might pursue the role of stimulus complexity           contains. In other words, the studies reported here are those
by assessing the possible interactions between stimulus               that have been published (or made available online) and
type, familiarization duration, age, and direction of looking-        were findable through our search criteria (see supplementary
time preference.                                                      material for a full list of included studies). Since the effect is
   Several of the studies in the dataset were designed to test        small, we expect that a number of failures to replicate the
the limits of SL. They have been included because in all              original finding are confined to the file-drawer, simply
cases infants might have opted to segment the language                because they were underpowered. Further, studies showing
based on TPs alone; we hypothesized that, once taken in               a familiarity preference might not be published as those are
sum, these studies might have revealed evidence that TPs              not expected in replications of Saffran et al., (1996).
drive segmentation even in the face of alternative cues. This         Including such (presumed) file-drawer studies would make
did not turn out to be the case – there is no reliable effect for     our estimates much more reliable and we strongly
segmentation when all studies are considered together.                encourage researchers with unpublished work to contact the
Moreover, and surprisingly, there is no pattern that unites           authors and contribute these findings (or any published data
samples in which cues are congruent with TPs vs those in              that may have been regrettably missed).
conflict with TPs. These results, in fact, suggest that infants          A second limitation is missing information. For example,
only succeed at tracking TPs when presented with artificial           in order to compute effect sizes and their variance for
speech sounds. Given the results of the Bergmann & Cristia            within-participant designs, it is necessary to know the
(2016) meta-analysis, we find this unlikely to reflect the true       correlation between infants’ preferences for each test-item
state of the world; rather, we believe it suggests that what          type. We have temporarily imputed these figures based on
does drive performance in the relatively simple paradigm of           similar data (Bergmann & Cristia, 2016), and ran additional
TP-based word segmentation remains underspecified and                 analyses to confirm that different values result in similar
requires further theoretical, experimental, and meta-                 outcomes. However, we hope that authors who can retrieve
analytical consideration. Future work extending from the              this data will be willing to enrich our dataset, and
current dataset will aim to contribute to this discussion by          recommend to all to include this information in future
accruing enough data to be able to examine additional                 publications
moderators (e.g. familiarization duration) and outcome
variables (i.e. effect sizes based on proportions of infants          Conclusion
showing the effect, as opposed to standardized means of               This meta-analytic analysis of statistical learning as applied
looking-time differences).                                            to word segmentation has revealed a reliable but small
                                                                  128

effect. We hope that this paper promotes future research that     Kidd, C., Piantadosi, S. T., & Aslin, R. N. (2012). The
will seek to better characterize infant performance on SL           Goldilocks effect: Human infants allocate attention to
tasks, and will thus contribute to stronger theories and            visual sequences that are neither too simple nor too
models of infant cognition and behaviour.                           complex. PloS One, 7, e36399.
                                                                  Kidd, C., Piantadosi, S. T., & Aslin, R. N. (2014). The
                    Acknowledgments                                 Goldilocks effect in infant auditory attention. Child
The authors thank the Cognitive Science Society for hosting         Development, 85, 1795-1804.
a meta-analysis tutorial in 2016 and for participants of this     Lew-Williams, C., & Saffran, J. R. (2012). All words are
tutorial, who pre-coded some of the included papers. Alexis         not created equal: Expectations about word length guide
Black was supported by the UBC 4 Year Fellowship and                infant statistical learning. Cognition, 122, 241-246.
NSERC Discovery Grant (Individual) to Carla L. Hudson             Lewis, M., Braginsky, M., Tsuji, S., Bergmann, C.,
Kam “Constraints on language acquisition and how they               Piccinini, P. E., Cristia, A., & Frank, M. C. (2017). A
change (or don’t) with age.” Christina Bergmann was                 Quantitative Synthesis of Early Language Acquisition
supported by the European Horizon 2020 programme                    Using Meta-Analysis. Preprint posted on PsyArXiv at
(Marie Skłodowska-Curie grant No 660911), the Agence                https://osf.io/preprints/psyarxiv/htsjm/
Nationale pour la Recherche (ANR-10- IDEX-0001-02                 Lipsey, M.W., & Wilson, D.B. (2001). Practical meta-
PSL*, ANR-10-LABX-0087 IEC), and the Fondation de                   analysis. Thousand Oaks, CA: Sage.
France.                                                           Lloyd-Kelly, M., Gobet, F., & Lane, P. C. (2016). Under
                                                                    Pressure: How Time-Limited Cognition Explains
                         References                                 Statistical Learning by 8-Month Old Infants. Proceedings
                                                                    of the 38th Annual Conference of the Cognitive Science
Aslin, R. N. (2017). Statistical learning: a powerful               Society (pp. 1476-1480). Austin, TX: Cognitive Science
  mechanism that operates by mere exposure. Wiley                   Society.
  Interdisciplinary Reviews: Cognitive Science, 8, e1373.         Morris, S. B. (2000). Distribution of the standardized mean
Bergmann, C., & Cristia, A. (2016). Development of infants'         change effect size for meta‐ analysis on repeated
  segmentation of words from native speech: A meta-                 measures. British Journal of Mathematical and Statistical
  analytic approach. Developmental Science, 19, 901-917.            Psychology, 53, 17-29.
Champely, S. (2016). pwr: Basic Functions for Power               Newport, E. L. (2016). Statistical language learning:
  Analysis. R package version 1.2-0. https://CRAN.R-                Computational, maturational, and linguistic constraints.
  project.org/package=pwr                                           Language and Cognition, 8, 447-461.
Cohen, J. (1988). Statistical power analysis for the              Pearl, L., Goldwater, S., & Steyvers, M. (2010). Online
  behavioral sciences (2nd Ed.). Hillsdale, NJ: Lawrence            learning mechanisms for Bayesian models of word
  Erlbaum Associates.                                               segmentation. Research on Language and Computation,
Dunlap, W.P., Cortina, J.M., Vaslow, J.B., & Burke, M.J.            8, 107-132.
  (1996). Meta-analysis of experiments with matched               R Core Team (2016). R: A language and environment for
  groups or repeated measures designs. Psychological                statistical computing. R Foundation for Statistical
  Methods, 1, 170–177.                                              Computing, Vienna, Austria. https://www.R-project.org/
Frank, M. C., Bergelson, E., Bergmann, C., Cristia, A.,           Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
  Floccia, C., Gervain, J., ... Yurovsky, D. (under review).        Statistical learning by 8-month-old infants. Science, 274,
  A collaborative approach to infant research: Promoting            1926-1928.
  reproducibility, best practices, and theory-building.           Sakaluk, J. (2016, February 16). 7. Make It Pretty: Forest
  Preprint posted on PsyArXiv at https://osf.io/preprints/          and Funnel Plots for Meta-Analysis Using ggplot2. [Blog
  psyarxiv/27b43/                                                   post]. Retrieved from https://sakaluk.wordpress.com/2016
Graf Estes, K., & Lew-Williams, C. (2015). Listening                /02/16/7-make-it-pretty-plots-for-meta-analysis/
  through voices: Infant statistical word segmentation            Simonsohn, U., Nelson, L. D., & Simmons, J. P. (2014). P-
  across multiple speakers. Developmental Psychology, 51,           curve: A key to the file-drawer. Journal of Experimental
  1517-1528.                                                        Psychology: General, 143, 534–547.
Hunter, M. A., & Ames, E. W. (1988). A multifactor model          Thiessen, E. D., & Saffran, J. R. (2003). When cues collide:
  of infant preferences for novel and familiar stimuli.             Use of stress and statistical cues to word boundaries by 7-
  Advances in Infancy Research 5, 69-95.                            to 9-month-old infants. Developmental Psychology, 39,
Johnson, E. K., & Tyler, M. D. (2010). Testing the limits of        706-716.
  statistical learning for word segmentation. Developmental       Viechtbauer, W. (2010). Conducting meta-analyses in R
  science, 13(2), 339-345.                                          with the metafor package. Journal of Statistical Software,
Kemler Nelson, D. G., Jusczyk, P. W., Mandel, D. R.,                36, 1-48.
  Myers, J., Turk, A., & Gerken, L. (1995). The head-turn
  preference procedure for testing auditory perception.
  Infant Behavior and Development, 18, 111-116.
                                                              129

