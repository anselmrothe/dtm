         Leveraging mutual exclusivity for faster cross-situational word
                                     learning: A theoretical analysis
           Shohei Hidaka (shhidaka@jaist.ac.jp) and Takuma Torii (tak.torii@jaist.ac.jp)
                                    Japan Advanced Institute of Science and Technology
                                              1-1 Asahidai, Nomi, Ishikawa, Japan
                                 George Kachergis (george.kachergis@gmail.com)
                          Dept. of Artificial Intelligence / Donders Institute, Radboud University
                                                    Nijmegen, the Netherlands
                           Abstract                                   Beyond lexical constraints that reduce the number of
   Past mechanistic accounts of children’s word learning           hypothesis meanings considered for a given word in a
   claim that a simple type of cross-situational learning is       given situation, another possible remedy for the contra-
   powerful enough to match observed rates of learning,            diction between the difficulty of the unconstrained in-
   even in quite ambiguous situations. However, a limita-
   tion in some of these analyses is their reliance on an un-      ductive account of word learning and the ease of the
   realistic assumption that the learner only hears a word in      observed process is that learners also reduce uncer-
   situations containing the intended referent. This study         tainty in the word-object map by statistical inference
   analyzed a more general type of cross-situational learn-
   ing based on the relative frequency of word-object pairs,       over time, based on observing word-object pairs across
   and found it to be slower than the simple mechanism             multiple situations. Cross-situational learning (Pinker,
   analyzed in prior work. We then analytically explored           1984; Akhtar & Montague, 1999; Siskind, 1996) is a
   whether relative-frequency learning can be improved by
   incorporating the mutual exclusivity (ME) principle–            type of learning based on this idea, which has been an-
   an assumption that words map to objects 1-to-1. Our             alyzed both empirically and theoretically over decades
   analyses show that with a certain type of correlation in        (Yu, 2008; Blythe, Smith, & Smith, 2010). Blythe et al.
   word-to-word relationship, ME makes relative frequency
   learning as efficient as fast-mapping, which can learn a        (2010) formally quantified the effect of a type of cross-
   word in one exposure.                                           situational learning in terms of the rate of vocabulary
   Keywords: Word learning; Cross-situational learning             growth. More recent studies (Blythe, Smith, & Smith,
   models; Mutual exclusivity; Language acquisition                2016; Vogt, 2012) further showed that this type of cross-
                                                                   situational learning can be considerably slowed down for
                       Introduction                                certain types of word co-occurrence distributions, includ-
To a new learner of a language with a completely                   ing power-law distributions in which most words are seen
unknown word-referent mapping system, determining                  relatively rarely, which describe word frequency distribu-
which words refer to which referents in any given scene            tion in natural languages (Zipf, 1949).
may seem impossible on the face of it, since a word could
                                                                      These theoretical analyses are still quite limited in
refer not only to an object (e.g., ‘apple’), but to a class
                                                                   their generality. The class of cross-situational learning
of objects (e.g., ‘fruit’), a property (‘red’), or any one of
                                                                   analyzed in these past studies is called eliminative learn-
endless possible combinations or configurations of fea-
                                                                   ing. In this scheme, when a learner is exposed to a set
tures in the scene–an unconstrained problem of logical
                                                                   of referents, a correct word is spoken–never is a word
induction (Quine, 1960). In contrast to this theoretical
                                                                   spoken when its intended referent is not present. In this
observation about referential uncertainty, children are
                                                                   case, the learner can safely “eliminate” the possibility
thought of as efficient learners, and in fact most human
                                                                   of word A being associated to the object B, if he or
children do learn to understand and use an impressive
                                                                   she experiences one episode that the word A is spoken
number of words within the first years of life, achiev-
                                                                   without the object B. As this special assumption does
ing a vocabulary of roughly 60,000 by 18 years of age
                                                                   not generally hold in real-world learning, the estimates
(Bloom, 2000). Developmental researchers have theo-
                                                                   on the speed of cross-situational learning in past stud-
rized that children use a variety of lexical constraints
                                                                   ies give only an optimistic upper bound for its learning
to limit the number of possible mappings they consider,
                                                                   efficiency.
and a number of empirical studies support these claims
(Clark, 1987; Markman, 1990, 1992; Golinkoff, Hirsh-                  In this study, we consider a more general type of cross-
Pasek, Bailey, & Wegner, 1992). One lexical constraint,            situational learning, called relative frequency learning,
used here as in past theoretical accounts–and supported            of which eliminative learning is a special case. In the
by empirical developmental data, is that learners are bi-          relative frequency learning scheme, it is assumed that
ased to map words to entire objects, rather than to a              a language system encodes the word-object pair with
feature of an object, or a group/configuration of objects          frequency higher than the other candidate pairs as the
(Markman, 1990).                                                   correct one, and the learner infers such relatively more
                                                               2205

frequent word-object pairs from the sample. Under this            (channel), and the learner decodes (infers) the correct
assumption, the eliminative learning scheme is identified         word-object map using the underlying regularity: the
with the special case of seeing the correct word-object           correct word-object pair is the most frequent among the
pair with probability 1. In general, however, the elim-           others.
inative learning rule cannot apply (or will mislead the              There are theoretical analyses of a special case of this
learner if it is forced to apply) in word learning of a           relative frequency learning, in which the correct word
relative-frequency language system.                               is spoken only in the presence of the corresponding ob-
   Therefore, relative frequency learning is generally            ject (i.e., p(object|word) = 1). In this special case, the
slower than the eliminative learning. Thus, the main              learner can use not only the knowledge that the correct
problem considered in this study is what plausible fac-           pair is more frequent, but also the quite strong rule that
tor might make this type of learning more efficient – and         any object which does not appear with a spoken word
can it be made efficient enough to be a realistic account         cannot be the intended referent of that word. Thus, this
for children’s word learning? Specifically, we analyze the        learning scheme, which eliminates any word-object pair
beneficial effect of learners applying a general principle        with probability less than 1 is called eliminative learning
of mutual exclusivity (ME), an assumption of a word-              (Blythe et al., 2010). In this study, beyond this special
object regularity requiring that no two objects are associ-       case, we analyze a more general case of language and
ated to one word. Application of a ME principle has long          learning coded on the basis of relative frequency.
been theorized to be a constraint that can speed chil-
dren’s word learning (Markman & Wachtel, 1988), and               Formulation
has found empirical support in both children (Halberda,           Denote the frequency of object o given word w by f (o |
2003) and adults (Yurovsky & Yu, 2008; Kachergis, Yu,             w). Then, suppose the learner (decoder) declares that
& Shiffrin, 2012). We then consider a word-word statis-           the object o ∈ O is the referent of the word w ∈ W with
tical relationship in which a group of distractor objects         probability
tend to co-occur with a word and thus slow learning.
   In the following, we first outline the theoretical frame-                                          ef (o|w)
                                                                                    P (o | w) = P            f (o|w)
                                                                                                                     .
work in which we provide a series of analyses of relative                                           o∈{O} e
frequency learning. Second, we evaluate the basic learn-
ing efficiency in this scheme. Then we extend this eval-          In this scheme, the error, wrong declaration of the
uation of learning efficiency to multiple scenarios with          correct object, for word w with the number of ob-
different word-to-word statistical relationships.                 served    situations n is proportional to (n, w) :=
                                                                            f (o|w)−f (w|w)
                                                                  P
                                                                     o6=w e                 . The sum of the errors for all words
           Relative-frequency learning
                                                                                 P
                                                                  (n, w) := w∈W (n, w) is an exponential function of
Basic framework                                                   the number of situations. Let us denote the rate of
                                                                  the exponential function as R, and thus (n) = e−Rn .
In this study, we consider the following word learning            For aPcode with rate R encoding less than eRn signals,
scenario. The learner is exposed to multiple words and            limn w∈W P (o | w) = 1, and thus it is said to be learn-
objects in each situation. In each situation, the learner         able (reachable in information-theoretic terminology). If
does not know which word refers to which object, and              the rate satisfies (n) = e−Rn < e−Cn for any code, the
the correct word-object mapping can only be inferred              constant C is said to be the capacity of this channel in
by integrating evidence across observations of multiple           information-theoretic terms (Shannon, 1948). The rate,
situations. Let W = {1, . . . , n} be a set of words and          or the exponent coefficient of the error function, is a fun-
O = {1, . . . , m} a set of objects (or referents) which          damental characteristic of the language-learning system
appear in these situations. In this study, we consider            when viewed as a signal transmitting process.
a language structure with one-to-one word-object map-
ping, in which n = m and the word i refers to object              Efficiency
i. This is a quite strong assumption, which may not be            In the relative frequency learning scheme, the object o
considered entirely realistic as it is. It offers, however, a     with the second largest probability given the word w,
first approximation upon which we can base the analysis           pw|w > po|w > po0 |w for o0 6= o, w, is a key parameter
and later extend it.                                              giving the asymptotic time to learn the word w. With
   Here, we consider a particular word learning scheme,           objects with the largest and second largest probability,
called relative frequency learning, in which each object’s        the sample frequency can be written as follows. Let p =
to-be-associated (i.e., ‘correct’) word is spoken in its          1 − p. Specifically, consider that the sample frequency
presence with greater frequency than any other word.              fnow = fn (o|w) follows the binomial distribution
This is a code in the sense of information theory – the
                                                                                                       
signal, the correct word-object mapping, is encoded in                                               n
the statistical regularity in observation across situations                P (fnow |n, pow ) =             pfnow · pn−f  now
                                                                                                   fnow ow            ow
                                                              2206

with probability pow .                                            corresponding object can be uniquely identified, which
   Given this, the error probability in learning is char-         is effectively the same as fast mapping. Thus, the worst-
acterized as follows. The probability for the word w to           case learning time approaches that of relative frequency
be associated with the object o is proportional to efnow .        learning, and the best-case learning time approaches that
For a sufficiently large n, the difference between the two        of fast mapping, as the number of words is sufficiently
random variables asymptotically approaches                        large.
                         efnow −fno0 w                            Randomly distributed distractors
                    lim                    = C,
                   n→∞ en∆o,o0 |w                                 Random learning order Consider the case that each
                                                                  word is learned in a serial order and each has k distrac-
                          ow −po0 w
where ∆o,o0 |w := pow p̄pow +po0 w p̄o0 w . If there are m ob-    tors. Furthermore suppose that the learning order is
jects with the second largest probability pow > q >               a random permutation, namely any order is uniformly
maxo0 6=w, po0 w for the word w, the error probability is         sampled. Figure 1 shows a schematic co-occurrence ma-
                             pow −p 0
                                     o w
                       −n
1 − P (w|w) → Cme pow p̄ow +po0 w p̄o0 w . Thus, the rate of      trix of the five such word-object pairs (filled markers)
the relative-frequency code is R = minw ∆w|w where                with k = 2 randomly distributed distractors (open mark-
                                                                  ers) for each pair. In this case, one expects that one word
                         pow − maxo0 6=o po0 w                    is likely to be learned after the k distractors with prob-
       ∆o|w :=                                            .       ability 1/(k + 1). This is exactly true, if the number of
                pow pow + maxo0 6=o po0 w maxo0 6=o po0 w
                                                                  words n approaches to infinitely large. Therefore, the
This analysis implies that the word-object pair with the          sum of expected learning time for all the words is
smallest margin to second largest probability decides the                                                   
learning rate in the relative frequency code.                                               k           1
                                                                                 T =n           T1 +       T0 .            (1)
                                                                                          k+1         k+1
  Incorporating mutual exclusivity (ME)
                                                                  Thus, when the learning order is a random permuta-
In the above analysis of the relative frequency code,
                                                                  tion, the expected learning time is only the factor of
the lexical constraint of one-to-one word-object mapping            1
is not taken into consideration in the learning process.          k+1 shorter than the original time nT1 at shortest.
However, if the learner exploits the fact that no two ob-
jects are associated with the same word, namely correct                Word                     Objects              #D
word-object pairs are mutually exclusive, the learning is              “Circle”         ●      △          ☆              2
expected to be more efficient than the alternative with-               “Triangle”              ▲ □             ◇         2
out the knowledge. Let us call this ME learning. The
difference in the rate of learning assuming ME and gen-
                                                                       “Square”         ○      △ ■                       2
eral relative frequency would be the effect of introducing             “Star”           ○                 ★ ◇            2
a ME constraint in cross-situational learning.                         “Diamond”               △ □             ◆         2
   With ME, the learner can exclude object o when learn-
ing word w, if the object o is likely to be associated            Figure 1: A schematic word-object co-occurrence matrix
with some other word w0 6= w. Thus, the learning or-              in the case with random learning order and randomly
der of the words has considerable impact in learning un-          distributed distractors.
der ME. As the previous analysis shows that the sec-
ond most probable objects for word w is the key fac-
tor giving the learning rate, let us call them distractors        Shared distractors
against the word w, and denote the set of distractors by          Best and worst learning order Let us consider the
D(w) := {w0 | maxo6=w fo|w = fw0 |w }.                            best and worst case by manipulating which words the
                                                                  k distractors are associated. In one of the best cases,
Best- and worst-case scenarios                                    every word shares the same set D of k distractors. Fig-
Here let us analyze ME learning under a simplification            ure 2 shows a schematic co-occurrence matrix of the five
that the learning time for the words with no distractor           such word-object pairs (filled markers), and each pair
is T0 and that for the words with one more distractors            has k = 2 distractors (open markers) and most of words
is T1 . The former case with no distractor is said to be          share the same two distractors. In this case, the short-
fast mapping, in which a particular word-object pair is           est learning time is obtained by a sequence of learned
presented alone in a situation, and the learner learns            words in which the k words with the k distractors as
the pair in a single shot (Carey & Bartlett, 1978). The           their correct objects first (required about T1 time each)
latter case is analyzed in the previous section in case of        and the others later (required T0 time each). In the ex-
the relative frequency learning. In this case, if all the         ample (Figure 2), one of the best order is to learn the
distractors has been eliminated, by the effect of ME, the         word “Circle” and “Triangle” at the first two rows in the
                                                              2207

matrix, and then learn the other words. In this case, the      specific class of statistical regularity in the word-word re-
total learning time is                                         lationship. Specifically, suppose there are two groups of
                                                               words: in the one group of words, each word has no dis-
                   T = kT1 + (n − k)T0 .                       tractor, and in the other group of words, each word has
                                                               k distractors, whose referring words have no distractor
As the number of words n gets larger with a constant k,        (Figure 3). Thus, the learner is exposed to a mixture of
the learning time approaches to that of the fast mapping       two groups of words with and without distractors. Fig-
(T0 per word), which is the lower bound of learning time.      ure 3 shows a schematic co-occurrence matrix of such
   In one of the worst cases, on the other hand, the           five word-object pairs, in which each of the first group of
longest learning time is obtained by the reversed se-          words (“Circle” and “Star”) has no distractors, and each
quence, in which the words with the k distractors as their     of the other group of words has two distractors whose re-
correct objects are learned last. In total, the longest        ferring words are the members of the first group.
learning time is                                                  Although this statistical regularity in word-to-word
                          T = nT1 .                            relationships looks similar overall to the previous case
As the number of words n gets larger with a constant           (compare Figure 2 and 3), this new case is substantially
k, learning time approaches that of relative frequency         different from the previous cases. The key observation
learning, which is the upper bound of learning time.           here is that no distractor words have any distractors
                                                               against themselves. Thus, the first group of words (po-
Random learning order Thus, this analysis with the             tential distractors to the other group of words) would
best and worst case scenario suggests that the learning        be learned via fast mapping, and the other group would
order of words has a large impact on learning time. How-       be learned also via fast mapping after their distractors
ever, the expected learning time with the shared distrac-      are learned before their learning. The learning timing of
tors is, again, exactly 1/(k + 1), which is no better than     these two groups are probabilistic, but the first group of
the learning time of the case with k random distractors        words are expected to be learned earlier on average than
(Equation (1)):                                                the other group.
                                          
                          k          1
              T =n           T1 +        T0 .                       Word                       Objects             #D
                        k+1        k+1
                                                                    “Circle”           ●                              0
This analysis suggests that even systematically shared              “Triangle”         ○     ▲           ☆            2
distractors cannot improve the learning time on average,            “Square”           ○          ■      ☆            2
if the learning order is uniformly at random.
                                                                    “Star”                               ★            0
     Word                     Objects            #D                 “Diamond”          ○                 ☆     ◆      2
     “Circle”          ●    △ □                      2
                                                               Figure 3: A schematic word-object co-occurrence matrix
     “Triangle”        ○    ▲ □                      2         in the case with the two groups of words. Each of the
     “Square”          ○    △ ■                      2         first group of words (“Circle” and “Star”) has no distrac-
     “Star”            ○    △          ★             2         tors, and each of the second group of words (“Triangle”,
     “Diamond”         ○    △               ◆        2         “Square” and “Diamond”) has k = 2 distractors, whose
                                                               referring words (“Circle” and “Star”) has no distractors.
Figure 2: A schematic word-object co-occurrence ma-
trix in the case with random learning order and k = 2          Efficiency analysis
distractors shared by all the words systematically.
                                                               Specifically, suppose that each word in the group with
                                                               distractors is learned at the time step t by the probability
 Correlation in word-to-word relationship
                                                                                    pt = (qt + qt p)pt−1 ,
Mixture of two groups of words
As the previous analysis suggests that the relative fre-       where p is the probability to learn this word with dis-
quency learning of a one-to-one word-object map in the         tractors at each step, and qt is the probability to learn
cross-situational setting is as slow as independent learn-     it without distractor at step t, or is said the probability
ing even by incorporating ME. This result is largely due       for the
                                                                     P∞ learning at step t to be fast mapping. By set-
to the statistical structure of the word-word relationship     ting t=1 (1 − p)pt−1 t = T1 and qt = 0 for any t, this
– in the previous analysis, each word has k other ran-         learning time with k > 0 distractors is identified with
dom words as distractors. In this section, we consider a       the previous analysis.
                                                           2208

   Suppose that there are n0 words without distractors,             This analytic implication is striking in that cross-
and t0 < t samples out of the all t − 1 samples are drawn        situational learning on the basis of relative frequency,
from this group of words with equal probability. Then,           which itself is as slow as independent learning with a
according to Hidaka (2014), as n0 → ∞, the probability           random word-word relationship, can become as efficient
to learn the m words of this group with the t0 samples           as fast-mapping, up to a constant time per word. At the
asymptotically approaches to the binomial distribution           very least, this analysis implies that the nature of the
                       n0  
                                                                 word-to-word relationships is a critical factor in deter-
                      X     n0 m n0 −m                           mining the efficiency of relative-frequency based cross-
                                 r rt
                     m=0
                            m t                                  situational learning.
where rt := 1 − (1 − 1/n0 )t0 . If each word in the group                               Discussion
with distractors is associated to k distractive words uni-
formly at random, the fast-mapping probability is                In this paper, we studied cross-situational word learn-
                                                                 ing from a theoretical perspective as the formation of a
                  n0                                       one-to-one word-object map. Our formulation of cross-
                 X      n0 m n0 −m m             n0
           qt =             rt rt            /       .           situational learning is defined as learning on the basis of
                 m=0
                        m                 k       k
                                                                 the relative frequency of objects for each word, which
                                                                 is a more realistic alternative model than eliminative
As the hypergeometric distribution1 approaches the bi-
                                                                 learning, a model analyzed in past studies (Blythe et
nomial distribution as n0 → ∞, we obtain
                                                                 al., 2010, 2016) that is anyhow a special case of rela-
           k 
       m      n0         m      k            k
                                                m−k             tive frequency learning. Thus, our analysis of relative
           /        −                   1−              → 0.     frequency learning is both more general and more re-
        k      k         k      n0          n0
                                                                 alistic than previously-proposed frameworks. Our anal-
                                                                 ysis shows that its total learning time depends on the
Using these asymptotic distributions for n0 → ∞, we
                                                                 minimal difference between the most frequent and the
obtain the binomial distribution
                                                                 second-most frequent objects among all the words, and
                                  k            n0 −k         that it is quite slow.
                  n0 !          k              k
        qt →                 rt         1 − rt           .          Given that relative frequency learning alone is ineffi-
              k!(n0 − k)!       n0             n0
                                                                 cient, we next analyzed the case when the learner applies
With further transform for a sufficiently large n0 , we          the lexical constraint that no two referents are associated
obtain the fast-mapping probability to be                        to a single word. This principle of mutual exclusivity
                                    k                          (ME) has been hypothesized to be an important means
                                  t0                             of reducing ambiguity for children learning language
                         qt ≈           .
                                 n0                              (Markman & Wachtel, 1988; Markman, 1990, 1992), and
                                                                 empirical work has found that both children (Golinkoff et
This expression thus implies that the probability qt of          al., 1992; Halberda, 2003; Markman, Wasow, & Hansen,
learning via fast mapping with k distractors approaches          2003) and adults in cross-situational word learning ex-
1, if the sample of the words without distractors t0 is          periments (Yurovsky & Yu, 2008; Kachergis et al., 2012)
comparable to the number of such words n0 .                      show a preference for learning mappings consistent with
Implications                                                     ME. Using ME, a word can be learned via fast mapping
                                                                 (learned on its first sample), if all the distracting words
Suppose the number of words without distractors is n0 =
                                                                 appearing with it are already learned. However, the ef-
γn with a certain constant 0 < γ < 1, and the number of
                                                                 fect of ME on the average learning time is quite limited
samples t0 = γt. In this case, as t0 /n0 = t/n, after the
                                                                 – the same (up to a constant multiplier) as that of in-
point when the number of samples is comparable with
                                                                 dependent relative frequency learning, if the distractors
the number of words, this learning is sufficiently treated
                                                                 for each word are distributed uniformly. In summary,
as the fast mapping. Thus, the learning time of a word
                                                                 this analysis suggests that the order in which words are
with k distractors asymptotically approaches the speed
                                                                 learned is related to the statistical nature of the word-
of fast-mapping after some constant number of samples
                                                                 to-word relationship–i.e., the structure among the co-
for each word. In other words, in the long run, any
                                                                 occurring distractors.
words would be considered learned in the fast-mapping
manner, if any distractor word has no distractors against           Therefore, we finally analyzed the case in which a set
itself.                                                          of words is composed of two word groups: in one group,
                                                                 each word has no distractors, and in the other group
   1
     Gives the probability of k successes in n draws, from a     each word has k distractors, which are the words with-
population of size N with exactly K successes. Thus, similar
to the binomial distribution, but drawing without replace-       out any distractors. Here, it is not just a mixture of
ment.                                                            two types of words, but the distracting words have no
                                                             2209

distractors to themselves, and thus they are likely to            (Ed.), Mechanisms of language acquisition. Hillsdale,
be learned earlier than the other group. Thus, in this            NJ: Erlbaum.
schematic word structure, the expected learning order is        Gershkoff-Stowe, L., & Hahn, E. R. (2007). Fast map-
correlated to the number of distractors for the group of          ping skills in the developing lexicon. Journal of Speech,
words. We hypothesize that, with this statistical reg-            Language, and Hearing Research, 50 , 682–697.
ularity, relative frequency learning can be as efficient        Golinkoff, R. M., Hirsh-Pasek, K., Bailey, L. M., & Weg-
as learning via fast-mapping, which has been observed             ner, N. R. (1992). Young children and adults use
in young children (Mervis & Bertrand, 1994; Gershkoff-            lexical principles to learn new nouns. Developmental
Stowe & Hahn, 2007). Our analysis suggests that this              Psychology, 28 (1), 99–108.
hypothesis is supported: the learning time is comparable        Halberda, J. (2003). The development of a word-learning
with that of fast mapping learning up to a constant num-          strategy. Cognition, 87 (1), B23–B34.
ber of samples per word, when a certain ratio of words          Hidaka, S. (2014). General type token distribution.
has no distractors. We expect that this analytic result           Biometrika, 101 (4), 999–1002.
can be extended to a more general case, such that there         Kachergis, G., Yu, C., & Shiffrin, R. M. (2012). An asso-
are multiple groups with different numbers of distractors         ciative model of adaptive inference for learning word–
up to k and a group of words with k distractors that has          referent mappings. Psychonomic Bulletin and Review ,
no distractors which have k or more distractors against           19 (2), 317–324.
themselves.                                                     Markman, E. M. (1990). Constraints children place on
   In summary, we have analyzed a more general and                word meanings. Cognitive Science, 14 , 57-77.
more realistic class of word learning models, relative fre-     Markman, E. M. (1992). Constraints on word learning:
quency learning. Although we showed that learning in              Speculations about their nature, origins and domain
this more general framework can be quite slow, we then            specificity. In M. R. Gunnar & M. P. Maratsos (Eds.),
examined learning under assumptions of mutual exclu-              Modularity and constraints in language and cognition:
sivity and word-to-word correlations that might more              The minnesota symposium on child psychology (pp.
closely approximate learning situations in the natural            59–101). Hillsdale, NJ: Erlbaum.
language environment. By modifying situations to in-            Markman, E. M., & Wachtel, G. F. (1988). Children’s
clude realistic variants of these two factors, we showed          use of mutual exclusivity to constrain the meanings of
that learning a full-sized vocabulary could be accom-             words. Cognitive Psychology, 20 , 121–157.
plished on a realistic timescale. Although this work is         Markman, E. M., Wasow, J. L., & Hansen, M. B. (2003).
preliminary, the analytical techniques employed here can          Use of the mutual exclusivity assumption by young
be applied to other, yet more realistic cross-situational         word learners. Cognitive Psychology, 47 (3), 241–275.
learning schemes, incorporating better approximations           Mervis, C. B., & Bertrand, J. (1994). Acquisition of the
of the language environment, of the problem faced by              novel name - nameless category (n3c) principle. Child
the learner, and of the biases employed by the learner.           Development, 65 , 1646-1662.
                 Acknowledgments                                Pinker, S. (1984). Learnability and cognition. Cam-
This study is supported by the JSPS KAKENHI Grant-                bridge, MA: MIT Press.
in-Aid for Young Scientists JP 16H05860.                        Quine, W. V. O. (1960). Word and object. Cambridge,
                                                                  MA: MIT Press.
                      References                                Shannon, C. E. (1948). A mathematical theory of com-
Akhtar, N., & Montague, L. (1999). Early lexical ac-              munication. Bell System Tech. Journal , 27 , 379–423.
  quisition: the role of cross–situational learning. First      Siskind, J. M. (1996). A computational study of cross-
  Language, 19 , 34–358.                                          situational techniques for learning word-to-meaning
Bloom, P. (2000). How children learn the meaning of               mappings. Cognition, 61 , 39–91.
  words. Cambridge, MA: MIT Press.                              Vogt, P. P. (2012). Exploring the robustness of cross-
Blythe, R. A., Smith, A. D. M., & Smith, K. (2016).               situational learning under Zipfian distributions. Cog-
  Word learning under infinite uncertainty. Cognition,            nitive Science, 36 (4), 726–739.
  151 , 18–27.                                                  Yu, C. (2008). A statistical associative account of vocab-
Blythe, R. A., Smith, K., & Smith, A. D. M. (2010).               ulary growth in early word learning. Language Learn-
  Learning times for large lexicons through cross-                ing and Development, 4 (1), 32–62.
  situational learning. Cognitive Science, 34 (4), 620–         Yurovsky, D., & Yu, C. (2008). Mutual exclusivity in
  642.                                                            cross-situational statistical learning. In Proc. of cogsci
Carey, S., & Bartlett, E. (1978). Acquiring a single new          30. Austin, TX: Cognitive Science Society.
  word. Papers and Report on Child Language Develop-            Zipf, G. (1949). Human behavior and the principle of
  ment, 15 , 17–29.                                               least effort. Cambridge, MA: Addison-Wesley.
Clark, E. V. (1987). The principle of contrast: A con-
  straint on language acquisition. In B. MacWhinney
                                                            2210

