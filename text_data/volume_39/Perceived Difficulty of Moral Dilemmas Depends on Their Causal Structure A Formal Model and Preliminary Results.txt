        Perceived Difficulty of Moral Dilemmas Depends on Their Causal Structure:
                                        A Formal Model and Preliminary Results
Barbara Kuhnert1 (kuhnertb@informatik.uni-freiburg.de), Felix Lindner2 (lindner@informatik.uni-freiburg.de)
             Martin Mose Bentzen3 (mmbe@dtu.dk), Marco Ragni1,2 (ragni@informatik.uni-freiburg.de)
                          1 Cognitive    Computation Lab, University of Freiburg, Freiburg im Breisgau, Germany
                     2 Foundations    of Artificial Intelligence, University of Freiburg, Freiburg im Breisgau, Germany
                                 3 Management Engineering, Danish Technical University, Lyngby, Denmark
                                  Abstract                                  resents a qualitative advance in the ability to make consis-
                                                                            tent and differentiated judgments concerning moral norms
     We propose causal agency models for representing and reason-
     ing about ethical dilemmas. We find that ethical dilemmas, al-         and principles. Conversely, the theory of moral reasoning ad-
     though they appear similar on the surface, differ in their formal      vocated by Mikhail (2007) assumes that there is moral gram-
     structure. Based on their structural properties, as identified by      mar triggering certain moral judgments. He hypothesizes two
     the causal agency models, we cluster a set of dilemmas in Type
     1 and Type 2 dilemmas. We observe that for Type 1 dilemmas             rules for the grammar: the norm prohibiting intentional bat-
     but not for Type 2 dilemmas a utilitarian action does not domi-        tery as a means, and the norm of double effect valuating bat-
     nate the possibility of refraining from action thereby constitut-      tery as side effect. The research by Greene, Sommerville,
     ing a conflict. Hence, we hypothesize, based on the model, that
     Type 1 dilemmas are perceived as more difficult than Type 2            Nystrom, Darley, and Cohen (2001); Haidt (2001) claims a
     dilemmas by human reasoners. A behavioral study where par-             prevalence of emotionally based moral intuition. Greene and
     ticipants rated the difficulty of dilemmas supports the models’        Haidt (2002) are moving away from moral reasoning tending
     predictions.
                                                                            towards moral judgments caused by immediate affective in-
     Keywords: Moral Reasoning; Moral Complexity; Moral                     tuitions and emotions. Greene et al. (2001) advanced the dual
     Dilemmas; Causal Agency Models; Ethical Principles
                                                                            process model of moral judgment. They assume competi-
                                                                            tive moral subsystems in the brain resp. moral reasoning that
                             Introduction                                   is influenced by the mutual interaction and competition be-
  Currently, we experience a hot debate on moral reasoning and              tween two distinct psychological systems: (1) the emotional,
  artificial intelligence (AI). In one respect, the discussion is           intuitive, deontological judgment system and (2) the rational,
  about how to apply AI technology morally. In another re-                  calculated, utilitarian judgment system.
  spect, there is a requirement to enable AI technology itself to              Throughout the literature, various hypothetical moral
  make moral decisions. Fields of application are self-driving              dilemmas are used to investigate questions concerning hu-
  cars (Bonnefon, Shariff, & Rahwan, 2016), robots navigat-                 man morality, moral reasoning and moral judgments. We will
  ing in social environments (Lindner, 2015), and even robots               make use of four dilemmas:
  that give moral advice (Lindner & Bentzen, 2017). As a con-
  sequence, new research areas such as machine ethics (Allen,              1. Runaway Trolley Dilemma A runaway trolley is about to
  Wallach, & Smit, 2006) and moral human-robot interaction                     run over and kill five people. If a bystander throws a switch
  (Malle, Scheutz, Arnold, Voiklis, & Cusimano, 2015) arise.                   then the trolley will turn onto a sidetrack, where it will kill
     To address the requirement for autonomous moral decision                  only one person.
  making, we recently introduced a software library for model-
                                                                           2. Pregnancy Dilemma A pregnant woman is about to give
  ing hybrid ethical reasoning agents (short: HERA)1 (Lindner
                                                                               birth to her triplets. If the doctors treat the woman then her
  & Bentzen, 2017). The goal of the HERA project is to pro-
                                                                               triplets will live, but she will die. Otherwise, the triplets
  vide theoretically well-founded and practically usable logic-
                                                                               will die, but the life of the pregnant women will be saved.
  based machine ethics tools for implementation in artificial
  moral agents such as (social) robots and software bots. To               3. Boat Dilemma A boat is about to sink because of over-
  align human moral reasoning with moral reasoning by ma-                      weight. If the crew is told to throw the biggest person into
  chines, our development of formal models and algorithms is                   the sea then the boat will not sink and the other three pas-
  informed by moral psychology and moral philosophy. We                        sengers will be saved (but the big person will die).
  aim for the integration of various theories about human moral
  development, moral reasoning, and ethics.                                4. Hijacked Airplane Dilemma An airplane was hijacked by
     There are several approaches to explain human moral rea-                  terrorists, and the terrorists threaten to crash the airplane
  soning. Kohlberg (1984), whose approach is based on Pi-                      against a populated area on the ground. If the military
  aget’s “genetic epistemology” claimed that individuals are                   shoots the airplane the passengers will die but the airplane
  passing through six invariant and universal stages in the de-                will crash in a deserted area thus not harming anyone else.
  velopment of moral reasoning. Reaching the next stage rep-
                                                                               Several ways of classifying dilemmas and different moral
      1 http://www.hera-project.com                                         reasoners have been proposed: Greene, Nystrom, Engell,
                                                                       2494

Darley, and Cohen (2004) differentiate between personal             model. The set of boolean structural equations in a model is
dilemmas and impersonal dilemmas. Among subjects, com-              called a causal mechanism. The truth assignment of the root
monly more deontological judgments are produced with per-           node of the graph is called a world or an option. Formally,
sonal dilemmas, while impersonal dilemmas commonly pro-             we define causal agency models as follows:
duce consequentialist judgments (Moll & de Oliveira-Souza,          Definition 1 (Causal Agency Models)
2007). Crockett (2013) proposes a model-based system for            A (boolean) causal agency model, M, is a tuple hU = A ∪
consequentialist reasoning: The reasoner evaluates the best         B,C, F, u,W i, where, A = {a1 , . . . , am } is a nonempty finite set
outcome of an action by starting from the current action and        of propositional variables called the actions. B = {b1 , . . . , bk }
searching through a decision tree. In the model-free evalu-         is a (possibly empty) finite set of propositional variables
ation, which is associated with deontological reasoning, the        called the background variables. Together the actions and
forward searching is not activated. Shou and Song (2015)            background variables are the exogenous variables as defined
found that most of their subjects, irrespective of whether they     above. C = {c1 , . . . , cn } is a finite (possibly empty) set of
chose a deontological decision or a consequentialist deci-          propositional variables called the endogenous variables. F
sion, evaluated consequences when information about out-            is a causal mechanism explained above. u : literals → Z is a
come probabilities was provided. Wiegmann and Waldmann              utility function assigning an integer value to each literal. W
(2014) propose that the moral dilemmas’ underlying causal           is a set of boolean interpretations of (A ∪ B).
structure supports moral intuition and thus is an important
factor for the moral judgments humans make.                            We assume some familiarity on the part of the reader with
   Thus, we observe that research has been focused on the ef-       classical propositional logic (and (∧), or (∨), not (¬), and
fects of content and structure of moral dilemmas on human           so on) and of truth functional semantics. A formula con-
moral judgments. Our research focus is on moral complex-            taining variables such as (c1 ∧ a1 ), is intended to mean that
ity and adds evidence for how structural properties of moral        consequence c1 and action a1 both obtain. We write M, wi |=
dilemmas affect their perceived difficulty. The paper is struc-     (c1 ∧ a1 ) for (c1 ∧ a1 ) is true with option wi (or at world wi )
tured as follows: First, we introduce causal agency models          in the model M. Apart from propositional formulas we need
as a tool for representing moral dilemmas in terms of causes        simple arithmetic formulas expressing the utility of literals.
and utilities. Second, we define ethical principles within this     We write u(vi ) = z, for an integer z, with the intended mean-
framework. Third, the four aforementioned moral dilemmas            ing that the utility of vi is z, similarly we write u(vi ) ≥ u(v j )
are modeled using causal agency models. Based on struc-             for the utility of vi is equal to or greater than the utility of v j .
tural commonalities and differences of these models, we dis-        We extend the utility function to conjunctions of literals by
tinguish two dilemma types, which we term Type 1 and Type           addition of the utilities of the conjuncts. The utility of other
2 dilemmas. We hypothesize that Type 1 dilemmas are more            formulas (e.g., disjunctions) is undefined.
difficult to solve for humans than Type 2 dilemmas. Fourth,
we present an empirical study which shows that our model                                  Ethical Principles
predicts human ratings about the perceived difficulty for the       Causal agency models play the role of representations of situ-
two types of moral dilemmas.                                        ations involving moral decisions. We now define ethical prin-
                                                                    ciples according to which moral permissibility of actions can
                 Causal Agency Models                               be assessed based on the actions’ consequences. For the fol-
                                                                    lowing discussion, the principle of act-utilitarianism and the
Ethical principles can be modeled as specifications of moral
                                                                    notion of Pareto dominance are of particular importance.
permissibility in causal agency models. Causal agency mod-
els are extensions of causal models that are used for counter-         The utilitarian principle focuses on consequences of ac-
factual reasoning about causality, responsibility, blame, and       tions. It states that an agent ought to perform the action
related concepts (Halpern, 2016). In our HERA framework,            among the available alternatives with the overall maximal
an ethical principle is represented as a logical formula whose      utility. We adopt an act-utilitarian interpretation which does
truth determines which actions are permissible according to         not distinguish between doing and allowing, i.e., the causal
the principle and which are not. Actions and their con-             structure of the situation is not taken into account. Thus the
sequences are modeled as directed acyclic graphs showing            action which the agent ought to perform is the one which
causal influence. At the root of the graph will be actions and      leads to the best possible situation, i.e., the highest utility,
other independent variables influencing consequences further        regardless of what the agent causes and intends.
down the graph. Boolean structural equations capture all the        Definition 2 (Utilitarian Permissibility)
information about the causal relationship between variables.        Let w0 , ..., wn be the available options, and conswi =
For instance, to model that the trolley from the Runway Trol-       {c | M, wi |= c} be the set of consequences and their nega-
ley Dilemma will turn onto a sidetrack when the bystander           tions that obtain with these options. An option w p is per-
throws the switch, we may write the boolean structural equa-        missible according to the utilitarian principle if and only if
tion turn := throw. The boolean variable turn will be true in       none of its alternatives yield more overall utility, i.e., M, wi |=
                                                                    u( consw p ) ≥ u( conswi ) holds for all wwi .
                                                                       V                V
the model whenever the boolean variable throw is true in the
                                                                2495

   The utilitarian principle allows that an action brings about         els. Commonalities and differences are discussed both with
some bad consequences if it at the same time brings about               respect to representation and ethical reasoning.
more good consequences. For instance, it allows sacrificing
some people if this sacrifice serves the good of many people.           Representations
As an alternative to utilitarian permissibility we introduce the        Consider the Runaway Trolley dilemma (cf., p.1). We model
principle of Pareto permissibility. To this end, we first define        this situation from the perspective of the bystander, who faces
the notion of Pareto dominance, which allows us to conclude             the decision to either throw the switch or to refrain from do-
that some action brings about a negative outcome in some                ing so. Let a1 be the action variable representing the action of
respect, although it may be the optimal action from an utili-           throwing the switch, and a2 be the action variable represent-
tarian point of view. An option wa dominates another option             ing refraining from throwing the switch. The consequence
wb if and only if wa is no worse in any aspect compared to wb ,         variable c1 represents that the one person on the other track
and wa improves at least one aspect of wb either by making              dies, and the consequence variable c2 represents that the five
more good consequences obtain or less bad consequences ob-              persons on the current track die. The causal mechanism is
tain. Thus the agent does not change the world for the worse            expressed by structural equation in the following way: The
and will change it for the better by choosing the dominant              structural equation c1 := a1 states that throwing the switch
action instead of the dominated one.                                    brings about the death of the one person on the other track,
Definition 3 (Pareto Dominance)                                         and the structural equation c2 := ¬a1 states that not throwing
                                                            good
Let w0 , w1 be two available options, let conswi =                      the switch will bring about the death of the other five persons.
{c | M, wi |= c ∧ u(c) > 0} be the set of good consequences             We assign utilities u(c1 ) = −1 and u(c2 ) = −5 to the conse-
                      good
of option wi , conswi = {c | M, wi |= ¬c ∧ u(c) > 0} the set            quences reflecting the number of deaths. For the lucky case
of good consequences that does not obtain in option wi , and            that c1 or c2 do not obtain, we assume positive consequences,
consbad                                                                 viz., u(¬c1 ) = 1 and u(¬c2 ) = 5. (One could argue that it is
      wi = {c | M, wi |= c ∧ u(c) ≤ 0} the bad consequences of
option wi . Option w0 dominant option w1 if and only if the             also appropriate to set u(¬c1 ) = u(¬c2 ) = 0, because survival
following conditions hold: 1) w0 shares all the good con-               does not improve the persons’ current state of being alive. On
                                           good
sequences with w1 (M, w0 |= consw1 ), 2) w0 either has
                                    V                                   the other hand, to escape from danger intuitively bears pos-
at least one good consequence that does not hold in w1 , or             itive utility. We consider this question as another empirical
w1 has at least one bad consequence that does not hold in               question that is out of the scope of this paper. For now it is
                       good                                             important to note our findings do not depend on this choice.)
w0 (M, w0 |= consw1 or M, w0 |= ¬ consbad
                W                            V
                                                    w1 ), and 3) all       We consider now the Pregnancy dilemma and model the
the bad consequences       of w 0 are also bad  consequences  of w1     situation from the perspective of the doctor, wo faces the de-
(M, w1 |= consbad
             V
                    w0  ).                                              cision to either treat the woman or to refrain from doing so.
   Based on Pareto dominance, Pareto permissibility is de-              Thus, we are assuming two actions a1 , treating the woman,
fined. Pareto permissibility permits options not dominated by           and a2 , refraining from treating the woman. Moreover, we
other options. Pareto permissibility can thus be understood             introduce consequence c1 representing that the woman dies,
as a principle of moral rationality: If there is an option that         and consequence c2 representing that the triplets die. The
is better in all aspects compared to an alternative, then the           structural equations are c1 := a1 and c2 := ¬a1 . The utilities
only rational choice is to choose the better one. It would be           are set in accordance with the number of dying individuals:
irrational (and thus impermissible) to choose the worse alter-          u(c1 ) = −1 and u(c2 ) = −3. As with the first dilemma, we
native.                                                                 assume that not dying yields positive utility, and hence we set
Definition 4 (Pareto Permissibility)                                    u(¬c1 ) = 1 and u(¬c2 ) = 3.
Let w1 , ..., wn be the set of options available to an agent. Op-          Note that the Pregnancy dilemma is structurally isomor-
tion wi is permissible according to the Pareto principle if and         phic to the Runaway dilemma, i.e., the dilemmas can be
only if it is not dominated by some option w j .                        mapped to each other. The only difference is the number of
   As will become apparent below, utilitarian permissibility            deaths in case of inaction (3 versus 5). Hence, we do not
and Pareto permissibility predict the same set of permissible           expect big differences regarding the complexity of reasoning
actions for some dilemmas and different sets of permissible             about these dilemmas.
actions for other dilemmas. Generally, actions permissible                 The Boat dilemma is modeled from the perspective of the
from the utilitarian point of view are also permissible from            crew, that has to decide whether to throw the biggest person
the Pareto point of view. But the converse does not hold: For           into the sea. We assume two actions a1 , throwing the biggest
some dilemmas, the set of actions permitted by each principle           person into the sea, and a2 , refraining from doing so. In con-
differ. In those cases of disagreement the moral reasoner has           trast to the two previous dilemmas, it would be incorrect to
to solve a conflict.                                                    model this dilemma as a choice between the one dying be-
                                                                        cause of performing a1 and the other three dying because of
                Models of Moral Dilemmas                                refraining from action. Instead, the model has to capture that
In this section, the four dilemmas presented in the introduc-           the biggest person will die in both cases, viz., either because
tion are modeled within the framework of causal agency mod-             of being thrown into the sea or by drowning together with his
                                                                    2496

colleagues because of the sinking ship. To represent this situ-        tive consequence of a1 is that the biggest person dies resp.
ation appropriately, we assume three consequences: the ship            the passenger die). Second, verify that indeed M, wa1 |= >
sinks (c1 ), the biggest person dies (c2 ), and the three other        (satisfying condition 1 of the definition of Pareto dominance,
passengers die (c3 ). The structural equations are c1 := ¬a1           all the good consequences of refraining are also good conse-
(the ship will sink if the biggest person is not thrown into the       quences of throwing, viz., there are none), M, wa1 |= ¬c2 ∨
see), c2 := a1 ∨ c1 (the biggest person will die if she is thrown      ¬c3 (satisfying condition 2 of the definition of Pareto dom-
into the sea or if the ship sinks), and c3 := c1 (the three other      inance, throwing (shooting) yields one of the good conse-
passengers will die if the ship sinks). The utilities again re-        quences not yielded by refraining, viz., ¬c3 ), and M, wa2 |= c2
flect the number of deaths: u(c2 ) = −1 and u(c3 ) = −3, and           (satisfying condition 3 of the definition of Pareto dominance,
as with the other two principles we assume that u(¬c2 ) = 1            the bad consequences of throwing (shooting) is also a bad
and u(¬c3 ) = 3.                                                       consequence of refraining).
   The Hijacked Airplane dilemma again is isomorphic to the               To sum up, for the isomorphic pair Runway Trolley
Boat dilemma. It can thus be modeled accordingly: a1 refers            dilemma and Pregnancy dilemma, both taking action and re-
to the action of shooting the airplane, and a2 to refraining           fraining are Pareto permissible but only the former is permit-
from doing so. Consequence c1 represents the airplane crash-           ted by the utilitarian principle. Thus, the two principles are in
ing, c2 represents the death of the passengers, and c3 corre-          conflict. For the isomorphic pair Boat dilemma and Hijacked
sponds to the death of people on the ground. The utilities can         Airplane dilemma, the two principles agree on only permit-
be set to any values such that u(c2 ) > u(c3 ).                        ting taking action.
Ethical Reasoning                                                      Type 1 and Type 2 Dilemmas
The ethical principles “utilitarian permissibility” and “Pareto        Our formal investigations suggest that the moral dilemmas we
permissibility” defined above can now be applied to the out-           are considering can be classified based on their formal prop-
lined models of the four moral dilemmas. The first observa-            erties. All the considered dilemmas are constituted by the
tion is that according to utilitarian permissibility taking action     choice between a big sacrifice as a consequence of inaction
(a1 ) is permissible and refraining from action (a2 ) is imper-        or a smaller sacrifice as a consequence of action. However,
missible in all four dilemmas, i.e., it is obligatory to throw the     in case of the Runaway Trolley and the Pregnancy dilemma,
switch, to treat the woman, to throw the biggest crew mem-             the sets of negatively affected people are disjoint, whereas in
ber into the sea, and to shoot the hijacked airplane. This is          case of the Boat dilemma and the Hijacked Airplane dilemma,
rather easy to see by considering the sums of the utilities.           the set of negatively affected people as a consequence of ac-
E.g., throwing the switch in the Runaway Trolley dilemma               tion is a subset of the set of negatively affected people as a
yields utility u(c1 ∧ ¬c2 ) = −1 + 5 = 4 whereas not throwing          consequence of inaction. This analysis yields that putting
the switch yields u(¬c1 ∧ c2 ) = 1 − 5 = −4.                           other people in danger by saving some raises moral conflicts,
   For the Runaway Trolley dilemma and the Pregnancy                   whereas saving a subset of people in danger does less so.
dilemma, performing action a1 does not dominate refraining                We take this difference to be a justification for subsuming
from action (a2 ) according to the definition of Pareto domi-          dilemmas of the Runaway Trolley and Pregnancy dilemma
                                     good                              type under Type 1 dilemmas, and dilemmas of the Boat and
nance. To see this, note that conswa2 = {¬c1 } (i.e., the good
thing about not throwing the switch is that the one person             Hijacked Airplane type under Type 2 dilemmas. We conjec-
will not die, and the good thing about not treating the woman          ture that the utilitarian choice does Pareto dominate the alter-
is that the woman will not die) but M, wa1 6|= ¬c1 (i.e., the          native option in case of Type 2 dilemmas whereas it does not
one person will die in case of throwing the switch, and the            in Type 1 dilemmas. Thus, for Type 1 dilemmas, ethical prin-
woman will die in case of treatment). Conversely, using ex-            ciples predict different sets of permissible actions, and hence
actly the same argument refraining from action does not dom-           there is a conflict to resolve which is not present for Type 2
inate acting. Thus, no matter how one decides someone will             dilemmas. We therefore hypothesize that Type 2 dilemmas
be harmed who will not be harmed under the alternative op-             are easier to solve for humans, and we present a study which
tion. Because no action is dominated by the other, both the            confirms our hypothesis.
actions are permissible according to Pareto permissibility.
   For the Boat dilemma and the Hijacked Airplane dilemma,                                       Hypotheses
performing action a1 is the only Pareto permissible choice.            The above theoretical analysis predicts that Type 2
The reason is that drowning the biggest person and shoot-              dilemmas—due to the absence of a moral conflict—are easier
ing the airplane dominate the respective alternatives. Note            to solve than Type 1 dilemmas. These considerations lead to
that wa1 dominates wa2 according to the definition of Pareto           two testable hypotheses:
                                            good
dominance: First, observe that conswa2 = 0/ (i.e., refrain-
                                                            good
                                                                       • Hypothesis 1: Type 1 dilemmas such as the Pregnancy and
ing from action yields no positive consequences), conswa2 =               the Runaway Trolley dilemma are rated as equally difficult.
{¬c2 , ¬c3 } (i.e., when refraining from action none of the pos-
itive consequences hold), and consbad  wa = {c2 } (i.e., the nega-     • Hypothesis 2: Type 2 dilemmas such as the Boat dilemma
                                          1
                                                                   2497

   and Hijacked Airplane dilemma are rated as significantly
   easier to solve than Type 1 dilemmas.
   Both hypotheses can be formally justified: The Type 1
dilemmas Pregnancy and Runaway Trolley are isomorphic,
i.e., each one can be mapped to the other conserving the
structure of the problem. Hypothesis 2 is justified for Type
2 dilemmas, as the utilitarian optimum dominates the possi-
bility of refraining from action. This does not hold for Type
1 dilemmas. These hypotheses are investigated in the next
section experimentally.
                         Experiment
We report the second part of an experiment that focuses on
rating the difficulty of moral dilemmas.                             Figure 1: Frequencies in the evaluation of the moral dilemma
                                                                     difficulty between two tasks (∗ ≤ .05, ∗ ∗ ∗ ≤ .001).
Methods
Participants Participants were recruited on the online plat-           Table 1: Mean values for the participants rating of the
form Amazon Mechanical Turk and received a monetary                    difficulty to find a decision in the selected scenario.
compensation for their participation. A total of 60 partici-
pants (f = 33) completed the study (Mage = 40.7, SDage =
8.86, minage = 21, maxage = 70). 33% of the participants re-                                             Meandifficulty
ported to have finished high school or college, 12% stated to
have an associate degree, 32% reported to have a bachelor de-            Decision Task        PW             RT             OB
gree while 23% stated to have a master or a higher academic
degree.                                                                  PW–RT            M = 72.37      M = 60.23
                                                                                          SD = 28.37     SD = 32.40
Procedure, Design and Materials After the introduction                                    M = 58.32                     M = 51.05
                                                                         PW–OB
to the setting participants received three problems. Each                                 SD = 32.48                    SD = 37.22
problem consisted of brief descriptions of two moral dilemas             RT–OB                           M = 50.07      M = 43.94
                                                                                                         SD = 32.99 SD = 32.91
(c.f., Bucciarelli, Khemlani, & Johnson-Laird, 2008), both
presented at the same time on the left or the right part of the         Note: PW: Pregnant Woman scenario; RT: Runaway Trolley
                                                                       scenario; OB: Overweight Boat scenario
screen. Participant had to decide which of these two moral
decision situations was more difficult to make, given that they
should aim for saving lifes. More precisely, the participants        Trolley can be found (exact binomial test, two-sided, n.s.,
had to decide between the Pregnancy and Runaway Trolley              n = 60). There is a significant difference in the evaluation
Dilemma, the Pregnancy and Boat Dilemma, and the Run-                of the moral dilemmas Pregnancy and Overweight Boat (ex-
away Trolley and Boat Dilemma. Hence, participants were              act binomial test, two-sided, p ≤ .05, n = 60) and a signifi-
making a binary decision that was encoded in a dichotomous           cant difference in the evaluation of the moral dilemmas Run-
variable. After selecting the more difficult scenario the par-       away Trolley and Overweight Boat (exact binomial test, two-
ticipants had to rate the perceived difficulty on a scale from 0     sided, p ≤ .001, n = 60). Once more, Fig. 1 illustrates the
(hardly more difficult) to 100 (extremely more difficult) using      differences of difficulty per decision task. The mean values
a slider. This value was encoded in a second variable.               of the participant’s rating of their personal difficulty to find
                                                                     a decision in the previously selected scenario are shown in
Results                                                              Table 1. Subsequent two-tailed t-tests showed no significant
The frequencies of selections for the moral dilemma decision         differences between the mean values MPW and MRT (decision
tasks can be found in Fig. 1. In the first problem the same          task PW–RT), MPW and MOB (decision task PW–OB), and
number of participants rated either the Pregnancy Dilemma            also not for MRT and MOB (decision task RT–OB) concerning
or the Trolley Problem to be the more difficult one. In the sec-     their rating of the subjective difficulty.
ond problem 38 participants decided the Pregnancy Dilemma
to be the more difficult decision scenario while 22 partici-         Discussion
pants chose the Boat Dilemma. In the third problem 44 par-           As our theory predicted moral dilemmas can systematically
ticipants opted for the Trolley Dilemma and 16 for the Boat          differ in their perceived difficulty: When asking about the
Dilemma. A two-tailed binomial test was used to compare              Pregnancy and Runaway Trolley dilemmas, as hypothesized,
the frequencies for the dichotomous variable.                        no significant difference in the relative difficulty rating could
   As predicted, no reliable difference in the evaluation of         be identified. We explain this by the dilemmas’ same com-
the difficulty of the moral dilemmas Pregnancy and Runaway           plexity of the formal structure requiring a similar cognitive
                                                                 2498

effort. However, the questions concerning the decision dif-            ethics? IEEE Intelligent Systems, 21(4), 12–17.
ficulties between the ethical scenarios Pregnancy and Over-          Bonnefon, J.-F., Shariff, A., & Rahwan, I. (2016). The so-
weight Boat or the Runaway Trolley and Overweight Boat                 cial dilemma of autonomous vehicles. Science, 352(6293),
resulted in reliable differences in the evaluation of the diffi-       1573–1576.
culty of the moral decision situation. In both cases the Boat        Bucciarelli, M., Khemlani, S., & Johnson-Laird, P. N. (2008).
Dilemma was selected reliably less often. These results sup-           The psychology of moral reasoning. Judgment and Deci-
port our theory of a different formal structure implying a dif-        sion, 3(2), 121.
ferent cognitive effort and therefore a lower complexity of the      Crockett, M. J. (2013). Models of morality. Trends in cogni-
Boat Dilemma.                                                          tive sciences, 17(8), 363–366.
   Once the participants have selected the moral dilemma they        Greene, J. D., & Haidt, J. (2002). How (and where) does
perceived to be more difficult (the dichotomous decision),             moral judgment work? Trends in cognitive sciences, 6(12),
their subsequent rating of the difficulty in the interval from         517–523.
0 to a 100 is statistically equal in comparison to the rating of     Greene, J. D., Nystrom, L. E., Engell, A. D., Darley, J. M., &
the participants who chose the other dilemma confirming the            Cohen, J. D. (2004). The neural bases of cognitive conflict
result. Overall, there is a tendency towards a lower decision          and control in moral judgment. Neuron, 44(2), 389–400.
difficulty in the Boat Dilemma.                                      Greene, J. D., Sommerville, R. B., Nystrom, L. E., Dar-
                                                                       ley, J. M., & Cohen, J. D. (2001). An fMRI investiga-
                    General Discussion                                 tion of emotional engagement in moral judgment. Science,
The formally predicted distinction between Type 1 and Type 2           293(5537), 2105–2108.
moral dilemmas have been empirically supported. Our results          Haidt, J. (2001). The emotional dog and its rational tail: a so-
support the theoretical assumption that less the dilemma’s             cial intuitionist approach to moral judgment. Psychological
content but the formal structure and the associated cogni-             Review, 108(4), 814–834.
tive effort is a predicting factor affecting people’s rating of      Halpern, J. Y. (2016). Actual causality. Cambridge, MA: The
a dilemmas’ difficulty. We recall that a main difference be-           MIT Press.
tween moral dilemmas of Type 1 and Type 2 are either based           Kohlberg, L. (1984). Essays on moral development: Vol. 2.
on action that the utilitarian choice does not or does Pareto          the psychology of moral development: Moral stages, their
dominate the alternative choices. This connects the presented          nature and validity. Harper & Row.
formalism with ethical principles and a decision theoretic in-       Lindner, F. (2015). Soziale Roboter und soziale Räume: Eine
terpretation. For Type 1 dilemmas, ethical principles predict          Affordanz-basierte Konzeption zum Rücksichtsvollen Han-
different sets of permissible actions, and hence there is a con-       deln. Doctoral dissertation, Department of Computer Sci-
flict to resolve which is not present for Type 2 dilemmas. The         ence, University of Hamburg, Hamburg.
absence of such a conflict appear at least on the problems’          Lindner, F., & Bentzen, M. M. (2017). The hybrid ethical
surface to be easier to solve due to the lower cognitive ef-           reasoning agent IMMANUEL. In B. Mutlu, M. Tsche-
fort they require. Further investigations ought to contain a           ligi, A. Weiss, & J. E. Young (Eds.), Proceedings of the
replication of the results with balanced materials and higher          2017 conference on human-robot interaction (HRI2017).
sample sizes. In addition applying qualitative research such           ACM/IEEE.
as interviews or thinking aloud techniques may give deeper           Malle, B. F., Scheutz, M., Arnold, T., Voiklis, J., & Cusi-
insight in the complex human decision-making process par-              mano, C. (2015). Sacrifice one for the good of many?: Peo-
ticularly in morally difficult decision situations. This would         ple apply different moral norms to human and robot agents.
offer additional insights about the motives, thoughts, and con-        In Proceedings of the tenth annual acm/ieee international
cepts people have when they have to solve tasks about moral            conference on human-robot interaction (pp. 117–124).
principles and can provide the reasons for their decisions. By       Mikhail, J. (2007). Universal moral grammar: theory, evi-
applying a qualitative content analysis of the different causal        dence and the future. Trends in cognitive sciences, 11(4),
structure of dilemmas may improve the detection and catego-            143–152.
rization of the objective, systematic, and formal features of        Moll, J., & de Oliveira-Souza, R. (2007). Moral judgments,
the dilemma’s content. These categories in turn can be val-            emotions and the utilitarian brain. Trends in cognitive sci-
idated by an assignment of dilemmas as a possible task in a            ences, 11(8), 319–321.
further experiment. Having a formal theory at hand allows            Shou, Y., & Song, F. (2015). Moral reasoning as probability
to systematically analyze the implications of the objectives,          reasoning. In D. C. Noelle & P. P. Maglio (Eds.), Proceed-
concepts, and features relevant for moral decision making.             ings of the 37th annual meeting of the cognitive science
Our formalism is able to distinguish between moral dilem-              society (pp. 2176–2181). Austin, TX.
mas and—at least for the reported cases—predict a perceived          Wiegmann, A., & Waldmann, M. R. (2014). Transfer effects
subjective difference between human raters.                            between moral dilemmas: A causal model theory. Cogni-
                                                                       tion, 131(1), 28–43.
                          References
Allen, C., Wallach, W., & Smit, I. (2006). Why machine
                                                                 2499

