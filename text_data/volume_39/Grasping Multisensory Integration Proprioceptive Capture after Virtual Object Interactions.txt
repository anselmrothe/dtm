  Grasping Multisensory Integration: Proprioceptive Capture after Virtual Object
                                                               Interactions
                                 Johannes Lohmann (johannes.lohmann@uni-tuebingen.de)
                                    Department of Computer Science, Cognitive Modeling, Sand 14
                                                          Tübingen, 72076 Germany
                                Jakob Gütschow (jakob.guetschow@student.uni-tuebingen.de)
                                    Department of Computer Science, Cognitive Modeling, Sand 14
                                                          Tübingen, 72076 Germany
                                          Martin V. Butz (martin.butz@uni-tuebingen.de)
                                    Department of Computer Science, Cognitive Modeling, Sand 14
                                                          Tübingen, 72076 Germany
                               Abstract                                  vious modal encodings (Thelen, Talsma, & Murray, 2015).
   According to most recent theories of multisensory integration,        Quak, London, and Talsma (2015) suggest that task require-
   weighting of different modalities depends on the reliability of       ments typically determine whether a unimodal or a complex,
   the involved sensory estimates. Top-down modulations have             multisensory representation is formed.
   been studied to a lesser degree. Furthermore, it is still debated
   whether working memory maintains multisensory information                Our aim in the present study was two-fold. First, we
   in a distributed modal fashion, or in terms of an integrated rep-     wanted to investigate whether multisensory integration is
   resentation. To investigate whether multisensory integration          modulated by task relevance. Second, we wanted to probe
   is modulated by task relevance and to probe the nature of the
   working memory encodings, we combined an object interac-              the nature of the stored representations. To investigate these
   tion task with a size estimation task in an immersive virtual         questions, we combined an object interaction task involving
   reality. During the object interaction, we induced multisen-          multisensory conflict with a size estimation task. We let par-
   sory conflict between seen and felt grip aperture. Both, visual
   and proprioceptive size estimation showed a clear modulation          ticipants perform a grasp-and-carry task in an immersive vir-
   by the experimental manipulation. Thus, the results suggest           tual reality, by tracking the hands of the participants. Conflict
   that multisensory integration is not only driven by reliability,      was introduced in terms of a visual offset, either expanding
   but is also biased by task demands. Furthermore, multisensory
   information seems to be represented by means of interactive           or shrinking the visual grip aperture, thereby dissociating vi-
   modal representations.                                                sion and proprioception. Moreover, we augmented the object
   Keywords: Multisensory Integration; Multisensory Conflict;            interaction with vibrotactile feedback, which signaled when
   Object Interaction; Virtual Reality                                   the relevant object was grasped. After the object interaction,
                                                                         we let participants judge the size of the object they interacted
                           Introduction                                  with either visually or based on the grip aperture. If vision
Adaptive interaction with the environment requires the com-              and proprioception are integrated, visual estimates should be
bination of various sensory signals. According to theories               biased in the same way as proprioceptive estimates. On the
of predictive coding, this integration is driven by a desire             other hand, if there was no bias in visual estimates, this would
for consistency between internal models and the external                 imply an independent storage of modal information.
world (Friston, 2010), as well as by a desire for consistency
across different internal models (Butz, Kutter, & Lorenz,                                            Method
2014; Ehrenfeld, Herbort, & Butz, 2013). Research on the
                                                                         Participants
mechanism of multisensory integration has shown that this
consistency is achieved in terms of a maximum likelihood in-             Twenty students from the University of Tübingen participated
tegration which combines different sensory signals based on              in the study (seven males). Their age ranged from 18 to 34
their respective reliability estimates, resulting in a Bayesian          years (M = 22.1, SD = 3.9). All participants were right-
estimate about the state of the external world (Ernst & Banks,           handed and had normal or corrected-to-normal vision. Partic-
2002; Ernst & Bülthoff, 2004). It is still debated, however,            ipants provided informed consent and received either course
whether this estimate is represented by means of an inte-                credit or a monetary compensation for their participation.
grated representation (Cowan, 2001) or by means of separate,             Three participants could not complete the experiment due to
modality specific representations which are integrated on de-            problems with the motion capture system, only the data of the
mand (Baddeley & Hitch, 1974). Experimental results show                 remaining 17 participants was considered in the data analysis.
strong interactions between modalities in the internal repre-
sentation, for instance between visual and auditory working              Apparatus
memory (Morey & Cowan, 2005). Furthermore, unimodal re-                  Participants were equipped with an Oculus Rift c DK2
trieval from a multisensory representation is affected by pre-           stereoscopic head-mounted display (Oculus VR LLC, Menlo
                                                                     2634

Park, California). Motion capture was realized by the com-                    60 cm from left to right and 55 cm in depth. Corresponding
bination of a Synertial IGS-150 upper-body suit and an IGS                    to the data generated by the IGS suit an upper body rig was
Glove for the right hand (Synertial UK Ltd., South Brighton,                  placed in the scene. It was positioned about 45 cm in front
United Kingdom). Rotational data from the suit’s and glove’s                  of the spawning position of the cube, slightly behind the the
inertial measurement units was streamed to the computer con-                  container. Hence, participants could reach both the container
trolling the experiment via a Wifi connection. The data was                   as well as the cube comfortably with their right arm. The rig
then used to animate a simplistic hand model in a virtual real-               itself was not rendered, only the right hand of the participants
ity. Since the IGS system only provides rotation data, we used                appeared in the scene visually.
a Leap Motion c near-infrared sensor (Leap Motion Inc, San                       The multisensory conflict between visual and propriocep-
Francisco, California, SDK version 2.3.1) to initially scale the              tive grip aperture was realized in terms of a visual angular
virtual hand model according to the size of the participants’                 offset on the root joints of the thumb and index finger. They
hands. To allow participants to confirm their size estimates                  could be rotated either 10◦ towards each other, or away from
without manual interactions, participants were equipped with                  each other. To maintain the same aperture, this visual offset
a headset. Speech recognition was implemented by means of                     had to be compensated by an adjustment of the actual aperture
the Microsoft Speech API 5.4. The whole experiment was                        in the opposite direction. To compensate for a visual offset
implemented with the Unity R engine 5.0.1 using the C# in-                    shrinking the grip aperture, the grip aperture had to be wider,
terface provided by the API. During the experiment, the scene                 while a visual offset extending the grip aperture required a
was rendered in parallel on the Oculus Rift and a computer                    closer grip aperture. In one third of the trials, no manipula-
screen, such that the experimenter could observe and assist                   tion was applied (the different offset conditions are shown in
the participants.                                                             Fig. 1, right panel).
   To provide the participants with vibrotactile feedback dur-
ing object interactions, we used two small, shaftless vibration               Procedure
motors attached to the tip of the thumb and the index finger                  Participants received a verbal instruction at the beginning of
of the participants. The diameter of the motors was 10 mm,                    the experiment regarding the use and function of the applied
the height was 3.4 mm. The motors were controlled via an                      VR equipment. Then, they were equipped with the inertial
Arduino Uno microcontroller (Arduino S.R.L., Scarmagno,                       motion capture system, consisting of the suit and the glove.
Italy) running custom C software. The microcontroller was                     If necessary, the finger sensors of the glove were fixated with
connected to the computer via a USB port which could be                       rubber bands. After aligning the sensors and enabling the data
accessed by the Unity R program. If a collision between the                   streaming, the vibration motors were fastened underneath the
virtual hand model and an object was registered in the VR, the                thumb and index finger tip with rubber bands. Participants
respective motor was enabled with an initial current of 2.0 V.                were then seated comfortably on an arm chair.
The deeper the hand moved into the object, the higher the ap-                    After this, participants were asked to hold their right hand
plied current (up to 3.0 V) and the according vibration. At                   over the Leap sensor to scale the virtual hand size according
a current of 3.0 V, the motors produced a vibration with 200                  to their actual hand size. The control was then switched to
rotations per second, the resulting vibration amplitude was                   the IGS system and participants put on the HMD to start the
0.75 g. The wiring diagram as well as additional information                  training phase. Participants could practice the grasping and
regarding the components are available online. 1                              carrying of the cube until they felt comfortable with the task.
                                                                              They had to complete at least 15 successful repetitions of the
Virtual Reality Setup                                                         task before they were allowed to proceed. The grasp and carry
The VR scenario put participants in a small clearing covered                  task is described in detail in the next section.
with a grasslike texture, surrounded by a ring of hills and                      After completing the training, the experimenter switched
various trees. A stylized container was placed in the center                  manually to the main experiment. The experiment consisted
of the scene and served as target for the transportation task                 of eight blocks, each composed of 15 trials. The multisensory
(see Fig. 1, left panel). The to-be-grasped and carried object                conflict between seen and felt grip aperture was introduced
was a cube rendered with a marble texture. The size of the                    during the intertrial interval while the screen was blacked
cube varied from trial to trial but the cube always appeared                  out.3 In each trial participants had to grasp a cube and put
at the same position in the scene. Textual information, like                  it into the target container. After the object interaction, the
trial instructions and error feedback were presented on differ-               scene faded out and one of two possible reproduction scenes
ent text-fields aligned at eyeheight in the background of the
scene.                                                                        movements.
                                                                                  3 While most participants remained unaware to the manipulation
   Centered at the participants’ hip2 , the task space covered                and attributed the variance in their grip aperture to inaccuracies of
    1 http://www.wsi.uni-tuebingen.de/lehrstuehle/cognitive-
                                                                              the tracking equipment, two participants reported to be aware of the
                                                                              manipulation after the experiment. Seeing that conscious awareness
modeling/staff/staff/johannes-lohmann.html                                    was not critical in this experiment, we did not perform a behavioral
    2 Based on the inertial data from the IGS suit, it is possible to         manipulation check in terms of a signal detection task to determine
calculate a kinematic chain with the hips as root. Hence, the position        whether participants were able to consciously detect the manipula-
of the hip joint in the virtual scene is the reference point for all body     tion of the visual grip aperture.
                                                                          2635

Figure 1: The left panel shows the VR scene and the initial position and fixation checks before the presentation of the target
cube. Participants had to maintain a stable fixation on the fixation cross, the green spheres represent the starting position. The
right panel shows the different offset conditions. Inward offsets are indicated by the light gray joints, dark gray joints indicate
the outward offset condition.
appeared. This was independent of the success in the object          the container. Success was indicated by the cube bursting into
interaction, the reproduction scene was also shown in case of        an explosion of smaller green cubes. Interactions were can-
error trials. In these scenes participants had to reproduce the      celed if the cube was penetrated overly strongly, dropped out-
size of the cube they interacted with either visually or by in-      side the container, moved outside the reachable space (e.g. by
dicating the size in terms of a grip aperture. After each block,     throwing it), or in case the interaction took more than 20 sec-
there was a break of at least ten seconds, after the fourth          onds. If one of the conditions was met, participants received
block, a longer break of at least two minutes was adminis-           error feedback and the trial progressed with the reproduction
tered. Participants were allowed to put off the HMD dur-             task.
ing the breaks. After the experiment, participants were asked           After completing or failing the interaction, the markers for
to complete a presence questionnaire (IPQ, Schubert, Fried-          the initial position reappeared and participants had to move
mann, & Regenbrecht, 2001). The whole procedure took 90              their hands back into the initial position. Then a visual mask
to 120 minutes, including the preparation and the practice tri-      was applied, accompanied by random vibrations on the finger
als.                                                                 tips. The visual and tactile masking commenced for one sec-
                                                                     ond. After the masking the scene faded to black and after one
Grasp and Transportation Task At the beginning of each               second, one of the two reproduction scenes appeared. The
trial, participants had to move their right hand into a desig-       offset manipulation was removed during the blank interval.
nated starting position, consisting of red, transparent spheres
                                                                     Size Estimation In both versions of the size estimation
indicating the required positions of the fingers and the palm.
                                                                     task, participants had to reproduce the cube size. For the vi-
The spheres turned green when the respective joints were in
                                                                     sual reproduction, the scene was similar to the one in which
position. Furthermore, participants had to maintain a stable
                                                                     the interaction took place. However, the ground textures were
looking direction on a fixation cross (see Fig. 1, left panel).
                                                                     replaced and different tree models were used to avoid possible
When both requirements were met, the fixation cross as well
                                                                     comparisons between the cube size and external landmarks.
as the visible markers of the initial position disappeared and
                                                                     A cube was placed at the center of the scene, at the same po-
the target cube appeared. Participants were instructed to grasp
                                                                     sition where the cube during the interaction phase appeared.
the cube with a pinch grasp and to move it into the target con-
                                                                     Above the cube, a slider was displayed, which allowed the
tainer. A successful pinch required the tips of the thumb and
                                                                     participants to scale the cube by dragging the slider button
the index finger to be placed on opposite sites of the cube and
                                                                     with their fingertips. The slider spanned approximately 20
to maintain a stable grip aperture. Participants received vibro-
                                                                     cm from left to right. The initial position of the slider button
tactile feedback whenever touching the cube. The feedback
                                                                     and thus the initial size of the visual reference cube was de-
scaled with the depth of penetration, becoming more intense
                                                                     termined by the cube size during the interaction phase. For
the deeper the fingers were moved into the cube. The task was
                                                                     the smaller three sizes the slider started out at 10% and for
successfully completed by placing or dropping the cube into
                                                                 2636

the two larger sizes it started out at 90% of the sliding range.
                                                                            Table 1: ANOVA table for the analysis of the size esti-
   For the proprioceptive reproduction, all visuals were deac-
                                                                            mates. The assumption of sphericity was violated for the
tivated (including the hand model), only the horizon as well
                                                                            cube size factor and the interaction between offset and re-
as small white sparks in the center of the scene remained ac-
                                                                            production condition, the according p-values were subjected
tive to remind the participants that the experiment was still
                                                                            to a Greenhouse-Geisser adjustment.
running. Participants were instructed to indicate the size of
the cube they interacted with by means of the grip aperture                   factor                                df     F           p       η2p
between thumb and index finger. To confirm their estimate,                    size                                  4   34.84      < .001∗     .69
participants were requested to say the German word for “con-                  offset                                2   17.55      < .001∗     .52
tinue” or “done” (“weiter” or “fertig”). The voice control                    repro. type                           1    0.48         .50      .03
identified these commands and ended the trial, recording ei-
ther the slider position - indicating the visual edge length of               size× repro. type                     4    2.94       .027∗      .16
the cube - or the grip aperture as the size estimate.                         offset × repro. type                  2    3.95       .045∗      .20
                                                                              size × offset                         8    1.03         .42      .06
Factors
                                                                              size × offset × repro. type           8    2.35       .022∗      .13
We varied three factors across trials. First, the edge length of
the cube, which had to be interacted with and which size had
to be estimated, was either 7 cm, 7.35 cm, 7.7 cm, 8.05 cm, or
                                                                            Team, 2016) and the ez package (Lawrence, 2015). All
8.4 cm. Second, the visual grip aperture was either shrunk, or
                                                                            post-hoc t-tests were adjusted for multiple comparisons by
extended by 10◦ , or corresponded with the felt grip aperture.
                                                                            the method proposed by Holm (Holm, 1979). Results from
In the following, we will refer to visual offsets shrinking the
                                                                            the presence questionnaire were compared with the reference
aperture as inward offsets, conversely, we will refer to offsets
                                                                            data from the online database.5 There were no significant dif-
extending the aperture as outward offsets. Third, we varied
                                                                            ferences.
the reproduction modality, which could either be visual or
proprioceptive. Hence, the experiment followed a 5 × 3 ×                    Size Estimates
2 within-subject design. Each of the 30 conditions was re-
peated four times, resulting in 120 trials. The trial order was             Data were analyzed with a 5 (cube size) × 3 (offset) × 2 (re-
randomized.                                                                 production type) factors repeated measures ANOVA. Results
                                                                            are shown in Tab. 1. The analysis yielded significant main
Dependent Measures                                                          effects for cube size and offset. The main effect for cube
Besides the size estimates in the two different reproduction                size matches the actual cube size: larger cubes were estimated
conditions, we obtained several time measures. Movement                     larger and smaller cubes were estimated smaller. To check if
onset was determined as the time between the end of the fix-                the estimates were veridical, we tested whether the estimated
ation until leaving the starting position. Contact time refers              cube sizes differed from the actual cube sizes. None of the
to the time between movement onset and successful grasp.                    respective comparisons yielded significant results.
Interaction time refers to the time interval between the grasp                 With respect to the main effect of offset, participants over-
and reaching the container.                                                 estimated the cube size in case of inward offsets, compared
                                                                            to conditions with no offset (t(16) = 3.45, p = .007). For out-
                              Results                                       ward offsets participants underestimated the cube size, com-
Data was aggregated according to the 5 × 3 × 2 within-                      pared to conditions with no offset (t(16) = 2.98, p = .009).
subject design. Seeing that the size estimation had to be per-              Finally participants provided larger estimates in case of in-
formed after error trials as well, there are no missing data                ward, compared to outward offsets (t(16) = 5.23, p < .001).
with respect to the size estimates. For the duration measures,                 Both, cube size and offset interacted with the reproduction
only correct trials were considered. The overall error rate was             condition. The interaction between cube size and reproduc-
high (nearly 30%), due to the task complexity. In case of                   tion type is due to a systematic overestimation of the larger
missing time data, the respective cell mean was interpolated                cubes in case of the visual reproduction. In both cases, the
within participants by the mean over all conditions with the                estimates are significantly larger than the actual sizes of 8.05
same offset type. For all dependent measures, values differ-                cm (t(16) = 4.26, p = .003), and 8.4 cm (t(16) = 3.21, p =
ing more than two times of the standard deviation from the                  .022), respectively.6
mean were excluded, which was the case for 2% of all data                      The interaction between reproduction condition and offset
points.4                                                                    was further analyzed with post-hoc t-tests. Estimates in case
   Size estimates, time measures, and error rates were an-                  of outward offsets were significantly smaller than in case of
alyzed with repeated measures ANOVAs using R (R Core                            5 Available at http://www.igroup.org/pq/ipq/index.php
    4 Please note that the data pattern remains nearly unaffected if            6 The  considerable overestimation might be partially due to the
the data is not filtered. Removing the size estimates from error trials     initial slider position in the visual reproduction, starting at 90% of
only reduces the effect size of the three-way interaction.                  the sliding range for larger cubes.
                                                                        2637

Figure 2: Three-way interaction between reproduction condition, cube size and offset. Significant differences with p < .05
between estimates in case of inward and outward offsets are indicated by an asterisk. The respective t-tests were one-sided
(inward > outward) and were adjusted for multiple comparisons. The dashed line indicates the actual cube size.
inward offsets, both, for visual (t(16) = -2.21, p = .021), as         set (F(2,32) = 76.57, p < .001, η2p = .83). Slowest contact
well as for proprioceptive (t(16) = -5.48, p = .002) reproduc-         times were observed for outward offsets, while inward offsets
tion. However, the differences between the offset conditions           yielded the fastest response times. All of the respective pair-
were much more pronounced in case of proprioceptive repro-             wise comparisons yielded significant results. The analysis of
duction, resulting in the observed two-way interaction.                the interaction times yielded a significant main effect for off-
   This pattern of results was modified by a three-way inter-          set as well (F(2,32) = 4.90, p < .014, η2p = .23). Participants
action between cube size, offset and reproduction condition.           were slower in transporting the cube in case of outward off-
Separate ANOVAs for the different cube sizes showed that               sets. Post-hoc t-tests showed that the interaction times were
the interaction between reproduction condition and offset was          significantly elevated in case of outward offsets, both com-
only present for cubes of intermediate (7.7 cm) and large size         pared to inward offsets (t(16) = 2.39, p = .042), as well as to
(8.05 cm). For these two conditions, there were no significant         trials without offset (t(16) = 2.42, p = .042).
differences between the offset conditions in case of visual re-
production. The differences for proprioceptive reproduction            Error Rates
remained significant. The main effect of offset, however, re-          The analysis of the error rates yielded significant main effects
mained significant for all of these separate analyses.                 for cube size (F(4,64) = 4.27, p = .004, η2p = .21) and offset
   With respect to our hypotheses, the difference between in-          (F(2,32) = 12.22, p < .001, η2p = .43). In general, partici-
ward and outward offsets is most relevant. To check whether            pants made fewer errors during interactions with larger cubes.
inward offsets always result in larger estimates than outward          Furthermore, error rates were higher in case of inward off-
offsets, we checked whether the respective difference is sig-          sets. Post-hoc t-tests showed that error rates increased for
nificant for the five different cube sizes, separately for the two     inward offsets, when compared to both outward offsets (t(16)
reproduction conditions. In case of proprioceptive reproduc-           = -3.67, p = .004), and no offsets (t(16) = -4.56, p < .001).
tion, the difference is significant for all cube sizes, except the
smallest one of 7 cm. For visual reproduction the differences                             General Discussion
reached significance for all cube sizes, except the intermedi-
ate (7.7 cm) and large size (8.05 cm). The results are shown           Previous studies on multisensory integration have shown a
in Fig. 2.                                                             dominance of visual information in the perception of object
                                                                       size (e.g. Ernst & Banks, 2002). To investigate whether task
Time Measures                                                          demands, which require to focus on another modality, can
Data were analyzed with a 5 (cube size) × 3 (offset) fac-              reduce this dominance, we let participants perform a grasp-
tors repeated measures ANOVA. No significant effects were              and-carry task under multisensory conflict between vision
found for the movement onset times. The analysis of ob-                and proprioception. In order to do so, we manipulated the
ject contact times yielded a significant main effect for off-          mapping between seen and felt grip aperture. After the ob-
                                                                   2638

ject interaction we let participants estimate the size of the ob-     visual or a proprioceptive estimate is influenced by the type of
ject they interacted with – either visually or by providing a         reproduction. The considerable difference between the effect
proprioceptive estimate via grip aperture. Our results show           sizes implies a different weighting of the modality-specific
a systematic bias in the size estimates due to the introduced         encodings in the two reproduction conditions.
offset between seen and felt grip aperture. A wider grip aper-
ture resulted in object size overestimations, while a smaller                                   References
aperture yielded underestimations. This was true for both, vi-        Baddeley, A. D., & Hitch, G. (1974). Working memory.
sual and proprioceptive size estimates. Hence, the adaptation            Psychology of learning and motivation, 8, 47–89.
of the size estimation followed the proprioceptive adaptation,        Butz, M. V., Kutter, E. F., & Lorenz, C. (2014). Rubber
which was necessary to compensate for the visual offset.                 hand illusion affects joint angle perception. PloS One, 9(3),
   While the offset manipulation led to different actual grip            e92854.
apertures for cubes of the same size, the visual impression of        Cowan, N. (2001). The magical number 4 in short-term mem-
both the cube size and the grasp of the virtual hand remained            ory: a reconsideration of mental storage capacity. Behav-
the same. Thus, if the size estimate was dominated by the vi-            ioral and brain sciences, 24(1), 87–114.
sual impression, there should have been no effect of the offset       Ehrenfeld, S., Herbort, O., & Butz, M. V. (2013). Modu-
condition in the visual reproduction trials. In contrast, our re-        lar neuron-based body estimation: maintaining consistency
sults show a clear influence of proprioceptive information on            over different limbs, modalities, and frames of reference.
the size estimates in both modalities. However, this influence           Frontiers in Computational Neuroscience, 7(Article UNSP
was much more pronounced in the case of the proprioceptive               148).
reproduction. Apparently, proprioceptive information domi-            Ernst, M. O., & Banks, M. S. (2002). Humans integrate vi-
nated the resulting percept, even if proprioception was much             sual and haptic information in a statistically optimal fash-
noisier than vision, indicated by the comparatively large vari-          ion. Nature, 415(6870), 429–433.
ance in the proprioceptive size estimates.                            Ernst, M. O., & Bülthoff, H. H. (2004). Merging the senses
                                                                         into a robust percept. Trends in Cognitive Sciences, 8(4),
   The combination of VR with motion capturing enabled us
                                                                         162–169.
to dissociate vision and proprioception in an interactive setup.
                                                                      Friston, K. (2010). The free-energy principle: a unified brain
Compared to previous studies, which investigated the effects
                                                                         theory? Nature Reviews Neuroscience, 11(2), 127–138.
of mismatching sensory information regarding an object, the
                                                                      Holm, S. (1979). A simple sequentially rejective multiple
applied setup allows to manipulate the own body perception
                                                                         test procedure. Scandinavian Journal of Statistics, 65–70.
without affecting the visual impression of the external, virtual
                                                                      Lawrence, M. A.              (2015).       ez:     Easy analy-
world. Some issues with respect to the experimental setup
                                                                         sis and visualization of factorial experiments
remain. The high error rates imply that even with the vibro-
                                                                         [Computer software manual].                 Retrieved from
tactile augmentation, the object interaction remained difficult
                                                                         https://CRAN.R-project.org/package=ez                     (R
for the participants. Especially in case of outward offsets,
                                                                         package version 4.3)
participants took quite long to grasp and carry the cube. The
                                                                      Morey, C. C., & Cowan, N. (2005). When do visual and ver-
error rates were elevated for inward offsets, which were as-
                                                                         bal memories conflict? the importance of working-memory
sociated with the fastest grasping and interaction times, im-
                                                                         load and retrieval. Journal of Experimental Psychology:
plying a speed accuracy trade-off. Furthermore, our setup did
                                                                         Learning, Memory, and Cognition, 31(4), 703.
not comprise a control condition without grasping. Includ-
                                                                      Quak, M., London, R. E., & Talsma, D. (2015). A multisen-
ing trials which only require touching the object will clarify
                                                                         sory perspective of working memory. Frontiers in human
whether the mere presence of a graspable object yields a bias
                                                                         neuroscience, 9.
towards proprioceptive information, or if performing the ac-
                                                                      R Core Team. (2016). R: A language and environment for
tual interaction is necessary to induce the bias.
                                                                         statistical computing [Computer software manual]. Vienna,
   Despite these issues, the results allow us to draw the fol-           Austria. Retrieved from https://www.R-project.org/
lowing two conclusions. First, visual and proprioceptive in-          Schubert, T., Friedmann, F., & Regenbrecht, H. (2001). The
formation regarding the object size seem to be stored sepa-              experience of presence: Factor analytic insights. Presence,
rately, but are able to affect each other. If there was only a           10(3), 266–281.
single percept reflecting the cube size across modalities, then       Thelen, A., Talsma, D., & Murray, M. M. (2015). Single-
the reproduced size should be independent of the reproduc-               trial multisensory memories affect later auditory and visual
tion modality. This is clearly not the case, given the huge              object discrimination. Cognition, 138, 148–160.
difference in the variance of the visual and proprioceptive es-
timates and the stronger bias in proprioceptive compared to
visual reproduction. This conclusion dovetails with results
reported by (Ernst & Banks, 2002), who showed that sensory
data are stored separately, when they originate from different
modalities. Second, the integration process that produces a
                                                                  2639

