                                   Eye movements during reference production:
           Testing the effects of perceptual grouping on referential overspecification
                                                   Ruud Koolen (r.m.f.koolen@uvt.nl)
                              Tilburg center for Cognition and Communication (TiCC), Tilburg University
                                                   PO Box 90153, 5000 LE, The Netherlands
                                                Yorick Fliervoet (yorick@fliervoet.com)
                              Tilburg center for Cognition and Communication (TiCC), Tilburg University
                                                   PO Box 90153, 5000 LE, The Netherlands
                               Abstract                                    answers to this question is to be found in visual scene percep-
   When referring to a target object in a visual scene, speakers are
                                                                           tion, and explore to what extent certain objects in a scene are
   assumed to consider certain distractor objects that are visible to      more likely to be perceived than others. For example, in Fig.
   be more relevant than others. However, previous research that           1, the plate on the sideboard might be overlooked because it
   has tested this assumption has mainly applied offline measures          is placed on a different surface than the target (i.e., sideboard
   of visual attention, such as the occurrence of overspecification        rather than table), or because it has a different type (i.e., plate
   in speakers’ target descriptions. Therefore, in the current study,      rather than bowl). In these cases, the distractor set would be
   we take both online (eye-tracking) and offline (overspecifica-          limited to the large bowl, making a minimal description such
   tion) measures of attention, to study how perceptual grouping
   affects scene perception, and reference production. We manip-           as “the small bowl” likely to be uttered. On the other hand, if
   ulated three grouping principles: region of space, type similar-        the plate on the sideboard catches attention anyway, for ex-
   ity, and color similarity. For all three factors, we found effects,     ample because it has a different color than the target object,
   either on eye movements (region of space), overspecification            the perceived color variation may cause speakers to overspec-
   (color similarity), or both (type similarity). The results for type     ify with color (Koolen et al., 2013).
   similarity provide direct evidence for the close link between             Although there is growing awareness that scene perception
   scene perception and reference production.
                                                                           and language production are indeed closely linked, previous
   Keywords: Reference production; Perceptual grouping; Eye-               research in this direction has generally taken indirect, offline
   movements; Overspecification; Visual scene perception.                  measures of visual attention. Therefore, in the current paper,
                                                                           we combine online (eye-tracking) and offline (occurrence of
                           Introduction                                    overspecification) measures to search for structural relations
Suppose you want to point out the marked object in Fig. 1 to               between scene perception and attribute selection for referring
a listener. To complete this task, you should produce a refer-             expressions.
ring expression such as “the small bowl” or “the small green
bowl”, to distinguish the target object from the other objects             Theoretical background
that are present in the visual scene (the distractors). Although           The starting point of our research is the assumption that in a
both above example expressions allow the listener to identify              reference production task, speakers do not regard all objects
the target, the second one is overspecified: it contains a color           in a visual scene to be relevant distractors, but rather rely on
attribute that is unnecessary for unique identification.                   a subset of distractor objects. More specifically, speakers are
                                                                           expected to only consider the distractors that are in their focus
                                                                           of attention (Beun & Cremers, 1998). One can think of vari-
                                                                           ous factors that determine whether an object is perceived or
                                                                           not, such as its physical distance to the target (i.e., proximity).
                                                                           Given that proximity predicts that only objects that are close
                                                                           to the target referent are in the speaker’s focus of attention, it
                                                                           can influence the composition of the distractor set for a visual
                                                                           scene (Clarke, Elsner, & Rohde, 2013a).
                                                                             Proximity is one of the Gestalt laws of perceptual grouping
                                                                           that were originally introduced by Wertheimer (1923), next
                                                                           to similarity, closure, continuation, and pragnanz. These laws
   Figure 1: An example visual scene (Koolen et al., 2014)                 are principles of perceptual organization that serve as heuris-
                                                                           tics: mental shortcuts for how we perceive the visual environ-
  From prior research (e.g., Pechmann, 1989; Koolen, Goud-                 ment (Wagemans et al., 2012) and create meaningful groups
beek, & Krahmer, 2013; Rubio-Fernàndez, 2016), it is known                 of objects that we see around us (Thórisson, 1996). On top of
that speakers overspecify their referring expressions very fre-            the classical laws of grouping, Palmer (1992) defined another
quently. Why do they do so? We argue that at least one of the              principle, common region of space, which holds that objects
                                                                       2439

that fall within an enclosing contour, such as a table surface,       well as their eye movements during the reference production
are usually perceived as a group as well.                             task. Speech data were annotated for the occurrence of over-
   This study will apply a manipulation of common region of           specification; i.e., if descriptions contained a redundant color
space, as well as two manipulations of similarity: color simi-        attribute. This variable served as a replication of Koolen et al.
larity and type similarity. Previous research that directly tests     (2014). New in our study are the eye-tracking data. Here, we
how these principles influence reference production is scarce.        analyzed the number of fixations on the distractor we manip-
For color similarity, we know that speakers overspecify more          ulated, and the total gaze duration for that object.
often when they perceive color variation in a scene than when            For region of space, we hypothesize that if a distractor is in
all objects are of the same color (Koolen et al., 2013; Rubio-        the same region of space as the target, it is viewed more often
Fernàndez, 2016). This effect of color variation interacts with       and longer than if the region of space is different, and that this
type similarity: the proportion of overspecification is highest       will eventually lead to more overspecification. The same goes
when there is at least one distractor object that shares its type     for type similarity, with more views, longer viewing time and
with the target, but not its color (Koolen, Krahmer, & Swerts,        more overspecification for a distractor of the same rather than
2016). Also common region of space has been found to affect           a different type than the target. Lastly, for color similarity, we
referential overspecification, as revealed by Koolen, Houben,         expect to find that a distractor most likely attracts attention if
Huntjens, and Krahmer (2014). In their experiment, Koolen             it has a different color than the target, resulting in more views,
et al. used scenes such as the one depicted in Fig. 1, displayed      longer viewing times, and again more overspecification than
in both 2D and 3D. The target was always on the table, and –          for a distractor that shares its color with the target.
mainly for the 3D scenes – speakers overspecified more often
when a differently colored distractor was also on the table (in                                    Method
the same group as the target) rather than on the sideboard (in
a different group), although the physical distance between the        Participants
objects was the same in both scenarios.                               Thirty-one participants (26 female, mean age: 21.6) took part
   Crucially, the above papers, as well as many others studies        in the experiment. The participants were gathered randomly
on reference production (e.g., Clarke et al., 2013a), have used       at the campus of Tilburg University, and received a piece of
indirect measures of visual attention, such as the occurrence         candy as a reward. All participants were native speakers of
of overspecification. This is problematic in studying how the         Dutch, the language of the experiment.
distractors in a visual scene shape attribute selection. For ex-
ample, although the experiment by Koolen et al. (2014) sug-           Materials
gests that region of space affects overspecification, there is
                                                                      The stimulus material consisted of near-photorealistic visual
no direct evidence that this result is due to the way in which
                                                                      scenes like the example scenes presented in Fig. 2 on the next
speakers might ignore distractors that are not in the same re-
                                                                      page. As noted above, the scenes were taken from the related
gion as the target referent. Therefore, in the current research,
                                                                      previous study by Koolen et al. (2014). They depicted a living
we collect eye movements as a direct, online measure of vis-
                                                                      room containing a dinner table and a sideboard, and some ob-
ual attention, and combine these data with a more traditional,
                                                                      jects such as chairs for a more realistic look. The scenes were
offline analysis of referential overspecification.
                                                                      modeled and rendered using Maxon’s Cinema 4D.
   While eye-tracking methodologies are very commonly used
                                                                         The table and the sideboard formed the two surfaces (i.e.,
to investigate language comprehension (e.g., Tanenhaus, Spi-
                                                                      regions of space) that were important for our manipulations,
vey, Eberhard, & Sedivy, 1995), they are still rare in language
                                                                      since these were the spaces where the target and its two dis-
production research, initially because speech movements can
                                                                      tractors were positioned. The target object always occurred
disrupt eye movement data (Pechmann, 1989; Griffin & Da-
                                                                      on the table, in the middle of the scene, together with a dis-
vison, 2011). After some early studies that explored the effect
                                                                      tractor close next to it (either left or right). This first distractor
of object fixations on order of mention (e.g., Griffin & Bock,
                                                                      object always had the same type and color as the target object,
2000; Meyer, Sleiderink, & Levelt, 1998), some researchers
                                                                      but a different size. This way, the distractor ensured that size
recently started to apply eye-tracking to test the effects of per-
                                                                      was always needed for a distinguishing description, and that
ceptual and conceptual scene properties on rather open-ended
                                                                      mentioning color thus resulted in an overspecified referring
descriptions (Coco & Keller, 2012; 2015) and object naming
                                                                      expression. The scenes also had a second distractor object, by
(Clarke, Coco & Keller, 2013b). However, none of this work
                                                                      means of which our three manipulations of perceptual group-
has tested systematically how perceptual grouping affects at-
                                                                      ing were realized.
tribute selection for reference production.
                                                                         Firstly, there was a manipulation of perceptual grouping in
Current study                                                         the law of common region of space. This manipulation was
                                                                      operationalized by positioning the second distractor either in
To study how different manipulations of perceptual grouping           the same region of space as the target (i.e., on the table, see
affect reference production, we conducted an experiment in            the left scenes of Fig. 2), or in a different region (i.e., on the
which speakers described target objects in visual scenes. The         sideboard, see the right pictures of Fig. 2). It is important to
stimuli were taken from Koolen et al. (2014), for the sake of         note that the physical distance between the target object and
comparability. We recorded both the participants’ speech as           the second distractor was the same in both scenarios.
                                                                  2440

    Fig. 2: Examples of critical trials in our experiment. The distractor shares its region of space with the target (i.e., the table)
  in the left scenes, and is in a different region (i.e., the sideboard) in the right scenes. The distractor has the same type as the
 target in the upper four pictures, and a different type in the lower four pictures. The distractor has the same color as the target
         in the first, second, fifth and sixth picture, and a different color in the third, fourth, seventh, and eighth picture.
   Secondly, we had two manipulations of perceptual group-              Fig. 2, where the second distractor object (the plate) has a
ing related to the law of similarity. The first one varied the          different type than the target object (the bowl) in the lower
type of the distractor: this type could be the same as the tar-         four trials, while all relevant objects are of the same type in
get’s type, or different. Example scenes can again be found in          the upper four trials. Another manipulation of similarity was
                                                                   2441

employed by varying the color of the second distractor: this             questions. Once the procedure was clear, the experimenter
color could again be the same as or different than the color of          left the booth, and the experiment started.
the target object (see again Fig. 2 for example scenes).                    All participants were shown a total of 64 stimuli (32 critical
  While Fig. 2 depicts all visual scenes that were created for           trails and 32 fillers) in a random order. The visual scenes were
the bowl, the same was done for three other types of targets:            depicted in the middle of the screen, filling 70% of the avail-
a plate, a mug and a cutting board. The scenes for these four            able space; the remaining 30% consisted of a grey border sur-
object types were manipulated in all conditions, resulting in            rounding the scenes. Before every trial, a screen with an ‘X’
eight trials for each object type. Participants were thus pre-           appeared somewhere in the 30% contour area. When this X
sented with thirty-two (four x eight) critical trails. In all trials,    had been fixated for one second, the next visual scene ap-
the target object could only be distinguished by mentioning              peared automatically. When fixating the X did not work, par-
type and size; if participants included color, it made the de-           ticipants could make the next scene appear manually by
scription overspecified.                                                 pressing spacebar. The position of the X was different for all
  Two measures were taken to avoid participants from using               trials: they appeared in a random position in the grey border,
the same strategy for all critical trials. Firstly, we had thirty-       again to make sure that participants did not develop a viewing
two filler trials. Although the scenes for these fillers had the         strategy. There were 1.6 times more X triggers on the top and
same basic set-up as the critical trails, with all kinds of objects      bottom row than on the left and right side, in proportion to
placed on the table and the sideboard, there were more objects           the 1680x1050 screen resolution. Once all 64 trials had been
present, which could all be the target for that scene. Further-          completed, participants were instructed to leave the booth. It
more, since all objects in the filler trials were white, partici-        took around 30 minutes to complete the experiment.
pants were discouraged to use color when referring to the tar-
get here.                                                                Research design
  Secondly, to prevent participants from developing a view-              The experiment had a 2x2x2 design with three within-partic-
ing strategy, we created two versions of the experiment. For             ipants factors: region of space (same, different), type (same,
both versions, half of the visual scenes for the critical trials         different), and color (same, different). Three dependent vari-
were mirrored. In version 1, this was done for the scenes in             ables were measured: the occurrence of color in the target de-
which the second distractor was in the same region of space              scriptions; the gaze duration upon the manipulated distractor
as the target object, while in version 2, all the scenes in the          in milliseconds per trial per participant; and the number of
different region of space condition were mirrored. Thus, by              times that the manipulated distractor was fixated per trial per
taking this measure, all participants saw half of the critical           participant.
trails mirrored.
                                                                         Data coding and preparation for analysis
Procedure
                                                                         All recorded object descriptions were transcribed and coded
The experiment took place in a soundproof booth, located in              for the presence of color (0 or 1). For the eye-tracking data,
the SensoMotoric Instruments lab at Tilburg University. The              we first checked for ill measurements, and excluded the data
eye-tracking measurements were made with a SMI RED250                    recorded for one participant from further analysis. We then
device, operated by the IviewX and the ExperimentCenter                  assigned all fixations to either one out of four areas of interest
software-packages. The eye-tracker had a sampling rate of                (AOIs) we defined. There was one AOI for the target, one for
250HZ. We used the microphone of a webcam to record the                  the sideboard, one for the central part of the table, and one
descriptions of the participants; the camera was taped off for           remainder area. The AOIs for the sideboard and the central
privacy reasons. The stimulus materials were displayed on a              part of the table represented the areas where the manipulated
22 inch P2210 Dell monitor, with the resolution set to 1680x             distractor could be placed. The remainder area was used for
1050 pixels, with 90.05 pixels per square inch.                          fixations that were not on the target or distractor objects that
  After entering the laboratory, participants signed a consent           were present in the scenes. The AOIs where the manipulated
form, and read a first basic instruction stating that they were          distractor could occur were central to our analyses.
going to act as the speaker in a language production experi-                The coding process resulted in a separate path file for every
ment. Participants were then seated in the soundproof booth,             participant. These path files were converted into a single file,
in front of the eye tracker, and their eyes were calibrated us-          and loaded into SPSS for statistical analysis. Although there
ing a 9-point validation method. When the calibration was                was supposed to be data for 960 target descriptions (30 speak-
completed successfully, participants were invited to read a              ers times 32 trials), the data for 24 trials could not be analyzed
second instruction, which was more detailed than the first               because either the description or the eye movements were not
one, and stated that participants were going to produce oral             recorded correctly. The final analysis thus contained data for
descriptions of target objects in visual scenes in such a way            936 trials.
that these objects could be distinguished from the remaining                While the data for all 936 trials was used to analyze the re-
objects in the scene. It was emphasized that using location              dundant use of color, we created subsets of the data to analyze
information in the descriptions (e.g., “the bowl on the left”)           gaze duration and the number of fixations. For both variables,
was not allowed. After this second instruction, participants             we only analyzed the cases where speakers fixated – and thus
completed two practice trials, and had the possibility to ask            saw – the manipulated distractor. This was the case in 680 out
                                                                     2442

of 936 cases. For gaze duration, we then calculated for every          (M = 1242.9, SE = 66.2) were looked at longer than distrac-
trial the total amount of time that the participant looked at the      tors for which this was not the case (M = 1036.5, SE = 63.5).
manipulated distractor object, and standardized this score by          The third factor, color similarity, did not affect gaze duration:
calculating the z-score per trial per speaker. Only the scores         although the distractor was looked at slightly longer when it
in the range of -3 ≤ z ≤ 3 were included in the analysis, which        had the same (M = 1176.6, SE = 61.6) rather than a different
means that scores for 13 cases were filtered out.                      (M = 1102.8, SE = 67.9) color than the target, this difference
   For the number of fixations, we created a similar subset of         was not significant (F(1,651) = .65, n.s.).
the data, but this time we calculated the number of times that
speakers looked at the manipulated distractor for every trial.         Results for number of fixations
Again, the z-score was calculated, which led to the exclusion          The third dependent variable in our experiment was the num-
of 12 trials that were not part of the final analysis for this var-    ber of fixations on the manipulated distractor. Again, there
iable.                                                                 were effects of region of space and type similarity, but not of
                                                                       color similarity.
                              Results                                    Firstly, when the distractor was in the same region of space
To test for significance, we performed a series of univariate          as the target object, participants looked at this object signifi-
ANOVA tests. We only report on interactions when they are              cantly more often (M = 2.04, SD = .06) than when it occurred
significant. Given that we used subsets of the data in our sta-        in a different region of space (M = 1.56, SD = .06); F(1,652) =
tistical analyses, performing repeated measures tests was not          33.37, p < .001, ŋp2= .049. Similarly, when the distractor was
possible due to empty cells.                                           of the same type as the target object, it was fixated more often
                                                                       (M = 1.93, SD = .06) than when it had a different type (M =
Results for redundant color use                                        1.67, SD = .06). Again, we found no effect of color similarity:
In general, our speakers included a redundant color attribute          the distractor’s color (same: M = 1.85, SE = .06; different: M
in 64% of the descriptions. The first ANOVA was performed              = 1.76, SE = .06) did not influence the number of fixations
to test if redundant color use was affected by our manipula-           (F(1,652) = 1.15, n.s.).
tions of perceptual grouping.
   The first factor that we expected to affect the redundant use                                 Discussion
of color was region of space. However, we did not find a sig-          The goal of this research was to test how perceptual grouping
nificant effect here (F(1,927) = .11, n.s.): speakers redundantly      affects reference production. We combined both online (eye-
used color equally often when the manipulated distractor was           tracking) and offline (occurrence of referential overspecifica-
in the same (M = .64, SE = .02) or a different (M = .64, SE =          tion) measures of visual attention to study the extent to which
.02) region of space as compared to the target.                        grouping causes speakers to ignore certain distractors that are
   For our two manipulations of similarity, we did find effects        present in a visual scene, aiming to connect the observed scan
on the redundant use of color. In these cases, the main effects        patterns referential overspecification. We had three manipu-
of type similarity (F(1,927) = 9.94, p < .01, ŋp2 = .011) and color    lations of grouping (i.e., common region of space, color sim-
similarity (F(1,927) = 5.44, p < .05, ŋp2 = .006) were due to an       ilarity, and type similarity), all realized by varying the loca-
increase in redundant color use when the manipulated distrac-          tion and characteristics of one specific distractor object in the
tor had the same type as the target, and a different color (M =        visual scenes that were presented to the participants.
.77, SE = .03). The other three cells were practically indistin-         The first manipulation that was present in our stimuli made
guishable (same type - same color: M = .61, SE = .03; diffe-           the manipulated distractor object appear either in the same or
rent type - same color: M = .60, SE = .03; different type -            a different region of space as compared to the target referent.
different color: M = .59, SE = .03). This pattern resulted in a        In Koolen et al. (2014), this manipulation led to a significant
significant interaction between type similarity and color sim-         effect of grouping on overspecification, with more redundant
ilarity (F(1,927) = 7.47, p < .01, ŋp2 = .008).                        color attributes in the ‘same group’ condition rather than the
                                                                       ‘different group’ condition. In the current study, we could not
Results for gaze duration                                              replicate this result: the proportions of overspecification that
                                                                       we found were the same in both conditions. However, we did
The second ANOVA was run to analyze if our manipulations
                                                                       find effects of region of space in the eye-tracking data: when
of grouping on the total amount of time that speakers looked
                                                                       the distractor was in the same region as the target referent, it
at the manipulated distractor.
                                                                       was viewed longer and more often than when it was in a dif-
   Firstly, there was a main effect of region of space on gaze
                                                                       ferent region. This way, region of space (Palmer, 1992) influ-
duration (F(1,651) = 215.5, p < .001, ŋp2= .249), showing that
                                                                       ences the extent to which certain distractors are considered in
the distractor object was looked at significantly longer when          a reference production task.
it occurred in the same (M = 1812.7, SD = 60.87) rather than             The question remains why the patterns for common region
a different (M = 466.7, SE = 68.6) region of space than the            of space that we observed in the eye-tracking data were not
target. A similar effect was found for the manipulation of type        reflected in effects on overspecification with color, such as
similarity (F(1,651) = 5.06, p < .05, ŋp2= .008). For this factor,     found by Koolen et al. (2014). To explain this issue, we refer
we found that distractors that shared their type with the target       to some practical differences between the two studies. Firstly,
                                                                   2443

Koolen et al. (2014) displayed the stimuli on a big television        Clarke, A., Elsner, M., & Rohde, H. (2013a). Where’s Wally:
screen, while the current experiment used only 70% of a com-            the influence of visual salience on referring expression
puter screen. Perhaps more important was that Koolen et al.             generation. Frontiers in Psychology, 4, article 329.
found a convincing effect of common region of space for 3D            Clarke, A., Coco, M. & Keller, F. (2013b). The impact of at-
visual scenes, but that the effect was small for 2D scenes. In          tentional, linguistic, and visual features during object nam-
the current study, only 2D scenes were used, due to the eye-            ing. Frontiers in Psychology, 4: article 927.
tracking paradigm. Given that our 2D scenes led to clear ef-          Coco, M. & Keller, F. (2012). Scan patterns predict sentence
fects of region of space in the eye-tracking data, it would be          production in the cross-modal processing of visual scenes.
interesting to test how this grouping principle affects lan-            Cognitive Science, 36 (7), 1207-1223.
guage on variables other than overspecification, such as flu-         Coco, M. & Keller, F. (2015). Integrating mechanisms of vis-
ency and speech onset time.                                             ual guidance in naturalistic language production. Cognitive
   For type similarity, the effect of the manipulation in the ref-      Processing 16 (2), 131-150.
erence production data resonates the pattern in the eye-track-        Griffin, Z. & Bock, K. (2000). What the eyes say about speak-
ing data. When the distractor had the same type as the target,          ing. Psychological Science, 11, 274- 279.
it was viewed longer and more often than when the type was            Griffin, Z. & Davison, J. (2011). A technical introduction to
different, and the proportion of overspecified references was           using speakers’ eye movements to study language. The
higher. These results show direct evidence for the close link           Mental Lexicon, 6 (1), 53-82.
between visual scene perception and language production, in           Koolen, R., Goudbeek, M., & Krahmer, E. (2013). The effect
line with the few previous studies in this direction (e.g., Coco        of scene variation on the redundant use of color. Cognitive
& Keller, 2012; 2015; Griffin & Bock, 2000). For color sim-             Science, 37 (2), 395-411.
ilarity, we found a significant interaction with type similarity      Koolen, R., Houben, E., Huntjens, J., & Krahmer, E. (2014).
for the speech data, with an increase in overspecification with         How perceived distractor distance influences reference
color when the distractor had the same type as the target, and          production: Effects of perceptual grouping in 2D and 3D
a different color. This interaction is a replication of Koolen et       scenes. In Proceedings of the 36th annual meeting of the
al. 2016). For the eye-tracking data, there were no significant         Cognitive Science Society (CogSci). Québec, Canada.
effects or interactions with color similarity involved, presum-       Koolen, R., Krahmer, E., & Swerts, M. (2016). How distrac-
ably since color differences “pop out” of the scene (Treisman           tor objects trigger referential overspecification: testing the
& Gelade, 1980). As such, there is no strict need for speakers          effects of visual clutter and distance. Cognitive Science, 40
to fixate distractors (repeatedly) in order to perceive their dif-      (7), 1607-1647.
ferent color.                                                         Meyer, A., Sleiderink, A. & Levelt, W. (1998). Viewing and
   Finally, we would like to discuss our decision to use subsets        naming objects: eye movements during noun phrase pro-
of the data for the eye-tracking analyses. In these subsets, we         duction. Cognition, 66, B26-B33.
only included data for the trials where the speaker fixated the       Palmer, S. (1992). Common region: a new principle of per-
manipulated distractor object (or at least the AOI where it was         ceptual grouping. Cognitive Psychology, 24 (3), 436-447.
occurred) at least once. Thanks to this approach, we could be         Pechmann, T. (1989). Incremental speech production and ref-
certain that speakers were most likely aware of the existence           erential overspecification. Linguistics, 27, 89-110.
of this object, which makes the observed effects of perceptual        Rubio-Fernández, P. (2016). How redundant are redundant
grouping even more valid: it excludes, for example, measure-            color adjectives? An efficiency-based analysis of color
ment errors that occur when speakers change their position in           overspecification. Frontiers in Psychology, 7: 153.
front of the eye-tracker. However, one can also argue that our        Wagemans, J., Elder, J., Kubovy, M., Palmer, S., Peterson,
approach was too strict, because in order to form a description         M., Singh, M., & Von der Heydt, R. (2012). A century of
of a target object, it is not necessary to scan all objects in the      Gestalt psychology in visual perception: I. Perceptual grou-
scene. In future analyses, we aim to refine our paradigm, also          ping and Figure–ground organization. Psychological Bul-
by distinguishing various time windows for every trial to test          letin, 138 (6), 1172.
both the structural and temporal relations between scene per-         Tanenhaus, M., Spivey, M., Eberhard, K. & Sedivy (1995).
ception and reference production.                                       Integration of visual and linguistic information in spoken
                                                                        language comprehension. Science, 268, 1632-1634.
                     Acknowledgments                                  Thórisson, K. (1994). Simulated perceptual grouping: an ap-
We thank Jan Huntjens and Eugène Houben (www.eyetrac-                   plication to human-computer interaction. Proceedings of
tive.com) for developing the stimulus materials, and Rein Co-           the 16th annual conference of the Cognitive Science Society
zijn for his assistance in programming the experiment and an-           (CogSci), 876-881. Atlanta, Georgia, USA.
alyzing the data.                                                     Treisman, A. & Gelade, G. (1980). A feature integration the-
                                                                        ory of attention. Cognitive Psychology, 12, 97-136.
                           References                                 Wertheimer, M. (1923). Untersuchungen zur Lehre von der
                                                                        Gestalt. Psychologische Forschung, 4, 301-350.
Beun, R.J., & Cremers, A. (1998). Object reference in a
   shared domain of conversations. Pragmatics & Cognition,
   6 (1/2), 121-152.
                                                                  2444

