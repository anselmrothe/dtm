       Decoding Partner Type in Human-Agent Negotiation using functional MRI
                         Eunkyung Kim (eunkyung@usc.edu)1 , Jared Gilbert (jaredgil@usc.edu)1 ,
                  Charlotte Horowitz (shchar@umich.edu)2 , Jonathan Gratch (gratch@ict.usc.edu)3 ,
                 Jonas T. Kaplan (jtkaplan@usc.edu)1 and Morteza Dehghani (mdehghan@usc.edu)1
                      1 Brain and Creativity Institute, University of Southern California, Los Angeles, CA 90089
                               2 Department of Psychology, University of Michigan, Ann Arbor, MI 48109
                   3 Institute for Creative Technologies, University of Southern California, Playa Vista, CA 90094
                               Abstract                                 with Theory of Mind (ToM), due to their importance in so-
                                                                        cial interactions. ToM refers to the ability of one person to
   People interact differently with humans than they do with com-
   puters, but there is minimal research on what brings about           reason about another person’s mental states, including their
   these differences. Using agents labeled as either “another par-      intentions and beliefs (Premack & Woodruff, 1978). Previ-
   ticipant” or a “computer program”, we investigated the differ-       ous fMRI studies have demonstrated that cortical activity in
   ences in people’s behavior and brain activity during the course
   of a negotiation paradigm. Our results indicate that people per-     the neural structures related to ToM tend to be more active
   ceive human-labeled agents more human-like than computer-            when participants were told they were facing a human partner
   labeled agents, and the level of concession in the negotiations      compared to a computer program (Kircher et al., 2009). Re-
   is dependent on agent type. We have also found that these dif-
   ferences can be captured in brain activation by showing that         search also demonstrated that activity in these same regions
   parts of the Theory of Mind neural correlates are activated in       scaled according to the human-likeness of their interaction
   human-labeled agent conditions, but not in computer-labeled          partner when using computer-animated characters or nonhu-
   agent conditions. We further demonstrate that brain activity
   can predict whether the negotiation agent was introduced as          man agents (Chaminade, Hodgins, & Kawato, 2007; Krach et
   a competing human player or a computer program. Overall,             al., 2008).
   our study suggests that labeling an interaction partner as ei-
   ther another human or a computer program leads to significant           Many previous behavioral and neuroimaging studies have
   impacts on one’s decision making.                                    used negotiation platforms to examine human-agent commu-
   Keywords: Human-Agent Interaction; Negotiations; fMRI                nication, because negotiations involve complex cognitive ef-
                                                                        fort and established social interaction techniques. For exam-
                           Introduction                                 ple, studies show that when participants play the Ultimatum
                                                                        Game against computer partners, they are more likely to ac-
Can computer agents act as substitutes for human beings dur-
                                                                        cept unfair offers compared to when they play against hu-
ing the course of an interaction? This has been a popular topic
                                                                        man partners, where they tend to be less willing to accept
in sci-fi movies for decades. In fact, some computer agents
                                                                        offers of unequal value (Sanfey, Rilling, Aronson, Nystrom,
that were thought to exist only in movies a few decades ago,
                                                                        & Cohen, 2003). Studies have also shown that people have
are now widely used in daily life. Smartphones, for exam-
                                                                        stronger emotional reactions to unfair offers made by other
ple, are commonly used to execute voice commands through
                                                                        humans (Vant Wout, Kahn, Sanfey, & Aleman, 2006).
programs like Siri, and movie theaters now have more ticket
vending machines than guest personnel.                                     Using a multi-round, multi-object negotiation platform for
   However, human-agent interactions are often quite differ-            our research, we explored whether a computer agent intro-
ent from human-human interactions (Gray, Gray, & Wegner,                duced as another human was perceived more anthropomor-
2007; Melo, Marsella, & Gratch, 2016), and many factors                 phically than one that was introduced as a computer program.
contribute to these differences. Researchers have continu-              We then investigated whether agent type produced behavioral
ously tried to identify what these disparities are and why              differences, and whether one type of agent resulted in more
they occur, with the hopes to bridge the gap between human-             concessions compared to the other. In a follow up experiment,
human and human-robot/agent encounters.                                 we compared brain activity during interactions with human-
   A robot’s appearance has been found to be paramount                  labeled and computer-labeled agents to determine whether
in the interaction style of the human subjects. For ex-                 these perceptual differences were also observable in brain
ample, when people interface with robots that have me-                  patterns. Following collection of fMRI data, we investigated
chanical, nonhuman like features, even when the robot per-              whether classifiers could be trained to determine whether the
forms human-like actions, they are often unable to over-                participant was playing against a human-labeled or computer-
look these traits (Hegel, Krach, Kircher, Wrede, & Sagerer,             labeled agent.
2008). Thus, robots designed to have eyes similar to hu-                   We hypothesized that participant behavior and brain ac-
mans (Banh, Rea, Young, & Sharlin, 2015), or baby face-like             tivity would be different during interactions with human-
heads (Powers & Kiesler, 2006), were found to be more ef-               labeled agents, compared to interactions with computer-
fective in evoking a more human-like interaction.                       labeled agents, even though both agents used exactly the same
   These differences have also been extensively studied us-             strategies and emotions. Our initial experiment consisted of
ing brain imaging techniques, especially regions associated             an online negotiation task intended to explore perceptual and
                                                                    2413

                                            Figure 1: Objects Negotiation Task Timeline
behavioral differences pertaining to anthropomorphic charac-          ioral data collection only, so in this paper, a modified version
teristics in human and computer-labeled agents. Next, we              of this task was used for collection of both behavioral and
adapted our negotiation framework into an fMRI experiment,            brain data. Figure 1 shows the timeline of the modified ver-
attempting to find neural differences for the two distinct part-      sion of this task. Some of the modifications made included
ner conditions. In addition to these studies, we also ran a pre-      an emotion-reporting phase and offer-review phase, which
diction algorithm and multi-voxel pattern analysis (Norman,           were added to separate collection of brain data between dif-
Polyn, Detre, & Haxby, 2006) based on the fMRI data.                  fering phases. In addition, a partner introduction phase was
   This work is distinct from previous studies due to the use         added, allowing participants to receive a notification specify-
of an identical computer agent, regardless of what partner            ing whether their partner type was another participant or the
type was specified. The majority of previous studies em-              computer program before the negotiation began.
ployed computer-animated characters or robots that had dif-              The sequence of the modified Objects Negotiation Task is
fering levels of anthropomorphism. We demonstrate that even           as follows. When the task begins, the negotiation partner
though the same computer agent is used, perceptual differ-            type is displayed. Specifically, in the human-labeled agent
ences were captured in behavioral and brain data. To the best         condition, the message shown to the participant is ‘In this
of our knowledge, this is one of the first lines of research that     task, you will be negotiating with the other participant.’ In
uses a multi-round negotiation platform to investigate percep-        a computer-labeled agent condition, the same message was
tions of anthropomorphism. We believe that natural interac-           shown but ‘the other participant’ was changed to ‘a computer
tions take place over multiple rounds/sessions, and it is there-      program’. Next, a ‘connection establishment’ message for the
fore important to investigate perception differences through          human condition and a ‘program setup’ message for the com-
multi-round negotiations.                                             puter condition appear on screen, to persuade participants of
   This paper is structured as follows. First, we introduce           their partner setting. Throughout the negotiation, the partner
and explain the Object Negotiation Task, the platform used            type is constantly included on screen so the participant clearly
for both experiments described. Next, we outline an ex-               recognizes his/her partner type. The partner is labeled as ‘the
ploratory, behavioral experiment performed to examine the             other participant’ or ‘the computer program.’
differences between interactions with a human-labeled agent
                                                                         In the first negotiation round, items are positioned in the
and a computer-labeled agent. After which we discuss our
                                                                      middle row, indicating that those items belong to neither
fMRI experiment, using the same paradigm as the first, try-
                                                                      player. The participant is asked to propose an initial offer
ing to identify differences in brain activity. Lastly, we discuss
                                                                      by moving items into his/her own set of boxes (bottom row)
the implications of our results and future work.
                                                                      or their partner’s set of boxes (top row). Once the initial offer
                                                                      is made, the partner (agent) chooses an emotion pertaining to
                Objects Negotiation Task                              the offer which is then displayed to the participant. Available
The Objects Negotiation Task is a web-based multi-round               emotions include: happy, content, neutral, angry and sad. The
negotiation task where a participant and a computer agent             partner only shows the predefined emotion for each round.
can take turns distributing objects (Dehghani, Carnevale, &           After the emotion is displayed, the partner decides whether
Gratch, 2014). The original version was designed for behav-           to accept or reject the offer. This decision is based on a pre-
                                                                  2414

defined offer value; when the payoffs of the predefined offer
are more than the participant’s current offer, the partner re-
jects, when the payoff is less, the partner accepts.
   If the participant’s offer is accepted, the items are dis-
tributed as proposed and the participant is notified. If the par-
ticipant’s offer is rejected, the partner then proposes a coun-
teroffer. When the counteroffer is received, the participant
has 5-seconds for review. During this time, the participant
can only observe; no items can be transferred. The review
time was specifically introduced for optimal brain activation,
as we wanted to record an active decision-making process.
For the same reason, our analysis was focused on data col-              Figure 2: Payoffs for agents and participants across both
lected during this review phase. After the review phase, the            agent strategies.
participant reports his/her emotion about the proposed offer
by choosing from the following descriptive options: happy,
content, neutral, angry, or sad. The participant also decides
whether to accept or reject the offer. If the participant rejects
the offer, a new round begins, and all phases are repeated.
The negotiation can last for a maximum of six rounds. If no
agreement is made in six rounds, neither party receives any-
thing.
              Study 1: Online Experiment
We designed an online experiment to determine whether peo-
ple perceive human-labeled agents differently than computer-
labeled agents during interactions in our negotiation game, as          Figure 3: Anthropomorphism Scores for human-labeled
well as to find behavioral differences between agent type in            agents and computer-labeled agents. Higher score means the
concession-making.                                                      agent is perceived as more human-like. The error bar shows
Negotiation Partners Two sets of strategies and two types               standard errors.
of emotions were used for the partner agents. Agent strategies
included tough and soft. A tough strategy starts with a greedy
offer, and a soft strategy starts with a relatively generous offer.     questionnaire. In the anthropomorphism questionnaire, par-
Figure 2 shows payoffs for the agent and the participant when           ticipants rated their impression of their partner using a scale
the agent uses tough or soft strategies.                                from 1 to 7, where 7 means human-like and 1 means machine-
   Agent emotions included anger and neutral (no emotion).              like. Subjects were also given a simple attention-check ques-
Anger was chosen because it was found to be the most ef-                tion, implemented to make sure the participants were paying
fective emotion in yielding concessions during negotiation              attention; it merely asked what type of partner they were as-
tasks (Van Kleef, De Dreu, & Manstead, 2004). For the anger             signed during the task. Each participant was compensated $1.
condition, the agent displayed an angry face in rounds 2, 4,            Data Analysis We excluded subjects who had participated
and 6, and a neutral face in rounds 1, 3, and 5. For the neutral        in our previous negotiation studies or failed to give the cor-
condition, the agent reported a neutral face in every round.            rect answer to the attention-check question. After exclusion,
Procedure 420 subjects (237 male and 183 female; mean                   we had data from 329 subjects. Scores from each condi-
age = 33.5) living in the United States were recruited via              tion were calculated for the anthropomorphism questionnaire
Amazon Mechanical Turk (MTurk). Each participant was                    to verify whether participants perceived human-likeness dif-
asked to read a hypothetical scenario in which they acted as a          ferently between agents. In addition, we calculated conces-
restaurant owner, and negotiated for fruit with another restau-         sions across partner type in each condition to analyze behav-
rant representative due to a fruit shortage as a result of a re-        ioral differences. Concession was calculated by subtracting
cent fire in a local market. Each subject was then told to ne-          payoffs of agreed offers from payoffs of initial offers. A
gotiate with either a computer program or another (hypothet-            three-way between-subjects analysis of variance (ANOVA)
ical) MTurk player. Regardless of type label, the negotiation           was used to find the interaction between partner type, part-
partner was always a pre-programmed computer agent. After               ner strategy, and partner emotion during concession.
completing all negotiations, subjects were asked to fill out an         Results The anthropomorphism scores of the human-
anthropomorphism questionnaire (Bartneck, Kulić, Croft, &              labeled agents and the computer-labeled agents are shown in
Zoghbi, 2009) about their partner, as well as a demographic             Figure 3. 1-way ANOVA results show that people consis-
                                                                    2415

                                                                     Participants 20 healthy American subjects (10 male and 10
                                                                     female), recruited via the University of Southern California
                                                                     online bulletin board, took part in this study. Subjects were
                                                                     21.4 years old on average (SD = 2.58). All participants were
                                                                     right-handed and had no history of neurological or psychiatric
                                                                     disorders.
                                                                     Negotiation Partners Although we were only interested in
                                                                     tough agent type, we used two types of soft agents on top of
                                                                     four types of tough agents (human/computer-labeled × an-
                                                                     gry/neutral agents). This is modification was implemented
                                                                     because subjects participated in a series of consecutive ne-
Figure 4: Concessions to human-labeled agents and                    gotiations, unlike our online experiment where each subject
computer-labeled agents. The error bars show standard er-            only played in a single negotiation. Including soft agents en-
rors.                                                                sured that participants did not play with the same agent over
                                                                     and over again. Each subject negotiated with six types of
                                                                     agents. While every subject negotiated with four types of
tently thought their partner to be more human-like when told         tough agents, 10 subjects (5 male and 5 female) negotiated
their partner was a human player, no matter what the negoti-         with two types of emotion-neutral soft agents, while the re-
ation strategy (F(1, 327) = 14.09, p < 0.001).                       maining 10 subjects negotiated with two types of emotion-
   Concessions to human-labeled agents and computer-                 angry soft agents. Agent order was randomized.
labeled agents during negotiations are shown in figure 4.
ANOVA results show that there is a 2×2×2 interaction be-             Procedure Each participant was greeted by an experi-
tween agent type (human/computer) × agent emotion (an-               menter and introduced to the confederate as the competing
gry/neutral) × agent strategy (tough/soft) for concession            player. The participant and the confederate were guided to a
(F(1, 321) = 3.387, p = 0.066). We also ran a 2×2 ANOVA af-          preparation room where they filled out an informed consent
ter dropping each strategy. A two-way interaction was found          form, incidental findings form, and safety screening form.
for tough strategy (F(1, 164) = 4.699, p = 0.031).                   After forms were completed, the confederate was guided to
                                                                     a separate MRI room for “setting up”. The participant was
Discussion Our findings from anthropomorphism scores
                                                                     given the instructions and rules regarding the negotiation task,
suggest that there are perception differences in the interac-
                                                                     and played a trial negotiation against a computer program
tions between human-labeled agents and computer-labeled
                                                                     before starting the experiment. During the trial, a trackball
agents. Also, our ANOVA results suggest that there is an in-
                                                                     mouse similar to one used in the scanner environment was
teraction between agent type × agent emotion × agent strat-
                                                                     provided, so that the participant became familiarized with it’s
egy for concession. This indicates that not only are people’s
                                                                     operation. The participant was then guided to the actual MRI
perceptions of the two agents distinct, but their behaviors also
                                                                     room and was told that while in the scanner he/she would
vary depending on agent type. To study whether these be-
                                                                     run through three negotiation tasks with the participant in the
havioral differences have neural correlates, we designed the
                                                                     other MRI room, and three negotiation tasks with the com-
following fMRI experiment. Because the largest concession
                                                                     puter program. The task was back projected on a screen,
differences were found in the tough conditions, implying the
                                                                     seen through a mirror attached to the head coil, and oper-
tough strategy was best suited to observe those differences in
                                                                     ated a trackball mouse to navigate negotiations. In each task,
behavior, we mainly employed tough agents in the following
                                                                     a different set of negotiation items were used, and payoffs for
experiment.
                                                                     these items varied with position, in order to give an impres-
                                                                     sion that each negotiation was unique. Participants answered
              Study 2: fMRI Experiment                               a shortened version of the anthropomorphism questionnaire
                                                                     at the completion of each round. After a maximum of six ne-
We hypothesized that perceptual and behavioral differences           gotiation rounds, participants filled out a handedness and de-
could be captured in brain activity, especially in ToM               mographic questionnaire. Before leaving, subjects were de-
related brain regions, as they were found to be corre-               briefed and compensated $30.
lated with human-likeness of physically existing human-like
robots (Chaminade et al., 2007; Krach et al., 2008). Each            fMRI Data Acquisition fMRI scans were performed at the
subject performed the negotiation task with both types of            USC Dana & David Dornsife Cognitive Neuroscience Imag-
agent in order to compare brain activity from human-labeled          ing center. Images were acquired using a 3-Tesla Siemens
vs. computer-labeled agent interaction. To make interac-             PRISMA MRI scanner with a 20-channel matrix head coil.
tions with human-labeled agents more realistic, we intro-            Two sets of high-resolution anatomical images were acquired
duced a confederate into the study, so participants believed         for registration purposes. Six sets of echo-planar images
they would be competing against another human player.                (EPI), one set for each negotiation, were acquired continu-
                                                                 2416

                                                                    human-labeled agent to have more human-like qualities.
                                                                       MVPA, with searchlight as a feature selection method, re-
                                                                    vealed that agent type (human/computer) can be predicted
                                                                    based on brain activity during proposal-review phases. Pre-
                                                                    diction accuracy for agent type was 58.41%, with a standard
                                                                    error 0.01%, where chance level is 50%. The improvement
                                                                    was found to have statistical significance (Two-tailed t-test: p
                                                                    < 0.001).
Figure 5: Frontal medial cortex from Harvard-Oxford atlas
(left) and overlaid accuracy map for all participants (right).      Discussion The results of Study 2 demonstrates that differ-
A part of frontal medial cortex was included in the accuracy        ences in how we perceive the ’humanness’ of an agent can
map (white dotted box).                                             be captured using fMRI. Specifically, our results show that
                                                                    parts of the ToM neural correlates are activated in human-
                                                                    labeled agent conditions, but not in computer-labeled agent
ously with the following parameters: TR = 2,000ms, TE =             conditions. This finding is consistent with previous stud-
25ms, flip angle = 90◦ , 64×64 matrix, one shot per repeti-         ies that reported increased brain activity in ToM brain re-
tion, in-plane resolution 3×3 mm2 , 41 transverse slices, each      gions corresponding to human-likeness of interacting part-
3mm thick, covering the whole brain. Total scan time for each       ners (Chaminade et al., 2007; Krach et al., 2008). Our
participant was approximately 50 minutes.                           MVPA analysis further revealed that these differences are
                                                                    great enough that classifiers can be trained that can reliably
Data Analysis We conducted a general linear model
                                                                    distinguish brain activity between the two types of agents.
(GLM) analysis and then used the results as input for multi-
voxel pattern analysis (MVPA). GLM analysis was performed                               Overall Discussion
using FMRIB’s Software Library (FSL) to locate brain re-
gions activated during proposal review phases. As mentioned         Our goal was to investigate differences in behavior and brain
earlier, this phase was specifically targeted due to the like-      activity during human-agent negotiations. Focusing on part-
lihood of collecting data pertaining to decision making for         ner type, we hypothesized that both parameters would be dis-
subsequent negotiation rounds. For GLM analysis, data pre-          tinct when comparing computer-labeled and human-labeled
processing steps included motion correction, brain extrac-          interactions.
tion, spatial smoothing, slice timing correction, and high-pass        Results from our online experiment indicate that peo-
temporal filtering. After completing data pre-processing, we        ple perceive human-labeled agents more human-like than
modeled brain activity during proposal review phases using          computer-labeled ones, even though both used parallel strate-
a double gamma hemodynamic response function. Data col-             gies and emotions. This suggests that people’s attitudes to-
lection from all other time points were used as baseline. We        wards computer partners are distinguishable from those to-
then performed MVPA to find brain regions that illustrated          wards human partners. Furthermore, a 3-way interaction be-
different patterns across agent type. In MVPA, neural rep-          tween agent type × agent emotion × agent strategy was found
resentations were decoded by applying pattern-classification        for concession.
algorithms on fMRI data (Norman et al., 2006). We used                 Results from our fMRI experiment suggest that brain pat-
detrended and z-scored GLM analysis results as inputs for           terns observed during interactions with human-labeled agents
MVPA, and trained a linear Support Vector Machine (SVM)             are different from ones with computer-labeled agents. More
classifier using feature selection, introduced to improve clas-     specifically, the medial prefrontal cortex, part of the ToM-
sification performance by picking the most relevant features        related neural structures, was found to be included in accu-
as inputs for the classifier (Guyon & Elisseeff, 2003). Search-     racy maps, indicating neural activity during interactions with
light analysis (Kriegeskorte, Goebel, & Bandettini, 2006) was       human-labeled agents are distinct from ones with computer-
used as the feature selection method to analyze contents mul-       labeled agents. This is in line with a previous finding, where
tivariately at each location in the brain. We implemented           the medial prefrontal cortex was found to be activated while
a leave-one-participant-out cross validation as balance for         playing rock-paper-scissors with a human player, but not acti-
MVPA. More details on fMRI data analysis can be found               vated when playing the same game with a known, pre-defined
in (Kim, Gimbel, Litvinova, Kaplan, & Dehghani, 2016), as           computer algorithm (Gallagher, Jack, Roepstorff, & Frith,
the same analysis methods were used.                                2002). Using a negotiation paradigm, a more complicated
                                                                    task than rock-paper-scissors due to the inclusion of multi-
Results The right side of Figure 5 shows an overlaid ac-            ple decision-making rounds, we found that the same effect
curacy map for all participants. Accuracy maps were ac-             exists with differently labeled agents. Negotiations require a
quired from the top 5% of all t-maps, which were generated          more substantial cognitive effort than a game like rock-paper-
using t-tests versus chance. Interestingly, medial prefrontal       scissors; there are a larger amount of possible actions to con-
cortex, one of the ToM brain regions, was included in the           sider, an increased opportunities for loss, and a greater obli-
accuracy map, suggesting that people indeed perceived the           gation to compete, or cooperate and come to some sort of
                                                                2417

agreement. The negotiation tasks used in the aforementioned            Dehghani, M., Carnevale, P. J., & Gratch, J. (2014). Inter-
experiments are able to advantageously measure interactions              personal effects of expressed anger and sorrow in morally
that require high levels of cognitive energy, and are therefore          charged negotiation. Judgment and Decision Making, 9(2).
more useful when attempting to explore human-robot inter-              Gallagher, H. L., Jack, A. I., Roepstorff, A., & Frith, C. D.
actions.                                                                 (2002). Imaging the intentional stance in a competitive
   Our findings are also consistent with previous studies that           game. Neuroimage, 16(3), 814–821.
found ToM-related neural structures to be more activated               Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions
when interacting with agents that had more human-like char-              of mind perception. Science, 315(5812), 619–619.
acteristics, regardless of whether those agents happened to            Guyon, I., & Elisseeff, A. (2003). An introduction to variable
be robots or computer-generated characters (Chaminade et                 and feature selection. The Journal of Machine Learning
al., 2007; Krach et al., 2008). These findings imply per-                Research, 3.
ceptual variance between interactions with human-like and              Hegel, F., Krach, S., Kircher, T., Wrede, B., & Sagerer, G.
nonhuman-like agents, and leads us to believe that human                 (2008). Understanding social robots: A user study on an-
participants do engage in greater mentalising efforts when               thropomorphism. In Robot and human interactive commu-
faced with human-labeled or human-like robots.                           nication, 2008. ro-man 2008. the 17th ieee international
   In conclusion, we examined the relationship between ne-               symposium on (pp. 574–579).
gotiation partner type and behavioral and neural measures re-          Kim, E., Gimbel, S. I., Litvinova, A., Kaplan, J. T., & De-
garding individual’s perceptions of human-agent interactions.            hghani, M. (2016). Predicting decision in human-agent
Our study suggests that when either by labeling agents as                negotiation using functional mri. Proceedings of the 38th
other humans or as computer programs significantly impacts               Annual Meeting of the Cognitive Science Society.
one’s perception of the situation; this is ultimately demon-           Kircher, T., Blümel, I., Marjoram, D., Lataster, T., Krabben-
strated through negotiation behavior and brain activity. The             dam, L., Weber, J., . . . Krach, S. (2009). Online mentalis-
results give us further insight into the counter-play between            ing investigated with functional mri. Neuroscience letters,
emotional and cognitive processes, leading us to believe that            454(3), 176–181.
our emotions may have greater impact on decision making                Krach, S., Hegel, F., Wrede, B., Sagerer, G., Binkofski, F., &
than which we are consciously aware. Ultimately, these re-               Kircher, T. (2008). Can machines think? interaction and
sults inform us that there is a noticeable and consistent dif-           perspective taking with robots investigated via fmri. PloS
ference between the perceptual and emotional reactions that              one, 3(7), e2597.
humans have towards other humans when compared to those                Kriegeskorte, N., Goebel, R., & Bandettini, P. (2006).
same reactions with computer agents. Further research needs              Information-based functional brain mapping. Proceedings
to be executed to more thoroughly understand why these dif-              of the National Academy of Sciences of the United States of
ferences in interaction occur, but this study has illustrated that       America, 103(10).
computers and technology do indeed impact the way humans               Melo, C. D., Marsella, S., & Gratch, J. (2016). People do not
interact with the world, and each other. This is important               feel guilty about exploiting machines. ACM Transactions
to consider as computers continue to be increasingly imple-              on Computer-Human Interaction (TOCHI), 23(2), 8.
mented in everyday life and society.                                   Norman, K. A., Polyn, S. M., Detre, G. J., & Haxby, J. V.
                                                                         (2006). Beyond mind-reading: multi-voxel pattern analysis
                                                                         of fmri data. Trends in cognitive sciences, 10(9).
                     Acknowledgments
                                                                       Powers, A., & Kiesler, S. (2006). The advisor robot: tracing
This research is supported by AFOSR FA9550-14-1-0364.                    people’s mental model from a robot’s physical attributes.
                                                                         In Proceedings of the 1st acm sigchi/sigart conference on
                         References                                      human-robot interaction (pp. 218–225).
                                                                       Premack, D., & Woodruff, G. (1978). Does the chimpanzee
Banh, A., Rea, D. J., Young, J. E., & Sharlin, E. (2015). In-            have a theory of mind? Behavioral and brain sciences,
   spector baxter: The social aspects of integrating a robot as          1(04), 515–526.
   a quality inspector in an assembly line. In Proceedings of          Sanfey, A. G., Rilling, J. K., Aronson, J. A., Nystrom,
   the 3rd international conference on human-agent interac-              L. E., & Cohen, J. D. (2003). The neural basis of eco-
   tion (pp. 19–26).                                                     nomic decision-making in the ultimatum game. Science,
Bartneck, C., Kulić, D., Croft, E., & Zoghbi, S. (2009). Mea-           300(5626).
   surement instruments for the anthropomorphism, animacy,             Van Kleef, G. A., De Dreu, C. K., & Manstead, A. S. (2004).
   likeability, perceived intelligence, and perceived safety of          The interpersonal effects of anger and happiness in negotia-
   robots. International journal of social robotics, 71–81.              tions. Journal of personality and social psychology, 86(1).
Chaminade, T., Hodgins, J., & Kawato, M. (2007). Anthro-               Vant Wout, M., Kahn, R. S., Sanfey, A. G., & Aleman, A.
   pomorphism influences perception of computer-animated                 (2006). Affective state and decision-making in the ultima-
   characters’ actions. Social cognitive and affective neuro-            tum game. Experimental brain research, 169(4), 564–568.
   science, 2(3), 206–216.
                                                                   2418

