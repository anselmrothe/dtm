                            Inferential Pitfalls in Decoding Neural Representations
                                            Vencislav Popov (vencislav.popov@gmail.com)
                               Department of Psychology, Carnegie Mellon University, Pittsburgh, PA, USA
                                                Markus Ostarek (markus.ostarek@mpi.nl)
                                     Max Planck Institute for Psycholinguistics, Nijmegen, Netherlands
                                             Caitlin Tenison (ctenison@andrew.cmu.edu)
                               Department of Psychology, Carnegie Mellon University, Pittsburgh, PA, USA
                               Abstract                                       In this article, we review some of the known inferential
                                                                           limitations of existing fMRI analysis methods and we highlight
   A key challenge for cognitive neuroscience is to decipher the           a previously unrecognized issue in interpreting results from
   representational schemes of the brain. A recent class of decoding       stimulus-feature-based encoding and decoding models. The
   algorithms for fMRI data, stimulus-feature-based encoding
                                                                           latter are steadily becoming the de facto gold standard for
   models, is becoming increasingly popular for inferring the
   dimensions of neural representational spaces from stimulus-             investigating neural representational spaces (Haxby et al. 2014,
   feature spaces. We argue that such inferences are not always valid,     Naselaris & Kay, 2015).
   because decoding can occur even if the neural representational
   space and the stimulus-feature space use different representational     Univariate vs. multivariate analysis
   schemes. This can happen when there is a systematic mapping             Before the advent of the more advanced techniques we review
   between them. In a simulation, we successfully decoded the binary       below, the main fMRI analysis tool was based on comparing
   representation of numbers from their decimal features. Since
                                                                           how activity in a single voxel or averaged activity in a
   binary and decimal number systems use different representations,
   we cannot conclude that the binary representation encodes decimal       contiguous area of voxels differs between task conditions or
   features. The same argument applies to the decoding of neural           stimuli. These univariate subtraction methods have been
   patterns from stimulus-feature spaces and we urge caution in            informative about the relative engagement of certain brain areas
   inferring the nature of the neural code from such methods. We           in specific tasks. Unfortunately, the coarse nature of this method
   discuss ways to overcome these inferential limitations.                 precludes fine-grained inferences about the underlying
                                                                           representational content and computations that give rise to the
                           Introduction                                    observed BOLD signal. By ignoring the possibility that
A key challenge for cognitive neuroscience is to decipher the              information might be represented in a distributed manner across
representational schemes of the brain, to understand the neural            voxels, the assumptions underlying univariate subtraction
code that underlies the encoding and representation of sensory,            methods limit their use in understanding neural representations.
motor, spatial, emotional, semantic and other types of                     In addition, these methods cannot tell us whether changes in
information. To address these issues researchers often employ              activation are due to representational preferences, processing
neuroimaging techniques like functional magnetic resonance                 differences, or attentional variation among conditions
imaging (fMRI), which measures the blood oxygenation level-                (Coutanche, 2013).
dependent (BOLD) activation in the brain that is elicited when                In contrast, multivoxel pattern analysis (MVPA) techniques
participants engage with different stimuli. A common                       have attempted to overcome this limitation by looking at how
assumption has been that the underlying neural representation of           various categories of stimuli or task conditions lead to
each stimulus has measurable but complex effects on the BOLD               differences (i.e. MVP classification) or similarities (i.e. RSA) in
activation patterns. In order to understand what those patterns of         distributed patterns of activity over multiple voxels. These
activity can tell us about how the brain processes and represents          methods have become popular because they allow researchers to
information, researchers have used various analytical tools such           study neural representational spaces with increasing sensitivity
as univariate subtraction methods, multivariate pattern (MVP)              and resolution. For example, a seminal study by Haxby et al.
classification, representational similarity analysis (RSA) and,            (2001) found that visual object categories can be classified based
recently, explicit stimulus-feature-based encoding and decoding            on the pattern of activation that their exemplars elicited in the
models (for reviews, see Davis & Poldrack, 2013, Haxby,                    ventral temporal cortex. The classification was successful
Connolly, & Guntupalli, 2014, or Naselaris, Kay, Nishimoto, &              despite the lack of overall activation differences in that region.
Gallant, 2011). Despite their differences, these methods aim to            Similar methods have been used to show that concepts have
quantify how changes in task conditions and the properties of the          language-invariant representations in the anterior temporal lobe
stimuli relate to changes in BOLD activation and vice versa.               (Correia et al., 2014), that very similar visual scenes can be
Where these methods differ is in how they achieve that mapping             discriminated in the hippocampus (Bonnici et al., 2012) and that
and in what inferences they allow us to draw.                              during their retrieval from memory, the shape, color and identity
                                                                       961

of visual objects can be differentially decoded across several           Stimulus-feature-based encoding models
cortical areas (Coutanche & Thompson-Schill, 2015).                      To overcome this limitation many researchers are turning to a
   Despite early enthusiasm that MVPA methods could be used              novel analysis method that is known by a few different names –
to understand the structure of the neural code and the nature of         voxelwise modelling (Naselaris & Kay, 2015), stimulus-model
the underlying representations (Norman, Polyn, Detre, & Haxby,           based encoding and decoding (Haxby et al., 2014), voxel-based
2006), conventional MVP classification and RSA techniques                encoding and decoding models (Naselaris et al., 2011), and
share one of the same fundamental inferential limitations of             forward models (Brouwer & Heeger, 2009; Fernandino,
univariate methods. Successful classification or careful                 Humphries, Conant, Seidenberg, & Binder, 2016). This
inspection of confusions/similarity matrices can indicate that           approach can decode the identity of novel types of stimuli from
some relevant information about the stimulus class is present in         neural activity by predicting activity not for the stimuli
the population of analyzed voxels, but it cannot identify exactly        themselves, but for a set of simpler features into which they can
what that information is, or how it is represented and organized         be decomposed. In a seminal study, Mitchell et al. (2008)
(Naselaris & Kay, 2015; Poldrack, 2011; Tong & Pratte, 2012).            predicted the neural activity associated with individual novel
Because neural data is correlational, many different properties of       words based only on the activation of other words. To achieve
the stimuli might lead to successful classification of the stimulus      that, they decomposed each word into a vector of weights on 25
category, the task condition, or the brain state in question. For        sensory-motor semantic features (verbs such as “eat”, “taste”,
example, successfully categorizing whether a word represents an          “run”, “fear”, etc.). The weights were estimated from co-
animate or an inanimate object does not necessarily mean that            occurrence statistics of the word with each verb feature in a large
the region of interest encodes that category distinction. There are      corpus. They trained a classifier to predict the neural activity
many differences between animate and inanimate objects, such             associated with each constituent feature of a training set of
as differences in their sensory and functional features (Farah &         words, which resulted in separate neural activation maps for
McClelland, 1991) that could be responsible for the successful           each feature. Neural activity for novel test words was then
classification.                                                          predicted highly accurately as a linear combination of the
   Another limitation of conventional MVP classifiers is that            semantic feature activation maps weighted by the association of
they cannot generalize and predict behavioral responses to novel         the word with each feature. Based on these results, Mitchell et
types of stimuli or task conditions. To understand why, we can           al. (2008) concluded that the neural representation of concrete
conceptualize classifiers in terms of types and tokens. An MVP           nouns might be based on sensory-motor features.
classifier is usually trained on stimuli that are tokens from               Similar approaches have been used to predict the neural
several types. For example, the stimuli tokens might be different        response to novel natural images using Gabor filter features
category exemplars, and the classifier is trained to predict the         (Kay, Naselaris, Prenger, & Gallant, 2008), to novel colors based
type of category to which they belong. Alternatively, the tokens         on color tuning curve features (Brouwer & Heeger, 2009), to
might be multiple presentations of the same word in different            novel music clips based on acoustic timbre features (Casey,
modalities or languages and the types are the unique words               Thompson, Kang, Raizada, & Wheatley, 2012), to natural
themselves. In the first case, the classifier can only be used to        sounds based on frequency, spectral and temporal modulations
predict category membership of words that belong to one of the           (Santoro et al., 2014), to novel faces based on a PCA
categories on which it was trained. In the second case even              decomposition of face features (Lee & Kuhl, 2016), to novel
though the classifier could be used to predict exemplars in novel        words based on subjective sensory-motor ratings (Fernandino et
languages or modalities, it is again restricted only to exemplars        al., 2016). The motivating question behind the majority of these
of the words on which it was trained in the first place. In general,     studies has been about the nature of the representations used by
while the tokens being tested might be novel, they will be               the brain in encoding the experimental stimuli, and the results
potentially decoded only if they are exemplars of a type that has        have been used to argue that the neural representation is based
already been trained on.                                                 on the constituent features of the stimuli used in the model.
   For example, if one trains a classifier to predict the color of          To summarize, stimulus-feature encoding models generally
objects and trains it on yellow and orange objects (Coutanche &          use the following analysis procedure: 1) Specify a set of features
Thompson-Schill, 2015), one will not be able to predict the color        and dimensions that hypothetically underlie the representation of
of novel objects that are green. This methodological limitation is       a stimulus set in brain. 2) Decompose a set of stimuli into vectors
important - just as understanding how the decimal system                 of weights for each feature. 3) Select a region of interest (ROI)
represents numbers allows people to understand and manipulate            in the brain from which to analyze neural activation. 4) Train a
numbers they have never seen before, a complete understanding            model to predict activity in each voxel for a training set of
of any neural representational system should allow researchers           stimuli, using the weights of their features as predictors. 5)
to use the neural pattern associated with novel stimuli to predict       Derive activation pattern maps (e.g. regression coefficients)
their identity, even if those stimuli are not exemplars of the types     associated with each feature. 6) Predict neural activity in the ROI
on which a particular model was trained on.                              for novel stimuli, based on their feature weights and the
                                                                         activation pattern maps for each feature. 7) Compare predicted
                                                                         neural activity for each novel stimulus with their observed neural
                                                                         activity and derive a measure of fit and accuracy. In essence,
                                                                         stimulus-feature-based encoding models attempt to map a
                                                                     962

stimulus feature representational space, where each feature is a           Here lies the problem – this inference is not formally valid.
separate dimension, and each stimulus is a point in that space, to      We need to consider what the data would have looked like if the
a neural activation space, where each voxel is a separate               underlying neural representation was actually different (Mahon,
dimension, and the activation pattern elicited by each stimulus is      2015). In this example, the successful decoding of conceptual
a point in that space.                                                  identity in the GSN based on an encoding model of sensory-
                                                                        motor features does not necessitate the representational format
What can we infer about neural representations?                         in the GSN to be sensory-motor in nature. The results might be
What can a successful mapping between a stimulus feature space          obtained even if the GSN uses amodal representations, as long
and a neural activation space tell us about the nature of the           as there is a non-arbitrary mapping between representations in
representation used by the brain? A common inference in these           the GSN and sensory-motor features. To illustrate, let us
studies has been that if you can predict the identity of novel          hypothetically assume that the GSN literally encodes word co-
stimuli based on that mapping, then the neural representation is        occurrence statistics. As co-occurrence statistics correlate with
likely based on the feature set used by the model. Put formally,        sensory-motor feature ratings, it would be possible to predict
the inferential claim goes as follows:                                  GSN activity patterns based on these features, even if they are
                                                                        not driving the activity patterns. In contrast, successful decoding
   1) We can represent certain stimuli as a combination of              would be impossible if the mapping between the GSN
       lower-level features                                             representations and sensory-motor features was arbitrary. Thus,
   2) We can show that it is possible to predict the neural pattern     Fernandino et al.'s (2016) results constitute evidence against the
       caused by a novel stimulus in brain area A from an               possibility that conceptual representations in heteromodal areas
       encoding model based on these features                           bear an arbitrary relation to sensory-motor features, as has been
   3) Therefore, brain area A encodes those features and uses a         argued by some proponents of symbolic systems (Fodor &
       representational scheme based on them.                           Pylyshyn, 1988), but should not be taken as conclusive evidence
   This claim has been made to different degrees both in                that the GSN encodes multimodal sensory-motor information.
theoretical and methodological papers reviewing the                        This issue is not limited to the specific study discussed above.
approach (e.g., Haxby et al., 2014; Naselaris & Kay, 2015;              To put the claim more generally, we argue that information in
Naselaris et al., 2011; Norman et al., 2006; Tong & Pratte,             one representational system might be decoded based on features
2012), as well as in empirical studies that use it to address           from another, even if they use different representational
representational questions (Fernandino et al., 2016; Kay et             schemes, as long as there is at least a partially systematic
al., 2008; Mitchell et al., 2008; Santoro et al., 2014; although        mapping between them. Specifically, while such encoding
some are more cautionary, e.g. Lee & Kuhl, 2016). If this               models should be able to predict the neural activation from the
inference is valid, then encoding models could be an                    features of a stimulus if the brain uses a representational scheme
extremely powerful tool for understanding the nature of                 based on those features, the reverse is not guaranteed1. A
neural representations.                                                 successful prediction can also occur when the stimulus feature
   A useful illustrative example of this inference in practice          space is systematically related to the features that underlie the
comes from a recent study by Fernandino et al. (2016). The              neural representational scheme. However, that relationship need
authors wanted to understand how conceptual information is              not be one of equivalence. There are at least three ways in which
represented in a set of higher-order non-modality-specific brain        mappings between representational systems can be made and
regions in General Semantic Network (Binder, Desai, Graves, &           successful prediction can occur in two of those cases.
Conant, 2009). An encoding model based on subjective ratings
for 5 sensory-motor features of training words (“color”,                Types of mappings
“motion”, “sound”, “shape”, “action”) was used to predict               Arbitrary mappings between representations. First, items
activation patterns related to novel individual words. The model        from two representational systems might be related in an entirely
successfully predicted above chance the brain activity patterns         arbitrary way. For example, the meaning of words is mostly
for concrete words in the semantic network regions (61% mean            unrelated to their orthographic features2, and the geographic
accuracy), but not in a set of control regions associated with          locations of countries are not predictive of their names, etc. More
visual word form processing. Based on this finding, Fernandino          generally, consider two unordered sets of items,                 =
et al. (2016) suggested that “the brain represents concepts as          { , , … , } and = { , , … , }. An arbitrary mapping
multimodal combinations of sensory and motor representations”           between these two sets exists when the mapping from a specific
and that “heteromodal areas involved in semantic processing             item in set A to a corresponding item in set B is unrelated to the
encode information about the relative importance of different           mappings between the remaining items in the sets. In the context
sensory-motor attributes of concepts, possibly by storing               of encoding models and the brain, decoding of novel items from
particular combinations of sensory and motor features”.                 one set would be impossible based on a feature model from the
                                                                        other set, if these two sets are arbitrarily related.
1
  this problem is similar, but not identical, to the problem of         in this domain (e.g., Monaghan et al., 2014), word meanings
reverse inference (Poldrack, 2006)                                      cannot be systematically predicted based on their
2
  Whereas a minor degree of systematicity does seem to exist            orthography and vice versa.
                                                                    963

 Table 1 Examples of studies that use feature encoding models
 Source                        Item                       Features                             Response vector
                                                          Co-occurrence statistics with        Pattern of activation in all cortical
 Mitchell et al., (2008)       Concrete words (dog)
                                                          25 sensory-motor verbs               voxels
                                                          5 sensory-motor relevance            Pattern of activation in the GSN
 Fernandino et al., (2016)     Concrete words (dog)
                                                          ratings                              (Binder et al., 2009)
                                                                                               17 binary digits [0 0 0 0 0 0 0 0 0 0 0 0
 Current simulation            Numbers (3497)             5 decimal digits [0 3 4 9 7]
                                                                                               0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1]
Sets that use the same representational format. In contrast, a                                …        →        (   ×2 )
successful prediction can occur if the two sets use the same
representational format. Consider the set of multi-digit numbers
                                                                        10011 → 1 × 2 + 0 × 2 + 0 × 2 + 1 × 2 + 1 × 2
in the decimal system, = {10,11, … ,427, … }, and the set of
                                                                                              = 16 + 2 + 1 = 19
10 digits in the decimal system, = {0,1,2,3,4,5,6,7,8,9,10}.
These sets use the same representational format to represent             Clearly, there is a systematic but non-linear mapping between
quantities (the decimal system), and there is a systematic linear     the decimal and the binary system, and yet, these two systems
mapping from the features (the digits), to the multi-digit            use different codes to represent numbers. If our argument is
numbers, such that:                                                   correct then it should be possible to predict the binary
                                                                      representation of a number based on a decimal feature encoding
                        …       =      (   × 10 )                     model. Below we present a simulation that achieves this by
                                                                      applying the encoding model approach often used in
       3491 = 3 × 1000 + 4 × 100 + 9 × 10 + 1 × 1                     neuroimaging studies. Within the simulation, binary vectors are
   When we have such systematic mappings between systems              analogous to voxel activation patterns, and the encoding model
that use the same representational format, knowing the mapping        is based on decimal representations (Table 1).
function allows us to decompose any item from set A as a
combination of features from set B. An example of such a                  Simulation: Decoding binary representations
mapping would be Fernandino et al.’s (2016) suggestion that the               with a decimal feature encoding model
general semantic network encodes multimodal combinations of              As detailed previously, encoding models predict stimulus
sensory-motor features by integrating information from                identity from brain activation by modelling the relationship
modality-specific sensory-motor areas. If this were true, then        between the constituent features of the training stimuli and their
you could predict the neural pattern of novel items from their        corresponding BOLD activation in a group of voxels. Then they
featural representations, which is what that study found as well.     use that relationship to estimate the expected neural activation
Sets that use different but systematically related                    patterns for novel test items based on their feature
representational formats. However, there is an alternative,           representations. The predicted activation pattern for each
which would also allow you to make a successful prediction            stimulus is compared to the observed patterns for all test stimuli.
from encoding models. Two sets can use different                      For the following simulation, let us consider the numbers from
representational schemes, while maintaining a systematic              0 to 99 999 as our stimulus set. They can be decomposed into 5-
mapping between themselves that allows us to predict the              dimensional feature vectors where each feature is a decimal digit
mapping of any one pair of items from knowledge of the                (e.g., 3497 can be decomposed as [0 3 4 9 7]. These features can
mapping function. Within the context of conceptual                    be considered analogous to the 5 sensory-motor relevance
representations in the brain, higher-level heteromodal areas          ratings of words used by Fernandino et al. (2016) or to the co-
might use a representational code that is different from the one      occurrence statistics with sensory-motor verbs used by Mitchell
used by sensory-motor cortices, but there might be a systematic       et al. (2008). Further, let us consider the binary representation
mapping between representations in each system3.                      numbers as 17-dimensional vectors (e.g. [0 0 0 0 0 0 0 0 0 0 0 0
   For a simplified example, consider the relation between the        0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1], to be analogous to the
decimal and the binary systems for representing numeric values.       BOLD activation pattern in a set of 17 voxels in an ROI under
A binary represented value can be transformed into a decimal          investigation. The correspondence between these patterns and
number by applying the following formula:                             actual neuroimaging studies using this approach is demonstrated
                                                                      in Table 1.
                                                                         We trained an encoding model to predict the binary activation
                                                                      pattern for a given number, based on its 5-dimensional decimal
   3
     What makes representational codes different is a                 limitations we will briefly cover this issue in the general
surprisingly difficult question to answer. Due to space               discussion, but a more in-depth treatment is needed
                                                                  964

feature representation. The modelling followed 4 steps: 1)               binary and decimal number systems share many properties, and
splitting the stimuli into a training (90%) and a test (10%) set, 2)     that they are merely different implementations of the same
fitting multiple linear regression models on the training set with       fundamental representation. For example, both systems use the
the 17 binary features as response variables, and the 5 decimal          position of a digit to encode its magnitude, and as a result, all
features as predictors, 3) calculating predicted activation pattern      arithmetic procedures that can be performed with decimal
(predicted maps, PMs) for each test item from its decimal                numbers can be applied to binary numbers as well. We propose
features and the multivariate regression model, 4) comparing the         that the key issue in determining whether two representations are
PMs with the actual binary patterns for all test items (observed         the same is whether you can establish a one-to-one mapping
maps, OMs). In the comparison stage, we computed the                     relation between features at different levels of representation in
Euclidean distance between each PM and the OMs for all test              each system. For example, if you substitute each decimal digit
items, and we calculated the percentile rank of the similarity           with a unique letter, the resulting system would appear different
between the PM and the OM of each item. For example, if the              from the decimal system only on the surface, but the relation
PM for the number 29782 were most similar to OM for that                 between multi-digit numbers and their features would be the
number, then the percentile rank for it would be 10 000/10 000           same in both cases4 In contrast, decimal and binary features have
= 1. However, if it were more similar to the OMs of 1 000 other          a qualitatively different relation to the numbers they represent.
items, then its percentile rank would be 9 000/10 000 = 0.9.             Despite this, binary representations can be decoded based on
   The encoding model was successful in decoding the binary              decimal features, illustrating the inferential problem of encoding
representation of untrained items based only on their decimal            models we address here.
features. The prediction accuracy of the linear regression model            It is important to clarify that the “one-to-one” mapping is an
was 0.7 (SD = 0.24) and a wilcoxon signed rank test showed that          abstract requirement. We are not claiming that to establish
it was above chance (p < .0001). Since by definition binary and          representational equivalence between the brain and a certain set
decimal number systems use different representational formats,           of features that it is necessary to find a one-to-one mapping
we cannot conclude that the representation of binary numbers             between the basic feature components of stimuli and activation
encodes decimal features. By analogy, the successful decoding            in individual voxels or groups of voxels. The brain does not
of patterns of neural activation based on a stimulus feature space,      compute and represent information at the voxel level – voxel
cannot be used to infer that the brain encodes information about         activations are the result of averaged activity over hundreds of
these features or that its neural representational space is              thousands of neurons. The general lack of access to large-scale
organized along the dimensions of that feature space.                    neural level activity in the living human brain makes it even
                                                                         more important to not only discover analytical tools that helps us
                            Discussion                                   relate voxel activation to possible representations, but also to
   Stimulus-feature based encoding models (Haxby et al., 2014,           understand the limitations of those tools and what they can and
Naselaris et al., 2011) are a powerful new tool for studying how         cannot tell us.
the constituent features of stimuli relate to the neural activation         An important question that naturally arises from the caveats
patterns elicited by these stimuli. They represent a significant         we discussed is how one can maximize confidence in the
methodological advance over more traditional MVPA methods                outcome of a forward encoding model approach, or conversely,
because they allow us to predict neural activation for novel items       guard oneself against unjustified inferences. We propose that it
and because they can be used to decode the identity of such items        is crucial to compare the performance of several possible
from neural data alone. While this is an impressive feat and an          encoding models. To that aim, it is not sufficient to use a
incredibly useful tool, we have to be cautious in interpreting           "baseline model" that is unrelated to the domain of interest (i.e.,
what such successes mean for our understanding of the                    compare a semantic feature model to a low-level visual word
representational system of the brain. Both theorists (e.g., Haxby        form model). Instead, one or several alternative representational
et al., 2014; Naselaris & Kay, 2015; Naselaris et al., 2011;             models should be tested that are derived from competing
Norman et al., 2006; Tong & Pratte, 2012) and practitioners (e.g.        theories (i.e., semantic model A vs. semantic model B). To
Fernandino et al., 2016; Kay et al., 2008; Mitchell et al., 2008;        illustrate, an elegant comparison of a sensory-based vs. non-
Santoro et al., 2014) have suggested that we can infer that the          sensory-based semantic model was achieved by Anderson et al.
brain uses a certain set of features to encode information, if we        (2015). These authors contrasted a visual model with a word co-
can successfully decode the activity of novel items from such            occurrence model to investigate which brain regions represent
features. However, as we have argued here, this inference is not         modality-specific visual features, and which do not (using
formally valid. Successful decoding might be the result of a             differential correlation in RSA rather than an encoding model).
systematic relationship between the representational system of           The relative superiority of a particular model at predicting
the brain and the stimulus feature set, even if those utilize            activation patterns in a brain region makes it more likely that the
different representational schemes.                                      brain is using the representational scheme of the better
   How do we know whether two representational systems are               performing model rather than the alternative. However, it is
truly different? It could be argued that in our example, both            important to keep in mind that such comparisons only provide
   4
     in fact, because of that linear one-to-one relationship,            perfect decoding accuracy; compare that to the 0.7 decoding
replicating our simulation with these two examples leads to              accuracy for the decimal-to-binary model
                                                                     965

evidence for the relative likelihood of each model, but, due to the          mean activation: why, how, and what does it tell us? Cognitive,
limitations discussed above, still do not allow us to infer that the         Affective & Behavioral Neuroscience, 13(3), 667–673.
winning model is the “true” model.                                         Coutanche, M. N., & Thompson-Schill, S. L. (2015). Creating
   For that reason, besides the assessment of relative model                 Concepts from Converging Features in Human Cortex. Cerebral
performance based on model comparison, a second crucial step                 Cortex, 25(9), 2584–2593.
is to evaluate absolute prediction performance. In particular, the         Davis, T., & Poldrack, R. A. (2013). Measuring neural representations
observed decoding accuracy can be compared to the “noise                     with fMRI: practices and pitfalls. Annals of the New York Academy
ceiling”, or to the “upper limit of prediction accuracy” (Naselaris          of Sciences, 1296(1), 108–134.
et al., 2011), reflecting the maximal performance that can be              Farah, M. J., & McClelland, J. L. (1991). A computational model of
feasibly achieved given the noise present in the signal. The gap             semantic memory impairment: modality specificity and emergent
between the two can be thought of as the variance that is not                category specificity. Journal of Experimental Psychology: General,
explained by the current model, which should motivate and                    120(4), 339.
guide the search for an improved or alternative version of the             Fernandino, L., Humphries, C. J., Conant, L. L., Seidenberg, M. S., &
model. Until such maximal performance is obtained, we should                 Binder, J. R. (2016). Heteromodal Cortical Areas Encode Sensory-
be careful in making strong representational inferences about the            Motor Features of Word Meaning. Journal of Neuroscience, 36(38),
brain from the currently available analytic methods.                         9763–9769.
   Ultimately, many of these inferential caveats exist because             Haxby, J. V., Connolly, A. C., & Guntupalli, J. S. (2014). Decoding
fMRI data is correlational. Comparing alternative models and                 Neural Representational Spaces Using Multivariate Pattern Analysis.
evaluating absolute prediction performance might eventually                  Annual Review of Neuroscience, 37(1), 435–456.
converge on the true underlying feature model, but this is not             Haxby, J. V., Gobbini, M. I., Furey, M. L., Ishai, A., Schouten, J. L., &
guaranteed. We propose that an even better way to test                       Pietrini, P. (2001). Distributed and overlapping representations of
representational hypotheses might be to introduce experimental               faces and objects in ventral temporal cortex. Science, 293(5539),
manipulations that affect the hypothesized representational                  2425–2430.
dimensions. For example, one could prime participants to weight            Kay, K. N., Naselaris, T., Prenger, R. J., & Gallant, J. L. (2008).
some features of the stimuli more than others. If that leads to              Identifying natural images from human brain activity. Nature,
changes in the performance of a classifier based on the primed               452(7185), 352–355.
features, this would constitute much stronger evidence that these          Lee, H., & Kuhl, B. A. (2016). Reconstructing Perceived and Retrieved
features underlie the neural representational scheme in question.            Faces from Activity Patterns in Lateral Parietal Cortex. Journal of
This proposal is logical but it has not been experimentally tested           Neuroscience, 36(22), 6069–6082.
yet, and we look forward to seeing how it will fare in practice.           Mahon, B. Z. (2015). The Burden of Embodied Cognition. Canadian
                                                                             Journal of Experimental Psychology, 69(2), 172–178.
                            References                                     Mitchell, T. M., Shinkareva, S. V., Carlson, A., Chang, K.-M., Malave,
Anderson, A. J., Bruni, E., Lopopolo, A., Poesio, M., & Baroni, M.           V. L., Mason, R. A., & Just, M. A. (2008). Predicting human brain
   (2015). Reading visually embodied meaning from the brain: visually        activity associated with the meanings of nouns. Science, 320(5880),
   grounded computational models decode visual-object mental                 1191–1195.
   imagery induced by written text. NeuroImage, 120, 309-322.              Monaghan, P., Shillcock, R. C., Christiansen, M. H., & Kirby, S. (2014).
Binder, J. R., Desai, R. H., Graves, W. W., & Conant, L. L. (2009).          How arbitrary is language? Phil. Trans. R. Soc. B, 369(1651),
   Where Is the Semantic System? A Critical Review and Meta-                 20130299.
   Analysis of 120 Functional Neuroimaging Studies. Cerebral Cortex,       Naselaris, T., & Kay, K. N. (2015). Resolving ambiguities of MVPA
   19(12), 2767–2796.                                                        using explicit models of representation. Trends in Cognitive Sciences,
Bonnici, H. M., Kumaran, D., Chadwick, M. J., Weiskopf, N., Hassabis,        19(10), 551–554.
   D., & Maguire, E. A. (2012). Decoding representations of scenes in      Naselaris, T., Kay, K. N., Nishimoto, S., & Gallant, J. L. (2011).
   the medial temporal lobes. Hippocampus, 22(5), 1143–1153.                 Encoding and decoding in fMRI. NeuroImage, 56(2), 400–410.
Brouwer, G. J., & Heeger, D. J. (2009). Decoding and reconstructing        Norman, K., Polyn, S., Detre, G., & Haxby, J. (2006). Beyond mind-
   color from responses in human visual cortex. The Journal of               reading: multi-voxel pattern analysis of fMRI data. Trends in
   Neuroscience, 29(44), 13992–14003.                                        Cognitive Sciences, 10(9), 424–430.
Casey, M., Thompson, J., Kang, O., Raizada, R., & Wheatley, T. (2012).     Poldrack, R. (2006). Can cognitive processes be inferred from
   Population Codes Representing Musical Timbre for High-Level               neuroimaging data? Trends in Cognitive Sciences, 10(2), 59–63.
   fMRI Categorization of Music Genres. In Machine Learning and            Poldrack, R. A. (2011). Inferring mental states from neuroimaging data:
   Interpretation in Neuroimaging (pp. 34–41). Springer Berlin               from reverse inference to large-scale decoding. Neuron, 72(5), 692–
   Heidelberg.                                                               697.
Correia, J., Formisano, E., Valente, G., Hausfeld, L., Jansma, B., &       Santoro, R., Moerel, M., Martino, F. D., Goebel, R., Ugurbil, K.,
   Bonte, M. (2014). Brain-Based Translation: fMRI Decoding of               Yacoub, E., & Formisano, E. (2014). Encoding of Natural Sounds at
   Spoken Words in Bilinguals Reveals Language-Independent                   Multiple Spectral and Temporal Resolutions in the Human Auditory
   Semantic Representations in Anterior Temporal Lobe. The Journal           Cortex. PLOS Computational Biology, 10(1), e1003412.
   of Neuroscience, 34(1), 332–338.                                        Tong, F., & Pratte, M. (2012). Decoding Patterns of Human Brain
Coutanche, M. N. (2013). Distinguishing multi-voxel patterns and             Activity. Annual Review of Psychology, 63(1), 483–509.
                                                                       966

