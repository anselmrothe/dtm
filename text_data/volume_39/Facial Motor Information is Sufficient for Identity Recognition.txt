                   Facial Motor Information is Sufficient for Identity Recognition
                                 Jonathan Vitale, Benjamin Johnston, & Mary-Anne Williams
                               {jonathan.vitale, benjamin.johnston, mary-anne.williams}@uts.edu.au
                                  University of Technology Sydney – Centre For Artificial Intelligence
              Innovation and Enterprise Research Lab (The Magic Lab) - 15 Broadway, Ultimo NSW 2007 - Australia
                               Abstract                                  framework was initially designed to only account for cod-
                                                                         ing identity-related features, such as sex, distinctiveness, age
   The face is a central communication channel providing infor-          and attractiveness (Valentine, 1991). Nevertheless, dynamic
   mation about the identities of our interaction partners and their
   potential mental states expressed by motor configurations. Al-        aspects of faces, such as facial expressions, were neglected.
   though it is well known that infants ability to recognise people      Recently, we developed a computational tool building on top
   follows a developmental process, it is still an open question         of the face-space framework (Vitale, Williams, & Jonhston,
   how face identity recognition skills can develop and, in par-
   ticular, how facial expression and identity processing poten-         2016) and able to exhibit interesting features in agreement
   tially interact during this developmental process. We propose         with modern understanding in face processing studies. In par-
   that by acquiring information of the facial motor configuration       ticular, we demonstrated that this novel face-space can repre-
   observed from face stimuli encountered throughout develop-
   ment would be sufficient to develop a face-space representa-          sent both invariant and dynamic features of face stimuli under
   tion. This representation encodes the observed face stimuli as        a shared representation facilitating the recognition of both fa-
   points of a multidimensional psychological space able to as-          cial expression and identity exhibited by novel face stimuli
   sist facial identity and expression recognition. We validate our
   hypothesis through computational simulations and we suggest           (Vitale et al., 2016).
   potential implications of this understanding with respect to the         In this paper we offer a new understanding of this face-
   available findings in face processing.                                space, suggesting that facial identity processing capabilities
   Keywords: face perception; face processing; face-space; face          can plausibly develop by interpreting the motor configuration
   identity processing; face expression processing; mirroring
                                                                         of observed face stimuli.
                                                                            In particular, from a functional level of analysis, we aim
                           Introduction                                  to demonstrate that assuming the existence of an early or
Face processing capabilities are of paramount importance for             innate system M otor(xi ) ⇒ E (xi ) able to map perceptual
the development of social skills (Grossmann, 2015).                      information of the observed face stimulus xi onto a mo-
   Developmental studies suggest that newborns can match                 tor interpretation of the exhibited facial expression E (xi ),
observed facial motor configurations via overt imitative be-             it is possible to develop another system C ognitive(Xnew ) ⇒
haviour (Meltzoff & Moore, 1983, 1992) or covert inner sim-              {E (Xnew ), I (Xnew )} assisting the discrimination of facial ex-
ulation mechanisms (Simpson, Murray, Paukner, & Ferrari,                 pressions E (Xnew ) and identities I (Xnew ) exhibited by newly
2014; Gallese & Caruana, 2016), even well before the devel-              encountered face stimuli Xnew . Therefore, this paper aims to
opment of early cognitive capabilities (but see Oostenbroek              provide computational evidence supporting the following hy-
et al., 2016 and Simpson et al., 2016 for a recent discussion            pothesis:
on the topic). Hence, it has been suggested that facial ex-
pression recognition may be mediated by early neural mech-               Hypothesis: It is possible to generalise the face-space
anisms mapping sensory information of the observed facial                framework to realise a twofold multidimensional space
configuration into a proprioceptive motor format (Gallese &              structure able to facilitate facial expression and identity
Caruana, 2016; Iacoboni, 2009) and therefore assisting imi-              processing capabilities by only interpreting the motor config-
tatory mechanisms (Simpson et al., 2014).                                uration exhibited by the face stimuli encountered during the
   On the contrary, face identity processing capabilities fol-           developmental process.
low a developmental process (Grossmann & Vaish, 2009).
Currently, facial identity processing development is not yet             This work is a significant contribution able to provide
well understood. For example, we do not know yet where in                a plausible explanation unifying traditional and modern
the face processing hierarchy representations of invariant (i.e.         findings in face processing studies, as we will discuss in the
identity features of the face) and dynamic (i.e. motor features          remainder of this paper.
of the face) features interact (Simion & Di Giorgio, 2015).
   According to the ‘face-space’ framework (Valentine, 1991;                                  Previous Findings
Valentine, Lewis, & Hills, 2015), facial representations are             Recently, we provided a novel understanding of the face-
encoded in a multidimensional psychological space. The di-               space framework (Vitale et al., 2016). The face-space frame-
mensions of this space are assumed to encode properties of               work is a widely used tool in face perception and process-
the facial signals that better discriminate one face from an-            ing research able to explain many of the phenomena underly-
other. The distance between two representations underlies                ing facial identity discrimination in both human experimen-
their dissimilarity from a psychological perspective. This               tal settings (Lee, Byatt, & Rhodes, 2000; Rhodes, Jaquet, et
                                                                     3447

Figure 1: The dual face-space presents a twofold structure: on
                                                                      Figure 2: An example of face-space development resulting by
one side it allows observations with similar motor configura-
                                                                      applying the mapping function in Equation 2. Face samples
tions to lie within close spatial locations (l), whereas at the
                                                                      belonging to the same identity are on average perceptually
same time “repulsing” observations of similar identities away
                                                                      closer to each other, thus being a bias for the classification of
(a `); on the other side, it happens exactly the viceversa. This
                                                                      facial expressions.
facilitates respectively facial expression and identity recogni-
tion, under common multidimensional codings.
                                                                      mension d  D and it ensures desirable properties in sub-
                                                                      sequent stages of the model (e.g. positive definiteness, see
al., 2011) and computational simulations (A. J. Calder, Bur-          Vitale et al., 2016):
ton, Miller, Young, & Akamatsu, 2001). This framework is                                                 >
                                                                                                  X̄ = Vpca X                       (1)
so important in face studies that it is “virtually impossible
to explain the interactions between the computational and                 It is important to note that in this paper we do not aim
cognitive approaches to understanding face recognition with-          to test the classification performance of the proposed model
out reference to this model. It serves as the glue that binds         against other computational models of face recognition, but
the theoretical and computational aspects of the problem to-          rather the plausibility of the proposed hypothesis in providing
gether” (A. Calder, 2011, page 17).                                   a new understanding of the mechanisms potentially underly-
                                                                      ing human face processing skills. Therefore, in our studies
   According to Valentine’s face-space, faces are points of
                                                                      we used the pixels intensities of static images as input to our
a multidimensional space based on their perceived proper-
                                                                      models to provide a simplified linear understanding of our
ties. This structure can plausibly account for coding identity-
                                                                      theory and related argument. Importantly, the input X̄ can be
related features. Unfortunately, dynamic aspects of the face,
                                                                      any vector of features extracted by the given face stimuli and
such as its motor configuration, were neglected in the tradi-
                                                                      able to encode perceptual information of the observed stim-
tional face-space account. This is a significant limitation, pre-
                                                                      uli. Therefore, a viable non-linear alternative of our model
venting the analysis of the interactions happening between
                                                                      can be obtained by pre-processing the input face stimuli X
facial expression and facial identity processing.
                                                                      by using an unsupervised deep neural network model trained
   Therefore, to fill this gap, we introduced a novel hypothe-
                                                                      to preserve invariant and dynamic features of the face in a
sis: the duality hypothesis. This hypothesis suggests that the
                                                                      more compressed and smart representation (Le et al., 2013),
face-space can plausibly exhibit a twofold structure integrat-
                                                                      instead of the proposed linear PCA. Finally, temporal dynam-
ing both dynamic and invariant features of the face into shared
                                                                      ics can be included by pre-processing a set of consecutive
codings, although preserving some separation among them to
                                                                      stimuli instead of static images, or by using other techniques
facilitate both facial expression and identity recognition (see
                                                                      improving temporal coherence in the resulting pre-processed
Figure 1 for a visual example). We named this understanding
                                                                      representation (Mobahi, Collobert, & Weston, 2009). These
with dual face-space and we validated the hypothesis, from a
                                                                      computational pre-processing stages resemble early process-
computational perspective, through a mathematical presenta-
                                                                      ing of human visual cortex and are therefore suitable exam-
tion and quantitative results.
                                                                      ples for potential future extensions of our theory and related
The Dual Face-Space                                                   model.
                                                                          In our previous work (Vitale et al., 2016), we showed that
Given a set of face stimuli shaped as column vectors of a
                                                                      it is possible to implement the dual face-space by solving the
matrix X, these stimuli have dimension D equal to the total
                                                                      following objective function:
number of pixels representing each face stimulus. By submit-
ting the matrix X to a Principal Component Analysis (PCA)                                         Tr(V > X̄(IN −W E )X̄ >V )
(Turk & Pentland, 1991) it is possible to obtain a mapping                        V ? = arg min                                     (2)
                                                                                         V ∈Rd×d Tr(V > X̄(IN −W I )X̄ >V )
matrix Vpca able to map the D-dimensional face stimuli X
into compressed d-dimensional representations X̄. This pro-           where W E and W I are two weight matrices setting desired
cess preserves most of the information carried by the face            topological constraints on the face-space via the resulting ob-
stimuli, but it compresses them in representations having di-         jective mapping matrix V ? . It is possible to obtain the weight
                                                                  3448

matrix W E by knowing the facial expressions exhibited by the               the training face stimuli. In this way the weight matrix W I
training samples and, when this matrix is used in Equation 2,               in Equation 2 can be replaced by the matrix W ∆ , thus realising
it encourages pairs of samples associated with the same fa-                 the following objective function:
cial expression to be in nearby locations in the resulting face-
space:                                                                                                      Tr(V > X̄(IN −W E )X̄ >V )
                                                                                       V ∆? = arg min                                               (6)
                                                                                                  V ∈Rd×d   Tr(V > X̄(IN −W ∆ )X̄ >V )
                                , if E (xi ) = E (x j )
                         (
                             1
                  WiEj = nEi                                        (3)     The optimal solution of the objective function in Equation 6
                            0,      otherwise.                              is the mapping matrix V ∆? . Thus, given a mapping matrix
   In Equation 3, nEi is the number of samples in X belonging               Vpca gathered by submitting the training data X to a PCA, as
to the facial expression class E (xi ) of the face stimulus xi in           previously described, it is possible to obtain the final mapping
                                                                                      ∆
                                                                            matrix Voverall realising the ∆ face-space as following:
the column i of matrix X.
   It is possible to realise the weight matrix W I by knowing                                             ∆
the identities exhibited by the training samples and, when this                                        Voverall = VpcaV ∆?                          (7)
matrix is used in Equation 2, it promotes repulsive forces be-                 The mapping matrix Voverall      ∆      is able to realise face-
tween pairs of samples belonging to the same identity, thus re-             space representations facilitating facial expression recogni-
ducing misclassification of facial expressions due to the iden-             tion, whereas the mapping matrix Ṽoverall    ∆              ∆
                                                                                                                                = σ(Voverall    ), hav-
tity bias (Sariyanidi, Gunes, & Cavallaro, 2015):                                                                 ∆
                                                                            ing the same component of Voverall but permutated in the in-
                                                                            verse order, realises representations able to facilitate facial
                                , if I (xi ) = I (x j )
                         (
                             1
                   I
                 Wi j = nIi                                         (4)     identity discrimination, although without the need of know-
                           0,       otherwise.                              ing the identities exhibited by the training samples, as sug-
   In Equation 4, nIi is the number of samples in X belong-                 gested by our hypothesis.
ing to the identity class I (xi ) of the face stimulus xi in the            Defining the New Weight Matrix
column i of matrix X. Figure 1 and Figure 2 show examples
                                                                            The purpose of the weight matrix W I in Equation 2 is to
of the rationale behind the constraints set by the suggested
                                                                            avoid that two face stimuli sharing the same identity, but ex-
weight matrices in Equation 2.
                                                                            hibiting different facial expressions, would get projected to
   Finally, given a generic matrix M and the following permu-
                                                                            nearby locations of the face-space promoting their misclas-
tation function:
                        1                                                  sification in the same facial expression class (see Figure 2).
                                  m2       m3      . . . md
                                                             
                         m                                                  This misclassification can easily happen since face stimuli
      M̃ = σ(M) =                                                   (5)
                         md md−1 md−2 . . . m1                              of the same identity share most of their perceptual features,
                                                                            and, on average, they are close-by in the perceptual space
permutating each column vector mi with i ∈ [1, . . . , d] of the            (Sariyanidi et al., 2015; Turk & Pentland, 1991). This prop-
matrix M in the inverse order1 we demonstrated that Equa-                   erty exhibited by face stimuli can be used to our advantage to
tion 2 is sufficient to provide multidimensional representa-                realise the desired weight matrix W ∆ .
tions able to facilitate both facial identity and expression                   For each of the N training face stimuli xi , shaped as column
recognition (Vitale et al., 2016).                                          vectors i ∈ [1, . . . , N] of the matrix X, we denote with ∆xi the
   In fact, given V ? as the optimal solution of the objective              set containing the perceptual distances δ(xi , x j ) between the
function in Equation 2, we demonstrated that the mapping                    face stimuli xi and the face stimulus x j ∈ X with i 6= j and
matrix Ṽ ? = σ(V ? ) is the optimal solution of another ob-                exhibiting a different facial expression from the one exhibited
jective function promoting facial identity discrimination ob-               by xi :
tained by inverting Equation 2. The mapping matrix Ṽ ? is
dual to the mapping matrix V ? , since it shares the same com-                  ∆xi = {δ(xi , x j ) | x j ∈ X ∧ xi 6= x j ∧ E (x j ) 6= E (xi )}    (8)
ponents (i.e. column vectors) of V ? but sorted in the opposite
order. Therefore, the objective function in Equation 2 realises                Since face stimuli of the same identity are perceptually
common codings able to facilitate on one hand facial expres-                close, their respective distances would be, at least on average,
sion classification (V ? ), and on the other hand facial identity           well below their distances from face stimuli with different
discrimination (Ṽ ? ).                                                     identities. Then, given the mean µ∆xi and standard deviation
                                                                            σ∆xi of the distances included in the set ∆xi it is possible to
                        The ∆ Face-Space                                    compute the set Ii≈ described as follow:
To validate our hypothesis, we suggest to approximate the                                 Ii≈ = {x j | δ(xi , x j ) < µ∆xi − βσ∆xi }                (9)
weight matrix W I with another weight matrix W ∆ imple-
mented without necessarily knowing the identity classes of                  where β is a parameter suggesting how many standard devi-
    1 In this paper we will use the notation M̃ to denote a matrix hav-     ations below the mean distance would be set the maximum
ing the same column vectors of another matrix M, but sorted in an           threshold. In this work, β was set equal to 2.5 after empir-
inverse order.                                                              ical tests with face stimuli gathered from different datasets
                                                                        3449

available in face recognition literature. The resulting set Ii≈         With each training data we estimated the mapping ma-
includes most of the training samples sharing the same iden-                ∆
                                                                     trix Voverall of the ∆ face-space proposed in this chapter as
tity of the sample xi .                                              per Equations 6 and 7. Then, each test sample was mapped
   Therefore, the weight matrix W ∆ can be realised as follow:       onto the ∆ face-space, thus obtaining the encodings Y ∆E =
                                                                       ∆> X and Y ∆I = Ỹ ∆E = Ṽ ∆> X, respectively used dur-
                                                                     Voverall                         overall
                       n∪i j , if x j ∈ Ii ∨ xi ∈ I j
                                          ≈         ≈
                    ( 1
                ∆                                                    ing the expression and identity recognition tasks for the ∆
             Wi j =                                         (10)
                      0,       otherwise.                            face-space condition.
                                                                        For each iteration, we compared the performance of the
where n∪i j is the number of unique samples in the set Ii≈ ∪         ∆ face-space against a baseline approach. The baseline ap-
I j≈ . The realised weight matrix W ∆ is clearly symmetric and       proach used all the pixels of the face stimuli to match sim-
the associated Laplacian behaves as a block centring matrix,         ilar facial expressions or identities. This is a fair method-
thus promoting a norm-based space (for in-depth details and          ology considering we pre-processed raw pixels data with a
mathematical proof refer to Vitale et al. (2016)). The objec-        simple PCA. In our previous contribution (Vitale et al., 2016)
tive function in Equation 6 can be solved through the iterative      we showed that the baseline and PCA performance are not
algorithm proposed by Ngo, Bellalij, and Saad (2012), simi-          differing. Thus, we used this approach as our baseline to
larly to our previous contribution (Vitale et al., 2016).            demonstrate that matching the expressions and identities of
                                                                     the considered dataset samples in the perceptual space was
                         Experiments                                 not a trivial task and that our psychological face-space can
In this paper, we will evaluate the proposed model using             indeed facilitate facial expression and identity recognition.
the Karolinska Directed Emotional Faces (KDEF) dataset                  The classification was performed using the nearest neigh-
(Lundqvist, Flykt, & Öhman, 1998), similarly to our previ-          bour algorithm. For each sample, xi , used by the baseline ap-
ous contribution. The dataset contains static images of 70           proach, and y∆i , used by the face-space model, we computed
subjects—35 female and 35 male—exhibiting seven differ-              the Euclidean distances from the centroids of each class in
ent prototypical facial expressions of basic emotions (anger,        the corresponding space, and we selected the class associated
disgust, fear, happiness, neutral, sadness and surprise). The        with the centroid closer to the sample.
pictures are taken in various face orientations and in two dif-         For each test sample during each iteration, the baseline ap-
ferent sessions (A and B).                                           proach provided a single prediction. Instead, our face-space
   We used the frontal pictures taken in session A. We ex-           model can use the first k = [1, . . . , d] components of the map-
                                                                                     ∆
                                                                     ping matrix Voverall  to map the face stimuli in face-space rep-
tracted the facial region from the images and reduced their
resolution to 80 × 80 pixels. Eyes and mouth were at ap-             resentations and perform recognition tasks. Thus, our model
proximately the same position. Illumination variations were          provided d predictions for each test sample during each it-
reduced by applying a simple equalisation process to the im-         eration. To gather a single prediction, we selected the most
ages (using the histeq function available in Matlab software).       frequent class (mode) predicted by the face-space model for
   We first pre-processed the data by submitting the pixels of       each test sample during each iteration, as per a majority vot-
the images in input to a PCA as explained previously. We             ing approach. For each iteration, we then computed the over-
retained the components able to explain 95% of the variance          all recognition rate for the baseline approach and the ∆ face-
of the original data resulting in 200 components.                    space in both facial expression and identity recognition con-
                                                                     ditions. This process led to 35 samples for each considered
Procedure                                                            approach and task.
The present experiment tests the ability of the new ∆ face-
space, implemented without knowing the identity labels of            Results
the training stimuli, to support subsequent processes of iden-       The distribution of the sampled recognition rates was first
tity and facial expression recognition.                              assessed for normality using a D’Agostino’s K-squared test
   In both the two conditions (i.e. facial expression and iden-      (D’Agostino & Pearson, 1973) finding that the samples from
tity recognition) we used repeated random iterations of the          both facial expression and identity tasks followed a normal
dataset’s samples (in this work 35 iterations for both the           distribution (p-values respectively 0.8571 and 0.1382). Thus,
tasks). In each iteration 25 subjects were randomly selected         the effect between the baseline approach and our face-space
as the test set among the 70 possible subjects to simulate un-       model were evaluated by a Student’s t-test (Keppel, 1991) at
familiar identities. For each of the 25 selected subjects were       a significant level of α = 0.01. The effect size was assessed
randomly chosen 2 facial expressions as probes for the iden-         by computing Cohen’s d (Cohen, 1977).
tity recognition task, and the remaining 5 facial expressions           The results for facial expression and identity recognition
as test samples, leading to a total of 125 test samples for each     are shown in Figure 3a and Figure 3b respectively. From the
iteration. The images of the other 45 subjects, together with        plots, it is possible to see that the novel ∆ face-space can fa-
the 50 selected probes, were used as the training set of the         cilitate both facial expression and identity recognition.
current iteration, leading to 365 training samples for each it-         In addition, the t-tests rejected the null hypothesis in both
eration.                                                             facial expression (p-value=6.5e−19) and facial identity (p-
                                                                 3450

                          (a)                                                                            (b)
Figure 3: Comparative analysis of the performance. (a,b) The recognition rates of the baseline approach and our face-space
model respectively during facial expression and facial identity recognition tasks.
value=1.6e−6) recognition tasks. The computed effect size             with emotional processing capabilities (Adolphs, 2002) and
suggested a large effect for both the two tasks (d = 3.03             interactions were observed between the STS and the LFG
for facial expression recognition and d = 0.98 facial iden-           (Haxby et al., 2000). Recent neuroscience studies suggest
tity recognition). The statistics reached high powers (both           that the STS is also related to mirroring mechanisms and im-
> 0.98).                                                              itative capabilities (Buxbaum, Shapiro, & Coslett, 2014) and
                                                                      Molenberghs, Brander, Mattingley, and Cunnington (2010)
      Potential Implications of the Hypothesis                        provided evidence suggesting that the role of the STS in im-
Although we validated our hypothesis through computational            itation is not only to passively register observed biological
simulations and it is not our aim to suggest that human brain         motion, but rather to actively represent sensory-motor corre-
implements the proposed face-space in this way, in this sec-          spondences between one’s actions and the actions of others.
tion we will discuss how these results can be of major impor-         Therefore, the STS, assisted by putative emotional brain areas
tance for cognitive science community, at least by focusing at        like the amygdala, can plausibly provide information neces-
a functional level of analysis.                                       sary to interpret the observed facial expression, as suggested
                                                                      in this paper with the assumed system M otor. This informa-
   Modern literature in face perception studies widely sug-
                                                                      tion, in turn, can be then used by the LFG to develop facial
gest interactions between invariant and dynamic features of
                                                                      identity recognition capabilities, as proposed by the psycho-
face stimuli. For instance, it has been shown that women
                                                                      logical face-space discussed in this paper.
and younger individuals appear to increase cues associated
with happiness, whereas men and older people those of anger
                                                                                              Conclusions
(Becker, Kenrick, Neuberg, Blackwell, & Smith, 2007) and
studies in face processing broadly suggest that face stimuli          We provided a new understanding of the face-space frame-
can be plausibly represented in multidimensional norm-based           work proposed by Valentine (1991) and able to realise a
spaces (Rhodes & Jeffery, 2006; Rhodes, Leopold, Calder,              twofold structure encoding invariant and dynamic features
& Rhodes, 2011) and that invariant and dynamic codings of             of the face under shared codings and consequently facili-
these spaces interact (A. J. Calder et al., 2001).                    tating facial expression and identity recognition capabilities.
   Interestingly, the proposed hypothesis well integrates with        This face-space can develop by only interpreting motor be-
traditional understandings in face studies suggesting distinct        haviour exhibited by face stimuli encountered during devel-
routes processing invariant and dynamic features of the face,         opment. We demonstrated the validity of our claim by pro-
while still supporting more recent findings suggesting that           viding compelling computational evidence and we discussed
representations of invariant and dynamic facial features par-         the potential implications of this new theoretical understand-
tially overlap (Pell & Richards, 2013). In fact, Haxby, Hoff-         ing in face perception and processing studies. Future works
man, and Gobbini (2000) suggest that changeable aspects of            aim in extending the model with non-linear techniques and
the face (i.e. eye gaze, expression and lip movement) are             possibly include temporal features, while at the same time
processed in the Superior Temporal Sulcus (STS), whereas              testing the theory by collecting human data from perceptual
invariant aspects of the face necessary to classify the exhib-        experiments.
ited identity are processed in a distinct brain area, the Lateral
Fusiform Gyrus (LFG). The STS presents neural connections                                      References
with the amygdala and other brain areas usually associated            Adolphs, R. (2002). Neural systems for recognizing emotion.
                                                                  3451

  Current Opinion in Neurobiology, 12(2), 169–177.                  Mobahi, H., Collobert, R., & Weston, J. (2009). Deep learn-
Becker, D. V., Kenrick, D. T., Neuberg, S. L., Blackwell, K.,         ing from temporal coherence in video. In Proceedings
  & Smith, D. M. (2007). The confounded nature of angry               of the 26th Annual International Conference on Machine
  men and happy women. Journal of Personality and Social              Learning (pp. 737–744).
  Psychology, 92(2), 179.                                           Molenberghs, P., Brander, C., Mattingley, J. B., & Cunning-
Buxbaum, L. J., Shapiro, A. D., & Coslett, H. B. (2014).              ton, R. (2010). The role of the superior temporal sulcus
  Critical brain regions for tool-related and imitative actions:      and the mirror neuron system in imitation. Human Brain
  a componential analysis. Brain.                                     Mapping, 31(9), 1316–1326.
Calder, A. (2011). Oxford handbook of face perception. Ox-          Ngo, T. T., Bellalij, M., & Saad, Y. (2012). The trace ratio
  ford University Press.                                              optimization problem. SIAM review, 54(3), 545–569.
Calder, A. J., Burton, A. M., Miller, P., Young, A. W., &           Oostenbroek, J., Suddendorf, T., Nielsen, M., Redshaw, J.,
  Akamatsu, S. (2001). A principal component analysis of              Kennedy-Costantini, S., Davis, J., . . . Slaughter, V. (2016).
  facial expressions. Vision Research, 41(9), 1179–1208.              Comprehensive longitudinal study challenges the existence
Cohen, J. (1977). Statistical power analysis for the behav-           of neonatal imitation in humans. Current Biology, 26(10),
  ioral sciences (revised ed.). New York: Academic Press.             1334–1338.
D’Agostino, R., & Pearson, E. (1973). Tests for departure           Pell, P. J., & Richards, A. (2013). Overlapping facial ex-
  from normality. empirical results for the distributions of b2       pression representations are identity-dependent. Vision Re-
  and b1. Biometrika, 60(3), 613–622.                                 search, 79, 1–7.
Gallese, V., & Caruana, F. (2016). Embodied simula-                 Rhodes, G., Jaquet, E., Jeffery, L., Evangelista, E., Keane,
  tion: beyond the expression/experience dualism of emo-              J., & Calder, A. J. (2011). Sex-specific norms code face
  tions. Trends in Cognitive Sciences.                                identity. Journal of Vision, 11(1), 1.
Grossmann, T. (2015). The development of social brain func-         Rhodes, G., & Jeffery, L. (2006). Adaptive norm-based cod-
  tions in infancy. Psychological Bulletin, 141(6), 1266.             ing of facial identity. Vision Research, 46(18), 2977–2987.
                                                                    Rhodes, G., Leopold, D. A., Calder, A., & Rhodes, G. (2011).
Grossmann, T., & Vaish, A. (2009). Reading faces in in-
                                                                      Adaptive norm-based coding of face identity. The Oxford
  fancy: developing a multi-level analysis of social stimulus.
                                                                      Handbook of Face Perception, 263–286.
  In T. Striano & V. Reid (Eds.), Social cognition: Devel-
                                                                    Sariyanidi, E., Gunes, H., & Cavallaro, A. (2015). Automatic
  opment, neuroscience and autism. Oxford, UK: Blackwell
                                                                      analysis of facial affect: A survey of registration, repre-
  Publishing.
                                                                      sentation, and recognition. IEEE Transactions on Pattern
Haxby, J. V., Hoffman, E. A., & Gobbini, M. I. (2000).
                                                                      Analysis and Machine Intelligence, 37(6), 1113–1133.
  The distributed human neural system for face perception.
                                                                    Simion, F., & Di Giorgio, E. (2015). Face perception and
  Trends in Cognitive Sciences, 4(6), 223–233.
                                                                      processing in early infancy: inborn predispositions and de-
Iacoboni, M. (2009). Do adolescents simulate? developmen-
                                                                      velopmental changes. Frontiers in Psychology, 6.
  tal studies of the human mirror neuron system. In T. Striano
                                                                    Simpson, E. A., Maylott, S. E., Heimann, M., Subiaul, F.,
  & V. Reid (Eds.), Social cognition: Development, neuro-
                                                                      Paukner, A., Suomi, S. J., & Ferrari, P. F. (2016). Com-
  science and autism. Oxford, UK: Blackwell Publishing.
                                                                      mentary on “Animal studies help clarify misunderstandings
Keppel, G. (1991). Design and analysis: A researcher’s                about neonatal imitation” by Keven and Akins.
  handbook. Prentice-Hall, Inc.                                     Simpson, E. A., Murray, L., Paukner, A., & Ferrari, P. F.
Le, Q. V., Ranzato, M., Monga, R., Devin, M., Chen, K.,               (2014). The mirror neuron system as revealed through
  Corrado, G. S., . . . Ng, A. Y. (2013). Building high-level         neonatal imitation: presence from birth, predictive power
  features using large scale unsupervised learning. In IEEE           and evidence of plasticity. Philosophical Transactions of
  International Conference on Acoustics, Speech and Signal            the Royal Society B, 369(1644).
  Processing (ICASSP) (pp. 8595–8598).                              Turk, M., & Pentland, A. (1991). Eigenfaces for recognition.
Lee, K., Byatt, G., & Rhodes, G. (2000). Caricature effects,          Journal of Cognitive Neuroscience, 3(1), 71–86.
  distinctiveness, and identification: Testing the face-space       Valentine, T. (1991). A unified account of the effects
  framework. Psychological Science, 11(5), 379–385.                   of distinctiveness, inversion, and race in face recognition.
Lundqvist, D., Flykt, A., & Öhman, A. (1998). The karolin-           The Quarterly Journal of Experimental Psychology, 43(2),
  ska directed emotional faces (KDEF). CD ROM from                    161–204.
  Department of Clinical Neuroscience, Psychology section,          Valentine, T., Lewis, M. B., & Hills, P. J. (2015). Face-
  Karolinska Institutet, 91–630.                                      space: A unifying concept in face recognition research. The
Meltzoff, A. N., & Moore, M. K. (1983). Newborn infants               Quarterly Journal of Experimental Psychology, 1–24.
  imitate adult facial gestures. Child Development, 702–709.        Vitale, J., Williams, M.-A., & Jonhston, B. (2016, August).
Meltzoff, A. N., & Moore, M. K. (1992). Early imitation               The face-space duality hypothesis: a computational model.
  within a functional framework: The importance of person             In 38th Annual Meeting of the Cognitive Science Society
  identity, movement, and development. Infant Behavior and            (p. 514-519).
  Development, 15(4), 479–505.
                                                                3452

