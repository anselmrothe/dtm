            Functionally localized representations contain distributed information:
                   insight from simulations of deep convolutional neural networks
                                               Nicholas Blauch (nblauch@umass.edu)
                                                    University of Massachusetts, Amherst
                                          Center for the Neural Basis of Cognition, Pittsburgh PA
                                                               Elissa Aminoff
                                              Department of Psychology, Fordham University
                                          Center for the Neural Basis of Cognition, Pittsburgh PA
                                                               Michael J. Tarr
                                          Department of Psychology, Carnegie Mellon University
                                          Center for the Neural Basis of Cognition, Pittsburgh PA
                              Abstract                                   modular processing within that region, leading to the authors
  Preferential activation to faces in the brain’s fusiform gyrus has
                                                                         renaming the region in terms of the modular processing (e.g.
  led to the proposed existence of a face module termed the              Fusiform Face Area). Not all authors agreed that preferential
  Fusiform Face Area (FFA) (Kanwisher et. al, 1997). However,            activation of a cortical region by a certain stimulus class was
  arguments for distributed, topographical object-form                   convincing evidence of underlying modular processing.
  representations in FFA and across visual cortex have been              Haxby et. al (2001) used multi-variate pattern analysis
  proposed to explain data showing that FFA activation patterns          (MVPA) to demonstrate that putative functional modules for
  contain decodable information about non-face categories                processing of scenes in the PPA and faces in the FFA contain
  (Haxby et. al, 2001; Hanson & Schmidt, 2011). Using two deep
  convolutional neural network models able to perform human-             patterns of activation useful for decoding whether a subject
  level object and facial recognition, respectively, we                  is viewing one of two categories not thought to be processed
  demonstrate that both localized category representations               within the module. These authors interpreted their findings in
  (LCRs) and high-level face-specific representations allow for          the context of an “object-form topography” model, in which
  similar decoding accuracy between non-preferred visual                 the ventral temporal cortex possesses a distributed,
  categories as between a preferred and non-preferred category.          topographical representation of object-form features which
  Our results suggest that neuroimaging of a cortical “module”
                                                                         underlie all forms of visual recognition. In their account, the
  optimized for face processing should yield significant
  decodable information for non-face categories so long as               large responses found in proposed functional modules are
  representations within the module are activated by non-face            complemented by small responses throughout ventral
  stimuli.                                                               temporal cortex in computations underlying visual
                                                                         categorization and other aspects of visual cognition.
  Keywords: module, localized categorical representation,
  distributed object-form topography, deep convolutional neural             Later, Spiridon & Kanwisher (2002) ran a similar fMRI
  network, virtual electrophysiology                                     study incorporating greater variability across images within a
                                                                         category (e.g. different viewpoints, exemplars, and image
                         Introduction                                    formats) in order to determine whether decodable abstract
                                                                         category information was truly distributed equally
          How are mental representations organized in the
                                                                         throughout ventral temporal cortex, as was argued by Haxby
brain? Do certain brain regions contain functional modules,
                                                                         et. al (2001), or whether there might be localized decoding
dedicated to representing and processing a very specific type
                                                                         advantages corresponding to the locations of proposed
of information? Or is neural real estate more generally
                                                                         functional modules. This study demonstrated that some
involved in the processing of many different types of stimuli?
                                                                         abstract categorical information was present for certain
Evidence from fMRI has been used to propose the existence
                                                                         categories outside their region of maximal activation (i.e. the
of functional modules for the processing of certain classes of
                                                                         location of a proposed module), replicating a main finding of
visual information within the brain. Cortical modularity was
                                                                         Haxby et. al (2001). However, controlling for the number of
proposed first for the visual processing of faces in the so-
                                                                         voxels used in decoding analysis, this study demonstrated
called Fusiform Face Area (FFA) (Kanwisher et. al, 1997),
                                                                         strong advantages in decodable information relating to
then for the visual processing of scenes/places in the so-called
                                                                         discrimination between a preferred category (e.g. faces) and
Parahippocampal Place Area (PPA) (Epstein & Kanwisher,
                                                                         a non-preferred category (e.g. houses) in the region of
1998), and then for the visual processing of body parts in the
                                                                         proposed modularity (e.g. FFA). Additionally, in PPA and
so-called Extrastriate Body Area (EBA) (Downing et. al,
                                                                         FFA, distinct disadvantages were found for the decoding of
2001). In each of these studies, preferential activation of a
                                                                         two non-preferred categories (e.g. faces vs. objects and
certain class of visual stimuli (e.g. faces) in a certain region
                                                                         objects vs. houses, respectively). Thus, while abstract
of the brain (e.g. fusiform gyrus) was used as evidence for
                                                                     136

categorical information of certain categories may exist            representations proposed by Haxby et. al (2001), in that a
outside the region where modular processing is proposed,           single value represents the abstract category information.
such abstract categorical information is by no means equally       However, localized category representations receive input
distributed throughout ventral temporal cortex. The authors        from a processing layer which is well-described as a
thus argued for a more modular account of PPA and FFA,             topographical object-form representation; thus, they are not
whereby these regions are primarily involved in the                true “modules”. The second type of representation is taken as
processing of a single category of information (scenes/houses      a deep layer of face-specific representations within the face-
and faces, respectively).                                          individuation network of Parki, Vedaldi, and Zimmerman
   To account for both sets of findings, Cowell & Cottrell         (2015), VGG-Face, which is optimized for facial recognition
(2013) performed multi-variate pattern analysis (MVPA) on          only. In our view, VGG-Face in toto is a face-dedicated
a neurocomputational model capable of discriminating               module; that is, a system optimized on and dedicated to to the
between the 6 visual categories used in the analyses of Haxby      processing of faces, only. The deep layer was chosen as a
et. al (2001). The neurocomputational model first applies          layer with high-level, complex face-specific features useful
Gabor filtering of input images to obtain a perceptual             for recognition, but not explicitly representing individuals.
representation; it then feeds the activations of many Gabor        We think that such representations are a reasonable model for
filters into a self-organizing Kohonen map, which utilizes         what is proposed to be encoded in FFA (see Kanwisher &
unsupervised learning to cluster its inputs into a two-            Yovel, 2006). We perform “virtual electrophysiology,”
dimensional representation. While the neurocomputational           (Yamins & DiCarlo, 2016) on both systems in order to
model contained no modular mechanisms, through                     determine whether these two types of category-specific
unsupervised learning it developed the types of functionally       representations produce the characteristic signal used to
localized stimulus representations used to argue in favor of       argue for distributed category-general representations:
modular processing, whereby certain patches of the Kohonen         decodable information for non-preferred categories.
grid contained both preferential activation and enhanced
decodable information about some categories. The effects                                       Method
were greatest for faces. Because they were able to simulate                  Model simulations were run in the MATLAB
the data used to argue both for localized and distributed          programming environment, using the MatConvNet toolbox
topographical representation with a neurocomputational             (Vedaldi & Lenc, 2015). Both models used in this study are
model of distributed topographical representations that is         examples of deep convolutional neural networks (DCNNs).
more parsimonious than one postulating the existence of            Such networks were developed by computer vision
functional modules, the authors rejected the interpretation of     researchers as engineering solutions for problems of visual
a functional module for face processing based on the data of       recognition (e.g. LeCun et. al, 1998; Krizhevsky et. al, 2012).
Spiridon & Kanwisher (2002).                                       DCNNs contain several layers of processing, each of which
   The result of Cowell & Cottrell (2013) demonstrates that        contains a set of mathematical filtering operations (units or
the evidence used to postulate functional modules may be           filters) which are convolved across the input, usually
accounted for by a model employing a distributed                   followed by a set of fully-connected layers which contain
representation. However, the model is unable to account for        units which apply simple weighted summations of the units
human-level behavioral performance, and rather was                 at the layer before. In all DCNNs for visual categorization,
constrained only to perform 6-way visual categorization. In        there exists a final layer of processing containing a set of units
the age of biologically-inspired computational systems             whose size is equal to the number of categories to be tested
capable of human-level object categorization (e.g.                 from, where each unit’s activation corresponds to the
Krizhevsky et. al, 2012) and face individuation (e.g. Parki,       likelihood that a certain category is present in the image; this
Vedaldi, and Zimmerman, 2015), such behavioral constraints         vector of information is typically transformed via a softmax
should become standard practice for models of neural               operation into explicit probabilities that the image may be
representation. The decision not to constrain the                  categorized into each possible category.
computational model to perform human level face                       The first DCNN model used is AlexNet (Krizhevsky et. al,
individuation, for example, belies the need for a functional       2012), pre-trained and uploaded to MatConvNet by Vedaldi
module for face processing. Thus, we examine two deep,             & Lenc (2015). AlexNet was trained to perform 1000-way
convolutional neural networks (DCNNs), one trained for             categorization of visual images on the 2011 ImageNet
large-scale object categorization and one trained for expert       training set, which contains 1.2 million images evenly
face individuation. In these networks, we focus on two types       distributed across 1000 categories. For simulations, a
of category-specific representations for analysis. The first       different set of images not used in training, the 2011
type of representation is the localized categorical                ImageNet validation set, was used as stimuli, containing 50
representation (LCR), found in the final hidden layer of           images for each of 1000 categories. First, we recorded the
AlexNet (Krizhevsky et. al, 2012), whereby a single unit           activation patterns of each unit within AlexNet to each image
represents the likelihood of a given category in an image          of the validation set. While the network is said to contain 5
shown to the network. Such a localized categorical                 convolutional layers and 3 fully-connected layers, additional
representation differs from the topographical object-form          intermediate        operations       (rectification,    pooling,
                                                               137

normalization) result in 22 stages of processing with                Vedaldi, and Zimmerman, 2015). To achieve a representation
activation values, where the first stage is defined by the RGB       to serve as a model of FFA representations, we examine the
coordinates of the image. Full details on AlexNet can be             activations in layer 35, the final layer before activations are
found in the original paper (Krizhevsky et. al, 2012).               condensed to individual face-specific representations. Layer
   In our initial analyses, we consider four representative          35 contains 4096 nodes representing high-level, complex
layers within AlexNet (Conv1, Conv5, FC6, and FC8) to                information optimized for face individuation. In performing
demonstrate how informational content changes with depth             virtual electrophysiology on VGG-Face, we use as stimuli the
in the network (Figure 1). The activation patterns of Conv1          fMRI localizer stimulus sets for faces, body-parts, objects,
are those which are input directly to Conv2, thus occurring          and scenes, in addition to the 2011 ImageNet validation set.
after rectification, max-pooling, and response normalization.        These localizer sets are used by TarrLab and many other
The activation patterns of Conv5 are taken after the fifth           laboratories in the Center for the Neural Basis of Cognition,
convolution and rectification, and are the inputs to FC6. The        Pittsburgh PA, for fMRI research in order to localize
patterns of fully-connected layers FC6 and FC8 are taken             functionally-defined regions such as the Fusiform Face Area
after rectification. For each unit of each layer considered, we      (FFA), Extrastriate Body Area (EBA), Lateral Occipital area
compute a set of “categorical signal-to-noise ratios” (cSNRs),       (LO), and Parahippocampal Place Area (PPA). Each localizer
for each category of ImageNet. For a given unit and category,        set contains 80 images of the category used to localize a
the cSNR is computed as the signal-to-noise ratio of the unit’s      corresponding functional brain area. 2-way classification
activation across all exemplars of the category. To create           tasks are created using pairs of the categories defining each
populations of units sorted by their cSNR for a given                localizer set. Additionally, a sample of 45 pairs taken from
discrimination task on a subset of categories, we first create       10 randomly drawn ImageNet categories are used to
a vector containing the maximum unit cSNRs across all                bootstrap an estimate of the ability to predict all pairs of
categories in the subset. This vector is then sorted in three        ImageNet categories. All units in VGG-Face layer 35 are
ways, keeping the indices of units available: increasing             used as predictors in a 2-way SVM classification system akin
cSNR, decreasing cSNR, and random. For each layer and                to that used in Figure 2 and the results are shown in Figure 3.
discrimination task, three populations of size n are created by
selecting the first n units from each of these vectors, for                                      Results
several values of n, and bootstrapping is performed across                     The results of initial system-wide analyses of
random samples of categories. The activation patterns of each        AlexNet representations are shown in Figure 1. In nearly all
population serve as the set of predictors for the classification     cases, decoding accuracy increases with the number of units
of the ImageNet validation set images for each category in           used as predictors in the classifier, and decreases with the
the discrimination task. Multi-class classification is achieved      number of categories required for discrimination. In Conv1,
with a classification-tree based system, using the fitctree          Conv5, and FC6, for all discrimination tasks, sorting units by
function in the MATLAB Statistics and Machine-Learning               their categorical signal-to-noise ratio (cSNR; see methods)
toolbox. The classifier is cross-validated using 10-folds of         allows for improvements in decoding accuracy given the
80% training, 20% testing samples (crossval function).               same number of units. However, in FC8, for all
Finally, the loss is computed across the several folds of the        discrimination tasks, sorting units by cSNR has no effect on
cross-validated model (kfoldLoss function). Across                   decoding accuracy, suggesting that localized categorical
bootrsapped camples of category, accuracy is reported as 1 –         representations in FC8 possess information relevant to
mean loss, and error bars are the standard error of accuracy.        decoding between non-preferred categories.
   Next, AlexNet FC8 is examined in more detail (Figure 2).             The results of detailed analyses of AlexNet fully-connected
In analyses similar to those conducted by Haxby et. al (2001),       layer 8 (FC8) are shown in Figure 2, where categories are
we compare the 2-way classification of preferred and non-            organized by whether they are preferred (explicitly
preferred categories. For a given unit, the preferred category       represented) or non-preferred (not represented) by a given
is the category which is explicitly represented; all other           unit in FC8. The decoding accuracy between the preferred
categories are potential non-preferred categories. Starting          category and a randomly chosen non-preferred category (see
with 20 randomly-drawn ImageNet categories, we generate              Methods) is not significantly greater than the decoding
100 pairs of preferred/non-preferred categories, and 100 pairs       accuracy between randomly-generated pairs of non-preferred
of non-preferred/non-preferred categories, with 5 pairs of           categories (p=0.57); both values are significantly greater than
each type for every category. For 2-way classification, we use       chance (p<0.001).
a support-vector machine classifier (fitcsvm function,                  The results of all analyses of VGG-Face are shown in
MATLAB Statistics and Machine-Learning toolbox). The                 Figure 3. All discriminations involving face as one of two
same cross-validation and bootstrapping methods described            categories yield perfect discrimination accuracy. 2 out of 4
in preceding analyses are used to generate an estimate of            discriminations involving pairs of non-face categories (scene
mean and standard error of classification accuracy for each          vs. body part; scene vs. object) yield perfect discrimination
pair type.                                                           accuracy. The remaining 2 discrimination tasks (body part vs.
   We perform similar analyses on VGG-Face, a DCNN                   object; pairs of ImageNet categories) yield non-perfect but
trained for face-individuation on over 2000 faces (Parki,            greater than chance discrimination accuracy (p<0.001).
                                                                 138

Figures
  Figure 1: Population decoding from specified layers of the DCNN. Populations are selected in three ordering schemes,
choosing the units with the highest cSNR (blue), the lowest cSNR (red), or at random (yellow). A large separation between
curves indicates a local code, whereas a small separation indicates a distributed code.
  Figure 2: Single-unit decoding of FC8 in AlexNet. Each             Figure 3: Support-vector machine (SVM) classification of
unit has a “preferred” category – the category it represents.     layer 35 activations of VGG-Face network, shown for
All other categories are non-preferred categories.                different pairs of categories. Each SVM is cross-validated
Bootstrapping was performed as described in Methods. Mean         with 10 folds of 80% training/20% test data, and the accuracy
accuracies and standard errors across bootstrapping are           is reported as 1 – mean loss across folds. Error bars are shown
shown. Accuracy for preferred/non-preferred is not                as 1 – standard error of loss across folds. For ImageNet,
significantly greater than accuracy for non-preferred only        standard error is computed across 45 bootstrapped pairs of 10
(p=0.57). Both values are significantly greater than chance       randomly chosen categories. All accuracies are significantly
(p<0.001).                                                        greater than chance (p < 0.001).
                                                              139

                         Discussion                                     An important conceptual point is that the interpretation of
                                                                     our results – that modules should not be rejected on the
          First, using AlexNet, an arbitrary deep
                                                                     grounds of producing domain-external information – rests on
convolutional neural network (DCNN) for visual object
                                                                     the assumption that a cortical module would be activated by
categorization, we demonstrated that units explicitly
                                                                     domain-external information. In the case of localized
representing a single visual category, what we deem localized
                                                                     categorical representations for object categories, it seems
categorical representations (LCRs), provide information
                                                                     likely that all categories would be processed and that some
allowing for the decoding of non-preferred categories, at a
                                                                     activation might reach LCRs not representing the category of
level equal to that for decoding between the represented
                                                                     viewing. However, in the case of a cortical module for face
category and a non-preferred category. Demonstrating that
                                                                     processing, this point is less clear. Evidence of subcortical
these localized categorical representations contain distributed
                                                                     face detection mechanisms (for review, see Johnson, 2005)
information related to non-preferred categories suggests that
                                                                     suggest that the brain may be capable of filtering out non-face
the presence of domain-general decodable information in a
                                                                     information from higher processing (i.e., in FFA), via a fast
putative domain-specific cortical region is not grounds to
                                                                     detection process. Though, as we sometimes perceive faces
reject domain-specificity, as was done by Haxby et. al (2001),
                                                                     on trees and in other places in which there are not faces, it is
and Hanson & Schmidt (2011), in favor of distributed object-
                                                                     likely that non-face information does, on occasion, pass
form topographical representations. While LCRs differ from
                                                                     through the face-detector for further processing. It is possible
distributed object-form topographical representations in that
                                                                     that all information that arises for domain-external stimuli in
they represent abstract category information in a single value,
                                                                     FFA, for example, comes from images or image parts which
the LCRs in AlexNet receive their input from a distributed
                                                                     contain something that looks enough like a face to pass
object-form representation of the sort proposed by Haxby et.
                                                                     through an early detection process, into higher regions of the
al (2001), and are by no means well-described as the sort of
                                                                     face processing network. Once the visual information is
functional modules rejected by this study and proposed by the
                                                                     allowed to pass, our results demonstrate that its processing
likes of Kanwisher et. al, (1997) for visual face processing,
                                                                     within a face-optimized processor should give rise to
Epstein & Kanwisher (1998) for visual place/scene
                                                                     decodable information.
processing, or Downing et. al (2001), for visual body-part
                                                                        Some authors have argued that the Fusiform Face Area
processing, whereby functional modules likely contain
                                                                     (FFA) is better described as a mechanism for expert-level,
several processing stages for fine-grained analysis of
                                                                     fine-grained visual discriminations rather than a face-
exemplars of the preferred category. To ask whether such
                                                                     processing module, suggesting that neural substrate within
functional modules might also give rise to decodable
                                                                     FFA is specialized for visual categorization requiring
information about stimuli outside the domain of modularity,
                                                                     repeated subordinate-level identification, a task which
we relied on a second DCNN specialized for face
                                                                     happens to occur most frequently in the context of face
individuation, VGG-Face.
                                                                     processing, thus resulting in the large preference for faces
   To acquire a representation of maximal similarity to the
                                                                     (e.g. Gauthier et. al, 1999; Tarr & Gauthier, 2000). Indeed,
high-level face-optimized representations thought to be
                                                                     our results add an interesting point to this theoretical
housed in the Fusiform Face Area, we took the layer 35
                                                                     framework. Regardless of whether FFA is specialized for
activations of VGG-Face, a set of 4096 nodes which project
                                                                     faces or expertise, if it develops representations useful for
to the individual face probability nodes one layer later. We
                                                                     discriminating      between       individual     faces,    these
model these layer 35 nodes as a face module akin to the
                                                                     representations are also likely to be useful for discriminating
domain-specific interpretation of the Fusiform Face Area
                                                                     other visual objects. Thus, learning a new category of
(e.g. Kanwisher et. al, 1997; Kanwisher et. al, 2006). We
                                                                     expertise (e.g. birds) might recruit a previously face-specific
demonstrated that this “face module” contains patterns of
                                                                     cortical region, on the basis of that region containing the most
activation capable of perfect discrimination between pairs of
                                                                     useful representations for the expert task, especially if
categories containing a face, and two of four pairs of
                                                                     exemplars of these categories have sufficient visual similarity
categories not containing a face; the other two pairs yielded
                                                                     to faces to pass through an early face-detection gate (if one
high discrimination significantly above chance. Thus, we
                                                                     exists). In this sense, FFA would not be a face module, but
find that domain-specific, face-optimized representations
                                                                     rather a brain area optimized most strongly for face-
yield domain-general decodable information. This result
                                                                     recognition, but also recruited for expert subordinate-level
provides support for the idea that activations within a cortical
                                                                     visual recognition.
“module” might contain information relevant to decoding
                                                                        Whether cortical modules exist in the sense motivated most
between categories for which that module is not specialized
                                                                     strongly by Kanwisher (2010) remains an open debate.
to process. This result strengthens our earlier result,
                                                                     However, should such cortical modules exist, if their
demonstrating that it is improper to reject the possibility of a
                                                                     representations are activated by non-preferred categories,
functional module associated with a given brain region on the
                                                                     these “modules” are likely to produce activation patterns
grounds that the region’s activation patterns allow for
                                                                     which allow for decoding between non-preferred categories,
decoding between stimuli unrelated to the module’s proposed
                                                                     the characteristic result of studies which sometimes claim
primary function.
                                                                     evidence of distributed, non-modular processing. As such, it
                                                                 140

behooves the field to develop more sensitive and diagnostic            specialized for face perception. The Journal of
measures to assess these critical questions regarding the              Neuroscience : The Official Journal of the Society for
fundamental nature of representation in the brain.                     Neuroscience,                 17(11),              4302–11.
                                                                       https://doi.org/10.1098/Rstb.2006.1934
                    Acknowledgments                                  Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012).
NB is grateful to his family, and especially to his parents Lisa       ImageNet Classification with Deep Convolutional Neural
and James, for their endless support; to the summer                    Networks. Advances In Neural Information Processing
Undergraduate Program in Neural Computation at CNBC,                   Systems,                                               1–9.
Pittsburgh, where the majority of this research was                    https://doi.org/http://dx.doi.org/10.1016/j.protcy.2014.09.
performed; to Ying Yang for mentorship on machine learning             007
techniques, and for helpful discussions of early pieces of this      LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998).
work throughout the summer; and finally to Rosie Cowell for            Gradient Based Learning Applied to Document
introducing him to the modular debate, which spawned the               Recognition. Proceedings of the IEEE, 86(11), 2278–2324.
theoretical interpretation of earlier results, as well as for          https://doi.org/10.1109/5.726791
helpful comments on an early version of this manuscript.             Spiridon, M., & Kanwisher, N. (2002). How distributed is
                                                                       visual category information in human occipito-temporal
                                                                       cortex? An fMRI study. Neuron, 35(6), 1157–1165.
                         References                                    https://doi.org/10.1016/S0896-6273(02)00877-2
Cowell, R. A., & Cottrell, G. W. (2013). What Evidence               Tarr, M. J., & Gauthier, I. (2000). FFA: a flexible fusiform
  Supports Special Processing for Faces? A Cautionary Tale             area for subordinate-level visual processing automatized
  for fMRI Interpretation. Journal of Cognitive                        by expertise. Nature Neuroscience, 3(8), 764–769.
  Neuroscience,                25(11),              1777–1793.         https://doi.org/10.1038/77666
  https://doi.org/10.1162/jocn                                       Vedaldi, A., & Lenc, K. (2015). MatConvNet. Proceedings
Downing, P. E., Jiang, Y., Shuman, M., & Kanwisher, N.                 of the 23rd ACM International Conference on Multimedia
  (2001). A Cortical Area Selective for Visual Processing of           -               MM                ’15,             689–692.
  the Human Body. Science, 293(September), 2470–2473.                  https://doi.org/10.1145/2733373.2807412
Epstein, R., & Kanwisher, N. (1998). A cortical                      Yamins, D. L. K., & DiCarlo, J. J. (2016). Using goal-driven
  representation of the local visual environment. Nature,              deep learning models to understand sensory cortex. Nature
  392(6676), 598–601. https://doi.org/10.1038/33402                    Neuroscience,                  19(3),              356–365.
Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P., &          https://doi.org/10.1038/nn.4244
  Gore, J. C. (1999). Activation of the middle fusiform “face        Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A.,
  area” increases with expert ise in recognizing novel                 Seibert, D., & DiCarlo, J. J. (2014). Performance-
  objects. Nature Neuroscience, 2(6), 568–73. Retrieved                optimized hierarchical models predict neural responses in
  from                                                                 higher visual cortex. Proceedings of the National Academy
  http://www.biac.duke.edu/education/courses/spring03/cog              of Sciences of the United States of America, 111(23), 8619–
  dev/readings/I. Gauthier et al (1999).pdf                            24. https://doi.org/10.1073/pnas.1403112111
Güçlü, U., & van Gerven, M. a. J. (2015). Deep Neural                Parkhi, O. M., Vedaldi A.and Zisserman, A. (2015). Deep
  Networks Reveal a Gradient in the Complexity of Neural               face recognition, Proceedings of the British Machine
  Representations across the Ventral Stream. Journal of                Vision Conference (BMVC).
  Neuroscience,              35(27),             10005–10014.
  https://doi.org/10.1523/JNEUROSCI.5023-14.2015
Hanson, S. J., & Schmidt, A. (2011). High-resolution
  imaging of the fusiform face area (FFA) using multivariate
  non-linear classifiers shows diagnosticity for non-face
  categories.       NeuroImage,        54(2),       1715–1734.
  https://doi.org/10.1016/j.neuroimage.2010.08.028
Haxby, J. V, Gobbini, M. I., Furey, M. L., Ishai, A.,
  Schouten, J. L., & Pietrini, P. (2001). Distributed and
  overlapping representations of faces and objects in ventral
  temporal cortex. Science, 293(September), 2425–2430.
  https://doi.org/10.1126/science.1063736
Kanwisher, N. (2010). Functional specificity in the human
  brain: A window into the functional architecture of the
  mind. Proceedings of the National Academy of Sciences,
  107(25),                                           11163–70.
  https://doi.org/10.1073/pnas.1005062107
Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The
  fusiform face area: a module in human extrastriate cortex
                                                                 141

