                                  A cognitive analysis of deception without lying
                                          Keith Ransom (keith.ransom@adelaide.edu.au)
                                               School of Psychology, University of Adelaide
                                       Wouter Voorspoels (wouter.voorspoels@kuleuven.be)
                                                  Brain & Cognition, University of Leuven
                                            Amy Perfors (amy.perfors@adelaide.edu.au)
                                               School of Psychology, University of Adelaide
                                           Daniel J. Navarro (dan.navarro@unsw.edu.au)
                                           School of Psychology, University of New South Wales
                                Abstract                                 truth, manipulating the level of suspicion of the hypothetical
                                                                         receiver and the information content of the available message
   When the interests of interlocutors are not aligned, either party
   may wish to avoid truthful disclosure. A sender wishing to            options.
   conceal the truth from a receiver may lie by providing false
   information, mislead by actively encouraging the receiver to          How to deceive in ten steps (with pictures)
   reach a false conclusion, or simply be uninformative by provid-       Communication relies on principles of cooperation (Grice,
   ing little or no relevant information. Lying entails moral and
   other hazards, such as detection and its consequences, and is         1989). The intended meaning of a sender rarely coincides
   thus often avoided. We focus here on the latter two strategies,       perfectly with the “literal” content of a message, but by mak-
   arguably more pernicious and prevalent, but not without their         ing assumptions about why the sender chose that particular
   own drawbacks. We argue and show in two studies that when
   choosing between these options, senders consider the level of         message, the receiver may infer the intended meaning. By
   suspicion likely to be exercised on the part of the receiver and      assuming that a sender is cooperative and produces messages
   how much truth must be revealed in order to mislead. Extend-          that follow the Gricean maxims (described below), a receiver
   ing Bayesian models of cooperative communication to include
   higher level inference regarding the helpfulness of the sender        can increase the speed and strength of the inferences they
   leads to insight into the strategies employed in non-cooperative      draw from those messages (Horn, 2004).
   contexts.                                                                But what if the sender is not trying to be cooperative? In
   Keywords: deception; Inductive inference; communication;              that case, there are three main strategies the sender can rely
   pragmatics                                                            on, each corresponding to different violations of the Gricean
                                                                         maxims. Consider the following scenario: You shot your
                           Introduction                                  neighbour’s hamster with your shotgun while she was away
     “You can tell he’s lying because his lips are moving.”              for the weekend. Obviously, you’d prefer that she didn’t learn
                                                                         the truth. However, you were given the key to her house to
   If only detecting lies were that simple! Despite its impor-           take care of her pet, so you are definitely a person of interest
tance, people generally perform at chance when classifying               in her investigation. How can you conceal the truth from her?
liars and truth tellers (C. Bond & DePaulo, 2006). Indeed,
most verbal and nonverbal cues have only marginal diagnos-               • Lying: You might try an outright lie: “I did not shoot your ham-
                                                                            ster”. Lying involves communicating a proposition to the receiver
tic value (DePaulo et al., 2003). Instead of focusing on cues               with the full knowledge that it is false. From a Gricean perspec-
to deception, a promising new approach considers how the                    tive, lying is a violation of the supermaxim of quality, stating that
cognitive processes involved in deception may differ from                   your contribution should be true.
telling the truth. It has been suggested, for example, that de-          • Being uninformative: It seems very sensible to be uninforma-
ception imposes higher cognitive demands on liars, who may                  tive. Neighbour: “Did you shoot my hamster?” You:“Have you
find it more difficult to furnish details when interviewed (Vrij            heard the new Justin Bieber album? It’s fantastic!”1 With this
                                                                            kind of utterance, it would seem that the receiver can infer noth-
& Granhag, 2012). A good understanding of the cognitive                     ing beyond her prior beliefs. But this violates the Gricean maxims
mechanisms underlying deception, taking into account the                    of relevance and quantity, and these violations can themselves be
complexities of the strategies employed, would be a tremen-                 informative about the sender’s intentions even if not the actual
                                                                            facts of the matter.
dous asset (G. D. Bond, 2012; Blandon-Gitlin, Fenn, Masip,
& Yoo, 2014).                                                            • Misleading: A third option is to mislead your neighbour by im-
   In the present research we analyse the challenge faced by                plicature. “I was not at home when your hamster was shot!” You
                                                                            tell her a truth very relevant to the issue at hand, but from which
would-be deceivers seeking to conceal the truth. We begin                   you believe a false conclusion will be drawn (you were not at
with a brief analysis of the deceiver’s perspective, identifying            home when you shot the hamster; you took it with you to a nearby
the main deceptive strategies, and outline a preliminary study              park for target practice). Misleading involves covertly violating
                                                                            the maxims of quantity, but may be harder to detect.
which illustrates people’s preferences for these strategies. We
then present two studies where we ask people to conceal the                  1 Admittedly,  this could well be considered a bald-faced lie.
                                                                     992

   In a preliminary study, we asked 96 first year psychology              raises suspicion. Consider the likely response of choosing to
students (87 women) at the University of Leuven to imagine                be uninformative, as in the Las Vegas scenario:
seven different scenarios like the following:
                                                                             Spouse: Did you gamble?
   A man arrives home after a weekend in Vegas, during which
   he won $2000 playing Poker, but lost $500 at the slot ma-                 Gambler: Where shall we go for dinner? I’m hungry.
   chines and $4000 on Blackjack. When he returns, he does                   Spouse: You lost money didn’t you?
   not know how to tell his wife. His wife knows that he has had             Gambler: Some of the guys won big.
   gambling problems in the past, but is convinced that they are
   resolved. Their relationship is currently strained, so the man            Spouse: How much did you lose?
   would rather not cause any additional problems. His wife asks
   him directly if he has gambled. Which of these answers would              As Sperber et al. (2010) points out, people have a toolbox
   you give if you were in his situation?                                 of cognitive mechanisms for epistemic vigilance that reduce
Participants selected a response from seven options com-                  the risk of being deceived. One such tool supports tracking
prised of two lies (e.g. “I didn’t gamble”), two uninformative            the cooperation of others; as a result, obvious departures from
statements (e.g. “there were a lot of people gambling”), two              that cooperation are noted (e.g., Mills, 2013). Responding in
misleading statements (e.g. “I won $2000 playing Poker”),                 an uninformative way violates the principle of cooperation so
and the truth. Figure 1 presents the preference of the par-               blatantly that the deception is revealed.
ticipants (collapsed across scenarios and equivalent response                A deceiver, sensitive to the epistemic vigilance of his coun-
options).                                                                 terpart may prefer instead to provide truthful but misleading
                                                                          utterances, but in doing so faces a delicate trade-off. Cho-
                                                                          sen well, such utterances may not only allay the receiver’s
                                                                          suspicion, but by virtue of the inferential boost accorded to
                                                                          cooperative speakers, the receiver may be led to a false con-
                                                                          clusion, terminating the search for further information. Yet if
                                                                          suspicion is already raised, the receiver is unlikely to fall for
                                                                          the false implicature, which relies on her assumption of co-
                                                                          operation (Dynel, 2011), and may use the information to get
                                                                          closer to the truth.
Figure 1: When choosing how to communicate in a variety of differ-           This analysis points to two opposite forces, balanced in
ent scenarios with a clear motivation to deceive, participants showed     the selection of one strategy over another. On one hand, the
a strong tendency to mislead rather than be uninformative.                knowledge that the receiver may engage in inference about
                                                                          the helpfulness of the statement may lead the sender to opt for
   Two important conclusions emerge from Figure 1. Firstly,
                                                                          a misleading yet informative statement. On the other hand, if
people were uncomfortable with deception: 37% of responses
                                                                          the sender considers that the receiver will be suspicious a pri-
involved telling the full truth and only 10% were outright lies:
                                                                          ori, he may resort to being uninformative. We examine these
a surprising number perhaps given that each scenario pro-
                                                                          factors in two experiments.
vided a clear motivation to deceive. However, this finding
is consistent with previous research showing that in general
                                                                                   Experiment 1: The deception game
people avoid lying through concerns regarding self-image,
guilt, and anxiety (Aquino & Reed, 2002). Of more relevance               As the basis for our empirical investigation, we use a simple
to our present purposes, we found that among those who                    two person communication game in which the interests of the
chose not to tell the truth, people showed a clear preference             sender and receiver are opposed. In the game, the sender (cast
for misleading over lying or being uninformative (37%, 10%                in the role of a pirate) and the receiver (cast as an explorer)
and 15% respectively). This finding is consistent with earlier            see four alternative maps, only one of which is genuine. Each
work on the topic (Montague, Navarro, Perfors, Warner, &                  map purports to show the true extent of a contiguous region
Shafto, 2011; Rogers, Zeckhauser, Gino, Schweitzer, & Nor-                where treasure is buried. The pirate, who knows the identity
ton, 2014).                                                               of the genuine map and must seek to protect it, is required to
                                                                          provide a hint to the explorer in the form of a small number of
Balancing suspicion and information                                       locations that lie within the region. The explorer must use this
So, why do people seem to prefer to actively mislead rather               information to guess the identity of the genuine map. Both
than be entirely uninformative? At first glance, it seems ra-             players know that lying is not allowed; so the pirate can only
tional to be as uninformative as possible: the receiver cannot            reveal locations where treasure is actually buried.
revise her beliefs on the basis of your utterances. Mislead-                 An example trial faced by participants, who took the role
ing on the other hand, involves salting your statements with a            of the pirate in this experiment, is shown in Figure 2. Figure
grain of truth – something which the receiver may build upon              2(a) illustrates the four maps shown to the pirate and (hypo-
to infer the whole truth.                                                 thetical) explorer for an example trial. In providing a hint
   An important motivation for choosing a misleading utter-               to the explorer, participants were restricted in their choice to
ance over a strictly uninformative one is because the latter              one of three kinds of hints : one uninformative, one mislead-
                                                                      993

                                                                            a trusting receiver, we expect people to be more inclined to
                                                                            mislead, provided that the amount of information disclosed is
                                                                            acceptable. But if the receiver is likely to be suspicious or too
                                                                            much information would otherwise be revealed, we expect
         (a) Four maps provided to the pirate and explorer.
                                                                            people to be uninformative.
                                                                                Participants were 120 undergraduates from the University
                                                                            of Leuven (86% female, ages 18-24, median 18) participating
                                                                            for course credit. Participants faced 30 trials in all: six sets
                                                                            of four maps were presented in conjunction with each of five
                                                                            crew configurations.
                                                                            Results and discussion
                                                                            Our first question was whether people’s decision to mislead
                                                                            or not depended on how much information the misleading
                                                                            option gave away. To address this, we examined whether
               (b) The pirate chooses one of three hints.
                                                                            the proportion of participants choosing each kind of hint de-
Figure 2: Experiment 1: The deception game.(a) Both the pirate              pended on the number of treasure maps that were excluded
and explorer see the same four maps; the shaded area marks the              by the M ISLEADING one. A chi-square test confirmed the
region where treasure be buried. Only one of the four maps is gen-
uine: the pirate seeks to conceal its identity, the explorer seeks to       dependency shown in Figure 3 (χ2 (4, 3600) = 93.31, p <
discover it. (b) The pirate must provide a hint to the explorer, and is     0.001): as the amount of information revealed by the M IS -
given three hints from which to choose: a M ISLEADING, U NINFOR -           LEADING hint increased, people were less willing to select
MATIVE , or H ELPFUL hint. Each hint marks a subset of locations
where treasure is buried (blue dots). Since lying is not permitted all      it, preferring instead to choose the U NINFORMATIVE option.
marked points lie within the shaded area when overlaid on the gen-          Indeed, in contrast to the pilot data in Figure 1, the U NIN -
uine map. The hints vary in their potential to drive inference. The         FORMATIVE option was the most favoured in this task. This
M ISLEADING hint appears to clearly point out the wrong map, de-
spite being consistent with all of them. The U NINFORMATIVE hint            is unsurprising perhaps, since a hint that excludes even one of
neither points to nor excludes any of the maps. The H ELPFUL hint           four maps is extremely informative.
excludes all of the maps except the genuine one.
ing, and one genuinely helpful. Figure 2(b) shows examples
of the three options, and illustrates the likely effect that each
hint would have on the inference of a trusting explorer.
   The informativeness of a hint was manipulated by varying
the number of treasure maps (out of four) that were excluded
by the hint. When maximally informative (H ELPFUL), a hint
excludes all treasure maps, except the true one (bottom row of
Figure 2b). When maximally U NINFORMATIVE, it excludes                      Figure 3: Experiment 1: Informativeness. The y-axis shows the
                                                                            number of times each type of hint (given by column label) was se-
no treasure maps (middle row). The M ISLEADING hints were                   lected as a function of the number of treasure maps excluded by the
designed to closely resemble one of the three false maps (top               misleading hint (x-axis): 0% means none were excluded, 25% means
row), and to exclude none (as in the example shown), one or                 one was, and 50% means that two were. People were sensitive to
                                                                            informativeness: when the misleading hint was more informative,
two of the treasure maps.                                                   people were less likely to mislead.
   People’s beliefs about the suspicion level of the receiver
(the hypothetical explorer) were manipulated by changing the
proportion of deceivers in the population that were suppos-                     Our second question was whether people’s decision was
edly providing information. Participants were told that they                affected by their estimate of how suspicious the receiver (the
were part of a crew of six sailors providing a hint to the ex-              hypothetical explorer) was likely to be. In light of this, we
plorer. Participants were also told that the explorer knew that             examined the relationship between participants’ choice of
the hint came from an unknown (but randomly selected) crew                  hints and the number of deceptive crew members providing
member and knew the proportion of deceptive crew members.                   hints for the explorer. Curiously, as Figure 4 illustrates, there
Varying the number of deceivers in the crew from one to five                was no evidence for a relation between the level of suspicion
was intended to raise the perceived suspicion level of the ex-              and the type of hint selected (χ2 (8, 3600) = 12.96, p = 0.11).
plorer. Our question was whether the pirate would track and                 Even when people knew that the explorer thought that five
use this information when providing hints, being more likely                out of the six possible senders was acting deceptively, they
to mislead when the suspicion level was lower. When facing                  did not alter their selection of hints.
                                                                        994

Figure 4: Experiment 1: Suspiciousness. The y-axis shows the             Figure 5: Experiment 2: Informativeness. The y-axis shows the
number of times each type of hint (given by column label) was se-        number of times each type of hint (given by column label) was se-
lected as a function of the implied suspicion level of the explorer.     lected as a function of the number of treasure maps excluded by the
The numbers on the x-axis represent the number of deceptive mem-         misleading hint (x-axis). As in Experiment 1, people were sensitive
bers in the crew that provides the explorer with a hint (more mem-       to informativeness: when the misleading hint was more informative,
bers suggests that the explorer should be more suspicious). There        people were less likely to mislead. Data from the control condition
was no dependency between choice of hint and number of deceptive         are excluded.
crew members.
          Experiment 2: Increasing suspicion
Experiment 1 found convincing evidence for the influence of
informativeness on the decision to mislead. If too much in-
formation would be revealed with a true but misleading state-
ment, people are more inclined to be uninformative. Surpris-
ingly, we did not find an effect of suspicion. What might be
going on here?                                                           Figure 6: Experiment 2: Suspiciousness. The y-axis shows the
                                                                         number of times each type of hint (given by the column label) was
    One possible explanation is simply that our manipulation             selected as a function of the implied suspicion level of the explorer.
was ineffective. Perhaps changing the number of deceptive                The x-axis reflects whether people were told that the explorer was
crew members was not salient enough or required too much                 expecting a hint from a member of another team (the HIGH SUSPI -
                                                                         CION condition) or from a teammate (the LOW SUSPICION condi-
effort for participants to interpret or keep in mind.                    tion). When participants knew that the explorer was apt to be sus-
    Experiment 2 was identical to Experiment 1, but rather than          picious of them, they were less inclined to be misleading, opting
                                                                         instead to be uninformative.
have people infer how suspicious the explorer might be from
the composition of the crew, we instead gave participants ex-
plicit information about the explorer’s beliefs. In the L OW             Results and discussion
S USPICION condition, participants were told that the explorer
suspected that the hint came from a teammate, whereas in                 As before, our first question was whether people were sensi-
the H IGH S USPICION the explorer suspected the hint came                tive to informativeness when choosing which hint to provide.
from an opponent. The experiment was similar in all other                Once again, there was a significant effect of informativeness
respects except for a control condition in which participants            (χ2 (4, 912) = 18.04, p = 0.001). As Figure 5 shows, the more
were asked to help the explorer (used to identify participants           maps the misleading option excluded, the less inclined people
who were not trying or did not understand the task). There               were to select it, favouring instead the uninformative option.
were also a number of filler items in which there was no ob-                In light of the null effect in Experiment 1, a perhaps more
viously misleading option.                                               interesting question is whether people were sensitive to the
                                                                         suspicion level of the explorer when deciding what to tell
    Participants were 98 adults recruited via Amazon Mechan-
                                                                         them. As Figure 6 reflects, when the suspicion level of the ex-
ical Turk and paid $1.25USD for 15 minutes participation.
                                                                         plorer is made more obvious, people are indeed sensitive to it.
Data from 22 participants who failed to demonstrate a suffi-
                                                                         Although the U NINFORMATIVE hint was still the most pop-
cient understanding of the experiment were excluded from
                                                                         ular overall, the M ISLEADING option was chosen far more
subsequent analysis.2 The remaining 76 participants were
                                                                         when the explorer was expecting a hint from a trusted team-
46% female and aged 20-63 (median age 28.5). Participants
                                                                         mate (χ2 (2, 912) = 85.95, p < 0.001). This suggests that peo-
faced 30 trials in all: 10 map sets (six experimental, four
                                                                         ple acting as senders are indeed attentive to the level of trust
fillers) were presented in each of the three condition blocks.
                                                                         presumed by the receiver; although, taken together with the
    2 These exclusions were of participants who failed to select the
                                                                         results from Experiment 1, tracking suspicion may be too
H ELPFUL message in a C ONTROL condition (where the goal was to          cognitively challenging where it is not especially salient.
help) on at least 40% of trials. We also excluded those who selected
the H ELPFUL message in the L OW S USPICION condition on 40% or                      Towards a computational model
more trials (where the goal was to hinder, and double bluffing was
unreasonable). There was no difference in the significance of our        Experiments 1 and 2 manipulated two important factors: the
findings if these people were included..                                 information content of the messages that deceivers could
                                                                     995

choose and their beliefs about the degree of suspicion with
which their messages would be received. Taken together, our
results show that both factors were important considerations.
In this section we present a computational model whose goal
is to aid our understanding of these results and generate new
testable predictions. While an in-depth analysis of the model
is beyond the scope of this paper, here we briefly describe the
relevant features.
   A convenient starting point for a model of the deception
game employed here – and for communication in general –
is rational inference (e.g., Goodman & Frank, 2016). In this
framework, a receiver faces the challenge of updating her be-
liefs on the basis of information disclosed by a sender. The           Figure 7: Model predictions for sender actions. Model predic-
                                                                       tions for the preference of a sender in the deception game for the
sender, for his part, selects information designed (according          misleading, uninformative and helpful message options. From left
to his goal) to help or hinder the receiver in her efforts.            to right, the panels present scenarios with increasingly suspicious
   We first evaluate things from the perspective of the re-            receivers (modelled through different kinds of inference about the
                                                                       sender’s goals and assumptions). The x-axes indicate how informa-
ceiver, who is confronted with a hint x (or, more generally,           tive the misleading option is (in terms of the proportion of hypothe-
an utterance). The receiver is assumed to update her beliefs h         ses excluded by it). The model predicts a decrease in preference
according to:                                                          for the misleading option as it becomes increasingly informative, as
                                                                       well as an increase in preference for misleading when the receiver is
                                                                       less suspicious.
         PR ECEIVER (h | x) ∝  ∑ PS  ENDER (x | h, s)P(h)P(s)  (1)
                               s∈S
where s represents a sampling strategy employed by the                 not only updates her beliefs about what is true, but simulta-
sender and S represents the range of such strategies consid-           neously makes inferences about the sender’s sampling strat-
ered. As a simplifying assumption, we assume that the re-              egy: learning whether the sender is helpful and knowledge-
ceiver considers the sender’s sampling strategy to be inde-            able play a critical role in epistemic vigilance, and has a sub-
pendent of the true hypothesis.                                        stantial impact on how rational agents reason (e.g., Shafto,
   This inference thus depends on the sender, who selects in-          Eaves, Navarro, & Perfors, 2012).
formation according to a sampling strategy:                               In Equations (1) and (2), the universe of sampling strate-
                                                                       gies S evaluated by the receiver is defined in terms of two
                PS ENDER (x | h) ∝ (PR ECEIVER (h | x))α       (2)
                                                                       things that she presumes about the sender: what does the
where α reflects the goals of the sender, and PR ECEIVER (h|x)         sender assume about her (reflected by PR ECEIVER (h|x)), and
the sender’s assumptions about how the receiver updates her            what are his goals (reflected in α). Many scenarios may be
beliefs. A sender who wishes to reveal the truth to the re-            modelled in this way, but here we consider three. If the re-
ceiver (i.e., to increase the receiver’s posterior probability for     ceiver is TRUSTING, this means that she is performing infer-
the correct hypothesis h) will have an α with a positive value;        ence over two possibilities: either the sender is trying to be
one who wishes to conceal the truth has a negative α; one              helpful (α = 1), or he is inattentive and thus not selecting in-
who behaves somewhat randomly has an α = 0. There are                  formation with care (α = 0). If the receiver is UNTRUSTING,
other ways to capture conflicting goals, like assigning sepa-          this means that she believes that the sender is trying to con-
rate utility functions for the sender and receiver with regard         ceal the truth from her (α = −1), under the mistaken assump-
to truth-predicated action, but we chose this for its relative         tion that he is trusted. Lastly, if the receiver is SUSPICIOUS,
simplicity.                                                            this means that she is performing inference over whether to
   To capture the patterns observed in our deception game,             be trusting or untrusting.
both equations have to be considered simultaneously. That                 How well does this approach capture the main qualitative
is, both sender and receiver must recursively consider the             patterns in the deception game? To answer this, we simu-
assumptions and strategies used by the other party. Impor-             late outcomes for the three scenarios we have outlined. In the
tantly, from the receiver’s perspective the inferential potential      leftmost panel of Figure 7, the receiver trusts the sender, but
of a message depends not only on the information as such,              is not sure how attentive he is: he may be acting helpfully
but also on the “sampling strategy” of the sender, which re-           (α = 1) or he may be providing poor but not actively mis-
flects the sender’s goals and assumptions about the receiver.          leading data, perhaps due to lack of motivation, attention, or
For example, sampling procedures that follow the principle of          information (α = 0).
cooperation and the Gricean maxims have a stronger inferen-               If the receiver updates her beliefs (concerning the true trea-
tial potential (e.g., Bergstrom, Moehlmann, & Boyer, 2006;             sure map) at the same time as her assumptions about the help-
Shafto, Goodman, & Griffiths, 2014; Voorspoels, Navarro,               fulness of the information received (α) then there is reason
Perfors, Ransom, & Storms, 2015). Crucially, the receiver              for the sender to choose a hint that seems informative. That
                                                                   996

the message appears informative supports the receiver’s as-           be inferred — when the receiver is already suspicious — then
sumption that it has been carefully selected, which further           preference shifts towards limiting the information disclosed.
fuels inference. This recursive process may lead the receiver
to draw a misleading conclusion if the sender is not actually                                Acknowledgments
helpful (as in our experiments). However, as the information          We thank Paulien Van Rijmenant for help with data collec-
content of the hint increases, so too does the risk that the re-      tion. KR was supported by an Australian Government Re-
ceiver will inadvertently arrive at the truth. Consequently, the      search Training Program Scholarship. WV is a postdoc at KU
model captures the fact that the sender’s preference for the          Leuven. AP was supported by ARC grants DP110104949 and
misleading hint declines with its information content.                DP150103280. DJN received salary support from ARC grant
   In the rightmost panel of Figure 7, in contrast, the receiver      FT110100431.
is certain that the sender is not to be trusted. If the sender is
aware of this, there is little to be gained by attempting to mis-
                                                                                                  References
                                                                      Aquino, K., & Reed, . I. (2002). The self-importance of moral
lead, and so the uninformative hint is preferred. The extent of          identity. Journal of Personality and Social Psychology, 83(6),
this preference is, once again, moderated by the information             1423-1440.
content of the misleading option.                                     Bergstrom, B., Moehlmann, B., & Boyer, P. (2006). Extending
                                                                         the testimony problem: evaluating the truth, scope and source of
   In many situations, a receiver will not be predisposed to             cultural information. Child Development, 77(3), 531-538.
regard the sender with complete trust, nor complete distrust,         Blandon-Gitlin, I., Fenn, E., Masip, J., & Yoo, A. (2014). Cognitive-
but rather will remain open to either possibility. We model              load approaches to detect deception: searching for cognitive
                                                                         mechanisms. Trends in Cognitive Science, 18(9), 441-444.
this case by assuming that the receiver is performing infer-          Bond, C., & DePaulo, B. (2006). Accuracy of deception judgments.
ence about whether the sender should be trusted (α = 1 or 0)             Personality and Social Psychology Review, 10(3), 214-234.
or not (α = −1). The preferences of an antagonistic sender            Bond, G. D. (2012). Focus on basic cognitive mechanisms and
                                                                         strategies in deception research (and remand custody of ‘wizards’
facing a Suspicious receiver are shown in the center panel of            to Harry Potter movies). Journal of Applied Research in Memory
Figure 7. The two conflicting forces are most pronounced                 and Cognition, 1(2), 128 - 130.
here, dividing the sender’s preference between the two strate-        DePaulo, B., Lindsay, J., Malone, B., Muhlenbruck, L., Charlton,
                                                                         K., & Cooper, H. (2003). Cues to deception. Psychological
gies. On the one hand, the sender may convince the receiver              Bulletin, 129(1), 74-118.
that he is actually trying to help by appearing informative, yet      Dynel, M. (2011). A web of deceit: A neo-gricean view on types
the (real) information can be used by the receiver to rule out           of verbal deception. International Review of Pragmatics, 3, 139-
                                                                         167.
previously plausible (but false) hypotheses.                          Goodman, N. D., & Frank, M. C. (2016). Pragmatic language inter-
   Overall, there are two clear patterns that were found in our          pretation as probabilistic inference. Trends in Cognitive Sciences,
                                                                         20(11), 818 - 829.
experiments and were also predicted by our model. Firstly, as         Grice, H. P. (1989). Studies in the way of words. Cambridge, MA:
the information content of the misleading option increases,              Harvard University Press.
there is an increasing preference for choosing the uninforma-         Horn, L. (2004). Implicature. In L. Horn & G. Ward (Eds.), Hand-
                                                                         book of pragmatics (p. 2-28). Blackwell Publishing.
tive hint. Secondly, the more trusting the receiver is assumed        Mills, C. M. (2013). Knowing when to doubt: Developing a critical
to be, the more popular the misleading option becomes. This              stance when learning from others. Developmental Psychology,
pattern of results is consistent with the idea that people may           49(3), 404-418.
                                                                      Montague, R., Navarro, D., Perfors, A., Warner, R., & Shafto, P.
be performing some kind of recursive inference over how sus-             (2011). To catch a liar: The effects of truthful and deceptive tes-
picious their interlocutor is when deciding how to deceive.              timony on inferential learning. In L. Carlson, C. Holscher, &
Furthermore, our results are consistent with the notion posited          T. Shipley (Eds.), Proceedings of the 33th annual meeting of the
                                                                         cognitive science society. Austin, TX: Cognitive Science Society.
here and elsewhere (e.g., Goodman & Frank, 2016; Shafto               Rogers, T., Zeckhauser, R., Gino, F., Schweitzer, M., & Nor-
et al., 2012), that receivers (from the sender’s perspective at          ton, M. (2014, september). Artful paltering: The risks and
least) perform joint inference over the goals of the sender and          rewards of using truthful statements to mislead others (HKS
                                                                         Working Paper No. RWP14-045). Harvard Kennedy School.
the truth of the matter at hand given the information received.          Retrieved from https://ssrn.com/abstract=2528625 doi:
                                                                         http://dx.doi.org/10.2139/ssrn.2528625
                          Conclusion                                  Shafto, P., Eaves, B., Navarro, D. J., & Perfors, A. (2012). Epistemic
                                                                         trust: Modeling children’s reasoning about others’ knowledge and
“There is nothing more deceptive than an obvious fact.”                  intent. Developmental Science, 15, 436-447.
                                                                      Shafto, P., Goodman, N. D., & Griffiths, T. L. (2014). A rational
                                          — Arthur Conan Doyle           account of pedagogical reasoning: Teaching by and learning from
                                                                         examples. Cognitive Psychology, 71, 55-89.
In two studies we have demonstrated that people’s preference          Sperber, D., Clement, F., Heintz, C., Mascaro, O., Mercier, H.,
                                                                         Origgi, G., & Wilson, D. (2010). Epistemic vigilance. Mind
for a deceptive strategy hinges on their assumption of whether           & Language.
cooperative norms are expected to apply. In situations where          Voorspoels, W., Navarro, D. J., Perfors, A., Ransom, K., & Storms,
high levels of trust and cooperation are warranted, deceivers            G. (2015). How do people learn from negative evidence? non-
                                                                         monotonic generalizations and sampling assumptions in inductive
are more inclined to actively mislead than to simply withhold            reasoning. Cognitive Psychology, 81, 1-25.
information. In this scenario, the deceiver seeks to leverage         Vrij, A., & Granhag. (2012). Eliciting cues to deception and truth:
the inferential boost of cooperative communication. In con-              What matters are the questions asked. Journal of Applied Re-
                                                                         search in Memory and Cognition, 1(2), 110-117.
trast, when the deceiver believes the false implication will not
                                                                  997

