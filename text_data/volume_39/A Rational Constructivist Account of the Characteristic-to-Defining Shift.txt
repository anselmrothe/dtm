         A Rational Constructivist Account of the Characteristic-to-Defining Shift
                                      Francis Mollica, Shirlene Wade, Steven T. Piantadosi
                                    {fmollica | swade | spiantadosi}@mail.bcs.rochester.edu
                 Department of Brain and Cognitive Sciences, University of Rochester, Rochester, NY 14627 USA
                               Abstract                                      While the characteristic-to-defining shift is commonly ob-
                                                                          served in concept acquisition, the process by which this oc-
   A widely observed phenomenon in children’s word-extensions             curs is unclear. One possibility is that the characteristic-to-
   and generalizations is the characteristic-to-defining shift,
   whereby young children initially generalize words based on             defining shift is a stage-like transition that occurs in the rep-
   typical properties and gradually transition into generalizing          resentational system (Werner, 1948; Bruner, Olver, Green-
   words using abstract, logical information. In this paper, we           field, et al., 1966). For example, the shift could be explained
   propose a statistically principled model of conceptual devel-
   opment grounded in the trade-off between simplicity and fit to         by a transition from representing concepts wholistically—
   the data. We run our model based on informant-provided fam-            i.e., using all the features of objects, to representing con-
   ily trees and the real-life characteristic features of people on       cepts analytically—i.e., narrowing in specific relevant fea-
   those trees. We demonstrate that the characteristic-to-defining
   shift does not necessarily depend on discrete change in rep-           tures of objects (Kemler, 1983). Neural network models
   resentation or processes. Instead, the shift could fall out nat-       of conceptual classification inherently capitalize on this idea
   urally from statistical inference over conceptual hypotheses.          when demonstrating a shift (e.g., Shultz, Thivierge, & Lau-
   Our model finds that the shift occurs even when abstract logical
   relations are present from the outset of learning as long as char-     rin, 2008). Another possibility is that there is a change in the
   acteristic features are informative but imperfect in their ability     mechanism by which one learns concepts. For example, con-
   to capture the underlying concept to be learned—a property of          cept learning might change from storing exemplars to con-
   our elicited features.
                                                                          structing prototype or rule-based representations. These hy-
   Keywords: characteristic-to-defining shift; concept learning;          pothetical changes in representation or processing might be
   development; computational modeling
                                                                          maturational in nature, such as the development of abstraction
                                                                          (Piaget & Inhelder, 1969). Alternately, they may be driven
                           Introduction                                   by inductive inference mechanisms operating over observed
Children can often comprehend a word and use a word with-                 data, a la rational constructivism (Xu, 2007).
out having a full grasp of its meaning. Consider the fol-                    From the outset we can narrow down this space of hy-
lowing scenario from Keil and Batterman (1984, pp. 226):                  potheses. The conceptual to defining shift is most likely a
“This smelly, mean old man with a gun in his pocket came to               function of data, not maturation (Keil, 1983). One predic-
your house one day and took your colored television set be-               tion of a maturational-shift is that at a single time-point, chil-
cause your parents didn’t want it anymore and told him that               dren should represent all words using characteristic features
he could have it.” While adults have a strong sense that the              or defining features, whereas a data-driven shift predicts that
man in the scenario is not a robber, young children are willing           both adults and children should have more exemplar-based
to label the man a robber. Across multiple domains, young                 representations in unfamiliar domains, and more rule-based
children have been shown to initially privilege perceptually-             representations in familiar domains. The former does not ex-
observable, characteristic information in concept learning.               plain children’s behavior—children seem to possess charac-
Eventually, children transition to more abstract, conceptually-           teristic representations and defining representations of differ-
aligned-upon meanings. This phenomena has been termed                     ent words at a single time point. The prediction of the latter—
the characteristic-to-defining shift (Keil & Batterman, 1984).            that individuals have more exemplar-based representations in
   Previous research has suggested that perceptual similar-               unfamiliar domains and more rule-based representations in
ity (e.g., shape) plays a strong role in young children’s early           familiar domains, is observed in adults (Chi, Feltovich, &
word-concept mappings (e.g. Landau, Smith, & Jones, 1988).                Glaser, 1981) and in children (Chi, 1985).
As children age, they begin to use deeper, relational prop-                  All of the aforementioned hypotheses require a discrete
erties for concept learning (Imai, Gentner, & Uchida, 1994;               shift in representation or process. However, it is un-
Keil & Batterman, 1984). For example, Keil and Batterman                  clear whether a representational or mechanistic shift is en-
(1984) probed kindergartners’, second graders’, and fourth                tirely warranted. To date, no model has tested whether a
graders’ definitions for several words using a scenario task.             characteristic-to-defining shift could be a natural by-product
In some scenarios, characteristic features of a term were pre-            of the continuous data-driven construction of concepts. We
sented without the defining features of the term; whereas,                evaluate this proposal in the task of learning kinship concepts.
other scenarios provided the defining features of the term                While “mommy” and “daddy” are some of a child’s earliest
without the typical characteristic features associated with the           produced words, children actually spend many years master-
term. Younger children extended a word’s meaning to more                  ing kin relations (e.g. Haviland & Clark, 1974; Benson &
scenarios lacking defining features—but possessing many                   Anglin, 1987; Keil & Batterman, 1984). For example, 7- and
characteristic features—than older children.                              8-year-olds are still unable to provide adequate definitions for
                                                                      799

a number of kinship terms (Haviland & Clark, 1974).                   the influence of data with semantic complexity by placing a
                                                                      simplicity weighted prior against a data-driven likelihood.
             The Acquisition of Kin Terms
Kinship is an ideal domain for studying the characteristic-to-                               Our Approach
defining shift because it easily lends to logical representations     We approach this problem at the computational level of anal-
(e.g. Kemp & Regier, 2012); the domain of kinship is fa-              ysis (Marr, 1982) to demonstrate how an ideal learner would
miliar to young children; and the characteristic and defining         manifest a characteristic-to-defining shift. We start with the
features behind kinship terms are fairly intuitive and straight-      model of Mollica and Piantadosi (2015), which demonstrates
forward. Furthermore, several semi-structured interviews at-          how a learner could use cross-situational word-referent occur-
tempting to uncover children’s knowledge of kinship demon-            rences to infer the concept that licenses how a word should be
strate considerable variation in children’s definitions. For ex-      extended. We extend the Probabilistic Context-Free Gram-
ample, the following is an interview with a six-year-old from         mar (PCFG) in their model to construct both characteristic
Benson and Anglin (1987, p. 48):                                      and defining hypotheses for kinship terms. We then col-
   I: What is an uncle?                                               lected data about the characteristic and logical relationships
   S: A man that’s related to ya.
   I: Tell me everything you know about an uncle.                     from two naive informants’ own family trees. This is im-
   S: He knew you when you were a baby...Sometimes they work          portant because the characteristic and logical relationships of
   to build houses... Sometimes they join in for the army.            real people allows us to test if natural data will contain per-
   I: Can you tell me anything else about an uncle?
   S: They help you. That’s all I know.                               ceptual and experiential features informative enough to ob-
   I: What kind of a thing is an uncle?                               serve a characteristic to defining shift. We ran the model on
   S: A man that’s related to you.                                    the informant-provided trees and a simulated tree to generate
Based on children’s definitions, researchers have proposed            possible characteristic and defining hypotheses for four kin-
theories weighing the importance of conceptual simplicity             ship concepts: BROTHER, GRANDMA, MOTHER and UNCLE.
(Haviland & Clark, 1974) and the role of sufficient data              These hypotheses were then scored using Mollica and Pianta-
(Benson & Anglin, 1987) in the acquisition of kinship terms.          dosi (2015)’s Bayesian model according to their simplicity
To explain the order of acquisition of kinship terms, Haviland        and ability to explain simulated word-referent data. We ana-
and Clark (1974) proposed a semantic complexity hypothe-              lyzed (1) whether an ideal learner is most likely to entertain
sis. In this account, the simplicity of a concept is defined          characteristic or defining hypothesis given an amount of data
as the fewest number of base relations (e.g., up one node on          and (2) the accuracy of the hypotheses in explaining the data
the family tree) required to explain a relationship on a kin-         as a function of the amount of data observed.
ship tree with a penalty on the variety of base relations used.          We expect that an ideal learner (without any maturational
Children use these base relations to build concepts in a piece-       factors) should demonstrate a characteristic-to-defining shift
wise fashion. By this logic, adult-like kinship concepts are          only if the elicited features (both perceptual and experiential)
acquired for semantically simpler terms before semantically           are informative but imperfect in their ability to capture the
complex terms. Haviland and Clark (1974)’s original hypoth-           underlying concept. If the elicited features accurately capture
esis is a learning model whereby children first develop per-          a concept, an ideal learner should never shift from generat-
ceptual features to construct a concept and only over time de-        ing characteristic hypotheses to defining hypotheses. On the
velop abstract, relational features. This formalism is entirely       contrary, if the elicited features are uninformative, and thus
consistent with the formalisms used in Mollica and Pianta-            poor at capturing a concept, an ideal learner might predomi-
dosi (2015), which we also adopt and describe below. Fur-             nately generate defining hypotheses, predicting either no shift
thermore, simplicity, in general, is an empirically grounded          or an implausibly rapid shift from characteristic to defining
principle underlying concept construction (Feldman, 2000).            hypotheses. Therefore, it is crucial that we collect data about
More specifically, the role of simplicity and communicative           the characteristic and logical relationships of real people to
efficiency in kinship terms has been demonstrated across a            test if natural data will contain features within the range of
variety of the world’s languages (Kemp & Regier, 2012).               informativity that will show a characteristic-to-defining shift.
   In addition to simplicity, researchers have proposed that
the amount and quality of the observed data drive word learn-         Data Collection
ing and conceptual development both in kinship (Benson &              To simulate data for the learning model, two informants, who
Anglin, 1987; Danziger, 1957) and in other domains (e.g.,             were blind to the experiment, drew their family tree, ranked
Weisleder & Fernald, 2013). For example, Benson and An-               each member in terms of how frequently they interacted with
glin (1987) found that the order of acquisition of kinship            them as a child (e.g., see Figure 1), and provided ten one-
terms was best predicted by children’s experience with their          word adjectives for each family member. For each informant,
relatives. In his rejection of stage theories, Danziger (1957)        the unique adjectives were used to construct a binary feature
proposed that conceptual development is primarily driven by           matrix (adjective by family member; e.g., see Figure 2). Each
opportunities provided by the environment. To account for             informant was presented with the feature matrix and asked to
the influence of data, we incorporate assumptions about plau-         indicate if each feature applied to each family member. In-
sible data distributions in our model. Further, we trade off          formants made a response to every cell of the matrix: zero if
                                                                  800

                                                                                family tree such that 90% of the time the data reflected ac-
                                                                                curate use of the true concept and 10% of the time the data
                                                                                was entirely random. To construct a data point, which took
                                                                                the form of a speaker-referent pair {s, r}, we first sampled
                                                                                a speaker s from a Zipfian distribution over all members of
                                                                                the family tree ordered by reported distance from the learner.
                                                                                Consequently, data from speakers ranked closer in distance
                                                                                to the learner were more likely to be sampled than data from
 Figure 1: Distance-ranked family tree from Informant One.                      speakers ranked distant to the learner, which is in line with
     START → CHAR                         START → DEF
                                                                                the intuition that most input a child receives comes from her
     CHAR → union( CHAR , CHAR )          DEF → union( DEF , DEF )              immediate family. We then sampled a referent r from the Zip-
     CHAR → intersection( CHAR , CHAR )   DEF → intersection( DEF , DEF )
     CHAR → set difference( CHAR , CHAR ) DEF → set difference( DEF , DEF )     fian distribution conditioned on the speaker and word. Given
     CHAR → complement( CHAR )            DEF → complement( DEF )
     CHAR → feature( VAL )                DEF → up node( DEF )                  all possible referents the speaker could be correctly referring
     VAL → {Yes, No}                      DEF → down node( DEF )
                                          DEF → lateral node( DEF )
                                                                                to when using the word, referents that are closer to the learner
                                          DEF → male( DEF )                     are more likely to be talked about than the learner’s more dis-
                                          DEF → female( DEF )
                                          DEF → X (i.e., the speaker)           tant relations. This reflects the intuition that a child is more
                                                                                likely to hear about her immediate family than distant rela-
Table 1: The Probabilistic Context Free Grammar used to                         tives. Both intuitions are supported by Benson and Anglin
generate kinship concepts                                                       (1987)’s survey of children’s experience with kinship terms
                                                                                and relations. During learning, we compute the likelihood of
the feature did not apply; one if the feature did apply. The
                                                                                the data under the same model used to simulate the data.
informants provided 109 and 88 unique features respectively
                                                                                   Together the prior and the likelihood specify a model for
including both experiential features (e.g., strict) and percep-
                                                                                all possible hypotheses constructed from the PCFG:
tually observable features (e.g., blonde). Additionally, we                                                     N
simulated data from the extended family tree used in Mollica                                   P(h|{s, r}Ni ) ∝ ∏ P(ri |si , h) · P(h)       (1)
and Piantadosi (2015). To sample from the extended tree, we                                                     i
ranked distance using Euclidean distance and constructed a                         With this model we can score the probability of a hypoth-
feature matrix for the tree based on 29 perceptually observ-                    esis conditioned on simulated data. We then investigate the
able features following the principles of Mendelian genetics1 .                 conditions under which a characteristic-to-defining “shift”
Extending the model                                                             will naturally emerge as children learn kinship concepts with-
                                                                                out positing discrete change.
The model incorporates a PCFG prior with uniform rule prob-
abilities to measure the simplicity of any composition of log-                                              Methods
ical or perceptual features. In the PCFG (see Table 1), we                      Discovering the most likely hypotheses considered by an
include set theoretical primitives—i.e., union, intersection,                   ideal learner according to Equation 1 is a complex inference
set difference and complement—for both characteristic and                       problem because the PCFG specifies an infinite set of possi-
defining hypotheses. For defining hypotheses, we include                        ble hypotheses. We solved this problem with Markov-Chain
gender primitives—i.e., male and female—and graph theo-                         Monte-Carlo (MCMC) methods, which provided us with
retical primitives that mimic the abstract primitives proposed                  samples from the posterior distribution by walking around the
by Haviland and Clark (1974): up node, down node and lat-                       space of hypotheses. In the limit these walks provably draw
eral node. The terminal for a defining hypothesis is an argu-                   samples from the true posterior distribution P(h|{s, r}Ni ). We
ment for the speaker X, as we assume that the kinship term                      implement our model using LOTlib (Piantadosi, 2014).
should be processed relative to the speaker. For characteris-                      At different amounts of data, we expected an ideal learner
tic hypotheses, we include a primitive for each feature, which                  to favor different hypotheses. Therefore, we explored the
takes a binary indicator variable and returns the set of fam-                   space varying the amount of data between 10 data points and
ily members with or without that feature. Using a PCFG as                       250 data points by 10 point increments. At each increment of
a prior penalizes complex hypothetical meanings and, thus,                      data, we ran eight chains per hypothesis type for one million
builds in a simplicity bias as discussed above. It is important                 steps. We stored the top 1000 hypotheses from each chain and
to note that our PCFG generates characteristic hypotheses—                      combined the hypotheses discovered across chains to form a
i.e., only containing characteristic information, and defining                  finite hypothesis space representing the posterior distribution
hypotheses—i.e., only containing logical information (and                       over hypotheses. We normalized all hypotheses by calculat-
gender). We leave the exploration of a hybrid characteristic-                   ing the likelihood over the same set of 1000 data points gen-
defining hypothesis space for future research.                                  erated using the same procedure used to generate data for in-
   Data for the learning model was noisily sampled from a                       dividual chains. We then divided this value by the amount of
    1 All family trees, feature matrices (and code) can be found at             data (i.e., 1000) to get a measure of each hypothesis’ average
https://github.com/MollicaF/LogicalWordLearning                                 log likelihood per data point.
                                                                            801

                              Results                                     their posterior probability relative to the correct hypothesis,
                                                                          which will make the correct hypothesis the maximum a pos-
The upper panels of Figure 4 show the posterior probability
                                                                          teriori (MAP).
of entertaining either a characteristic or defining hypothesis
                                                                              The range of hypotheses are similar between the different
(y-axis) as a function of the amount of data observed (x-axis).
                                                                          trees. Across all trees, characteristic hypotheses have very
For all of the words, we observe the characteristic-to-defining
                                                                          low posterior weighted F1 scores compared to the defining
shift–i.e., the probability of entertaining a characteristic hy-
                                                                          hypotheses. In other words, characteristic hypotheses mis-
pothesis is initially greater than the probability of entertaining
                                                                          label referents more than defining hypotheses. Yet, the pos-
a defining hypothesis. This means that a simple conceptual
                                                                          terior probability of characteristic hypotheses suggests that
learning model shows a characteristic-to-defining shift when
                                                                          characteristic hypotheses are clearly favored at low amounts
given real data about logical relations and characteristic fea-
                                                                          of data. Given the perspective that the emergence of defin-
tures.
                                                                          ing hypotheses is delayed due to the development of abstrac-
   The lower panels of Figure 4 show the posterior weighted
                                                                          tion, it is particularly important to note that even in a model
F1 score conditioned on hypothesis type (characteristic or
                                                                          with abstraction available from the beginning, we observe a
defining). The F1 score is the harmonic mean of precision
                                                                          characteristic-to-defining shift. Further, compared to a neu-
(i.e., the pressure to extend without over-extending) and recall
                                                                          ral network model where all features are initially considered
(i.e., the pressure to extend to all the correct referents). An F1
                                                                          (Shultz et al., 2008), a characteristic-to-defining shift is still
score of 1 reflects perfect performance. Notably in Figure
                                                                          observed in our model where it is initially more likely to only
4, the model successfully learns BROTHER, GRANDMOTHER,
                                                                          consider only a few features.
and MOTHER—i.e., posterior weighted F1 scores all reach 1.
                                                                              Taken together, this pattern of results demonstrates that
With 250 data points, the model does not successfully learn
                                                                          the characteristic-to-defining shift could naturally fall out of
UNCLE yet there still is a shift from characteristic to defin-
                                                                          a single statistical inference process with a single represen-
ing hypotheses on a larger timescale2 (Note the x-axis in the
                                                                          tational language3 . It is not necessary to propose a dis-
upper panels).
                                                                          crete change in representation or processing. Characteris-
   To help build intuitions about how the model works, Fig-               tic hypotheses are favored early because with little data the
ure 3 presents the three most likely hypotheses an ideal                  prior dominates inference–they generalize well to small data
learner trained on Informant One’s data would consider for                amounts and are comparatively less complex in the prior than
GRANDMA at three time points. Before observing data, an
                                                                          the best defining hypotheses. Only when there is enough
ideal learner should prefer the simplest hypotheses, which of-            data to warrant additional complexity will defining hypothe-
ten generalize to many referents. In this example the three               ses come to dominate inference.
most likely hypotheses are defining hypotheses that select the
speaker X, a male speaker and everybody but the speaker.                                                Discussion
After observing three data points, the hypotheses considered
become much more plausible and shift to characteristic fea-               In this paper, we tested whether a characteristic-to-defining
tures. At this time, the three best hypotheses for grandma are            shift would emerge naturally in a statistically principled
that grandmas are either outgoing, nosy or small. In general              learning model without positing a discrete mechanistic or rep-
the model is shifting from simple hypotheses that general-                resentational shift. In general, the model successfully learns
ize broadly to hypotheses that narrow in a bit more, yet still            kinship terms and demonstrates a characteristic-to-defining
over-extend. Immediately post-shift (i.e., 13 data points), we            shift using a single representational language of thought and
observe a mixture of characteristic and defining hypotheses.              a single statistical inference mechanism. Therefore, while a
The best hypothesis is the speaker’s parents’ parents, which              discrete shift in mechanism or process is possible, it is not
misses the female component of GRANDMA. The next best                     necessary to observe a characteristic-to-defining shift during
hypothesis is that grandmas are outgoing. The third best hy-              concept learning.
pothesis is actually the definition of a GRANDMA—i.e., the                    In our model, kinship concepts are developed through sta-
female parents of the speaker’s parents. This glimpse at the              tistical inference over word-referent data and observed kin-
hypotheses just after the shift illustrates that without a suffi-         ship structures, which could plausibly be developed from
cient amount of data, even the correct hypothesis is unlikely             statistical learning of structure (Katz, Goodman, Kersting,
because it is more complex in the prior. As we observe more               Kemp, & Tenenbaum, 2008; Kemp & Tenenbaum, 2008).
data, the imprecision of the two leading hypotheses decreases             When an ideal learner only observes data about a few ref-
                                                                          erents, there are simple characteristic hypotheses based on
    2 This may be due to data sparsity for UNCLE in the trees. As         perceptual observations that will explain the data; however,
UNCLE    is the most complex concept learned here, it may be that         as more data is observed, these hypotheses fail to adequately
UNCLE    requires more unique data points to be learned. Under our        fit the data and warrant a prior-likelihood trade-off, such that
Zipfian data sampling, the model receives data for less than half of
the unique uncles in the trees. When you relax the sampling assump-       more complicated defining hypotheses (which are unlikely
tion to uniform, the model does learn UNCLE and having the correct
hypothesis in the space alters the time scale of the shift (to around          3 This pattern holds if the data distribution is uniform or becomes
30 data points).                                                          more peaked—i.e., a Zipfian exponent of 0, 1 or 2.
                                                                      802

                                                                 Informant One
                                                       (109 features; 31 family members)
                                        brother                    grandma                    mother                       uncle
Posterior Probability
                        1.00
                        0.75
                        0.50                                                                                                       CHAR
                                                                                                                                   DEF
                        0.25
                        0.00
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600
                                                                        Number of Data Points
Posterior Weighted F1
                        1.00
                        0.75
                        0.50
                        0.25
                        0.00
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600
                                                                        Number of Data Points
                                                                Informant Two
                                                       (88 features; 21 family members)
                                        brother                    grandma                    mother                       uncle
Posterior Probability
                        1.00
                        0.75
                        0.50
                        0.25
                        0.00
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600
                                                                        Number of Data Points
Posterior Weighted F1
                        1.00
                        0.75
                        0.50
                        0.25
                        0.00
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600
                                                                        Number of Data Points
                                                                Simulated Tree
                                                                                                                                          Figure 2: Feature matrix (adjective by family
                                                       (29 features; 37 family members)                                                   member) supplied by Informant One.
                                        brother                    grandma                    mother                       uncle
                                                                                                                                              Before seeing data
Posterior Probability
                        1.00
                        0.75                                                                                                               X (i.e., the speaker)      −0.0861777
                        0.50                                                                                                               male(X)                    −4.7775256
                        0.25
                                                                                                                                           complement(X)              −4.7775256
                        0.00
                                                                                                                                              After seeing 3 data points
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600     outgoing                    −19.69045
                                                                        Number of Data Points                                              nosy                        −20.49538
                                                                                                                                                                       −21.56817
Posterior Weighted F1
                        1.00                                                                                                               small
                        0.75                                                                                                                  One data point after shift
                        0.50
                                                                                                                                           parents(parents(X))         −67.18689
                                                                                                                                           outgoing                    −67.31635
                        0.25
                                                                                                                                           female(parents(parents(X))) −68.14575
                        0.00
                               0   10   20   30   40   50 0   10   20   30   40   50 0   10   20   30   40   50 0    200    400    600    Figure 3: Best hypotheses at three different
                                                                        Number of Data Points                                             time points and their log posterior probability
                                                                                                                                          for Informant One learning GRANDMA.
Figure 4: For each tree, the top panel displays the posterior probability of using a characteristic (solid line) or a defining
(dashed line) hypothesis as a function of the amount of data observed. The bottom panel displays the posterior weighted F1
score conditioned on hypothesis type (characteristic as solid line, defining as dashed line) as a function of data.
                                                                                                               803

in the prior) are substantially more likely in explaining the          their ability to capture the underlying concept. While we ad-
data and thus come to dominate the posterior. Put simply, the          dress the problem of concept learning within the kinship do-
characteristic-to-defining shift can be a by-product of data-          main, the model framework can be extended to explain con-
driven learning.                                                       cept learning across multiple domains using different repre-
   There are two interesting implications/predictions of our           sentational formalisms.
model. First, our model predicts that the ideal learner will
shift from characteristic to defining hypotheses even when                                         References
she is capable of using abstraction from the outset of learn-          Benson, N. J., & Anglin, J. M. (1987). The child’s knowledge of
                                                                         english kin terms. First Language, 7(19), 41–66.
ing. This suggests that characteristic hypotheses may be use-          Bruner, J. S., Olver, R. R., Greenfield, P. M., et al. (1966). Studies
ful, and that the observation that children accept and generate          in cognitive growth. Wiley.
characteristic hypotheses at a young age does not preclude             Chi, M. T. (1985). Interactive roles of knowledge and strategies
                                                                         in the development of organized sorting and recall. Thinking and
their ability to use abstraction or generate logical/defining            learning skills, 2, 457–483.
hypotheses. Second, our model predicts that if there is a              Chi, M. T., Feltovich, P. J., & Glaser, R. (1981). Categorization
characteristic-to-defining shift, the relevant characteristic fea-       and representation of physics problems by experts and novices.
                                                                         Cognitive science, 5(2), 121–152.
tures should not capture a concept as well as defining features        Danziger, K. (1957). The child’s understanding of kinship terms: A
capture the concept; however, in order for a characteristic-             study in the development of relational concepts. The Journal of
to-defining shift to occur, the characteristic features must be          genetic psychology, 91(2), 213–232.
                                                                       Feldman, J. (2000). Minimization of boolean complexity in human
informative to a certain degree. If characteristic features are          concept learning. Nature, 407(6804), 630–633.
completely uninformative, defining hypotheses should domi-             Haviland, S. E., & Clark, E. V. (1974). this man’s father is my fa-
nate across all amounts of data.                                         ther’s son: a study of the acquisition of english kin terms. Journal
                                                                         of Child Language, 1(01), 23–47.
   In our initial stab at the problem, we have made several            Imai, M., Gentner, D., & Uchida, N. (1994). Children’s theories of
simplifications. For one, the grammar generated hypotheses               word meaning: The role of shape similarity in early acquisition.
                                                                         Cognitive Development, 9(1), 45–75.
to be purely characteristic or purely defining. This simpli-           Katz, Y., Goodman, N. D., Kersting, K., Kemp, C., & Tenenbaum,
fication is reasonable given how adults would extend a kin-              J. B. (2008). Modeling semantic cognition as logical dimension-
ship term. For example, if you meet a friend’s family for                ality reduction. In Proceedings of thirtieth annual meeting of the
                                                                         cognitive science society.
the first time at a neighborhood BBQ, you would presum-                Keil, F. C. (1983). On the emergence of semantic and concep-
ably extend the term uncle to their parent’s male siblings and           tual distinctions. Journal of Experimental Psychology: General,
not the neighbors, who might share several characteristic fea-           112(3), 357.
                                                                       Keil, F. C., & Batterman, N. (1984). A characteristic-to-defining
tures with your friend’s uncles. This is not to say that compe-          shift in the development of word meaning. Journal of Verbal
tent adult speakers do not maintain characteristic information           Learning and Verbal Behavior, 23(2), 221–236.
about kinship terms (e.g., grandmothers are typically nice,            Kemler, D. G. (1983). Exploring and reexploring issues of integral-
                                                                         ity, perceptual sensitivity, and dimensional salience. Journal of
old ladies). In the same vein, our characteristic and defin-             Experimental Child Psychology, 36(3), 365–379.
ing features did not share the same formalism (i.e., feature           Kemp, C., & Regier, T. (2012). Kinship categories across languages
matrices vs. graph-theoretical functions). A future version              reflect general communicative principles. Science, 336(6084),
                                                                         1049–1054.
of the model should permit characteristic and defining primi-          Kemp, C., & Tenenbaum, J. B. (2008). The discovery of structural
tives within the same hypothesis and possibly within the same            form. Proceedings of the National Academy of Sciences, 105(31),
formalism (e.g., a feature matrix containing both characteris-           10687–10692.
                                                                       Landau, B., Smith, L. B., & Jones, S. S. (1988). The importance
tic and defining features). This model should also be extended           of shape in early lexical learning. Cognitive development, 3(3),
beyond the kinship domain. Lastly, the model is sensitive to             299–321.
the structure of the PCFG in determining the prior. Further            Marr, D. (1982). Vision: A computational approach. Freeman &
                                                                         Co., San Francisco.
research should characterise the robustness of the model to            Mollica, F., & Piantadosi, S. T. (2015). Towards semantically rich
variation in the prior.                                                  and recursive word learning models. In Proceedings of the 37th
                                                                         annual meeting of the cognitive science society (pp. 1607–1612).
                                                                       Piaget, J., & Inhelder, B. (1969). The psychology of the child. Basic
                         Conclusion                                      Books.
                                                                       Piantadosi, S. T.         (2014).      LOTlib: Learning and In-
In summary, the widely observed characteristic-to-defining               ference in the Language of Thought.                  available from
shift falls out naturally from a rational data-driven process.           https://github.com/piantado/LOTlib.
Our simulations show that a data-driven inference mecha-               Shultz, T. R., Thivierge, J.-P., & Laurin, K. (2008). Acquisition of
                                                                         concepts with characteristic and defining features. Proceedings
nism (1) demonstrates a characteristic-to-defining shift in the          of the 30th Annual Conference of the Cognitive Science Society,
task of concept learning without positing a change in cogni-             531–536.
tive representations or processes and (2) succeeds at learning         Weisleder, A., & Fernald, A. (2013). Talking to children matters
                                                                         early language experience strengthens processing and builds vo-
most kinship words from a data distribution based on natural             cabulary. Psychological Science, 24(11), 2143–2152.
language statistics. We find that an ideal learner will demon-         Werner, H. (1948). Comparative psychology of mental development.
strate a shift even when more accurate abstract/logical rep-             Follett Pub. Co.
                                                                       Xu, F. (2007). Rational statistical inference and cognitive develop-
resentations are possible from the onset of learning provided            ment. The innate mind: Foundations and the future, 3, 199–215.
that characteristic features are informative but imperfect in
                                                                   804

