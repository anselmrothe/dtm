                        The Causal Frame Problem: An Algorithmic Perspective
                                    Ardavan S. Nobandegani1,2           Ioannis N. Psaromiligkos1
                                   {ardavan.salehinobandegani@mail.mcgill.ca, yannis@ece.mcgill.ca}
                                 1 Department   of Electrical & Computer Engineering, McGill University
                                              2 Department of Psychology, McGill University
                               Abstract                                 in time and computational resources—would never get to the
   The Frame Problem (FP) is a puzzle in philosophy of mind
                                                                        second step, had she adhered to such a methodology. In other
   and epistemology, articulated by the Stanford Encyclopedia of        words, in line with the notion of bounded rationality (Simon,
   Philosophy as follows: “How do we account for our apparent           1957), a boundedly-rational reasoner must have the option, if
   ability to make decisions on the basis only of what is relevant      need be, to merely consult a fraction of the potentially large—
   to an ongoing situation without having explicitly to consider
   all that is not relevant?” In this work, we focus on the causal      if not infinitely so—relevant submodel.
   variant of the FP, the Causal Frame Problem (CFP). Assuming             Icard and Goodman (2015) elegantly promote this insight
   that a reasoner’s mental causal model can be (implicitly) repre-
   sented by a causal Bayes net, we first introduce a notion called     when they write: “Somehow the mind must focus in on some
   Potential Level (PL). PL, in essence, encodes the relative po-       “submodel” of the “full” model (including all possibly rele-
   sition of a node with respect to its neighbors in a causal Bayes     vant variables) that suffices for the task at hand and is not too
   net. Drawing on the psychological literature on causal judg-
   ment, we substantiate the claim that PL may bear on how time         costly to use.”1 They then ask the following question: “what
   is encoded in the mind. Using PL, we propose an inference            kind of simpler model should a reasoner consult for a given
   framework, called the PL-based Inference Framework (PLIF),           task?” This is an inspiring question hinting to an interesting
   which permits a boundedly-rational approach to the CFP, for-
   mally articulated at Marr’s algorithmic level of analysis. We        line of inquiry as to how to formally articulate a boundedly-
   show that our proposed framework, PLIF, is consistent with           rational approach to the FP, at Marr’s (1982) algorithmic level
   several findings in the causal judgment literature, and that PL      of analysis.
   and PLIF make a number of predictions, some of which are
   already supported by existing findings.                                 In this work, we focus on the causal variant of the FP, the
   Keywords: Frame Problem; Time and Causality; Bounded                 Causal Frame Problem (CFP), stated as follows: Upon being
   Rationality; Algorithmic Level of Analysis; Rational Process         presented with a causal query, how does the reasoner manage
   Models                                                               to attend to her causal knowledge relevant to the derivation
                                                                        of the query while rightfully dismissing the irrelevant? We
                        1    Introduction                               adopt Causal Bayesian Networks (CBNs) (Pearl, 1988; Gop-
At the core of any decision-making or reasoning task, re-               nik et al., 2004, inter alia) as a normative model to represent
sides an innocent-looking yet challenging question: Given               how the reasoner’s internal causal model of the world is struc-
an inconceivably large body of knowledge available to the               tured (i.e., reasoner’s mental model). First, we introduce the
reasoner, what constitutes the relevant for the task and what           notion of Potential Level (PL). PL, in essence, encodes the
the irrelevant? The question, as it is posed, echoes the well-          relative position of a node (representing a propositional vari-
known Frame Problem (FP) in epistemology and philosophy                 able or a concept) with respect to its neighbors in a CBN.
of mind, articulated by Glymour (1987) as follows: “Given               Drawing on the psychological literature on causal judgment,
an enormous amount of stuff, and some task to be done                   we substantiate the claim that PL may bear on how time is
using some of the stuff, what is the relevant stuff for the             encoded in the mind. Equipped with PL, we embark on in-
task?” Fodor (1987) comments: “The frame problem goes                   vestigating the CFP at Marr’s algorithmic level of analysis.
very deep; it goes as deep as the analysis of rationality.”             We propose an inference framework, termed PL-based In-
   The question posed above perfectly captures what is really           ference Framework (PLIF), which aims at empowering the
at the core of the FP, yet, it may suggest an unsatisfying ap-          boundedly-rational reasoner to consult (or retrieve2 ) parts of
proach to the FP at the algorithmic level of analysis (Marr,            the underlying CBN deemed relevant for the derivation of
1982). Indeed, the question may suggest the following two-              the posed query (the relevant submodel) in a local, bottom-
step methodology: In the first step, out of all the body of             up fashion until the submodel is fully retrieved. PLIF allows
knowledge available to the reasoner (termed, the model), she            the reasoner to carry out inference at intermediate stages of
has to identify what is relevant to the task (termed, the rele-         the retrieval process over the thus-far retrieved parts, thereby
vant submodel); it is only then that she advances to the second         obtaining lower and upper bounds on the posed causal query.
step by performing reasoning or inference on the identified
submodel. There is something fundamentally wrong with this                  1 In an informative example on Hidden Markov Models (HMMs),
methodology (which we term, sequential approach to reason-              Icard and Goodman (2015) present a setting wherein the relevant
ing) which bears on the following understanding: The rele-              submodel is infinitely large—an example which highlights what is
                                                                        wrong with the sequential approach stated earlier.
vant submodel, i.e., the portion of the reasoner’s knowledge                2 The terms “consult” and “retrieve” will be used interchange-
deemed relevant to the task, oftentimes is so enormous (or              ably. We elaborate on the rationale behind that in Sec. 5, where we
even infinitely large) that the reasoner—inevitably bounded             connect our work to Long Term Memory and Working Memory.
                                                                    3046

We show, in the Discussion section, that our proposed frame-                    Before formally introducing the notion of PL, we articu-
work, PLIF, is consistent with several findings in the causal                late in simple terms what the idea behind PL is. PL simply
judgment literature, and that PL and PLIF make a number of                   induces a chronological order on the nodes of a CBN, al-
predictions, some of which are already supported by the find-                lowing the reasoner to encode the timing between cause and
ings in the psychology literature.                                           effect.5 As we will see, PL plays an important role in guiding
    In their work, Icard and Goodman (2015) articulate a                     the retrieval process used in our proposed framework. Next,
boundedly-rational approach to the CFP at Marr’s computa-                    PL is formally defined, followed by two clarifying examples.
tional level of analysis, which, as they point out, is from a                   Def. 1. (Potential Level (PL)) Let par(x) and child(x)
“god’s eye” point of view. In sharp contrast, our proposed                   denote, respectively, the sets of parents (i.e., immediate
framework PLIF is not from a “god’s eye” point of view and                   causes) and children (i.e., immediate effects) of x. Also let
hence could be regarded, potentially, as a psychologically                   T0 ∈ R ∪ {−∞}. The PL of x, denoted by pl (x), is de-
plausible proposal at Marr’s algorithmic level of analysis as                fined as follows: (i) If par(x) = ∅, pl (x) = T0 , and (ii) If
to how the mind both retrieves and, at the same time, carries                par(x) 6= ∅, pl (x) is a real-valued quantity selected from
out inference over the retrieved submodel to derive bounds                   the interval (maxy∈par(x) pl (y), minz∈child(x) pl (z)) such that
on a causal query. We term this concurrent approach to rea-                  pl (x) − maxy∈par(x) pl (y) indicates the amount of time which
soning, as opposed to the flawed sequential approach stated                  elapses between intervening simultaneously on all the RVs
earlier.3 The retrieval process progresses in a local, bottom-               in par(x) (i.e., do(par(x) = parx )) and x taking its value x
up fashion, hence the submodel is retrieved incrementally, in                in accord with the distribution P(x|parx ). If child(x) = ∅,
a nested manner.4 Our analysis (Sec. 4.1) confirms Icard                     substitute the upper bound of the given interval by +∞.           
and Goodman’s (2015) insight that even in the extreme case                      Parameter T0 symbolizes the origin of time, as perceived
of having an infinitely large relevant submodel, the portion                 by the reasoner. T0 = 0 is a natural choice, unless the rea-
of which the reasoner has to consult so as to obtain a “suffi-               soner believes that time continues unboundedly into the past,
ciently good” answer to a query could indeed be very small.                  in which case T0 = −∞. The next two examples further clar-
                                                                             ify the idea behind PL. In both examples we assume T0 = 0.
                2     Potential Level and Time
                                                                                              −∞                         −∞
Before proceeding further, let us introduce some preliminary
notations. Random Variables (RVs) are denoted by lower-                                pl (x) = 4        x        pl (x) = 4           x
case bold-faced letters, e.g., x, and their realizations by non-                                                                y
                                                                                                               pl (y) = 4.7               z
bold lower-case letters, e.g., x. Likewise, sets of RVs are de-                     pl (y) = 4.7         y        pl (z) = 5
noted by upper-case bold-faced letters, e.g., X, and their cor-                        pl (z) = 5         z
responding realizations by upper-case non-bold letters, e.g.,
                                                                                                                pl (t) = 5.6           t
X. Val(·) denotes the set of possible values a random quan-                                   +∞                         +∞
tity can take on. Random quantities are assumed to be dis-                                             (a)                          (b)
crete unless stated otherwise. The joint probability distribu-
tion over x1 , · · · , xn is denoted by P(x1 , · · · , xn ). We will use     Figure 1: Relation between PL and time. Three hollow dots
the notation x1:n to denote the sequence of n RVs x1 , · · · , xn ,          signify that the depicted CBNs extend into the past and future.
hence P(x1 , · · · , xn ) = P(x1:n ). The terms “node” and “vari-
able” will be used interchangeably. To simplify presenta-                       For the first example, let us consider the CBN depicted
tion, we adopt the following notation: We denote the prob-                   in Fig. 1(a) containing the RVs x, y, and z with pl (x) =
ability P(x = x) by P(x) for some RV x and its realiza-                      4, pl (y) = 4.7, and pl (z) = 5. According to Def. 1, the
tion x ∈ Val(x). For conditional probabilities, we will use                  given PLs can be construed in terms of the relative time be-
the notation P(x|y) instead of P(x = x|y = y). Likewise,                     tween the occurrence of cause and effect as articulated next.
P(X|Y ) = P(X = X|Y = Y ) for X ∈ Val(X) and Y ∈ Val(Y).                     Upon intervening on x (i.e., do(x = x)), after the elapse of
A generic conditional independence relationship is denoted                   pl (y) − pl (x) = 0.7 units of time, the RV y takes its value y in
by (A ⊥   ⊥ B|C) where A, B, and C represent three mutually                  accord with the distribution P(y|x). Likewise, upon interven-
disjoint sets of variables belonging to a CBN. Furthermore,                  ing on y (i.e., do(y = y)), after the elapse of pl (z) − pl (y) =
throughout the paper, we assume that ε is some negligibly                    0.3 units of time, z takes its value z according to P(z|y).
small positive real-valued quantity. Whenever we subtract ε                     For the second example, consider the CBN depicted in Fig.
from a quantity, we simply imply a quantity less than but ar-                1(b) containing the RVs x, y, z, and t with pl (x) = 4, pl (y) =
bitrarily close to the original quantity. The rationale behind               4.7, pl (z) = 5, and pl (t) = 5.6. Upon intervening on x (i.e.,
adopting such a notation will become clearer in Sec. 4.                      do(x = x)) the following happens: (i) after the elapse of
                                                                             pl (y)− pl (x) = 0.7 units of time, y takes its value y according
     3 We  elaborate more on this in the Discussion section.                 to P(y|x), and (ii) after the elapse of pl (z) − pl (x) = 1 unit of
     4 The  term “nested” implies that the thus-far retrieved submodel
is subsumed by every later submodel (provided that the reasoner pro-             5 More precisely, PL induces a topological order on the nodes of
ceeds with the retrieval process).                                           a CBN, with temporal interpretations suggested in Def. 1.
                                                                         3047

                                                                                      −∞
time, z takes its value z according to P(z|x). Also, upon inter-
vening simultaneously on RVs y, z (i.e., do(y = y, z = z)), af-
ter the elapse of pl (t) − maxr∈par(t) pl (r) = 0.6 units of time,                 pl (y)          y          y        y          y          y
t takes its value t according to P(t|y, z).
   In sum, the notion of PL bears on the underlying time-grid                     pl (t2 )        t2                  t2          t2        t2
upon which a CBN is constructed, and adheres to Hume’s
principle of temporal precedence of cause to effect (Hume,                        pl (t1 )        t1         t1       t1          t1        t1
1748/1975). A growing body of work in psychology liter-
ature corroborates Hume’s centuries-old insight, suggesting                        pl (x)          x          x        x          x          x
that the timing and temporal order between events strongly
influences how humans induce causal structure over them                               +∞        (a)        (b)      (c)        (d)        (e)
(Bramley, Gerstenberg, & Lagnado, 2014; Lagnado & Slo-
man, 2006). The introduced notion of PL is based on the                     Figure 2: Example. Query variables are shown in orange.
following hypothesis: When learning the underlying causal
structure of a domain, humans may as well encode the tem-
poral patterns (or some estimates thereof) on which they rely                 Starting from the target RV x in the original CBN (Fig.
to infer the causal structure. This hypothesis is supported               2(a)) and moving one step backwards,7 t1 is reached (Fig.
by recent findings suggesting that people have expectations               2(b)). Since pl (y) < pl (t1 ), y must be a non-descendant of
about the delay length between cause and effect (Greville &               t1 , and therefore, of x. Hence, conditioning on t1 d-separates
Buehner, 2010; Buehner & May, 2004; Schlottmann, 1999).                   x from y (Pearl, 1988), yielding (x ⊥       ⊥ y|t1 ). Thus P(x|y) =
It is worth noting that we could have defined PL in terms of              ∑t1 ∈Val(t1 ) P(x|y,t1 )P(t1 |y) = ∑t1 ∈Val(t1 ) P(x|t1 )P(t1 |y) imply-
relative expected time between cause and effect, rather than              ing: mint1 ∈Val(t1 ) P(x|t1 ) ≤ P(x|y) ≤ maxt1 ∈Val(t1 ) P(x|t1 ). It
relative absolute time. Under such an interpretation, the time            is crucial to note that the given bounds can be computed
which elapses between the intervention on a cause and the oc-             using the information thus-far retrieved, i.e., the informa-
currence of its effect would be modeled by a probability dis-             tion encoded in the submodel shown in Fig. 2(b). Taking
tribution, and PL would be defined in terms of the expected               a step backwards from t1 , t2 is reached (Fig. 2(c)). Using
value of that distribution. Our proposed framework, PLIF, is              a similar line of reasoning to the one presented for t1 , hav-
indifferent as to whether PL should be construed in terms of              ing pl (y) < pl (t2 ) ensures (x ⊥    ⊥ y|t2 ). Therefore, the fol-
absolute or expected time. Greville and Buehner (2010) show               lowing bounds on the posed query can be derived, which,
that causal relations with fixed temporal intervals are con-              crucially, can be computed using the information thus-far re-
sistently judged as stronger compared to those with variable              trieved: mint2 ∈Val(t2 ) P(x|t2 ) ≤ P(x|y) ≤ maxt2 ∈Val(t2 ) P(x|t2 ).
temporal intervals. This finding, therefore, seems to suggest             It is straightforward to show that the bounds derived in terms
that people expect, to a greater extent, fixed temporal inter-            of t2 are equally tight or tighter than the bounds derived in
vals between cause and effect, rather than variable ones—an               terms of t1 . Finally, taking one step backward from t2 , y is
interpretation which, at least to a first approximation, favors           reached (Fig. 2(d)) and the exact value for P(x|y) can be de-
construing PL in terms of relative absolute time (see Def. 1).6           rived, again using the submodel thus-far retrieved (Fig. 2(d)).
                                                                              We are now ready to present our proposed framework.
                 3     Informative Example
                                                                               4     PL-based Inference Framework (PLIF)
To develop our intuition, and before formally articulating our
proposed framework, let us present a simple yet informative               In this section, we intend to elaborate on how, equipped
example which demonstrates: (i) how the retrieval process                 with the notion of PL, a generic causal query of the form8
can be carried out in a local, bottom-up fashion, allowing for            P(O = O|E = E) can be derived where O and E denote, re-
retrieving the relevant submodel incrementally, and (ii) how              spectively, the disjoint sets of target (or objective) and ob-
adopting PL allows the reasoner to obtain bounds on a given               served (or evidence) variables. In other words, we intend to
causal query at intermediate stages of the retrieval process.             formalize how inference over a CBN whose nodes are en-
   Let us assume that the posed causal query is P(x|y) where              dowed with PL as an attribute should be carried out. Before
x, y are two RVs in the CBN depicted in Fig. 2(a) with PLs                we present the main result, a few definitions are in order.
pl (x), pl (y), and let pl (x) > pl (y). The relevant information             Def. 2. (Critical Potential Level (CPL)) The target vari-
for the derivation of the posed query (i.e., the relevant sub-            able with the least PL is denoted by o∗ and its PL is re-
model) is depicted in Fig. 2(e).                                          ferred to as the CPL. More formally, p∗l :, mino∈O pl (o) and
    6 There are cases, however, that, despite the precedence of cause          7 Taking one step backwards from variable q amounts to retriev-
to effect, quantifying the amount of time between their occurrences       ing all the parents of q .
may bear no meaning, e.g., when dealing with hypothetical con-                 8 We do not consider interventions in this work. However,
structs. In such cases, PL should be simply construed as a topo-          with some modifications, the presented analysis/results can be ex-
logical ordering. From a purely computational perspective, PL is a        tended to handle a generic causal query of the form P(O = O|E =
generalization of topological sorting in computer science.                E, do(Z = Z)) where Z denotes the set of intervened variables.
                                                                      3048

o∗ :, arg mino∈O pl (o). E.g., for the setting given in Fig. 2(a),          (iii) the lower and upper bound given in Lemma 1 are iden-
o∗ = x, and p∗l = pl (x). Viewed through the lens of time, o∗               tical, then the exact value of the posed query can be derived
is the furthest target variable into the past, with PL p∗l .                using the submodel retrieved in the process of obtaining RT .
   There are two possibilities: (a) p∗l > T0 , or (b) p∗l = T0 ,            Fig. 2(d) shows a setting wherein (i) and (iii) are both met.
with T0 denoting the origin of time; cf. Sec. 2. In the sequel,
we assume that (a) holds.9                                                  4.1     Case Study
   Def. 3. (Inference Threshold (IT) and IT Root Set (IT-                   Next, we intend to cast the Hidden Markov Model (HMM)
RS)) To any real-valued quantity, T , corresponds a unique                  studied in (Icard & Goodman, 2015, p. 2) into our frame-
set, RT , obtained as follows: Start at every variable x ∈ O ∪ E            work. The setting is shown in Fig. 3(left). We adhere to the
with PL ≥ T and backtrack along all paths terminating at x.
Backtracking along each path stops as soon as a node with PL                              −∞                           0.9
                                                                                   xt-3
less than T is encountered. Such nodes, together, compose                                 pl (xt−3 ) = −5              0.8
the set RT . It follows that: maxt∈RT pl (t) < T . T and RT
                                                                            yt-3   xt-2
                                                                                                                       0.7
                                                                                                            P (xt+1 jy!1:t )
are termed, respectively, Inference Threshold (IT) and the IT                             pl (xt−2 ) = −4
                                                                                                                       0.6
Root Set (IT-RS) for T .                                                    yt-2   xt-1                                0.5
   For example, the set of variables circled at the stages de-                            pl (xt−1 ) = −3
picted in Figs. 2(b-d) are the IT-RSs for T = pl (x) − ε,                   yt-1
                                                                                                                       0.4
                                                                                   xt
T = pl (t1 ) − ε, and T = pl (t2 ) − ε, respectively. Note that                           pl (xt ) = −2                0.3
instead of saying T = pl (x) − ε we could have said: for any                yt                                         0.2
                                                                                   xt+1
T ∈ (pl (t1 ), pl (x)). However, expressing ITs in terms of ε                             pl (xt+1 ) = −1
                                                                                                                       0.1
liberates us from having to express them in terms of inter-                               +∞                             -1-0   -2-0   -3-0   -4-0   -5-0   -6-0   -7-0   -8-0   -9-0 -10-0
                                                                                                                                                        T
vals, thereby simplifying the exposition. We would like to
emphasize that the adopted notation should not be construed
                                                                            Figure 3: Left: The infinite-sized HMM discussed in (Icard
as implying that the assignment of values to ITs is such a sen-
                                                                            & Goodman, 2015) with parameterization: P(xt+1 |xt ) =
sitive task that everything would have collapsed, had IT not
                                                                            P(x̄t+1 |x̄t ) = 0.9, and P(yt |xt ) = P(ȳt |x̄t ) = 0.8. Right: Ap-
been chosen in such a fine-tuned manner. To recap, in simple
                                                                            plying PLIF on the HMM shown in left. Vertical and hori-
terms, T bears on how far into the past a reasoner is con-
                                                                            zontal axes denote, respectively, the value of the posed query
sulting her mental model in the process of answering a query,
                                                                            P(xt+1 |y−∞:t ) and the adopted IT T . The vertical bars de-
and RT characterizes the furthest-into-the-past concepts en-
                                                                            pict the intervals within which the query lies due to Lemma
tertained by the reasoner in that process.
                                                                            1. The dotted curves—which connect the lower and upper
   Next, we formally present the main idea behind PLIF, fol-                bounds of the intervals—show how the intervals shrink as IT
lowed by its interpretation in simple terms.                                T decreases.
   Lemma 1. Let P(O|E) denote the posed causal query,
with O and E denoting, respectively, the disjoint sets of                   same parameterization and query adopted therein. All RVs in
target and observed variables. For any chosen IT T <                        this section are binary, taking on values from the set {0, 1};
p∗l and its corresponding RT , define S :, RT \ E. Then                     x = x indicates the event wherein x takes the value 1, and
the following holds: minS∈Val(S) P(O|S, E) ≤ P(O|E) ≤                       x = x̄ implies the event wherein x takes the value 0. We
maxS∈Val(S) P(O|S, E). Crucially, the provided bounds can be                assume pl (xt+i ) = i − 2.11 We should note that the assign-
computed using the information encoded in the submodel re-                  ment of the PLs for the variables in {yt−i }+∞  i=0 does not af-
trieved in the very process of obtaining the RT .                          fect the presented results in any way. The query of interest is
   The message of Lemma 1 is quite simple: For any chosen                   P(xt+1 |y−∞:t ). Notice that after performing three steps of the
inference threshold T which is further into the past than o∗ ,              sort discussed in the example presented in Sec. 3 (for the IT
Lemma 1 ensures that the reasoner can condition on S and                    T = −3 − ε), the lower bound on the posed query exceeds 0.5
obtain the reported lower and upper bounds on the query by                  (shown by the red dashed line in Fig. 3(right)). This obser-
using only the information encoded in the retrieved submodel.               vation has the following intriguing implication. Assume, for
   It is natural to ask under what conditions the exact value               the sake of argument, that we were presented with the follow-
to the posed query can be derived using the thus-far retrieved              ing Maximum A-Posterior (MAP) inference problem: Upon
submodel, i.e., the submodel obtained during the identifica-                observing all the variables in {yt−i }+∞
                                                                                                                   i=0 taking on the value 1,
tion of RT . The following remark bears on that.10                          what would be the most likely state for the variable xt+1 ? In-
   Remark 1. If for IT T , RT satisfies either: (i) RT ⊆ E,                 terestingly, we would be able to answer this MAP inference
or (ii) for all r ∈ RT , pl (r) = T0 , and mine∈E pl (e) > T , or           problem simply after three backward moves (corresponding
                                                                            to the IT T = −3 − ε). In Fig. 3(right), the intervals within
    9 For a discussion on the special case (b), the reader is referred
to: https://arxiv.org/pdf/1701.08100                                           11 Note that the trend of the upper- and lower-bound curves as well
   10 For a formal proof of Lemma 1, and the rationale behind Re-           as the size of the intervals shown in Fig. 3(right) are insensitive with
mark 1, the reader is referred to: https://arxiv.org/pdf/1701.08100         regard to the choice of PLs for variables {xt−i }+∞
                                                                                                                              i=−1 .
                                                                         3049

which the posed query falls (due to Lemma 1) in terms of the                 up approaches, on the other hand, incrementally construct a
adopted IT T are depicted.                                                   submodel (by moving backwards from the query variables),
   Our analysis confirms Icard and Goodman’s (2015) insight                  using which the posed query can be computed. It is crucial
that even in the extreme case of having infinite-sized relevant              to note that bottom-up approaches cannot stop at interme-
submodel (Fig. 3(left)), the portion of which the reasoner has               diate steps during the backward move and run inference on
to consult so as to obtain a “sufficiently good” answer to the               the thus-far constructed submodel without running the risk
posed query could happen to be very small (Fig. 3(right)).                   of compromising some of the (in)dependence relations struc-
                                                                             turally encoded in the CBN, which would yield erroneous in-
                          5    Discussion                                    ferences. This observation is due to the fact that there ex-
                                                                             ists no local signal revealing how the thus-far retrieved nodes
To our knowledge, PLIF is the first inference framework pro-
                                                                             are positioned relative to each other and to the to-be-retrieved
posed that capitalizes on time to constrain the scope of causal
                                                                             nodes—a shortcoming circumvented in the case of PLIF by
reasoning over CBNs, where the term scope refers to the por-
                                                                             introducing PL. It is worth reiterating again that PLIF sub-
tion of a CBN on which inference is carried out. PLIF does
                                                                             scribes to what we call the concurrent approach to reasoning
not restrict itself to any particular inference scheme. The
                                                                             (as opposed to the flawed sequential approach mentioned ear-
claim of PLIF is that inference should be confined within and
                                                                             lier), whereby retrieval and inference take place in tandem.
carried out over retrieved submodels of the kind suggested
                                                                             The HMM example analyzed in Sec. 4.1, with infinitely large
by Lemma 1 so as to obtain the reported bounds therein. In
                                                                             relevant submodel, stresses the importance and shows the ef-
this light, PLIF can accommodate any inference scheme, in-
                                                                             ficacy of the concurrent approach.
cluding Belief Propagation (BP), and sample-based inference
methods using Markov Chain Monte Carlo (MCMC), as two                           Work on causal judgment provides support for the so-
prominent classes of inference schemes. MCMC-based meth-                     called alternative neglect, according to which subjects tend
ods have been successful in simulating important aspects of a                to neglect alternative causes to a much greater extent in pre-
wide range of cognitive phenomena and accounting for many                    dictive reasoning than in diagnostic reasoning (Fernbach &
cognitive biases; cf. (Sanborn & Chater, 2016). Also, work in                Rehder, 2013; Fernbach, Darlow, & Sloman, 2011). Alter-
theoretical neuroscience has suggested mechanisms for how                    native neglect, therefore, implies that subjects would tend
BP and MCMC-based methods could be realized in neural                        to ignore parts of the relevant submodel while constructing
circuits; cf. (Gershman & Beck, 2016; Lochmann & Deneve,                     it. Recent findings, however, seem to cast doubt on alterna-
2011). For example, to cast BP into PLIF amounts to re-                      tive neglect (Cummins, 2014; Meder, Mayrhofer, & Wald-
stricting BP’s message-passing within submodels of the kind                  mann, 2014). Meder et al. (2014), Experiment 1 demon-
suggested by Lemma 1. In other words, assuming that BP                       strates that subjects appropriately take into account alterna-
is to be adopted as the inference scheme, upon being pre-                    tive causes in predictive reasoning. Also, Cummins (2014)
sented with a causal query, an IT according to Lemma 1 will                  substantiates a two-part explanation of alternative neglect ac-
be selected—at the meta-level—by the reasoner and the cor-                   cording to which: (i) subjects interpret predictive queries as
responding submodel, as suggested by Lemma 1, will be re-                    requests to estimate the probability of the effect when only
trieved, over which inference will be carried out using BP.                  the focal cause is present, an interpretation which renders al-
This will lead to obtaining lower and upper bounds on the                    ternative causes irrelevant, and (ii) the influence of inhabitory
query, as reported in Lemma 1. If time permits, the reasoner                 causes (i.e., disablers) on predictive judgment is underesti-
builds up incrementally on the thus-far retrieved submodel so                mated, and this underestimation is incorrectly interpreted as
as to obtain tighter bounds on the query.12 MCMC-based in-                   neglecting of alternative causes. Cummins (2014), Experi-
ference methods can be cast into PLIF in a similar fashion.                  ment 2 shows that when predictive inference is queried in a
   The problem of what parts of a CBN are relevant and what                  manner that more accurately expresses the meaning of noisy-
are irrelevant for a given query, according to (Geiger, Verma,               OR Bayes net (i.e., the normative model adopted by Fernbach
& Pearl, 1989), was first addressed by Shachter (1988). The                  et al. (2011)) likelihood estimates approached normative esti-
approaches proposed for identifying the relevant submodel                    mates. Cummins (2014), Experiment 4 shows that the impact
for a given query fall into two broad categories (cf. Ma-                    of disablers on predictive judgments is far greater than that
honey & Laskey, 1998, and references therein): (i) top-down                  of alternative causes, while having little impact on diagnostic
approaches, and (ii) bottom-up approaches. Top-down ap-                      judgments. PLIF commits to the retrieval of enablers as well
proaches start with the full knowledge of the underlying CBN                 as disablers. As mentioned earlier, PLIF abstracts away from
and, depending on the posed query, gradually prune the irrel-                the inference scheme operating on the retrieved submodel,
evant parts of the CBN. In this respect, top-down approaches                 and, hence, leaves it to the inference scheme to decide how
are inevitably from “god’s eye” point of view—a character-                   the retrieved enablers and disablers should be weighted and
istic which undermines their cognitive-plausibility. Bottom-                 subsequently integrated. In this light, PLIF is consistent with
                                                                             the results of Experiment 4 in (Cummins, 2014).
   12 The very property that the submodel gets constructed incremen-
tally in a nested fashion guarantees that the obtained lower and upper          In an attempt to explain violations of screening-off re-
bounds get tighter as the reasoner adopts smaller ITs; see Fig. 3(left).     ported in the literature, Park and Sloman (2013) find strong
                                                                         3050

support for the contradiction hypothesis followed by the me-        2010; Buehner & May, 2004).
diating mechanism hypothesis, and finally conclude that peo-            There is a growing acknowledgment in the literature that,
ple do conform to screening-off once the causal structure they      not only time and causality are intimately linked, but that
are using is correctly specified. PLIF is consistent with these     they mutually constrain each other in human cognition; cf.
accounts, as it adheres to the assumption that reasoners carry      (Buehner, 2014). In line with this view, we see our work also
out inference on their internal causal model (including all         as an attempt to formally articulate how time could guide and
possible mediating variables and disablers), not the poten-         constrain causal reasoning. While many questions remain
tially incomplete one presented in the cover story; see also        open, we hope to have made some progress towards better
(Rehder & Waldmann, 2017; Sloman & Lagnado, 2015).                  understanding of the CFP at the algorithmic level.
   Experiment 5 in (Cummins, 2014), consistent with                 Acknowledgments. We are grateful to Thomas Icard for valu-
(Fernbach & Rehder, 2013), shows that causal judgments are          able discussions. We would also like to thank Marcel Montrey and
strongly influenced by memory retrieval/activation processes,       Peter Helfer for helpful comments on an earlier draft of this work.
                                                                    This work was supported in part by the Natural Sciences and Engi-
and that both number of disablers and order of disabler re-         neering Research Council of Canada under grant RGPIN 262017.
trieval matter in causal judgments. These findings suggest
that the CFP and memory retrieval/activation are intimately                                           References
linked. In that light, next, we intend to elaborate on the ra-      Baddeley, A. (2003). Working memory: looking back and looking forward. Nature
                                                                       Review Neuroscience, 4(10), 829–839.
tionale behind adopting the term “retrieve” and using it in-        Baddeley, A. D., & Hitch, G. (1974). Working memory. Psychology of Learning and
                                                                       Motivation, 8, 47–89.
terchangeably with the term “consult” throughout the paper;         Bramley, N. R., Gerstenberg, T., & Lagnado, D. A. (2014). The order of things: In-
                                                                       ferring causal structure from temporal patterns. In Proceedings of the 36th annual
this is where we relate PLIF to the concepts of Long Term              conference of the cognitive science society (pp. 236–241).
Memory (LTM) and Working Memory (WM) in psychology                  Buehner, M. J. (2014). Time and causality: editorial. Frontiers in Psychology, 5, 228.
                                                                    Buehner, M. J., & May, J. (2004). Abolishing the effect of reinforcement delay on
and neurophysiology. Next, we elaborate on how PLIF could              human causal learning. Quarterly Journal of Experimental Psychology Section B,
                                                                       57(2), 179–191.
be interpreted through the lenses of two influential models of      Cummins, D. D. (2014). The impact of disablers on predictive inference. Journal of
WM, namely, Baddeley and Hitch’s (1974) Multi-component                Experimental Psychology: Learning, Memory, and Cognition, 40(6), 1638.
                                                                    De Neys, W., Schaeken, W., & d’Ydewalle, G. (2003). Inference suppression and
model of WM (M-WM) and Ericsson and Kintsch’s (1995)                   semantic memory retrieval: Every counterexample counts. Memory & Cognition,
                                                                       31(4), 581–595.
Long-term Working Memory (LTWM) model. The M-WM                     Ericsson, K. A., & Kintsch, W. (1995). Long-term working memory. Psychological
                                                                       Review, 102(2), 211.
postulates that “long-term information is downloaded into           Fernbach, P. M., Darlow, A., & Sloman, S. A. (2011). Asymmetries in predictive
a separate temporary store, rather than simply activated in            and diagnostic reasoning. Journal of Experimental Psychology: General, 140(2),
                                                                       168–185.
LTM,” a mechanism which permits WM to “manipulate and               Fernbach, P. M., & Rehder, B. (2013). Cognitive shortcuts in causal inference. Argu-
                                                                       ment & Computation, 4(1), 64–88.
create new representations, rather than simply activating old       Fodor, J. A. (1987). Modules, frames, fridgeons, sleeping dogs, and the music of the
memories” (Baddeley, 2003). Interpreting PLIF through the              spheres.
                                                                    Geiger, D., Verma, T., & Pearl, J. (1989). d-separation: from theorems to algorithms.
lens of the M-WM model amounts to the value for IT be-                 Fifth Workshop on Uncertainty in Artificial Intelligence, pp. 118–125.
                                                                    Gershman, S. J., & Beck, J. M. (2016). Complex probabilistic inference: From cogni-
ing chosen (and, if time permits, updated so as to obtain              tion to neural computation. In Computational Models of Brain and Behavior, ed A.
                                                                       Moustafa.
tighter bounds) by the central executive in the M-WM and the        Glymour, C. (1987). Android epistemology and the frame problem, The Robot’s
submodel being incrementally “retrieved” from LTM into M-              Dilemma: The Frame Problem in AI. pp. 65–75.
                                                                    Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E., Kushnir, T., & Danks, D. (2004).
WM’s episodic buffer. Interpreting PLIF through the lens of            A theory of causal learning in children: causal maps and bayes nets. Psychological
                                                                       Review, 111(1), 3-32.
the LTWM model amounts to having no retrieval from LTM              Greville, W. J., & Buehner, M. J. (2010). Temporal predictability facilitates causal
into WM and the submodel suggested by Lemma 1 being                    learning. Journal of Experimental Psychology: General, 139(4), 756.
                                                                    Hume, D. (1748/1975). An inquiry concerning human understanding. Oxford Univer-
merely “activated in LTM” and, in that sense, being simply             sity Press.
                                                                    Icard, T. F., & Goodman, N. D. (2015). A resource-rational approach to the causal
“consulted” in LTM. In sum, PLIF is compatible with both of            frame problem. Proc. of the 37th Annual Meeting of the Cognitive Science Society.
                                                                    Lagnado, D. A., & Sloman, S. A. (2006). Time as a guide to cause. Journal of Experi-
the narratives provided by the M-WM and LTWM models.                   mental Psychology: Learning, Memory, and Cognition, 32(3), 451–60.
                                                                    Lochmann, T., & Deneve, S. (2011). Neural processing as causal inference. Current
   A number of predictions follow from PL and PLIF. For in-            Opinion in Neurobiology, 21(5), 774–781.
                                                                    Mahoney, S. M., & Laskey, K. B. (1998). Constructing situation specific belief net-
stance, PLIF makes the following prediction: Prompted with             works. Proc. of the Conference on Uncertainty in Artificial Intelligence, pp. 370–
a predictive or a diagnostic query (i.e., P(e|c) and P(c|e),           378.
                                                                    Marr, D. (1982). Vision: a computational approach.
respectively), subjects should not retrieve any of the effects      Meder, B., Mayrhofer, R., & Waldmann, M. R. (2014). Structure induction in diagnostic
                                                                       causal reasoning. Psychological Review, 121(3), 277.
of e. Introspectively, this prediction seems plausible, and         Park, J., & Sloman, S. A. (2013). Mechanistic beliefs determine adherence to the
                                                                       markov property in causal reasoning. Cognitive Psychology, 67(4), 186–216.
can be tested, using a similar approach to (Cummins, 2014;          Pearl, J. (1988). Probabilistic reasoning in intelligent systems: networks of plausible
De Neys, Schaeken, & d’Ydewalle, 2003), by asking subjects             inference. Morgan Kaufmann.
                                                                    Rehder, B., & Waldmann, M. R. (2017). Failures of explaining away and screening off
to “think aloud” while engaged in predictive or diagnostic             in described versus experienced causal learning scenarios. Memory & Cognition, 45,
                                                                       245-260.
reasoning. Also, PL yields the following prediction: Upon           Sanborn, A. N., & Chater, N. (2016). Bayesian brains without probabilities. Trends in
intervening on cause c, subjects should be sensitive to when           Cognitive Sciences, 20(12), 883–893.
                                                                    Schlottmann, A. (1999). Seeing it happen and knowing how it works: how children un-
effect e will occur, even in settings where they are not partic-       derstand the relation between perceptual causality and underlying mechanism. Dev
                                                                       Psychol, 35(1), 303.
ularly instructed to attend to such temporal patterns. Recent       Shachter, R. D. (1988). Probabilistic inference and influence diagrams. Operations
                                                                       Research, 36(4), 589–604.
findings suggesting that people have expectations about the         Simon, H. A. (1957). Models of man. Wiley.
delay length between cause and effect already provide some          Sloman, S. A., & Lagnado, D. (2015). Causality in thought. Annual Review of Psychol-
                                                                       ogy, 66, 223–247.
supporting evidence for this prediction (Greville & Buehner,
                                                                3051

