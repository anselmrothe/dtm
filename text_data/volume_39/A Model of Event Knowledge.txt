                                                 A Model of Event Knowledge
                                                  Jeffrey L. Elman (jelman@ucsd.edu)
                                    Department of Cognitive Science, 9500 Gilman Drive
                                                         La Jolla, CA 92093 USA
                                                       Ken McRae (kenm@uwo.ca)
                                          Department of Psychology, Social Science Centre
                                                       London, ON N6A 5C2 Canada
                               Abstract                                  comprehension. One assumption that appears to be shared
   We present a connectionist model of event knowledge that is           (though was often implicit) was that the use of
   trained on examples of sequences of activities that are not           world/pragmatic/event        knowledge        in     language
   explicitly labeled as events. The model learns co-occurrence          comprehension occurred at late stages in processing. In
   patterns among the components of activities as they occur in          large part this reflected theoretical assumptions of the time
   the moment (entities, actions, and contexts), and also learns to      in linguistics and psycholinguistics, but it is also true that
   predict sequential patterns of activities. In so doing, the model     the typical experimental tasks used at the time were off-line,
   displays behaviors that in humans have been characterized as          and did not lend themselves to tracking real-time
   exemplifying inferencing of unmentioned event components,             incremental processing.
   the prediction of upcoming components (which may or may
                                                                            Over the years, there have been a number of attempts to
   not ever happen or be mentioned), reconstructive memory,
   and the ability to flexibly accommodate novel variations from         formalize this kind of knowledge, giving rise to mechanistic
   previously encountered experiences. All of these behaviors            explanations involving frames (Minsky, 1974), scripts
   emerge from what the model learns.                                    (Schank & Abelson, 1977), schema (Norman & Rumelhart,
                                                                         1981), and stories (Mandler, 1984), among others. Although
   Keywords: events; schema; scripts; prediction; recurrent              the core intuitions motivating these proposals were widely
   connectionist model                                                   accepted, the actual implementations revealed a number of
                                                                         challenges. Templates were inherently rigid and inflexible.
                           Introduction                                  Yet most situations admit a large range of variation and
We know many things about the world. How that                            novelty. Moreover, many situations involve blends of
knowledge is organized, its content, and how it is stored,               multiple events. Symbolic architectures did not lend
accessed, and learned have been the subject of semantic                  themselves to dealing with such challenges. Thorny
memory research for some time. A long and rich tradition of              questions were raised and not satisfactorily answered: What
scholarship has produced a relatively stable set of                      is an event (and what is not)? What is the content and detail
theoretical constructs that are used for discussing this kind            of event knowledge? Does event knowledge have a structure
of knowledge, including categories, concepts, and features.              common across all event types? How is event knowledge
   But people also possess another type of knowledge that                accessed and used? How is event knowledge learned? These
has been long recognized as extremely important, although                questions remain open to this day.
it is less clearly understood. This is knowledge about                      Several recent developments have encouraged cognitive
common situations and events, and has been referred to by a              scientists to focus more intensely on event knowledge and
range of names, including pragmatic knowledge and world                  how best to model it. Our own interest arises from work in
knowledge. Such knowledge appears to serve multiple                      language processing using real-time measures to examine
purposes. It guides our behavior, and helps us interpret the             processing as comprehenders deal with incrementally
behavior of others. We use this knowledge to anticipate the              presented input. There is now considerable evidence that
consequences of events as they unfold. We use this                       event knowledge plays a significant role in comprehension
knowledge extensively in language understanding to make                  very early in processing. Indeed, it guides expectations even
inferences about components of situations that may be                    in advance of input being received. The time course of how
unstated or incompletely described.                                      this knowledge is accessed and deployed is now not only of
   Bartlett (1932) was one of the first psychologists to talk            great theoretical interest (insofar as it may constrain our
about the role of such knowledge in memory. Later, in the                theories about the cognitive architecture underlying
1970s and 1980s, cognitive psychologists such as Bransford               language understanding), but has become something that
and colleagues demonstrated that event knowledge is                      can be measured empirically.
important in encoding and retrieving details about                          A second development was the emergence of non-
situations. Garrod and Sanford, among many others, showed                symbolic computational frameworks that demonstrate the
that this kind of knowledge supports inferences in language              ability to capture behaviors that simultaneously reflect
                                                                                                                                     1
                                                                     337

awareness of global abstractions as well as sensitivity to          Fill in missing information. Both during learning and
ways in which those abstractions may be graded and                  testing, the model may be exposed to activity descriptions in
affected by subregularities and even idiosyncracies.                which some highly expected information is omitted. The
Connectionist models have these qualities (although                 model should be able to activate missing elements, as
Bayesian models often do as well). Our research uses a              appropriate (pattern completion). In human terms, the model
connectionist model because they exhibit key additional             should be able to make elaborative inferences.
capabilities. They learn by example, and they allow us to
probe in (simulated) real time the dynamics of the network’s        Architecture
responses to incrementally presented input.                         The architecture of the model is shown in Figure 1.
   In the remainder of this paper, we present a model and
report a set of simulations we have conducted. We begin by
explaining the design criteria that guided model
development. These criteria were chosen because we
believe they are needed to model processes that reflect the
use of event knowledge in human behavior. We conclude by
discussing what we have learned from the model, and ways
in which it might guide future research.
                         The Model
                                                                    Figure 1
Design Criteria
The model’s architecture was developed with the goal that it
                                                                    There is a single network, but the left and right portions play
should have the following four properties.
                                                                    complementary roles. The left portion receives input from
                                                                    the world in the form of (localist) specifications of potential
Learn the components that comprise an activity. We                  participants, actions, and contexts that might characterize
make the assumption that events can be viewed as                    the current activity under description. Each rectangle thus
sequences of activities, where activities occur in the              represents a number of possible inputs of the same category
moment and are comprised of various participants,                   (agents, patients, etc.). It should be emphasized, however,
actions, and contexts. Rather than prespecifying a                  that there is no representational status to these groups. As
template for necessary or sufficient components, the                far as the network is concerned, every input node in all of
model must learn which components occur and co-occur                these groups is orthogonal to every other node. If there are
across contexts and sequences. These co-occurrences                 similarities in terms of behavior or statistics of privilege of
may be statistically variable, and the model must learn             occurrence, the network must discover them. Input nodes
these (often high-order) statistical interdependences.              are fully connected to nodes in the Hidden Unit layer, and
                                                                    hidden units also connect (with different weights) back to
Learn the temporal structure of activity sequences. We              input units. This use of recurrence allows the network not
also assume that the temporal structure of activity sequences       only to learn co-occurrence patterns among input units, but
that make up an event may be variable across instances of           also to implement constraint satisfaction. This means that
any given event type. The model must learn this temporal            after the network has learned, it has the potential to activate
structure, including cases in which that structure is rigid and     missing elements in an input pattern, as appropriate. The
obligatory as well as cases in which there is a high degree of      Next Activity side of the network consists of units that are
variability or optionality. The model should be able to use         identical to the Current Activity units, but the job of the
its knowledge of temporal structure to anticipate likely            Next Activity units is to predict which activity will follow,
future activities given previously encountered sequences.           given the sequence so far. Recurrent connections from the
These expectations should reflect both global contingencies         hidden units back to themselves are critical for this function
as well as predictions that may reflect more idiosyncractic         because they provide the network with an internal
variants of an activity sequence. In human terms, the model         representation (which must be learned) of the past that can
should be able to make predictive inferences.                       be used for prediction. This architecture builds on elements
                                                                    of prior modeling that has provided a strong foundation for
Learn to generalize from specific examples of events.               the present approach, including in particular Botvinick and
Although the model will learn from multiple examples of a           Plaut (2004), Elman (1990), Rogers and McClelland (2004),
given event type, it must learn the (often graded) patterns         Rumelhart, Smolensky, McClelland, and Hinton (1986), St.
that underly them. It must also learn subregularities and if        John and McClelland (1990), and Reynolds, Zacks, and
possible, exceptions.                                               Braver (2007).
                                                                                                                                  2
                                                                338

Training and Testing                                              in response to the input sequence John is in a restaurant;
Simulations were conducted using the rbp package from the         John cuts himself; What happened to John? (the query takes
PDPtool simulator (McClelland, 2016). Weights in the              the form of simply presenting John without any specified
network were initialized with random values between ±0.1          result, so the network must fill in the information). Figure 3
and adjusted gradually using backpropagation through time         shows similar activations, but in response to the sequence
(Williams & Zipser, 2004). Training stimuli were either           John is in the forest; John cuts himself; What happened to
artificially generated activity sequences (Studies 1-3)           John?
presented one activity at a time, or sequences obtained from
human norming data (Study 4). After training, testing was
conducted by freezing weights and presenting the network
with input sequences designed as analogs of stimuli used in
human experimental paradigms. Details of the general
training       regime        can       be       found      in
http://tatar.ucsd.edu/jeffelman/EventModelTraining.html,
and details relevant to each simulation are given below.
                                                                  Figure 2
                   Simulation Results
Study 1: Pattern completion and elaborative and
predictive inferences
Typical language use relies heavily on interlocutors’ shared
knowledge. This allows speakers to omit information that is
assumed to be known by the comprehender, and allows
comprehenders to infer unstated information. A frequent
distinction is made between elaborative inferences, which
involve unstated details regarding an activity currently          Figure 3
described, and predictive (or forward) inferences, which
involve expectations about what will occur next. Bridging         After receiving the input that John is in a restaurant, a knife
inferences are those in which a comprehender draws on             is inferred to be present, whereas in the forest, axe is
knowledge only as needed to understand a prior statement.         activated. These may be considered elaborative inferences.
The extent to which, and conditions under which, such             Then when John cuts himself, with no instrument
inferences are drawn remains a topic of debate. Bridging          mentioned, the network immediately begins to predict the
inferences are largely uncontroversial. However, whether,         result that is consistent with the instrument. These are
and under which conditions, elaborative and predictive            predictive inferences. Such inferences have not always been
inferences occur is still debated (for review, see Murray,        found in humans, however. One possibility raised by
Klin, & Myers, 1993). In Study 1, we first verify that the        Murray et al. (1993) is that failures to detect predictive
constraint satisfaction properties of the network do support      inferences may result from experimental stimuli in which
inference under optimal conditions. We then examine the           either the forward inference is disrupted, or it is not tested
fragility or robustness of such inferencing because it has        soon enough. In Figure 4, we see what happens when the
been claimed that discrepant data have arisen from stimulus       discourse is disrupted by switching to a new topic, which is
properties and the sensitivity of behavioral measures.
Simulation 1.1. The network was trained on event
sequences that ranged in length from three to six activities.
The sequences might be glossed as (1) John goes to a fancy
restaurant; (2) John is cutting wood in the forest, using an
axe; (3) John (and other people) cut themselves accidentally
with a knife, and he bleeds; (4) John (and other people) cut
themselves accidentally with an axe and the wound is fatal;
(5) Mary and Penny are in the library and Mary asks Penny          Figure 4
a question, which Penny answers. Having learned these
sequences, the model was then tested on novel sequences.          a situation involving Mary, immediately after the cutting
The sequences were novel both in that they omitted critical       activity. The network begins to predict that John will bleed
information, and they involved new combinations of                (because he is assumed to have cut himself with a knife,
activities that the model had not encountered in the same         given the restaurant context). However, as soon as Mary is
event. Figure 2 shows activations in the Next Activity units      introduced, the activations of all consequences of cut
                                                                                                                               3
                                                              339

decrease sharply. Probing for the consequence of John              Study 2: Novel Events and Blending
cutting himself subsequent to this topic change would show         In real life, events exhibit not only variability (which the
little or no evidence of the predictive inference, consistent      model accommodates, as we see in Figures 1 and 2) but
with Murray et al.’s findings.                                     often are combined in novel ways. Fixed templates or rigid
Simulation 1.2. One open question concerns precisely how           structures are ill suited for dealing with this. In the next
far into the future comprehenders predict when processing          simulation, we test the model’s ability to flexibly respond
incrementally presented language. In much of the empirical         when events are combined in unusual ways.
literature focusing on prediction in language, there has been
an implicit assumption that the next word in a sequence is         Simulation 2.1. The model was trained on sequences that
anticipated by comprehenders, but nothing beyond that.             included examples of going to a restaurant (as in Simulation
However, more recent findings suggest that when language           1.1), and activities corresponding to a romantic relationship
is used to describe an event, comprehenders anticipate             between two people (John and Mary), with Mary being
event-relevant elements even at points in the discourse            married to a third person (Bill). Furthermore, the model was
where they might not be appropriate (Metusalem, Kutas,             exposed to examples of aggressive behavior between
Urbach, Hare, McRae, & Elman, 2012). A simplified                  various people (but not including John or Bill). In many of
stimulus example is the short story: The crowd is in the           the latter examples, weapons are used. Gun is a more typical
stands. The crowd looks around. The skater goes to the             weapon, but knives are used occasionally. After training, the
podium. The audience applauds, The skater receives a ___.          model was tested on a sequence that might be glossed as
Participants’ brain activity was measured while reading the        John and Mary are at a fancy restaurant. John and Mary
final noun. When an event-appropriate word, such as medal,         cut steak with a knife. Bill enters the restaurant. Bill attacks
was presented, the N400 amplitude was small. A word that           John. Activations of relevant nodes are shown in Figure 6.
was completely anomalous (e.g., bleach) elicited a large
N400. However, a word that was contextually anomalous
but event-appropriate (e.g., podium) produced an N400 with
intermediate amplitude. The authors interpreted this as
evidence that event elements are activated and available
even at times when they might not be expected immediately.
Figure 5 shows the network’s activations in the Next
Activity units throughout such a stimulus sequence.
                                                                   Figure 6
                                                                   Two things are apparent. First, as soon as Bill enters the
                                                                   restaurant, the model quickly adjusts its expectations about
                                                                   what it predicts will happen next. Second, and more
                                                                   interesting, is that although the model has learned that gun
                                                                   is the most common weapon used in aggressive behavior,
                                                                   the presence of knife that was established from the outset
                                                                   (even prior to its mention) leads to the knife being the
Figure 5                                                           predicted instrument in this new situation. Thus, the model
By the second activity, the network has already activated          not only adjusts to a change in sequence structure that it has
two event-appropriate elements, podium and medal. Bleach           not encountered before, but it also flexibly incorporates
is not activated at all. As the focus shifts in the fourth         relevant components from the first event into the second
activity back to the crowd, both medal and podium are              event. That is, the model produces a novel response to a
deactivated. However, near the end, the network re-activates       situation it has never encountered by drawing and
both. The re-activation of medal is not surprising because it      integrating knowledge from different events.
has been mentioned explicitly. However, the network has
also learned that podium is the likely location for awarding a     Study 3: Priming
medal and so activates it as well, though at a lower level.        Studies 1 and 2 illustrate examples of priming. There is a
There are two lessons from this simulation. First, behavioral      large literature showing that event relevant information
evidence for the activation of putatively inferred event           facilitates processing target elements related to that event.
elements may depend on the timing of the probe. Second, it         These include typical agents, patients, and instruments
may be that only highly sensitive behavioral measures will         priming their event-relevant verbs, priming between event-
reveal the presence of partially activated event elements.         relevant nouns, and verbs priming their event-related agents,
These elements, even if only partially activated, become           patients, and instruments (for review, see McRae &
more easily accessible should subsequent discourse make            Matsuki, 2009). The model exhibits the same behavior, not
reference to them. This in fact was seen in Simulation 1.1.        shown here because of space limitations. Instead, we
                                                                                                                                 4
                                                               340

demonstrate an example of priming involving second order            conducted a norming study to sample people’s knowledge
dependencies between event elements. Bicknell et al. (2010)         of types of events.
found that the patient that is expected to follow a given verb
may depend on the agent carrying out the action. Thus,              Norming study 4.1 We used 81 events, drawing on prior
shopper saved… primes money, whereas the lifeguard                  literature that has used stimuli that describe events and
saved… primes person. (Control conditions established that          situations. Some of these events have clear goals and
the priming was not directly between the agent or verb and          outcomes (e.g., fixing a flat tire). Other events are more
the patient, but that it required the combination.)                 situation-like, in that things happen but the goal and
                                                                    outcome are less clear (e.g., going to a picnic). Using
Simulation 3.1. The model was trained on various examples           Mechanical Turk, participants were asked to list up to 12
of shoppers and lifeguards (and other people) in events in          activities for each event. Participants saw a random subset
which saving was one of the activities. Typically, reflecting       of 10-12 of the 81 events, and each event was presented to
the corpus analyses carried out by Bicknell et al., shoppers        22-24 different participants. Table 1 shows responses from
save money whereas lifeguards save people. When probed              three participants for fixing a flat tire.
with the partial description of an activity shopper+saved
                                                                                           Table 1: fixing a flat tire
(Figure 7), the model predicted money as the most likely
patient, compared to lifeguard+saved, which led to greater          Pull over               Get out of car           Pull over
                                                                    Get out of car          Loosen lug nuts          Open trunk
activation of person (Figure 8). However, we also see that          Open trunk              Jack up car              Get tire iron
that there is an asymmetry in the responses, such that at later     Get spare tire          Remove lug nuts          Get spare tire
stages in processing, lifeguard+saved results in an increased       Get jack                Remove flat tire         Put on hazard lights
activation of money (though still lower than person).               Remove flat tire        Put on new tire          Jack up car
                                                                    Put on new tire         Tighten lug nuts         Remove lug nuts
                                                                    Tighten lug nuts        Remove jack              Take flat tire off
                                                                    Put flat tire in trunk                           Put on new tire
                                                                                                                     Tighten lug nuts
                                                                                                                     Lower car
                                                                    The data can be visualized using graph analysis, in which
                                                                    nodes represent activities and directed arrows show
Figure 7                          Figure 8                          temporal sequence (size indicates frequency), as in Figure 9.
This reflects asymmetries in the training data that mirror
asymmetries in corpus analyses, that is, that save is overall
more commonly associated with money than with people.
We might test the model’s predictions (to our knowledge, as
of now untested) by testing whether the timing of the patient
probe leads to different degrees of facilitation, depending on
when the probe was presented.
Study 4: Learning from Human Data
In the previous simulations, we used training sets that were
designed by hand. The design of the training corpora was
                                                                    Figure 9
controlled to carefully probe the network’s behavior under
different learning situations. This strategy is similar to that     Some of the sequences are consistently ordered (e.g., jack
used in many human behavioral experiments. But in real              up car > remove flat tire > put on new tire), undoubtedly
life, people’s knowledge of events results from experiences         reflecting causal constraints. Other sequences may be
that may involve considerably greater variability.                  performed optionally at different times. How does the model
Consolidating such experiences and making sense of                  deal with such data?
commonalities, subregularities, and exceptions is a                 Simulation 4.1. The model was trained on the activity
challenge. Furthermore, temporal structure may vary                 sequences provided by 23 participants for fixing a flat tire.
considerably not only between different event types but             Of particular interest is that although the model responds
even within a single event type. For example, there may be          appropriately to the data it was trained on, its responses also
some parts of an event in which the ordering of activities is       incorporate what it has learned from other participants. The
consistent and even obligatory (eggs must be broken before          model thus does not slavishly reproduce the individual
they are fried), whereas activity sequences in other parts of       training data, but detects general patterns that are common
the event may be optional (one might make coffee before             across all the data.
making eggs, or after). To investigate these issues, we                Can the model generate activity sequences on its own? We
                                                                    tested this by seeding the model with a reasonable starting
                                                                                                                                          5
                                                                341

activity, and then using the most strongly predicted                                        References
elements as the subsequent input. This process iterated until
                                                                   Bartlett, F. C. (1932). A Theory of Remembering.
the event was complete. The initial five activities in the
                                                                     Cambridge, UK: Cambridge University Press.
network’s self-generated sequence are shown in Figure 10
                                                                   Bicknell, K., Elman, J. L., Hare, M., Mcrae, K., & Kutas,
(presenting greater than five makes the figure unreadable).
                                                                     M. (2010). Effects of event knowledge in processing
Notably, the network’s self-generated activity sequence is
                                                                     verbal arguments. Journal of Memory and Language,
not identical to any single participant’s sequence. However,
                                                                     63(4), 489-505.
it is a completely reasonable abstraction of the sequencing
                                                                   Botvinick, M. M., & Plaut, D. C. (2004). Doing without
across all participants’ descriptions.
                                                                     schema hierarchies: A recurrent connectionist approach to
                                                                     normal and impaired routine sequential action.
                                                                     Psychological Review, 111(2), 395-429.
                                                                   Elman, J. L. (1990). Finding structure in time. Cognitive
                                                                     Science, 14(2), 179-211.
                                                                   Mandler, J. M. (1984). Scripts, Stories and Scenes: Aspects
                                                                     of Schema Theory: Hillsdale, NJ: Erlbaum.
                                                                   McRae, K., & Matsuki, K. (2009). People use their
                                                                     knowledge of common events to understand language,
                                                                     and do so as quickly as possible. Language and
Figure 10                                                            Linguistics Compass, 3, 1417-1429.
                                                                   McClelland, J. L. (2017). PDPTool. Palo Alto: Stanford
                          Discussion                                 University. Retrieved from
  Our goal was to develop a model that could learn the               https://web.stanford.edu/group/pdplab/pdphandbook/
structure and temporal dynamics of activity sequences, as          McRae, K., Hare, M., Elman, J. L., & Ferretti, T. R. (2005).
well as the co-occurrence properties of participants,                A basis for generating expectancies for verbs from nouns.
activities, and contexts in those sequences. Although we             Memory and Cognition, 33(7), 1174-1184.
might call these sequences events, the concept of event is         Metusalem, R., Kutas, M., Urbach, T. P., Hare, M., McRae,
not a primitive in the model and events are not pre-defined          K., & Elman, J. L. (2012). Generalized event knowledge
templates. Rather, what we might call an event is an                 activation during online sentence comprehension. Journal
epiphenomenal consequence of having to learn about                   of Memory and Language, 66(4), 545-567.
activity sequence structure. Having done this, the                 Minsky, M. (1974). A Framework for Representing
architecture of the model allows it to perform pattern               Knowledge. Cambridge, MA: MIT Press.
completion, both in the moment (supporting elaborative             Norman, D. A., & Rumelhart, D. E. (1981). The LNR
inferences) and across time (supporting predictive                   approach to human information processing. Cognition,
inferences). The model replicates a wide range of behavioral         10(1), 235-240.
studies (only a few of which are described herein) for which       Reynolds, J. R., Zacks, J. M., & Braver, T. S. (2007). A
event knowledge has been hypothesized to play a role. It             computational model of event segmentation from
also produces unanticipated behaviors that can be tested             perceptual prediction. Cognitive Science, 31, 613-643.
empirically to assess the model.                                   Rogers, T. T., & McClelland, J. L. (2004). Semantic
  A great deal remains to be done. The model’s inputs serve          cognition: A parallel distributed processing approach.
as cues to event knowledge, but the model itself does not            Cambridge, MA: MIT Press.
provide those cues. Those cues must come from perceptual           Rumelhart, D. E., Smolensky, P., McClelland, J. L., &
or motor evidence from the world as well as a language               Hinton, G. E. (1986). Schemata and sequential thought
processor. Nor does the model provide an account for how             processes in PDP models. In J. L. McClelland & D. E.
these various cues can serve to alter focus on different event       Rumelhart (Eds.), Parallel Distributed Processing:
elements, including adjusting how the temporal contour of            Explorations in the Microstructure of Cognition (Vol. 2,
the event is understood (e.g., by grammatical aspect). We            pp. 7-57). Cambridge, MA: MIT Press.
are guardedly optimistic that these are tractable problems,        Schank, R. C., & Abelson, R. P. (1977). Scripts, plans,
and that the model we propose here provides a solid                  goals, and understanding: An inquiry into human
framework for understanding how people acquire, represent,           knowledge structures. Hillsdale, NJ: Lawrence Erlbaum
and use knowledge of events in the world.                            Associates.
                                                                   St. John, M., & McClelland, J. L. (1990). Learning and
                    Acknowledgments                                  applying contextual constraints in sentence
                                                                     comprehension. Artificial Intelligence, 46, 217-257.
This work was supported by grants from the NIH
                                                                   Williams, R. J., & Zipser, D. (1989). A learning algorithm
(CHD053136) and Natural Sciences and Engineering
                                                                     for continually running fully recurrent neural networks.
Research Council of Canada (OGP0155704).
                                                                     Neural Computation, 1, 270-280.
                                                                                                                              6
                                                               342

