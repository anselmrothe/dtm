                             Convention-formation in iterated reference games
                                Robert X.D. Hawkins, Michael C. Frank, Noah D. Goodman
                                             {rxdh, mcfrank, ngoodman}@stanford.edu
                                             Department of Psychology, Stanford University
                              Abstract                                 end. Later studies (e.g. Clark & Wilkes-Gibbs, 1986) refined
   What cognitive mechanisms support the emergence of linguis-         this paradigm, using larger arrays of tangram-like figures
   tic conventions from repeated interaction? We present re-           and emphasizing the intricate back-and-forth process through
   sults from a large-scale, multi-player replication of the clas-     which speakers and listeners negotiate over references. The
   sic tangrams task, focusing on three foundational properties
   of conventions: arbitrariness, stability, and reduction of ut-      referring expressions generated by participants in these stud-
   terance length over time. These results motivate a theory of        ies revealed a number of rich qualitative phenomena. Here,
   convention-formation where agents, though initially uncertain       we focus on three that are both prescribed top-down by theo-
   about word meanings in context, assume others are using lan-
   guage with such knowledge. Thus, agents may learn about             ries of convention-formation and also arise bottom-up as ma-
   meanings by reasoning about a knowledgeable, informative            jor axes of variation in our data: arbitrariness, stability, and
   partner; if all agents engage in such a process, they success-      the systematic reduction of utterance length over time.
   fully coordinate their beliefs, giving rise to a conventional
   communication system. We formalize this theory in a compu-             Arbitrariness is a definitional property of conventions
   tational model of language understanding as social inference        (Lewis, 1969): there must be multiple solutions that would be
   and demonstrate that it produces all three properties in a sim-
   plified domain.                                                     equally successful as long as both players “agree” (e.g. driv-
   Keywords: conventions; pragmatics; communication                    ing on the left vs. right side of the road). By the final round
                                                                       in a language game, for example, one pair might successfully
                          Introduction                                 use the expression ‘dancer’ to refer to a tangram, while an-
Just as drivers depend on shared behavioral conventions to             other might use ‘skater’. The other definitional property we
safely navigate traffic, successful communication depends on           consider is stability: it is in everyone’s best interest to keep
a set of shared linguistic conventions. Speakers of different          using a convention once established. Finally, reduction is
languages around the world refer to the same object in many            more specific to the reference game paradigm and refers to
different ways, yet when ordering a coffee in San Francisco,           the transformation of longer, complex expressions into sim-
one can confidently use the English word “coffee” and be un-           pler expressions over the course of interaction, as Krauss &
derstood. How do these conventions – classically character-            Weinheimer (1964) observed. While this broad phenomenon
ized by Lewis (1969) as arbitrary but stable solutions to re-          has been replicated many times, exactly what is reduced re-
curring coordination problems – form in the first place?               mains an open empirical question.
   While global conventions adopted and sustained through-                Theories of convention-formation differ primarily in the
out a large population of speakers may develop over longer             extent to which sophisticated social reasoning and common
time scales, we also effortlessly coordinate on local con-             ground is required. At one extreme, agents use simple heuris-
ventions – or conceptual pacts (Brennan & Clark, 1996) –               tic updating rules and do not need to represent or reason about
within the span of a single dialogue. For example, when                other agents at all (Barr, 2004; Centola & Baronchelli, 2015;
discussing possible conditions to use in an upcoming experi-           Young, 2015). Simulations elegantly show how arbitrary sig-
ment, a team of collaborators might begin the meeting using            naling systems can spread and come to stably dominate large
long descriptions to refer to each condition but end the meet-         populations. However, due to their ‘rich get richer’ dynamic,
ing using conventional terms like “condition A” and “condi-            it is not clear how simple heuristic updating mechanisms
tion B.” Since global conventions are hypothesized to emerge           alone could account for reduction in repeated interaction. At
through diffuse, repeated interactions of this more local kind         the other extreme are theories in which agents recursively
(Garrod & Doherty, 1994), the cognitive mechanisms under-              track what information is mutual knowledge, often formalized
lying convention-formation in such interactions are of foun-           in a game theoretic setting (Lewis, 1969). Wilkes-Gibbs &
dational interest.                                                     Clark (1992) and others have proposed that agents engage in
   In a seminal study by Krauss & Weinheimer (1964), pairs             a collaborative process of actively establishing mutual knowl-
of participants played a cooperative language game where               edge, though the mechanisms allowing conventions to emerge
they were presented with arrays of ambiguous shapes in ran-            under such conditions have not been instantiated in a formal
domized orders. The players were assigned the roles of di-             model to our knowledge.
rector and matcher and allowed to talk freely. The matcher’s              In this paper, we argue for a theoretical position on the
goal was to rearrange their shapes to match the director’s             spectrum between these poles: conventions form when uncer-
board, and the director’s goal was to communicate useful de-           tain agents treat their partners’ knowledge as ground truth.
scriptions. Over multiple rounds, descriptions were dramati-           In other words, agents assume their partner is knowledgeably
cally shortened: an early description like “upside-down mar-           and rationally using some conventional lexicon mapping la-
tini glass in a wire stand,” became simply “martini” by the            bels to meanings but are themselves initially unsure of its
                                                                   482

                                                                      ticipants easily refer to locations in the grid (see Fig. 1).
                                                                      Procedure After passing a short quiz about task instruc-
                                                                      tions, participants were randomly assigned the role of either
                                                                      ‘director’ or ‘matcher’ and automatically paired into virtual
                                                                      rooms containing a chat box and grid of stimuli. Both par-
                                                                      ticipants could freely use the chat box to communicate at any
                                                                      time. The director’s tangrams were fixed in place, but the
                                                                      matcher could click and drag the shapes to reorder them. The
                                                                      director had to send messages about the locations of differ-
                                                                      ent tangrams on their fixed board; the matcher had to iden-
                                                                      tify the corresponding tangram shapes and move them to the
Figure 1: Example trial in experimental interface. Both play-         correct locations. When the players were satisfied that their
ers could freely use the chat box, and the matcher could click        boards matched, the matcher clicked a ‘submit’ button that
and drag the tangram images.                                          gave players feedback on their score (out of 12) and scram-
                                                                      bled the tangrams for the next round. After six rounds, play-
                                                                      ers were redirected to a short exit survey. We collected the
identity. Through observing their partner’s behavior in re-           raw text of every message sent and every swapping action
peated actions, agents learn and adopt that lexicon, though           taken by the matcher1 .
their partner in fact begins in the same state of ignorance.
When both agents independently adopt such a social learn-             Results
ing strategy, they align to one another, coordinating on and
                                                                      Arbitrariness and stability We begin by examining sig-
implicitly creating shared conventions.
                                                                      natures of arbitrariness and stability in our data. We opera-
   To motivate this theory, we first conduct a large-scale repli-
                                                                      tionalize these concepts using the information-theoretic mea-
cation of the tangrams task on the web, which has tradition-
                                                                      sure of entropy:
ally been limited to relatively small sample sizes in the lab.
We use distributions of lexical and syntactic features in the
                                                                                         H(W ) = ∑ P(w) log P(w)
text corpus to operationalize arbitrariness, stability, and re-                                      w
duction, which have been difficult to analyze at a fine-grained
level due to the sparseness of existing data. Taking these in-        where P(w) denotes the distribution over frequencies of word
sights into account, we then formalize our theory in a compu-         tokens used within a game. Broadly speaking, entropy mea-
tational model of communication in repeated reference games           sures the predictability of a distribution. It is maximized
based on recent successes capturing language understanding            when all elements are equally likely and declines as the dis-
as social inference (Goodman & Frank, 2016; Goodman &                 tribution becomes more structured, i.e. when the probability
Stuhlmller, 2013). Finally, we show that this model qualita-          mass is concentrated on a small subset of elements.
tively produces all three empirical signatures in a simplified           To derive predictions, we consider a permutation-test null
domain inspired by the tangrams task.                                 model in which utterances on each of the six rounds are
                                                                      scrambled across games, designed to break any existing struc-
          Replication of the Tangrams task                            ture in each game’s idiosyncratic word distributions. The
To collect a corpus of reference game dialogue that supports          mean empirical entropy should only differ from the null dis-
more detailed analyses of convention-formation, we ported             tribution of entropies generated from this scrambling process
the tangrams task used in Clark & Wilkes-Gibbs (1986) to a            if both arbitrariness and stability hold.
real-time, multi-player web environment.                                 First, note that if stability did not hold, scrambling would
                                                                      have no effect on the entropy within individual games: a
Methods                                                               given speaker would already use different words each round,
Participants 200 participants were recruited from Ama-                and swapping out the identity of those words would not af-
zon’s Mechanical Turk and paired into dyads to play a real-           fect the entropy of the word distribution. There would be no
time communication game using the framework in Hawkins                structure to break.
(2015). We excluded games that terminated before the com-                If stability holds but arbitrariness does not, all players
pletion of 6 rounds and where participants reported a native          would adopt the single optimal (non-arbitrary) way to refer to
language different from English, leaving a corpus of 67 com-          each tangram. Therefore, the entropy of their word distribu-
plete games with a total of 9967 utterances.                          tions also should not be affected by scrambling: a speaker’s
                                                                      real words would be swapped out for the same tokens gen-
Stimuli On every trial of the game, both participants were
                                                                      erated by another speaker. Scrambling wouldn’t break the
shown a 6 × 2 grid containing twelve tangram shapes, repro-
duced from Clark & Wilkes-Gibbs (1986). Cells were labeled                1 Data are available at https://cocolab.stanford.edu/
with fixed numbers from one to twelve in order to help par-           datasets/tangrams.html
                                                                  483

                                                      #1                            #2                    #3             #4     #5         #6       #7               #8           #9        #10
                         unigrams                     a                             like                  looks          the    one        with     to               of           and       on
                          bigrams                     looks like                    like a                a person       is a   to the     with a   the right        the left     the one   a square
                                                                            Table 1: Top 10 unigrams and bigrams with the highest reduction
                                # words per tangram                                                       # listener messages                 % adjectival clauses                   % subordinate clauses
          20                                                                        20                                                                                     0.15
 metric
          15                                                                        15                                               0.2
          10                                                                                                                                                               0.10
                                                                                    10                                               0.1
           5                                                                         5                                                                                     0.05
           0                                                                         0                                               0.0                                   0.00
                                2                     4                     6                             2          4          6              2          4            6               2         4           6
                                                                                                                                    round #
Figure 2: Reduction phenomena. From left: (1) mean message length in words per tangram, (2) mean number of listener
messages, (3) proportion of utterances containing adjectival clauses, (4) proportion of utterances containing subordinate clauses.
Error bars are bootstrapped 95% CIs.
           % reduction
                         0.75                                                                                 cat                      words used by speakers decreases over time (see Fig. 2). This
                         0.50                                                                                        closed            decrease replicates a highly reliable reduction effect found
                         0.25
                                                                                                                                       throughout the literature on iterated reference games (Bren-
                                                                                                                     open
                                                                                                                                       nan & Clark, 1996; Krauss & Weinheimer, 1964). Likely due
                         0.00
                                                                                                                                       to our purely textual (vs. spoken) interface, participants in our
                                    dets
                                           pronouns
                                                          preps
                                                                  adverbs
                                                                            verbs
                                                                                     adjectives
                                                                                                  nouns                                task used significantly fewer words overall than previously
                                                                                                                                       reported (e.g. an average of 20 words on the 1st round, com-
                                    Part of Speech category                                                                            pared to 40 in Clark & Wilkes-Gibbs (1986)) The following
                                                                                                                                       analyses break down this broad reduction into a finer-grained
Figure 3: Reduction rates for different parts of speech. Error                                                                         set of phenomena.
bars are bootstrapped 95% CIs.                                                                                                            The next level of granularity motivating our model ap-
                                                                                                                                       proach concerns which kinds of words are most likely to be
                                                                                                                                       dropped. Is the speaker adopting a shorthand where they
structure of the distribution, because the structure would be                                                                          drop uninformative function words, or are they simplifying
the same for all participants.                                                                                                         or narrowing their descriptions by omitting meaningful de-
                                                                                                                                       tails (Clark & Wilkes-Gibbs, 1986)? We used the Stanford
   Finally, if both arbitrariness and stability hold, then differ-                                                                     CoreNLP part-of-speech tagger (Toutanova, Klein, Manning,
ent speakers would adopt different referring expressions that                                                                          & Singer, 2003) to count the number of words belonging
persist from round to round. Hence, scrambling should in-                                                                              to each part of speech in each message. Fig. 3 shows the
crease the average game’s entropy from a relatively low level:                                                                         percent reduction of different parts of speech from the first
each game’s idiosyncratic, concentrated distribution of words                                                                          round to the sixth round. We find that determiners (‘the’, ‘a’,
would be mixed together to form more heterogeneous and                                                                                 ‘an’) are the most likely class of words to be dropped with
therefore high-entropy distributions.                                                                                                  an 86% reduction rate, on average. Nouns (‘dancer’, ‘rab-
   To test this prediction, we computed the average within-                                                                            bit’) are the least likely class to be dropped with only an 62%
game entropy for 1000 different permutations of speaker ut-                                                                            rate. Closed-class parts of speech are strictly more likely to
terances. Since this permutation scheme keeps the number of                                                                            be dropped than open-class parts of speech.
messages per participant constant and simply swaps out the                                                                                While this finding is consistent with the possibility that
content of those messages within each round, it controls for                                                                           speakers adopt a shorthand using more fragments as the game
the fact that some speakers sent more messages than others                                                                             proceeds, we find a more complex dynamic by examining the
and also that speakers in earlier rounds use more words (see                                                                           table of unigrams and bigrams most likely to be dropped (see
next section). We found that our null distribution lay within                                                                          Table 1). Note that alongside dropped articles (‘a’, ‘the’),
the interval [4.88, 4.91], which is significantly higher than the                                                                      there are a number of words that form conjunctions (‘and’)
true entropy (averaged across games) of 4.36, p < 0.001. This                                                                          and modifiers (‘of’, ‘with’, ‘the right’). In other words, it
pattern is consistent only with signatures of both arbitrariness                                                                       may be more likely that when function words are dropped, it
and stability.                                                                                                                         is primarily as part of larger grammatical units that provide
Reduction Next, we turn to a set of analyses examining                                                                                 additional information in identifying the target.
reduction in utterance length over the course of the experi-                                                                              We explicitly examined this hypothesis by running the
ment. At the coarsest level, we find that the mean number of                                                                           Stanford constituency parser (Schuster & Manning, 2016),
                                                                                                                                 484

tagging the occurrence of subordinate/adverbial clauses (‘sit-         image of one (L (’dancer’, abstract ballerina) = 0.6), but ap-
ting facing left’) and adjectival clauses (‘angel that is pray-        ply to both better than a non-category member like an image
ing’) .2 We found that both were reduced over the course               of a dog (L (’dancer’, dog) = 0.05).
of the game (see Fig. 2), lending additional support for the              Our approach to convention-formation begins with the ad-
hypothesis that whole meaningful clauses are increasingly              ditional assumption of lexical uncertainty (Bergen, Levy, &
omitted. This result prompts a characterization of reduc-              Goodman, 2016; Smith, Goodman, & Frank, 2013). In other
tion where, due to uncertainty at the outset about the use-            words, we assume that instead of having perfect knowledge
fulness of any particular lexical unit, initial phrases pile on        of L , the listener has uncertainty over the exact meanings of
multiple partially redundant modifiers and descriptors. As             lexical items in the current context (i.e. it is initially unclear
the game progresses and ambiguity of reference decreases,              which of the ambiguous tangram shapes “the dancer” might
these additional meaningful units become less useful and can           refer to). They begin with some prior P(L ) about the iden-
be dropped. We return to this characterization more formally           tity their partner’s true lexicon, which may be initially biased
within the scope of our model below.                                   toward certain meanings. By conditioning on repeated ob-
                                                                       servations of their partner’s behavior, they use Bayes rule to
                                Model                                  infer this true lexicon:
Here, we present a probabilistic model of language produc-
tion under uncertainty, which captures several of the signa-                             PLn (L |d) ∝ P(L ) ∏ Sn (si |ui , L )
                                                                                                              i
ture properties of conventions shown above. This model be-
longs to the family of Rational Speech Act (RSA) models,               where d = {si , ui } is a set of observations of si and ui com-
which have been successful in explaining a wide range of lin-          ing from previous exchanges3 . The listener marginalizes over
guistic phenomena – including scalar implicature, adjectival           this posterior when interpreting the speaker’s utterance:
vagueness, overinformativeness, indirect questions, and non-
literal language use – as arising from a process of recursive                           Ln (s|u, d) ∝ ∑ PLn (L |d)Ln (s|u, L )
social reasoning. Most previous applications of RSA have fo-                                           L
cused on the listener’s problem of language comprehension,
                                                                       The speaker, in turn, considers what utterances would be most
but the puzzle of conventionalization is primarily a question
                                                                       informative for such a listener:
of speaker production. An nth order pragmatic speaker trying
to convey a particular state of affairs s ∈ S assuming lexi-
                                                                                                                               !
con L is assumed to select an utterance u ∈ U by trading off           Sn (u|s, d) ∝ exp(α log      ∑ PSn (L |d)Ln−1 (s|u, L )   −cost(u))
its expected informativity (with respect to a rational listener                                      L
agent) against its cost, usually based on length (Goodman &
                                                                       where the posterior over lexica PSn (L |d), uses the listener
Frank, 2016):
                                                                       likelihood Ln−1 . For the purposes of this paper, we fix the
         Sn (u|s, L ) ∝ exp (α log Ln−1 (s|u, L ) − cost(u))           depth of recursion at n = 2. This model is implemented in
                                                                       the probabilistic programming language WebPPL (Goodman
where α is a soft-max optimality parameter controlling the             & Stuhlmller, electronic).4 Following Smith et al. (2013),
extent to which the speaker maximizes over listener infor-             we begin by showing how a random initial choice is taken to
mativity. The listener, in turn, inverts the speaker model to          be evidence for a particular lexicon and becomes the base for
reason about what underlying state s the speaker is trying to          successful communication even though neither party knows
convey, given their utterance u:                                       its meaning at the outset.
                     Ln (s|u, L ) ∝ P(s)Sn (u|s, L )                   Results
                                                                       Arbitrariness and stability Consider an environment with
   This recursion bottoms out in a literal listener who directly       two abstract shapes ({s1 , s2 }), where the speaker must choose
looks up the meaning of the utterance in the lexicon:                  between two utterances ({u1 , u2 }) incurring equal cost. Their
                                                                       prior P(L ) over the meaning of each utterance is given by a
                      L0 (s|u, L ) ∝ L (u, s) · P(s)
                                                                       Beta distribution5 , so on the first round both utterances are
   As in several other recent applications of RSA (Graf, De-               3 There is a broader debate over the timescales at which lexi-
gen, Hawkins, & Goodman, 2016), we use a graded seman-                 cons and lexicon learning mechanisms operate; here, we assume a
tics, where utterances are better or worse descriptions of par-        discourse-level structure to the lexicon, where there is uncertainty
                                                                       over how words are used in the given conversation. See Frank,
ticular referents. For instance, the utterance “dancer” may ini-       Goodman, & Tenenbaum (2009) for a related approach at the scale
tially be expected to apply to a photorealistic image of a bal-        of cross-situational word learning.
                                                                           4 All results can be reproduced running our code in the browser
lerina (L (’dancer’, ballerina) = 0.99) more than an abstract
                                                                       at http://forestdb.org/models/conventions.html
    2 Specifically, we used the Universal Dependencies tags csubj,         5 In our implementation, we enumerate over coarse-grained bins;
ccomp, xcomp, and advcl for subordinate clauses and acl for ad-        preliminary experiments using variational inference on the full con-
jectival clauses (Schuster & Manning, 2016)                            tinuous distribution give similar results.
                                                                   485

    A                 initial         u1,s1       u1,s2          B                  alpha         1       2     5           C 1.4
                                                                                                                        mean # words
                                                                                                                                       1.3
           1.00                                                          1.00
           0.75                                                          0.75                                                          1.2
P(u1,s1)                                                      accuracy
           0.50                                                          0.50
                                                                                                                                       1.1
           0.25                                                          0.25
           0.00                                                          0.00                                                          1.0
                  0     1       2      3      4   5       6                     0           2             4         6                        0   1   2      3      4   5   6
                                    round #                                                     round #                                                  round #
Figure 4: (A) Probability of speaker using u1 to refer to s1 , broken out by initial observation: while players are initially
ambivalent between the two labels (arbitrariness), the initial mapping is likely to persist (stability). (B) Accuracy rises as
speaker and listener align. (C) When conjunctions are introduced into the grammar, utterances get shorter over time (reduction).
equally likely to apply to either shape. If the speaker was try-                                  ally from lexical primitives, using the product rule:
ing to get their partner to pick s1 , then, since each utterance
is equally (un)informative, they would randomly sample one                                                     L (ui and u j , o) = L (ui , o) × L (u j , o)
(say, u1 ), and observe the listener’s selection of a shape (say,                                    Analogous to our tangram stimuli, which have many am-
s1 ). On the next round, the speaker uses the observed pair                                       biguous features and figurative perspectives that may be
{u1 , s1 } to update their beliefs about their partner’s true lex-                                evoked in speaker descriptions, we consider a simplified sce-
icon, uses these beliefs to generate a new utterance, and so                                      nario where speakers can refer to two different features of the
on. To examine expected dynamics over multiple rounds, we                                         two objects {o1 , o2 }. The speaker has four primitive words at
forward sample many possible trajectories.                                                        their disposal – two words for shape ({us1 , us2 }) and two for
    We observe several important qualitative effects in our sim-                                  color {uc1 , uc2 } – and has uncertainty over the initial mean-
ulations. First, the fact that a knowledgeable listener responds                                  ings of all four.
to utterance u with s provides evidence for lexicons in which                                        While we established in the previous section that conven-
u is a good fit for s, hence the likelihood of the speaker using                                  tions can emerge over a reference game in the complete ab-
u to refer to s increases on subsequent rounds (see Fig.4A). In                                   sence of initial preferences, players often bring such prefer-
other words, the initial symmetry between the meanings can                                        ences to the table. A player who hears ‘ice skater’ on the
be broken by initial random choices, leading to completely                                        first round of our tangrams task is more likely to select some
arbitrary but stable mappings in future rounds. Second, be-                                       objects more than others, even though they still have some
cause the listener is also learning the lexicon from these ob-                                    uncertainty over its meaning in the context. To show that our
servations under the same set of assumptions, they converge                                       model can accommodate this fact, we allow the speaker’s ini-
on a shared set of meanings; hence, expected accuracy rises                                       tial prior meanings to be slightly biased. us1 and uc1 are more
on future rounds (see Fig. 4B). Third, because one’s part-                                        likely to mean o1 ; us2 and uc2 are more likely to mean o2 .
ner is assumed to be pragmatic, agents can also learn about                                          We ran 1000 forward samples of 6 rounds of speaker-
unheard utterances. Observing d = {u1 , s1 } also provides ev-                                    listener interaction, and averaged over the utterance length
idence that u2 is not a good fit for s1 by Gricean maxims: if u2                                  at each round.6 Our results are shown in Figure 4C: the ex-
were a better fit for s1 , the speaker would have used it instead                                 pected utterance length decreases systematically over each
(Grice, 1975). Finally, failed references lead to conventions                                     round. To illustrate in more detail how this dynamic is
just as effectively as successful references: if the speaker in-                                  driven by an initial rational preference for redundancy relax-
tends s1 and says u1 , but then the listener incorrectly picks s2 ,                               ing as reference becomes more reliable, we walk step-by-step
the speaker will take this as evidence that u1 actually means                                     through a single trajectory.
s2 in their partner’s lexicon and become increasingly likely to                                      Consider a speaker who wants to refer to object o1 . They
use it that way on subsequent rounds.                                                             believe their knowledgeable partner is slightly more likely to
Reduction in utterance length Finally, we show how our                                            interpret their language using a lexicon in which us1 and uc1
model explains reduction of utterance length over multiple in-                                    apply to this object, due to their initial bias. However, there
teractions. For utterances to be reduced, of course, they must                                    is still a reasonable chance that one or the other alone actu-
vary in length. Motivated by our empirical observation that                                       ally refers strongly to o2 in the true lexicon. Thus, it is use-
meaningful clauses are the primary unit of reduction, we ex-                                      ful to produce the conjunction “us1 and uc1 ” to hedge against
tend our grammar to include conjunctions. This is one of the                                      this possibility, despite its higher cost. Upon observing the
simplest ways to constructing longer utterances composition-                                          6 In our simulations, we used α = 10 and found the basic reduc-
                                                                                                  tion effect over a range of different biases
                                                                                            486

listener’s response (say, o1 ), the evidence is indeterminate         less serves as a lower bound on the degree of social reasoning
about the separate meanings of us1 and uc1 but both become            needed to capture lexical conventions in these games.
increasingly likely to refer to o1 . In the trade-off between in-
formativity and cost, the shorter utterances remain probable                               Acknowledgements
options. Once the speaker chooses one of them, the symmetry           We thank Nicole Maslan for her contributions during piloting. This
                                                                      work was supported by ONR grant N00014-13-1-0788 and a Sloan
collapses and that utterance remains most probable in future          Research Fellowship to NDG. RXDH was supported by the Stanford
rounds. In this way, meaningful sub-phrases are omitted over          Graduate Fellowship and the National Science Foundation Graduate
time as the speaker becomes more confident about the true             Research Fellowship under Grant No. DGE-114747.
lexicon.
                                                                                                  References
                                                                       Barr, D. J. (2004). Establishing conventional communication sys-
                    General Discussion                                   tems: Is common knowledge necessary? Cognitive Science,
                                                                         28(6), 937–962.
In this paper, we revisited the classic phenomenon of                  Bergen, L., Levy, R., & Goodman, N. D. (2016). Pragmatic rea-
convention-formation in a large-scale, text-based replication            soning through semantic inference. Semantics and Pragmatics,
of the tangrams task. We argued that several key qualitative             9(20).
                                                                       Brennan, S. E., & Clark, H. H. (1996). Conceptual pacts and lexi-
patterns in the data – arbitrariness, stability, and the reduc-          cal choice in conversation. Journal of Experimental Psychology:
tion of utterance length over repeated interactions – can be             Learning, Memory, and Cognition, 22(6), 1482.
explained by our model of informative communication under              Centola, D., & Baronchelli, A. (2015). The spontaneous emer-
                                                                         gence of conventions: An experimental study of cultural evolu-
lexical uncertainty. This model formalizes a theory where                tion. Proceedings of the National Academy of Sciences, 112(7),
conventions emerge via uncertain agents who assume their                 1989–1994.
partner is knowledgably and informatively using some con-              Clark, H. H., & Wilkes-Gibbs, D. (1986). Referring as a collabora-
                                                                         tive process. Cognition, 22(1), 1–39.
ventional lexicon. Through repeated observations of their              Frank, M. C., Goodman, N. D., & Tenenbaum, J. B. (2009). Using
partner’s actions, agents learn this lexicon, thereby coordi-            speakers’ referential intentions to model early cross-situational
nating and aligning to one another.                                      word learning. Psychological Science, 20(5), 578–585.
                                                                       Garrod, S., & Doherty, G. (1994). Conversation, co-ordination and
   Theories of convention-formation vary in the extent to                convention: An empirical investigation of how groups establish
which social reasoning about common ground is required.                  linguistic conventions. Cognition, 53(3), 181–215.
                                                                       Goodman, N. D., & Frank, M. C. (2016). Pragmatic language inter-
Our agents lie on a spectrum between the heuristic updating              pretation as probabilistic inference. Trends in Cognitive Sciences,
agents of Barr (2004) and the sophisticated agents of Clark &            20(11), 818–829.
Wilkes-Gibbs (1986), who collaboratively build up explicit             Goodman, N. D., & Stuhlmller, A. (2013). Knowledge and im-
                                                                         plicature: Modeling language understanding as social cognition.
representations of mutual knowledge. Speakers and listen-                Topics in Cognitive Science, 5(1), 173–184.
ers in our model implicitly coordinate their beliefs through           Goodman, N. D., & Stuhlmller, A. (electronic). The design and im-
a shared history of observations, which serves as “common                plementation of probabilistic programming languages. Retrieved
                                                                         from http://dippl.org
ground” in an informal sense. They make critical use of prag-          Graf, C., Degen, J., Hawkins, R. X. D., & Goodman, N. D. (2016).
matic, social reasoning in order to learn meanings, but do not           Animal, dog, or dalmatian? Level of abstraction in nominal refer-
explicitly consider the fact that this history is shared, or rep-        ring expressions. In Proceedings of the 38th annual conference of
                                                                         the Cognitive Science Society.
resent their partner’s own uncertainty.                                Grice, H. P. (1975). Logic and conversation. In P. Cole & J. Morgan
   By capturing reduction, which purely heuristic theories               (Eds.), Syntax and semantics (pp. 43–58). New York: Academic
have not yet demonstrated, we showed that minimal assump-                Press.
                                                                       Hawkins, R. X. D. (2015). Conducting real-time multiplayer exper-
tions of social reasoning go a long way in accounting for key            iments on the web. Behavior Research Methods, 47(4), 966–976.
phenomena. Still, our model falls short in some ways. For              Hawkins, R. X. D., & Goldstone, R. L. (2016). The formation of
instance, because we do not provide a mechanisms for the                 social conventions in real-time environments. PLoS ONE, 11(3),
                                                                         1–14.
listener agent to respond with confirmation, repair, or follow-        Krauss, R. M., & Weinheimer, S. (1964). Changes in reference
up questions, we cannot make explicit predictions about the              phrases as a function of frequency of usage in social interaction:
reduction in listener messages (as shown in Fig. 2) or the               A preliminary study. Psychonomic Science, 1(1-12), 113–114.
                                                                       Lewis, D. (1969). Convention: A philosophical study. Harvard
effect of listener input on the conventionalization process.             University Press.
These phenomena require our model to deal with planning                Schuster, S., & Manning, C. D. (2016). Enhanced english universal
over extended dialogues, and more sophisticated speech acts.             dependencies: An improved representation for natural language
                                                                         understanding tasks. In LREC 2016.
Similarly, while our model was explicitly designed with lin-           Smith, N. J., Goodman, N. D., & Frank, M. C. (2013). Learning
guistic conventions in mind, it remains to be seen whether the           and using language via recursive pragmatic reasoning about other
same formulation generalizes to broader behavioral conven-               agents. In NIPS (pp. 3039–3047).
                                                                       Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003).
tions. For example, the real-time coordination games used in             Feature-rich part-of-speech tagging with a cyclic dependency net-
Hawkins & Goldstone (2016) may not require players to rea-               work. In NAACL-HLT (pp. 173–180).
son about a structured lexicon with noise, but an action policy        Wilkes-Gibbs, D., & Clark, H. H. (1992). Coordinating beliefs in
                                                                         conversation. Journal of Memory and Language, 31(2), 183–194.
representation may play a similar role. While there remain             Young, H. P. (2015). The evolution of social norms. Annual Review
many complex aspects of convention-formation in communi-                 of Economics, 7, 359–387.
cation games left for future research, our approach nonethe-
                                                                  487

