    Watching Non-Corresponding Gestures Helps Learners with High Visuospatial
  Ability to Learn about Movements with Dynamic Visualizations: An fNIRS Study
                                        Birgit Brucker (b.brucker@iwm-tuebingen.de) a
                                         Björn de Koning (b.b.dekoning@fsw.eur.nl) b
                           Ann-Christine Ehlis (ann-christine.ehlis@med.uni-tuebingen.de) c
                             David Rosenbaum (david.rosenbaum@med.uni-tuebingen.de) c
                                         Peter Gerjets (p.gerjets@iwm-tuebingen.de) a
                       a
                         Leibniz-Institut für Wissensmedien, Schleichstrasse 6, 72076 Tuebingen, Germany
               b
                 Erasmus University Rotterdam, Burgemeester Oudlaan 50, 3062 PA Rotterdam, The Netherlands
  c
    Department of Psychiatry & Psychotherapy, University Hospital Tuebingen, Calwerstr. 14, 72076 Tuebingen, Germany
                            Abstract                                    with the hands (Marcus et al., 2013) or learning to classify
  This study investigates whether making and observing
                                                                        fish movements (Brucker et al., 2015). However, so far (1)
  (human) gestures facilitates learning about non-human                 there is only a handful of studies investigating the
  biological movements and whether correspondence between               instructional potential of dynamic visualizations addressing
  gesture and to-be-learned movement is superior to non-                biological movement and most of them focus on hand-
  correspondence. Functional near-infrared spectroscopy was             manipulative tasks, and (2) it is yet unexplored to what
  used to address whether gestures activate the human mirror-           extent learning about biological movements from dynamic
  neuron system (hMNS) and whether this activation mediates             visualizations can be enhanced by additional instructional
  the facilitation of learning. During learning, participants
  viewed the animations of the to-be-learned movements twice.           support. These aspects provided the basis for the present
  Depending on the condition, the second viewing was                    study wherein we investigated the value of observing and
  supplemented with either a self-gesturing instruction (Y/N)           making gestures for learning to classify fish movement
  and/or a gesture video (corresponding/non-corresponding/no).          patterns from dynamic visualizations.
  Results showed that high-visuospatial-ability learners showed
  better learning outcomes with non-corresponding gestures,             Gestures and Learning
  whereas those gestures were detrimental for low-visuospatial-
  ability learners. Furthermore, the activation of the inferior-        It is by now relatively well-established that making and
  parietal cortex (part of the hMNS) tended to predict better           observing gestures is beneficial for acquiring knowledge
  learning outcomes. Unexpectedly, making gestures did not              about different scientific topics and spatial problem solving
  influence learning, but cortical activation differed for learners     (e.g., Chu & Kita, 2011; Cook & Goldin-Meadow, 2006). In
  who self-gestured depending on which gesture they observed.           learning about movements from dynamic visualizations,
  Results and implications are discussed.
                                                                        there is also increasing evidence that showing hands in
  Keywords:       Learning     about     movements;       dynamic       manual tasks (e.g. origami folding, Marcus et al., 2013) or
  visualizations; human mirror-neuron system;             gestures;     observing gestures in addition to the learning material
  functional near-infrared spectroscopy.                                improves learning outcomes (Brucker et al., 2015; De
                                                                        Koning & Tabbers, 2013). It is assumed that this is due to
      Learning from Dynamic Visualizations                              the activation of brain regions (i.e., the human mirror-
In recent years, dynamic visualizations such as animations              neuron system [hMNS]; Fogassi & Ferrari, 2011; Rizzolatti
and videos have become a popular instructional tool to                  & Craighero, 2004) involved in the observation,
visualize processes and phenomena that are dynamic in                   understanding and imitation of other persons’ actions. This
nature (e.g., cardiovascular system, lightning formation, fish          is in line with the current hypothesis that the stimulation and
movements). Obviously, dynamic visualizations are well-                 involvement of this hMNS might be beneficial for learning
suited for this purpose given that they explicitly depict               about complex continuous aspects with dynamic
visuospatial information over time. Nevertheless, research              visualizations (Ayres et al., 2009; Van Gog et al., 2009).
thus far indicates that dynamic visualizations are often not                Initial evidence for this comes from a study by Brucker
superior to learning from static visualizations (e.g., Castro-          et al. (2015) wherein low- and high-visuospatial-ability
Alonso et al., 2016; Mayer et al., 2005). It appears that               learners had to learn fish movement patterns from dynamic
dynamic visualizations are particularly effective for learning          visualizations whilst observing additional gestures that did
about movements when biological movement is involved                    or did not correspond to the depicted movements. Results
(Hoffler & Leutner, 2007) like when learning to tie knots               showed better learning outcomes and higher cortical
                                                                    168

activation in the inferior-frontal cortex (part of the hMNS)        instructions and visualization formats. Higher visuospatial
for low-visuospatial-ability learners after watching gestures       ability may compensate for “poor” instructions (i.e., in our
that corresponded to the to-be-learned fish movements               case unrelated non-corresponding gestures, cf. Methods
compared to watching non-corresponding gestures. High-              section), whereas learners with lower visuospatial ability
visuospatial-ability learners achieved high learning                suffer from such instructions (cf. ability-as-compensator
outcomes with both gestures. Unexpectedly, low-                     hypothesis; Höffler, 2010). For example, relating this to the
visuospatial-ability learners who watched the non-                  Brucker et al. (2015) study, high-visuospatial-ability
corresponding gestures could also achieve high learning             learners likely possess the skills and resources to see when
outcomes if they activated their inferior-parietal cortex (also     gestures are in conflict with the depicted content and come
part of the hMNS). These findings provide the first                 up with an own strategy to elaborate on the relevant
indication that the hMNS is also involved in representing           movements, whereas low-visuospatial-ability learners do
non-human biological or even non-biological movements, if           not possess these skills and therefore are less able to deal
the observer is able to anthropomorphize these movements            with situations where gestures are in conflict with the
(cf. De Koning & Tabbers, 2011). So, drawing on the                 dynamic visualizations resulting in lower learning
hMNS by showing learners gestures associated with the               outcomes. Thus, taking into account learners’ visuospatial
learning content seems an effective instructional strategy to       ability is relevant when studying the value of gestures in
improve learning about biological movements from                    learning about movements from dynamic visualizations.
dynamic visualizations.
   Based on the notion that learner-generated gestures, as          Present Study
compared to just observing other’s gestures, have a more            This study addresses the question to what extent learning
direct and stronger influence on the degree to which the            about biological movements from dynamic visualizations
hMNS is activated (e.g., Montgomery, Isenberg, & Haxby,             can be enhanced by adding information in the form of
2007), asking learners to make gestures related to the              gestures. We implemented gesture-information in two ways:
movements depicted in a dynamic visualization themselves            By making gestures of the learners themselves and by
may be a way to further enhance learning (cf. De Koning &           observing gestures displayed on a video. We investigated
Tabbers, 2011). Additional advantages of self-performed             making gestures (by the learner) by contrasting (1) studying
gestures relate to the manner (e.g., speed, amplitude) in           the dynamic visualizations whilst making gestures to (2)
which the gestures are made and the possibility to draw on          studying the visualizations without making gestures.
one’s personal experiences (with fish movement) in order to         Moreover, we examined observing gestures (that do or do
perform the gestures. By embodying the learning content in          not correspond to the depicted non-human biological
one’s sensory and motor systems based on physical                   movements) by contrasting studying the dynamic
movements (i.e., gestures), the information is coded in a           visualization whilst (1) observing corresponding versus (2)
distinct, visuospatial representational format that enriches        observing non-corresponding versus (3) not observing
the way the information is represented, thereby creating a          additional gestures. Furthermore, functional near-infrared
higher-quality mental representation (Paas & Sweller,               spectroscopy (fNIRS), which is a non-intrusive
2012). Higher-quality mental representations are associated         neurophysiological method to gather data about cortical
with better learning (Goldin-Meadow et al., 2001), yielding         activation of humans, is used to investigate whether the
faster and more accurate performance on learning tests. It is       hMNS is activated during viewing gestures and learning
important to note that these anticipated benefits only arise as     about biological movements from dynamic visualizations.
long as the act of making gestures is not too demanding,            We hypothesize that studying the dynamic visualization
complex or distracting (De Koning & Tabbers, 2013;                  with additionally making gestures yields higher learning
Skulmowski et al., 2014). Together, by focusing on self-            outcomes than studying without making gestures.
performed gestures whilst learning about biological                 Additionally, we hypothesize that studying the dynamic
movements from dynamic visualizations, we move into a               visualizations with additionally observing gestures yields
promising but yet unexplored field of research (for an              higher learning outcomes than studying without observing
exception see De Koning & Tabbers, 2013).                           gestures. In accordance with Brucker et al. (2015), this
                                                                    pattern is expected to vary as a function of level of gesture
Visuospatial Ability, Gestures, and Learning                        correspondence and learner’s visuospatial ability: low-
As processing continuous changes requires visuospatial              visuospatial-ability learners are expected to show higher
ability (cf. Hegarty, 1992), it is likely that learners’            learning outcomes only on corresponding gestures, whereas
visuospatial ability will determine how much they benefit           high-visuospatial-ability learners are expected to show
from dynamic visualizations and additional gestures (cf.            improved learning outcomes for corresponding and non-
Hegarty & Waller, 2005). According to previous research             corresponding gestures. Furthermore, we hypothesize that
(e.g., Höffler, 2010) learners with higher visuospatial ability     the hMNS is more strongly activated with self-performed
outperform learners with lower visuospatial ability during          gestures than with observed gestures, which in turn is more
learning with visualizations, and visuospatial ability may          strongly activated than studying without gestures.
moderate the effectiveness of learning with different               Moreover, we hypothesize that higher hMNS activation is
                                                                169

associated with higher learning outcomes. This is expected           dimensional space (i.e. different paddle-like or wave-like
to be particularly true for low-visuospatial learners.               movements). The four different movement patterns were: 1.
                                                                     oscillation of the pectoral fins; 2. undulation of the body; 3.
                           Methods                                   undulation of the dorsal and anal fins; and 4. oscillation of
                                                                     the dorsal and anal fins (and undulation of the pectoral fins).
Participants and Design                                              During identifying these movement patterns it is very
One hundred and eighteen university students (M = 24.37              challenging that fish may deploy other movements in
years, SD = 3.99; 84 females; 109 right handed) were                 addition (e.g., to navigate) and these additional movements
recruited via an online system (http://www.orsee.org/) and           can easily be mistaken for movements used for propulsion
compensated with 10 Euro. They had to learn to                       in another movement pattern. We used the fish animations
discriminate different fish according to their movements             and gesture videos from Brucker et al. (2015). The
based on dynamic visualizations. There were four different           movement cycles of the movement patterns were presented
to-be-learned movement patterns of fish. The participants            in loops in the animations (30 s per movement pattern, 25
saw each movement pattern twice: Firstly, they saw an                fps, size: 480 x 360 pixels). The gestures were presented in
animation of the specific movement pattern. Secondly, they           the respective conditions in loops in the videos (30 s per
saw the animation of the specific movement pattern again.            movement pattern, 25 frames per s, size: 480 x 360 pixels).
But this time depending on the experimental condition, the           The presentation of all visualizations was system-controlled.
animation could have been complemented with two
additional sources: either a written instruction to self-gesture
(making gestures) and/or a video of a person performing
gestures with his hands and arms (observing gestures).
Depending on this 2-by-3-between subjects design of the
study with the two independent factors making gesture and
observing gesture there were six conditions in total. Making
gesture was varied in two variants: Participants either did or
did not get the instruction “Please make your own gestures,
that help you to better understand the movement.”
Observing gesture was varied in three variants: Participants
either saw gestures that did correspond or that did not                Figure 1: Six conditions in the 2-by-3-design of the study.
correspond (i.e., were unrelated) to the fish movement
patterns or they saw no gesture at all (see Figure 1).
                                                                     Measures
   For the observing gestures conditions we used the                 Learning Outcomes To assess learning outcomes, we
gestures from Brucker et al. (2015). For the corresponding           administered a movement pattern classification test
gestures, an expert regarding fish movements displayed with          comprising 45 dynamic multiple-choice items. These items
his hands and arms representations of the respective                 consisted of underwater videos of real fish performing one
movements as clearly as possible, whereas for the non-               of the four to-be-learned movement patterns or a distractor
corresponding gestures the (same) expert performed                   movement pattern. Learners had to identify the body parts
gestures with his hands and arms that were unrelated to the          relevant for propulsion and their way of moving to choose
fish movement patterns (i.e., waving, circulating the                for each item the kind of movement pattern that was
forearms around each other, drumming, and pointing.                  depicted. Each item was visible for 7 s and immediately
   Participants saw the animation of the first fish movement         afterwards participants had 3 s time to choose the correct
for 30 s. Then a pause of 30 s (black screen) followed before        answer by pressing a corresponding button. Each item was
they saw the animation of the first fish movement with its           awarded one point for the correct answer (0 to max. 45
additions (depending on the experimental condition) for 30 s         points). The test items were presented in blocks of 30 s so
again. Then again a pause of 30 s (black screen) followed            that 3 items were grouped together. Pauses of 30 s (black
before the presentation of the next fish movement started in         screen) followed each block.
the same manner. The learners were instructed to relax in
the pauses with the intention that the activations of the brain      Learners’ Visuospatial Ability To assess learners’
areas of interest were supposed to return to baseline level          visuospatial ability we used a short version of the paper
before the next visualization was displayed.                         folding test (PFT, Ekstrom et al., 1976; ten multiple-choice
                                                                     items; total processing time: three minutes). In this task,
Materials                                                            participants see five options from which they have to choose
Participants were asked to learn to classify four different          the correct answer. The stimuli are depictions of papers that
fish movement patterns. These fish movement patterns                 are folded stepwise and then were punched in the folded
differ in terms of the parts of the body that generate               state. The answer options depict unfolded papers with
propulsion (i.e., several fins or the body itself) and also in       punches being either in the correct or incorrect positions.
the manner of how these body parts move in the three-                Each correct answer is worth one point (max. 10 points).
                                                                 170

Cortical Activation During viewing the fish animation for            gestures and learners’ visuospatial ability on learning
the second time in the learning phase, cortical activation           outcomes (F(2, 106) = 7.93, MSE = 119.63, p = .001, η2p =
was assessed via fNIRS measurements with an ETG-4000                 .13; see means and standard errors in Figure 2). There were
(Hitachi Medical Co.). We used a 2x22 channel array as               no other significant interactions or three-way-interactions
probe set that was placed over fronto-temporo-parietal               (all ps > .35, ns). The significant interaction between
regions and was centered at the T3-T4 and C3-C4 positions            observing gestures and learners’ visuospatial ability on
(not exactly terminating on these positions because of the           learning outcomes showed that for participants with high
fixed interoptode distances) according to the standard               visuospatial ability (defined as one standard deviation above
locations of the 10-20 system for electrode placement                the sample mean) the non-corresponding gesture led to
(Jasper, 1958). The fNIRS system measures the change in              better learning outcomes than the corresponding gesture (p
the product of hemoglobin (Hb) concentration and effective           = .001) and no gesture (p = .02). For participants with low
optical path length in human brain tissue. The unit of Hb            visuospatial ability (defined as one standard deviation below
change is molar concentration (mM = mmol/l) multiplied by            the sample mean) non-corresponding gestures were worse
optical path length (mm). Local increases of Hb are                  for learning than no gesture (p < .01), whereas there was no
indicators of cortical activity (Obrig & Villringer, 2003).          significant difference between the corresponding gesture
                                                                     condition and the no gesture condition (p = .23, ns). Thus,
Procedure                                                            the non-corresponding gestures are beneficial for high-, but
Participants were tested individually. After reading a printed       detrimental for low-visuospatial-ability learners.
overview with information about the procedure of the study,
they had to answer the demographics and the PFT. Then, the
experimenter placed and adjusted the fNIRS probe set on
the scalp of the participants. Subsequently, the computer-
based learning materials were presented (learning phase).
For each of the four to-be-learned movement patterns,
learners were presented with the two presentations of the
fish animations (1. fish animation and 2. fish animation plus
additional gesture video and/or self-gesturing instruction
depending on the experimental condition). Following the
learning phase (8 min) learners performed a filler task               Figure 2. Interaction between learners’ visuospatial ability
(about 8 min), in which they answered some questions on                      and observing gestures on learning outcomes.
object positions of depicted objects. Subsequently, learners
completed the movement classification test (15 min).                 Cortical Activation
Participants were instructed to put both their forefingers and       To analyze the cortical activation, we defined two regions of
both their middle fingers on predefined keys as well as one          interest (ROIs) on the left hemisphere for the hMNS among
of their thumbs on the space bar to answer the test items.           the respective channels (cf. Rizzolatti & Craighero, 2004).
The predefined keys were labeled on the screen with static           The two ROIs were the left inferior-frontal cortex (IFC) and
screenshots from the learning animations of the four                 the left inferior-parietal cortex (IPC, cf. Figure 3). Cortical
movement patterns and the spacebar was labeled with a grey           activation in these areas was analyzed with two ANCOVAs
bar indicating movements that were not part of the learning          with the factors making gestures, observing gestures, and
phase (i.e. distractor items). In total, one experimental            learners’ visuospatial ability as a covariate. We had to
session lasted approximately 50 minutes.                             exclude five participants from these analyses because of
                                                                     poor data quality resulting in a total number of 113
                            Results                                  participants in these analyses. Even though making gestures
                                                                     did not influence results on learning outcomes, analyses on
Learning Outcomes                                                    cortical activation showed tendencies for an interaction
To analyze learning outcomes, we conducted an ANCOVA                 between making gestures and observing gestures for both
(univariate analysis of covariance) with the factors making          IFC activation (F(2, 100) = 2.94, MSE = .001, p = .06, η2p =
gesture, observing gesture, and the continuous factor                .06) and IPC activation (F(2, 100) = 2.42, MSE = .001, p =
learners’ visuospatial ability as a covariate. We inserted all       .06, η2p = .05). There were no other significant main effects
interaction terms in the analysis to investigate the possible        or interactions in these analyses (all ps > .104, ns). Pairwise
interactions. For learning outcomes, results showed no main          comparisons revealed that participants observing
effect of making gestures (F < 1, ns), no main effect of             corresponding gestures showed higher IFC activation if they
observing gestures (F(2, 106) = 1.65, MSE = 119.63, p =              self-gestured than when they did not self-gesture (p = .005).
.20, η2p = .03, ns), but there was a significant main effect for     However, participants observing non-corresponding
learners’ visuospatial ability (F(1, 106) = 11.58, MSE =             gestures showed higher IPC activation if they self-gestured
119.63, p = .001, η2p = .10). This effect has to be interpreted      than when they did not self-gesture (p = .02). This might be
in terms of the significant interaction between observing            an indicator that during watching corresponding gestures the
                                                                 171

IFC is more important, whereas during processing non-                they properly understand the depicted movement. In
corresponding gestures the IPC becomes more important –              contrast, low-visuospatial-ability learners presumably are
at least when the participants were instructed to self-gesture.      insufficiently equipped for managing such a situation of
                                                                     conflicting information (e.g., they do not have the resources
                                                                     to identify the mismatch or do not know how to cope with
                                                                     that), and are not able to accurately process the movements
                                                                     and to avoid reduced performance.
                                                                         In this study, IFC activation tended to predict better
                                                                     learning outcomes. However, compared to the Brucker et al.
      Figure 3. Spatial arrangement of the left probe set.           (2015) study, we did not find the result pattern that IPC
                                                                     activation compensates for missing support of visuospatial
Effects of Cortical Activation on Learning                           ability or non-conflicting gestures. This might be explained
To address the question whether higher hMNS activation is            by the fact that in the present study participants who neither
directly associated with better learning outcomes, we                have visuospatial ability nor non-conflicting gestures at their
conducted two ANCOVAs with the factors making gestures,              disposal (i.e. the group of low-visuospatial-ability learners
observing gestures, learners’ visuospatial ability and               who saw non-corresponding gestures) still could focus on
cortical activation in terms of IFC activation or IPC                the fish animation. This was possible because in this study
activation, respectively. There was a tendency that higher           the gestures were presented at the same time as the fish,
IFC activation lead to higher learning outcomes (F(1, 88) =          whereas in our prior study the gestures were presented
3.22, MSE = 124.85, p = .08, η2p = .04). This analysis on            separated in time from the fish animations. However, further
IFC activation did also show the main effect for visuospatial        research should investigate direct comparisons of sequential
ability (F(1, 88) = 7.58, MSE = 124.85, p < .01, η2p = .08) as       and simultaneous presentations of additional gestures.
well as the interaction between observing gesture and                    Another interesting result of this study is that, in contrast
visuospatial ability (F(2, 88) = 3.93, MSE = 124.85, p = .02,        to our hypothesis, self-performed gestures did not improve
η2p = .08; both effects reported for learning outcomes, see          learning outcomes. In line with this, several recent attempts
Figure 2). For IFC activation there were no other significant        to augment learning about non-human movement (e.g.,
main effects or interactions (all ps > .27, ns). The analysis        lightning formation, grammar rules) by instructing learners
on IPC activation did also show the main effect for                  to make gestures while studying an animation also failed to
visuospatial ability (F(1, 88) = 7.18, MSE = 128.56, p < .01,        improve learning performance (e.g. De Koning & Tabbers,
η2p = .08) and the interaction between observing gesture and         2013; Post et al., 2013). Collectively, the conclusion from
visuospatial ability (F(2, 88) = 5.18, MSE = 128.56, p < .01,        this and other studies is that independent from timing of
η2p = .11; both effects reported for learning outcomes, see          gestures (during or after learning from dynamic
Figure 2). For IPC activation there were no other significant        visualizations) and instructional approach (instruct specific
main effects or interactions (all ps > .189, ns).                    ways to perform gestures or let learners decide how to
                                                                     perform gestures) making gestures does not seem to benefit
                         Discussion                                  learning from dynamic visualizations involving non-human
                                                                     movement. Importantly, however, making gestures did
This study investigated whether making and observing
                                                                     activate the hMNS. Participants who were instructed to self-
additional gestures improves learning about biological
                                                                     gesture activated different parts of the hMNS depending on
movements from dynamic visualizations and to what extent
                                                                     which gesture they simultaneously observed: with the
this is related with the cortical activation in areas associated
                                                                     corresponding gestures there was higher IFC activation,
with the hMNS. Regarding learning outcomes, our results
                                                                     whereas with the non-corresponding gestures there was
indicate that the observation of gestures has different effects
                                                                     higher IPC activation. This can be brought in line with our
for high- and low-visuospatial-ability learners, particularly
                                                                     previous findings (Brucker et al., 2015), in which we also
when dealing with non-corresponding gestures. For high-
                                                                     found evidence that the IFC plays a role during watching
visuospatial-ability learners, non-corresponding gestures
                                                                     corresponding gestures, whereas the IPC comes into the
improved learning (even beyond corresponding gestures),
                                                                     picture when (conflicting) non-corresponding gestures have
whereas for low-visuospatial-ability learners the observation
                                                                     to be processed. The IPC is associated with processes of
of non-corresponding gestures had detrimental effects on
                                                                     motion analysis and motor imagery, which may both be
learning. These findings are largely in line with those
                                                                     helpful in the context of identifying the mismatch between
reported by Brucker et al. (2015) and indicate that
                                                                     the to-be-learned movements and the non-corresponding
particularly when high-visuospatial-ability learners are
                                                                     gestures. However, future research is needed to explore
challenged by a desirable difficulty (cf. Schüler, 2017), in
                                                                     these processes in more detail. Future research should also
this case by creating a conflict between the visualized fish
                                                                     address one limitation of this study – namely the lack of
movements and the (mismatching) gestures, they are
                                                                     insight into learners’ strategies – by replicating it with
stimulated to put more effort in reducing the conflict and
                                                                     think-aloud protocols so that it is possible to discover the
come up with a strategy to more elaborately process the
                                                                     strategies learners use when observing and making (non-
relevant movements. This in turn increases the chance that
                                                                 172

corresponding) gestures in learning from dynamic                    Hegarty, M. (1992). Mental animation: Inferring motion
visualizations. Furthermore, it is important to further               from static diagrams of mechanical systems. Journal of
identify potential neural correlates of (gesture-supported)           Experimental Psychology: Learning, Memory and
learning with dynamic visualizations and to further unravel           Cognition, 18, 1084-1102.
the relations between activation in different parts of the          Hegarty, M., & Waller, D. (2005). Individual differences in
brain and learning outcomes. The present study provides a             spatial ability. In P. Shah, & A. Miyake (Eds.), Handbook
starting point from which future research endeavors within            of Visuospatial Thinking. Cambridge University Press.
this emerging field of research can be explored with the goal       Höffler, T.N. (2010). Spatial ability: Its influence on
to incorporate (observing and making) gestures in a way that          learning with visualizations—a meta-analytic review.
learning about non-human movements from dynamic                       Educational Psychological Review, 22, 245-269.
visualizations is enhanced. In conclusion, this study shows         Höffler, T.N., & Leutner, D. (2007). Instructional animation
that observing additional gestures is helpful for learning            versus static pictures: A meta-analysis. Learning and
about movements, but learners need different types of                 Instruction, 17, 722-738.
gestures depending on their amount of visuospatial ability.         Jasper, H. H. (1958). The ten-twenty electrode system of the
Thus, different types of gestures should be applied: High-            International Federation. Electroencephalography and
visuospatial-ability learners should be challenged with non-          Clinical Neurophysiology, 10, 370-375.
corresponding gestures, whereas low-visuospatial-ability            Marcus, N., Cleary, B., Wong, A., & Ayres, P. (2013).
learners might be supported with corresponding gestures.              Should hand actions be observed when learning hand
                                                                      motor skills from instructional animations? Computers in
                         References                                   Human Behavior, 29, 2172-2178.
Ayres, P., Marcus, N., Chan, C., & Qian, N. (2009).                 Mayer, R. E., Hegarty, M., Mayer, S., & Campbell, J.
   Learning hand manipulative tasks: When instructional               (2005). When static media promote active learning:
   animations      are   superior    to   equivalent     static       Annotated illustrations versus narrated animations in
   representations. Computers in Human Behavior, 25, 348-             multimedia instruction. Journal of Experimental
   353.                                                               Psychology: Applied, 11, 256–265.
Brucker, B., Ehlis, A.-C., Häußinger, F.B., Fallgatter, A.J.,       Montgomery, K.J., Isenberg, N., & Haxby, J.V. (2007).
   & Gerjets, P. (2015). Watching corresponding gestures              Communicative hand gestures and object-directed hand
   facilitates learning with animations by activating human           movements activated the mirror neuron system. Social
   mirror-neurons: An fNIRS study. Learning and                       Cognitive and Affective Neuroscience, 2, 114–122.
   Instruction, 36, 27-37.                                          Obrig, H., & Villringer, A. (2003). Beyond the visible –
Castro-Alonso, J.C., Ayres, P., & Paas, F. (2016).                    Imaging the human brain with light. Journal of Cerebral
   Comparing apples and oranges? A critical look at research          Blood Flow & Metabolism, 23, 1-18.
   on learning from statics versus animations. Computers &          Paas, F., & Sweller, J. (2012). An evolutionary upgrade of
   Education, 102, 234-243.                                           cognitive load theory: Using the human motor system and
Chu, M., & Kita, S. (2011).The Nature of Gestures’                    collaboration to support the learning of complex cognitive
   Beneficial Role in Spatial Problem Solving. Journal of             tasks. Educational Psychology Review, 24, 27-45.
   Experimental Psychology: General, 140, 102-116.                  Post, L.S., van Gog, T., Paas, F., & Zwaan, R. A. (2013).
Cook, S.M., & Goldin-Meadow, S. (2006). The role of                   Effects of simultaneously observing and making gestures
   gesture in learning: Do children use their hands to change         while studying grammar animations on cognitive load and
   their minds? Journal of Cognition and Development, 7,              learning. Computers in Human Behavior, 29, 1450-1455.
   211 - 232.                                                       Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron
De Koning, B.B., & Tabbers, H.K. (2011). Facilitating                 system. Annual Review of Neuroscience, 27, 169–192.
   understanding of movements in dynamic visualizations:            Schüler, A. (2017). Investigating gaze behavior during
   An embodied perspective. Educational Psychology                    processing of inconsistent text-picture information:
   Review, 23, 501-521.                                               Evidence for text-picture integration. Learning and
De Koning, B.B., & Tabbers, H.K. (2013). Gestures in                  Instruction, 49, 218-231.
   instructional animations: a helping hand to understanding        Skulmowski, A., Bunge, A., Kaspar, K., & Pipa, G. (2014).
   non-human movements? Applied Cognitive Psychology,                 Forced-choice decision-making in modified trolley
   27, 683-689.                                                       dilemma situations: a virtual reality and eye tracking
Ekstrom, R., French, J., Harman, H., & Dermen, D. (1976).             study. Frontiers in Behavioral Neuroscience, 8, 426.
   Manual for Kit of Factor-Referenced Cognitive Tests.             Van Gog, T., Paas, F., Marcus, N., Ayres, P., & Sweller, J.
   Princeton: Educational Testing Service.                            (2009). The mirror-neuron system and observational
Fogassi, L., & Ferrari, P.F. (2011). Mirror systems. Wiley            learning: Implications for the effectiveness of dynamic
   Interdisciplinary Reviews: Cognitive Science, 2, 22-38.            visualizations. Educational Psychology Review, 21, 21-
Goldin-Meadow, S., Nusbaum, H., Kelly, S.D., & Wagner,                30.
   S. (2001). Explaining math: gesturing lightens the load.
   Psychological Science, 12, 516–22.
                                                                173

