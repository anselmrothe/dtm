Influence of using 3D images and 3D-printed objects on spatial reasoning of
experts and novices
Akihiro Maehigashi (mhigashi@cog.human.nagoya-u.ac.jp)
Kazuhisa Miwa (miwa@is.nagoya-u.ac.jp)
Masahiro Oda (moda@mori.m.is.nagoya-u.ac.jp)
Graduate School of Informatics, Nagoya University, Japan

Yoshihiko Nakamura (ynakamura@jo.tomakomai-ct.ac.jp)
Department of Computer Science and Engineering, National Institute of Technology, Tomakomai College, Japan

Kensaku Mori (kensaku@is.nagoya-u.ac.jp)
Information and Communications, Nagoya University, Japan

Tsuyoshi Igami (igami@med.nagoya-u.ac.jp)
Graduate School of Medicine, Nagoya University, Japan
two-dimensional (2D). They explained that using 3D images
is more effective because they integrate the multiple perspectives expressed by 2D images into a single viewpoint, provide supplementary depth cues, and display object features
that would be invisible in 2D images.

Abstract
This study focuses on the infuence of a three-dimensional (3D)
graphic image and a 3D-printed object on the spatial reasoning
of experts and novices in the medical field. The spatial reasoning task of this study required doctors specializing in digestive surgery to infer cross sections of a liver with a 3D image and a 3D-printed object in a situation where liver resection
surgery was simulated. The task performance was compared
with that of university students who conducted the same task in
Maehigashi et al. (2016). The results of the analysis indicated
that the doctors showed the same task performance when using
the 3D image and the 3D-printed object. However, the university students learned faster and inferred the inside of a liver
structure more accurately with the 3D-printed object than with
the 3D image, and they performed equally to the professional
doctors. Our results are then discussed in relation to previous
studies.
Keywords: Spatial reasoning; Spatial mental model; Expertise; External representation; 3D printer

Recently, the prevalence of 3D printers has made it possible for people to replicate objects. 3D printers offer an unprecedented means to express information and are being used
in various fields such as education, industrial manufacturing,
and medicine. However, very few studies have investigated
the influence of 3D-printed objects on spatial reasoning.

Introduction
Spatial reasoning and 3D-printed object
Spatial reasoning refers to the inference of an object’s shape
and structure and the physical relationship between objects
by using spatial information (Byrne & Johnson-Laird, 1989).
Spatial reasoning is ubiquitous in daily activities such as planning routes, inferring a road’s slope angle, or even arranging
furniture in a room.
When people engage in spatial reasoning, they form spatial mental models in their minds. Spatial mental models
are internal representations of the spatial relations among elements, and it is considered that they allow people to do perspective taking, reorientation and spatial inferences (Tversky,
1993). Spatial mental models are strongly influenced by the
types of external resources that are referred to for its formation. Tversky (1991) experimentally showed that route
searches were more accurate when the route information
was displayed on a map rather than text. Moreover, John,
Cowen, Smallman, and Oonk (2001) indicated that the understanding of a geometric structure was more accurate with
a three-dimensional (3D) graphic image rather than with a

Some studies experimentally investigated human understanding of molecular structures using concrete models
(Barrett, Stull, Hsu, & Hegarty, 2015; Stull, Barrett, &
Hegarty, 2013). The results of these experiments demonstrated no difference in task accuracy between the use of 3D
images and concrete models. However, in their experiments,
task accuracy rate was very high. Therefore, further investigations that consider situations requiring people to understand more complex structures with physical object models
are necessary.
Maehigashi et al. (2016) experimentally investigated spatial reasoning of human organ structure using 3D-printed organs. As a result, they found that the understanding of a
human organ’s structure was more rapid and accurate when
examined with a 3D-printed object rather than with a 3D
graphic image. Their study indicated the possibility that using 3D-printed objects might reduce both the cognitive load
and the cost of information access in forming and manipulating spatial mental models. In addition, based on ethnographical research, Maehigashi et al. (2015) investigated the
influence of using a 3D-printed human liver on doctors in real
liver resection surgeries. Their results showed that using such
objects enhanced the formation of elaborate spatial mental
models of a patient’s liver. It also enhanced the mental simulation of liver resections and the formation of shared spatial
mental models of a patient’s liver among doctors.

2669

Expertise

Materials

Experts in various fields use chunking strategy for encoding, storing, and manipulating spatial information. Chase
and Simon (1973) showed that chess masters could encode
and store multiple positions of chess pieces in a game situation in a single chunk. Also, Busey, Yu, Wyatte, and
Vanderkolk (2013) compared the eye movements of experts
with those of novices in fingerprint matching. Their results
indicated that experts were able to match wider regions of
two fingerprints in a single instance than novices, and they
could encode and store the various characteristics of fingerprint structures as a single unit. Moreover, an experiment
by Hegarty, Keehner, Khooshabeh, and Montello (2009) revealed that fourth year dentistry students inferred the anatomical structure of teeth more accurately than first year students
and could encode, store, and manipulate the various characteristics of teeth structures as a single chunk.
Hegarty et al. (2009) proposed that the fourth year dentistry
students developed spatial mental models of teeth based on
their anatomical knowledge of teeth and their experiences of
learning operative skills for dentistry, and such mental models
would facilitate chunking strategy. Some studies have shown
the similar concepts. For example, Woods (1999) stated that
radiologists have developed organized mental matrixes which
integrate radiological characteristics, and therefore, they are
highly adept in visual management and able to synthesize the
characteristics of diseases. Also, Gobet and Simon (1998)
demonstrated how chess masters developed mental templates
of chess positions based on their prior experiences, enabling
them to encode large and multiple quantities of information.
Related to such discussions, some studies have investigated the relationship between an expert’s spatial abilities
and spatial reasoning. Spatial ability is the capability to
mentally store and manipulate spatial representations accurately (Hegarty & Waller, 2005). An experiment by Hegarty
et al. (2009) demonstrated that the spatial abilities of experts influence their performance of spatial reasoning. Conversely, Ackerman (1988) investigated the relationship between expertise and various cognitive abilities and indicated
that the development of domain specific knowledge actually
decreases the influence of spatial ability on task performance.
The purpose of this study was to investigate the influences
of the use of 3D images and 3D-printed objects on the spatial
reasoning of both experts and novices. The relationship between the spatial abilities of experts and their performances
in spatial reasoning was also examined.

The materials in this study were exactly the same as those
used by Maehigashi et al. (2016). Two desks, a primary and
a secondary desk, were used in the experiment. The primary
desk was set in front of a participant, and the secondary desk
was set by the right side of the participant. The primary and
secondary desks represented an operating table and tool stand
as used in a surgical setting. Three boxes were placed on the
primary desk. Each box contained a 3D-printed object of a
liver (target) which represented a patient’s liver and an answer sheet. Placed on the secondary desk was either a computer displaying a liver’s 3D image or a box containing a 3Dprinted object that displayed the inside structure of a liver.
Figure 1 shows a 3D image, a 3D-printed object, and a target.

Experimental task
In this study, we used a spatial reasoning task in a situation
where actual liver resection surgery was simulated. The participants inferred the positions of a tumor within a liver and
also the veins on cross sections of a liver by referring to its internal structure as displayed in a 3D image and a 3D-printed
object.

Figure 1: (a) 3D image, (b) 3D-printed object, and (c) target
The 3D image was created by using Pluto, a computeraided diagnosis system developed at Nagoya University’s
Graduate School of Information Science. It was created based
on data from a patient’s liver measured by computed tomography (CT) (Figure 1a). In the 3D image, the thickest vein,
an inferior vena cava (IVC), and five veins branching from
the IVC were represented in blue. A tumor was represented
in white. The participants could rotate and zoom in and out
of the image by using a mouse.
The 3D-printed object and the three targets were created
by using a 3D printer with the same CT liver data as the
3D image (Figure 1b, 1c). The 3D-printed object shows a
liver’s inside structure. In contrast, the target’s surface was
colored light gray, and the liver’s inside structure was invisible just as a patient’s liver would be in real-life surgery. A
line was drawn around each of the three targets. Each line
was sketched in a different location. Also, on each target the
letters “A” and “B” were written to indicate the two separated
areas based on the drawn line. Two sets of 3D images, 3Dprinted objects, and three targets were created from different
CT liver datum.

Vein and tumor location tests
The tests used in this study were exactly the same as those
used by Maehigashi et al. (2016). The experiment employed
a spatial reasoning task. Participants were required to take a
vein and tumor location test for each target while referring to
either the 3D image or the 3D-printed object. In the vein location test, participants were required to indicate the location
of the veins that appeared on the cross section by cutting the
target along the drawn line. Specifically, participants were
required to mark “O” for the IVC and “X” for the branching

2670

vein on the cross section’s outer contour printed on the answer sheet (Figure 2). In the tumor location test, participants
were asked to identify the area of the liver, either A or B,
where the tumor had occurred.

Figure 2: Vein location test. (a) Contour of cross section of
liver, (b) cross section of liver, and (c) participant’s answer.
(a) shows the outer contour of a liver’s cross section printed
on the answer sheet. (b) shows an actual cross section of a
liver. (c) shows a participant’s answer, which provides the
number of IVCs, Os, and the branching veins, Xs, (drawn
correctly here).

Experiment
Method
Participants and Factorial design Twenty-two doctors
specializing in digestive surgery participated in this experiment. Their work experience ranged from eight to 22 years
(M = 10.57). The experiment had a single-factor within participants design. The factor was the external representation
(image and object).
Procedure The experimental procedure was generally the
same as those of Maehigashi et al. (2016). First, the participants took a spatial ability test produced by Guay and
McDaniels (1976). It comprised 24 questions that required
mental rotations. The participants were required to answer as
many questions as possible within three minutes. Next, all
of the participants performed practice and experimental tasks
with the 3D image in the image condition and the 3D-printed
object in the object condition. In the practice task, the 3D image or the 3D-printed object, which represented one IVC and
three branching veins, were used. First, the participants observed and learned about the inside structure using either the
3D image or the 3D-printed object for one to three minutes.
Following on, they took the vein and tumor location tests for
one target, referring to the image or the object.
After the practice, all participants conducted the experimental task. During the learning period, participants observed the inner liver structure for three to five minutes using either the 3D image or the 3D-printed object. When the
participants deemed themselves ready after three minutes had
passed, or when five minutes passed, the tests began. Participants took out the target and answer sheet from one of the
three boxes on the primary desk and attempted to complete
the vein and tumor location tests. During the task, participants were allowed to refer to either the 3D image or the
3D-printed object freely.

After the participants completed the tests for one target,
they returned it together with the answer sheet back into the
box and took a different set from another box. The task was
completed when they had finished the tests for all three targets. After the experimental task was completed in one condition, the participants took a five-minute break and performed
the practice and experimental tasks in the other condition.
For the image and object conditions, the 3D image and
the 3D-printed object created by the different CT liver datum
were used. The order of the task conditions and the combinations of CT liver datum were counterbalanced between
the participants. Three sets of targets and answer sheets were
randomly placed inside the boxes on the primary desk. Participants were instructed to perform the tasks as accurately
as possible. Furthermore, removing the target from the primary desk was forbidden during the experiment, as it would
be impossible for doctors to remove a patients liver from the
operating table in a real-life surgical operation. However, removing the 3D-printed object from the secondary desk was
permitted because in a surgical operation, doctors can place
a 3D-printed liver right beside a patient’s liver to confirm its
interior structure (Maehigashi et al., 2015).

Results
The participants of this study were doctors with anatomical
and medical knowledge as well as first hand medical experience. Therefore, the data of this study was treated as an
expert’s performance data. We compared our data to that
of Maehigashi et al. (2016) which examined the exact same
tasks under the same conditions on 48 university students who
did not possess any anatomical and medical knowledge.
We conducted 2(Expertise: expert and novice) × 2(External representation: image and object) analysis of variance (ANOVA) on the dependent variables. Since the external representation factor (image and object) was a betweenparticipants factor in the study by Maehigashi et al. (2016),
we conducted a two-way between participants ANOVA in our
analyses.
First, the learning time was the mean time taken by the participants to observe the inner structure of either the 3D image
or the 3D-printed object before attempting the tests in each
condition (Figure 3). The results of the analysis showed a significant interaction (F(1, 88) = 4.75, p < .05). The analysis
of the simple main effect showed that in the image condition,
the learning time was significantly shorter for the expert condition than for the novice condition (F(1, 88) = 14.84, p <
.001). However, in the object condition, there was no significant simple main effect on the expertise factor (F(1, 88) =
0.60, p = .44). Also, in the novice condition, the learning
time was significantly shorter for the object condition than
for the image condition (F(1, 88) = 15.70, p < .001). However, in the expert condition, there was no significant simple
main effect on the external representation factor (F(1, 88) =
0.78, p = .38). In addition, there were significant main effects
on both the expertise factor (F(1, 88) = 10.67, p < .01) and
the external resource factor (F(1, 88) = 11.74, p < .001).

2671

Learning time (sec)!

300

Expert
Novice

250
200
150
100
50
0
Image

Object

Figure 3: Learning time. The error bars indicate the standard
error.

was a significant interaction (F(1, 88) = 5.23, p < .05). The
results of the simple main effect analysis showed that in the
image condition, there was a significant simple main effect
on the expertise factor; in other words, participants in the
expert condition drew the number of veins more accurately
than those in the novice condition (F(1, 88) = 25.45, p <
.001). However, in the object condition, there was no significant simple main effect of the expertise factor (F(1, 88) =
3.28, p = .07). Also, in the novice condition, there was
a significant simple main effect on the external representation factor, highlighting that more veins were accurately
drawn in the object condition than in the image condition
(F(1, 88) = 9.80, p < .01). However, in the expert condition,
there was no significant simple main effect on the external
representation factor (F(1, 88) = 0.01, p = .92). In addition,
there were significant main effects in both the expertise factor
(F(1, 88) = 23.50, p < .001) and the external resource factor
(F(1, 88) = 4.58.p < .05).

Task completion time (sec) !

250

Absolute difference value!

Following on, the task completion time was calculated as
the mean time from when the first target was pulled out until the third target was returned to the box in each condition
(Figure 4). The results of the analysis showed no significant
interaction (F(1, 88) = 0.10, p = .76). There was, however,
a significant main effect on the expertise factor as the task
completion time was shorter for the novice condition than for
the expert condition (F(1, 88) = 21.84, p < .001). Also, there
was no significant main effect on the external resource factor
(F(1, 88) = 2.08, p = .15).
Expert

1.5

1.5

Novice
1

1

0.5

0.5

0

0

Image

Novice

Object
IVC

200

Expert

Image

Object

Branching veins

Figure 5: Absolute difference value. The error bars indicate
the standard error.

150
100
50
0
Image

Object

Figure 4: Task completion time. The error bars indicate the
standard error.
In the vein location test score, we calculated the mean absolute difference value between the correct number of veins
in the stimuli and the number of veins drawn on the answer
sheet for the IVC and the branching veins in each condition
(Figure 5). If the score is closer to zero, the number of drawn
veins is more accurate.
For the IVC, all participants in the expertise condition correctly drew the veins, making the mean absolute difference
value zero. On the other hand, for the branching veins, there

In each tumor location test, a score of one was assigned
if the tumor location was correctly answered. The tumor
location test score was the mean total of the test results
for the three targets in each condition (Figure 6). In other
words, the higher the score, the more accurate is the answer. The results showed a significant interaction (F(1, 88) =
4.64, p < .05). The analysis of the simple main effect indicated that in the image condition, the score was significantly higher for the expert condition than for the novice
condition (F(1, 88) = 5.96, p < .05). However, in the object condition, there was no significant simple main effect
on the expertise factor (F(1, 88) = 0.37, p = .55). Also, in
the novice condition, the score was significantly higher for
the object condition than for the image condition (F(1, 88) =
24.27, p < .001). However, in the expert condition, there was
no significant simple main effect on the external representation factor (F(1, 88) = 3.54, p = .06). Additionally, there
was a significant main effect on the external resource factor
(F(1, 88) = 4.64, p < .05), but no significant main effect on

2672

the expertise factor (F(1, 88) = 1.69, p = .20).

Tumor location test score!

Expert
Novice

3

2

1

0
Image

Object

Figure 6: Tumor location test score. The error bars indicate
the standard error.
Furthermore, correlation analyses were conducted on the
relationship between the spatial ability test scores of the experts and their task performance, learning time, task completion time, absolute difference value for branching veins, and
tumor location test score, in the image and object conditions.
However, there was no significant correlation.
Finally, a t-test was conducted on the test scores for spatial
ability in both the expert and novice conditions. The score
was higher in the expert condition (M = 10.86) than in the
novice condition (M = 8.48) (t(68) = 2.20, p < .05). These
results did not confirm the homogeneity of the spatial abilities
between the experts and the novices. However, the results of
the correlation analyses indicated that the experts did not use
the advantage of their spatial ability to conduct the task.

Discussion
Accuracy of spatial reasoning
The results of the vein and tumor location tests revealed that
the university students inferred a liver’s inner structure more
accurately with the 3D-printed object than with the 3D image
and performed it to a standard equal to that of the professional
doctors.
The university students formed spatial mental models of
livers probably for the first time. Since the real world offers
more depth cues than the virtual 3D environment (Kemeny
& Panerai, 2003), using the 3D image might require more
cognitive load in order to form spatial mental models than using the 3D-printed object. The university students who used
the 3D image apparently needed to mentally complement or
modify spatial information, temporarily storing such information in their memory and mentally resizing it in order to
map the information to the target. However, the students with
the 3D-printed object were assumedly able to store the spatial
information temporarily in their memory as they perceived it

and mapped the information from the 3D-printed object directly to the target without having to internally modify or resize it. Therefore, the university students with the 3D-printed
object were assumed to have a smaller cognitive load, and,
consequently, make fewer errors from the internal manipulation of spatial information and, therefore, able to show test
performances equal to that of doctors.
It is also possible that the university students with the 3Dprinted object experienced lower information accessing costs
than those who used the 3D image. Information accessing
cost is incurred when acquiring information (Gray, Sims, Fu,
& Schoelles, 2006). Participants with the 3D image had to
manipulate a computer mouse in order to acquire the required
information. However, participants with the 3D-printed object had only to pick up and physically rotate a 3D-printed
object. Thus, accessing information with a 3D-printed object
was considered easier and less prone to errors or omissions
than working with a 3D image.
However, the doctors showed the same task performance
when using the 3D image and the 3D-printed object. It is
inferred that the experts obtain spatial mental models developed by their prior knowledge and experiences (Hegarty et
al., 2009). The doctors who participated in this study might
be in possession of developed rigid spatial mental models of
livers, and they were therefore able to modify their mental
models based on the information displayed on both the 3D
image and the 3D-printed object respectively. As a result,
even though the 3D image is not as in-depth as the 3D-printed
object, the doctors could still manage to create an equally accurate spatial mental model for the tests by depending on their
already developed spatial mental models.

Learning and task completion time
Analysis of the learning time revealed that the doctors showed
the same task performance when using the 3D image and the
3D-printed object. However, the university students with the
3D-printed object finished their period of learning quicker
than those with the 3D image and performed equally to the
doctors.
As explained above, by using the 3D-printed objects, the
university students were assumed to be able to reduce their
cognitive load and information accessing cost. Therefore,
they might be able to facilitate the formation of spatial mental models and perform equally to the doctors. Also as written
above, the doctors were considered to have developed mental models. By modifying these mental models accordingly,
they might be able to form spatial mental models with the 3D
image as quickly as when they used the 3D-printed objects.
The results of the task completion time indicated that the
university students performed the task faster than the doctors
either with the 3D image or with the 3D-printed object. Some
previous studies also experimentally showed that experts took
a longer time to complete tasks than novices (Busey et al.,
2013; Krupinski, 1996). One possibility is that since experts could access the related information by recalling and
utilizing their existing knowledge, this process might cause

2673

a longer task completion time. Previous studies showed that
chess masters focused their eyes on the empty spaces more
than novices when pieces on the board were being memorized
(Charness, Reingold, Pomplun, & Stampe, 2001; Reingold,
Charness, Pomplun, & Stampe, 2001). The chess masters
were thought to be processing the related information stored
in their long term memory. Another possibility is that experts
could be more careful than novices. Previous studies showed
that fingerprint experts were more skeptical than novices, and
it therefore took them longer to match fingerprints (Busey et
al., 2013).

Experts’ spatial ability and spatial reasoning
performance
When the university students used the 3D image, there was
a significant relationship between their spatial abilities and
spatial reasoning performance (Maehigashi et al., 2016). In
particular, high ability students demonstrated longer learning times and a more accurate inference to the positions of
branching veins. On the other hand, in this study, whenever
the doctors used the 3D image or the 3D-printed object, there
was no relationship between their spatial abilities and spatial
reasoning performance.
These results are different to that of Hegarty et al. (2009).
The main difference between the previous study and this
study can be related to the participants’ degrees of expertise.
The experts in Hegarty et al. (2009) were fourth year dentistry
students. In contrast, the experts in this study were doctors
with many years of work experience, and they therefore had
many more years of expertise in the specialized field than the
experts in Hegarty et al. (2009). Therefore, in this study, the
spatial ability of experts did not influence spatial reasoning
performance as indicated in Ackerman (1988).

Acknowledgements
This work was supported by JSPS KAKENHI Grant Number
JP15H01614.

References
Ackerman, P. L. (1988). Determinants of individual differences during skill acquisition: Cognitive abilities and information processing. Journal of Experimental Psychology:
General, 117, 288-318.
Barrett, T. J., Stull, A. T., Hsu, T. M., & Hegarty, M. (2015).
Constrained interactivity for relating multiple representations in science: When virtual is better than real. Computers and Education, 81, 69–81.
Busey, T., Yu, C., Wyatte, D., & Vanderkolk, J. (2013).
Temporal sequences quantify the contributions of individual fixations in complex perceptual matching tasks. Cognitive Science, 37, 731–756.
Byrne, R. M. J., & Johnson-Laird, P. N. (1989). Spatial
reasoning. Journal of Memory and Language, 28, 564-575.
Charness, N., Reingold, E. M., Pomplun, M., & Stampe,
D. M. (2001). The perceptual aspect of skilled perfor-

mance in chess: Evidence from eye movements. Memory
and Cognition, 29, 1146-1152.
Chase, W., & Simon, H. A. (1973). Perception in chess.
Cognitive Science, 4, 55-81.
Gobet, F., & Simon, H. A. (1998). Expert chess memory:
Revisiting the chunking hypothesis. Memory, 6, 225–255.
Gray, W. D., Sims, C. R., Fu, W.-T., & Schoelles, M. J.
(2006). The soft constraints hypothesis: A rational analysis approach to resource allocation for interactive behavior.
Psychological Review, 113, 461–482.
Guay, R., & McDaniels, E. (1976). The visualization of viewpoints. West Lafayette: The Purdue Research Foundation.
Hegarty, M., Keehner, M., Khooshabeh, P., & Montello, D. R.
(2009). How spatial abilities enhance, and are enhanced by,
dental education. Learning and Individual Differences, 19,
61-70.
Hegarty, M., & Waller, D. (2005). Individual differences
in spatial abilities. In P. Shah & A. Miyake (Eds.), The
cambridge handbook of visuospatial thinking (p. 121-169).
New York: Cambridge University Press.
John, M. S., Cowen, M. B., Smallman, H. S., & Oonk,
K. M. (2001). The use of 2d and 3d displays for shapeunderstanding versus relative-position tasks. Human Factors, 43, 79-98.
Kemeny, A., & Panerai, F. (2003). Evaluating perception in
driving simulation experiments. Trends in Cognitive Sciences, 7, 31–37.
Krupinski, E. A. (1996). Visual scanning patterns of radiologists searching mammograms. Academic Radiology, 3,
137–144.
Maehigashi, A., Miwa, K., Oda, K., Nakamura, Y., Mori, K.,
& Igami, T. (2016). Influence of 3d images and 3d-printed
objects on spatial reasoning. Proceedings of the 38th Annual Meeting of the Cognitive Science Society, 414-419.
Maehigashi, A., Miwa, K., Terai, H., Igami, T., Nakamura, Y.,
& Mori, K. (2015). Investigation on using 3d printed liver
during surgery. Proceedings of the 37th Annual Meeting of
the Cognitive Science Society, 1476-1481.
Reingold, E. M., Charness, N., Pomplun, M., & Stampe,
D. M. (2001). Visual span in expert chess players: Evidence from eye movements. Psychological Science, 12,
48–55.
Stull, A. T., Barrett, T., & Hegarty, M. (2013). Usability of
concrete and virtual models in chemistry instruction. Computers in Human Behavior, 29, 2546–2556.
Tversky, B. (1991). Spatial mental models. In G. H. Bower
(Ed.), The psychology of learning and motivation: Advances in research and theory (p. 109-145). New York:
Academic Press.
Tversky, B. (1993). Cognitive maps, cognitive collages,
and spatial mental models. In A. U. Frank & I. Campari
(Eds.), Spatial information theory: A theoretical basis for
gis (p. 14-24). Berlin: Springer-Verlag.
Woods, B. P. (1999). Visual expertise. Radiology, 211, 1-3.

2674

