                 “I won’t lie, it wasn’t amazing”: Modeling polite indirect speech
                   Erica J. Yoon, Michael Henry Tessler, Noah D. Goodman and Michael C. Frank
                                         {ejyoon, mtessler, ngoodman, mcfrank} @stanford.edu
                                             Department of Psychology, Stanford University
                              Abstract                                   & Frank, 2016). A speaker with a high weight on social util-
   Why are we polite when we talk to one another? One hypoth-            ity will try to save her listener’s face: She hides or risks losing
   esis is that people expect others to choose what to say based         information in her intended message by making her utterance
   on their goals both to transfer information efficiently (an epis-     false to some degree. On the other hand, a speaker with a
   temic goal) and to make the listener feel good (a social goal).
   In our previous work, we found that when these two goals con-         high weight on epistemic utility prioritizes truthfulness and
   flict, they sometimes produce white lies. In the current work,        informativity, and she may risk a loss of the listener’s (or the
   we expand on this theory to consider another prominent case of        speaker’s own) face. These ideas were formalized in a model
   polite speech: indirect remarks using negation (e.g., “It wasn’t
   amazing”). With minimal extensions from our previous frame-           of pragmatic language understanding, building on the Ratio-
   work, our formal model suggests that a pragmatic speaker will         nal Speech Act (RSA) theory (for a review, see Goodman &
   produce more indirect remarks when the speaker wants to be            Frank, 2016). We tested the polite RSA model (pRSA) by ex-
   informative and seem considerate at the same time. These
   predictions were borne out in a language production experi-           amining white lies. The model captured human participants’
   ment. These findings suggest that the conflict between social         inferences about a speaker’s goals given her utterance (e.g.,
   and epistemic goals can account for a broad range of politeness       saying a good talk was “amazing” implies that she is being
   phenomena.
                                                                         nice) and about the true state of the world given a speaker’s
   Keywords: Politeness; computational modeling; communica-
   tive goals; pragmatics                                                goal (e.g., saying “good” may mean the talk was only okay if
                                                                         the speaker wanted to be nice).
                          Introduction                                      In the current work, we extend our framework to another
Language users hear and produce polite speech on a daily                 polite speech act: indirect speech. White lies are produced
basis. Adults and even young children spontaneously pro-                 when a speaker tries to save the listener’s face by stretch-
duce requests in polite forms (Axia & Baroni, 1985; Clark                ing the truth. But instead of lying, people sometimes try to
& Schunk, 1980), and speakers use politeness strategies even             be polite by being more indirect. Through indirect speech,
while arguing, preventing unnecessary offense to their inter-            a speaker can express meaning that is different from the lit-
actants (Holtgraves, 1997). But being polite conflicts with              eral meaning of the utterance (Searle, 1975). In this work, we
one important goal of cooperative communication: exchang-                focus on negation (“not”), which has the potential to be in-
ing information efficiently and accurately (Grice, 1975). Peo-           direct. For instance, “Mark isn’t the cleanest person I know”
ple tell white lies (“Your new dress is gorgeous!”) and pro-             may suggest that the speaker thinks Mark is unclean (inferred
duce indirect speech that is longer and more nuanced than the            meaning) rather than not being the person who has the great-
simplest form of their intended message (“I don’t think that             est degree of cleanliness (literal meaning). Negation can be
dress looks phenomenal on you” as opposed to “It looks ter-              used as a hedging or mitigating device to address an undesir-
rible”) to make others feel good. Speakers risk potential loss           able state that is face-threatening to the addressee (Brown &
of their intended message (indirect speech), intentionally con-          Levinson, 1987; Grice, 1975).
vey wrong information (lies), and suffer inefficiencies – all in            What may lead a speaker to produce indirect remarks? An
the service of being polite. If information transfer were the            indirect remark may be motivated by the speaker’s goal to
only currency in communication, politeness would be both                 convey some face-threatening information, while being seen
infelicitous and undesirable.                                            as a polite person who avoids threatening others’ face. In our
   A cooperative speaker, however, can be imagined as one                previous work, we described a pragmatic listener that jointly
with both an epistemic goal to improve the listener’s knowl-             inferred the true state and the goals of the speaker. Build-
edge as well as a social goal to minimize potential damage to            ing on this model, we describe here a speaker whose goal is
the hearer’s (and the speaker’s own) self-image, called face             to lead this pragmatic listener to infer the true state and at-
(Brown & Levinson, 1987). If the speaker’s intended mean-                tribute to the speaker certain goals (e.g., face-saving). For
ing contains no threat to the speaker or listener’s face, then the       instance, “It wasn’t amazing” does not preclude the possibil-
speaker will choose to convey the meaning in an explicit and             ity that the presentation was bad, and may in fact be prag-
efficient manner (putting it “on the record”). As the degree             matically strengthened to mean that it was actually bad. Yet
of face-threat becomes more severe, however, a speaker will              because the speaker does not choose the more direct “It was
choose to be polite by producing more indirect utterances.               bad”, the listener will infer a face-saving goal. Thus saying
   Inspired by this set of ideas, we have argued that listeners          “It wasn’t amazing” can accomplish the goal of conveying
think about polite speech as reflecting a tradeoff between two           that the presentation was bad while the speaker is seen as not
goals: information transfer (which we called epistemic util-             wanting to make the listener feel bad. On the other hand, if
ity) and face-saving (social utility; Yoon, Tessler, Goodman,            the speaker does not care about being seen as face-saving,
                                                                     3602

she will produce less indirect speech. Further, if the presenta-            Extensions to pRSA
tion was actually good, or even decent, the speaker will pre-               We build on pRSA by adding negative utterances and mod-
fer to produce a directly positive remark (“It was good”) in                eling a more sophisticated speaker. First, we extend the ut-
either case. Thus we predict more indirect speech when the                  terance alternatives to include negation. Previously we con-
true state is bad, and an interaction with the speaker’s desire             sidered five possible utterances: {It was terrible, bad, okay,
to both be informative and be seen as wanting to save face.                 good, and amazing}, all direct assertions of specific states
In what follows, we derive our hypotheses using our formal                  (e.g., “It was amazing” would be true for the state of 5 but
model and present an empirical test of the hypotheses.                      untrue for the states of 1 or 2). Now the speaker may say, {It
                                                                            wasn’t terrible, bad, okay, good, and amazing}. These utter-
                   Computational Model                                      ances indirectly address the referent by negating certain state.
In the current work, we introduce a minimal extension to our                We assume that it is more costly to say utterances with nega-
previous RSA model (pRSA; Yoon et al., 2016) to allow for                   tion, which makes the utterance morphemically longer and
speaker production of indirect remarks using negation.                      is harder to process (Clark & Chase, 1972). In our full data
                                                                            analysis, we put a prior on this negation cost parameters and
Polite RSA                                                                  infer its likely values from the data.
RSA models assume speakers choose utterances approx-                           Most importantly, we extended the recursive reasoning in
imately optimally given a utility function (Goodman &                       the model. For our experiment, we consider the pragmatic
Stuhlmuller, 2013). pRSA posited that the speaker’s utility                 speaker (S2 ) who chooses an utterance based on the pragmatic
function can be decomposed into two components. First,                      listener model (Eq. 1), thinking about the state as well as goal
epistemic utility (Uepi ) refers to the standard, informative               weights that the pragmatic listener will infer.
utility in RSA: the amount of information a literal listener                                    ˆ ∝ exp(λ2 · ln(PL (s, βˆ | w)) −C(w))
(L0 ) would still not know about world state s after hearing                        PS2 (w | s, β)                1
a speaker’s utterance w. Second, social utility (Usoc ) is the              This crucially captures the idea that the speaker both wants
expected subjective utility of the state inferred given the ut-             to convey the state s, and to be seen as someone with goals
terance w. The expected subjective utility is related to the                ˆ We simplify from the Yoon et al. (2016) model by in-
                                                                            β.
intrinsic value of the state, and we use a value function (V )              cluding only a single mixture parameter φ governing the ex-
to map states to subjective utility values. This captures the               tent to which the speaker is being informative vs. face saving:
affective consequences for the listener of being in state s. Fi-            βepi = φ, βsoc = 1 − φ.
nally, some utterances might be costlier than others. The util-                We implemented this model using the probabilistic pro-
ity of an utterance subtracts the cost c(w) from the weighted               gramming language WebPPL (Goodman & Stuhlmuller,
combination of the social and epistemic utilities.                          2014)1 . In the next section, we explore the model’s predic-
         ˆ = βepi · ln(PL (s | w)) + βsoc · EP                              tions for speaker productions of indirect speech with negation
U(w; s; β)                  0                   L 0
                                                    (s|w) [V (s)] −C(w)     vs. direct speech with no negation.
The speaker (S1 ) in pRSA chooses utterances w softmax-                                            Model predictions
optimally given the state s and his goal weights β.         ˆ The prag-
                                                                            Before describing our experimental data, we derive predic-
matic listener (L1 ) jointly infers the state s and the utility             tions from the pRSA model. In these initial simulations, we
weights of the speaker, βepi and βsoc (Goodman & Lassiter,                  use fixed goal weights and parameters – in later fits, we will
2015; Kao, Wu, Bergen, & Goodman, 2014).                                    derive these parameters from the data using Bayesian data
                                                                            analysis. Since the model requires measurements of literal
                                                                            semantics (e.g., what “not good” means on a given dimen-
            PL1 (s, βˆ | w) ∝ PS1 (w | s, β)
                                          ˆ · P(s) · P(β)  ˆ         (1)
                                                                            sion), we first describe these measurements and then give
             PS (w | s, β)ˆ ∝ exp(λ1 · E[U(w; s; β)]) ˆ              (2)    model predictions using them.
               1
               PL0 (s | w) ∝ [[w]](s) · P(s)                         (3)    Semantic measurement
   Within our experimental domain, we assumed there were                    We probed judgments of literal meanings of the target words
five possible states of the world corresponding to the value                assumed by our model and used in all our experiments.
placed on a particular referent (e.g., rating deserved by the               Materials, methods, and results 25 participants with IP
presentation the speaker is commenting on, akin to a Yelp rat-              addresses in the United States were recruited on Amazon’s
ing): S = {s1 , ..., s5 }. We assume a uniform prior distribution           Mechanical Turk. We used 13 different context items that
over possible states of the world. The states have subjective               were previously used in Yoon et al. (2016), in which someone
numerical values V (si ) = α · i, where α is a free parameter.
                                                                                1A  complete implementation of the model, raw data and anal-
[[w]](s) corresponds to the lexical meaning of the utterance w
                                                                            yses, and links to the experiments and pre-registration of hypothe-
(e.g., “good”) when applied to state s. We gather independent               ses and method can be found at https://github.com/ejyoon/
ratings for these literal meanings.                                         cogsci2017.
                                                                        3603

                                         terrible                   bad                   okay                       good               amazing
                          1.00
            proportion    0.75
                                                                                                                                                        it was ~
                          0.50
            acceptances   0.25                                                                                                                          it wasn't ~
                          0.00
                                 1   2      3       4   5   1   2    3    4   5   1   2    3     4    5   1      2    3     4   5   1   2   3   4   5
                                                                                  state (1=worst)
Figure 1: Semantic measurement results. Proportion of acceptances of utterance types (colors) combined with target words
(facets) given the true state represented on a scale of hearts. Error bars represent 95% confidence intervals.
Figure 2: Schematic model predictions (left), experimental results (center) and fitted model predictions (right) for average
proportion of negation produced among all utterances, given true states (x-axis) and goals (colors).
evaluated a performance of some kind. For example, in one                                            Model parameters and predictions
of the contexts, Ann saw a presentation, and Ann’s feelings                                          The S2 speaker in our model has the goal to convey the state
toward the presentation (true state) were shown on a scale out                                       and to be seen as having a particular set of goals. We ex-
of five hearts (e.g., two out of five hearts filled in red color).                                   plore predictions for 3 hypothetical speakers, corresponding
The question of interest was “Do you think Ann thought the                                           to 3 different φ mixture parameter weights: (a) an informative
presentation was / wasn’t X?” and participants responded by                                          speaker who wants to convey high epistemic utility (prioritiz-
choosing either “no” or “yes.” The target could be one of five                                       ing information transfer; φ = 0.9) (b) a social speaker who
possible words: terrible, bad, okay, good, and amazing, giv-                                         wants to convey high social utility (making the listener feel
ing rise to ten different possible utterances (with negation or                                      good; φ = 0.1) (c) a both-goal speaker who wants to convey
no negation). Each participant read 50 scenarios, depicting                                          a balance between the two utilities (φ = 0.5).2
every possible combination of states and utterances. The or-
                                                                                                        Figure 2 (left) shows the speaker’s production probabilities
der of context items was randomized, and there were a max-
                                                                                                     associated with producing an indirect speech act (i.e., an ut-
imum of four repeats of each context item per participant.
                                                                                                     terance with negation) for the three different speakers as the
For this and subsequent experiments, we analyzed the data
                                                                                                     true state of the world is varied. We see, consistent with our
by collapsing across context items.
                                                                                                     intuition, that indirect speech was relatively more preferred in
                                                                                                     bad states than in good states. As well, we see higher prob-
                                                                                                     ability of negation production for the speaker who wants to
   For each utterance-state pair, we computed the posterior                                          convey both goals (epistemic and social) relative to each goal
distribution over the semantic weight (i.e., how consistent X
                                                                                                          2 In
                                                                                                             addition, the model has a few parameters not of theoretical
utterance is with Y state) assuming a uniform prior over the
                                                                                                     interest. For the purposes of generating model predictions a priori,
weight. Meanings of the words as judged by participants were                                         we assign values to these parameters consistent with the previous
as one would expect (see Figure 1). We used the fraction of                                          literature with this class of models: the speaker optimality parameter
participants that endorsed utterance w for state s to set infor-                                     (λ1 assigned to 2); the pragmatic speaker optimality parameter (λ2
                                                                                                     to 2); the value scale parameter (α to 1) in the utility function; and
mative priors to infer posterior credible values of the literal                                      the parameter governing the cost of producing a negation (C(u) to
meanings from data in the speaker production experiment.                                             2).
                                                                                               3604

independently. Indirect speech does not convey that much in-
formation and so the informative speaker (a) would disprefer
it. The social speaker (b) who wants to convey a face-saving
goal would tend to signal a better-that-actual state through
direct positive remarks. The both-goal speaker produces in-
direct remarks to avoid direct remarks that are either true but
face-threatening, or face-saving but false.
           Speaker production experiment
To compare against our model predictions, we measured par-
ticipants’ predictions for the most likely utterance (w) pro-
duced by the speaker, given a description of the true state.
                                                                             Figure 3: Example of a trial in Experiment 1.
For example, given that Ann wanted to make Bob feel good
but felt that his poem deserved 2 out of 5 hearts, what would
she say? We hypothesized that when there was no tradeoff            Behavioral results
between informativity and face-threat avoidance (i.e., when
the addressee’s performance was great), speakers would use          Our hypotheses for utterance production by speakers with dif-
truthful and face-saving direct remarks (“[Your poem] was           ferent goals were borne out (see full results in Figure 4).
amazing”) regardless of their described goals. However,             For good states (4 and 5 hearts), positive direct remarks were
when there was a conflict between the epistemic and social          judged to be the most likely utterances across all three goal
goals (i.e., when the addressee’s performance was poor), a          conditions. For less-than-perfect, but still decent states, there
speaker who tried to convey both goals would use vague indi-        was a greater degree of expectation of white lies (e.g., “It was
rect remarks (“[Your poem] wasn’t terrible”) more often than        amazing” for 4 hearts) given a social goal. For bad states
direct face-threatening remarks (“[Your poem] was bad”; pre-        (1 and 2 hearts), as predicted, there were more instances of
ferred by a speaker who only considered the epistemic goal)         expected indirect remarks overall across all goal conditions
or direct face-saving remarks (“[Your poem] was good”; pre-         given bad states. Critically, speakers with both informative
ferred by a speaker who wanted to convey only a social goal).       and social goals produced more indirect remarks than were
                                                                    observed in the other two goal conditions (Figure 2, center).
Method                                                              Model results
                                                                    Model fitting In this experiment, participants were told
Participants 202 participants with IP addresses in the
                                                                    what speakers’ intentions were (e.g., wanted to make Bob feel
United States were recruited on Amazon’s Mechanical Turk.
                                                                    good). We assume that the intention descriptions conveyed
Stimuli and Procedure As in the semantics measurements              the weight mixture φ that the speaker was using. We put un-
above, we used scenarios in which a person (e.g., Bob) gave         informative priors on this mixture (φ ∼ Uniform(0,1)) and in-
some performance and asked for another person (e.g., Ann)’s         ferred their credible values separately for each goal condition
opinion on the performance. Additionally, we provided infor-        (“wanted to X”) using Bayesian data analytic techniques (Lee
mation on the speaker Ann’s goal – to make Bob feel good, or        & Wagenmakers, 2014). We also used the fraction of partic-
to give as accurate and informative feedback as possible, or        ipants that endorsed utterance w for state s to set informative
both – and the true state – how Ann actually felt about Bob’s       priors to infer posterior credible values of the literal meanings
performance (e.g., 2 out of 5 hearts). Each participant read        from data.
15 scenarios, depicting every possible combination of goals            There were four additional parameters of the model, on
and states. The order of context items was randomized, and          which we put uninformative priors: the speaker optimality
there were a maximum of two repeats of each context item            parameter (λS1 ∼ Unif(0,20)); the pragmatic speaker optimal-
per participant.                                                    ity parameter (λS2 ∼ Unif(0,5)); the value scale parameter
    Each scenario was followed by a question that read, “If         (α ∼ Unif(0,5)) in the utility function; and the cost param-
Ann wanted to make Bob feel good but not necessarily give           eter (C(u) ∼ Unif(1,10)). We inferred their posterior credible
informative feedback (or to give accurate and informative           values from the data. We ran 4 MCMC chains for 80,000
feedback but not necessarily make Bob feel good, or BOTH            iterations, discarding the first 40,000 for burnin. The Max-
make Bob feel good AND give accurate and informative feed-          imum A-Posteriori (MAP) estimate and 95% Highest Prob-
back), what would Ann be most likely to say?” Participants          ability Density Interval (HDI) were: λS1 : 2.16 [2.02, 3.61];
indicated their answer by choosing one of the options on            λS2 : 0.91 [0.83, 1.75]; α: 2.71 [0.98, 4.59]; C(w): 2.04 [1.95,
the two dropdown menus, side-by-side, one for choosing be-          2.25]. To generate utterance predictions, given our model and
tween was vs. wasn’t and the other for choosing among ter-          the inferred parameters, we evaluated the posterior predictive
rible, bad, okay, good, and amazing (see Figure 3).                 distribution, marginalizing out all parameters.
                                                                3605

Figure 4: Experimental results (solid lines) and fitted model predictions (dashed lines) for speaker production. Proportion
of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true
states (columns) and speaker goals (rows). Error bars represent 95% confidence intervals for the data and 95% highest density
intervals for the model.
Results The inferred weights for each goal condition were             model did not yield the expected difference for negation pro-
largely as expected: For the “wanted to give informative feed-        duction between both-goal and social conditions (Figure 2,
back” (informative) condition, the model put a relatively high        right); though the trend was numerically correct, the effect
weight on epistemic utility (0.81). For the “wanted to make           was much smaller in the fit model than the schematic one.
[listener] feel good” (social) condition, the model inferred          There are several possible explanations for this small devi-
that the speaker was using a moderate weight on epistemic             ation. In our experimental data, the social speaker placed a
utility (0.51). For the “wanted BOTH to make [the listener]           higher weight on epistemic utility than in our schematic pre-
feel good and give informative feedback” (both) condition,            dictions. Thus, the particular goal descriptions we used in the
the model assigned a weight on epistemic utility between the          experiment may have suggested that the social speaker still
weights for the other two goal conditions (0.57). Overall,            wanted to be seen as informative, and have led to little dif-
the weights tended to be more biased towards prioritizing the         ferentiation between the social vs both-goal speaker. Another
epistemic utility.                                                    possible cause is that participants preferred a different kind
   The predictions for the speaker’s utterance were overall           of indirect speech than the model – in particular, the both-
highly consistent with the experimental findings (Figure 4).          goal speaker preferred to produce “It wasn’t amazing” in the
The posterior predictive of the model explained almost all            schematic model predictions, whereas participants in our ex-
of the variance in the production data r2 (150) = 0.962 (Fig-         periment chose “It wasn’t terrible.” This discrepancy between
ure 5). The model successfully predicted distinct patterns for        the two remarks is interesting, because their implied meaning
each goal condition. The informative speaker produced direct          is similar. In a pilot experiment where participants were asked
remarks whose literal meanings mapped onto the true states            to infer the true state (number of hearts) from an utterance, “It
(e.g., “It was terrible” given 1 heart). The social speaker pro-      wasn’t amazing” and “It wasn’t terrible” were very similar (˜2
duced remarks that were positively biased compared to the             hearts).
true states (e.g., “It was okay” given 2 hearts).
   While the model in the both condition did produce indi-                                       Discussion
rect utterances (e.g., “It wasn’t terrible” given 1 heart) it did     Why are we polite? Here we explored a formal instantiation
so slightly less than the empirical data. For this reason, the        of the hypothesis that two conflicting speaker goals – epis-
                                                                  3606

                                                                      the need for indirect speech results from the conflict between
                                                                      these two. These findings provide strong support for a utility-
                                                                      theoretic framing of politeness, and suggest new directions in
                                                                      understanding of pragmatic language use in social contexts.
                                                                                          Acknowledgments
                                                                      This work was supported by NSF grant BCS 1456077 to
                                                                      MCF, ONR grant N00014-13-1-0788 to NDG, NSF Gradu-
                                                                      ate Research Fellowship DGE-114747 to MHT, and NSERC
                                                                      PGS Doctoral scholarship PGSD3-454094-2014 to EJY.
                                                                                               References
                                                                       Axia, G., & Baroni, M. R. (1985). Linguistic politeness at
                                                                        different age levels. Child Development, 918–927.
                                                                       Brown, P., & Levinson, S. C. (1987). Politeness: Some uni-
                                                                        versals in language usage (Vol. 4). Cambridge Univ. Press.
Figure 5: Full distribution of human responses vs. model
                                                                       Clark, H. H., & Chase, W. G. (1972). On the process of com-
predictions. Error bars represent 95% confidence intervals
                                                                        paring sentences against pictures. Cognitive Psychology,
for the data (vertical) and 95% highest density intervals for
                                                                        3(3), 472–517.
the model (horizontal).
                                                                       Clark, H. H., & Schunk, D. H. (1980). Polite responses to
                                                                        polite requests. Cognition, 8(2), 111–143.
                                                                       Goodman, N. D., & Frank, M. C. (2016). Pragmatic lan-
temic and social – can be used to explain a range of polite             guage interpretation as probabilistic inference. Trends in
behavior, including white lies and indirect speech acts us-             Cognitive Sciences, 20(11), 818–829.
ing negation. Our model predicted that speakers should pro-            Goodman, N. D., & Lassiter, D. (2015). Probabilistic seman-
duce more indirect remarks in cases of greater face threat              tics and pragmatics: Uncertainty in language and thought.
(given the addressee’s poorer performance) and in cases                 In S. Lappin & C. Fox (Eds.), The handbook of contempo-
where speakers wanted to be both informative and nice. Our              rary semantic theory, 2nd edition. Wiley-Blackwell.
experimental data confirmed these predictions. The model’s             Goodman, N. D., & Stuhlmuller, A. (2013). Knowledge and
overall fit to the data was very strong, although it did not show       implicature: Modeling language understanding as social
the predicted dominance of indirect speech for the both-goal            cognition. Topics in Cognitive Science, 5.
speaker at low states. Whether this discrepancy between the            Goodman, N. D., & Stuhlmuller, A. (2014). The Design and
initial and data-fitted predictions was due to variation in goal        Implementation of Probabilistic Programming Languages.
weight based on experimental scenarios or a discrepancy in              http://dippl.org.
preferences for particular utterances is a question for future         Grice, H. P. (1975). Logic and conversation. In Readings in
work.                                                                   language and mind. Blackwell.
   An important contribution of this work is in showing the            Holtgraves, T. (1997). YES, but. positive politeness in con-
generalizability of our formal model (pRSA) to the case of              versation arguments. Journal of Language and Social Psy-
indirect speech acts. The current work took a step in address-          chology, 16(2), 222–239.
ing speakers’ self-presentation: Not only do speakers want             Holtgraves, T., & Joong-nam, Y. (1990). Politeness as uni-
to save the listener’s face, but they also want to save their           versal: Cross-cultural perceptions of request strategies and
own face, by appearing informative and considerate to the lis-          inferences based on their use. Journal of Personality and
tener. In future work we hope to explore this aspect more and           Social Psychology, 59(4), 719.
test how our model’s utilities can be extended to capture the          Kao, J. T., Wu, J. Y., Bergen, L., & Goodman, N. D. (2014).
speaker’s desire to appear polite, genuine, and even modest.            Nonliteral understanding of number words. Proceedings of
Using the model to explore other kinds of polite speech such            the National Academy of Sciences, 111(33), 12002–12007.
as indirect requests (“Would you mind closing the window?”;            Lee, M. D., & Wagenmakers, E. J. (2014). Bayesian cogni-
Clark & Schunk, 1980) and manifestations of polite speech               tive modeling: A practical course. Cambridge Univ. Press.
in different cultures (e.g., Holtgraves & Joong-nam, 1990)             Searle, J. R. (1975). Indirect speech acts. In P. Cole & J.
are also important future directions.                                   Morgan (Eds.), Syntax and semantics (vol. 3): Speech acts.
   In sum, our formal model and experimental work represent             New York: Academic Press.
an advance in polite speech understanding. With a minimal              Yoon, E. J., Tessler, M. H., Goodman, N. D., & Frank, M. C.
extension to our existing model, we were able to capture sub-           (2016). Talking with tact: Polite language as a balance be-
tle patterns in people’s inferences about indirect speech pro-          tween kindness and informativity. In Proceedings of the
duction. Our empirical findings suggest that neither epistemic          thirty-eighth annual conference of the Cognitive Science
nor social motives alone motivate indirect speech; instead,             Society.
                                                                  3607

