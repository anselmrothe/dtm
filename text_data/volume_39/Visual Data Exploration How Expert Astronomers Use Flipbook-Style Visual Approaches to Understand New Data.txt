                          Visual Data Exploration: How Expert Astronomers Use
                      Flipbook-Style Visual Approaches to Understand New Data
                                 Fernanda Monteiro Eliotta (fernanda.m.eliott@vanderbilt.edu)
                                          Keivan Stassunb (keivan.stassun@vanderbilt.edu)
                                             Maithilee Kundaa (mkunda@vanderbilt.edu)
               a Department    of Electrical Engineering and Computer Science, b Department of Physics and Astronomy
                     Vanderbilt University, PMB 351679, 2301 Vanderbilt Place, Nashville, TN 37235-1679, USA
                                Abstract                                  front and center—to assist and augment human capabilities in
                                                                          the discovery process (Honavar, Hill, & Yelick, 2016).
    What are the cognitive processes in play when someone uses a
    visualization tool to interactively explore a new dataset? Here,         One vital role for data visualization is the open-ended,
    we focus on one particular type of visualization—the scatter          open-minded exploration of data that leads to unexpected in-
    plot—which, despite (or perhaps because of) its simplicity, is        sight, often manifested at first as a “striking” or “interesting”
    still one of the most frequently used plot types in many data-
    intensive disciplines. We conducted a pilot study to investigate      multivariate plot, such as with the H-R diagram. To take a
    how expert astronomers interact with an unfamiliar dataset us-        more recent example, an astronomy research team at Van-
    ing a visualization tool called Filtergraph, which supports rapid     derbilt University developed a visualization tool called Fil-
    and easy visualization of large datasets. We present both quali-
    tative and quantitative results, including observations about the     tergraph (see Figure 1) designed to allow people to rapidly
    temporal dynamics of visual data exploration as well as inter-        and easily explore large datasets of up to a few million points
    esting behavioral patterns that we saw in our participants, such      (Burger et al., 2013). Using the Filtergraph software to visu-
    as users taking “circular walks” through the data at various lev-
    els of abstraction.                                                   alize stellar variability data gathered by the Kepler spacecraft
                                                                          resulted in an unexpected and “visually interesting” scatter-
    Keywords: Data exploration; graph understanding; informa-
    tion visualization; scatter plots; visualization software.            plot, which in turn led to the discovery of stellar granulation
                                                                          “flicker” and its utility for stellar and exoplanets research,
                            Introduction                                  a significant finding that was published in Nature (Bastien,
                                                                          Stassun, Basri, & Pepper, 2013).
When astronomer Henry Norris Russell first introduced the
now-called Hertzsprung-Russell (H-R) diagram, he wrote,
“The appearance of [the figure] suggests the hypothesis that,
if we could put on it some thousands of stars, instead of the
300 now available, ...we would find the points representing
them clustered principally close to two lines, one descending
sharply along the diagonal...the other ...running almost hor-
izontally. ...These two classes of stars were first noticed by
Hertzsprung, who has applied to them the excellent names of
giant and dwarf stars” (Russell, 1914, p. 287).
    In addition to Russell’s obvious desire for more data, his
wonderfully vivid description conveys the fundamentally vi-
                                                                          Figure 1: A screenshot of the Filtergraph data visualization
sual nature of this discovery. Indeed, the H-R diagram has
                                                                          interface (Burger et al., 2013), and also the initial view shown
been called “perhaps the most spectacularly successful exam-
                                                                          to participants in our pilot study.
ple of a simple scatterplot” in all of science (Spence & Gar-
rison, 1993, p. 1). Today, like many disciplines, astronomy                  Here, we report our preliminary results on a pilot study
enjoys volumes of data that Russell could only have imag-                 to investigate how expert astronomers interact with an un-
ined. However, an astronomer’s expertise to make sense out                familiar dataset using scatterplots generated by Filtergraph.
of data—to recognize which patterns represent actual scien-               We use a novel analysis approach that is different from, but
tific discovery—remains as vital today as it was in 1914.                 complementary to, existing methods that focus on measuring
    Most human sense-making with data involves a visually-                actions or tasks conducted by the data analyst. Instead, our
mediated interaction between the data and the percep-                     approach measures interactions in terms of dataset attributes:
tual/cognitive processes of the user—data visualization. Data             which variables from a large dataset does an analyst look at,
visualization can be as short and simple as glancing at a print-          when, and why? We present both qualitative and quantita-
out of a plot on paper, or as lengthy and complex as spending             tive results from this study, including observations about the
months analyzing and modeling a large dataset. There is an                temporal dynamics of visual data exploration as well as in-
increasing need for interactive data visualization tools that not         teresting behavioral patterns that we saw in our participants,
only leverage the latest in pattern recognition and data min-             such as users taking “circular walks” through the data at var-
ing algorithms, but also place the cognitive needs of the user            ious levels of abstraction.
                                                                      2754

                       Related Work                                     use while processing external visualizations of information.
There is a rich foundation of work in HCI (Human Computer                                          Methods
Interaction), visual analytics, and infovis that aims to under-
                                                                        We conducted a pilot study to investigate how expert as-
stand the processes by which people interact with and under-
                                                                        tronomers interact with an unfamiliar dataset using the Fil-
stand data. Sanderson and Fisher (1994) present a widely-
                                                                        tergraph visualization tool shown in Figure 1. We chose the
used, general framework for thinking about user interactions
                                                                        domain of astronomy as being representative of today’s data-
with an interactive tool in terms of sequences of actions that
                                                                        intensive disciplines. In designing our study, we wanted to
represent different user functions, such as connecting ideas or
                                                                        choose a data exploration task that was open-ended enough
introducing comments.
                                                                        to provide a realistic challenge to our participants, but also
   Specifically in relation to data visualization, Yi and col-
                                                                        that had at least some constraints so that we could analyze
leagues (2007) identify seven modes of interaction with visu-
                                                                        meaningful differences across participants. We decided to in-
alization tools, such as select, explore, and filter, that they be-
                                                                        vite astronomers to our lab to participate in one-hour sessions,
lieve are important for understanding the visual sense-making
                                                                        during which they would be instructed to “explore” an astron-
process. Brehmer and Munzner (2013) present a task typol-
                                                                        omy dataset that they had not previously seen. All necessary
ogy that bridges low-level interactions with high level tasks
                                                                        IRB approvals were obtained prior to the study.
and goals during visualization activities. Pirolli and Card
                                                                           Dataset. We chose a dataset that we believed would not re-
(2005) present a detailed cognitive task analysis of visual
                                                                        quire complex mathematical operations to make sense of, and
sensemaking in the domain of intelligence analysis. ElTayeby
                                                                        also that would not be from too specialized a subfield within
and Dou (2016) present methods for studying exploratory
                                                                        astronomy. The dataset we chose is described in Berlind
data visualization that leverage the automated analysis of
                                                                        et al. (2006) and contains data describing 90, 893 galaxies,
rich, quantitative interaction log data to identify and under-
                                                                        which are individually discriminated through 10 attributes
stand underlying patterns of interaction.
                                                                        (including the galaxy ID), or group separated through 9 at-
   Saraiva and colleagues (2005) conducted a very interesting           tributes (including the group ID), as shown in Table 1.
pilot study specifically focused on open-ended, exploratory
data analysis in the domain of bioinformatics. They focus on            Table 1: The 19 attributes in the galaxy dataset used for our
how a visualization tool can complement a dataset in order to           pilot study (Berlind et al., 2006), along with letter codes used
facilitate insights that may lead to a discovery. One impor-            throughout this paper. The last two shaded items represent
tant issue they addressed was how to define and measure in-             arithmetic combination of attributes that we observed partici-
sight. They defined insight based on the context of their work          pants construct on the fly during the study sessions.
as well as based on characteristics such as time, hypotheses,
correctness, and category. Their results show the influence
of the visualization tool itself over the processes of human
interpretation and insight.
   Mayr and colleagues (2016) looked at how mental mod-
els parallel a user’s use of external visualization tools. They
identify key characteristics pertaining to mental models, such
as content, structure, coherence, perspectivity, generalizabil-
ity, and utility, and they review existing empirical methods
for conducting user studies to get at these characteristics.
   Finally, there is important work being done to understand
data visualization and sensemaking in terms of core cog-
nitive capabilities that people bring to bear on such tasks.
Healey and Enns (2012) provide a research survey on cogni-
tive theories of attention and perceptual processing as appli-             Study protocol. We recruited 7 graduate students in as-
cable to data visualization. They provide examples of factors           tronomy from the Vanderbilt community, ranging in age from
that drive visual attention (such as visual feature hierarchies,        23 to 28 years old, with 2 identifying their gender as female,
memory, and prediction) and also factors that impair atten-             4 as male, and 1 as two-spirited. We ran participants in five
tion, such as what happens during change blindness, with ob-            sessions: two sessions (S1 and S4) each involved two par-
servations about how improperly designed visualizations can             ticipants conducting data exploration collaboratively, and the
significantly impact a user’s mental models of the data.                other three sessions (S2, S3, and S5) each involved a single
   Tversky (2003) reflects about humans, actions, and space,            participant. Note that as part of our pilot study design, we
emphasizing the importance of differences in how people rep-            decided to include both individual and collaborative sessions
resent space across different spatial reference frames (e.g., in        to better inform our approaches for future studies.
a navigation task versus a graphical understanding task). She              Participants received gift cards as compensation for their
includes discussion of the spatial references frames people             time. Each session proceeded as follows. First, the partici-
                                                                    2755

pant(s) filled out a short demographic questionnaire. Then,          tion of about 73 minutes; see Table 2.
we asked participants to sit down at a computer workstation             Analysis approach. We gathered data using a combina-
and use Filtergraph to visualize and explore the galaxy data         tion of note-taking by study personnel, paper forms, and in-
set. We provided a printout listing all dataset attributes and       teraction data collected on the computer workstation through
their semantic descriptions. A member of our study team              screen recordings of each session. To analyze results, we de-
sat with participants during the session, asking open-ended          fined the concepts of major observations and minor observa-
questions to better understand how the interaction was un-           tions of the dataset, as illustrated in Figures 2 and 3.
folding. At the end of the session, participants were asked to          Definition: A major observation is a grouping of contigu-
write down their own impressions about the study, and ideas          ously viewed scatterplots within which the attributes assigned
about what software, tools, catalogs, or other data-related af-      to X and Y axes remain constant. When a user changes the
fordances would make their life as an astronomer easier.             attribute assigned to either the X or Y axis (or both), a new
                                                                     major observation begins.
Table 2: Session details from our pilot study. M gives the
                                                                        Definition: A minor observation is a grouping of contigu-
number of major observations in each session, and N gives
                                                                     ously viewed scatterplots that occurs during a major obser-
the number of minor observations.
                                                                     vation, within which one or more individual, highly related
                                                                     scatterplots are viewed. For example, looking at a 3D scatter-
                                                                     plot but rotating the plot to see many different views would
                                                                     constitute a single minor observation of the data.
                                                                        We used screen recordings to identify major and minor ob-
                                                                     servations within each session. We did not count plots that
                                                                     were generated in the course of defining a single set of plot-
                                                                     ting parameters (i.e., because Filtergraph redraws plots nearly
   Filtergraph settings. To constrain the visualizations used        instantly, while the user might still be typing). Also, some-
by participants, we asked participants not to change the Fil-        times participants assigned the exact same parameters to the
tergraph setting that selects scatterplots as the visualization      current plot, not actually changing the plot at all. We did not
type. Within the scatterplot setting, Filtergraph offers many        count these immediately repeated plots either. Finally, for
interactive options for changing how the dataset is visualized.      continuously changing plots, which we saw especially when
The attributes assigned to X and Y axes can be changed, and          participants were smoothly rotating or moving 3D plots, we
a Z axis attribute can optionally be added. Attributes can also      only counted the first and last views as separate plots within
be assigned to the color dimension or used to select or fil-         the same minor observation.
ter out portions of the data. Anywhere individual attributes            Exclusions. During session S2, an attribute was plotted
are used, arbitrary mathematical transformations or combina-         by mistake; the participant had intended to plot a different
tions of attributes can also be assigned. Additionally, there        attribute instead and only discovered their mistake after 12
are options for changing the background plot color as well as        minutes. We do not include these “mistake” plots in our cur-
the size and shape of data points. When the Z axis is in use,        rent analysis, though certainly these kinds of mistakes will
there are options to rotate the plot or change its scale.            be considered in future work. In addition, session S5 was
   All the sessions started from the same home screen, shown         qualitatively very different from Sessions S1 through S4. In
in Figure 1, with the X-axis set to attribute A, the Y-axis set      session S5, the participant appeared to pay very little atten-
to attribute B, and the color set to attribute C (see Table 1).      tion to the semantics of the attributes that were being plotted
                                                                     (even when prompted to consider attribute meanings by our
   One concern we had was that participants might get bored
                                                                     study team member). This participant declared to be select-
or fatigued during the session and generate plots only to fill
                                                                     ing attributes randomly, and engaging in a primarily percep-
the time, and not through genuine interest and curiosity in
                                                                     tual exploration of the dataset. While we find this pattern of
exploring the dataset. Thus, the member of our team who
                                                                     interaction in session S5 extremely interesting, we felt that
sat with participants tried to be friendly and engaging, to help
                                                                     a different approach would be needed to analyze these data,
create a positive session environment. (Note that this member
                                                                     and so we have left the analysis of session S5 for future work.
of our team comes from a computer science background, not
astronomy, and so we do not believe this “social” aspect of the
study sessions introduced significant biases in which parts of
                                                                                      Results and Discussion
the dataset the participants would choose to focus on.)              Here, we discuss preliminary results from our pilot study.
   In addition, after 45 minutes, the participants were in-          While there is certainly work to be done in analyzing the
formed that they could finish their current activity and end         specific, astronomy-related meanings of participants’ data vi-
the session, if they wanted to, or they could continue to work       sualization choices, including a detailed criterial analysis on
for as long as they chose. As it turns out, all of our partici-      their mental models (Mayr et al., 2016), that type of anal-
pants chose to stay past the 45 minute mark, with a minimum          ysis falls outside the scope of the current paper and will be
session duration of about 48 minutes and a maximum dura-             part of future work. For now, we focus on describing the
                                                                 2756

            Figure 2: For session S1, plots showing the first minor observation for each of the 12 major observations.
Figure 3: For session S2, in chronological order, from left to right: plots showing the 28 minor observations within the fourth
major observation. Note the “circular walk”: the yellow, red, and blue boundaries indicate 3 different plots that were each
observed twice. The six plots with a black background are unclear due to the small number of plotted points.
         Figure 4: Number of major observations generated during each session for different combinations of attributes.
general behavioral patterns of data visualization that we ob-         X or Y axes. Interestingly, only 4 major observations were
served, including the temporal dynamics of participant inter-         shared by two or more sessions; this shows the high variabil-
actions with the Filtergraph tool. Table 2 gives details of the       ity in data exploration paths taken by different individuals.
five sessions that we ran for this study.                                Attribute I was the only one never assigned to either the
   Distribution of major observations by attribute. Con-              X or Y axes. It turns out that this attribute is Boolean; it
sider the 17 data attributes contained in the galaxy dataset          indicates whether the galaxy is the brightest in its group, and
(see Table 1). Note that two of the original 19 attributes are ID     so it makes sense to not be chosen for one of the primary axes.
numbers, for galaxies and groups of galaxies, and so do not           Attributes P (a measure of galaxy morphology) and Q (was
capture “meaningful” in the same sense as the other 17. The           there a problem while measuring the galaxy) are the other two
number of possible major observations that could be made              categorical variables in the dataset; interestingly, these were
from this data, i.e., possible assignments of attributes to X         assigned to axes at various times during one of the sessions.
and Y axes, is (17 choose 2) = 272 possibilities. If we allow            The BC combination was the only major observation
mathematical transformations or combinations of attributes,           shared across all four sessions. B gives the longitude of the
then the number of possible major observations is infinite.           galaxy group center, and C gives the latitude. So, plotting the
   Across all sessions, participants viewed a total of only 38        BC combination produces what is essentially a spatial “map”
distinct major observations, as shown in Figure 4. This figure        of the galaxies represented in the dataset.
also shows which attributes participants assigned to either the          Temporal dynamics of data exploration. We are partic-
                                                                  2757

Figure 5: Distribution of major and minor observations over time, for sessions S1 (top) through S4 (bottom). Each point
indicates a group of highly related individual plots (or, for example, a single continuous rotation of the same 3D plot). Major
observations repeated within or across sessions are marked by colored labels.
ularly interested in understanding the temporal dynamics of            not at all in session S2, occasionally in session S1, and quite
open-ended data exploration. How frequently do our partici-            a lot in sessions S3 and S4. In sessions S2 and S4, we saw
pants switch from one major or minor observation to the next?          similar “circular walk” patterns within some of the major ob-
   Figure 5 illustrates the temporal distributions of major and        servations; the participant often returned to the same minor
minor observations for all four sessions. By looking at the            observation that they had started with, before moving on to
blue dots in this figure, we can see the most active periods,          the next minor or major observation. Figure 3 depicts an ex-
the ones in which many plots were quickly generated. We                ample of a “circular walk” within session S2.
can also see periods in which a single minor observation was              Within each major observation, it seems as though partici-
studied at some length. (Note also that the large gap early            pants are directing a type of “movement” from the first to the
in session S2 is due to data we omitted, as described earlier.)        last plot (depicted via minor observations); a story is being
The first point of interest is that participants generally chose       told through the movement of data points across the plots.
to “flip through” the dataset at a fairly brisk pace. Part of this     This notion of movement/story strongly brings to mind the
could, of course, be due to the participants knowing they had          idea of flipbooks. For instance, Figure 3 shows a story re-
only one hour to complete the study, but we expect the same            garding the relationship between the attributes F and E.
to hold in more naturalistic settings as well.                            Other qualitative observations. To conclude our presen-
   The average duration of minor observations was about 61             tation of preliminary results, we present a few high-level ob-
seconds, though this distribution has a long tail that falls off       servations about patterns of data exploration in our study.
fairly consistently and extends to the longest minor obser-               Starting point: Participants seemed to choose a starting
vations at around 554 seconds. For major observations, the             point to anchor themselves in relation to the dataset. Ses-
average duration was about 229 seconds, with a maximum                 sions S1 and S2 began by plotting attributes that involve the
of about 1046 seconds. The durations of major observations             spatial position of galaxies, perhaps to let participants estab-
seem to show a bimodal tendency, with many major obser-                lish a mental map of the spatial layout of the galaxy dataset.
vations falling under the 150 second mark, but another large           Sessions S3 and S4 began by looking at attributes like the
grouping lying in the 150-400 second range.                            number of galaxies in each group and the velocity with which
   Interestingly, participants often returned to the same ma-          each group is moving away from us, perhaps establishing an
jor observation within the same session. This pattern occurs           egocentric reference frame of “us versus the galaxies.”
                                                                   2758

   Mouse gestures: Participants frequently used the mouse as           tion tool developed at Vanderbilt University through the Van-
a communicative or attention-focusing tool, i.e., to gesture at        derbilt Initiative in Data-intensive Astrophysics (VIDA).
the visualizations. While some of these were directed at our
study team member who was observing the session, many of                                         References
these mouse gestures also occurred when participants were              Bastien, F., Stassun, K. G., Basri, G., & Pepper, J. (2013). An
interacting with Filtergraph and thinking about what to do                observational correlation between stellar brightness varia-
next. Sessions S1 and S2 exhibited many more mouse ges-                   tions and surface gravity. Nature, 500(7463), 427–430.
tures than did sessions S3 and S4.                                     Berlind, A., Frieman, J., Weinberg, D., Blanton, M., Warren,
   Paper aids: Participants in sessions S1 and S2 relied heav-            M., Abazajian, K., . . . others (2006). Percolation galaxy
ily on the paper printout of attribute details throughout the             groups and clusters in the sdss redshift survey: identifica-
sessions. Participants in S3 and S4, on the other hand, used              tion, catalogs, and the multiplicity function. ApJ Supple-
the printout at the start, but, during the interaction itself, re-        ment Series, 167(1), 1.
lied more on the list of attributes provided by Filtergraph.           Brehmer, M., & Munzner, T. (2013). A multi-level typology
   Collaboration/leadership: In both of the sessions with two             of abstract visualization tasks. IEEE Transactions on Visu-
participants, we observed that one of the participants seemed             alization and Computer Graphics, 19(12), 2376–2385.
to lead the exploratory line of thought. But note that leading         Burger, D., Stassun, K., Pepper, J., Siverd, R., Paegert, M.,
does not necessarily means commanding the mouse and di-                   De Lee, N., & Robinson, W. (2013). Filtergraph: An
rectly interacting with the workstation. In one session, the              interactive web application for visualization of astronomy
“thought” leader was also the one interacting with Filter-                datasets. Astronomy and Computing, 2, 40–45.
graph, but in the other session, the “thought” leader was not          ElTayeby, O., & Dou, W. (2016). A survey on interaction log
the primary tool interaction person.                                      analysis for evaluating exploratory visualizations. In Proc.
   Collaboration/corrections: We observed that, in the ses-               of the beyond time and errors on novel eval methods for
sions with two participants, one helped the other to quickly              visualization (pp. 62–69).
correct mistakenly plotted attributes. In contrast, during ses-        Healey, C., & Enns, J. (2012). Attention and visual mem-
sion S2 (which involved a single participant), an attribute was           ory in visualization and computer graphics. IEEE trans.
plotted by mistake and not discovered for 12 minutes.                     Visualization & Comp. Graphics, 18(7), 1170–1188.
                                                                       Honavar, V., Hill, M., & Yelick, K. (2016). Accelerating
          Conclusion and Future Directions                                science: A computing research agenda. arXiv preprint
                                                                          arXiv:1604.02006.
Our findings highlight a few interesting properties of how
                                                                       Mayr, E., Schreder, G., Smuc, M., & Windhager, F. (2016).
domain experts explore an unfamiliar dataset, particularly
                                                                          Looking at the representations in our mind: Measuring
in terms of temporal and dimensional patterns. The next
                                                                          mental models of information visualizations. In Proc. of
challenge is to understand how, as people follow exploratory
                                                                          the beyond time and errors on novel eval methods for visu-
paths through a dataset, they build meaningful cognitive rep-
                                                                          alization (pp. 96–103).
resentations of what they see, and how they are able to iden-
                                                                       Pirolli, P., & Card, S. (2005). The sensemaking process and
tify encounters with unexpected, significant data patterns.
                                                                          leverage points for analyst technology as identified through
   We anticipate that temporal patterns are especially impor-
                                                                          cognitive task analysis. In Proceedings of international
tant from a cognitive perspective because they describe not
                                                                          conference on intelligence analysis (Vol. 5, pp. 2–4).
just moment-to-moment attentional switches but also serve
                                                                       Russell, H. N. (1914, May). Relations Between the Spectra
as a way of marking successive stages at which a person’s
                                                                          and Other Characteristics of the Stars. Popular Astronomy,
mental model of a dataset is likely changing. Five minutes
                                                                          22, 275-294.
spent looking at a single plot, versus five minutes spent “flip-
                                                                       Sanderson, P. M., & Fisher, C. (1994). Exploratory sequential
ping” through multiple plots, are both likely to be equally
                                                                          data analysis: Foundations. Human–Computer Interaction,
important modes of exploration. The key is figuring out the
                                                                          9(3-4), 251–317.
cognitive purpose served by each.
                                                                       Saraiya, P., North, C., & Duca, K. (2005). An insight-based
   We are also intrigued by the frequency of “circular walks”
                                                                          methodology for evaluating bioinformatics visualizations.
in the exploratory paths taken by our participants. Viewing
                                                                          IEEE trans. visualization & comp. graphics, 11, 443–456.
the same plot twice serves no obvious purpose from a purely
                                                                       Spence, I., & Garrison, R. (1993). A remarkable scatterplot.
statistical or data mining perspective. However, in humans,
                                                                          The AM STAT, 47(1), 12–19.
we predict that these “circular walks” actually serve key roles
                                                                       Tversky, B. (2003). Structures of mental spaces how people
related to memory, attention, salience, etc.
                                                                          think about space. EAB, 35(1), 66–80.
                                                                       Yi, J., ah Kang, Y., & Stasko, J. (2007). Toward a deeper
                    Acknowledgments
                                                                          understanding of the role of interaction in information vi-
We would like to thank Dr. Andreas Berlind who gener-                     sualization. IEEE trans. visualization & comp. graphics,
ously shared the galaxy dataset we used in our study. This                13(6), 1224–1231.
research makes use of Filtergraph, an on-line data visualiza-
                                                                   2759

