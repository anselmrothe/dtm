        Speakers’ gestures predict the meaning and perception of iconicity in signs
          Gerardo Ortega1,2 (gerardo.ortega@mpi.nl), Annika Schiefner1 (a.schiefner@student.ru.nl), &
                                              Aslı Özyürek1,2,3 (asli.ozyurek@mpi.nl)
                                           1
                                             Centre for Language Studies, Radboud University,
                            2
                             Max Planck Institute for Psycholinguistics, and 3Donders Centre for Cognition
                                           Wundtlaan 1, 6525XD Nijmegen, The Netherlands
                               Abstract                              Bartolotti, 2010; McNeill, 1992). Sign languages, in
  Sign languages stand out in that there is high prevalence of
                                                                     contrast, occur independently from speech, and critically,
  conventionalised linguistic forms that map directly to their       they have the same levels of linguistic organisation as those
  referent (i.e., iconic). Hearing adults show low performance       reported in spoken languages (Sandler & Lillo-Martin,
  when asked to guess the meaning of iconic signs suggesting         2006).
  that their iconic features are largely inaccessible to them.          One point of intersection between sign and gesture is
  However, it has not been investigated whether speakers’            iconicity. Speakers can depict through iconic gestures the
  gestures, which also share the property of iconicity, may          visual form of a concept and integrate them with speech as
  assist non-signers in guessing the meaning of signs. Results
  from a pantomime generation task (Study 1) show that               part of a multimodal message. For instance, when a speaker
  speakers’ gestures exhibit a high degree of systematicity, and     says ‘I’ll be outside’ while producing the gesture of smoking
  share different degrees of form overlap with signs (full,          it is clear to the interlocutor that she is going for a cigarette.
  partial, and no overlap). Study 2 shows that signs with full       On the other hand, a large proportion of a signed lexicon has
  and partial overlap are more accurately guessed and are            iconic motivation (Pietrandrea, 2002), and crucially, signs
  assigned higher iconicity ratings than signs with no overlap.      may have overlapping structures as gestures (e.g., the sign
  Deaf and hearing adults converge in their iconic depictions
                                                                     TO-SMOKE depicts a person smoking a cigarette).
  for some concepts due to the shared conceptual knowledge
  and manual-visual modality.                                           The similarities between sign and gesture were
                                                                     overlooked for many decades, but in recent years scholars
     Keywords: iconicity; gesture; sign language; embodied           have begun systematically comparing both modes of manual
  cognition
                                                                     communication to shed light on their differences and
                                                                     similarities (e.g., Cormier, Schembri, & Woll, 2013;
                           Introduction                              Goldin-Meadow & Brentari, 2015; Perniss, Özyürek, &
A question that has puzzled psychologists and linguists for          Morgan, 2015; Quinto-Pozos & Parrill, 2015). Given the
decades is to what extent sign iconicity is accessible to            growing body of evidence showing that gestures and signs
individuals with no knowledge of a sign language. Iconicity,         share more forms and functions than previously assumed
defined as the direct relationship between a linguistic form         (arguably due to the shared manual-visual modality)
and its referent, is a ubiquitous property of sign languages         (Perniss et al., 2015), we investigate whether non-signing
observable at many of their linguistic levels of organisation        adults fall back on their own gestural repertoire to make
(Cuxac, 1999; Perniss, Thompson, & Vigliocco, 2010;                  judgements about conventionalised signs. The aim of the
Pietrandrea, 2002). Sign-naïve adults can accurately guess           present study is therefore to investigate whether the overlap
the meaning of only a small proportion of signs (Griffith,           in form between signs (i.e., linguistic structure) and gestures
Robinson, & Panagos, 1981; Grosso, 1993; Klima &                     (i.e., iconic depictions) predicts non-signers’ ability to guess
Bellugi, 1979; Pizzuto & Volterra, 2000), but it has been            the meaning of signs and assign iconicity ratings.
hard to establish what factors allow them to map certain
features of a sign to its correct referent. In an attempt to         Perception of sign iconicity
shed light on this question, we look at the iconic gestures          Iconicity and the extent to which sign-naïve adults can
produced by hearing non-signers. Given that iconic gestures          understand the meaning of iconic signs has been a central
are expressed through the same (manual-visual) modality,             focus of attention in sign research. The first investigations
and importantly, they also share the property of iconicity           on the topic demonstrated that iconicity is not easily
(Kendon, 2004; McNeill, 1992), we entertain the hypothesis           accessible to non-signers and that the meaning of signs is
that non-signers may rely on their own gestural repertoire to        very difficult to access. In their seminal study, Klima and
make form-meaning judgements about signs.                            Bellugi (1979) asked hearing adults without any knowledge
                                                                     of a sign language to guess the meaning of a set of signs.
Iconicity in gesture and sign                                        When signs were presented in isolation and when they had
Gestures are a fundamental aspect of human communication             to select the correct meaning out of five plausible
and are present in all ages and cultures (Kendon, 2004;              candidates, participants showed a very low success rate (less
McNeill, 1992). Gestures are holistic units highly integrated        than 10%). They showed significant improvement, however,
with speech that together convey unified semantic                    when they were presented the sign along with its English
information of a multimodal utterance (Kelly, Creigh, &              translation, and were asked to explain the iconic relationship
                                                                    889

between the sign and its meaning. Participants showed              For instance, it has been found that the iconic co-speech
overall agreement in that they were able to accurately          gestures used in object descriptions are highly systematic
describe the iconic motivation of more than 50% of the          and their form depends on the physical properties of the
signs (e.g., most participants agreed that the sign VOTE        referent (Masson-Carro, Goudbeek, & Krahmer, 2015).
depicted a person putting a ballot in a box). This study set a  Objects that can be manipulated with the hands (e.g., a pen)
benchmark in sign language research and convincingly            are represented with gestures mimicking how the object is
argued that iconicity is difficult to access by hearing non-    held; while objects with low manipulability affordances
signers and that the notion of iconicity is better understood   (e.g., a sink) are represented through gestures outlining their
as a property that lies in a continuum with the meaning of      shape. A striking degree of systematicity has also been
some signs being more transparent than others.                  reported in elicited silent gestures (i.e., pantomimes). When
  Another study highlights the possibility that similarities    asked to express concepts in pantomime, participants tend to
between signs and the gestures used by the hearing              systematically differentiate actions from tools through
community may assist sign-naïve participants in guessing        distinct gestural forms (i.e., re-enactment of bodily
the meaning of signs. Grosso (1993) showed a set of iconic      movements for verbs and handshapes representing the form
and arbitrary signs in Italian Sign Language (LIS) to hearing   of objects for nouns) (Padden et al., 2013; Padden, Hwang,
non-signing adults and asked them to guess their meaning.       Lepic, & Seegers, 2015). More recently, high degree of
Participants could not provide a correct response for a large   systematicity in the structure of pantomimes has also been
proportion of signs (76%) but they were very accurate for a     found across different semantic domains and for
considerable number of items on the list (24%). A detailed      geographically unrelated cultures. Ortega and Özyürek
analysis of the correctly guessed items revealed that these     (2016) elicited pantomimes from Dutch and Mexican adults
signs resemble the emblems commonly used by Italian             and found that both groups employ remarkably similar
speakers (e.g., the sign GOOD has the same form and             strategies to depict referents. Through the implementation of
meaning as the emblem used by hearing Italians). Emblems        specific types of iconic representations and their
have a conventionalised, culture-specific form and meaning      combinations, participants systematically represent concepts
(Kendon, 1995, 2004) so when non-signing adults are             across different semantic domains. These pantomimes bare
confronted by signs that overlap in structures, they rightly    strong resemblance with the structures of recently
assume that they also share the same meaning. This study is     discovered sign languages (Safar & Petatillo, in
one of the first to suggest that non-signers’ ability to guess  preparation), so it has been argued that pantomimes reveal
the meaning of signs is based on the structural similarities    some of the cognitive dispositions that give rise to a signed
between conventionalised (linguistic) signs and the gestures    lexicon in emerging sign languages.
produced by the surrounding speaking community.                    The relevance of these studies is two-fold: first, they
  A limitation of this study is that it presupposes that only   demonstrate that iconic gestural depictions are not as
emblems facilitate the accurate guessing of the meaning of      variable as previously assumed, but rather are deployed
signs but does not say how other types of gestures may also     systematically to represent concrete concepts within specific
be recruited. Emblems have highly conventionalised hand         semantic domains. Second, such systematicity results in
configurations, are used for specific pragmatic purposes        shared knowledge about some manual forms across a
(Kendon, 1995, 2004), and have mental representations akin      community of speakers. As a consequence, individuals are
to those of abstract words (Gunter & Bach, 2004), so they       likely to have expectations of how a concept should be
are retrievable gestural entities that can be compared with     represented in the manual-visual modality – at least for a set
convetionsalised signs. However, other types of iconic          of referents. This has important implications for the
gestures may also be used as a basis to make judgments          perception of sign iconicity by non-signers. Non-signing
about the meaning of signs. In this study, we turn to the       adults confronted by conventionalised signs for the first
systematic iconic gestures shared in a community of             time will not make judgements about their meaning in a
speakers to investigate how overlap in form with                vacuum. Rather, they are likely to fall back on their gestural
conventionalised      signs      influences    meaning-based    knowledge to make judgments about the meaning of iconic
judgements about signs.                                         signs.
Systematicity in iconic gestures                                The Present Study
The form of iconic gestures has been assumed to be              Based on evidence that many iconic gestures are highly
variable, with their structure depending on the context in      systematic across individuals (Masson-Carro et al., 2015;
which they are used, the interlocutor, and the                  Ortega & Özyürek, 2016; Padden et al., 2013, 2015; van
communicative intent of the speaker. It has been assumed        Nispen, van de Sandt-Koenderman, Mol, & Krahmer, 2014)
that individuals tailor their gestures to the main focus of a   it is possible to assume that non-signing adults have at their
conversation and as a result they vary in form and meaning      disposal a cohort of shared gestures with specific forms and
from one conversation to the next (Müller, 2013). However,      meanings on which they may base their judgment about
recent studies have found that contrary to this received        signs. In order to test this hypothesis, we carried out two
knowledge, the iconic gestures produced by hearing adults       studies. In Study 1 we elicited pantomimes from non-
exhibit a high degree of systematicity, and tend to represent   signing adults to determine which gestures were the most
very similar forms across individuals.                          systematic across participants. Once these pantomimes were
                                                               890

selected, we compared them to signs from Sign Language of        one parameter differed from the gesture (Figure 1B). 3) No
the Netherlands (NGT) and looked for signs that overlapped       overlap (N=54): signs in which two or more parameters
in form to different degrees (full, partial, or no overlap).     differed. This category consisted of 27 signs that did not
These signs served as stimulus materials for Study 2. In this    overlap at all with the elicited gesture, plus an additional 27
study, a different group of participants were presented with     signs for which no default gesture could be established
the signs and were asked, first, to guess their meaning. After   (Figure 1C). These three groups of NGT signs (N=146)
they gave their response, they were given the correct            were the stimuli for Study 2.
translation, and then were asked to give iconicity ratings.
The prediction is that when signs map directly to their          Study 2: Open-cloze and iconicity rating
gesture non-signing adults will be more accurate at guessing     Participants
their meaning and will assign higher iconicity ratings (e.g.,    The participants of this study were a different group of 20
the gesture and the NGT sign TO-SMOKE represent a                hearing native speakers of Dutch (14 female, mean age =
person smoking a cigarette so participants are likely to be      21.8 years) with no knowledge of NGT or any other sign
very accurate and give high iconicity ratings). The expected     language. None of them took part in the pantomime
results will lend credence to the hypothesis that sign-naïve     generation task.
adults base their responses not only on their emblems
(Grosso, 1993), but also on other types of (iconic) gestures
                                                                 Stimuli
that are systematic within a community.
                                                                 The stimuli consisted of videos of the 146 NGT selected
                                                                 from Study 1 (i.e., signs with full, partial, and no overlap
                         Methodology                             with gesture). Videos were produced by a deaf signer with
Study 1: Pantomime generation task                               neutral face and without mouthings to avoid giving away
Participants                                                     cues about the meanings of the signs.
Twenty native speakers of Dutch (10 females, age range:
21-46, mean: 27 years) living in the area of Nijmegen, the
Netherlands, took part in the study.
Procedure
Participants were seated in front of a computer and were
asked to produce a gesture that conveyed exactly the same
meaning as the word on the screen. They were explicitly
told that it was not allowed to speak or to point to any object
in the room and that they could say ‘pass’ if they were
unable to generate a pantomime. Two cameras were
positioned on each side of the participant to record their
gestural productions. Trials started with a fixation cross
(500 ms) followed by the target word (4000 ms) time during
which they had to produce their gesture. After the 4000 ms
ended, the next trial began. The motivation behind this strict
timing was to elicit participants’ most intuitive response.
Participants were presented a total of 273 words.
   Pantomimes were coded according to the description
parameters proposed by Bressem (2013), which are based
on the phonological parameters handshape, location, and
movement of sign languages. Based on these features, we
looked at the gestures that exhibited the same structure
across a large number of participants. If the same gesture           Figure 1: Examples of sign-gesture pairs with different
was produced by at least 12 out of 20 participants, it was         degrees of overlap. A) TO-CUT shares all the components
considered the default gesture for that concept. These            (handshape, location, movement) between sign and gesture.
resulted in a total of 119 pantomimes that were consistent        B) TO-SAW differs in only one parameter (handshape). C)
across a large proportion of the pool of participants (mean              In LAPTOP, sign and gesture have no overlap.
number of participants producing the same pantomime:
15.14).                                                          Procedure
   These default gestures were compared to their NGT             At the beginning of each trial, an NGT sign in citation form
translation on each phonological parameter (i.e., handshape,     was presented. After the video had played in full and
location and movement) to select items with different            disappeared from the screen, a new screen was presented
degrees of form overlap. This comparison resulted in three       instructing participants to guess the meaning of the sign and
categories of signs. 1) Full overlap (N=36): gesture-sign        write its meaning in one word (typed). Participants were
pairs did not differ in any parameter (Figure 1A). 2) Partial    required to type in an answer for every item but they were
overlap (N=56): this category includes signs in which only       also allowed to skip items if they could not come up with a
                                                                891

meaning. After participants had entered an answer, a new                                          Results
screen of instructions came up. Here participants were given
                                                                      Performance on the open cloze was highly variable across
the actual meaning of the sign and were asked to judge how
                                                                      participants and items. While only nine items (6.2%) were
well the sign represented its meaning. The sentence read:
                                                                      correctly identified by all participants, half of the signs (73
‘The meaning of the sign is [translation equivalent]. How
                                                                      signs) were correctly identified by at least 25% of
much does the sign look like its meaning?’ The screen
                                                                      participants. For 26 items (17.8%), all answers were
displayed a 7-point Likert and participants were required to
                                                                      semantically related to the target meaning, suggesting that
type in their rating (1 representing the lowest similarity and
                                                                      participants were able to correctly identify some aspect of
7 the highest).
                                                                      the sign but did not make the full abstraction to the target
                                                                      meaning (e.g., sign: TO-FLY; response: bird). Regarding
Analysis                                                              the iconicity ratings, participants were able to give a
Participants gave a response for a large proportion of the            response for all items. In order to establish to what extent
signs with passes representing only 6.5% of responses.                sign-gesture overlap contributes to guessing the meaning of
Despite being instructed to write only one word, many                 a sign and assign iconicity ratings, we considered the
responses were phrases, but they were still included in the           following variables in the statistical analysis.
analysis. Based on the Dutch version of the Boston Naming             Independent variable: Degree of overlap (full, partial, and
Task (Roomer, Hoogerwerf, & Linn, 2011), answers were                 no overlap)
coded as correct and incorrect. Answers were coded as
correct if they matched exactly the expected answer (e.g.,            Dependent variables:
sign: TO-PULL; response: to pull) or if they were synonyms             i. Proportion of correct answers (open cloze)
of each other (e.g., sign: TO-PHONE; response: to ring).              ii. Proportion of semantically related answers (open cloze)
This category also included answers that were not the same
                                                                     iii. Proportion of semantically unrelated answers (open
part of speech as the target sign, but where the answer was
specific to the target concept (e.g., sign: TO-PHONE;                       cloze)
response: telephone)1. We also included phrases containing           iv. Mean iconicity rating
a verb and the correct argument depicted in the sign (e.g.,
sign: BANANA; response: to peel a banana). Responses                     A multivariate ANOVA was run to determine the
that did not fit into any of these categories were classed as         relationship between type of gestural overlap (full, partial
incorrect answers.                                                    and, no overlap) and the dependent variables of the open
   Incorrect answers were subdivided into responses that              cloze and the iconicity ratings. Using Pillai's Trace we
were semantically related and unrelated to the sign.                  found a significant overall effect of the degree of overlap, V
Semantically related answers included responses that                  = 0.541, F(6,230)=14.205, η2= .27, p < .001. The following
belonged to the same semantic domain (e.g., sign: DUCK;               sections will describe the between-subjects effects for each
response: penguin); as well as answers that were lacking the          dependent variable.
appropriate abstraction to the target concept (e.g., the sign            i) Turning to the proportion of correct answers in the
MONKEY, which re-enacts how a primate scratches the                   open cloze, tests of between-subjects revealed a significant
sides of its torso, was often labelled as scratching).                effect of degree of overlap, F(2,116)=24.168, η2= .194, p <
   The semantically unrelated category included responses             .001. Planned contrasts revealed an increase of correct
that were plainly wrong, or answers derived from visual               answers from no overlap items (M = 0.12, SE = .03) to
information of the sign, but that had no relationship with the        partial overlap (M = 0.46, SE = .05, Δ = -0.31, SEΔ = .06, p
concept (e.g., the sign MOUNTAIN describes the outline of             <.001, BCa 95% CI [-0.45, -0.18]), but no significant
two horizontal bumps, but it was often interpreted as a               difference between partial and full overlap (M = 0.61, SE =
camel).                                                               .06, p = .209). The proportion of correctly identified items
   For the open cloze, the proportions of correct,                    was thus higher for items with full and partial overlap than
semantically related, and semantically unrelated answers              for those with no overlap (Figure 2).
were calculated for every item, thereby collapsing across                ii) Regarding the proportion of incorrect answers that
participants' answers. Missing answers were discarded for             were semantically related to the sign, a test of between-
this analysis and did not contribute to the proportions. For          subjects effects revealed no significant effect of the degree
the iconicity ratings, all values were averaged across                of overlap between gestures and signs, p = .305. That is,
participants to obtain the mean ratings for each of the 146           wrong answers in the open cloze were equally distributed
signs.                                                                across the three types of signs (full, partial, and no overlap).
                                                                         iii) Turning to the proportion of incorrect answers that
                                                                      were semantically unrelated to the target concept, tests of
                                                                      between-subjects effects revealed a significant effect of the
                                                                      degree of overlap, F(2,116)=26.909, η2= .317, p < .001.
                                                                      Signs with no overlap were significantly less likely to be
   1
     In Dutch, verb/noun distinctions are differentiated through      guessed correctly (M =0.75, SE = .05) than those with
affixes to the root. For example, telefoneren (to phone) is a verb    partial overlap (M = 0.41, SE = .05, Δ = 0.34, BCa 95% CI
and telefoon (telephone) is a noun. The English translations do not   [0.21, 0.47], p < .001). Signs with full overlap were
reflect that participants responded with a single word.
                                                                    892

significantly more likely to be guessed accurately than signs   partial overlap. This suggests that despite their slight
with partial overlap (M = 0.21, SE = .04, Δ = 0.192, BCa        structural differences, these two types of signs bear enough
95% CI [0.05, 0.33], p =.009). In other words, the less         resemblance to participants’ gestures to make an association
similar a sign is from a gesture, the more likely it is to be   between them.
guessed inaccurately.                                              Signs and gestures share the same physical constraints to
  iv) When we look at iconicity ratings, we found an            express a concept in the manual modality, with the referent
association with the degree of overlap between sign and         shaping to some extent the features than can be expressed
gesture F(2,111.836)=54.13, η2=.483, p < .001. Planned          with the hands (Masson-Carro et al., 2015). It is therefore
contrasts revealed a significant increase of mean iconicity     not surprising that signs and gestures converge in the
ratings from no overlap (M = 3.18, SE = 0.22) to partial        strategies to depict the visual characteristics of many
overlap (M = 5.34, SE = .17, Δ = -2.13, BCa 95% CI [-           concepts. If signs and gestures have similar structures for
2.617, -1.642], p < .001) but not from partial to full overlap  some concepts, it means that deaf and hearing adults share
(M = 5.92, SE = .15, p = .07). These results suggest that       conceptual knowledge about these concepts (i.e., visual,
when signs have greater overlap in form with their gestures     semantic, perceptual, sensorimotor representations). When
they perceive signs as more iconic (see Figure 3).              there is sufficient overlap between signs and gesture, non-
                                                                signing adults may tap into these schemas to make
                                                                judgements about the meaning of signs. These findings also
                                                                relate to research showing that humans – as well as other
                                                                primates – understand and evaluate the correctness of
                                                                others’ actions through the activation of brain regions
                                                                engaged when they perform the same actions themselves
                                                                (Koelewijn, van Schie, Bekkering, Oostenveld, & Jensen,
                                                                2008; Rizzolatti, Fadiga, Gallese, & Fogassi, 1996).
                                                                   The errors produced by participants, however, clearly
                                                                show that if gesture and sign mismatch, or if the meaning of
                                                                signs departs slightly from the features they depict,
                                                                participants are unable to estimate accurately the meaning of
                                                                a sign. As a result, they will also rate the sign as less iconic.
                                                                Non-signers have a very limited scope to assign meanings to
                                                                signs and seem to be inclined to describe only what is
    Figure 2: Mean proportion of correctly guessed answers
                                                                directly encoded in them. While they are capable of
     as a function of gesture overlap with the target sign
                                                                extracting some visual information from the signs they often
                                                                fail to respond with the correct metonymic associate (e.g.,
                                                                they respond scratch instead of monkey). This goes to show
                                                                that despite their similarities, sign languages have
                                                                established linguistic conventions not shared with gestures
                                                                and thus are inaccessible to non-signing adults.
                                                                   This study adds to the body of research investigating how
                                                                modality shapes linguistic/communicative structures
                                                                (Perniss et al., 2015).
                                                                                      Acknowledgments
                                                                This work was supported by a Veni grant by the
                                                                Netherlands Organisation for Scientific Research (NWO)
                                                                awarded to the first author. We would like to thank the
                                                                members of the Multimodal Language and Cognition lab at
    Figure 3: Mean iconicity ratings as a function of gesture   Radboud University for their helpful comments, in
                 overlap with the target sign                   particular to Swen Schreiter, Linda Drijvers, and James
                                                                Trujillo for their support.
                          Discussion
                                                                                          References
These data expands on previous research by showing that
the gestural repertoire of non-signing adults is recruited to   Cormier, K., Schembri, A., & Woll, B. (2013). Pronouns
make judgments about the meaning of lexical signs. We                  and pointing in sign languages. Lingua, 137, 230–247.
showed that signs that overlap in form with their gestures             http://doi.org/10.1016/j.lingua.2013.09.010
are guessed more accurately and are judged as more iconic.      Cuxac, C. (1999). French sign language: proposition of a
The proportion of correct answers and iconicity ratings were           structural explanation by iconicity. Gesture-Based
higher for signs that overlapped in form with gestures, but            Communication in Human-Computer, 1739(1), 165–
there was no additional improvement between full and                   184.
                                                                Goldin-Meadow, S., & Brentari, D. (2015). Gesture, sign
                                                               893

      and language: The coming of age of sign language                Cognitive Science Society (CogSci 2016) (pp. 1182–
      and gesture studies. Behavioral and Brain Sciences,             1187). Austin, TX.: Cognitive Science Society, Inc.
      8(4),                                              1–82.  Padden, C., Hwang, S.-O., Lepic, R., & Seegers, S. (2015).
      http://doi.org/10.1017/S0140525X15001247.                       Tools for Language: Patterned Iconicity in Sign
Griffith, P. L., Robinson, J. H., & Panagos, J. M. (1981).            Language Nouns and Verbs. Topics in Cognitive
      Perception of iconicity in American sign language by            Science,                   7(1),                  81–94.
      hearing and deaf subjects. The Journal of Speech and            http://doi.org/10.1111/tops.12121
      Hearing          Disorders,       46(4),        388–97.   Padden, C., Meir, I., Hwang, S.-O., Lepic, R., Seegers, S., &
      http://doi.org/dx.doi.org/10.1044/jshd.4604.388                 Sampson, T. (2013). Patterned iconicity in sign
Grosso, B. (1993). Iconicity and Arbitrariness in Italian             language lexicons. Gesture, 13(3), 287–305.
      Sign Language: An Experimental Study. University of       Perniss, P., Özyürek, A., & Morgan, G. (2015). The
      Padua, Italy.                                                   influence of the visual modality on language structure
Gunter, T. C., & Bach, P. (2004). Communicating hands:                and conventionalization: Insights from sign language
      ERPs elicited by meaningful symbolic hand postures.             and gesture. Topics in Cognitive Science, 7(Special
      Neuroscience Letters, 372(1), 52–6.                             Issue), 2–11.
Kelly, S. D., Creigh, P., & Bartolotti, J. (2010). Integrating  Perniss, P., Thompson, R. L., & Vigliocco, G. (2010).
      speech and iconic gestures in a Stroop-like task:               Iconicity as a general property of language: evidence
      evidence for automatic processing. Journal of                   from spoken and signed languages. Frontiers in
      Cognitive       Neuroscience,      22(4),      683–694.         Psychology,              1(227),            1664–1678.
      http://doi.org/10.1162/jocn.2009.21254                          http://doi.org/dx.doi.org/10.3389/fpsyg.2010.00227
Kendon, A. (1995). Gestures as illocutionary and discourse      Pietrandrea, P. (2002). Iconicity and arbitrariness in Italian
      structure markers in Southern Italian conversation.             Sign Language. Sign Language Studies, 2(3), 296–
      Journal      of    Pragmatics,      23(3),     247–279.         321. http://doi.org/dx.doi.org/10.1353/sls.2002.0012
      http://doi.org/dx.doi.org/10.1016/0378-                   Pizzuto, E., & Volterra, V. (2000). Iconicity and
      2166(94)00037-f                                                 transparency in Sign Languages: A cross-linguistic
Kendon, A. (2004). Gesture: Visible action as utterance.              cross-cultural view. In K. Emmorey & H. L. Lane
      Cambridge: Cambridge University Press.                          (Eds.), The signs of language revisited: An anthology
Klima, E., & Bellugi, U. (1979). The Signs of Language.               to Honor Ursula Bellugi and Edward Klima (pp. 229–
      Harvard: Harvard University Press.                              250). Mahwah, N. J.: Lawrence Erlbaum Associates.
Koelewijn, T., van Schie, H. T., Bekkering, H., Oostenveld,     Quinto-Pozos, D., & Parrill, F. (2015). Signers and Co-
      R., & Jensen, O. (2008). Motor-cortical beta                    speech Gesturers Adopt Similar Strategies for
      oscillations are modulated by correctness of observed           Portraying Viewpoint in Narratives. Topics in
      action.       NeuroImage,         40(2),       767–775.         Cognitive      Science,    7(Special    Issue),    1–23.
      http://doi.org/10.1016/j.neuroimage.2007.12.018                 http://doi.org/10.1111/tops.12120
Masson-Carro, I., Goudbeek, M., & Krahmer, E. (2015).           Rizzolatti, G., Fadiga, L., Gallese, V., & Fogassi, L. (1996).
      Can you handle this? The impact of object affordances           Premotor cortex and the recognition of motor actions.
      on how co-speech gestures are produced. Language,               Cognitive      Brain    Research,     3(2),    131–141.
      Cognition         and        Neuroscience,         1–11.        http://doi.org/10.1016/0926-6410(95)00038-0
      http://doi.org/10.1080/23273798.2015.1108448              Roomer, E. K., Hoogerwerf, A. C., & Linn, D. E. (2011).
McNeill, D. (1992). Hand and mind: What gestures reveal               Boston benoem taak 2011. Utrecht.
      about thought. Chicago: University of Chicago Press.      Safar, J., & Petatillo, R. (n.d.). Strategies of noun-verb
Müller, C. (2013). Gestural modes of representation as                distinction in Yucatec Maya Sign Languages. In O. Le
      techniques of depcition. In C. Müller, A. Cienki, S.            Guen, J. Safar, & M. Coppola (Eds.), Emerging Sign
      Ladewig, D. McNeill, & J. Bressem (Eds.), Body -                Languages of the Americas. Sign Language Typology
      Language - Communication: An International                      Series. Berlin: Mouton de Gruyter.
      Handbook on Multimodality in Human Interaction            Sandler, W., & Lillo-Martin, D. (2006). Sign Language and
      (pp. 1687–1701). Berlin: De Gruyter Mouton.                     Linguistic Universals. Cambridge: Cambridge
Ortega, G., & Ozyürek, A. (2016). Generalisable patterns of           University Press.
      gesture     distinguish    semantic     categories    in  van Nispen, K., van de Sandt-Koenderman, M., Mol, L., &
      communication without language. In A. Papafragou,               Krahmer, E. (2014). Pantomime Strategies: On
      D. Grodner, J. Mirman, & J. Trueswell (Eds.),                   Regularities in How People Translate Mental
      Proceedings of the 38th Annual Meeting of the                   Representations into the Gesture Modality. In
      Cognitive Science Society (pp. 1182–1187). Austin,              Proceedings of the 36th Annual Conference of the
      TX: Cognitive Science Society, Inc.                             Cognitive Science Society (CogSci 2014) (pp. 3020–
Ortega, G., & Özyürek, A. (2016). Generalisable patterns of           3026). Austin, TX: Cognitive Science Society, Inc.
      gesture     distinguish    semantic     categories    in
      communication without language. In A. Papafragou,
      D. Grodner, D. Mirman, & J. Trueswell (Eds.),
      Proceedings of the 38th Annual Meeting of the
                                                               894

