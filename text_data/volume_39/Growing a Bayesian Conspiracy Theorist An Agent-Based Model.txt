                Growing a Bayesian Conspiracy Theorist: An Agent-Based Model
                                          Jens Koed Madsen (jens.madsen@ouce.ox.ac.uk)
                                     School of Geography and the Environment, University of Oxford
                                            OX1 3QY, South Parks Road, Oxford, United Kingdom
                                                        Orcid: 0000-0003-2405-8496
                                           Richard Bailey (richard.bailey@ouce.ox.ac.uk)
                                     School of Geography and the Environment, University of Oxford
                                           OX1 3QY, South Parks Road, Oxford, United Kingdom
                                                Toby D. Pilditch (t.pilditch@ucl.ac.uk)
                                  Department of Experimental Psychology, University College London
                                            WC1E 6BT, Gower Street, London, United Kingdom
                               Abstract                               2008) where every agent is rational (here, Bayesian) and
  Conspiracy theories cover topics from politicians to world
                                                                      where information is potentially available to challenge the
  events. Frequently, proponents of conspiracies hold these           viewpoint of the agent.
  beliefs strongly despite available evidence that may challenge         Specifically, we are interested in exploring the possibility
  or disprove them. Therefore, conspiratorial reasoning has           of generating conspiratorial beliefs. That is, beliefs that are
  often been described as illegitimate or flawed. In the paper,       maintained despite being objectively false and there being
  we explore the possibility of growing a rational (Bayesian)         available evidence to challenge or disprove the theory in
  conspiracy theorist through an Agent-Based Model. The agent         question. Proponents of such beliefs frequently hold these
  has reasonable constraints on access to the total information
  as well its access to the global population.                        positions strongly. We explore whether it is possible to
    The model shows that network structures are central to            strengthen confidence in objectively mistaken beliefs
  maintain objectively mistaken beliefs. Increasing the size of       through a rational process given imperfect knowledge about
  the available network yielded increased confidence in               the world. Rather than assuming illegitimate updating
  mistaken beliefs and subsequent network pruning, allowing           processes or special cognitive functionality, the model tests
  for belief purism. Rather than ameliorating and correcting          if, in principle, a Bayesian conspiracy theorist can emerge
  mistaken beliefs (where agents move toward the correct
                                                                      and be maintained. That is, the model explores whether or
  mean), large networks appear to maintain and strengthen
  them. As such, large networks may increase the potential for        not individual differences are a necessary requirement for
  belief polarization, extreme beliefs, and conspiratorial            the emergence and maintenance of extreme beliefs.
  thinking – even amongst Bayesian agents.                               The Burton quote at the top of the introduction can be
                                                                      seen as foundational for the paper. It suggests that beliefs
  Keywords: Conspiratorial thinking; Extreme beliefs; Agent-
  Based Models; Bayesian updating                                     can be generated and maintained as a fragment of a larger,
                                                                      and often very different, picture. Further, it intimates that
                          Introduction                                humans generate inferences about the world on the back of
                                                                      the evidence available to us at any given time in our lives.
  Truth is the shattered mirror strewn in myriad bits; while each
                                                                      This information may come through first-hand experience or
                believe his little bit the whole to own
        Richard Burton (The Kasîdah of Hâjî Abdû El-Yezdî)            through other sources such as parents, peers, media outlets,
                                                                      and experts.
In recent years, scientists, scholars, and commentators have             In order to set the scene for the Agent-Based Model, we
remarked upon the apparent rise of epistemic echo chambers            briefly consider how conspiratorial thinking has previously
(see e.g., Bakshy et al., 2016) and increasing political              been approached in the literature.
polarization. Echo chambers refer to communities, online or
otherwise, that interact predominantly with themselves and                             Conspiratorial thinking
who rarely, if ever, seek information aside from the                     Conspiracy theories can be loosely defined as beliefs that
information available within the chamber. Whether                     are held strongly when evidence is broadly available to
endogenously created (such as cults) or exogenously created           challenge or entirely refute the theory. Yet, proponents
(such as living on an island with no contact to the outside           maintain (and might even strengthen) their belief in the
world), the emergence and maintenance of epistemically                theory despite the availability of this evidence. However, in
enclosed systems and their consequences is interesting and            order to adequately simulate emerging conspiracy theories,
worth studying. The current paper explores the possibility of         we need to employ a more stringent definition of
generating, maintaining and strengthening encapsulated                conspiratorial thinking.
belief communities through an Agent-Based Model (Gilbert,
                                                                  2657

   According to Barkun (2003), conspiracy theories are               2012), a Bayesian model of appeals to authority (e.g. Hahn
characterized by three traits. First, conspiracy theories            et al., 209; Harris et al., 2015), and skepticism in climate
operate under the assumption that nothing happens by                 change (Cook & Lewandoswky, 2016). Further, Bayesian
accident. From a cognitive perspective, this may be                  agents represent a rational process of integrating new
described as causal oversensitivity where the reasoner               information with prior beliefs pertaining to that hypthesis.
generates causal links between disparate and supposedly              For this reason, Bayesian agents have been used previously
separate pieces of information, leading to over-connection.          to explore belief diffusion in networks (see e.g. Jern et al.,
Second, Barkun argues that for conspiracy theorists, nothing         2009; Olsson, 2013; Denrell & Le Mens, 2017).
is really what it appears to be on the surface (i.e. the ‘real’         While the current work builds on similar Bayesian
causal mechanisms between pieces of information is                   accounts of belief updating, we provide a novel contribution
covered up(?) by any official story). This element, too,             to the field by implementing a computational, Agent-Based
suggests a cognitive agent who over-weights and over-                Model that allows for interaction between agents across
generates causal links between independent pieces of                 time.
information. For example, some proponents of the moon                   For the purpose of this paper, we take conspiratorial
landing conspiracy theory believes the director of A Space           thinking to be strongly held beliefs that depart from the
Oddysey: 2001, Stanley Kubrick, to be involved in                    objective mean where evidence is available to challenge or
producing faked photography because Kubrick hired crew               refute the theory. Barkun and Birchall argue that these
for 2001 who used to work for NASA (Frederick Orway and              beliefs arise from mistaken or flawed heuristics and/or
harry Lange). Finally, Barkun argues that conspiracy                 illegitimate reasoning processes that bias proponents of
theorists tend to believe things to be highly connected. To          conspiracy theories toward connectivity, attribution of
this end, Barkun argues that conspiracy theories eventually          hidden intentions and over-generation of causal structures.
become enclosed systems that are falsifiable if confronted           Further, Grimes (2016) argues that conspiratorial beliefs are
with additional evidence and therefore “a matter of faith            untenable with larger network structures, as the available
rather than proof”. Presumably, this entails that conspiracy         information to challenge erroneous views increases. As
theorists might stop seeking new information and instead             discussed below, there are some potential challenges for
assume their beliefs to be a priori true. As evident from            conspiracy accounts that assume special cognitive functions
these definitions, the operationalizing of conspiracy theories       such as oversensitivity toward causal connections as the
usually involves special cognitive make-up and a heuristic           default cognitive foundation.
process that treat information related to the conspiracy
theory as qualitatively different from ‘normal’ belief                        Challenges for traditional accounts
updating. The current model explores whether these are               The traditional perspectives on conspiratorial thinking may
valid assumptions.                                                   be challenged on at least two grounds. First, it is potentially
   Indeed, Birchall (2006) describes conspiratorial thinking         problematic to ascribe different cognitive functions to the
as illegitimate updating and belief maintenance (as opposed          emergence of conspiratorial thinking for two reasons. For
to normative, legitimate reasoning). In general,                     one, it is unclear whether this type of reasoning would
conspiratorial thinking is typically conceived as an                 permeate all beliefs held by that individual (e.g. would a
abnormal and potentially fallacious (or illegitimate)                conspiracy theorist also be prone to over-generate causal
reasoning process, which relies heavily on cognitively               structures in billiards or snooker). If it were not systemic, it
biased heuristics such as over-generation of causal links,           would (insufficiently) appear to be a post hoc account of a
erroneous attribution of motives, and mistaken perception of         particular belief that happens to exhibit such properties. For
interconnectivity. Commonly, these conspiratorial thinking           another, it would not represent a process account of
accounts assume conspiracies are a product of mistaken or            conspiratorial thinking. Rather, it would assume differences
misguided reasoning.                                                 and apply these to arrive at the conclusion. Instead, we
   In this paper, we provide a proof of concept that                 explore whether it is possible to generate objectively
conspiratorial thinking can emerge from Bayesian rational            mistaken beliefs from the same cognitive processes that
paradigms given access to a subset of evidence and the               generate objectively true beliefs. Both of these would
possibility of interacting with other like-minded agents. As         remove the expectancy of abnormality on the part of the
will be argued later, we believe both of these assumptions to        conspiracy theorist.
be realistic and grounded in psychological findings. As will            Second, traditional accounts tend to focus on the cognitive
be explained further in the paper, we show that                      function of the isolated individual, rather than on systemic
conspiratorial agents do not require special cognitive               belief diffusion as a result of interactions with other people.
abilities or predispositions in order to be supremely                As discussed in the following, studies and simulations have
confident in their (objectively mistaken) belief. This               shown that aggregate behavioral patterns might not be
approach is reminiscent of work conceptualizing supposed             reducible to the components in isolation if the components
reasoning flaws through cognitively reasonable processes.            can interact with each other in meaningful ways (see e.g.
This work includes, but is not limited to, Bayesian accounts         Johnson, 2001; Ball, 2005) given complex and dynamic
of argument fallacies (e.g., Corner et al., 2011; Harris et al.,     environments (Johnson, 2009). Faced with the problem of
                                                                 2658

epistemic isolation, we apply Agent-Based Modeling to              that they might regrow or migrate. Further, patches may
explore the potential of growing a Bayesian conspiracy             facilitate or restrict movement of agents in the simulated
theorist without adding special cognitive functions to the         space. The patches provide the foundational and potentially
agent in question.                                                 dynamic environment in which the agents live and act. In
                                                                   the model we present, the environment restricts interaction
                 Agent-Based Modeling                              between agents if the search potential is low.
In order to circumvent the problems caused by traditional             Compared with traditional methods, ABMs are capable of
individual-based accounts of cognition, we employ Agent-           simulating dynamic and adaptive decision-making in
Based Modeling, which allows for simulations of belief             changeable environments (Miller & Page, 2007). This
networks populated by Bayesian agents. This further allows         allows for agents to self-organize without hard-wiring
for introduction of heterogeneity, as will be discussed later      expected aggregate behavioral patterns such as emergent
(here, initial sampling allows agents to gather and evaluate       echo chambers. Rather, ABMs allow for these properties to
data individually, which provides heterogeneous priors).           emerge, or, in the terminology of Epstein and Axtell (1996),
Agent-Based Models (ABMs) are computer simulated                   to grow. ABMs further allow for agent and environmental
multi-agent systems that describe the behavior of and              heterogeneity (i.e. agents with different cognitive
interactions between individual agents, who operate in             capabilities).
synthetic environments (Gilbert, 2008; Bandini et al., 2009).
Agents are encoded on a computational basis, and may                     Growing a Bayesian conspiracy theorist
implement and explore models of cognitive function. They           The aim of the current model is to test a proof of principle
allow for complex, dynamic and adaptive systems to emerge          that conspiracy theorists can emerge through entirely
through interactions between agents and with the                   rational processes without providing any special cognitive
environment as well as across time (Miller & Page, 2007).          functions, heuristic strategies, or access to unique
ABMs may be described in terms of their three fundamental          information. In order to do so, we generate an Agent-Based
components: Agents, Links, and Patches.                            Model where agents can sample information, communicate
   Agents are the nodes representing the active cognitive          with one another, and update their beliefs about the world.
entities of the system. They can make decisions and make              Given this initial proof of concept, we simplify the
use of information in any way that is formally expressible.        epistemic challenge and consider only one abstract belief.
These functions include, but are in no way limited to, utility     The true probability of the Gaussian distribution from which
valuations, Bayesian belief inferences, stock market               the agents sample is 0.5. The standard deviation can be
engagement, and so forth. The agents may reproduce (e.g.           manipulated to represent greater or lesser noise in the
give birth to a new agent), move around the simulated              information environment. In the present paper, the standard
space, and make new (and potentially more relevant)                deviation is set to 0.2. For the sake of understanding, the
decisions as they learn more about the environment. In order       probability may represent the belief in the fairness of a coin.
to engage with the environment, agents will have specified         If the coin is fair, the distribution of tosses is trivially 50-50
rules for agent-environment interactions such as fishing,          between heads and tails. However, if the coin is not fair, the
purchasing a house, moving around the simulated space and          distribution can be skewed in the direction of either heads or
so forth. These behaviors and inferences may yield dynamic         tails. Understood in this way, the agents try to understand if
and adaptive aggregate behavioral patterns. For example, if        they are in a world in which the coin is fair (uncovering, as
all agents harvest simultaneously, Tragedy of the Commons          it were, the true, underlying probabilities) or if they are in a
type problems (Ostrom, 2012) can emerge. In the present            world where the coin is rigged to either side (arriving at an
model, we allow for Bayesian belief updating as the agents         objectively mistaken belief).
encounter new information or talk with other agents via               If agents are able to generate, maintain and possibly
links.                                                             strengthen a mistaken belief in the epistemic state of the
   Links represent rules for possible interactions between         belief, the agent will have exhibited conspiratorial traits, as
agents. Links can be any interactivity that can be expressed       this fulfills the criterion for the definition in the above: a
formally. The interaction may be direct (e.g. communication        potentially strongly held, yet objectively mistaken belief,
between two agents or sales structure between agents, see          availability of information to challenge or refute the theory,
Epstein & Axtell, 1996) or indirect (e.g. social attraction or     and access to that information. The literature review
repulsion or emotional feedback, see Schelling, 2006;              uncovered two central positions that we explore here. One,
Epstein, 2013). Interactions allow for feedback loops to           we explore Grimes’ (2016) argument that conspiratorial
emerge, which in turn may generate aggregate behavioral            thinking is untenable in a large network structure. If this is
patterns that are irreducible to the components in isolation.      true, we should see a global regression towards the
   Patches represent the simulated environment in which            objectively true mean given larger networks (that is, fewer
agents exist. They can have any and all properties that are        agents who believe they are in a rigged coin world). Two,
formally describable. If consumable (such as grass for             we explore Barkun and Birchall’s arguments that
sheep, fish for fishers), they may give the agent energy,          conspiratorial thinking relies on illegitimate reasoning and
money, or other affordances. Patches may be dynamic such           biased heuristics. As will be described below, the agents in
                                                               2659

the model are perfect Bayesian reasoners. If conspiratorial           are relatively tolerant and will engage in conversation with
thinking requires special cognitive properties, we should not         any other agent who is within ± 1.5 standard deviations of
expect the Bayesian agents to generate strong and mistaken            its own perception of the world. Given Gaussian
beliefs about the world. The model implements six key                 distributions, this means that the agent will speak to 86.6%
elements: generation of prior beliefs, constrained search,            of people within its belief distribution. Thus, they are
network generation, communication between agents, belief              willing to talk to and integrate information from agents who
updating, and network pruning.                                        have different viewpoints than their own. However, if they
     In order to generate a subjective prior belief, agents are       are confident in their belief, they will engage with less
born onto the world and sample randomly generated data                diverging viewpoints, as their probability density narrows.
from a Gaussian distribution (µ = 0.5, σ = 0.2). In a                 As an analogy, this means that an agent might be willing to
frequentist manner, these are used to calculate a perceived           discuss political questions with people with different points
mean and probability density. The sampling represents the             of view, but would refuse to engage in discussion with
worldview of each particular agent before they are able to            people who believe that fair coin-flips are 60-40 rather than
communicate with other agents.                                        50-50 in cases where they are absolutely certain about the
  Having generated a prior belief for each agent (and thus            latter and less certain about the former.
introduced sampling heterogeneity), the model relies on four             In sum, the agent is born into the world by sampling
additional assumptions and mechanisms. First, agents                  randomly generated pieces of information related to the
cannot sample all available data in the simulated world. This         hypothesis in question. This informs the mean and standard
means that they do not have access to all data sampling that          deviation of their prior. Second, the agents generate
other agents have encountered unless they communicate                 networks with other agents within their network radius
with the other agent in order to learn the beliefs of that            (which may be limited or encompass the full system).
agent. As such, agents do not have perfect and complete               Having set up the model, the agents will communicate
knowledge about the world in which they live. We believe              freely and honestly (i.e. representing their belief in the
this is a reasonable assumption, as humans do not have                hypothesis to the best of their ability), which enables
perfect knowledge in real life. Second, although all other            Bayesian belief updating. Agents will maintain
agents are hypothetically available, agents cannot                    communication networks with other agents who are within
communicate to every other agent in the simulated world.              1.5 standard deviation of their subjective understanding of
Rather, each agent randomly generates the amount of                   the world (i.e. their belief in the hypothesis). If agents
possible communication links. Like the first assumption, we           within the network fall outside of those boundaries, the
believe this is a reasonable assumption, as humans in the             agent deactivates the network contact with that particular
real world cannot communicate with every other person on              agent. If agents cannot find any suitable agents within their
the planet, but has to settle for a subset of all living persons.     range, they decrease confidence (simulating negative
  Third, in order to make the agents rational, they update            feedback) and thus expand acceptable search parameters for
their beliefs about the world in a Bayesian manner.                   the following tick. This allows for dynamic network pruning
Bayesian updating represents the rational integration of              (Ngampruetikorn & Stephens, 2015).
prior beliefs with new evidence to generate posterior belief
in the hypothesis. This approach has been applied to a host           Main findings: Limited and extended networks
of related phenomena such as argumentation (Hahn &                    We implemented the above model in NetLogo (5.2.1) and
Oaksford, 2006; 2007), source credibility (Bovens and                 manipulated the model in terms of the size of the network.
Hartmann, 2003; Harris et al., 2015), and reasoning and               For limited networks, agents had a search range of 10 of 100
decision-making (Oaksford & Chater, 2007). The                        (as a product of their geographical location). Extended
integration is formally expressed through Bayes’ theorem              networks, on the other hand, had a search range of 80 of
                                                                      100. Agents could connect to and sample randomly from
                                                                      other agents within agent search range who fall within their
                                                                      network criteria. Figs 1a and 1b show the extent to which
where p(h|e) denotes the posterior belief in the hypothesis           search capability influences network generation.
(h) given the evidence (e). As such, agents treat each new
encounter as a data point to be integrated within their
subjective probability density function. Bayesian updating
ensures that the agents are fully rational in their belief               a                                                         b
revision when encountering new evidence.                                     Figures 1a and 1b: Limited and extensive networks
  Finally, several studies on confirmation bias, selectivity
bias, and in-group behavior strongly suggest that agents are          The overall belief structure did not differ significantly
not entirely stochastic and non-directed in their information         between limited and extended networks. Some, but not all
search. Taking inspiration from segregation studies (e.g.,            agents regressed towards toward the mean while some
Schelling, 2006), we introduce a mild preference for people           agents retained their objectively mistaken belief (see Fig. 2a
who remotely share their beliefs about the world. The agents          and 2b, which are histograms where number of believers are
                                                                  2660

on the y axis and agent belief is on the x axis), we observe        gleaned through interactions with other agents.
differences in belief confidence. As seen in Figs. 3a and 3b,       Consequently, by limiting the amount of other agents with
extended networks allowed for interactions with                     whom an agent can engage, the model naturally also limits
increasingly like-minded agents, which in turn increased            the access to available information. Principles one and two
belief confidence. This is true both for agents who obtain          are concerned with the degree to which the agent can
objectively true and false beliefs. As agents become                sample information and learn about the world. Three, agents
increasingly confident, their probability density narrows,          search for and interact with other agents on the basis of their
meaning that they are less willing to engage with agents            current worldview. They are willing to communicate with
with differing beliefs. Extended networks allow them to             most other agents, but avoid other agents with whom they
form and maintain contact with agents who share their               radically disagree about the nature of the world.
specific beliefs such that they increase their confidence in
that particular view of the world. This means purification of       The Rise of Echo Chambers
beliefs and purification of networks, i.e. the emergence of         Together, these three (we believe reasonable) assumptions
epistemic echo chambers.                                            show that larger networks do not yield belief amelioration
                                                                    (as was postulated by some theoreticians who believed the
                                                                    Internet to facilitate greater communication between people
                                                                    and thereby allow a global regression towards the mean).
                                                                    Rather, the model shows that extended networks, given
                                                                    plausible constraints to exposure, lead to the growth of echo
                                                                    chambers and eventual belief purism, whereby agents
  a                                                          b      increasingly discard those who do not share their specific
   Figures 2a and 2b: Limited and extended belief structures        beliefs about the world.
                                                                       One might compare this increasing belief purism to
                                                                    development of political ideologies. In a limited network
                                                                    structure (e.g., a small village), the model suggests that left-
                                                                    leaning voters are willing to communicate with other left-
                                                                    leaning voters (and some right-winged voters depending on
                                                                    the mean and probability density function of the specific
   a                                                         b      voter, mutatis mutandis for right-winged voters). However,
   Figures 3a and 3b: Limited and extended confidence (0-1)         in an extended network structure (such as a metropolis or
                                                                    Facebook), the model suggests that voters will have access
Overall, the model shows that fully rational agents can             to other voters who have more similar worldviews. This
maintain and potentially strengthen objectively mistaken            allows for emergence of political echo chambers where
beliefs. Further, given a mild preference for interaction with      extreme voters have access to other extreme voters. From
like-minded agents, we observe the rise echo chambers.              this, greater belief confidence grows and network pruning
This effect is strengthened with the size of the network.           increases, as belief purism emerges. We therefore expect
Rather than making extreme beliefs untenable as predicted           increases in network structures will facilitate rather than
by Grimes, we show that large networks, here quantified in          hinder belief extremism and confidence in worldviews.
terms of the number of reachable agents for any given agent,           The model presented in the current paper allows for this
can engender extreme belief maintenance and belief purism.          dynamic adaption. In the beginning, agents cluster around
                                                                    people with whom they share general beliefs about the
         Discussion and concluding remarks                          world. However, as they increase in confidence, their
                                                                    probability densities narrow, meaning that fewer agents will
The Agent-Based Model in the paper provides a theoretical           fit within the ± 1.5 standard deviations of the perceived
proof of concept that a Bayesian agent can become an                mean. As the agent becomes increasingly confident in its
ardent conspiracy theorist under three main assumptions.            own reading of the world, it will be decreasingly inclined to
One, the agent does not have perfect and full access to all         engage with agents who entertain different viewpoints. This
available information that exists in the world, but can only        allows for belief communities to fracture and radical and
sample a sub-set of that information. This means that the           supremely confident cells to emerge. The emergent echo
agent does not rely on perfect knowledge of the system.             chambers function as cyclical maintenance of a peculiar
Depending on the practical conceptualization of information         belief.
accessibility, the agent may have access to very limited or            This finding is interesting because larger networks did not
more extended amounts of information. Two, the agent                yield belief amelioration, but rather belief solidification. It
cannot talk to every other person in the world, but can only        opens up for a novel way to approach and model epistemic
talk to a sub-set of all existing agents. Similar to assumption     communities that maintain strong beliefs despite available
one, this means the agent cannot converse with all other            data challenging their beliefs (e.g., creationists, climate
agents and learn their subjective access to information. In         skeptics, and radicalized or discriminatory beliefs).
the current model, information after prior sampling is
                                                                2661

                                                                   Denrell, J. & Le Mens, G. (2017) Information Sampling,
Emergence of reasonably mistaken views                               Belief Synchronization, and Collective Illusions,
Central to the model, the agents do not have full and perfect        Management Science 63 (2), 528-547
knowledge of the world and can only talk to a sub-set of           Epstein, J. (2013) Agent_Zero: Toward Neurocognitive
other existing humans. Given the fact that agents update             foundations For Generative Social Science, Princeton
their beliefs in a Bayesian manner, their cognitive system           University Press
can be described as rational and entirely reasonable. Yet,         Epstein, J. & Axtell, R. (1996) Growing Artificial Societies:
given incomplete access to data and given the network                Social Science from the Bottom Up, MIT Press
properties, the model shows that the agents can become             Gilbert, N. (2008) Agent-Based Models, SAGE Publications
entirely confident in objectively mistaken views. As such,         Grimes, D. R. (2016) On the Viability of Conspiratorial
we show that extreme beliefs such as conspiracies could              Beliefs, PLoS One 11 (1), e0147905
emerge through entirely rational processes. While this does        Hahn, U., Harris, A. J. L., & Corner, A. (2009). Argument
not preclude heuristic strategies or special cognitive               content and argument source: An exploration. Informal
functions, the model shows that these are not necessary for          Logic, 29, 337-367.
strongly held mistaken beliefs to emerge. Aside from               Hahn, U., & Oaksford, M. (2006) A normative theory of
emerging, mistaken beliefs are also able to survive (and             argument strength, Informal Logic 26, 1-24
even strengthen) in such an environment rather than being          Hahn, U., & Oaksford, M. (2007) The rationality of
swallowed by mainstream beliefs.                                     informal argumentation: A Bayesian approach to
   Further, agents had a mild preference for communicating           reasoning fallacies, Psychological Review 114, 704-732
with like-minded agents. Rather than making extreme                Harris, A. J. L., Hahn, U., Madsen, J. K., & Hsu, A. S.
beliefs untenable, the model suggests that increasing the size       (2015). The Appeal to Expert Opinion: Quantitative
of the network intensifies the process of radicalization and         support for a Bayesian Network Approach. Cognitive
augments the confidence even in an objectively mistaken              Science 40, 1496-1533
belief. In the age of the Internet, this finding is worth          Harris, A., Hsu, A. & Madsen, J. K. (2012) Because Hitler
considering seriously and exploring further                          did it! Quantitative tests of Bayesian argumentation using
   In conclusion, we have provided a proof of concept that           Ad Hominem, Thinking & Reasoning 18 (3), 311-343
shows the impact of network structures in generating and           Jern, A., Chang, K-M. & Kemp, C. (2009) Bayesian belief
maintaining extreme beliefs such as conspiratorial thinking.         polarization, Advances in Neural Information Processing
A Bayesian agent can generate and even increase its                  Systems 22 (NIPS 2009)
confidence in objectively mistaken beliefs.                        Johnson, N. (2009) Simply Complexity: A Clear Guide to
                                                                     Complexity Theory, Oneworld Publications
                        References                                 Johnson, S. (2001) Emergence, Penguin Publications
Ball, P. (2005) Critical Mass: How one things leads to             Miller, J. H. & Page, S. E. (2007) Complex adaptive
   another, Random House, London: UK                                 systems: An introduction to computional models of social
Bakhsy, E., Messing, S. & Adamic, L. A. (2016) Exposure              life, Princeton University Press
   to ideologically diverse news and opinion on Facebook,          Ngampruetikorn, V. & Stephens, G. J. (2015) Bias, Belief,
   Science 348 (6239), 1130-1132                                     and Consensus: Collective opinion formation on
Bandini, S., Manzoni, S. & Vizzari, G. (2009) Agent Based            fluctuating networks, arXiv 1512.09074v1
   Modeling and Simulation: An Informatics Perspective,            Oaksford, M. & Chater, N. (2007) Bayesian Rationality:
   Journal of Artificial Societies and Social Simulation 12          The probabilistic approach to human reasoning. Oxford,
   (4), 1-16                                                         UK: Oxford University Press
Barkun, M. (2003) A Cultural of Conspiracy: Apocalyptic            Olsson, E. J. (2013) A Bayesian simulation model of group
   Visions in Contemporary America, University of                    deliberation and polarization, in Zenker, F. (Ed.) Bayesian
   California Press                                                  Argumentation, Synthese Library, Springer
Birchall, C. (2006) Knowledge Goes Pop: From Conspiracy            Ostrom, E. (2012) The Future of the Commons: Beyond
   Theory to Gossip, Berg Publishers, Oxford: UK                     Market Failure and Government regulation, The Institute
Bovens, L., & Hartmann, S. (2003). Bayesian epistemology.            of Economic Affairs
   Oxford: Oxford University Press                                 Schelling, T. (2006) Micromotives and Macrobehavior,
Cook, J. & Lewandowsky, S. (2016) Rational irrationality:            Norton and Company, New York: NY
   Modeling climate change belief polarization using
   Bayesian networks, Topics in Cognitive Sciences 8, 160-
   179
Corner, A., Hahn, U. & Oaksford, M. (2011). The
   psychological mechanism of the slippery slope argument.
   Journal of Memory & Language, 64, 133-152.
                                                               2662

