   Do Accurate Metacognitive Judgments Predict Successful Multimedia Learning?
                                         Nicholas V. Mudrick (nvmudric@ncsu.edu)
                 North Carolina State University, Department of Psychology, 2310 Stinson Drive, 640 Poe Hall
                                                       Raleigh, NC 27695 USA
                                              Michelle Taub (mtaub@ncsu.edu)
                 North Carolina State University, Department of Psychology, 2310 Stinson Drive, 640 Poe Hall
                                                       Raleigh, NC 27695 USA
                                             Roger Azevedo (razeved@ncsu.edu)
                 North Carolina State University, Department of Psychology, 2310 Stinson Drive, 640 Poe Hall
                                                       Raleigh, NC 27695 USA
                             Abstract                                   Research on metacognitive monitoring during multimedia
  Successful performance during multimedia learning requires
                                                                     learning has traditionally employed modified meta-
  accurate metacognitive judgments. However, little research         comprehension paradigms (based on Nelson & Narens’
  has investigated the influence of accurate metacognitive           metamemory framework, 1990), during which participants
  judgments for different representations of information (e.g.,      are asked to make metacognitive judgments (e.g., ease-of-
  text and diagram) on performance during multimedia                 learning [EOL], immediate and delayed JOLs, retrospective
  learning. As such, we investigated if participants’                confidence judgments [RCJs]) during various stages of
  metacognitive judgments for text and diagrams (i.e., content       multimedia learning (e.g., Burkett & Azevedo, 2012; Eitel,
  evaluations; CEs) were significantly related to increased
  performance and higher confidence during multimedia                2016; Pilegard & Mayer, 2015). The major assumption of
  learning. Metacognitive judgments and performance measures         this research is that the timing of metacognitive judgments
  were collected from 48 undergraduate participants during 18        made during multimedia learning (before learning, during
  randomized trials. Results using multilevel modeling               learning, and after learning) will vary in accuracy, selection
  indicated that participants’ CEs for text-based content were       of cognitive strategies, and subsequent performance,
  significantly predictive of performance. Results also showed       dependent on the specific experimental manipulation (e.g.,
  that accurate CEs for diagrams interacted with accurate
                                                                     delayed JOLs are more predictive of performance than
  multiple-choice responses to predict higher retrospective
  confidence judgments (i.e., higher confidence). Identifying        EOLs; Burkett & Azevedo, 2012; Nelson & Dunlosky,
  metacognitive judgments predictive of increased performance        1991). As this research has identified that most meta-
  during multimedia learning has important theoretical,              cognitive judgments for multimedia are often inaccurate
  conceptual, and analytical implications.                           (e.g., Serra & Dunlosky, 2010), much of the literature has
  Keywords: multimedia learning; metacognition; meta-                focused on ways to improve metacognitive judgments. For
  cognitive judgments; multilevel modeling; performance;             example, some research has focused on manipulating the
  science learning                                                   framing of metacognitive judgment prompts to improve
                                                                     judgment accuracy (e.g., Pilegard & Mayer, 2015; Vössing,
                                                                     Stamov-Roßnagel, & Heinitz, 2016). Pilegard and Mayer
Research indicates learning with multimedia materials (e.g.,
                                                                     (2015) compared JOLs (i.e., how well do you remember the
text and diagram) is more effective than learning through
                                                                     content) to judgments of understanding (JOUs; i.e., how
text alone (Butcher, 2014; Mayer, 2014). Successful
                                                                     well do you understand the information) and found JOUs
multimedia learning entails individuals actively and
                                                                     were more predictive of retention and transfer compared to
accurately selecting, organizing, and integrating text- and
                                                                     JOLs. These findings suggest that framing metacognitive
image-based information into a coherent mental model
                                                                     judgment prompts (e.g., from JOLs to JOUs) significantly
(Mayer, 2014). However, research suggests learners do not
                                                                     impacts the metacognitive processes employed during
always engage in accurate and effective metacognitive
monitoring and regulation during learning with multimedia            multimedia learning, potentially indicating there may be
                                                                     other metacognitive judgments participants use that can
(Azevedo, 2014). Specifically, research has indicated
                                                                     successfully influence performance. In support of this
participants often exhibit overconfidence when monitoring
                                                                     assertion, research on hypermedia and self-regulated
their own understanding during multimedia learning (Serra
                                                                     learning (SRL) suggests several other metacognitive
& Dunlosky, 2010). The multimedia heuristic suggests
                                                                     processes may be more predictive of multimedia learning
learners’ own judgments of learning (JOLs; i.e., how well
                                                                     outcomes (Greene & Azevedo, 2009).
they will remember the information) are largely inflated
                                                                        Azevedo, Greene, and Moos (2007) developed a
when compared to their actual performance because
                                                                     classification scheme by which 35 micro-level meta-
individuals perceive multimedia content as being easier to
                                                                     cognitive judgments can be evident during successful SRL
learn than with text alone (Serra & Dunslosky, 2010).
                                                                     with hypermedia-based learning environments. One
                                                                 2766

example of these judgments is a content evaluation (CE).             In this study, we examined participants’ text CEs,
CEs are judgments learners make to assess the relevancy of        diagram CEs, multiple-choice responses, and RCJs during
the content (e.g., multimedia) they are viewing to their          multimedia learning to answer the following three
current goal (e.g., answering a science question about a          questions: (1) Are accurate text and diagram CEs associated
human body system; Greene & Azevedo, 2009). CEs are               with an increase in the likelihood of an accurate multiple-
key metacognitive judgments for successful multimedia             choice response? (2) Is there a significant relationship
learning, such that accurate CEs can direct participants to       between text and diagram CE accuracy and RCJs? (3) Is
study more efficiently. For example, if the goal is to answer     there a significant relationship between the interactions of
a science question about the human body system and                text and diagram CEs and multiple-choice responses on
participants evaluate the text but not the diagram they are       RCJs?
viewing to be relevant to their goal, they should invest more        To address our research questions, we proposed the
effort and time to study the text (as opposed to the diagram),    following hypotheses:
employ the appropriate cognitive strategy (e.g., make an             H1: Accurate text and diagram CEs will be significantly
inference), and therefore be more likely to answer the            associated with an increase in the likelihood of an accurate
question correctly.                                               multiple-choice response.
   Other research on metacognitive judgments during                  H2: The relationship between text and diagram CE
hypermedia learning has identified the predictive validity of     accuracy and RCJs will be significant.
traditional metacomprehension judgments like RCJs. For               H3: The relationship between the interactions of text and
example, Mengelkamp and Bannert (2010) investigated the           diagram CEs and multiple-choice responses on RCJs will be
stability of participants’ RCJs as they learned about operant     significant.
conditioning with a hypermedia environment. Results
indicated that the absolute accuracy (i.e., difference between                               Method
judgments and performance) was stable throughout the
learning session, and relative accuracy (correlation between      Participants
judgments and performance) was significantly predictive of        Forty-eight undergraduates (69% female) enrolled at a large
hypermedia learning outcomes.                                     mid-Atlantic university participated in this study. Their ages
   Theories of multimedia learning suggest participants           ranged from 18 to 24 (M = 20.04, SD = 1.60), and they were
cognitively process information from text and diagrams            compensated up to $30 for their participation.
separately and in different ways (Burkett & Azevedo, 2012;
Mayer, 2014). Additionally, researchers have outlined the         Experimental Design
multimedia effect to indicate that students demonstrate
                                                                  This study used a 3×3×2 within-subjects design (18 trials).
longer periods of recall and higher levels of retention when
                                                                  Each participant was exposed to three human agent facial
learning with text and images as opposed to learning only
                                                                  expressions: neutral (neutral facial expression), congruent
with text (Butcher, 2014). However, evidence suggests
                                                                  (i.e., joy for facial expressions congruent with the content
learners do not always engage in effective selection,
                                                                  relevancy), and incongruent (i.e., confusion for facial
organization, and integration of multiple representations and
                                                                  expressions incongruent with content relevancy). Each
instead exhibit a bias toward text-based (as opposed to
                                                                  participant was also exposed to each type of multimedia
diagram-based) information during multimedia learning
                                                                  content relevancy: fully relevant (text and diagram relevant
(Hegarty & Just, 1993). Since cognitive processes are
                                                                  to the question), text somewhat relevant (but diagram still
different for text and diagrams, it should be expected that
                                                                  fully relevant), and diagram somewhat relevant (but text still
metacognitive judgments will also be different.
                                                                  fully relevant). Additionally, two types of questions were
   Accurate metacognitive monitoring and regulation are
                                                                  posed: function (regarding the function of a body system)
required during multimedia learning to achieve an increase
                                                                  and malfunction (regarding a malfunction of a body
in learning outcomes (Azevedo, 2014). However, little
                                                                  system). Based on these manipulations each student
research has examined the specific processes underlying
                                                                  completed 18 trials, with different combinations of human
successful metacognitive monitoring and regulation during
                                                                  agent facial expression, multimedia relevancy type, and
multimedia learning. Specifically, few metacognitive
                                                                  question type. For this paper, our analyses focused on meta-
judgments have been found to be predictive of successful
                                                                  cognitive judgments across the trials and experimental
multimedia learning outcomes (e.g., overconfident JOLs;
                                                                  manipulations.
Serra & Dunlosky, 2010). We argue that examining other
metacognitive judgments (CEs, RCJs) can inform us of
                                                                  Materials
monitoring processes that are more indicative of successful
learning and performance. In contrast to the limited research     The materials used in this study included the following: an
on metacognitive judgments during multimedia learning, we         informed consent form; a demographic questionnaire; and a
focus on different metacognitive judgments and identify           researcher-developed, 4-foil, 18-item multiple-choice
how they can contribute to superior learning outcomes.            pretest of basic knowledge of human body systems (e.g.,
                                                                  integumentary and nervous systems). Each question on the
                                                              2767

pretest specifically related to the content presented in each     answer by typing their response into a text box.
multimedia science content slide.                                 Subsequently, participants were asked to make another RCJ
   Additionally, this study included 18 researcher-developed      based on their justification. This procedure was followed for
multimedia science content slides developed with a faculty        all 18 trials with each trial randomized across participants.
member in human biology. The relevancy manipulations
were created by including information that was related to         Procedure
but not necessary for answering the question.                     Once participants entered the lab they were asked to
                                                                  complete an informed consent form. Then the eye tracker
MetaTutor Multimedia Learning Environment                         was calibrated by the researcher.1 Following calibration,
The MetaTutor multimedia learning environment is a                participants were asked to complete a computerized
multimedia-based content presentation tool designed to            demographic questionnaire and an 18-question, 4-foil
examine the influence of a human agent’s facial expressions       pretest that assessed their basic science knowledge across
on participants’ cognitive strategies and metacognitive           the multiple body systems (e.g., urinary, endocrine)
judgments during learning about human body systems. The           presented in the experiment. After the pretest, participants
environment consists of a human agent capable of facially         completed the 18 previously described trials. The
expressing several emotional states (i.e., neutral, confusion,    experimental session lasted approximately 90 min.
joy), science questions and corresponding multimedia
science content, and metacognitive judgment prompts               Coding
(EOLs, text and diagram CEs, and RCJs). The multimedia            Text and diagram CE judgments were recorded across the
science content consists of three paragraphs (Flesch-Kincaid      18 trials (i.e., 18 text + 18 diagram = 36 total CE judgments
readability score range: 9.1–12.5; M = 10.5) and a diagram        for each participant). Responses were coded based on their
depicting the concept described in the text.                      accuracy, such that an accurate CE judgment was given a
   The environment presents 18 linearly structured, self-         score of 1, a partially correct judgment was scored as 0.5,
paced trials consisting of metacognitive judgments (e.g.,         and an incorrect judgment was scored as 0. For example, if
EOLs, CEs, and RCJs), multimedia content presentation,            participants judged the diagram as somewhat relevant and a
and human agent facial expressions.                               text as fully relevant during a “diagram somewhat relevant”
   The 18 trials have the identical format. In each trial,        trial, they were given a score of 1 for each response because
participants are first presented with a science question and      the text was still fully relevant to the question being asked,
asked to submit an EOL, How easy do you think it will be to       whereas the diagram was only somewhat relevant.
learn the information needed to answer this question?                Participants’ responses to the 4-foil, multiple-choice
Participants made their EOL judgment on a scale from 0%           questions were coded by correctness. A correct response
to 100%, increasing in increments of 20%. Participants were       was coded as 1 and an incorrect response was coded as 0.
then presented with a content slide containing the text,             Participants’ RCJs were coded on a scale from 50% to
diagram, science question presented previously, and human         100%. A score of 50% indicated participants simply guessed
agent. After 30 s (to ensure participants had enough time to      at their answer (indicating they believed they had a 50/50
initially review the material), participants were prompted to     chance of getting their answer correct), whereas a score of
assess the relevancy of both the text and diagram, Do you         100% indicated participants were completely confident in
feel the text/diagram on this page is relevant to the question    their response.
being asked?, by making two CE judgments on a Likert-
type scale (ranging from 1–3) on the following statements:                                    Results
The text/diagram is relevant, The text/diagram is somewhat
relevant, and The text/diagram is not relevant. Upon making       Research Question 1: Are accurate text and
their text and diagram CEs, the human agent expressed a           diagram CEs associated with an increase in the
congruent, incongruent, or neutral facial expression based
                                                                  likelihood of an accurate multiple-choice response?
on the relevancy of the content (e.g., a congruent facial
expression of joy if the text and diagram were relevant to        A fully unconditional model (i.e., with no predictor
the question being asked). Following the agent’s expression,      variables) dichotomous outcomes (i.e., accurate multiple-
participants were permitted to reread the text and reinspect      choice response = 1, inaccurate = 0), was conducted on
the diagram at their own pace. After they re-examined the         multiple-choice accuracy. Results indicated that the average
multimedia content, participants were prompted to answer          probability of responding to a multiple-choice question
the science question by choosing the correct response from        correctly was 60%.
4-foil answers. After submitting their answer, participants          A dichotomous outcomes model was conducted on
were prompted to make a RCJ by answering How confident            multiple-choice accuracy (i.e., accurate = 1, inaccurate = 0)
are you that the answer you provided is correct?                  with text and diagram CE accuracy as the predictor
Participants made their judgment on a scale from 50% to           variables. Results revealed that more accurate text CEs
100% increasing in increments of 10%. After submitting
                                                                     1
their response, participants were required to justify their            Although eye-tracking data were collected, they were not
                                                                  analyzed for this study.
                                                              2768

(OR = 1.98, t = 3.09, p = 0.002) but not diagram CEs (OR =
0.98, t = –0.10, p > 0.5) were associated with an increase in
the likelihood of correctly answering multiple-choice                                           82
                                                                     Retrospective Confidence
                                                                                                80
questions. Specifically, as text CE response accuracy
                                                                                                78
increased, there was a 98% increased chance of responding
                                                                                                76                Low MC Response
correctly. That is, if participants were accurate in their text                                 74
CEs, they were substantially more likely to respond                                                               Accuracy
                                                                                                72
                                                                          Judgments (%)
correctly to the multiple-choice questions.                                                     70
                                                                                                68                High MC Response
Research Question 2: Is there a significant                                                     66                Accuracy
relationship between text and diagram CE                                                             Low   High
accuracy and RCJs?
                                                                                Diagram Content Evaluation Accuracy
A fully unconditional model conducted on RCJs indicated
29.8% of the variability was between participants (t00 =
79.61, z = 4.24, p < 0.001) and 70.2% was within                  Figure 1: Interaction between diagram CE response
participants (σ2 = 187.49, z = 19.99, p < 0.001), justifying      accuracy and MC response accuracy on RCJs.
further analysis.
  An unconstrained multiple level 1 predictor model was              traditionally examined in the multimedia learning
run on RCJs using text CE and diagram CE accuracies as            literature (e.g., JOLs), can contribute to improved
the predictor variables. Results revealed that an increase in     performance and higher confidence.
both text CE accuracy (γ10 = 5.70, t = 3.95, p < 0.001) and          Results from Research Question 1 indicated accurate text
diagram CE accuracy (γ20 = 6.01, t = 4.63, p < 0.001)             CEs were significantly predictive of an increased chance of
significantly predicted an increase in RCJs. As the               responding correctly to multiple-choice questions, whereas
accuracies of participants’ text and diagram CEs increased,       diagram CEs were not. These results partially support our
their reported confidence in their performance also               hypothesis, demonstrating participants could more
increased. This model accounted for 6.2% of the within-           accurately assess the relevancy of the text-based (as
participant variance in participants’ RCJs.                       opposed to diagram-based) material related to answering the
                                                                  science question. Furthermore, these results are consistent
Research Question 3: Is there a significant                       with theories of multimedia learning that suggest
relationship between the interactions of text and                 individuals cognitively process text- and diagram-based
diagram CEs and multiple-choice responses on                      material separately (Mayer, 2014; Schnotz, 2014). It is
RCJs?                                                             possible that participants not only cognitively process the
A constrained multiple level 1 predictor model was run on         text and diagrams separately, but also metacognitively
RCJs using text and diagram CE accuracies and their               monitor the information in text and diagrams separately and
interactions with multiple-choice responses as predictor          with varying levels of accuracy. Given evidence suggesting
variables. Results indicated the interaction between text CE      individuals exhibit a bias toward processing text-based
accuracy and multiple-choice response accuracy was not            information (at the expense of diagrams; Hegarty & Just,
significant (γ40 = 1.50, t = 0.50, p = 0.62). However, results    1993), in addition to the redundancy of the diagram-based
did reveal a significant interaction effect between diagram       information to the text, participants may have realized the
CE accuracy and multiple-choice response (γ40 = –7.21, t =        text-based information was sufficient and thus relevant
–2.75, p = 0.006), such that participants whose diagram CEs       enough to answer the multiple-choice questions correctly.
were most accurate and who also had more accurate                    As hypothesized, results from Research Question 2
multiple-choice responses also reported more confidence in        demonstrated that text and diagram CEs significantly
their answers (see Figure 1). This model accounted for 7.7%       predicted higher RCJs. Specifically, the more accurate
of the within-participant variance in participants’ RCJs.         participants’ text and diagram CEs were, the more confident
                                                                  they were in their multiple-choice responses. Taken together
                        Discussion                                with the previous finding, these results indicate participants
                                                                  may have relied on their relevancy judgments of both the
The goal of this study was to examine the relationships           text and diagram when they made their RCJs (as opposed to
between metacognitive judgments and their contributions to        answering the question). As such, this finding significantly
increased performance during multimedia learning. Overall,        augments research on metacognitive judgments during
results revealed that when participants made accurate text        multimedia learning by indicating a significant relationship
CEs, they were more likely to respond correctly to multiple-      between multiple metacognitive judgments.
choice questions. Additionally, accurate text and diagram            Lastly, results from Research Question 3 indicated the
CEs contributed to higher reported confidence in answers.         interaction between diagram CE accuracy and multiple-
As such, our findings augment current understanding of            choice response accuracy significantly predicted increased
how different metacognitive judgments, from those                 RCJs. More specifically, participants who provided more
                                                              2769

accurate diagram CEs and responded accurately to multiple-                  Future Directions and Implications
choice questions also reported more confidence in their
                                                                   The results of this study have important implications for
answers. These results partially support our hypothesis that
                                                                   future studies examining the influence of metacognitive
both text and diagram CEs interact with multiple-choice
                                                                   judgments on performance during multimedia learning.
responses to predict increased RCJs. Additionally, this
                                                                   First, future research should include analyses of multi-
result is supported by previous literature that suggests a
                                                                   channel trace data (e.g., eye tracking, facial expressions of
significant relationship between performance and RCJs
                                                                   emotions) that would allow for a more comprehensive
(e.g., Mengelkamp & Bannert, 2010). These results also
                                                                   depiction of the cognitive, affective, and metacognitive
support our assumption that since cognitive processes are
                                                                   processes that occur when making CEs during multimedia
different for different representations of information, so too
                                                                   learning (see Azevedo, 2014). Specifically, analyzing eye-
are metacognitive monitoring processes. However, research
                                                                   tracking data can provide a micro-level description of the
is limited regarding the metacognitive processes involved
                                                                   cognitive processes (e.g., coordination of information
when learning with and comprehending diagrams.
                                                                   sources) contributing to increased performance and accurate
   Overall, these results suggest that accurately assessing the
                                                                   text and diagram CEs. For example, does more time spent
relevancies of text and diagrams differentially impacts
                                                                   reading the text contribute to more accurate text CEs? Do
performance and future metacognitive judgments (e.g.,
                                                                   specific eye-movement “signatures,” as evidenced by scan
accurate CEs related to increased RCJs). Results also
                                                                   path analyses, indicate greater integration of multimedia
indicated that when participants responded to multiple-
                                                                   information and subsequently lead to increased
choice questions, they relied on their metacognitive
                                                                   performance? Further, examining the influence of
judgments of the text rather than diagrams. In contrast,
                                                                   participants’ affective processes (e.g., emotions) would
participants relied on metacognitive judgments of diagrams
                                                                   provide evidence of how they influence cognitive and
and their performance when making RCJs. Previous
                                                                   metacognitive processes. For example, are participants’
research has indicated a significant relationship between
                                                                   facial expressions of confusion predictive of decreased CE
CEs and performance (e.g., Greene & Azevedo, 2009).
                                                                   accuracy? How do participants’ facial expressions of
However, unlike previous literature, these results suggest
                                                                   frustration influence the quality of their multiple-choice
text and diagram CEs differentially impact not only
                                                                   responses? Lastly, as this study was limited to analyzing the
performance, but also reported confidence. Ultimately, these
                                                                   accuracy of RCJs, future research should seek to determine
results confirm that other metacognitive judgments for
                                                                   how CEs contribute to the accuracy of RCJs. It is possible
different representations of information can predict greater
                                                                   that participants’ CEs were accurate, but they exhibited
performance during multimedia learning.
                                                                   over- or under-confidence when making their RCJs.
                                                                      As our results indicated that diagram but not text CEs
                         Limitations                               interacted with multiple-choice responses to predict RCJs,
Our study has several limitations. First, as we were               they emphasize the differential impact of multiple
primarily interested in the relationship between                   representations of information on participants’ meta-
metacognitive judgments (e.g., CEs, RCJs) and performance          cognitive judgments. Future research should examine the
across conditions, we did not examine the impact of content        specific impact of different representations (e.g., diagrams,
relevancy (e.g., fully relevant text and diagram, text less        graphs, illustrations) on participants’ metacognitive
relevant, diagram less relevant) or question type (e.g.,           judgments to address the gap in the literature and gain better
function vs. malfunction science question). Furthermore, the       understanding of the metacognitive monitoring processes
information needed to answer the multiple-choice questions         involved during multimedia learning.
correctly was primarily located in the text, which may have           Using a within-subjects design allowed us to examine the
influenced participants’ CE judgments. Future research             differential impact of how accurate metacognitive
should include separate function and malfunction questions         judgments influenced performance and confidence with
based on the information presented in the diagrams.                reduced error caused by individual differences.
Moreover, we did not examine the accuracies of RCJs as             Additionally, using multilevel modeling (Raudenbush &
multiple-choice responses were dichotomously coded as              Bryk, 2002) enabled us to accurately assess within-subjects
correct or incorrect. Future research will include measures        variance without violating traditional statistical assumptions
of absolute and relative accuracies for RCJs (e.g., Schraw,        (e.g., independence of observations) that many within-
2009). Lastly, we can only make limited conclusions                subjects designs ignore. Despite these benefits, future
regarding the underlying cognitive and metacognitive               research should explore other experimental designs that are
processes (e.g., multiple fixations on irrelevant diagrams)        less controlled (e.g., more naturalistic) to increase the
that contributed to the accuracies of the text and diagram         ecological validity of these findings. Due to our sample size,
CEs and multiple-choice responses, as multichannel trace           we did not find significant between-subjects variance; future
data (e.g., eye tracking) were not analyzed. Despite these         research should replicate these analyses with larger samples
limitations, this study has several important implications.        to determine individual differences indicative of improved
                                                                   metacognitive judgment accuracy and performance (e.g.,
                                                                   prior knowledge of body systems).
                                                               2770

  Additionally, these results indicate the importance of            and diagrams: Relations with transfer, effort, and spatial
coordinating multiple sources of information (e.g., text and        skill. International Journal of Science Education, 37,
diagram) and can be used to inform the design of                    2476–2502.
educational training regimens. For example, future research       Burkett, C., & Azevedo, R. (2012). The effect of multimedia
should explore the impact of cognitive (e.g., Bergey,               discrepancies on metacognitive judgments. Computers in
Cromley, & Newcombe, 2015) and metacognitive (e.g.,                 Human Behavior, 28, 1276–1285.
Azevedo, 2014) instruction that emphasizes how individuals        Butcher, K. (2014). The multimedia principle. In R. E.
should learn using both text and diagrams. Training can be          Mayer (Ed.), The Cambridge handbook of multimedia
provided to demonstrate how to accurately judge the                 learning (2nd ed.). New York, NY: Cambridge University
relevancy of texts and diagrams, as well as emphasize the           Press.
importance of accurate metacognitive judgments in relation        Eitel, A. (2016). How repeated studying and testing affects
to increased performance. Furthermore, these results can            multimedia learning: Evidence for adaption to task
also inform the design of future intelligent, adaptive              demands. Learning and Instruction, 41, 70–84.
multimedia-based learning environments to support and             Greene, J. A., & Azevedo, R. (2009). A macro-level
scaffold accurate metacognitive judgments. If participants          analysis of SRL processes and their relations to the
continuously make inaccurate text CEs, the system can               acquisition of a sophisticated mental model of a complex
intervene by cueing their attention to the relevant text-based      system. Contemporary Education Psychology, 34, 18–29.
information or by providing additional relevant declarative       Hegarty, M., & Just, M. A. (1993). Constructing mental
and conditional knowledge (e.g., how to accurately judge            models of machines from text and diagrams. Journal of
the relevancy of different representations of information).         Memory and Language, 32, 717-742.
  Lastly, the results from this study suggest accurate            Mayer, R. E. (2014). Cognitive theory of multimedia
metacognitive judgments are required for increased                  learning. In R. E. Mayer (Ed.), The Cambridge handbook
performance and confidence during multimedia learning.              of multimedia learning (2nd ed.). Cambridge, England:
Traditionally, metacognitive judgments during multimedia            Cambridge University Press.
learning have been found to be largely inaccurate. However,       Mengelkamp, C., & Bannert, M. (2010). Accuracy of
our results indicate other metacognitive processes (e.g.,           confidence judgments: Stability and generality in the
CEs) may be more informative of increased performance.              learning process and predictive validity for learning
For example, future studies could examine the influence of          outcome. Memory & Cognition, 38, 441–451.
accurate feelings of knowing (i.e., individuals are aware of      Nelson, T. O., & Dunlosky, J. (1991). When people’s
having read information but are unable to recall it on              judgments of learning (JOLs) are extremely accurate at
demand) and how they can contribute to increased                    predicting subsequent recall: The “delayed-JOL effect.”
performance during multimedia learning. As such, future             Psychological Science, 2, 267–270.
research examining the influence of other metacognitive           Nelson, T. O., & Narens, L. (1990). Metamemory: A
judgments will significantly augment our understanding—as           theoretical framework and new findings. The Psychology
well as the contemporary theoretical frameworks of                  of Learning and Motivation, 26, 125-173.
multimedia learning—of the relationship between cognitive         Pilegard, C., & Mayer, R. E. (2015). Within-subject and
and metacognitive processes contributing to increased               between-subject conceptions of metacomprehension
performance.                                                        accuracy. Learning and Individual Differences, 41, 54–
                                                                    61.
                    Acknowledgments                               Raudenbush, S. W., & Bryk, A. S. (2002). Hierarchical
The research presented in this paper is supported by funding        linear models: Applications and data analysis methods
from the National Science Foundation (DRL 1431532). The             (2nd ed.). Thousand Oaks, CA: SAGE.
authors would like to thank the members of the SMART              Schnotz, W. (2014). The integrated model of text and
Lab and the IntelliMedia Group at NCSU for their                    graphics comprehension. In R. E. Mayer (Ed.), The
assistance in this project.                                         Cambridge handbook of multimedia learning (2nd ed.).
                                                                    New York, NY: Cambridge University Press.
                         References                               Schraw, G. (2009). A conceptual analysis of five measures
                                                                    of metacognitive monitoring. Metacognition and
Azevedo, R. (2014). Multimedia learning of metacognitive            Learning, 4, 33–45.
  strategies. In R. E. Mayer (Ed.), The Cambridge                 Serra, M. J., & Dunlosky, J. (2010). Metacomprehension
  handbook of multimedia learning (2nd ed.). New York,              judgments reflect the belief diagrams improve learning
  NY: Cambridge University Press.                                   from text. Memory, 18, 698–711.
Azevedo, R., Greene, J., & Moos, D. (2007). The effect of a       Vössing, J., Stamov-Roßnagel, C., & Heinitz, K. (2016).
  human agent’s external regulation upon college students’          Images in computer-supported learning: Increasing their
  hypermedia learning. Metacognition and Learning, 2, 67–           benefits for metacomprehension through judgments of
  87.                                                               learning. Computers in Human Behavior, 57, 221–230.
Bergey, B. W., Cromley, J. G., & Newcombe, N. S. (2015).
  Teaching high school biology students to coordinate text
                                                              2771

