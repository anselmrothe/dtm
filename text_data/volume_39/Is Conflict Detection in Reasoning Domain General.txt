                           Is Conflict Detection in Reasoning Domain General?
                                            Darren Frey (darren@post.harvard.edu)
                                            Paris Descartes University, Sorbonne Paris Cité
                                               CNRS UMR 8240, LaPsyDÉ, Paris, France
                                        Wim De Neys (wim.de-neys@parisdescartes.fr)
                                            Paris Descartes University, Sorbonne Paris Cité
                                               CNRS UMR 8240, LaPsyDÉ, Paris, France
                             Abstract                                   countless testable hypotheses and a diverse set of
   A great deal of reasoning research indicates that individuals
                                                                        approaches and methods. While most parties agree that
   are often biased by intuitive heuristics. However,                   heuristics are useful, efficient, and often optimal means of
   contemporary results indicate that individuals seem sensitive        navigating complex environments, investigators disagree
   to their biases; they seem to detect conflict with reasoning         about how often and in what contexts they conflict with
   norms. One of the key remaining questions is whether this            logical and mathematical principles. Evans (2003, 2010),
   conflict sensitivity is domain general. To address this              Kahneman (2011), and Stanovich and West (2000) insist
   question, we administered a battery of five classical reasoning      that individuals regularly make reasoning mistakes because
   tasks to a large sample of subjects and assessed their conflict
   detection efficiency on each task by measuring their response        of unchecked heuristic inferences, while Gigerenzer (2008),
   confidence. Results indicate that conflict detection is, in most     Katsikopoulos (2013) and others emphasize that heuristics
   senses, not domain general, though there are compelling              are generally ecologically rational and truth preserving.1
   exceptions.                                                             Until recently, one of the cardinal doctrines of the dual
   Keywords: conflict detection; reasoning; bias; domain                process account of reasoning mistakes relied on the
   generality; decision making                                          imperceptibility of reasoning conflicts. Prominent scholars
                                                                        have argued that our reasoning mistakes masquerade
                         Introduction                                   beneath our awareness, which is, at least partially, what
                                                                        accounts for their ubiquity. Surely—the argument goes—if
That human reasoning is prone to error comes as no surprise
                                                                        reasoners were aware of their mistakes they would correct
to most everyone. Upon reflection, we discern blunders in
                                                                        them. However, many contemporary empirical analyses of
our own reasoning in the most ordinary of circumstances:
                                                                        reasoning bias suggest that individuals are often sensitive to
we realize we miscalculated how long a trip would take us;
                                                                        conflicts between heuristics and normative principles even
we come to acknowledge our snap judgment of a colleague
                                                                        when they err (e.g., Bonner & Newell, 2010; De Neys &
was mistaken. Likewise, we often witness mistakes in
                                                                        Glumicic, 2008; Pennycook, Fugelsang, & Koehler, 2015;
others and throughout history, some of which aggregate in
                                                                        Handley & Trippas, 2015).
the most atrocious of ways: an innocent man is convicted,
                                                                           Researchers have demonstrated this across a number of
judged, tried, and sentenced to more than forty years of
                                                                        diverse reasoning tasks using many different methods.
solitary confinement based on the shakiest possible
                                                                        Much of the work relies on contrasting tasks that contain
evidence, the testimony of a single untrustworthy witness
                                                                        conflicts between intuitively cued heuristics and normative
(e.g., the case of Albert Woodford, see Aviv, 2017).
                                                                        principles with structurally identical tasks containing no
   Although mistakes like this seem, at first, entirely
                                                                        such conflict. Standard behavioral markers that index
unrelated, one could argue they often issue from a uniform
                                                                        conflict on lower level tasks, like response times (RT) and
set of underlying tendencies. Exploring these tendencies
                                                                        confidence levels (Yeung & Summerfield), also indicate
has motivated much of the research in reasoning and
                                                                        people are sensitive to conflict in higher level reasoning
decision making throughout the past four decades. One
                                                                        tasks (Bonner & Newell, 2010; De Neys & Glumicic, 2008;
compelling and especially generative account of reasoning
                                                                        Pennycook, Fugelsang, & Koehler, 2012). Additionally,
mistakes contrasts two types of thinking: fast, associative,
                                                                        people tend to fixate visually on the conflicting elements of
heuristic thinking and slower, more demanding, rule-based
                                                                        the tasks, as evidenced in eye and gaze tracking experiments
reasoning (Kahneman, 2011). Returning to the example of
                                                                        (De Neys & Glumicic, 2008; Ball, Phillips, Wade, &
misjudging a colleague, the fast type of reasoning (System
1) seems to account for our initially misguided impression,             1
which is then revised upon reflection—and after gathering                 Given these fairly fundamental disagreements, it should come as
                                                                        no surprise that what counts as a normative response in any
more evidence—by the slower, more deliberate type of
                                                                        number of contexts is hotly debated. For the sake of simplicity,
thinking (System 2).                                                    terms like “normative,” “correct,” and “logical” will be used to
   The family of dual process theories that rely on                     indicate conclusions that are considered correct in classical logic
contrasting these two forms of reasoning has provided                   and probability.
                                                                    391

Quayle, 2006), and they register heightened levels of                Participants
arousal on skin conductance recordings (De Neys, Moyens,             A total of 318 undergraduates (260 female; average age =
& Vansteenwegen, 2010). There is neuropsychological                  22.32, SD = 6.11) at Paris Descartes University completed
evidence of conflict sensitivity as well, derived from both          the experiment.
fMRI (De Neys, Vartanian, & Goel, 2008; Simon et al,.
2015) and EEG analyses (De Neys, Novitskiy, Ramautar, &              Materials
Wagemans, 2010). Despite the diversity of methods and                The experiment consisted of adaptations of five classic
tasks supporting these effects, there are many who find the          reasoning tasks. For each of the five tasks, participants
research problematic, largely because its results seem to            received two conflict items, two no-conflict items, and one
imply that individuals have fairly immediate access to               abstract control, resulting in 25 items. The tasks were as
logical and probabilistic principles (Mata, Schubert, &              follows.
Ferreira, 2014; Pennycook et al., 2012; Singmann, Klauer,
& Kellen, 2014; Travers, Rolison, & Feeney, 2016). Even              Bat and Ball Items (BB) The conflict items in this set were
the most ardent proponents of the work acknowledge that it           modeled after the canonical CRT problem (Frederick,
is still developing and in need of greater clarification (De         2005): “A bat and a ball together cost $1.10. The bat costs
Neys, 2012, 2014).                                                   $1 more than the ball. How much does the ball cost?” The
   Although conflict detection has been explored with a              answer that often comes to mind is 10 cents, though the
variety of methods and across various tasks, no previous             correct answer is 5 cents ($0.05 + $1.05 = $1.10).
research examines individuals' tendencies to detect conflict         Participants likely intuitively substitute the “costs $1 more
across a range of tasks, giving researchers no clear sense of        than” phrase with “costs $1,” so to generate no-conflict
how or whether conflict sensitivities interact. It is unclear,       variants one simply removes this phrase (see De Neys,
for example, whether a given person's ability to detect a            Rossi, & Houdé, 2013).
conflict between an intuitively cued heuristic and a
reasoning rule on a particular kind of task is related to her        Ratio Bias Items (RB) Also called “denominator neglect”
ability to do so on different tasks. In essence, a key open          problems, these items consist of asking participants to
question is whether conflict detection is domain general or          choose between two trays, a small tray and a large one,
task specific.                                                       containing a mixture of gray and white marbles. The
   By further clarifying the precise nature of conflict              participants' goal is to get a gray marble, but the marble will
detection, research of this sort will help characterize              be drawn from the tray they select at random. In a conflict
emergent dual process theories, especially those that                item, the absolute value of gray marbles in the large tray is
explicitly rely on conflict detection mechanisms. For                greater than the absolute value of gray marbles in the small
example, Pennycook et al's (2015) three-stage dual-process           tray, but the relative value of gray marbles is greater in the
model relies on differentiating between successful conflict          small tray (e.g., 19/100 vs. 2/10, 19% vs. 20%). Since the
detection and “cognitive decoupling,” which is the more              marble is being selected at random, one should choose the
resource intensive process of rejecting a conclusion at odds         tray that maximizes the relative likelihood of getting a gray
with reasoning rules even when it has been facilitated by a          marble (the small tray), but participants are often intuitively
certain heuristic. Crucially, although conflict detection            and immediately drawn to the larger tray. To generate no-
failures are a prominent feature of this model, it is unclear if     conflict items one aligns the relative and absolute values in
conflict sensitivity is a stable individual difference. If           a tray, so that the tray most likely to have a gray marble—
conflict detection is domain general, then one would expect          the one with the highest relative value—is also the most
the prominence of these failures to extend fairly globally.          perceptually salient one—the one with the highest absolute
Apart from further specifying the theory, such a conclusion          value (e.g., 21/100 vs. 2/10, see Bonner & Newell, 2010).
would offer a partial account of the prevalence of cognitive
biases. However, if conflict detection is task specific, then        Syllogism Items (SYL)            Syllogisms are fundamental
one can suppose that empirically observed detection on a             arguments in classical logic that consist of two premises and
given task is largely unrelated to others, and the prevalence        a conclusion, which necessarily follows from the premises
of bias needs to be accounted for in other ways.                     when the argument is valid. When the conclusion is at odds
    To address this issue, we presented a battery of the most        with common beliefs, participants tend to deem it logically
intensively studied tasks in the field to a large number of          invalid even when explicitly told just to evaluate the
reasoners. This enabled us to assess their conflict detection        argument's validity (Markovits & Nantel, 1989). A conflict
efficiency by measuring their response confidence.                   item consists of a logically valid (or invalid) argument
Examining the relationship of detection efficiency across the        structure with an unbelievable (or believable) conclusion.
tasks gives us evidence with which to evaluate whether               Here is an example of an unbelievable but valid argument:
conflict detection is domain general or task specific.               All mammals can walk. Whales are mammals. ∴ Whales
                                                                     can walk. No-conflict items are those in which common
                            Method                                   beliefs and the argument's logical structure both cue the
                                                                 392

same response. All problems were based on Markovits and             conflict content, task order, and conflict presentation order.
Nantel's material (1989).                                           The conflict and no-conflict contents were balanced across
                                                                    participants, such that half the participants received, for
Base Rate Items (BR) Base rate items consist of statistics          example, the conflict conjunction item above, while the
describing a sample from which an individual is randomly            other half received its no-conflict analogue, and vice versa.
selected along with a description of the individual. Here is        Additionally, the order in which a given task was presented
an example of a conflict item: “In a study 1000 people were         varied, as did whether an individual first saw a conflict or
tested. Among the participants there were 5 sixteen-year-           no-conflict item. A partial Latin square of these factors
olds and 995 forty-year-olds. Lisa is a randomly chosen             generated 10 different experiment formats, which were
participant of the study. Lisa likes to listen to techno and        distributed evenly across the participant sample.
electronic music. She often wears tight sweaters and jeans.            All items were presented on their own page. At the
She loves to dance and has a small nose piercing. What is           bottom of which there was a scale where participants
most likely? (A.) Lisa is sixteen. (B.) Lisa is forty.” This        indicated how confident they were in their response on a
item creates a conflict by calling to mind a stereotype that is     range from 0% (not at all confident) to 100% (completely
at odds with the statistically most likely outcome. To              confident).
generate no-conflict items, one aligns the statistics and the
intuitively cued heuristic. For example to turn the above                                      Results
item into a no-conflict example, switch the base rates so the
the sample consists of 995 sixteen-year-olds and 5 forty-           Accuracies
year-olds. All problems were based on De Neys and                   Table 1 (first two rows) presents averages of accuracy levels
Glumicic's (2008) material.                                         on each of the tasks, separated by conflict status.
                                                                    Replicating classical findings, performance on no-conflict
Conjunction Items (CON) Modeled on the classic Linda                items was consistently higher than performance on conflict
problem, participants received descriptions about                   items. In all cases except for RB, contrasts between
individuals that either intuitively prompt a single statement       performance on conflict and no-conflict items was
(no-conflict) or a conjunctive statement (conflict), and they       significant (all BB/SYL/BR/CON t > 10.07, p < 0.001; RB:
are asked to decide which statement is most likely. Since a         t(315) = 1.10, p = 0.28).
single statement is always more likely than a conjunctive
statement, subjects should always choose the single                       Table 1: Accuracies and Conflict Detection Effects
statement regardless of whether it coheres with the
stereotype. Here is an example of a conflict item: “Jon is
32. He is intelligent and punctual but unimaginative and
somewhat lifeless. In school, he was strong in mathematics
but weak in languages and art. Which one of the following
statements is most likely? (A.) Jon plays in a rock band.
(B.) Jon plays in a rock band and is an accountant.” Since
the description generally cues an accountant stereotype,
subjects often wrongly choose the less likely option, B. No-
conflict items simply isolate the heuristically cued option.
All problems were based on De Neys, Cromheeke, and
Osman's (2011) material.                                            Conflict Detection
                                                                   To get a sense of how widely conflict detection efficiency is
Procedure                                                           distributed across tasks, it is useful to look at what
The participants were tested in groups of no more than thirty       proportion of the sample tended to detect conflict on the
students in a silent classroom at the beginning of a course.        entire battery. At the aggregate level, averaged across tasks,
In addition to the conflict and no-conflict items illustrated       we observe most individuals (74.70%) tend to a lowered
above, participants answered one abstract neutral problem           confidence level on conflict vs. no-conflict items. Across all
per task. These were designed to query abstract knowledge           tasks, this difference amounts to a 9.50% diminution in
of relevant reasoning rules and were variants of the above          confidence on incorrectly solved conflict items compared to
tasks with no clear, consistent intuitive or heuristic prompts.     correctly solved conflict items, t(307) = 12.01, p < 0.001.
Accuracy on the neutral control items was high (mean                This is roughly reflected in the task by task contrasts,
accuracy 81.6%, SD = 0.18). All analyses were run filtering         though it is highly variable. For example, in the case of the
for controls and they made no significant impact on any of          BB items the confidence diminution was 23.15%, while
the results. Thus, we will present only our unfiltered data in      most others hovered around 10%, and, in contrast with
what follows and will not discuss the control items further.        previous findings (Stupple, Ball, Evans, Kamal-Smith,
   The overall structure of the experiment, a within subject        2011), there was little difference between confidence levels
design, was manipulated in three ways: it was balanced for          on SYL items (0.37%). In all cases except for SYL, t(177)
                                                                393

= 0.50, p = 0.61, the task specific confidence decrease was             detection on a given task was predicted by one's tendency to
significant: BB/RB/BR/CON: all t > 2.65, all p < 0.01.                  detect conflict on all of the other tasks. For example, to see
                                                                        if we can predict whether an individual shows an effect on
Task Specificity and Domain Generality                                  the BB items, we tallied how often she showed an effect on
With a view to evaluating whether conflict detection is task            all the other items (RB, SYL, BR, and CON) and used the
specific or domain general, we ran four primary kinds of                latter as our predictor variable.
analyses: correlations between conflict items across tasks;
correlations between conflict detection effects across tasks;                     Table 3: Predicting Conflict Detection Effects
analyses of the distribution of conflict detection effects by
individual; and regressions to predict conflict detection
effects with a composite meant to uncover diffuse evidence
of domain generality.
   Table 2 summarizes the results of the first two analyses.
The statistics above the diagonal are correlations between
conflict detection effects across biased individuals on each
of the tasks. The correlations below the diagonal are
between accuracies on each of the conflict items across
tasks for all participants (N = 318). Accuracies on conflict
items were significantly correlated between all tasks (all p <          As is clear from Table 3, the goodness of fit of these first
0.04), although most correlations are fairly modest, ranging            models (BB, RB, SYL, BR, CON) was generally quite low.
from 0.12 to 0.32.                                                      The pseudo R2's (McFadden's) range from < 0.001 to 0.02,
                                                                        except for the BB model which was at the limit of what is
     Table 2: Conflict Accuracy and Detection Correlations              considered reasonably good (0.17). The relative goodness
                                                                        of this model is reflected in its higher beta coefficient
                                                                        (1.02), which is significant (p < 0.001).
                                                                           The only other models with significantly predictive
                                                                        coefficients were the BR and CON models. However, given
                                                                        the tight correlation between these items discovered in the
                                                                        first analysis, we wondered if this was driving the effect.
                                                                        Indeed, if one runs a restricted model, omitting the correlate
            * 0.05 < p < 0.01; ** p < 0.01. Subscripts indicate Ns.
                                                                        of the predictor (leaving out CON in the BR case, and vice
                                                                        versa), the models (BR2 and CON2 in Table 3) have inferior
   As a reminder, a conflict detection effect is, in this               goodness of fit and coefficients that are both smaller and no
context, a diminution of confidence on an incorrectly solved            longer significant.2
conflict item relative to a correctly solved no-conflict item.
Given the notorious noisiness and subjectivity of confidence            Individual Differences
measures and the difficulty of interpreting conflict detection          So far, we have uncovered little evidence of domain
effect sizes (Frey, Johnson, & De Neys, 2017), this is                  generality in conflict detection. However, most of the
measured in a binary way: one either shows the effect or one            previous findings rely on averaging effects across reasoners.
does not. In stark contrast to the pattern below the diagonal,          It might well be the case that there are individuals who show
correlations between conflict detection effects—those above             evidence of fairly generalized conflict detection. The
the diagonal—are almost uniformly insignificant. The only               concern we address in this section is that important
exception is CON & BR, which was correlated at 0.16 (p <                differences between individuals might be lost by
0.02). The correlation between BR & SYL was marginally                  aggregating as we have, a concern that echoes theorists who
significant, r = 0.144, p = 0.078. Additionally, Bayes                  emphasize the importance of examining individual
Factors for the correlations were all below 0.52, except                differences in reasoning and decision making (Baron, 2010).
CON & BR, which was 1.59.
   The binary correlations of conflict detection effects                2
                                                                          This analysis was meant to assess whether there was a rather
provide no real evidence of domain generality. However, if
                                                                        diffuse and non-specific conflict detection signal that predicted an
there is a general and diffuse signal, why should that be               individual's detection on a given task by a composite of their
captured by simple, pairwise correlations? Perhaps it is the            relative effects on other tasks. Were the data not binary, a factor
case that conflict detection on a particular task is better             analysis would perhaps be appropriate here. Essentially, this was
predicted by a non-specific and global sensitivity to conflict          the most liberal test we could devise to check for generality of
across tasks. We ran a regression analysis to address this              conflict detection effects. However, it is worth noting that a more
hypothesis, using the combined predictive power of a                    conventional test, using multiple regressions with all tasks as
participant's responses across all tasks. In particular, we             predictors except the one being predicted, generated the exact same
used logistic regressions to determine whether conflict                 pattern of results, with all models being uninformative except
                                                                        where BR & CON items were concerned.
                                                                    394

   To address this issue, we present a final means of              were correlated, and the more liberal regression models
characterizing the sample's overall conflict sensitivity,          relying on them were minimally predictive, as was the
which is summarized in Figure 1. We scored every biased            model predicting the bat and ball (BB) problems. So we
participant individually in order to get a sense of the            found, additionally, no clear evidence of hard and fast task
distribution of conflict detection effects. For a given            specificity.
individual, the total number of tasks on which she showed a           One might classify our findings as “domain specific,”
conflict detection effect was divided by the total number of       where a domain is defined as a set of problems that share
tasks on which she was biased, giving us a range of                similar reasoning rules subject to comparable competing
detection levels spanning from 0 (showing no effect on any         intuitive heuristics. From such a perspective, base rate and
of the tasks on which an individual is biased) to 1 (showing       conjunction items would be considered to fall within the
an effect on all of the tasks on which an individual is            same domain, as they share similar underlying reasoning
biased).                                                           structures (statistics and probabilities, respectively) that are
                                                                   in conflict with comparable intuitively prompted heuristics
                                                                   (social stereotypes in both cases), and in indeed both were
                                                                   developed to evaluate biases resulting from the
                                                                   representativeness heuristic.
                                                                      This hybrid outcome has a number of exciting theoretical
                                                                   features and practical applications. For example,
                                                                   Teovanović, Knežević, & Stankov (2015) argue against a
                                                                   single, explanatory factor underlying cognitive biases that
                                                                   one can easily relate to general intelligence. The account
                                                                   we present here is commensurate with those findings, as it
                                                                   seems indicative of multiple, often dissociable loci of
                                                                   conflict detection failures.       Additionally, one of the
                                                                   implications of our findings is that a conflict detection
                                                                   failure on a given task may be largely dissociable from a
                                                                   conflict detection failure on a distant task. This is a hopeful
    Figure 1: Frequency of Reasoners by Detection Level            conclusion, especially given the evidence that at the
                                                                   individual level such failures are a non-negligible source of
   There are concentrations of individuals who consistently        reasoning bias (e.g., Pennycook et al., 2015).              The
detect (Detection Level 1: 18.09% of the sample), detect           prominence of conflict detection failures on a certain task
half the time (Detection Level 0.50: 21.28% of sample), and        need not paint a grim picture of reasoning globally.
who consistently do not detect (Level 0: 12.77% of the             However, the association within what we are calling a
sample), with all other participants distributed between           domain indicates that at points detecting on a given task will
these three groups. The observation that up to 13% of the          be related to detection on a different task, a relationship that
sample shows a Detection Level 0 is in line with previous          could be exploited educationally. For example, a reasonable
findings that suggest there are subsets of reasoners who           pedagogical strategy might begin by allocating resources to
consistently fail to detect conflict (Frey, Johnson, & De          the easier of two related tasks, relying on the shared
Neys, 2017, Pennycook et al., 2015). The additional                conflict prompting structures to aid in instructional transfer
observation that 18% of the sample shows perfect detection         and facilitate instruction on the second task.
across all tasks also implies that there might be exceptions          These findings raise many additional questions. Since
to the overall trend toward task specificity. Although this        confidence measures are inherently noisy, our results are
distribution is compatible with the few studies that have          necessarily tentative. It will be important to revisit the
explored individual differences in conflict detection              question of the domain generality of conflict detection with
previously, we cannot confirm the representativeness of this       additional      measures,     especially     response     times.
kind of a distribution given our methods, as we could have         Additionally, given that we were interested in performance
arrived at it by chance.                                           across many tasks, we were only able to use a few items per
                                                                   task, so our findings need to be interpreted cautiously.
                         Discussion                                Another particularly promising research project will be to
                                                                   further characterize those individuals who detect conflict in
                                                                   a domain general manner. For example, it would be
While performance on conflict items was consistently
                                                                   particularly instructive to determine whether they share
correlated, we found no clear indication that conflict
                                                                   similar general cognitive capacities or tend have related
detection is similarly correlated. Even using a more liberal
                                                                   thinking dispositions.
measure, one that leverages the predictive power of the
entire panel of tasks to anticipate conflict detection on a
                                                                                         Acknowledgements
single task, there was only the faintest signal of generality.
Nevertheless, base rate (BR) and conjunction (CON) items
                                                               395

This research was supported by a research grant                     Frey, D., Johnson, E., De Neys, W. (2017, forthcoming)
(DIAGNOR, ANR-16-CE28-0010-01) from the Agence                          Individual Differences in Conflict Detection During
National de la Recherche. Additionally, Darren Frey is                  Reasoning. Quarterly Journal of Experimental
supported by the Sorbonne Paris Cité International Grant                Psychology
(INSPIRE).                                                          Gigerenzer, G. (2008). Gut Feelings: The Intelligence of the
                                                                        Unconscious (Reprint edition). Penguin Books.
                           References                               Handley, S. J., & Trippas, D. (2015). Chapter Two-Dual
                                                                        processes and the interplay between knowledge and
Aviv, R. (2017, January). How Albert Woodfox Survived                   structure: a new parallel processing model. Psychology
     Solitary. The New Yorker.                                          of Learning and Motivation, 62, 33–58.
Ball, L. J., Phillips, P., Wade, C. N., & Quayle, J. D. (2006).     Kahneman, D. (2011). Thinking, Fast and Slow. New York:
     Effects of belief and logic on syllogistic reasoning:              Farrar, Straus and Giroux.
     Eye-movement evidence for selective processing                 Katsikopoulos, K. V. (2014). Bounded rationality: the two
     models. Experimental Psychology, 53(1), 77–86.                     cultures. Journal of Economic Methodology, 21(4), 3
Baron, J. (2010). Looking at Individual Subjects in                     61–374.
     Research on Judgment and Decision Making (or                   Markovits, H., & Nantel, G. (1989). The belief-bias effect in
     anything). Acta Psychologica Sinica, 42(1), 88–98.                 the production and evaluation of logical conclusions.
Bonner, C., & Newell, B. R. (2010). In conflict with                    Memory & Cognition, 17(1), 11–17.
     ourselves? An investigation of heuristic and analytic          Mata, A., Schubert, A.-L., & B. Ferreira, M. (2014). The
     processes in decision making. Memory & Cognition,                  role of language comprehension in reasoning: How
     38(2), 186–196.                                                    “good-enough” representations induce biases.
De Neys, W. (2012). Bias and Conflict: A Case for Logical               Cognition, 133(2), 457–463.
     Intuitions. Perspectives on Psychological Science, 7(1),       Pennycook, G., Fugelsang, J. A., & Koehler, D. J. (2012).
     28–38.                                                             Are we good at detecting conflict during reasoning?
De Neys, W. (2014). Conflict detection, dual processes, and             Cognition, 124(1), 101–106.
     logical intuitions: Some clarifications. Thinking &            Pennycook, G., Fugelsang, J. A., & Koehler, D. J. (2015).
     Reasoning, 20(2), 169–187.                                         What makes us think? A three-stage dual-process model
De Neys, W., Cromheeke, S., & Osman, M. (2011). Biased                  of analytic engagement. Cognitive Psychology, 80, 34–
     but in Doubt: Conflict and Decision Confidence. PLoS               72
     ONE, 6(1), e15954.                                             Simon, G., Lubin, A., Houdé, O., & Neys, W. D. (2015).
De Neys, W., & Glumicic, T. (2008). Conflict monitoring in              Anterior cingulate cortex and intuitive bias detection
     dual process theories of thinking. Cognition, 106(3),              during number conservation. Cognitive Neuroscience,
     1248–1299.                                                         6(4), 158–168.
De Neys, W., Moyens, E., & Vansteenwegen, D. (2010).                Singmann, H., Klauer, K. C., & Kellen, D. (2014). Intuitive
     Feeling we’re biased: Autonomic arousal and reasoning              logic revisited: new data and a Bayesian mixed model
     conflict.     Cognitive, Affective, &          Behavioral          meta-analysis. PloS One, 9(4).
     Neuroscience, 10(2), 208–216.                                  Stanovich, K. E., & West, R. F. (2000). Individual
De Neys, W., Novitskiy, N., Ramautar, J., & Wagemans, J.                differences in reasoning: implications for the rationality
     (2010). What makes a good reasoner?: Brain potentials              debate? The Behavioral and Brain Sciences, 23(5),
     and heuristic bias susceptibility. In Proceedings of the           645–665; discussion 665–726.
     Annual Conference of the Cognitive Science Society             Stupple, E. J. N., Ball, L. J., Evans, J. S. B. T., & Kamal-
     (Vol. 32, pp. 1020–1025).                                          Smith, E. (2011). When logic and belief collide:
De Neys, W., Rossi, S., & Houdé, O. (2013). Bats, balls, and            Individual differences in reasoning times support a
     substitution sensitivity: cognitive misers are no happy            selective processing model. Journal of Cognitive
     fools. Psychonomic Bulletin & Review, 20(2), 269–273.              Psychology,                 23(8),                931–941.
De Neys, W., Vartanian, O., & Goel, V. (2008). Smarter than             https://doi.org/10.1080/20445911.2011.589381
     we think: when our brains detect that we are biased.           Teovanović, P., Knežević, G., & Stankov, L. (2015).
     Psychological Science, 19(5), 483–489.                             Individual differences in cognitive biases: Evidence
Evans, J. S. B. T. (2003). In two minds: dual-process                   against one-factor theory of rationality. Intelligence, 50,
     accounts of reasoning. Trends in Cognitive Sciences,               75–86.
     7(10), 454–459.                                                Travers, E., Rolison, J. J., & Feeney, A. (2016). The time
Evans, J. S. B. T. (2010). Intuition and Reasoning: A Dual-             course of conflict on the Cognitive Reflection Test.
     Process Perspective. Psychological Inquiry, 21(4), 313–            Cognition, 150, 109–118.
     326.                                                           Yeung, N., & Summerfield, C. (2012). Metacognition in
Frederick, S. (2005). Cognitive reflection and decision                 human decision-making: confidence and error
     making. Journal of Economic Perspectives, 25–42.                   monitoring. Philosophical Transactions of the Royal
                                                                        Society B: Biological Sciences, 367(1594), 1310–1321.
                                                                396

