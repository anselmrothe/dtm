Please Explain: Radical Enactivism and its Explanatory Debt
Lachlan Douglas Walmsley (lachlan.walmsley@anu.edu.au)
School of Philosophy, 9 Fellows Road
Canberra, ACT 2602 Australia

have given us good reasons to think otherwise (Kaplan
2015; Kaplan & Bechtel 2011). Although many of the
dynamical models appealed to by the RECers provide
elegant and predictive descriptions of phenomena, they do
not explain those phenomena. Their second alternative, I
call the historical explanation. Although this is a good
explanation, it is, by itself, not the right kind of explanation
to compete with the representational explanation. Even with
the addition of associationist mechanisms, the explanation
still fails to explain certain intelligent behaviour, a limitation
that led to the initial widespread endorsement of the
representational explanation in cognitive science. Therefore,
RECers owe us an explanation of cognition that can displace
the representational explanation.3

Abstract
Radical Enactivism is a position in the philosophy of
cognitive science that aims to displace representationalism,
the dominant position in cognitive science for the last 50-60
years. To accomplish this aim, radical enactivism must
provide an alternative explanation of cognition. Radical
enactivism offers two alternative explanations of cognition.
The first I call the dynamical explanation and the second I call
the historical explanation. The mechanists have given us
reasons for doubting that the first alternative makes for a good
explanation. The historical explanation does not hit the right
explanatory target without the introduction of a proximate
mechanism, but the proximate mechanisms suggested by
radical enactivism are associationist mechanisms, the
limitations of which led to the initial widespread endorsement
of representationalism. Therefore, radical enactivism cannot
displace representationalism in cognitive science.

2 The Representational Explanation

Keywords: radical enactivism, representation, dynamical
explanation, computationalism, explanation

1 Introduction
Radically enactive cognition (REC) is a position in the
philosophy of cognitive science aiming to displace
representationalism (Hutto & Myin 2013), the dominant
position in cognitive science for the last 50-60 years.1 To
accomplish this aim, proponents of REC—or RECers—
must settle their explanatory debt by providing us with an
alternative explanation of cognition. Cognition, here, is
understood in a non-question begging biological sense as
that system functioning to coordinate behaviour intelligently
(Godfrey-Smith 1996).2 It’s a familiar phenomenon. It’s
what happened when you wrote your last paper or organised
your last workshop. It’s probably what happened when you
performed some less sophisticated tasks too. The RECers
owes us an explanation of that. For half a century, the
representational explanation of cognition has been the
defining explanation of cognitive science—“the only game
in town” (Fodor 1975). But the RECers argue that the
representational explanation is bad. If we can’t play the
representation game anymore what game shall we play?
REC is committed to two alternative explanations of
cognition. The first, I call the dynamical explanation. Here,
RECers presuppose that all dynamical models make for
good explanations, and David Kaplan and William Bechtel
1
Radical enactivism is just one position in the greater antirepresentationalist movement in the philosophy of cognitive
science. Less ambitious positions within this movement will not be
discussed in this paper.
2
This understanding does not presuppose that cognition must be
explained by appealing to representation.

According to the representational explanation, intelligent
behaviour is coordinated through the manipulation and
transformation of information-bearing structures called
representations. There are a number of versions of the
explanation, however, owing to the different ways in which
the term “representation” has been used. William Ramsey
identifies four ways in which the term has been used
(Ramsey 2007). Here, I defend only the representational
explanation of the classical computational theory of
cognition (CCTC), so only two of the four notions of
representation Ramsey identifies are relevant: the IO-notion
and S-representation. For brevity’s sake, I will discuss only
the IO-notion (Ramsey 2007: 68-77).4
The IO-notion of representation is used to describe those
situations in which some structure standing in for another is
taken as a system’s input (hence the “I”) and transformed
into another structure (again standing in for yet another
structure), which is its output (hence the “O”). If this is a
little abstract, imagine a calculator taking as input some
structures standing in for numbers and mathematical
operators—say, “2,” “3,” “+,” and “=.” All going well, the
calculator transforms its input into another structure, “5,”
which stands in for the number five, and which the
3
There is another class of alternatives to the representational
explanation as I characterize it in §2, which I call cognitiveneuroscience explanations. REC does not offer these explanations
so they won’t be considered here. Relating the representational
explanation to these alternatives will be left for future work.
4
CCTC can be made more rigorous with any number of formal
theories of computation. Here, I follow Gallistel and King’s and
assume a functioning homomorphism view of computation and the
Turing machine mathematical formalism because these apply to
the desert ant example in section 4.1 (see Gallistel & King 2009:
196-206).

1313

calculator gives as its output. Here’s another example.
Imagine a face recognising computer. Again, its input is a
structure standing in for another structure, a face in this
case. Let’s say its input is a portrait of Charles Darwin. All
going well, the computer transforms its input and gives as
output a different structure that stands in for the individual
to whom the face belongs. Something like “Charles
Darwin.” CCTC models the transformation of a structure
from input to output as a series of operations carried out by
component sub-systems. Each sub-system also takes as its
input structures standing in for other structures and gives as
its output yet more such structures. It is due to this on-going
replacement and its role in the transformation of system
input to system output that CCTC takes such systems to
manipulate and transform structures standing in for other
structures—that is, representations.5
If you are sceptical of CCTC’s representational
explanation then consider the digital computer. The digital
computer can perform calculation and facial recognition as
in the examples above and does so in the way I’ve
described. The digital computer is a paradigm case of a
physical system for which the representational explanation
is good. It is, in effect, an existence proof for good
representational explanations. No matter what position you
occupy in the philosophy of cognitive science, if it follows
from your argument that the representational explanation of
a digital computer is bad, then that is a reductio against your
argument. Whether or not the representational explanation is
good for human cognition is an empirical question. But
RECers argues that the representational explanation of
human cognition is bad on theoretical grounds.

2.1 The Cost of the Representational Explanation
RECers claim that we should reject the representational
explanation because it is too metaphysically demanding to
be naturalised.6 A naturalistic explanation, here, is
understood as one that can be squared with our current
scientific knowledge—no spooky stuff. The representational
explanation is too metaphysically demanding, REC claims,
because it posits the existence of content, which determines
what a structure stands for: the structure “5” stands in for
the number five because of its content. According to REC,
no naturalistic account of content has succeeded in
explaining the “special properties,” such as “truth,
reference, implication,” attributed to content (Hutto & Myin
2013: 67). These properties make content, and hence the

5

This is a minimal conception of CCTC. Many classical
computationalists, such as Jerry Fodor (1975), endorse a language
of thought, but CCTC is compatible with the absence of a language
of thought. Furthermore, CCTC need not (and I think should not)
posit anything like that found in our folk psychological theories
(Stich 1983).
6
This is not the only reason RECers have for rejecting
representations. For example, another reason, which I deal with
below, concerns the causal efficacy of semantic properties. For
brevity’s sake I can present no more reasons here.

representational
explanation,
“too
metaphysically
extravagant to be accepted by hard- nosed naturalists” (21).
As a naturalist, I shy away from metaphysical
extravagance, and I agree that no naturalistic account of
representation has explained content as REC understands it.
But I resist the assumption that content must have such
metaphysically demanding properties, such as truth and
reference. One reason why REC might make this
assumption is because their emphasis is partly on mentality
and the mind: “Enactivism is inspired by the insight that the
embedded and embodied activity of living beings provides
the right model of understanding minds” (Hutto & Myin
2013: 4, my emphasis). The focus of the representational
explanation radical enactivists hope to displace, however, is
not on the mind but on cognition. It may prove difficult to
give good naturalistic explanations of the mind’s features
because the mind simply doesn’t lend itself to good
naturalistic explanation. But I will leave that to the
philosophers of mind.
Can we make do with less metaphysically demanding
accounts of representational in cognitive science? I think we
can. Furthermore, I think REC must also make do with less
metaphysically demanding accounts of representation
because they are committed to the existence of public
representational systems, such as public language. How
does “5” come to stand in for (at least in most instances) the
number five in our public language? Radical enactivists
cannot answer that “5” stands for the number five because
of representations internal to the language users. The
meaning of public representations can’t be due to something
metaphysically extravagant in your head or in mine. Such an
answer is anathema to RECers. Instead, public structures
like “5” come to stand in for what they do in virtue of the
interactions between public language users (Hutto 2008).
This was, roughly, Wittgenstein’s view of language in his
Philosophical Investigations. According to this view, “5”
stands in for the number five because we use that structure,
either as a written symbol or as an utterance, in those
situations involving five-type things, such as when we ask
someone to fetch five stones or to wait five days. Over time,
language users become expert at recognising situations like
these and can use “5” in situations involving much more
complicated or abstract entities, like dollars and electrons.
For Wittgenstein, structures stand in for other structures (in
most cases) in virtue of their functional role in a system of
public language users. In slogan form: “the meaning of a
word is its use in the language” (Wittgenstein 2009/1953:
§43). So “5” or “five” means (has as its content) the number
five because of the way in which “5” is used in a
community of language users.7
REC is committed to something like Wittgenstein’s
meaning-as-use account. A metaphysically undemanding
explanation of representation such as this can generalise to
cognitive systems. Just as utterances can be said to stand in
for other structures in virtue of their functional role in a
7

This is only a sketch of Wittgenstein’s view, but a sketch will
do here.

1314

public system, so can structures in a computational system.
These structures can be said to stand in for others in virtue
of how they are passed between the different sub-systems of
the computational system and how they are transformed by
each sub-system—that is, how they are used within and by
the system. You might be sceptical of a Wittgensteinflavoured meaning-as-use account of representation. And
it’s fine if you are. All that’s important here is that REC is
committed to an explanation of interactions between
organisms—that is, human public practices—that involves
representation and avoids metaphysical extravagance. If
public practice can be given a metaphysically undemanding
representational explanation then so can cognition. There is
no reason to suppose that representational explanations of
intraorganism processes will be any more metaphysically
extravagant than those for interorganism processes.
Advancing the representational explanation, at least as it
is understood in CCTC, does not entail positing anything as
problematic as REC suggests it does. As I outlined above,
within CCTC we can posit representations and explain
representational content in virtue of a structure’s function
within the computational system. A structure stands in for
what it does because of the role that structure plays in the
computational system. Furthermore, this way of grounding
content is analogous to REC’s strategy for grounding the
content of public representations. So, if REC remains
sceptical of CCTC’s representational explanation, as I have
outlined it in this section, then they must rethink their own
commitments to the existence of public representational
systems.
Furthermore, according to CCTC’s representational
explanation, structures in a computational system are not
causally efficacious because of their content. They are
causally efficacious because of how their formal properties
map onto physical parts of the target system, such as
transistors or neurons (Fodor 1981; Pylyshyn 1984; Gallistel
and King 2009). If the RECers suppose the representational
explanation requires that structures be causally efficacious
because of their content then they are setting up a straw
person. Hence, I take it this is not their position. If the
RECers accept CCTC’s representational explanation but
reject other versions of the representational explanation,
such as those according to which structures are causally
efficacious in virtue of their content, then they are
conservatives, classical computationalists rather than
radicals. Hence, I take it this is not their position. Instead, I
take it that REC is a position according to which CCTC’s
representational explanation is unnecessary for explaining
any intelligent behaviour. This is an empirical question. And
we have good reasons to answer it in favour of the
representational explanation (see §4.1 especially). From
here on, I argue that REC’s candidate replacement
explanations are not genuine alternatives to the
representational explanation of CCTC or, where they are
genuine alternatives, they fail to explain some intelligent
behaviour that the representational explanation can.

3 The Dynamical Explanation
The first alternative to the representational explanation
offered by REC is the dynamical explanation: “the vast sea
of what humans do and experience is best understood by
appealing to dynamically unfolding, situated embodied
interactions and engagements with worldly offerings”
(Hutto & Myin 2013: ix). Dynamical explanations are
constructed with the language of dynamical systems theory,
which models how physical systems change over time with
differential and difference equations. These equations
quickly become analytically intractable as structures or
details are added but their solutions can be satisfactorily
approximated using numerical methods and computer
simulation. From the approximate solutions, modellers
create geometric visualisations of the different ways in
which the system can change over time as transitions
through a state space. The explanation’s language is
complex, but it need not concern us here. The problem with
dynamical explanations is not the language in which they
are described.
A paradigm case of a dynamical model is the HakenKelso-Bunz (HKB) model of human hand movements
(Haken et al. 1985). The model captures “voluntary
oscillatory motions of the two index fingers”—that is, the
movement of your index fingers when you move them back
and forth in a coordinated fashion, either symmetrically or
asymmetrically. In particular, it captures the abrupt change
from asymmetrical and symmetrical coordination when the
oscillations reach a certain frequency. HKB is a
phenomenological model, built to have a close qualitative fit
with the system’s behaviour: the “first step in the
development of the model is to provide a mathematically
accurate description of the main qualitative features of the
data” (349).
HKB has received much attention because it is a minimal
model of a “relatively simple two-component system”
(Bressler & Kelso 2001: 28) with predictive power,
capturing the dynamics of a wide range of interactions
including those between an agent and their environment
(Kelso 1994) and between two agents (Schmidt et al. 1990).
For RECers and similarly inclined anti-representationalists,
models like this provide good alternative explanations
because they make simple and generalisable predictions
(without positing content): “If models are accurate enough
to describe observed phenomena and to predict what would
have happened had circumstances been different, they are
sufficient as explanations” (Chemero & Silberstein 2008:
12). Although accurately describing the behaviour of a large
class of systems is a virtue of these models, good
descriptions and predictions are not sufficient for
explanation.
Dynamical explanations of the intelligent coordination of
behaviour can only be genuine alternatives to the
representational explanation if they are genuine
explanations. Dynamical explanations are only genuine
explanations if the predictions and descriptions of behaviour
offered by models like HKB are also explanatory.

1315

Description and prediction are certainly similar to
explanations. The covering law account of explanation, for
example, treats them as having the “same logical character”
as each other (Hempel 1958: 37; 1965). But they are
importantly different from explanation (Kaplan 2015;
Kaplan & Bechtel 2011). The difference between
description and explanation is obvious: a description of a
phenomenon is simply a statement of the explanandum. The
difference between prediction and explanation is not so
obvious but just as real.
To see the difference between prediction and explanation,
imagine a flagpole, which casts a shadow as the sun rises
and sets. As the position of the sun changes, so does the
shape and size of the shadow. The two change together with
law-like regularity. Hence, we can use the height of the
flagpole along with the position of the sun and some
mathematics to predict the shape and size of the shadow.
We can also use the shape and size of the shadow along
with the position of the sun and some mathematics to
predict the height of the flagpole, but we cannot explain the
height of the flagpole in virtue of the shadow’s shape and
size. Although predictions can run either way, from flagpole
to shadow and from shadow to flagpole, explanations run in
only one direction—in this case, from flagpole to shadow
(Bromberg 1966; also Kaplan & Bechtel 2011: 440-441).
Explanations must inform us of that which gives rise to a
phenomenon, so an explanation of the height of the flagpole
would appeal to the factory in which it was made, but not to
its shadow.
Precise mathematical models of behaviour like HKB are
not the explanans.8 They are the explanandum. This is not
especially controversial; dynamical modellers themselves
are aware of this. Haken et al., for example, admit of their
model that it describes the coupling between the two hands
but says nothing about what gave rise to that coupling and
leave this for “further theoretical and experimental research”
(Haken et al. 1985: 355). Short an actual explanation of the
phenomena described by HKB, Haken et al. provide a howpossible explanation, describing a mechanism that might be
responsible for causing the phenomena: “one coupling
might be established via the corpus callosum, the wellknown band of fibres that joins the two hemispheres of the
brain” (ibid.). Another explanation of the regularities
described by dynamical models like HKB may involve the
manipulation and transformation of information-bearing
structures. The behaviour of digital computers, for example,
can be modelled using the tools of dynamical systems
theory, but, as I said above, it is a paradigm case of a system
for which the representational explanation is good. Hence,
dynamical models of cognition—explanatory or not—are
compatible with representational explanations. Even if
8
As Kaplan (2015) argues, dynamical models can be
explanatory when construed as representing the dynamics of the
mechanism responsible for the phenomena to be explained, but not
when they are merely phenomenological. In these cases, the
mechanism and not just its dynamic behaviour constitute the
explanation.

REC’s dynamical explanation were genuinely explanatory it
would be compatible with representational explanation.

4 The Historical Explanation
REC’s second alternative to the representational explanation
is the historical explanation. In this case, cognition is
explained in virtue of an agent’s “history of previous
engagements and not in some set of internally stored mental
rules and representations” (Hutto & Myin 2013: 9). To
make this concrete, imagine some behaviour:
“Someone is living in a house with a kitchen in the hallway,
such that she has to walk around a sideboard to get to the
other side. Suppose that at some point the sideboard gets
removed, but that the person still takes the same curve to get
to the other side of the hall.” (Degenaar & Myin 2014:
3642)
Here is the historical explanation of that behaviour:
“In the new situation, the person is going through the same
old motions in absence of the environmental basis for these
motions. Over the years, a behavioural pattern has emerged:
the person tends to take a particular trajectory when walking
through the hallway.” (Degenaar & Myin 2014: 3642)
The historical explanation is neither mere prediction nor
description. Unlike REC’s first alternative explanation, its
second is genuinely explanatory. However, it is still not a
genuine alternative to the representational explanation.
Rather, it is compatible with the representational
explanation. As Jan Degenaar and Erik Myin say of the
above example, “This might involve representations or it
might not” (Degenaar & Myin 2014: 3642).
The historical explanation is not the right kind of
explanation to be an alternative to the representational
explanation because the historical explanation is an ultimate
explanation, while CCTC’s representational explanation is a
proximate explanation. Niko Tinbergen (1963) first made
the distinction between proximate and ultimate
explanations. An example will help illustrate the distinction:
humans regularly help needy others at a cost to themselves.
One explanation of this behaviour is that empathising with
needy others motivates us to help them (Batson 2011). This
is a proximate explanation. It tells you about the mechanism
here and now—empathy—that produces the helping
behaviour. But why this sort of mechanism? Why are we
empathetic? This question calls for an ultimate explanation,
which might explain the helping behaviour as the result of
selection for a particular behavioural disposition in terms of
benefits to an organism or group’s fitness. For example,
perhaps our empathetic ancestors were better carers for their
and their kin’s young, so our empathetic ancestors did better
than our nonempathetic ones and empathy spread through
the population (De Waal 2008). Importantly, ultimate
explanations need not refer to evolution. They can also refer
to an agent’s developmental history (Baum 1994). For
example, an ultimate explanation of an agent without the

1316

disposition to help may be that their helping was rewarded
materially early in their developmental history such that the
agent came to expect material rewards to follow from
helping (Warnaken & Tomasello 2014). Hence, when there
are no material rewards on the horizon, the agent doesn’t
help. Here, our ultimate explanation refers to a learning
process rather than an evolutionary one.
Proximate and ultimate explanations are natural partners,
with one explaining the mechanism producing the behaviour
here and now and the other explaining why that kind of
mechanism exists instead of another. Since REC’s historical
explanation is compatible with the representational
explanation it is no real alternative at all.

4.1 The Proximate Explanation
RECers might respond that their historical explanation does
involve a proximate mechanism, which is something akin to
what Kim Sterelny (2003) calls a detection system.
Detection systems link certain environmental stimuli with
certain behavioural responses and do not involve the
manipulation and transformation of information-bearing
structures.9 In the example above, entering the hallway has
been linked with the response of taking a particular
trajectory. This connection has been wired up through
something like simple association-based learning—the
hallway becomes associated with taking the trajectory in
virtue of certain rewards, such as not bumping into the
sideboard. But detection systems can also be wired up
through evolutionary processes. Organisms can be born
responding to particular stimuli with particular responses
because such organisms have had greater reproductive
success. The infamous male Photuris firefly, for example, is
born with such a detection system, which links a certain
series of flashes with the response of flying toward the
source of the flashes. Female Photuris fireflies produce
these flashes and males find them, so the two can mate.
Although often effective, detection systems are fragile.
The Photinus firefly’s detection system is exploited by the
Photuris firefly. They produce the flashing just like the
Photinus females, catching and eating a fair number of
unfortunate males (Lloyd 1965). Sterelny’s robust systems
are, as the name suggests, less fragile than detection
systems. These link a number of environmental stimuli with
a particular response. But even these have their limits. Once
the causal chain through which a relevant aspect of an
environment and an appropriate behavioural response are
linked becomes sufficiently complex and rare, it becomes
invisible to whatever processes build detection and robust
systems, such as associationist learning or evolution by
selection. Sterelny argues that this is the case in complex
social environments in which deception is common and
multi-place relations between group members matter, and
from which language can emerge as it has in the case of
human lineage. Explaining human cognition, then, will
9

Some might want to resist this claim and argue that detection
systems do involve information-bearing structures. For good
reasons to not to resist see (Ramsey 2007).

require a proximate explanation appealing to more than
detection systems and associationist learning.
If the only good proximate explanation RECers have up
their sleeves is one involving associationist mechanisms
linking a stimulus with response in virtue of a history of
interaction then that’s a problem. As Sterelny argues, the
complexities of social life are such that stimulus-response
systems like Photinus’s just won’t do. But REC needs more
than a good proximate explanation for human social
behaviour (here, RECers will argue is richly scaffolded by
shared practices and hence not as computationally
demanding as it seems). REC also needs one for the
behaviour of much simpler organisms, such as insects
(Gallistel 1990, Gallistel & King 2009). Desert ants, among
other insects, often trace winding paths away from their
nests as they forage. Upon returning to their nests, they
don’t retrace their steps, but take an almost direct route.
This is known as path integration or dead reckoning. It
requires integrating information both about the distance and
direction travelled from the nest. This ability has been
experimentally demonstrated (Wehner & Srinivasan 1981).
In Wehner and Srinivasan’s experiment, ants forage from
their nest to a feeder station 20m away. Upon reaching the
feeder station, the ants are transferred to a test area several
hundred meters away with a replica feeder station. From this
replica, the ants take a direct path to where their nest should
be. When they reach this point they begin searching for their
nest in different directions. In these experiments, the ants
are clearly not using environmental cues. If they were, they
would find their actual nest, not where their nest should be.
Their destination is a novel location, so they cannot be
navigating by anything like habit. In this instance, there is
no history of on-going interactions to appeal to and no
stable environmental stimuli with which behaviour can be
associated. A good explanation is one positing a
computational process involving representations of the ants’
location relative to the nest and feeder station.

5 Revolution?
The radical enactivists owe me an explanation. They owe
you one too. They owe us all an explanation of how
biological systems like you and I behave in the complicated
ways we do. They owe us an explanation of cognition.
Importantly, the explanation cannot one of those advanced
before the cognitive revolution. You cannot displace the
representational explanation with stimulus-response
mechanisms because the representational explanation
initially gained traction in virtue of the limitations of such
mechanisms.
So what new explanations are on offer? There is the
dynamical explanation, according to which our actions are
the results of dynamically unfolding interactions with our
environments. But what explains why these dynamics obtain
instead of others? When I become reciprocally coupled with
my environment, what initiates and maintains that coupling
such that my behaviour can be predicted with a set of
elegant differential equations? Although the models of the

1317

dynamical explanation can offer mathematically precise
descriptions of behaviour, they don’t explain why those
descriptions hold. If those in the radical camp want an antirepresentational revolution, they must fill the explanatory
gap left by the representational explanation. So far, they
have failed to do this.

Acknowledgments
Thank you to Ronald Planer and David Kalkman for their
comments on drafts of this paper. Thank you also to three
anonymous reviewers whose comments were both fair and
insightful. Funding was provided by Australian Research
Council (Grant No. ARC FL13).

References
Batson, C. D. (2011). Altruism in humans. Oxford: Oxford
University Press.
Baum, W. M. (1994). Understanding behaviorism: Science,
behavior, and culture. New York: Harpercollins College
Division.
Bressler, S. L. & Kelso, J. A. S. (2001). Cortical
coordination dynamics and cognition. Trends in cognitive
science, 5, 26-36.
Bromberger, S. (1966). Why questions. In R. G. Colodney
(ed.). Mind and Cosmos. Pittsburgh, PA: University of
Pittsburgh Press.
Chemero, A. & Silberstein, M. (2008). After the philosophy
of mind: replacing scholasticism with science. Philosophy
of Science, 75, 1-27.
De Waal, F. B. M. (2008). Putting the altruism back into
altruism: the evolution of empathy. Annual Review of
Psychology, 59, 279-300.
Degenaar, J. & Myin, E. (2014). Representation-hunger
reconsidered. Synthese, 191, 3639-3648.
Fodor, J. A. (1975). The Language of Thought, Cambridge,
MA: Harvard University Press.
Fodor, J. A. (1981). Representations. Cambridge, MA: MIT
Press.
Gallistel, C. R. & King, A. (2009). Memory and the
Computational Brain. Malden: Wiley-Blackwell.
Godfrey-Smith, P. (1996). Complexity and the Function of
Mind in Nature. Cambridge: Cambridge University Press.
Haken, H., Kelso, J. A. S., & Bunz, H. (1985). "A
theoretical model of phase transitions in human hand
movements," Biological Cybernetics, 51, 347-356.
Hempel, C. G. (1958). The theoretician's dilemma: A study
in the logic of theory construction. Minnesota Studies in
the Philosophy of Science, 2, 173-226.
Hempel, C. G. (1965). Aspects of scientific explanation.
Aspects of Scientific Explanation; And other Essays in the
Philosophy of Science. New York: The Free Press.
Hutto, D. D. (2008). Folk Psychological Narratives: The
Sociocultural Basis of Understanding Reasons.
Cambridge, MA: MIT Press.
Hutto, D. D. & Myin, M. (2013). Radicalizing Enactivism:
Basic Minds Without Content. Cambridge, MA: MIT
Press.

Kaplan, D. M. (2015). Moving parts: the natural alliance
between dynamical and mechanistic modeling
approaches. Biology & Philosophy, 30, 757-786.
Kaplan, D. M. & Bechtel, W. (2011). Dynamical models: an
alternative or complement to mechanistic explanations?
Topics in Cognitive Science, 3, 438-444.
Kelso, J. A. S. (1994). Elementary coordination dynamics.
In S. P. Swinnen, H. Heuer, J. Massion, & P. Casaer
(eds.). Interlimb Coordination: Neural, Dynamical, and
Cognitive Constraints. San Diego: Academic Press: 301318.
Lloyd, J. E. (1965). Aggressive mimicry in Photuris: firefly
femmes fatales. Science, 149, 653-654.
Pylyshyn, Z. (1984). Computation and Cognition.
Cambridge, MA: MIT Press.
Ramsey, W. M. (2007). Representation Reconsidered.
Cambridge: Cambridge University Press.
Schmidt, R. C., Carello, C., & Turvey, M. T. (1990). Phase
transitions and critical fluctuations in the visual
coordination of rhythmic movements between people.
Journal of Experimental Psychology: Human Perception
and Performance, 16, 227.
Sterelny, K. (2003). Thought in a Hostile World: The
Evolution of Human Cognition. Malden: Blackwell
Publishing.
Stich, S. P. (1983). From Folk Psychology to Cognitive
Science: The Case Against Belief. Cambridge, MA: MIT
Press.
Tinbergen, N. (1963). On aims and methods of ethology.
Zeitschrift für Tierpsychologie, 20, 410-433.
Warneken, F. & Tomasello, M. (2014). Extrinsic rewards
undermine altruistic tendencies in 20-month-olds.
Motivation Science, 1, 43-48.
behaviour of desert ants, genus Cataglyphis (Formicidae,
Hymenoptera). Journal of Comparative Physiology, 142,
315-338.
Wittgenstein, L. (2009/1953). Philosophical Investigations.
Trans. G. E. M. Anscombe, P. M. S. Hacker, & J. Schulte.
4th ed. Malden: Wiley-Blackwell.

1318

