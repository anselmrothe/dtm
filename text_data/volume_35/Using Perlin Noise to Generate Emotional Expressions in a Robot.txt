UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using Perlin Noise to Generate Emotional Expressions in a Robot
Permalink
https://escholarship.org/uc/item/4qv84958
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Beck, Aryel
Hiolle, Antoine
Cañamero, Lola
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                Using Perlin Noise to Generate Emotional Expressions in a Robot
                                                 Aryel Beck (aryelbeck@gmail.com)
                                                Antoine Hiolle (a.hiolle@herts.ac.uk)
                                             Lola Cañamero (l.canamero@herts.ac.uk)
                    Embodied Emotion, Cognition and (Inter-)Action Lab, School of Computer Science & STRI
                               University of Hertfordshire, College Lane, Hatfield, Herts AL10 9AB, UK
                               Abstract                                the same time lively and flexible enough to be believable and
                                                                       engaging.
   The development of social robots that convey emotion with
   their bodies—instead of or in conjunction with their faces—
   is an increasingly active research topic in the field of human-                                 Affect Space
   robot interaction (HRI). Rather than focusing either on pos-        This study is part of our research investigating the elabora-
   tural or on dynamics aspects of bodily expression in isolation,
   we present a model and an empirical study where we combine          tion of an Affect Space for the generation of emotional body
   both elements and produce expressive behaviors by adding dy-        language to be displayed by robots. It builds on an Affect
   namic elements (in the form of Perlin noise) to a subset of         Space that was generated using key poses (Beck, Cañamero,
   static postures prototypical of basic emotions, with the aim of
   creating expressions easily understandable by children and at       & Bard, 2010; Beck, Hiolle, Mazel, & Cañamero, 2010). In
   the same time lively and flexible enough to be believable and       the context of this paper, a key pose is a posture modeled after
   engaging. Results show that the noise increases the recognition     an actor performance so that it clearly describes the emotion
   rate of the emotions portrayed by the robot.
                                                                       displayed.
   Keywords: Bodily emotional expression; human-robot inter-
   action; affective robotics; Perlin noise.                           Static features
                                                                       In animation, one of the standard methods for creating con-
                          Introduction                                 vincing and believable displays relies on expressive key poses
Echoing the importance of emotional expression in social               rather than body language in motion (Thomas & Johnston,
interaction and communication among humans, the devel-                 1995; Vala, Paiva, & Rui Gomes, 2008). Taking inspira-
opment of expressive robots that can interact with us in a             tion from this method, in previous work (Beck, Cañamero,
human-oriented way is nowadays a very active research topic            & Bard, 2010; Beck, Hiolle, et al., 2010) we used static key
in the field of human-robot interaction (HRI). Interest in using       poses as a basis to produce expressive animated behaviors in a
robot’s bodies for emotional expression is rapidly increasing.         humanoid robot. This method presents the advantage of per-
This is partly due to two main factors. On the one hand, an in-        mitting to investigate and model independently postural and
creasing corpus of research in psychology and neuroscience             motion-related expressive elements. This approach is also
(e.g., (Wallbott, 1998; De Gelder, 2006; Avizer, Trope, &              consistent with research on affective body expression sug-
Todorov, 2012)) is emphasizing the role of the body in con-            gesting that form and movement information are processed
veying emotion-specific information rather than merely non-            by separate pathways in the brain (Kleinsmith & Bianchi-
specific information related to intensity as it was previously         Berthouze, 2012). The key poses that we used are consistent
thought. On the other hand, the fact that a number of ro-              with the static features3 in (Kleinsmith, Bianchi-Berthouze,
botic platforms currently available have complex bodies with           & Steed, 2011).
a high number of degrees of freedom and/or good motion cap-               Our initial experiments (Beck, Cañamero, & Bard, 2010)
abilities, but do not necessarily have articulated faces—that is       showed that it is possible to successfully convey emotions
the case in Nao1 , the robot that we have used in this study.          using static key poses displayed by a Nao humanoid robot.
   While researchers typically focus either on the use of              Based on these results, we started to develop a continuous
expressive postural elements or on expressive aspects of               Affect Space for our robot by “blending” key poses to gener-
movement (Coulson, 2008)—see (Kleinsmith & Bianchi-                    ate new expressions (Beck, Hiolle, et al., 2010). The resulting
Berthouze, 2012) for a survey—the combination of both as-              system maps static key poses into a continuous dimensional
pects has not received as much attention in robotics. In the           model of emotion. Empirical results regarding the interpreta-
study resented here, we combine both elements and produce              tion of the static key poses generated by this Affect Space can
expressive behaviors by adding dynamic elements to a subset            be found in (Beck, Hiolle, et al., 2010). While some of the ex-
of static postures prototypical of basic emotions. Our under-          pressions were clearly recognized, our results also show that
lying motivation from the point of view of HRI2 , as part of           some of the generated key poses are ambiguous and do not
the European project ALIZ-E (www.aliz-e.org), was to create            convey a clear emotion. In addition, feedback from people in-
a set of expressions easily understandable by children and at          teracting with the robot indicated that they found it too static,
    1 www.aldebaran-robotics.com.
                                                                       which might have a negative impact on the perception on the
    2 See (Cañamero, 2002, 2008) for discussions of design issues         3 In particular, the collar joint angle was also found to be salient
regarding expressive robots for HRI.                                   to the expression of emotion through body posture.
                                                                   1845

robot and hence on the interaction. This led us to hypothes-           This mapping was chosen, rather than directly using the
ize that the addition of dynamic aspects to the key poses could        speed of the motors, due to constraints imposed by our
greatly improve the understanding and believability of the ex-         robot. However, it should be noted that the actual velo-
pressions.                                                             city of the movement also depends on the amplitude of the
                                                                       noise, since the time is kept constant but the amplitude var-
Animating Emotional Key Poses Using Perlin Noise                       ies. Based on the existing literature, we expected that this
To endow the key poses with a dynamic dimension, we ad-                parameter would have a significant effect on the percep-
ded Perlin noise4 (Perlin, 1990) to them. In animation, Perlin         tion of the emotion as it is related to Quantity of Motion
noise—a coherent noise that is highly controllable—is a well-          (Camurri, Mazzarino, & Volpe, 2003), Speed (Roether,
known tool used to procedurally generate movements and in-             Omlor, Christensen, & Giese, 2009; Bernhardt, 2010) and
crease the lifelikeness of animations. It presents the advant-         Activation (Wallbott, 1998; Hartmann, Mancini, Buisine,
ages of being simple and computationally cheap, which are              & Pelachaud, 2005).
important factors for implementation on a robotic platform.
                                                                    • Jerkiness was introduced by applying random variations
Moreover, the parameters used to generate it can be modu-
                                                                       to the duration parameter, slightly modifying the interval
lated, resulting in different types of animations. Perlin noise
                                                                       of update of the joint angle. The literature suggests that
can be used to modify movement but also to create different
                                                                       jerkiness has a strong effect on the expression of emo-
types of non-repetitive and “idle” behaviors, as well as to gen-
                                                                       tion (Hartmann et al., 2005; Lee, Park, & Nam, 2007;
erate textures. In robotics, Perlin noise and similar methods
                                                                       Bernhardt, 2010).
have also been used, applied to joint angles, to increase the
lifelikeness of robot movements and to generate idle behavi-
ors (Snibbe, Scheeff, & Rahardja, 1999; Ishiguro, 2005).
                                                                                          The Experiment
   Going beyond standard practice, in the work reported in          To assess the potential of using Perlin noise to express emo-
this paper we have used Perlin noise to generate all the move-      tions in robots, we designed a study to investigate the rela-
ments of the robot, rather to simply modify existing traject-       tion between characteristics of the movements generated us-
ories. The addition of Perlin noise values to the current joint     ing Perlin noise and the perceived emotion.
angles produces a Perlin noise-based animation for the cur-            Independent Variables: Three independent variables
rent pose of the robot. Although this step has not been valid-      were manipulated: Emotional Key Pose, Velocity and Jerki-
ated with formal perceptual studies, the movements generated        ness.
have been successfully used as idle behavior in empirical in-
                                                                    • Key Pose had five different values that corresponded to the
teraction studies with children carried as part of the ALIZ-E
                                                                       different emotions tested.
project (Nalin et al., 2012).
                                                                    • Velocity had three levels and described how fast the robot
Using Perlin Noise to Express Emotions                                 moved.
Following a “deep” approach to emotion modeling
                                                                    • Jerkiness had two levels. In the Jerky condition, the velo-
(Cañamero, 2008), affective expression in our robot is
                                                                       city of each movement (generated using Perlin noise) was
driven by the dynamics of the internal “affective state” of
                                                                       multiplied by a random value between 0.5 and 1.5 ensur-
the robot in its interaction with the world. Consequently,
                                                                       ing that the mean of the velocity remained the same but
movements produced by Perlin noise can be modulated by
                                                                       introducing variation of speed during the animation. In the
the internal state of the robot and used as a tool to express
                                                                       Regular (non-Jerky) condition, the speed (given by the Ve-
emotions. This novel use of Perlin noise can potentially be
                                                                       locity condition) remained constant throughout the whole
a powerful tool to create more subtle expressions in robots,
                                                                       animation.
since it permits to procedurally create non-repetitive body
movements that convey different emotions or nuances of the          This resulted in 35(5 Key Poses ∗ 3Velocity ∗ 2 Jerk + 5 static)
same emotion. Another advantage of our approach is that             animations tested.
such expression would not be limited to a single platform
and could be reused across different robots—both humanoid              Dependent Variables: Perception of emotion was defined
and non-humanoid.                                                   in terms of Emotional Label, Valence and Arousal.
   One of the main challenges posed by the use of Perlin noise
to express emotions is to find a mapping between the paramet-       Participants
ers used to generate the noise and the emotion to be conveyed.      20 Participants were recruited, mostly members of staff of the
In our model, we used the following mappings:                       University of Hertfordshire (9 females and 11 males) ranging
                                                                    in age from 18 to 55 (M=29.31, SD=11.93).
• Velocity was mapped to the time taken by the robot to
   move, i.e., the shorter the time the higher the velocity.        Apparatus
    4 See http://freespace.virgin.net/hugo.elias/models/            Five key poses were selected from previous studies (Figure
m perlin.htm for a description of the method used.                  1): two positive, two negative and one neutral that had been
                                                                1846

Figure 1: The five key poses (from left to right: sadness, an-         Table 1: Recognition rate of the Key Poses with and without
ger, neutral, pride, happiness)                                        added movements
                                                                         Emotion   Recognition Rate Static Recog. Rate with Movement Best Condition
                                                                         Sadness   84%                     100%                      Slow Regular
                                                                         Anger     42%                     68%                       Fast Regular
                                                                         Pride     63%                     74%                       Medium Regular
                                                                         Happiness 79%                     95%                       Fast Jerky
                                                                         Neutral   84%                     74%                       Medium Regular
                                                                            Figure 2: Effect of Changing the Key Pose on Valence
recognized well above chance level in previous studies (Beck,
Cañamero, & Bard, 2010; Beck, Hiolle, et al., 2010). To en-
sure stability, the robot was sitting and only the joint angles
of the upper body were modified while changing key pose.
The animations were generated by adding Perlin noise to the
joints of the upper body (as described above).
Procedure
The same experimenter tested all participants individually.
Once each participant had given consent at the beginning of
their session, they were given standardised explanation re-
garding the questionnaire that they were expected to answer
and were instructed to imagine that the robot was reacting to
something. In this context, Valence was defined as the ex-                As part of the validation of the material, a two-ways (static
tent to which this “something” was positive or negative, and           vs. highest recognition rate) Repeated Measures ANOVA
Arousal was defined as the level of energy (low to high en-            was conducted on the total Number of Correct Interpretations
ergy).                                                                 comparing the static display and the highest recognition rate
   After confirming that they understood all the questions,            with movement for each emotion. This was done to check
participants watched and assessed the 35 animations. Each              that it was possible to increase the recognition rate by adding
animation was displayed only once in a randomized order                movements generated with Perlin noise in at least one con-
different for each participant. A distance was introduced to           dition for the different key poses. The results show that this
avoid having the same pose coming twice in a row. Each                 was the case (F(1, 18) = 9.08, p < 0.01, η2 = 0.33). Table IV
time, the robot took a pose and displayed an animation dur-            also highlights the recognition rates as well as the conditions
ing 15 seconds and returned to a non-expressive key pose (a            in which the highest recognition rates were obtained.
second neutral pose) until the participant answered. For each             In the following sections, the data was analysed us-
animation, participants were asked to describe the animation           ing 5(Key Pose)*3(Velocity)*2(Jerkiness) Repeated Measures
using their own terms and eventually choose an emotion la-             Anovas on the dependent variables. It should be noted that
bel from a list of six emotions. The list was comprised of             since they do not have a Jerkiness condition, the static poses
Anger, Sadness, Fear, Neutral, Pride, Happiness and Excite-            were not included in these tests.
ment. Participants completed ratings of Valence and Arousal
on a 10-point Lickert scale. After all the poses had been as-          Effect of Changing the Key Pose Displayed
sessed, participants were fully debriefed. Each session lasted         Effect on the Number of Correct Interpretations As
approximately 30 minutes.                                              expected, Key Pose had a significant effect on the
                                                                       Number of Correct Interpretations (F(4, 72) = 6.89, p <
                            Results                                    0.01, partial η2 = 0.99). This indicates that overall, when
Since this experiment uses a modified set of key poses (unlike         displayed with movements, the key poses were not all equally
in the test of the static key poses, here the robot is sitting), it    well recognized. Post-Hoc tests (Least Significant Differ-
was necessary to validate the material created for this study.         ence) showed that the poses for Sadness and Pride were re-
                                                                       cognized better than the others (p < 0.01).
Validation of the Sitting Key Poses                                    Effect on Valence Key Pose had a significant effect on
Recognition rates showed that it was possible for participants         Valence (F(4, 72) = 33.26, p < 0.01, partial η2 = 0.65).
to correctly identify the different static key poses far above         Post-hoc tests (Least significant Difference) showed that the
chance level (Chance level would be 17%). Thus, it was pos-            pose for Sadness was perceived as more negative than the
sible for participants to identify the static key poses displayed      rest of the poses (p < 0.01 for all of them). The key pose
(Table 1).                                                             for Anger was perceived as more negative than Happiness
                                                                   1847

    Figure 3: Effect of Changing the Key Pose on Arousal          Table 2: Effect of Velocity and Jerkiness on Interpretation per
                                                                  Key Pose
                                                                    Key Pose   Effect of Velocity                     Effect of Jerkiness
                                                                    Sadness    F(2, 34) = 5.34, p < 0.05, η2 = 0.24   F(1, 17) = 11.73, p < 0.01, η2 = 0.41
                                                                               Slow > Medium(p < 0.05)                Regular > Jerki(p < 0.01)
                                                                               Slow > Fast(p < 0.01)
                                                                               Medium = Fast(p = 0.31)
                                                                    Anger      F(2, 34) = 6.21, p < 0.01, η2 = 12.43  F(1, 18) = 0.79, p = 0.39, η2 = 0.04
                                                                               Fast > Medium(p < 0.05)
                                                                               Fast > Slow(p < 0.01)
                                                                               Medium = Slow(p = 0.45)
                                                                    Neutral    F(2, 36) = 48.69, p < 0.01, η2 = 0.73) F(1, 18) = 0.00, p = 1, η2 = 0.00
                                                                               Slow > Fast(p < 0.01)
                                                                               Medium > Fast(p < 0.01)
                                                                               Slow = Medium(p = 0.1)
                                                                    Pride      F(2, 36) = 17.95, p < 0.01η2 = 0.50    F(1, 18) = 1.09, p = 0.31, η2 = 0.06
                                                                               Slow > Fast(p < 0.01)
                                                                               Medium > Fast(p < 0.01)
                                                                               Slow = Fast(p = 0.19)
                                                                    Happiness  F(2, 36) = 5.36, p < 0.01, η2 = 0.23)  F(1, 18) = 1.20, p = 0.29, η2 = 0.06
                                                                               Fast > Slow(p < 0.01)
                                                                               Fast = Medium(p = 0.09)
                                                                               Medium = Slow(p = 0.17)
(p < 0.01) and Pride (p < 0.01). There was however no sig-        ditions (p = 0.34). The Medium condition was perceived as
nificant difference between Anger and Neutral (p = 0.29).         significantly less positive than the Fast condition (p < 0.05).
Pride was perceived as significantly more positive than the          These results indicate that the fast movement condition was
rest of the key pose (p < 0.05 for all of them). Happiness        perceived as more positive than the other two.
was perceived as significantly more positive than Sadness         Effect on Arousal Velocity had a significant effect on
(p < 0.01), Anger (p < 0.01) and Neutral (p < 0.05) (Figure       Arousal (F(2, 36) = 93.60, p < 0.01, partial η2 = 0.84).
2)                                                                Post-Hoc tests (Least Significant Difference) showed that the
   These results indicate that participants’ perception of        Slow condition was perceived as less aroused than the Me-
Valence was affected by the Key Pose being displayed. Over-       dium condition (p < 0.01) which in turn was perceived as
all, negative key poses were interpreted as such and positive     less aroused than the Fast condition (p < 0.01).
key poses were interpreted as positive (Figure 2).                   These results indicate that overall the faster the movement
Effect on Arousal Key Pose had a significant effect on            is, the more aroused the expression is perceived.
Arousal (F(4, 72) = 13.29, p < 0.01, partial η2 = 0.42).
                                                                  Effect of Jerkiness
Post-Hoc tests(Least Significant Difference) showed that
Sadness was perceived as less aroused than Anger (p < 0.01),      Effect on Interpretation There was a trend of Jerky being
Pride (p < 0.01), and Happiness (p < 0.05). There was             more correctly interpreted than the same display in the Regu-
no significant difference between Sadness and Neutral (p =        lar condition (F(1, 18) = 4.21, p = 0.55, partial η2 = 0.49).
0.21). Anger was perceived as more aroused than Neutral           This was further explored while considering the interactions
(p < 0.01). However, there was no significant difference with     between the dependent variables.
Happiness (p = 0.26) and Pride (p = 0.37). Pride was per-         Effect on Valence Jerkiness had no significant effect
ceived as less aroused than neutral (p < 0.01). There was a       on Valence (F(1, 18) = 0.26, p = 0.62, partial η2 = 0.01).
trend toward Pride being perceived as less aroused than Hap-      These results indicate that overall, participants’ perception of
piness (p = 0.06).                                                Valence was not affected by the Jerkiness of the movements.
   These results indicate that perception of Arousal was af-
fected by the key pose being displayed (Figure 3).                Effect on Arousal Jerkiness had a significant effect on
                                                                  Arousal (F(1, 18) = 27.51, p < 0.01, partial η2 = 0.60).
Effect of Velocity                                                   Post-Hoc tests showed that the ”Jerky” condition was per-
                                                                  ceived as more aroused than the Regular one (p < 0.01).
Effect on Interpretation Velocity had a significant ef-
fect on the number of correct interpretation (F(2, 36) =          Interaction between the independent variables
11.02, p < 0.01, Partial η2 = 0.98). This effect was further      Interpretation There was an interaction between Key Pose
investigated while looking at the interactions between the de-    and Velocity of movements over the Number of Correct Inter-
pendent variables.                                                pretation (F(8, 144) = 13.15, p < 0.01, partial η2 = 1). Sim-
Effect on Valence Although it did not reach significance,         ilarly, there was an interaction between Key Pose and Jerki-
there was a trend of Velocity affecting Valence (F(2, 36) =       ness (F(4, 72) = 2.54, p < 0.05, partial η2 = 0.69). This in-
3.14, p = 0.06, partial η2 = 0.15). Post-Hoc tests (Least Sig-    dicates that the interpretation of emotion depended both on
nificant Difference) showed that there was a trend of Slow        the Key Pose being displayed, on the Velocity of movement
movement perceived as less positive than Fast (p = 0.07).         and on the Jerkiness. This was further investigated using re-
There was no difference between the Slow and Medium con-          peated measures ANOVAs on the different Key Pose and Ve-
                                                              1848

                                                                          ation available (Key Pose, Velocity and Jerkiness) was used to
Table 3: Effect of Velocity on Valence per Key Pose Dis-
                                                                          rate Arousal.
played
              Key Pose  Repeated Anovas
              Sadness   F(2, 36) = 0.43, p = 0.65, partial η2 = 0.02
                                                                          Interpretation Participants were able to correctly identify
              Anger     F(2, 36) = 1.46, p = 0.25, partial η2 = 0.08      the different static key poses. Whilst the recognition rate for
              Neutral   F(2, 36) = 0.86, p = 0.43, partial η2 = 0.05
              Pride     F(2, 36) = 1.57, p = 0.22, partial η2 = 0.08
                                                                          Anger was lower than for the other key poses, it was still
              Happiness F(2, 36) = 10.24, p < 0.01, partial η2 = 0.36     above chance level. This low recognition rate could be due
                        Fast > Slow(p < 0.01)
                        Fast > Medium(p < 0.01)                           to the modification done to the material as the robot was
                        Medium = Slow(p = 0.33)
                                                                          sitting down. The key pose was better recognised in previ-
                                                                          ous experiment with the robot standing up (Beck, Stevens,
locity conditions (Table 2). Table 2 shows that the highest re-           Bard, & Cañamero, 2012) and the lack of significant differ-
cognition rate for Sadness was with Slow and Regular move-                ence between the key poses for anger and neutral on Valence
ments, for Anger, it was with Fast movements (no effect of                that was found in this study could be due to the key pose for
jerkiness), neutral was better interpreted with Slow and Me-              anger being misinterpreted in most of the conditions. This
dium speed. Pride was better interpreted at Slow and medium               will have to be investigated in future work.
speed. For Happiness, it was with Fast and Medium speed.                     Moreover, when compared with static poses, the recogni-
                                                                          tion rates for the display with movements clearly show that
Valence There was a significant interaction between Ve-                   adding appropriate dynamic elements improves significantly
locity and Key Pose on Valence (F(8, 144) = 5.85, p <                     the expressivity of the key pose (Table 1). Although it was not
0.05, partial η2 = 0.11). This indicates that the effect of Velo-         possible to capture this statistically, Velocity seems to have a
city depends on the Key Pose. This was therefore investigated             consistent effect on interpretation. For instance, the key pose
in details using 3(Velocity) Repeated Measure Anovas on the               for sadness was interpreted as sad in slow motion (resulting
different Key Pose individually (Table 3).                                in the very high recognition rate in this condition); however,
Arousal There was a significant interaction between Key                   as the Velocity increased, it shifted toward anger and frustra-
Pose and Velocity on Arousal (F(8, 144) = 5.81, p <                       tion. This is consistent with the results found with regards to
0.01, partial η2 = 0.24). Repeated Measures Anovas were                   the effect of Velocity on Valence (Table 3) which show that,
therefore conducted on the different Key Pose conditions sep-             with the exception of happiness, Velocity had not effect on
arately. The results of these showed that the pattern were con-           Valence. Thus, these shifts in interpretation can be explained
stant for all of them and that the Fast condition was perceived           by the effect of Velocity on Arousal. In other words, a neg-
as more aroused than the Medium condition (p < 0.01 for all               ative expression, remains negative, but its level of Arousal
the Key Poses) which in turn was perceived as more Aroused                increases along with Velocity shifting from sadness to anger
than the Slow condition (p < 0.01 for all the Key Pose).                  and frustration. The interpretations of the key poses were af-
                                                                          fected by the Velocity and the Jerkiness of the movements.
                           Discussion                                     More precisely, the dependence between Key Pose and Velo-
Valence and Arousal As expected, Key Pose had a strong                    city with regards to the interpretation shows the importance
effect on Valence and Arousal. More precisely, the perceived              of matching the Velocity and the Jerkiness of movements to
Valence and Arousal were consistent with the respective po-               the Key Pose in order to express specific areas of the Affect
sitions of each Key Pose within the Affect Space (Figures 2               Space. The drop in recognition for Sadness in the Jerky con-
and 3). Moreover, Velocity had a marginal effect on Valence.              dition suggests the importance of regular movement for this
However, the interactions between Velocity and Key Pose sug-              expression.
gest that the difference in Valence was due to the key pose for              Even though pride was correctly labeled, the rating of
happiness (Table 3) as it was found that for all the other key            Arousal was higher than what could have been expected. This
poses, Velocity had no effect on Valence. Similarly, Jerki-               was also the case in (Beck, Cañamero, & Bard, 2010) and
ness did not affect the perceived Valence of the display. This            could be due to this specific posture. It could also be related
is consistent with existing results in psychology which sug-              to the physical aspect of the Nao robot, as the arm joints are
gest that Arousal is a formless cue that relates directly to the          very salient in this key pose.
movement kinematics while Valence seems to be related to                  Limitations and Future Work It is important to highlight
the relations between the different limb segments (Pollick,               that the key poses used for this study are prototypical and
Paterson, Bruderlin, & Sanford, 2001).                                    were intentionally selected to be expressive. This is appro-
   However, both Velocity and Jerkiness were found to in-                 priate and beneficial for the development of an expressive
crease the perception of Arousal. Taken together, the results             system. However, it is likely that the use of prototypical
suggest that the perceived Valence depended on the Key Pose               expressions had an effect on the results found in this study.
displayed without taking into account the different dynamic               Moreover, the Jerkiness condition could have been imple-
conditions. In contrast, the perceived Arousal depended on all            mented by manipulating the number of Harmonics and the
three dependent variables. Hence, participants relied only on             Frequency of the noise. This could result in different visual
the body posture to assess Valence. However, all the inform-
                                                                      1849

results with different effects on the perception of emotion. It      Coulson, M.         (2008).     Expressing emotion through
should also be noted that Perlin noise does not capture the            body movement: A component process approach. In
relationship that exists between the rotation of one joint and         L. Cañamero & R. Aylett (Eds.), Animating expressive
another. This may result in unrealistic animations (Egges &            characters for social interaction (p. 7186). John Benjamins
Magnenat-Thalmann, 2005). Although this did not seem to                Publishing Company.
be the case in this study as the material was carefully checked,     De Gelder, B. (2006). Toward the neurobiology of emo-
it could still have affected the results.                              tional body language. Nature Reviews, Neuroscience, 7,
   This study did not consider the effect of context on the            242-249.
perception of the body language displayed. However, it can           Egges, A., & Magnenat-Thalmann, N. (2005). Emotional
be argued that interpretation of emotion is context dependent          communicative body animation for multiple characters. In
and that changing the context could change the perception of           Proc. of the first int. workshop on crowd simulation (pp.
the expressions generated by this Affect Space. On the other           31–40). Lausanne, Switzerland.
hand, work on facial expressions of emotion has shown that           Hartmann, B., Mancini, M., Buisine, S., & Pelachaud, C.
at least for a few basic emotions, context is not necessary to         (2005). Design and evaluation of expressive gesture syn-
identify the expressed emotion. In other words, the expres-            thesis for embodied conversational agents. In Proc. 4th int.
sion of an emotion is to a certain extent independent from the         joint conf. on autonomous agents and multiagent systems
context, as evidenced by the widespread use of FACS. Simil-            (pp. 1095–1096). The Netherlands.
arly, the high recognition rates obtained in this study suggest      Ishiguro, H. (2005). Android science: Toward a new cross-
that these expressions could convey the intended emotion in            disciplinary framework. In Cogsci-2005 worskshop: To-
different contexts. However, people’s reaction to the emo-             ward social mechanisms of android science (p. 1-6).
tional expression are likely to differ. This will be investigated    Kleinsmith, A., & Bianchi-Berthouze, N. (2012). Affect-
as part of the ALIZ-E project.                                         ive body expression perception and recognition: A survey.
                                                                       IEEE Trans. on Affective Computing, 99(PrePrints).
                     Acknowledgments                                 Kleinsmith, A., Bianchi-Berthouze, N., & Steed, A. (2011,
This work was funded by the ALIZ-E FP7 European Project                August). Automatic recognition of non-acted affective pos-
(Grant 248116). The opinions expressed are solely the au-              tures. Trans.. Sys. Man Cyber. Part B, 41(4), 1027–1038.
thors’ and not necessarily those of the consortium.                  Lee, J.-H., Park, J.-Y., & Nam, T.-J. (2007). Emotional inter-
                                                                       action through physical movement. In Proc. of the 12th int.
                          References                                   conf. on human-computer interaction (pp. 401–410). Ber-
Avizer, H., Trope, Y., & Todorov, A. (2012). Body cues,                lin, Heidelberg: Springer-Verlag.
   not facial expressions, discriminate between intense posit-       Nalin, M., Baroni, I., Kruijff-Korbayov, I., Cañamero, L.,
   ive and negative emotions. Science, 338, 1225-1229.                 Lewis, M., Beck, A., et al. (2012). Childrens adaptation
Beck, A., Cañamero, L., & Bard, K. (2010, sept.). Towards an          in long-term interactions with a humanoid robot. In Proc.
   affect space for robots to display emotional body language.         of ro-man12.
   In Ro-man, 2010 ieee (p. 464 -469).                               Perlin, K. (1990). Noise and turbulence. Available from
Beck, A., Hiolle, A., Mazel, A., & Cañamero, L. (2010).               http://www.mrl.nyu.edu/˜ perlin/doc/oscar.html
   Interpretation of emotional body language displayed by ro-        Pollick, F., Paterson, H., Bruderlin, A., & Sanford, A. (2001).
   bots. In Proc. of the 3rd int. workshop on affective interac-       Perceiving affect from arm movement. Cognition, 82(2),
   tion in natural environments (pp. 37–42). Firenze, Italy.           B51–B61.
Beck, A., Stevens, B., Bard, K. A., & Cañamero, L. (2012,           Roether, C. L., Omlor, L., Christensen, A., & Giese, M. A.
   March). Emotional body language displayed by artificial             (2009). Critical features for the perception of emotion from
   agents. ACM Trans.. Interact. Intell. Syst., 2(1), 2:1–2:29.        gait. Vision, 9(6).
Bernhardt, D. (2010). Emotion inference from human                   Snibbe, S., Scheeff, M., & Rahardja, K. (1999). A layered
   body. Unpublished doctoral dissertation, University of              architecture for lifelike robotic motion. In Proc. of the 9th
   Cambridge, Computer Laboratory.                                     int. conference on advanced robotics.
Camurri, A., Mazzarino, B., & Volpe, G. (2003). Analysis             Thomas, F., & Johnston, O. (1995). The illusion of life. New-
   of expressive gesture: The eyesweb expressive gesture pro-          York: Abbeville Press.
   cessing library. Gesture-Based Communication in Human-            Vala, M., Paiva, A., & Rui Gomes, M. (2008). Effective bod-
   Computer Interaction, 460-467. (LNAI)                               ies for affective interaction. In L. Cañamero & R. Aylett
Cañamero, L. (2002). Playing the emotion game with                    (Eds.), Animating expressive characters for social interac-
   feelix. In K. Dautenhahn, A. Bond, L. Cañamero, & B. Ed-           tion (p. 87-101).
   monds (Eds.), Socially intelligent agents (Vol. 3, p. 69-76).     Wallbott, H. G. (1998). Bodily expression of emotion.
   Springer US.                                                        European J. of Social Psychology, 28(6), 879–896.
Cañamero, L. (2008). Animating affective robots for social
   interaction. In L. Cañamero & R. Aylett (Eds.), Animating
   expressive characters for social interaction (p. 103-121).
                                                                 1850

