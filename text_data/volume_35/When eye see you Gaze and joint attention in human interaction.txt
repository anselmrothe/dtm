UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
When eye see you: Gaze and joint attention in human interaction

Permalink
https://escholarship.org/uc/item/02h9m3wx

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Staudte, Maria
Pfeiffer, Ulrich

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

When eye see you: Gaze and joint attention in human interaction
Maria Staudte (masta@coli.uni-sb.de)

Ulrich Pfeiffer (ulrich.pfeiffer@uk-koeln.com)

Department of Computational Linguistics
Saarland University

Department of Psychiatry
University Hospital Cologne
cognition and communication are among the core symptoms
of autism spectrum disorders (ASD). Due to the broad impact
of joint attention on social and communicative skills, its study
has become a major focus in the empirical research on ASD.
The majority of this research is dedicated to understanding
the implications of mutual and triadic gaze for the development of skills related to communication among typically developing individuals and those with ASD (Mundy, Gwaltney,
& Henderson, 2010; Redcay et al., 2012).
Overall, this workshop aims to explore how traditionally
separate research areas such as social cognition/neuroscience,
psycholinguistics, human-computer interaction and developmental psychology contribute to an understanding of the general phenomenon of gaze-following and joint attention from
all these different perspectives – and how these fields can benefit and learn from each other, e.g. by comparing different
approaches and methodologies.

Keywords: joint attention; gaze; social interaction; language
processing; dialog; grounding.

Topic and Goals
Gaze behavior provides fundamental mechanisms for sharing
mental states such as goals and desires and helps to ground
communicative content. In order to establish common ground
in verbal and non-verbal interactions, interlocutors often need
to acquire knowledge about their interaction partners’ focus
of visual attention by following their gaze and, in turn, have
to direct their partners attention to their own target object or
location. Responding to or leading someone’s gaze to a location or an object of interest results in a situation of joint attention - a referential triad between two individuals and some
entity in the environment. As people often look at what they
attend to and where they intend to act, joint attention is considered fundamental to an understanding of other minds and
the interaction with other individuals.
Joint attention plays an important role in numerous socialcognitive processes, including Theory-of-Mind (Tomasello,
1995), perspective taking (Moll & Meltzoff, 2011), and processes relating to learning and memory from early infancy
throughout adulthood (Kim & Mundy, 2012). However, despite extensive research in virtually all areas of cognitive science aiming at an understanding of behavioral functions, cognitive processes, and neural mechanisms of joint attention,
there is a plethora of unresolved questions. The interplay of
the development of joint attention and language during infancy (Baldwin, 1995) or the relation between joint attention and the perception of other persons (Frischen, Bayliss,
& Tipper, 2007) are among those. Finally, the neural circuits subserving our ability to engage in joint attention have
been investigated only recently because appropriate methods to study gaze-based face-to-face interaction in real-time
have only recently been made available (Redcay et al., 2010;
Schilbach et al., 2010).
In addition to its role in social cognition, seeing and following or directing someone else’s gaze is crucial for effective
language learning (Morales et al., 2000) and language processing in adults (Clark & Krych, 2004; Hanna & Brennan,
2007; Staudte & Crocker, 2011). Monitoring each other’s
gaze behavior supports the understanding of what the interlocutor is saying or understanding (Richardson & Dale, 2005;
Hanna & Brennan, 2007) and fosters the synchronization of
interlocutors in discourse (Garrod & Pickering, 2004). Thus,
initiating or establishing joint attention at a chosen point during dialog can be a powerful means to augment and modulate
linguistic content.
Finally, severe impairments in multiple aspects of social

Relevance to the the CogSci Conference
Recently, there has been an increased interest in psycholinguistics and human-computer interaction as well as in social
cognition and ASD research to investigate human communication processes in more interactive settings. In particular, scientists have tried to extend their theories and experimental designs by the visual presence and the induced dynamics of an interaction partner in order to accommodate the
complex non-verbal behavior that typically accompanies and
greatly influences linguistic interaction. The domain of gaze
has aroused particular interest as single acts of looking combine perception and action in social encounters. By establishing joint attention, for instance, gaze behavior guides the exchange of goals and desires which are critical motivations for
communication. However, experiments incorporating such
complex and dynamic yet crucial aspects of human interaction are difficult to implement and a challenge to traditionally
very controlled procedures. In this workshop, we would like
to gather researchers from related fields and bring them closer
together by providing a platform for exchanging theories and
approaches as well as methodology that is suited for investigating the use and effect of gaze in human interaction (e.g.
Redcay et al., 2010; Saito et al., 2010; Wilms et al., 2010).
All related fields are core areas of cognitive science and our
research questions are currently of high interest in the field (as
partly reflected also by the invited symposium Joint Action).

Suitability of the Organizers
Dr. Maria Staudte has a background in psycholinguistics
and human-agent-interaction and has published in established
journals and conferences such as Cognition, HRI, and the An-

35

Contact Information

nual Conference of the Cognitive Science Society. Her interests have focused on studying how humans use (each other’s
or an artificial agent’s) eye-movements in order to ground references in a shared environment, to infer (referential) intentions, and to predict upcoming action. Ulrich Pfeiffer has
a background in linguistics, psychology, and social neuroscience and studies the behavioral functions and neural correlates of gaze behavior in real-time social interactions using a combination of novel and innovative interactive eyetracking and neuro-imaging methods. He has published in
established journals such as Frontiers in Psychology, Social
Cognitive and Affective Neuroscience, and PLoS One and
wrote a book chapter on eye-tracking methodology. He has
further co-edited a Research Topic Issue in Frontiers in Neuroscience titled Towards a Neuroscience of Social Interaction.

Maria Staudte, Saarland University / SUNY Stony Brook,
100 Bleecker St, Apt 2f, New York City, 10012 NY. Email:
masta@coli.uni-sb.de

References
Baldwin, D. A. (1995). Understanding the link between joint attention and language. In C. Moore & P. Dunham (Eds.), Joint
attention: Its origins and role in development. Lawrence Erlbaum Associates, Inc.
Clark, H. H., & Krych, M. A. (2004). Speaking while monitoring
addressees for understanding. Journal of Memory and Language, 50(1), 62–81.
Frischen, A., Bayliss, A. P., & Tipper, S. P. (2007). Gaze cueing of
attention: Visual attention, social cognition, and individual
differences. Psychological Bulletin, 133(4), 694-724.
Garrod, S., & Pickering, M. J. (2004). Why is conversation so easy?
Trends in Cognitive Sciences, 8(1), 8-11.
Hanna, J., & Brennan, S. (2007). Speakers’ eye gaze disambiguates
referring expressions early during face-to-face conversation.
Journal of Memory and Language, 57, 596-615.
Kim, K., & Mundy, P. (2012). Joint attention, social-cognition, and
recognition memory in adults. Frontiers in Neuroscience, 6,
172.
Moll, H., & Meltzoff, A. (2011). Perspective-taking and its foundation in joint attention. In N. Eilan, H. Lerman, & J. Roessler
(Eds.), Perception, causation, and objectivity. issues in philosophy and psychology (p. 286-304). OUP Oxford.
Morales, M., Mundy, P., Delgado, C., Yale, M., Messinger, D., Neal,
R., & Schwartz, H. (2000). Responding to joint attention
across the 6-through 24-month age period and early language
acquisition. Journal of Applied Developmental Psychology,
21(3), 283-298.
Mundy, P., Gwaltney, M., & Henderson, H. (2010). Self-referenced
processing, neurodevelopment and joint attention in autism.
Autism, 14(5), 408-429.
Redcay, E., Dodell-Feder, D., Pearrow, M., Mavros, P., Kleiner, M.,
Gabrieli, J., & Saxe, R. (2010). Live face-to-face interaction
during fMRI: a new tool for social cognitive neuroscience.
Neuroimage, 50(4), 1639-1647.
Redcay, E., O’Young, D., Slevc, L., Mavros, P., Gabrieli, J., &
Sinha, P. (2012). Gaze cues in complex, real-world scenes
direct the attention of high-functioning adults with autism.
In Proceedings of the 34th Annual Meeting of the Cognitive
Science Society.
Richardson, D. C., & Dale, R. (2005). Looking to understand: The
coupling between speakers’ and listeners’ eye movements
and its relationship to discourse comprehension. Cognitive
Science, 29(6), 1045-1060.
Saito, D., Tanabe, H., Izuma, K., Hayashi, M., Morito, Y., Komeda,
H., . . . others (2010). Stay Tuned: Inter-Individual Neural Synchronization During Mutual Gaze and Joint Attention.
Frontiers in Integrative Neuroscience, 4, 127.
Schilbach, L., Wilms, M., Eickhoff, S., Romanzetti, S., Tepest, R.,
Bente, G., . . . Vogeley, K. (2010). Minds made for sharing: initiating joint attention recruits reward-related neurocircuitry. Journal of Cognitive Neuroscience, 22(12), 27022715.
Staudte, M., & Crocker, M. W. (2011). Investigating joint attention
mechanisms through human-robot interaction. Cognition,
120(2), 268-291.
Tomasello, M. (1995). Joint attention as social cognition. In
C. Moore & P. Dunham (Eds.), Joint attention: Its origins
and role in development. Lawrence Erlbaum Associates, Inc.
Wilms, M., Schilbach, L., Pfeiffer, U., Bente, G., Fink, G., & Vogeley, K. (2010). Its in your eyes – using gaze-contingent
stimuli to create truly interactive paradigms for social cognitive and affective neuroscience. Social cognitive and affective
neuroscience, 5(1), 98-107.

Target Audience & Participants
The target audience of this workshop are researchers from
all subfields of cognitive science that have an interest in the
study of gaze behavior in interaction and communication. We
expect a large audience of approximately 30-40 participants.

(Invited/Keynote) Speakers
The following high-profile researchers have confirmed to give
keynote lectures:
• Dr. Andrew Bayliss, University of East Anglia, on ”Gaze
cueing: The influence of observing averted gaze on attention and affective evaluations”
• Prof. Susan Brennan, SUNY Stony Brook, tbd
• Prof. Peter Mundy, University of California at Davis, on
”The Interaction of Joint Attention and Communication:
Cognitive and Neurocognitive Factors”
• Prof. Elizabeth Redcay, University of Maryland, on ”Brain
systems supporting joint attention behaviors in typical development and autism”
In addition to the keynote lectures, we solicit submissions
of abstracts (around 350 words) related to the workshop topic
from all areas of the cognitive sciences. We intend this workshop to last a full day of which four 50-min slots would be
dedicated to the keynote lectures. Besides an opening session, we expect to have six more 20-min slots to be filled by
speakers based on abstract selection.

Publicizing and Documentation
We aim to make use of our large network of collaborators and
colleagues in order to personally publicize this workshop and
solicit submissions from specific individuals and labs. Further, we will use social media like Facebook as well as mailing lists such as AMLaP, LINGUIST or ESAN for general
advertisement. We have no plans for documentation of the
workshop outcome at this point since we truly view this event
as a kick-off event that should help to start discussions, form
synergies, and initiate new collaborations.

36

