UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Can Help Seeking Behavior in Intelligent Tutoring Systems Be Used as Online Measure for
Goal Orientation?

Permalink
https://escholarship.org/uc/item/69t056mp

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Otieno, Christine
Schwonke, Rolf
Salden, Ron
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Can Help Seeking Behavior in Intelligent Tutoring Systems Be Used as Online
Measure for Goal Orientation?
Christine Otieno (otieno@psychologie.uni-freiburg.de)
Rolf Schwonke (schwonke@psychologie.uni-freiburg.de)
Department of Educational and Developmental Psychology, University of Freiburg
Engelbergerstr. 41, D-79085 Freiburg, Germany

Ron Salden (rsalden@m-iti.org)
Madeira Interactive Technologies Institute, University of Madeira
Caminho da Penteada, 9020-105 Funchal, Portugal

Alexander Renkl (renkl@psychologie.uni-freiburg.de)
Department of Educational and Developmental Psychology, University of Freiburg
Engelbergerstr. 41, D-79085 Freiburg, Germany

Abstract
Questionnaires to assess goal orientation are widely used.
However, recent research indicates some shortcomings. Most
significantly, questionnaire data are unable to capture
developments and changes in students´ goal orientation
during the learning process. Therefore, it seems appropriate
to supplement questionnaire data with online measures that
directly tackle students’ behavior. We analyzed data of 57
students who participated in a study with the Cognitive Tutor
Geometry. Specifically, we analyzed relationships between
questionnaire data on goal orientation, the use of hints and a
glossary while working with the Tutor as potential online
indicators for goal orientation, and learning outcomes.
Results of our analyses show that our potential online
indicators systematically differ from questionnaire data of
goal orientation, yet have high predictive power for learning
outcomes. Therefore, online indicators may be used to
supplement questionnaire data of goal orientation and/or to
further optimize adaptation in intelligent tutoring systems.
Keywords: Motivation, Goal Orientation, Self-regulated
Learning, Intelligent Tutoring Systems

Introduction
Motivation and self-regulated learning are inseparably
intertwined.
One specifically important and wellinvestigated area of motivation is that of achievement goal
theory (Pintrich, 2000).
Initially, the theory’s basic
distinction was between mastery goal and performance goal
orientation (e.g., Dweck, 1986). Mastery goal orientation
refers to the goal of reaching understanding and mastery in a
field. Performance goal orientation refers to the goal to
perform better in comparison to others (Elliot & McGregor,
2001). Mastery goal oriented students have often been
found to show more effort and persistence during learning
and, as a result, better learning outcomes compared to
performance goal oriented students (Urdan, 1997). Elliot
and McGregor (2001) introduced “valence” as an additional
dimension to describe goal orientation; that is, approaching
success versus avoiding failure. This additional distinction
leads to four aspects of goal orientations: mastery-

approach, mastery-avoidance, performance-approach, and
performance-avoidance goal orientation.
Initially, goal orientation was regarded as a relatively
stable personality trait (e.g., Dweck & Leggett, 1988). Later
studies, however, put an emphasis on the influence of
situational variables and task characteristics on goal
orientation (e.g., Butler, 1993). Some researchers pointed
out as early as in the 90s, that students may not clearly
belong to one or the other group of learners in classroom
situations (i.e., performance versus mastery goal oriented or
approach versus avoidance oriented). In contrast, it is
highly plausible that students show both mastery and
performance goal orientations at the same time, albeit at
different levels. Also, there may be variations in the
students’ predominant goal orientation during learning
phases depending on the task at hand and level of expertise
(e.g., Meece & Holt, 1993). In analogy to the state-trait
concept of anxiety first introduced by Cattell and Scheier
(1961), recent research points to the reciprocal influences of
state and trait measures in the field of goal orientation
(Chen, Gully, Whiteman, & Kilcullen, 2000).
Typically, goal orientation is measured via self-report
questionnaires. This approach is rooted in the traditional
view of goal orientation as a personality trait and can be
considered to measure habitual goal orientation. Despite
their long tradition and proven utility in the field,
interpretation of questionnaire data of achievement goal
orientation can be problematic.
More specifically,
ambiguity between different questionnaires with respect to
their conceptual overlap often makes it difficult to compare
findings from different studies (Hulleman, Schrager,
Bodmann, & Harackiewicz, 2010). Also, data measured
before or after a learning phase using self-report
questionnaires lack the ability to capture decisions and
states of the learners as they arise from circumstances in the
learning environment and develop during the learning
process (Richardson, 2004). Consequently, recent research
calls for measurement of achievement goals not only by
questionnaires but also by online measures to grasp

1103

moment-to-moment actions and thereby the state aspect of
goal orientation at a fine-grained level. One way to track
goal orientation online is through traces in online learning
environments (e.g., Zhou & Winne, 2012).
In an attempt to investigate potential relationships
between online and offline measures for goal orientation
and their predictive power for learning outcomes, Zhou and
Winne (2012) enriched an instructional text presented
online with a set of hyperlinks and tags referring to the four
different goal orientations (mastery-approach, masteryavoidance, performance-approach, performance-avoidance).
Hyperlinks to be selected were presented next to the text
(e.g., “take a practice test on this”; performance-approach).
Within the text students could use highlighting to structure
the text and label highlights (e.g., “I want to learn more
about this”; mastery-approach; Zhou & Winne, 2012,
p.415). Selection of hyperlinks and tags were interpreted as
online traces for the respective goal orientation. Zhou and
Winne (2012) found that goal orientation as assessed by
questionnaire data do not correlate with goal orientation as
assessed by the traces captured online during the learning
process. These findings are in line with earlier research
indicating that self-reported measures of study tactics do
hardly correspond to respective online measures collected
during learning (Jamieson-Noel & Winne, 2003). The
differences between online measures and questionnaire data
for goal orientation could be partly seen as an indication of
state-trait differences in goal orientation. Additionally,
Zhou and Winne found an advantage of online traces over
questionnaire data to predict learning outcomes, which
raises the following question: Are online measures “better”
than questionnaire data to assess goal orientation for
educational purposes?
Another potential advantage of measuring goal orientation
online is that it is less obtrusive compared to explicitly
asking questions upon which students have to reflect. For
example, intelligent tutoring systems could use tracking data
that are collected during the learning process to estimate
students’ goal orientation at any given point in the learning
phase and adapt their responses to the students’ motivation
and attitudes (e.g., Arroyo, Cooper, Burleson, & Woolf,
2010). Such adaptation could make intelligent tutoring
systems even more effective (for an overview of recent
advances in intelligent tutoring systems, see Graesser,
Conley, & Olney, 2012).
Cognitive Tutors and other intelligent tutoring systems
have proven to be very effective in supporting individual
students’ learning in a variety of domains such as
mathematics or genetics (for an overview, see Koedinger &
Corbett, 2006) and are widely used in schools across the
United States as part of the regular mathematics curriculum.
Based on an online assessment of students’ learning,
Cognitive Tutors provide individualized support for guided
learning by doing.
Specifically, the Tutor selects
appropriate problems, gives just-in-time feedback, and
provides hints. Additionally, students can use a glossary to
look up definitions and explanations. Hints provide direct

instructions for the next step a student has to determine;
they are context sensitive and therefore adaptive to the
situation. The glossary offers definitions and explanations
for principles to be understood and learned; it is context
insensitive and therefore not adaptive to the specific
situation (Koedinger & Aleven, 2007).
In light of
achievement goal theory one could interpret the use of hints
as performance-goal oriented and the use of a glossary as
mastery-goal oriented behavior. Although hints can be used
in a mastery-goal oriented way, specifically if students
reflect upon them, they are often not used in this way. Their
adaptive nature to the problem at hand suggests their use in
order to immediately solve a problem rather than to deeply
reflect and understand the underlying principle. Sometimes
students even abuse hints in order to proceed quickly
through the learning environment, a behavior referred to as
“gaming-the-system” (Baker, Corbett, Koedinger, &
Wagner, 2004). The glossary, in contrast, is not directly
related to a to-be-determined problem step at hand.
Therefore, we assume that it is consulted whenever students
are interested in information that goes beyond the
immediate problem-solving step. We claim that this
behavior may be related to mastery-goal orientation as, in
contrast to hint use, it does not primarily improve immediate
performance in the learning environment but understanding.
Using online tracking data of hint and glossary use could
therefore be an unobtrusive and more proximal, “state-like”
indication of goal orientation compared to the more
reflected and “trait-like” measures gained by questionnaires.
In addition, the data are tracked automatically, not taking up
additional resources on either the side of the program or the
learner.

The Present Study
Attempting to test if the findings of Zhou and Winne
(2012) can be conceptually replicated in a different learning
environment, and if hint and glossary use could be valid
behavioral indicators for goal orientation, we reanalyzed a
data set from an earlier study where students learned
geometry principles using the Cognitive Tutor Geometry®
(Salden, Aleven, Renkl, & Schwonke, 2009). First, we
tested if self-reported goal orientations as assessed by a
questionnaire correspond to the respective online measures.
Second, we assumed, as in the study by Zhou and Winne
(2012), a positive relationship of glossary use and learning
outcomes (i.e., understanding) and a negative relationship of
hint use and learning outcomes. In our study, the learning
outcome tests (i.e., posttests) - presented immediately after
the learning phase and one week later - measured not so
much knowledge of routines but application and
understanding of the principles learned in the Cognitive
Tutor. Our expectations were also in line with earlier
studies showing better learning outcomes for masteryoriented students than for performance-oriented students
(for an overview, see Urdan, 1997). In addition, other
studies on the Cognitive Tutor found negative relations
between hint use and learning outcomes (e.g., Aleven &

1104

Koedinger, 2001).
Third, while Zhou and Winne (2012) did not find a
significant relationship of questionnaire data with
performance on posttest, theoretical considerations as well
as earlier studies led to the expectation that such a
relationship may exist (for an overview, see Urdan, 1997).
We therefore addressed the ("two-sided") research question
(as did Zhou and Winne) if online and questionnaire data
alike relate to learning outcomes.
Fourth, we checked if behavioral indicators for mastery as
well as performance goal orientation (i.e., glossary and hint
use, respectively) are stronger predictors of learning
outcomes than respective questionnaire data.
To even out potential influences of prior knowledge on
posttest performance we controlled for math grade (the
strongest predictor of learning outcomes in this study) in all
calculations involving posttest performance.
More
specifically, we addressed the following research questions:
(RQ1) Do self-reported goal orientations from the
questionnaire correlate with respective behavioral
indicators (i.e., hint use with performance goal
orientation and glossary use with mastery goal
orientation)?
(RQ2) Is there a positive relationship between glossary
use and learning outcomes and a negative
relationship between hint use and learning
outcomes?
(RQ3) What is the relationship between questionnaire data
of goal orientation and learning outcomes?
(RQ4) Are behavioral indicators for goal orientation better
predictors of learning outcomes than the respective
questionnaire data (i.e., are glossary and hint use
better predictors for learning outcomes than selfreport measures)?

Method
Sample and Design
Participants in our study were 57 students (19 in 9th grade
and 38 in 10th grade; age: M = 15.63, SD = .84) from a
German “Realschule”, which is equivalent to an American
high school. The original study comprised three conditions
to which participants were randomly assigned resulting in
an equal distribution of 19 students per condition. In two
conditions students were provided with worked examples to
solve the mathematical problems. Worked examples were
either faded out according to a fixed procedure (fixed fading
condition) or according to the student’s individual skill level
(adaptive fading condition). The third condition served as a
control and did not receive any worked examples (problem
condition; Salden et al., 2009). For the purpose of the
reanalysis of our data for this paper, that is to investigate
potential relationships between online and questionnaire
measures of goal orientation and learning outcome, we
examined all 57 participants as one group. To preclude
potential influences of conditions on the observed

relationships, however, we routinely calculated all analyses
for the separate conditions and checked for potential
significant differences. However, no such differences were
found.

Learning Environment – The Cognitive Tutor

Hint

Glossary

Figure 1. Screenshot of the Cognitive Tutor Geometry®
Cognitive Tutors provide adaptive feedback and model
students´ skill acquisition based on two algorithms: model
tracing and knowledge tracing (Koedinger & Corbett,
2006). Simulating the problem solving process enables the
Tutor, for example, to provide specific hints for a problem
situation. Also, all steps (i.e., all actions a student takes
while working with the program) are tracked in a logfile.
This data are used online for adaptation. For the purpose of
this paper we analyzed part of this logfile data, specifically
the amount of hint and glossary use (percentage in relation
to all activities of the student in the learning environment),
and correlated them with offline data of a goal orientation
questionnaire and posttest scores.
Learning Materials During the learning phase with the
Cognitive Tutor we asked students to work on fifteen
problems in a Cognitive Tutor lesson on geometry, covering
four geometry principles. The first eight problems required
the application of only one geometry principle. The last
seven problems combined different principles and were
therefore more complex. Before the learning phase we
provided students with instructions about the different tools
in the Tutor. More specifically, after giving an overview of
the learning environment, hints were introduced as an
assistance tool to use when “having trouble solving a task or
when reaching an impasse. The glossary was introduced as
an assistance tool to use if “you are unsure when to use a
certain mathematical principle or which is the
corresponding formula”. These instructions were routinely
used in several of our studies involving the Cognitive Tutor
Geometry (e.g., Salden et al., 2009; Schwonke et al., 2012).

1105

Instruments
Pretest The pretest was integrated in the Cognitive Tutor
and consisted of four geometry problems related to the
lessons taught later during the learning phase with the
program. All Cognitive Tutor help facilities (e.g., hints)
were disabled during the pretest. On average students
needed 21 minutes to complete the pretest. Mathematics
grade was a significantly stronger predictor of posttest
performance than the pretest. Therefore, we included
mathematics grade and not pretest scores in all analyses
referring to posttest performance.
Goal Orientation Questionnaire Before solving the
posttest, students were asked to answer 8 items concerning
their learning goal orientation while working with the
program on a scale from 1 to 6. Items were adapted from
Elliot and McGregor (2001) and reflected mastery-approach
and performance-approach goal orientations only.
Posttest A posttest consisting of the same problems as the
pretest was implemented in the learning environment.
Additionally, all participants were asked to complete a
paper-pencil test immediately after working with the Tutor
and one week later (delayed posttest). Immediate and
delayed posttests were identical. On average students
needed 31 minutes to complete the posttest and 21 minutes
to complete the delayed posttest.

Procedure
The first experimental session lasted 90 minutes on
average and was divided into three parts: pretest and
introduction, learning phase in the Cognitive Tutor, and
questionnaire on goal orientation as well as posttest. First,
students´ general prior knowledge was assessed by their
mathematics grade together with additional demographic
data such as age and gender. Then they received a brief
introduction on how to use the Cognitive Tutor followed by
a short pretest implemented in the Tutor measuring their
prior knowledge. After completing this pretest, students
read an instructional text providing information about the
rules and principles that were later addressed in the
Cognitive Tutor. In the tutoring part, students worked with
their respective version of the Cognitive Tutor. This
learning phase was followed by a questionnaire measuring
goal orientation with self-report measures and a knowledge
test. The students worked again on the knowledge test in a
second session (one week later).

Results and Discussion
To test if questionnaire data for goal orientation align
with respective online measures (RQ1) we determined
Pearson’s correlations between assumed behavioral
indicators for goal orientation (i.e., glossary use for mastery
goal orientation and hint use for performance goal
orientation) and self-report questionnaire data. There was
no significant relationship between glossary use and
mastery goal orientation (r = .13, p = .339) or hint use and
performance goal orientation (r = -.14, p = .298). These

findings are in line with Zhou and Winne (2012). The
missing relationship between behavioral data collected
online and questionnaire data collected after the learning
phase may indicate that the two measures capture different
constructs. One theoretically plausible interpretation is, that
both the online measures collected by Zhou and Winne and
our behavioral data, that is, hint and glossary use may
reflect state goal orientation while questionnaire data may
capture the trait aspect of goal orientation. However, one
could argue that state and trait measures of other
psychological constructs are generally correlated which
raises the question of construct validity of the online
measures. Therefore, more data is needed to decide if
online measures and specifically behavioral data as the ones
used in our study can be validly used as indicators for (state)
goal orientation, if they differ systematically from the
assumed trait measures of questionnaire data, and how both
state and trait mutually affect each other. However, our data
provides some initial evidence for the validity of hint and
glossary use as measures for goal orientation:
First, we determined the correlation between glossary and
hint use and found a very strong negative correlation: r = .84, p < .001. This indicates that students had a relatively
clear preference for either hints or glossary which is in line
with the assumption that the type of tool use indicates
whether the students were primarily concerned about
solving the problems (i.e., performance orientation) or
understanding the principles (i.e., mastery orientation) while
working on the Cognitive Tutor lessons.
Second, we tested if glossary use is positively related and
hint use is negatively related to learning outcomes (RQ2)
which should be the case if these online measures can be
associated with goal orientation. We determined partial
correlations between glossary and hint use and the
immediate and delayed posttest performance, controlling for
prior knowledge. Results indicate a significant positive
relationship for glossary use and immediate (r = .37, p =
.008) posttest score. Correlation of glossary use and the
delayed posttest score slightly failed to reach statistical
significance (r = .28, p = .050). There was a significant
negative relationship between hint use and performance on
the immediate (r = -.48, p < .001) as well as the delayed (r =
-.36, p = .009) posttest score. These relations can be seen as
evidence that glossary and hint use may indeed be valid
indicators for goal orientation. This may specifically be true
as our posttests measured deep understanding of the
principles learned in the Cognitive Tutor and not so much
knowledge of routines. In a test measuring the later,
differences between primarily performance versus mastery
goal oriented students may not be as pronounced.
Additionally, interpreting hint use as a measure for
performance goal orientation may provide one explanation
for the repeatedly found negative relations between hint use
in the Cognitive Tutor and performance on posttest.
We further tested the relationship between self-reported
mastery and performance goal orientation (i.e.,
questionnaire data) and learning outcomes (RQ3). We

1106

found a significant positive relation between mastery goal
orientation and delayed posttest scores (r = .41, p = .003).
The relationship between mastery goal orientation and
immediate posttest scores (r = .25, p = .076) slightly failed
to reach statistical significance. There was also no
significant relationship between self-reported performance
goal orientation and immediate posttest scores (r = -.21, p =
.144); the relationship between performance goal orientation
and delayed posttest scores (r = -.24, p = .086) failed to
reach statistical significance. These results are, at least
partly, in contrast to Zhou and Winne (2012) who observed
no statistically significant correlations between self-reported
goal orientations and posttest performance. However, the
results are in line with theoretical assumptions and earlier
studies using questionnaire data on goal orientation and
further corroborate the aforementioned relation between
goal orientation and learning outcomes.
To test if online measures or their respective
questionnaire data are better predictors for learning
outcomes (RQ4) we calculated separate stepwise linear
regression analyses, one for mastery goal orientation
(glossary use and respective questionnaire data) and one for
performance goal orientation (hint use and respective
questionnaire data) as potential predictors for immediate
and delayed posttest performance.
Concerning the
predictive power of mastery goal orientation (glossary use
vs. questionnaire data) for posttest scores results are mixed:
While glossary use was the sole best predictor for
immediate posttest scores, questionnaire data was the best
predictor for delayed posttest scores (Table 1). With regard
to the predictive power of performance goal orientation
(hint use vs. questionnaire data) for posttest scores, there
was a clear advantage of the behavioral data: Hint use was
the sole best predictor for both immediate and delayed
posttest scores (Table 2). Taken together, our results
indicate that specifically for mastery goal orientation
questionnaire data might yield predictive power beyond
behavioral online data, at least for long-term learning
effects. These results are not fully in line with Zhou and
Winne (2012) who consistently found online measures to be
the stronger predictors of learning outcomes in regression
models. There might be methodological explanations for
the differences between the two studies: We used a
different questionnaire as basis for our goal orientation
items and measured only two and not four aspects of goal
orientation. Also, the questionnaire used by Zhou and
Winne did not relate significantly to learning outcome
measures. In addition, utilizing hint and glossary use as
indicators for goal orientation might be a little more
"indirect" as compared to the online data collected by Zhou
and Winne (2012). For example, hint use might also be
elicited by errors made when trying to determine solution
steps, that is, it may be related to rather poor performance in
the learning environment. However, the very strong
negative correlation of r = -.84 between hint and glossary
use cannot be explained by these errors (partial correlation
controlling for errors is still highly significant with r = -.73,

p < .001).
Table 1: Glossary Use and Mastery Goal Orientation as
Predictors for Learning Outcomes

Posttest

Step 1
Glossary Use

B

SE
B

β

.22

.06

.42**

Delayed
Posttest

Step 1
.09
.03 .38**
Items on
Mastery Goal
Orientation
Step 2
Items on
.08
.03 .35**
Mastery Goal
Orientation
Glossary Use
.16
.06 .30*
Note. Posttest: R² = .18 for Step 1; Delayed Posttest:
R² = .15, ΔR² = .09 for Step 2 (p < .05).
* p < .05 and ** p < .01.
Table 2: Hint Use and Performance Goal Orientation as
Predictors for Learning Outcomes

Posttest

Delayed
Posttest

B

SE
B

β

Step 1
Hint Use

-.71

.15

-.53***

Step 1
Hint Use

-.56

.17

-.42**

Note. Posttest: R² = .28 for Step 1; Delayed Posttest:
R² = .18.
** p < .01 and *** p < .001.
Taken together, both behavioral online and offline
questionnaire data provide us with important insights for
understanding learners´ goal orientation and can be used to
supplement rather than to replace each other for the sake of
scientific advancement. Given the high predictive value of
behavioral online data, however, their use should be
considered for educational purposes in classrooms and
specifically in online learning environments, where an
unobtrusive and efficient collection of goal orientation data
could improve adaptation in intelligent tutoring systems and
thereby foster the learning process. In addition, one should
keep in mind that self-report measures of characteristics
such as goal orientation are potentially subject to a social
desirability bias which could be circumvented with
(indirect) online measures.
Can help seeking behavior in intelligent tutoring systems
be used as online measure for goal orientation? Even

1107

though we cannot answer this question based on our data
conclusively, our results provide a first and promising
indication that online behavior in intelligent tutoring
systems provides an unobtrusive and efficient additional or
even alternative measure to questionnaire data to assess goal
orientation in educational settings.

Acknowledgments
This work was supported by the Pittsburgh Science of
Learning Center which is funded by the National Science
Foundation; award number SBE-0354420. We are grateful
for Vincent Aleven’s assistance in conducting the original
study and would also like to thank him for his helpful
comments on an earlier version of this paper.

References
Aleven, V., & Koedinger, K. R. (2001). Investigations into
help seeking and learning with a Cognitive Tutor. In R.
Luckin (Ed.), Papers of the AIED-2001 Workshop on
Help Provision and Help Seeking in Interactive Learning
Environments (pp. 47–58).
Arroyo, I., Cooper, D. G., Burleson, W., & Woolf, B. P.
(2010). Bayesian networks and linear regression models
of students´ goals, moods, and emotions. Presented at the
Third International Conference on Educational Data
Mining (EDM2010), Pittsburgh, PA, USA.
Baker, R. S., Corbett, A. T., Koedinger, K. R., & Wagner,
A. Z. (2004). Off-task behavior in the Cognitive Tutor
classroom: When students “game the system”. In
Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems (pp. 383–390). New York,
NY, USA: ACM. doi:10.1145/985692.985741
Butler, R. (1993). Effects of task- and ego-achievement
goals on information seeking during task engagement.
Journal of Personality and Social Psychology, 65(1), 18–
31. doi:10.1037/0022-3514.65.1.18
Cattell, R. B., & Scheier, I. H. (1961). The meaning and
measurement of neuroticism and anxiety. Oxford
England: Ronald.
Chen, G., Gully, S. M., Whiteman, J.-A., & Kilcullen, R. N.
(2000). Examination of relationships among trait-like
individual differences, state-like individual differences,
and learning performance. Journal of Applied Psychology,
85(6), 835–847. doi:10.1037/0021-9010.85.6.835
Dweck, C. S. (1986). Motivational processes affecting
learning. American Psychologist, 41(10), 1040–1048.
doi:10.1037/0003-066X.41.10.1040
Dweck, C. S., & Leggett, E. L. (1988). A social-cognitive
approach to motivation and personality. Psychological
Review,
95(2),
256–273.
doi:10.1037/0033295X.95.2.256
Elliot, A. J., & McGregor, H. A. (2001). A 2 X 2
achievement goal framework. Journal of Personality and
Social Psychology, 80(3), 501–519.
Graesser, A. C., Conley, M. W., & Olney, A. (2012).
Intelligent tutoring systems. In K. R. Harris, S. Graham,
T. Urdan, A. G. Bus, S. Major, & H. L. Swanson (Eds.),

APA educational psychology handbook, Vol 3:
Application to teaching and learning. (pp. 451–473).
Washington, DC, US: American Psychological
Association.
Hulleman, C. S., Schrager, S. M., Bodmann, S. M., &
Harackiewicz, J. M. (2010). A meta-analytic review of
achievement goal measures: Different labels for the same
constructs or different constructs with similar labels?
Psychological
Bulletin,
136(3),
422–449.
doi:10.1037/a0018947
Jamieson-Noel, D., & Winne, P. H. (2003). Comparing selfreports to traces of studying behavior as representations of
students’ studying and achievement. Zeitschrift für
Pädagogische Psychologie/ German Journal of
Educational
Psychology,
17(3-4),
159–171.
doi:10.1024//1010-0652.17.34.159
Koedinger, K. R., & Aleven, V. (2007). Exploring the
assistance dilemma in experiments with Cognitive Tutors.
Educational Psychology Review, 19(3), 239–264.
Koedinger, K. R., & Corbett, A. (2006). Cognitive Tutors:
Technology bringing learning sciences to the classroom.
In R. K. Sawyer (Ed.), The Cambridge handbook of the
learning sciences. (pp. 61–77). New York, NY US:
Cambridge University Press.
Meece, J. L., & Holt, K. (1993). A pattern analysis of
students’ achievement goals. Journal of Educational
Psychology,
85(4),
582–590.
doi:10.1037/00220663.85.4.582
Pintrich, P. R. (2000). The role of goal orientation in selfregulated learning. In M. Boekaerts, P. R. Pintrich, & M.
Zeidner (Eds.), Handbook of self-regulation. (pp. 451–
502). San Diego, CA US: Academic Press.
Richardson, J. T. E. (2004). Methodological issues in
questionnaire-based research on student learning in higher
education. Educational Psychology Review, 16(4), 347–
358.
Salden, R., Aleven, V., Renkl, A., & Schwonke, R. (2009).
Worked examples and tutored problem solving:
Redundant or synergistic forms of support? Topics in
Cognitive Science, 1(1), 203–213.
Schwonke, R., Ertelt, A., Otieno, C., Renkl, A., Aleven, V.,
& Salden, R. (2012). Metacognitive support promotes an
effective use ofs instructional resources in intelligent
tutoring.
Learning
and
Instruction.
doi:10.1016/j.learninstruc.2012.08.003
Urdan, T. C. (1997). Achievement goal theory: Past results,
future directions. In M. L. Maehr & P. R. Pintrich (Eds.),
Advances in motivation and achievement (Vol. 10, pp.
99–141). Greenwich, CT: JAI Press.
Zhou, M., & Winne, P. H. (2012). Modeling academic
achievement by self-reported versus traced goal
orientation. Learning and Instruction, 22(6), 413–419.
doi:10.1016/j.learninstruc.2012.03.004

1108

