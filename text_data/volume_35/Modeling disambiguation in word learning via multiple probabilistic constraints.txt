UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling disambiguation in word learning via multiple probabilistic constraints
Permalink
https://escholarship.org/uc/item/15q1t7h9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Lewis, Molly
Frank, Michael
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                     University of California

  Modeling disambiguation in word learning via multiple probabilistic constraints
                                   Molly Lewis                                            Michael C. Frank
                               mll@stanford.edu                                         mcfrank@stanford.edu
                          Department of Psychology                                     Department of Psychology
                               Stanford University                                         Stanford University
                              Abstract                                    of the grocery store. There are an infinite number of possi-
                                                                          ble meanings of this word given this referential context, but
   Young children tend to map novel words to novel objects even           the child’s ability to correctly disambiguate would lead her
   in the presence of familiar competitors, a finding that has been
   dubbed the “disambiguation” effect. Theoretical accounts of            to rule out all meanings for which she already had a name.
   this effect have debated whether it is due to initial constraints      With this restricted hypothesis space, the child is more likely
   on children’s lexicons (e.g. a principle of mutual exclusivity) or     to identify the correct referent than if all objects in the context
   situation-specific pragmatic inferences. We suggest that both
   could be true. We present a hierarchical Bayesian model that           were considered as possible referents.
   implements both situation-level and hierarchical inference, and           What are the cognitive processes underlying this effect?
   show that both can in principle contribute to disambiguation
   inferences with different levels of strength depending on differ-      There are broadly two proposals in the literature. Under one
   ences in the situation and language experience of the learner.         proposal, Markman and colleagues (1988; 2003) suggest that
   We additionally present data testing a novel prediction of this        children have a constraint on the types of lexicons considered
   probabilistic view of disambiguation.
                                                                          when learning the meaning of a new word — a “mutual exclu-
   Keywords: Word learning; mutual exclusivity; Bayesian mod-             sivity constraint.” With this constraint, children are biased to
   els.
                                                                          consider only those lexicons that have a one-to-one mapping
                                                                          between words and objects. Importantly, this constraint can
                          Introduction                                    be overcome in cases where it is incorrect (e.g. adjectives),
A central property of language is that each word in the lexicon           but it nonetheless serves to restrict the set of lexicons initially
maps to a unique concept, and each concept maps to a unique               entertained when learning the meaning of a novel word. Un-
word (Clark, 1987). Like other important regularities in lan-             der this view, then, the disambiguation effect emerges from a
guage (e.g. grammatical categories), children cannot directly             constraint on the structure of lexicons.
observe this general property. Instead, they must learn to use               Under a second proposal, the disambiguation effect is ar-
language in a way that is consistent with this generalization             gued to result from online inferences made within the refer-
on the basis of evidence about only specific word-object pairs.           ential context (Clark, 1987; Diesendruck & Markson, 2001).
   Even very young children behave in a way that is consis-               Clark suggests that the disambiguation effect is due to two
tent with the one-to-one mapping between words and con-                   pragmatic assumptions held by speakers. The first assump-
cepts in language. Evidence for this claim comes from what                tion is that speakers within the same speech community use
is known as the “disambiguation” effect. In a typical demon-              the same words to refer to the same objects (“Principle of
stration of this effect (e.g. Markman & Wachtel, 1988), chil-             Conventionality”). The second assumption is that different
dren are presented with a novel and familiar object (e.g. a               linguistic forms refer to different meanings (“Principle of
whisk and a ball), and are asked to identify the referent of              Contrast”). In the disambiguation task described above, then,
a novel word (“show me the dax”). Children in this task                   children might reason (implicitly) as follows: You used a
tend to choose the novel object as the referent, behaving in              word I’ve never heard before. Since, presumably we both call
a way that is consistent with the one-to-one word-concept                 a ball “ball” and if you’d meant the ball you would have said
regularity in language, across a wide range of ages and ex-               “ball,” this new word must refer to the new object. Thus, un-
perimental paradigms (Mervis, Golinkoff, & Bertrand, 1994;                der this account, disambiguation emerges not from a higher-
Golinkoff, Mervis, Hirsh-Pasek, et al., 1994; Markman, Wa-                order constraint on the structure of lexicons, but instead from
sow, & Hansen, 2003; Halberda, 2003; Bion, Borovsky, &                    in-the-moment inferences using general pragmatic principles.
Fernald, 2013).                                                              These two proposals have traditionally been viewed as
   This effect has received much attention in the word learn-             competing explanations of the disambiguation effect. Re-
ing literature because the ability to identify the meaning of             search in this area has consequently focused on identifying
a word in ambiguous contexts is, in essence, the core prob-               empirical tests that can distinguish between these two theo-
lem of word learning. That is, given any referential context,             ries. For example, Diesendruck and Markson (2001) com-
the meaning of a word is underdetermined (Quine, 1960), and               pare performance on a disambiguation task when children
the challenge for the world learner is to identify the referent of        are told a novel fact about an object relative to a novel ref-
the word within this ambiguous context. Critically, the ability           erential label. They found that children disambiguated in
to infer that a novel word maps to a novel object makes the               both conditions and argued on grounds of parsimony that
problem much easier to solve. For example, suppose a child                the same pragmatic mechanism was likely to be responsible
hears the novel word “kumquat” while in the produce aisle                 for both inferences. More recent evidence contradicts this
                                                                      876

view: tests of children with autism, who are known to have
impairments in pragmatic reasoning, find comparable perfor-
mance on the disambiguation task between typically devel-
oping children and children with autism (Preissler & Carey,
2005; de Marchena, Eigsti, Worek, Ono, & Snedeker, 2011).
This result provides some evidence for the view that disam-
biguation is due to a domain-specific lexical constraint.
   We suggest that this competing-alternatives approach to the
disambiguation effect should be reconsidered. In a disam-
biguation task, learners may be making use of both higher-
order knowledge about how the lexicon is structured as well
as information about the pragmatic or inferential structure of
the task. Both of these constraints would then support chil-
dren’s inferences. In other words, these two classes of the-                  Figure 1: The generative process for our model.
ories may be describing distinct, but complementary mecha-
nisms that each contribute to a single empirical phenomenon,
with their weights in any given task determined by children’s         1). The critical feature of this existing model is that words are
age and language experience, the nature of the pragmatic sit-         assumed to be generated by intentions. This feature allows
uation, and other task-specific factors.                              the model to jointly solve the problems of mapping a word
   The model described here explores this proposal compu-             to an object in ambiguous contexts and learning a long term
tationally. We constructed a Bayesian model that captures             mapping between a word and concept.
effects of both inferences within individual situations and hi-          The learner infers a distribution over lexicons, given a cor-
erarchical inferences about the structure of lexicons. Infer-         pus S of situations (each consisting of sets of words w̄s and
ences about individual situations are modeled using an in-            objects ōs ). From Bayes’ rule, the posterior probability of a
tentional/pragmatic model of word learning (Frank, Good-              lexicon is given by
man, & Tenenbaum, 2009), while generalizations about the
nature of word-concept mappings are modeled as constraints                                                   P(S|l)P(l)
                                                                                           P(l|S) =                                     (1)
on the set of lexicons that the model considers. We present a                                          Âl 0 2L P(S|l 0 )P(l 0 )
set of simulations and a developmental experiment showing
that linguistic experience can influence the strength of disam-       We first define the likelihood term P(S|L) and then return to
biguation inferences at both levels.                                  the prior P(L), which implements hierarchical constraints C
   The goal of our model is not to provide an algorithmic de-         on lexicons.
scription of children’s word learning, which we assume de-               Using the generative process in Fig. 1, we can write the
pends on psychological factors such as memory and cognitive           likelihood of a particular situation in terms of the relationship
control. Instead, we aim to provide an ideal observer anal-           between the objects that were observed in the situation s, the
ysis: to derive normative predictions given a well-articulated        speaker’s referential intention is (a choice to speak about one
set of assumptions (Geisler, 2003). Human behavior can then           of the objects), and the referring word ws .1 As in our prior
be compared to this analysis, and deviations can be attributed        work, we assume that referential intentions are unobserved
to differences between the assumptions of the model and the           and sum across all possible intentions uniformly2 :
realities of human psychology. Critically, neither our model
(nor comparisons between it and human behavior) constitute                                 P(s|l) =     Â P(ws , os , is |l)            (2)
claims of human optimality: Though our model employs opti-                                             is 2o¯s
mal Bayesian inference, there is no implicit claim that human         By the conditional independence of words and objects, we
learners also do so (Frank, in press).                                can expand to:
                            Model
                                                                                         P(s|l) =   Â P(ws |is , l)P(is |os )           (3)
We model a word learner as performing Bayesian inference                                           is 2o¯s
to infer the structure of a lexicon l, which we represent as          Finally, we aggregate across situations by taking the product
a (sparse) bipartite graph connecting words W = w1 ...wn to           of each independent situation:
objects O = o1 ...om . We write the full possible set of lexicons
as L. An example enumeration of such lexicons for the case                1 In this analysis, we focus only on situations where a single re-
of n = m = 2 is given in Fig. 2.                                      ferring word is used.
                                                                          2 This assumption is made for purposes of simplicity only, as a
   We assume a generative structure identical to the the model
                                                                      variety of our previous work has explored the use of social and prag-
developed by Frank et al. (2009), with the added complexity           matic information in biasing the distribution over intended referents
of constraints placed on lexicons (described below; see Fig.          (Frank & Goodman, 2012).
                                                                  877

                                        1
                                                                                                                                         1 1
                                       0.9                                                                                               1 many
                                                                                                                                         many 1
                                       0.8                                                                                               null
               Posterior probability
                                       0.7
                                       0.6
                                       0.5
                                       0.4
                                       0.3
                                       0.2
                                       0.1
                                        0
                                                                                          Lexicons
                          word
                 object
                                             1 2     1 2   1 2   1 2   1 2   1 2   1 2    1 2     1 2    1 2   1 2   1 2    1 2   1 2   1 2   1 2
Figure 2: The posterior probability distribution over lexicons for our models for Simulation 1. Models were trained with
situations establishing the mapping between w1 and o1 (the familiar word/object pair) and a disambiguation situation including
w2 and objects o1 and o2 . The four different constraint models are distinguished by color in the main plot, while the 16 possible
lexicons are shown on the horizontal axis. Lexicons are marked as links between words and objects, with the correct (w2 and o2 )
mapping marked in green and the incorrect (w2 and o1 ) mapping marked in red. The noise parameter a was chosen arbitrarily
for display purposes and serves only to scale the results.
                                                                                                one word in a lexicon. The many-1 constraint applies a re-
             P(S|l) = ’ Â P(ws |is , l)P(is |os )                                   (4)         striction that each word maps to at most one object in a lexi-
                                              s2S i2ōs                                         con. The 1-1 constraint applies both of these restrictions, and
   We assume that there is some level of noise in both the                                      the null constraint applies neither of these restrictions.3 In
choice of word given intention P(ws |is , l) and the choice of                                  practice, these hypotheses were implemented such that each
intention given object P(is |os ), such that the speaker could                                  lexicon consistent with a constraint was equiprobable, and all
in principle have been mistaken about their referent or mis-                                    inconsistent lexicons had probability 0. For simplicity, we
spoken their word. We implement this decision by assuming a                                     assumed that P(c) µ 1, although this assumption could easily
constant probability of random noise for each of these, which                                   be modified in future work.
we notate a. For simplicity, a is assumed to be the same for                                       For the simulations below, we were able to infer exact pos-
both terms. The value of a serves only to scale the results                                     terior distributions by enumerating all possible lexicons and
we report below, but—as in nearly all probabilistic models—                                     normalizing (Equation 1).
some level of uncertainty about the individual observations is
necessary to make graded predictions.                                                           Simulation 1: Disambiguation at multiple levels
   We now consider the prior distribution over lexicons. We                                     As a first test of our model on the disambiguation task, we
define this prior hierarchically as being the product of a con-                                 trained the model on a corpus containing two situations. The
straint over lexicons c 2 C:                                                                    first was an unambiguous situation in which word w1 was as-
                                                                                                sociated with object o1 . This piece of evidence corresponded
                                             P(l) = P(l|c)P(c)                      (5)         to the known word in the disambiguation task (“ball” in the
We consider a hypothesis space of four different constraints                                    example described above). We also included a disambigua-
placed on the mappings between words and objects within                                         tion experimental situation, where the previously learned ob-
lexicons: one word to one object (1-1 constraint), one word to                                  ject o1 (ball), a new object o2 (whisk), and a novel word w2
many objects (1-many constraint), many words to one object                                         3 The 1-many constraint is related to the concept learning model
(many-1 constraint), and a null constraint. The 1-many con-                                     proposed by Goodman, Tenenbaum, Feldman, and Griffiths (2010)
straint applies a restriction that each object maps to at most                                  using a disjunctive normal form grammar.
                                                                                          878

                                       e                                              e                                        e
         0.7                                       0.7                                          0.7
         0.6                                       0.6                                          0.6
         0.5                                       0.5                                          0.5
         0.4                                       0.4                                          0.4
         0.3                                       0.3                                          0.3
         0.2                                       0.2                                          0.2
         0.1                                       0.1                                          0.1
           0                                         0                                            0
                  1     2       3      4                     1     2      3      4                      1      2      3      4
                     Number of objects                         Number of objects                           Number of objects
Figure 3: Results from Simulation 2. Each panel shows the probability of inferring a 1-1 constraint on the lexicon given a
different input corpus, described in text. Horizontal axes varies the overall number of distinct objects presented in the exposure
corpus, while the colored lines denote different numbers of exposures to the corpus.
(“dax”).                                                                 To explore the model’s ability to learn a hierarchical 1-1
   Figure 2 shows the posterior distribution over lexicons in-        constraint on lexicons, we trained our model on three cor-
ferred on the basis of this corpus. Each of the 16 possible           pora. Each corpus consisted of a set of situations with a single
lexicons (assuming a world with only two words and two                word and a single object, but we varied whether these map-
objects) are represented along the x-axis, where lexicons are         pings were consistent. The first, the “unambiguous exposure”
represented by object and word nodes connected by links.              corpus, showed unambiguous (1-1) mappings between words
   In this maximally simple simulation of the disambiguation          and objects. The second, the “occasionally ambiguous” cor-
task, all four prior constraints give the highest posterior prob-     pus, showed the same body of data but with two contradictory
ability to the lexicon that links the novel word and the novel        mappings appended to the end. The final, “fully ambiguous,”
object. This result emerges from the structure of the infer-          corpus consisted of one word that mapped to many objects.
ence problem: Given that the learner has already observed an          We varied both the number of exposures to the corpus (1–4)
association between w1 and o1 , lexicons that posit a link be-        and the number of objects in the corpus (1–4). We then ex-
tween w1 and o2 are less probable than those that posit a link        amined the posterior probability of the 1-1 constraint given
between w2 and o2 . This result comes about because an ob-            these exposure corpora.
ject with two names (w1 and w2 ) can be talked about in two              The results of this simulation are shown in Figure 3. Given
different ways, and each of them is individually less probable        1-1 evidence, the model induces a 1-1 constraint on lexicons,
than the one way of talking about an unambiguously-named              and this bias becomes stronger as the number of observations
object. (This result echoes the finding of mutual exclusivity         increases. The posterior probability of the 1-1 constraint is
in Frank et al., 2009).                                               decreased only slightly by a few ambiguous observations, re-
   These results suggest that disambiguation behavior in chil-        flecting the general robustness of this inference. In contrast,
dren could emerge without a 1-1 constraint on lexicons. On            in the fully ambiguous condition, the model learns with rela-
the other hand, prior constraints affected the strength of the        tively little data that a 1-1 constraint does not hold.
disambiguation inference. Constraints barring 1-many and
many-1 mappings increased the posterior probability of the                Simulation 3: Stronger mappings result in
correct lexicon; when both were in place, the correct lexicon                           stronger disambiguation
had by far the highest probability. Thus, probabilistic infer-        In Simulation 3, we explore whether providing more evidence
ence and hierarchical constraints both support disambigua-            for a link between the known word and object will in turn
tion behavior in the model.                                           strengthen the probabilistic disambiguation effect between
                                                                      words and objects. Recall that the disambiguation effect in
 Simulation 2: Learning constraints on lexicons                       Simulation 1 emerged as a result of prior evidence for an asso-
Simulation 1 suggested that a learner could behave consistent         ciation between the known word and object (“ball” and ball).
with a 1-1 constraint on lexicons without assuming a hard             Thus, this model predicts that if the learner receives more evi-
constraint on the structure of lexicons. Nevertheless, impos-         dence for an association between the known word and known
ing such a hard constraint raised the probability of a correct        object, the disambiguation bias should become stronger.
answer on the disambiguation task. In this simulation, we                We trained the model with either 1, 2, or 3 situations in
show that learners may induce a higher-order constraint on            which w1 was unambiguously associated with o1 . We then
lexicons given the right kind of evidence.                            tested the model in the disambiguation task with a known and
                                                                  879

                                     1                                              1
               Proportion Correct                             Proportion Correct
                                    0.8                                            0.8
                                    0.6                                            0.6
                                    0.4                                            0.4                                                             Experimental Data
                                                                                                                                             1
                                    0.2                                            0.2
                                                                                                                      Proportion Correct
                                                                                                                                           0.8
                                     0                                              0
                                          1       2       3                              1      2         3
                                                                                                                                           0.6
                                           Number of Labels                              Number of Labels
                                                                                                                                           0.4
                                                                                                                                                                       s
                                     1                                              1                                                      0.2                         s
                                                                                                                                                                       s
               Proportion Correct                             Proportion Correct
                                    0.8                                            0.8                                                       0
                                                                                                                                                   1       2      3
                                    0.6                                            0.6                                                             Number of Labels
                                    0.4                                            0.4
                                    0.2                                            0.2                                                     Low Noise
                                     0                                              0                                                      High Noise
                                          1       2       3                              1      2         3
                                           Number of Labels                              Number of Labels
Figure 4: Model predictions under each of the four lexical constraints (left) and experimental results (right) for success in the
disambiguation task as a function of the number of labels observed in training. Lower legend shows noise conditions for the
model simulations.
unknown object and a novel word, as in Simulation 1, but us-                                         ject (“And this one is cool too”) to ensure equal familiarity.
ing a Luce choice rule to compute the probability of a correct                                       In the test phase, the child was asked to point to the object
choice (Luce, 1963). If more observed associations between                                           referred to by a second novel label (“Can you show me the
the known word and object lead to a stronger bias toward cor-                                        zot?”). Number of labels used in the training phase was ma-
rect lexicons, we should expect the disambiguation bias to                                           nipulated between subjects. There were eight different novel
increase with the number of training situations.                                                     words and objects. Object presentation side, object, and word
   Assuming a 1-1 constraint, the magnitude of the bias to-                                          were counterbalanced across children.
ward correct lexicons increases with number of training situ-
ations with the known word–known object association (Fig.                                            Results
4, upper–left panel). In addition, the magnitude of this in-                                         Responses were coded as correct if participants selected the
crease is sensitive to the noise parameter a that determines                                         novel object at test. As predicted, children showed a stronger
the probability that the wrong word was spoken to refer to an                                        disambiguation effect as the number of training labels in-
object.                                                                                              creased, and as noise decreased with age (Fig. 4, right panel).
                                                                                                        We analyzed the results using a logit mixed model to pre-
                                          Experiment                                                 dict correct responses with age and number of labels as fixed
We tested the prediction that confidence in the known word                                           effects, and participant as a random effect. There was a sig-
mapping leads to a stronger disambiguation inference in                                              nificant effect of age (b = .044, p < .001) such that older chil-
preschool children.                                                                                  dren showed a stronger disambiguation bias. There was also a
                                                                                                     significant effect of number of labels, such that more training
Methods                                                                                              labels led to stronger disambiguation (b = .454, p < .001).
We recruited 110 children ages 2;1–4;11 from the floor of the                                        The interaction between age and number of labels was not
Boston Children’s Museum. In each one-year age group, we                                             significant (b = .019, p = .16). Children’s increased confi-
collected data from 35–38 children.                                                                  dence in the disambiguation inference, as a function of num-
   Each child completed four trials. Each trial consisted of a                                       ber of training labels, is consistent with model predictions.
training and a test phase in a “novel-novel” disambiguation
task (de Marchena et al., 2011). In the training phase, the                                                                                General Discussion
experimenter presented the child with a novel object, and ex-                                        The disambiguation effect suggests the presence of underly-
plicitly labeled the object with a novel label 1, 2, or 3 times                                      ing cognitive mechanisms that help children solve the diffi-
(“Look at the dax”), and contrasted it with a second novel ob-                                       cult mapping problem inherent of early word learning (Quine,
                                                                                               880

1960). Two classes of mechanisms have been proposed: a                                        References
constraint on the structure of permitted lexicons, and in-the-       Bion, R., Borovsky, A., & Fernald, A. (2013). Fast mapping,
moment pragmatic inferences about the most likely referent             slow learning: Disambiguation of novel word–object map-
given the context. We used a hierarchical Bayesian model to            pings in relation to vocabulary learning at 18, 24, and 30
explore the independent contributions of these two effects and         months. Cognition, 126, 39–53.
find that neither mechanism is necessary to create a bias, but       Byers-Heinlein, K., & Werker, J. (2009). Monolingual, bilin-
either is sufficient. Disambiguation is strongest when both            gual, trilingual: infants’ language experience influences the
mechanisms jointly contribute.                                         development of a word-learning heuristic. Developmental
   This result has important consequences for attempts to ex-          Science, 12, 815–823.
perimentally differentiate between the proposed accounts of          Clark, E. (1987). The principle of contrast: A constraint on
disambiguation. Given that both mechanisms can in principle            language acquisition. Mechanisms of Language Acquisi-
lead to disambiguation behavior, experimental tests of disam-          tion. Hillsdale, NJ: Erlbaum.
biguation cannot distinguish between these two theories (as          de Marchena, A., Eigsti, I., Worek, A., Ono, K., & Snedeker,
they are instantiated here). That is, evidence for disambigua-         J. (2011). Mutual exclusivity in autism spectrum disorders:
tion behavior is consistent with both a pragmatic account and          Testing the pragmatic hypothesis. Cognition, 119, 96–113.
a mutual exclusivity constraint account. Furthermore, there          Diesendruck, G., & Markson, L. (2001). Children’s avoid-
may be variability in the weights of these constraints across          ance of lexical overlap: A pragmatic account. Develop-
populations. For example, higher-order lexical constraints             mental Psychology, 37, 630.
may play a larger role in disambiguation for individuals with        Frank, M. C. (in press). Throwing out the Bayesian baby
impaired social-cognitive skills (e.g. autism), relative to typ-       with the optimal bathwater: Response to Endress (2013).
ically developing children. Our results suggest that future re-        Cognition.
search in this area should reconsider the assumption that a          Frank, M. C., & Goodman, N. (2012). Predicting pragmatic
single mechanism must completely and independently give                reasoning in language games. Science, 336, 998–998.
rise to the disambiguation effect.                                   Frank, M. C., Goodman, N., & Tenenbaum, J. (2009). Us-
   Our model may provide useful insight into disambiguation            ing speakers’ referential intentions to model early cross-
in bilingualism. For bilingual learners, the structure of asso-        situational word learning. Psychological Science, 20, 578.
ciations between words and objects in the environment dif-           Geisler, W. (2003). Ideal observer analysis. The Visual Neu-
fers from that of monolinguals. Bilingual learners typically           rosciences, 825–837.
observe two basic-level words associated with each object            Golinkoff, R., Mervis, C., Hirsh-Pasek, K., et al. (1994).
rather than one. To make sense of these associations, they             Early object labels: The case for a developmental lexi-
might ultimately form an overhypothesis that there is a 1-1            cal principles framework. Journal of Child Language, 21,
constraint on lexicons within each language, but they might            125–125.
nevertheless initially entertain a 1-many constraint as a hy-        Goodman, N., Tenenbaum, J., Feldman, J., & Griffiths, T.
pothesis. Indeed, there is evidence that disambiguation be-            (2010). A rational analysis of rule-based concept learning.
havior is weaker in bilingual and trilingual children (Byers-          Cognitive Science, 32, 108–154.
Heinlein & Werker, 2009).                                            Halberda, J. (2003). The development of a word-learning
                                                                       strategy. Cognition, 87, B23–B34.
   Finally, it is important to consider the limits of an ideal
                                                                     Luce, R. (1963). Detection and recognition. Handbook of
observer analysis. While our results suggest that both mecha-
                                                                       Mathematical Psychology, 1, 103–189.
nisms could contribute to disambiguation behavior, this find-
                                                                     Markman, E., & Wachtel, G. (1988). Children’s use of mutual
ing does not entail that both mechanisms do in fact contribute.
                                                                       exclusivity to constrain the meanings of words. Cognitive
It remains possible that disambiguation behavior is the result
                                                                       Psychology, 20, 121–157.
of a single mechanism. Nonetheless, given evidence from
                                                                     Markman, E., Wasow, J., & Hansen, M. (2003). Use of
other domains that the mind may simultaneously integrate
                                                                       the mutual exclusivity assumption by young word learners.
basic probabilistic inferences with higher-order constraints
                                                                       Cognitive Psychology, 47, 241–275.
(Tenenbaum, Kemp, Griffiths, & Goodman, 2011), it seems
                                                                     Mervis, C., Golinkoff, R., & Bertrand, J. (1994). Two-year-
likely that disambiguation behavior emerges from multiple
                                                                       olds readily learn multiple labels for the same basic-level
underlying cognitive mechanisms.
                                                                       category. Child Development, 65, 1163–1177.
                                                                     Preissler, M., & Carey, S. (2005). The role of inferences
                    Acknowledgements                                   about referential intent in word learning: Evidence from
                                                                       autism. Cognition, 97, B13–B23.
We gratefully acknowledge Jesse Snedeker for the suggestion          Quine, W. (1960). Word and object (Vol. 4). The MIT Press.
that led to the Experiment, as well as for providing materials       Tenenbaum, J., Kemp, C., Griffiths, T., & Goodman, N.
from de Marchena et al. (2011). We thank Joseph Auster-                (2011). How to grow a mind: Statistics, structure, and ab-
weil for valuable feedback, and Melina Flores for assistance           straction. Science, 331, 1279–1285.
in data collection.
                                                                 881

