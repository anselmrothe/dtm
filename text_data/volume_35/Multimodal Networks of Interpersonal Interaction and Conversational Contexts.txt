UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Multimodal Networks of Interpersonal Interaction and Conversational Contexts
Permalink
https://escholarship.org/uc/item/88v077x9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Paxton, Alexandra
Dale, Rick
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

    Multimodal Networks of Interpersonal Interaction and Conversational Contexts
                                        Alexandra Paxton (paxton.alexandra@gmail.com)
                                                 Rick Dale (rdale@ucmerced.edu)
                                 Cognitive and Information Sciences, University of California, Merced
                                                         Merced, CA 95341 USA
                              Abstract                                   of this work centers on one or two behavioral channels, but
   In interpersonal interaction, the terms synchrony or alignment
                                                                         a growing body of literature has begun to investigate how
   refer to the way in which communication channels like speech          multiple channels align during communication (e.g.,
   or body movement become intertwined over time, both across            Louwerse, Dale, Bard, & Jeuniaux, 2012).
   interlocutors and within a single individual. A recent trend in          A distinction can be drawn between alignment in a
   alignment research has targeted multimodal alignment,                 general sense and synchrony.1 We use the term alignment to
   exploring how various communication channels affect one               refer broadly to the concept that individuals, over time,
   another over time (e.g., Louwerse et al., 2012). While existing       change their affect, behavior, and cognition as a direct result
   research has made significant progress in mapping
   multimodal alignment during task-based or positively                  of their interaction with another individual. This umbrella
   valenced interactions, little is known about the dynamics of          term encompasses everything from mimicry, in which
   multimodal alignment during conflict. We visualize                    individuals are performing highly similar behaviors to their
   multimodal alignment during naturalistic affiliative and              interaction partner (e.g., Chartrand & Bargh, 1999), to more
   argumentative interactions as networks based on analyses of           complementary behavior patterns like synergy (e.g., Riley,
   body movement and speech. Broadly, we find that                       Richardson, Shockley, & Ramenzoni, 2011). Synchrony, on
   conversational contexts strongly impact the ways in which
                                                                         the other hand, can be considered a specific pattern of
   interlocutors’ movement and speech systems self-organize
   interpersonally and intrapersonally.                                  alignment and refers exclusively to the in-phase entrainment
   Keywords: alignment; conflict; conversation; interaction;             of behavior or communication channels.
   movement; network; speech; synchrony                                     In the spirit of intrapersonal alignment research spanning
                                                                         the last several decades (e.g., Haken, Kelso, & Bunz, 1985),
                          Introduction                                   the current research explores the dynamics of interpersonal
Interpersonal communication is a multimodal activity.                    alignment as a self-organizing property of human
Conversation        incorporates        multiple    channels       of    interaction. The present research focuses specifically on two
communication that enrich the interaction, like hand                     channels of communication—speech and body movement—
gestures, facial expressions, posture, and speech. To                    and the ways in which these channels are affected by each
effectively communicate with one another, interlocutors cue              other, by conversation partners, and by the conversational
in to each of these channels simultaneously, often without               context. If it is true that human interaction self-organizes
realizing the importance placed on each of them.                         around, for example, conversational goals, we should expect
   Considerable work has surveyed multimodal qualities of                to see multimodal alignment patterns changing across these
interaction (e.g., Norris, 2004). However, in general,                   different contexts.
experimental study of interpersonal communication in
cognitive science tends to target single behavioral channels.            Body Movement and Speech Alignment
This has led to significant advances in our understanding of             Previous work on speech and body movement demonstrates
these specific channels, but there is still much work to be              rich interactivity between and within individuals. Some of
done in investigating the connections among them.                        the earliest work in alignment research presents evidence for
Continued multimodal research will likely yield                          interpersonal and intrapersonal multimodal alignment
interesting—and possibly unexpected—relationships among                  between movement and speech channels (Condon &
channels that have been extensively explored unimodally.                 Ogston, 1966). Since then, research has continued to explore
For this reason, the current research explores multimodal                intrapersonal alignment, both in speech (Reitter, Moore, &
alignment situated within different conversational contexts.             Keller, 2010) and movement (Beek, Peper, & Daffertshofer,
   Specifically, the present research examines interpersonal             2002). However, body movement and speech have both
communication through alignment dynamics. Research on                    been studied extensively within the interpersonal alignment
interpersonal alignment focuses on how affect, behavior,                 literature as well, generally within affect-neutral, positively
and cognition of interacting individuals affect one another              valenced, or task-oriented settings.
over time. Over the past several decades, researchers have                  Studies of body movement alignment have spanned a
explored interpersonal alignment over a range of channels,               wide variety of behaviors, including gesture (Bernieri &
from movement (e.g., Richardson et al., 2007) to speech
(e.g., Garrod & Pickering, 2004) to cognition (e.g., Brennan,               1
                                                                              These specific terminologies are laid out here for the purpose
Galati, & Kuhlen, 2010). As aforementioned, the majority                 of the present paper, rather than trying to resolve the emerging
                                                                         terminological debate within the field.
                                                                     1121

Rosenthal, 1991), stepping (Miles, Griffiths, Richardson, &      within individuals, and recent trends have begun to situate
Macrae, 2010), and overall levels of body movement               this alignment within the context of multimodal interaction.
(Paxton & Dale, in press). Often, work on body movement          Yet, so far, the dynamics of multimodality in alignment
alignment incorporates elements of social psychology, like       have remained relatively unexplored. Moreover, research on
investigating how interpersonal alignment affects liking         alignment thus far has sampled only a small percentage of
(Chartrand & Bargh, 1999). Broadly speaking, these               the total space of human communicative contexts, focusing
findings generally cast the phenomenon as a pervasive and        primarily on task completion or friendly interactions.
relatively automatic process that can be enhanced with              Our primary goal in the present study is to add to the
liking or rapport. However, limited research suggests that       growing literature on the dynamics of multimodal
higher-level social factors may inhibit bodily alignment         alignment. We aim to extend various elements of previous
(Miles et al., 2010; Paxton & Dale, under revision).             findings on unimodal and multimodal alignment, both inter-
   Individuals also align over numerous measures of speech.      and intrapersonally. The present study explores participants’
Over time, interacting individuals have been shown to use        speech patterns and their relation to body movement with
more similar acoustic features (Kousidis & Dorran, 2008),        three initial hypotheses. First, we hypothesize that
sentence structures (Cleland & Pickering, 2003), and even        individuals will align to one another’s speech patterns but
respiratory patterns (McFarland, 2001). The tendency             will not demonstrate in-phase synchrony of speech, due to
toward alignment during interaction is so powerful that          the natural constraints of turn-taking. Second, we anticipate
individuals even align to simulated partners (Krämer, Kopp,      that individuals will exhibit multimodal intrapersonal
Becker-Asano, & Sommer, 2012). These and related                 synchrony, tending to move and speak at the same time.
findings of interpersonal alignment in speech have led some      Third, although we anticipate that individuals will be most
to suggest that this is an automatic tendency driven in part     likely to move while speaking (and the reverse), we expect
by shared cognitive representations (Brennan et al., 2010).      that analyses will reveal some evidence for interpersonal
   These past findings point to a distinct temporal structure    multimodal alignment (e.g., due to nodding).
of speech and movement during interaction. Recently,                The current project extends previous work on multimodal
researchers have begun to emphasize the importance of            alignment further by situating the research within different
investigating interpersonal multimodal alignment on a large      conversational contexts, namely affiliation and argument.
scale (e.g., Delaherche & Chetouani, 2010; Louwerse et al.,      As part of a larger line of research investigating alignment
2012). These questions allow researchers to more fully           in various contexts, the present research brings a focus on
understand the complex, interdependent structure of              asymmetric contexts—interactions in which individuals
communication channels during interaction.                       have conflicting, differing, or opposing goals—to bear on
                                                                 questions of multimodal alignment. Previous research has
Dynamics of Interpersonal Alignment                              demonstrated that conflict significantly decreases levels of
Mechanistic models of body mechanics (e.g., interlimb            interpersonal bodily synchrony (Paxton & Dale, under
coordination; Haken et al., 1985) have influenced recent         revision). We continue to explore alignment during conflict
work on the dynamics in interpersonal interaction (e.g.,         in the present project. Compared to non-asymmetric
Miles et al., 2010). Researchers have begun to explore the       contexts, we anticipate that argument will affect alignment
forms and functions of alignment, going beyond earlier           in several ways: first, that individuals will demonstrate a
studies simply investigating its existence. Such work is         more rigid turn-taking structure (possibly, e.g., to satisfy
dedicated to exploring the time course of alignment with the     implicit social demands for reciprocity); second, that levels
belief that—like many other phenomena—alignment is               of intrapersonal multimodal synchrony will remain
neither static nor uniform across contexts.                      consistent; and third, that levels of interpersonal multimodal
   Like the work discussed above, research on interaction        alignment will decrease. This pattern of results—balancing
dynamics has also focused on speech and movement                 stable conversational structures with sensitivity to
channels. From gaze patterns and postural sway (Shockley,        contextual factors—would reinforce claims of context-
Richardson, & Dale, 2009) to speech production (Tilsen,          dependent, emergent properties of human interactions.
2009), researchers have found support for dynamical                 In addition to analyzing these data, the present study also
interpersonal and intrapersonal alignment, both unimodal         hopes to begin work towards descriptive models of
and multimodal. Individuals’ patterns of alignment change        interpersonal and intrapersonal multimodal and unimodal
with task demands (Sebanz, Bekkering, & Knoblich, 2006),         alignment in different conversational contexts. After
social context (Miles, Lumsden, Richardson, & Macrae,            presenting our analyses, we highlight our findings in
2011), and even physical environment (Richardson et al.,         visualization networks of multimodal alignment dynamics.
2007), providing further support for claims of context
dependence in alignment (Riley et al., 2011).                                               Method
                    The Present Study                            Corpus
Previous work has pointed to distinct patterns of                The data presented here were collected by the authors as
organization of speech and body movement between and             part of a larger corpus comparing interpersonal alignment
                                                             1122

during argument and affiliation. The corpus comprised over              opposing views (e.g., one pro-life, the other pro-choice) and
35 naïve participant dyads engaged in different                         for which both participants indicated strong feelings was
conversational settings, collected from the University of               chosen. Up to two additional argumentative prompts were
Memphis and the University of California, Merced. As a                  chosen using the same criteria and were given to
further exploratory analysis building on previous findings              participants if they could not continue the argumentative
(Paxton & Dale, in press; Paxton & Dale, under revision),               conversation on the first topic for the entire time.
the present analyses were performed on a subset of the
participants from the University of California, Merced,                 Materials
based on uniformity of experimental conditions. The audio               Movement data were collected automatically using a frame-
data had not yet been analyzed, separately or in conjunction            differencing method (FDM; Paxton & Dale, in press).
with body movement.                                                     Participants sat facing one another during their
                                                                        conversations and were captured in profile in a single frame
Participants                                                            on a high-definition camcorder (Canon VIXIA HF M31).3
24 undergraduate participants (mean age=20.14 years) were               The videos were downsampled at 8Hz to a series of still
recruited as 12 dyads (6 female, 6 mixed-sex) through the               frames. The FDM tracked movement by registering changes
school’s online subject pool system. Participants signed up             in pixels across frames (see Figure 1 for toy visualization)
independently and were unable to see their partner’s identity           and applying a filter to remove extraneous pixel changes
beforehand. Only one dyad reported having known one                     (e.g., due to fluctuations in light sources). For additional
another prior to participation. One mixed-sex dyad was                  detail on the FDM, see Paxton and Dale (in press). See also
dropped from present analyses because their opinions were               Grammer, Honda, Jüette, and Schmitt (1999) for related
too similar to achieve any argument during the experiment.              methods.
Procedure
Upon arrival, participants were separated and individually
completed a number of questionnaires prior to interacting
with one another. One of the questionnaires was an opinion
survey that included a number of sociopolitical (e.g.,
                                                                             Figure 1: Sample FDM sequence of interacting dyad,
abortion, death penalty, legalization of marijuana) and
                                                                         aggregated over multiple frames for visualization purposes.
university-specific (e.g., a campus rule forbidding freshmen
students from bringing cars to campus) issues. The opinion
                                                                           Speech data were collected using individual lapel
survey posed the issues as open-ended, opinion-neutral
                                                                        microphones (Audio-Technica ATR 3350) and a mixer
questions. For each item, participants were given several
                                                                        (Azden CAM-3) so that each participant’s audio was
lines to write their opinion and were directed to indicate the
                                                                        captured on a separate channel. The present research used
strength of that opinion on a Likert-style scale from 1 (feel
                                                                        on/off speech states as the measure for speech. On/off
very weakly) to 4 (feel very strongly).
                                                                        speech states were obtained for each participant using the
   Participants were randomly assigned to one of two
                                                                        sound finder function in Audacity. Decibel cutoffs were
conditions based on the order of the two target
                                                                        individually determined for each dyad in order to maximize
conversations that they were prompted to have. All dyads
                                                                        sensitivity and specificity.
held a brief introduction conversation without the
                                                                           Samples of data obtained from each interaction type are
experimenter present (~3min) and two target conversations
                                                                        graphed in Figure 2. Each sample includes 250sec of
(10min each). Half of the dyads were given an affiliative
                                                                        interaction. Taken from the same dyad, the figures graph
prompt first and an argumentative prompt second; half of
                                                                        changes in body movement as red and blue lines, with
the dyads experienced the reverse order. After each target
                                                                        speech events depicted as boxes of corresponding color
conversation, participants were separated to complete post-
                                                                        behind the lines.
conversation measures. Participants were not informed in
advance of the conversation topics. After holding both target
conversations, participants were thanked and debriefed.
                                                                                                     Results
   For the affiliative conversation, dyads were instructed to           The present analyses tested for unimodal and multimodal
discuss     popular      media      that    both       participants     interpersonal and intrapersonal alignment. Cross-
enjoyed.2 Experimenters identified the argumentative                    correlations were calculated for interpersonal unimodal
prompt for each dyad based on participants’ responses to the            (e.g., participant A’s movement to participant B’s
opinion survey. The topic for which participants expressed              movement), interpersonal multimodal (e.g., participant A’s
                                                                        speech to participant B’s movement), and intrapersonal
   2                                                                       3
     Due to experimenter error, one dyad’s affiliative prompt was            The experimenter sat beside the camcorder, outside of the
based on a sociopolitical topic on which both agreed. However,          participants’ immediate range of vision, in order to monitor the
close inspection of the data confirmed the affiliative nature of the    equipment unobtrusively and to ensure the participants did not
conversation.                                                           stray from the assigned topic.
                                                                    1123

     Figure 2: Sample body movement time series of a single dyad during 250s of interaction during an affiliative (left) and
           an argumentative (right) conversation. Speech data are represented as shaded boxes of corresponding colors.
multimodal (e.g., participant A’s movement to participant           Speech The second model tested interpersonal speech
A’s speech) channels within a +/- 3000ms range, yielding a          alignment during different conversation contexts, using
series of cross-correlation                                         conversation type and time lag (125ms) to predict
coefficients (r). Using cross-correlation coefficients              interpersonal speech alignment (rspeech). As anticipated,
permitted us to investigate both in-phase synchrony and             increases in time lag predicted increases in rspeech (ß=.15;
longer-phase alignment trends within the data.                      p<.0001), while argumentative conversation type
  The data were primarily analyzed using a series of linear         significantly predicted a decrease in rspeech (ß=-.44;
mixed-effects models (Baayen, 2008), using dyad and                 p<.0001). The interaction term was also significant (ß=-.11;
condition as random effects unless otherwise noted. All             p<.001). Together, these results suggest that interlocutors
main and interaction terms were standardized prior to being         generally respected the turn-taking structure during all
entered into the models. As standardized values, the cross-         conversations but were more likely to exhibit overlapping
correlation coefficients can be interpreted as beta weights, a      speech during affiliative conversations.
measure of effect size (Keith, 2005).                                  To better situate these results, we performed
                                                                    complementary analyses comparing participants’ speech
Unimodal Alignment                                                  patterns during different conversation types, accounting for
Movement Previous analyses of the corpus found evidence             condition, conversation number, speaker, and dyad
for in-phase bodily synchrony (Paxton & Dale, under                 membership as random effects. In a model predicting turn
revision).4 To ensure that the subset analyzed here exhibited       length with conversation type, argumentative conversations
similar patterns, our first model predicted interpersonal           predicted slightly but significantly longer turn lengths
body movement alignment (rmov) with conversation type               compared with affiliative conversations (ß=.04; p<.005).
(affiliative or argumentative) and time lag (125ms                  Another model predicted total number of speech events in a
increments). Results confirmed that the subset of dyads             conversation by both participants using conversation type
conformed to broader patterns within the whole corpus.              and found that argumentative conversations had
Increases in time lag (i.e., comparing movement further             significantly fewer speech events than affiliative
removed in time) significantly predicted a drop in rmov (ß=-        conversations (ß=-.31; p<.0001).
.25; p<.0001), providing evidence for in-phase interpersonal
synchrony. Changes in rmov were also significantly predicted        Multimodal Alignment
by conversation type (ß=-.19; p<.0001), with lower levels of        Interpersonal Next, we predicted interpersonal multimodal
movement synchrony in argumentative conversations.                  cross-correlation coefficients (rmulti) with conversation type
Interestingly, while only trending toward significance in           and time lag. The main effect for conversation type was
analyses of the entire corpus, the interaction term between         again significant, with argumentative conversations
conversation type and time lag reached significance in this         predicting a significant drop in rmulti (ß=-.21; p<.0001).
subset of the data (ß=.14; p<.01): Interlocutors’ body              Neither time lag (ß=-.02; p=.39) nor the interaction term
movements were more tightly synchronized during                     (ß=.01; p=.76) reached significance.
affiliative conversations, reaching higher peak rmov and
falling more sharply as time lag increased.                         Intrapersonal Our final model predicted intrapersonal
                                                                    multimodal cross-correlation coefficients (rself) with
                                                                    conversation type and time lag. As predicted, we found no
  4
     One dyad included in the present analyses was excluded from    significant effect of conversation type on rself (ß=.01;
analyses in Paxton and Dale (under revision), due to incomplete     p=.75), suggesting that intrapersonal alignment may be less
data for other analyses.
                                                                1124

sensitive to conversation context than interpersonal
alignment. Increases in time lag again significantly
predicted decreases in rself (ß=-.34; p<.0001), suggesting
that interlocutors were more likely to be moving when
talking and vice-versa. As with unimodal body movement
alignment, the significance of time lag as a main effect
provided evidence for the existence of in-phase synchrony.
The interaction term also reached significance (ß=.09;
p<.05): Although participants exhibited in-phase
multimodal intrapersonal synchrony, individuals’ own body
movements and speech events were more tightly connected
during affiliative conversations.
Network Visualizations of Interaction
To create the network visualizations of interpersonal
interaction, we used body movement (M) and speech (S)
time series data rather than cross-correlation coefficients.
The networks were intended to capture relationships as they
occur in time. We created two independent networks, one
for affiliative interactions and the other for argumentative
interactions (Figure 3). Connection strengths were presented
as beta weights obtained through a series of linear mixed-
effects models.5 All models used condition, conversation
number, and dyad as random effects; the intrapersonal
models (M1:S1 and M2:S2) included participant as an
additional random effect. Models used the nodes as
predictors of other nodes, according to their connections                  Figure 3: Network visualizations for affiliative (top) and
(e.g., predicting M1 with M2).                                            argumentative (bottom) interactions. Colors correspond to
                                                                          those used in Figure 2. Connection strengths are shown as
                            Discussion                                    beta weights obtained from a series of linear mixed-effects
                                                                               models and can be interpreted as effect sizes. All
While we often intuitively acknowledge that conversational                           connections are significant (p<.001).
contexts affect the course of an interaction, our results
suggest that there are fundamental differences in                        context-dependent, although the effects may be quite small
interpersonal dynamics during different contexts. During                 for some elements or in some contexts.
conflict, interpersonal body movement synchrony                             Our findings paint conversation as a highly complex
diminishes. Interlocutors have a more rigid turn-taking                  interpersonal communication structure. While there are
structure with fewer and longer turns. Dyads use fewer                   some relatively stable elements within it (e.g., intrapersonal
instances of any overlapping speech, including events like               multimodal alignment), other elements are very sensitive to
laughter and verbal tracking. Interpersonal multimodal                   conversational contexts (e.g., interpersonal bodily
alignment—when one interlocutor is talking and the other is              synchrony). While complementary behaviors align across
simultaneously moving—drops. Furthermore, in many of                     interactions, argument as a conversation context appears to
these cases, the effect size of conversation type on these               exhibit additional constraints on alignment patterns. Based
measures is quite large, suggesting a very strong impact of              on these exploratory analyses, interpersonal communicative
context on these aspects of interaction.                                 structures appear to be self-organizing within the interaction
   On the other hand, some types of behavior exhibit                     and with strong regard to the overall context.
relatively more stable properties across context.                           The corpus analyzed here provides a rich source of
Interlocutors multimodally synchronize their own speech                  interaction data in multiple conversational contexts. We
and movement, tending to move and speak at the same time                 intend to continue to mine these data in order to better
regardless       of     conversational      contexts.      However,      understand the nature of multimodal communication and
intrapersonal multimodal synchrony can still be affected by              interaction and to collect additional corpora on other
context through interaction effects. We believe this                     conversation contexts. In doing so, we hope to more fully
reinforces a view of interpersonal interaction as inherently             develop the interaction network presented here. Future
                                                                         directions will pursue the creation of more predictive
   5
     The automated speech analysis produces off states frequently,       models of interpersonal (e.g., Mehler, Lücking, & Weiß,
as it prioritizes ignoring non-target speech. This can minimize the      2010) and intrapersonal (e.g., Tilsen, 2009) multimodal
magnitude of the negative correlations, since there are frequent off     alignment that can shape additional experimental work as
states that match in time during an interaction (e.g., pauses).
                                                                     1125

models like the HKB (Haken et al., 1985) have shaped              Kousidis, S., & Dorran, D. (2009). Monitoring convergence
intrapersonal unimodal alignment.                                   of temporal features in spontaneous dialogue speech.
                                                                    Proceedings of the First Young Researchers Workshop on
                   Acknowledgments                                  Speech Technology. Dublin, Ireland.
The authors would like to thank undergraduates J.P.               Krämer, N., Kopp, S., Becker-Asano, C., & Sommer, N.
Gonzales and Stephanie Frewen for their help in data                (2013). Smile and the world will smile with you - The
collection and preparation, respectively. This research was         effects of a virtual agent’s smile on users’ evaluation and
supported partially by NSF grants BCS-0826825 and BCS-              behavior. International Journal of Human-Computer
0926670.                                                            Studies, 71(3), 335–349.
                                                                  Louwerse, M. M., Dale, R., Bard, E. G., & Jeuniaux, P.
                                                                    (2012). Behavior matching in multimodal communication
                        References                                  is synchronized. Cognitive Science, 36(8), 1404–1426.
Baayen, R. H. (2008). Analyzing linguistic data: A practical      McFarland, D. H. (2001). Respiratory markers of
  introduction to statistics using R. Cambridge: Cambridge          conversational interaction. Journal of Speech, Language
  University Press.                                                 and Hearing Research, 44(1), 128-143.
Beek, P. J., Peper, C. E., & Daffertshofer, A. (2002).            Miles, L. K., Griffiths, J. L., Richardson, M. J., & Macrae,
  Modeling rhythmic interlimb coordination: Beyond the              C. N. (2010). Too late to coordinate: Contextual
  Haken–Kelso–Bunz model. Brain and Cognition, 48(1),               influences on behavioral synchrony. European Journal of
  149–165.                                                          Social Psychology, 40(1), 52–60.
Bernieri, F., & Rosenthal, R. (1991). Interpersonal               Miles, L. K., Lumsden, J., Richardson, M. J., & Macrae, C.
  coordination: Behavior matching and interactional                 N. (2011). Do birds of a feather move together? Group
  synchrony. In R. Feldman & B. Rime (Eds.),                        membership and behavioral synchrony. Experimental
  Fundamentals of nonverbal behavior: Studies in emotion            Brain Research, 211(3-4), 495–503.
  and social interaction. New York: Cambridge University          Mehler, A., Lücking, A., & Weiß, P. (2010). A network
  Press.                                                            model of interpersonal alignment in dialog. Entropy,
Brennan, S. E., Galati, A., & Kuhlen, A. K. (2010). Two             12(6), 1440–1483.
  minds, one dialog: Coordinating speaking and                    Norris, S. (2004). Analyzing multimodal interaction: A
  understanding. In B. H. Ross (Ed.), The psychology of             methodological framework. New York: Routledge.
  learning. Burlington: Academic Press.                           Paxton, A., & Dale, R. (in press). Frame-differencing
Chartrand, T. L., & Bargh, J. A. (1999). The chameleon              methods for measuring bodily synchrony in conversation.
  effect: The perception–behavior link and social                   Behavior Research Methods.
  interaction. Journal of Personality and Social Psychology,      Paxton, A., & Dale, R. (under revision). Argument disrupts
  76(6), 893–910.                                                   interpersonal alignment.
Cleland, A. A., & Pickering, M. J. (2003). The use of lexical     Reitter, D., Moore, J. D., & Keller, F. (2006). Priming of
  and syntactic information in language production:                 syntactic rules in task-oriented dialogue and spontaneous
  Evidence from the priming of noun-phrase structure.               conversation. Proceedings of the Conference of the
  Journal of Memory and Language, 49(2), 214–230.                   Cognitive Science Society (pp. 685–690). Vancouver,
Condon, W. S., & Ogston, W. D. (1966). Sound film                   Canada.
  analysis of normal and pathological behavior patterns.          Riley, M. A., Richardson, M. J., Shockley, K., &
  Journal of Nervous and Mental Disease, 143(3), 1–10.              Ramenzoni, V. C. (2011). Interpersonal synergies.
Delaherche, E., & Chetouani, M. (2010). Multimodal                  Frontiers in Psychology, 2, 38.
  coordination: Exploring relevant features and measures.         Richardson, M. J., Marsh, K. L., Isenhower, R. W.,
  Proceedings of the Second International Workshop on               Goodman, J. R. L., & Schmidt, R. C. (2007). Rocking
  Social Signal Processing (pp. 47–52). ACM.                        together: Dynamics of intentional and unintentional
Garrod, S., & Pickering, M. J. (2004). Why is conversation          interpersonal coordination. Human Movement Science,
  so easy? Trends in Cognitive Sciences, 8(1), 8–11.                26(6), 867–891.
Grammer, K., Honda, M., Jüette, A., & Schmitt, A. (1999).         Sebanz, N., Bekkering, H., & Knoblich, G. (2006). Joint
  Fuzziness of nonverbal courtship communication                    action: bodies and minds moving together. Trends in
  unblurred by motion energy detection. Journal of                  Cognitive Sciences, 10(2), 70–76.
  Personality and Social Psychology, 77(3), 487–508.              Shockley, K., Richardson, D. C., & Dale, R. (2009).
Haken, H., Kelso, J. S., & Bunz, H. (1985). A theoretical           Conversation and coordinative structures. Topics in
  model of phase transitions in human hand                          Cognitive Science, 1(2), 305–319.
  movements. Biological Cybernetics, 51(5), 347-356.              Tilsen, S. (2009). Multitimescale dynamical interactions
Keith, T. Z. (2005). Multiple regression and beyond.                between speech rhythm and gesture. Cognitive Science,
  Boston: Pearson Education.                                        33(5), 839–879.
Kopp, S. (2010). Social resonance and embodied
  coordination in face-to-face conversation with artificial
  interlocutors. Speech Communication, 52(6), 587–597.
                                                              1126

