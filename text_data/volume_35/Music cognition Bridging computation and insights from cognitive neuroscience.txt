UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Music cognition: Bridging computation and insights from cognitive neuroscience
Permalink
https://escholarship.org/uc/item/43p6n082
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Pearce, Marcus
Rohrmeier, Martin
Toiviainen, Petri
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

    Music cognition: Bridging computation and insights from cognitive neuroscience
   Marcus Pearce (marcus.pearce@eecs.qmul.ac.uk)                             Martin Rohrmeier (mr1@mit.edu)
 Centre for Digital Music and Research Centre in Psychology,       MIT Intelligence Initiative, Department of Linguistics and
       Queen Mary, University of London, E1 4NS, UK.                   Philosophy, Massachusetts Institute of Technology,
                                                                                       Cambridge, MA, USA
        Psyche Loui (ploui@bidmc.harvard.edu)                               Edward Large (large@ccs.fau.edu)
           Beth Israel Deaconess Medical Center and                           Ji Chul Kim (kim@ccs.fau.edu)
          Harvard Medical School, Boston, MA, USA.                       Center for Complex Systems & Brain Sciences
                                                                                    Florida Atlantic University
        Petri Toiviainen (petri.toiviainen@jyu.fi)                    Elvira Brattico (brattico@mappi.helsinki.fi)
                University of Jyväskylä, Finland                                     Aalto University, Finland
   Keywords: Music cognition; cognitive neuroscience;                      Petri Toiviainen and Elvira Brattico
   computational modelling; processing; prediction; grammar
                                                                    Decoding the musical brain during naturalistic
                    Goals and Scope                                                           listening
   In recent years, computational models have become an               Encoding, or prediction of neural activation from
increasingly important part both of cognitive science and          stimulus, is a common modeling approach in neuroscience.
cognitive neuroscience. In tandem with these developments          In our recent neuroimaging study, we applied encoding to
neuroscientific and cognitive investigations of musical            predict brain activity during listening to different pieces of
experience and behaviour have been gathering pace. In this         music from an extensive set of musical features
context, music cognition constitutes a rich and challenging        computationally extracted from the pieces, and found
area of cognitive science in which the processing of               widespread brain activation, including auditory, limbic, and
complex, multi-dimensional temporal sequences can be               motor areas (Alluri et al., Neuroimage, under review). With
studied without interference of meaning or semantics (see          such complex and distributed neural activation, evaluation
Pearce & Rohrmeier, 2012, for a review). Because of its            of different encoding models is not straightforward, because
complexity and well-defined problem-space, computational           the goodness of prediction is difficult to assess. Decoding,
modelling of music witnessed a rapid growth of successful          or prediction of physical or perceived stimulus features from
higher-order modelling approaches. This workshop                   the observed neural activation, has the potential benefit of a
investigates computational modelling as a bridge between           more straightforward model evaluation because of easier
cognition and the brain, with a focus on understanding the         performance characterization in terms of, for instance,
psychological mechanisms involved in perceiving and                correct classification rate.
producing music.                                                             In a series of experiments, our participants were
   Many approaches have been taken to modelling the large          measured with functional magnetic resonance imaging
variety of different cognitive processes involved in music         (fMRI) while they were listening to three different musical
perception and creation involving various modules of basic         pieces. Subsequently, musical features were computationally
structural processing, statistical learning, memory, as well as    extracted from the pieces, and continuous emotion ratings
motor, emotional and social cognitive processes. Recent            were collected from the participants. For decoding, the
computational models range from hierarchical, rule-based           fMRI data were subjected to dimensionality reduction via
systems for representing harmonic movement inspired by             voxel selection and spatial subspace projection, and the
probabilistic grammars for language, through oscillator            obtained projections were subsequently regressed against
based network models for modelling metrical and tonal              the musical features or the emotion ratings. To avoid
perception, to probabilistic methods derived from machine          overfitting, cross-validation was utilized. Different voxel
learning for modelling dynamic learning and predictive             selection criteria and subspace projection dimensionalities
processing of style-specific musical structure. Turning to         were used to find optimal prediction accuracy. The decoding
cognitive neuroscience, recent years have seen increasing          results and the challenges of the approach will be discussed
interest in advanced computational modelling of EEG and            at the symposium.
fMRI data used to distinguish brain regions responsible for
the processing of different aspects of music (e.g., rhythm,                                Psyche Loui
pitch, timbre, harmony) and the functional connectivity
between them. The purpose of this symposium is to bring               Behavioral and DTI Studies on Normal and
together and display current research trends towards a                  Impaired Learning of Musical Structure
synthesis of these two research areas linking the parameters          One of the central questions of cognitive science concerns
and subcomponents of cognitive models of musical                   how humans acquire knowledge from exposure to stimuli in
processing to functional and anatomical properties of the          the environment. In the context of music, knowledge
brain.
                                                                99

includes the structure of harmony and melody that govern          structural parsing and implicit learning to deal with these
how musical pitches are combined. While people of all             syntactic features. This talk presents the picture emerging
cultures and ages show some knowledge of the structure of         from converging evidence of theoretical approaches, recent
their music, people with tone-deafness (also known as             experimental work and computational modeling.
congenital amusia) show a lack of behavioral sensitivity to       Probabilistic models of musical syntactic processing based
harmony and melody. Here we combine behavioral evidence           on Hidden Markov Models and probabilistic context-free
from subjective ratings, neuroimaging evidence from               grammars underpin that the inference of complex nonlocal
Diffusion Tensor Imaging, and neuropsychological evidence         dependencies from mere exposure is plausible. They further
from tone-deaf individuals, to support the thesis that much       predict experimental data of musical tension and expectancy
of what we know and love about music is acquired via              showing that a variety of features of musical experience can
statistical sensitivity to the frequency and probability of       be modeled by such approaches.
occurrence of events in the auditory environment. This
statistical learning mechanism relies on intact white matter                            Marcus Pearce
connectivity between temporal and frontal lobe regions, and
may subserve multiple auditory-motor functions including           Expectation and Emotion in Music Perception:
language as well as music.                                               Computational Modeling of Dynamic
                                                                             Cognitive and Neural Processes
           Edward Large and Ji Chul Kim
                                                                  The idea that aesthetic experience of music is dependent on
          A Universal 'Grammar' for Music                         the confirmation and violation of expectation dates back at
   Since antiquity, science has asked whether mathematical        least to Hanslick. Meyer (1957) further proposed that such
relationships among acoustic frequencies govern the               expectations depend on probabilistic models of musical
perception of musical relationships. Modern psycho-               structure, acquired through exposure. However, until
physicists rejected this approach, citing evidence that the       recently such theories remained largely untested. Here we
auditory system performs a linear analysis of sound.              present evidence corroborating these proposals and filling in
Cognitive psychologists have since relied primarily on            some of the details in terms of cognitive and neural
statistical learning to explain music cognition, despite          processing. First, we show that musical expectations elicited
continued demonstrations of the importance of frequency           in a range of musical styles result reflect probabilities
relationships. Today evidence is rapidly mounting that the        acquired through a process of statistical learning. Subjective
auditory system is highly nonlinear, inviting reevaluation of     expectedness and uncertainty can be modeled dynamically
the role of frequency in constraining in the perception of        through time using the information-theoretic concepts of
music. Here, we present a dynamical systems analysis of           information content and Shannon entropy respectively.
auditory nonlinearities that predicts substantive universals      Second, we identify time-locked electrophysiological brain
in music perception and cognition. This approach explains         responses to events differing in information content. Third,
perceptual ratings of Hindustani raga not only by encultured      we show that variations in information content lead to
listeners, but also by listeners who were completely              distinct psychological and physiological emotional
unfamiliar with the music of North India. This evidence           responses elicited in a live concert of music for solo flute.
suggests that universal properties of neural oscillation          The results also indicate that expectations and emotion are
explain cross-cultural invariants in the perception of tonal      influenced by factors other than the musical structure such
music, implying neurodynamic constraints on the                   as visual aspects of the performance. In summary this
acquisition of musical languages.                                 research suggests that musical expectations rely on dynamic
                                                                  probabilistic cognitive processing of musical structure,
                    Martin Rohrmeier                              supported by corresponding neural processes, and generates
                                                                  characteristic physiological and psychological emotional
     Computational Models of Musical Syntax                       responses.
   In order to create the variety of our rich musical
experience, Western music employs a complex combination                                  Moderators:
of interwoven features of pitch, rhythm, metrical structure,            Marcus Pearce and Martin Rohrmeier
harmony and melody. Various computational models of
music processing are based on local (event-to-event)
processing of musical features (cf. Rohrmeier & Koelsch,                                  References
2012). On the other hand, a number of theoretical                 Pearce, M. T. & Rohrmeier, M. (2012). Music cognition and
approaches suggest that music involves recursive,                    the cognitive sciences. TopiCS in Cognitive Science, 4,
hierarchical structures organized in ways similar to                 468-484.
linguistic syntax. Further recent neurocognitive research         Meyer, L. B. (1957). Meaning in music and information
provides evidence indicating that musicians as well as               theory. Journal of Aesthetics and Art Criticism, 412-424.
nonmusicians are sensitive to subtle long-distance violations     Rohrmeier, M., Koelsch, S. (2012). Predictive information
resulting from the underlying syntactic structure. These             processing in music cognition. A critical review.
insights suggest that musical processing is more complex             International Journal of Psychophysiology, 83 (2),
than previously assumed and involves rich mechanisms of              164-175.
                                                              100

