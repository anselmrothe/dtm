UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Moving from Levels &amp; Reduction to Dimensions &amp; Constraints
Permalink
https://escholarship.org/uc/item/8qn6z6sv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Danks, David
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   Moving from Levels & Reduction to Dimensions & Constraints
                                                 David Danks (ddanks@cmu.edu)
                               Department of Philosophy, 135 Baker Hall, Carnegie Mellon University
                                                       Pittsburgh, PA 15213 USA
                              Abstract                                 input and output of the process. Finally, the
   Arguments, claims, and discussions about the “level of
                                                                       implementational level describes the physical realization of
   description” of a theory are ubiquitous in cognitive science.       the representation and the algorithm.
   Such talk is typically expressed more precisely in terms of the        Roughly speaking, the computational level specifies what
   granularity of the theory, or in terms of Marr’s (1982) three       problem is being (appropriately) solved; the algorithmic
   levels (computational, algorithmic, and implementation). I          level explains how it is solved; and the implementational
   argue that these ways of understanding levels of description        level gives the details of the physical substrate that does the
   are insufficient to capture the range of different types of         solving. As a concrete (non-cognitive) example, we can
   theoretical commitments that one can have in cognitive
   science. When we understand these commitments as points in          understand a word-processing program as (i) a process for
   a multi-dimensional space, we find that we must also                entering, editing, and rendering text documents (the
   reconsider our understanding of intertheoretic relations. In        computational level); (ii) a bunch of lines of code that
   particular, we should understand cognitive theories as              produce the appropriate behavior (the algorithmic level); or
   constraining one another, rather than reducing to one another.      (iii) changes of 1’s and 0’s in the internal memory registers
   Keywords: Level of description; Marr; Philosophy of                 of the computer (the implementational level).
   cognitive science; Reduction; Intertheoretic constraint                As a more cognitive example, consider the problem of
                                                                       learning causal structure from observational data (e.g.,
                    Limitations of Levels                              Cheng, 1997; Griffiths & Tenenbaum, 2005). A
                                                                       computational-level model of this problem would
It is customary within science to talk about our theories as
                                                                       characterize the relevant inputs (case-by-case observations
falling at different “levels of description”: biology is at a
                                                                       or a summary of a sequence of such cases), the output that
higher level of description than chemistry, which is itself at
a higher level than physics. Moreover, talk of levels is not           should result given such input (a representation that can be
restricted to the relationships between these large-scale              used for causal inference, decision-making, explanation,
                                                                       etc.), and any relevant cognitive constraints (though in
domains of science; a sub-symbolic model of causal
                                                                       practice, computational-level models rarely incorporate such
cognition can be said to be at a lower level of description
                                                                       constraints). An algorithmic-level model would characterize
than some symbolic model of the same cognition or
                                                                       the internal representations and cognitive processes by
behavior.
                                                                       which we humans happen to solve this challenge. And an
   “Levels talk” is particularly widespread in the cognitive
                                                                       implementation-level model would show how the relevant
sciences (as noted by many authors, such as Bechtel, 1994;
Bickle, 1998; Marr, 1982). The proliferation of talk about             computations are performed in particular brain regions (e.g.,
levels is quite unsurprising, given the many different                 frontal cortex as suggested by Fletcher, et al., 2001 or
                                                                       Satpute, et al., 2005).
methodologies used to develop theories of human behavior
                                                                          Marr’s three levels were a significant advance in part
and cognition. At the same time, exactly what is meant by a
                                                                       because they are based on the recognition that the
“level” is often left somewhat vague. Levels of description
                                                                       mathematical or computational specification of a cognitive
are sometimes identified with the ontological granularity of
                                                                       theory significantly underdetermines the commitments that
a theory, where its level is determined (largely) by its
                                                                       are implied by it. A Bayesian model of causal learning
objects. This characterization misses important distinctions,
however, such as the difference between a rational analysis            could, for example, be at the computational or algorithmic
that says how one should act, and a process model that                 level, depending on the intended interpretation of the terms
                                                                       in the model. Moreover, these differences in interpretation
describes the cognitive mechanisms generating behavior.
                                                                       (and so commitments) can matter: whether some experiment
   One of the most precise characterization of levels in
                                                                       or behavioral measure is a test of a model depends in part on
cognitive science—and certainly the most influential such
                                                                       the commitments of that model.
characterization—was given by Marr (1982), and captured
                                                                          Marr’s levels were also intended to help show that there
this key distinction. Marr’s three levels characterize
                                                                       can be distinct models of the same phenomenon that are not
information-processing devices in general, and processes in
the human mind more specifically. The computational level              competitors. That is, models M1 and M2 can be incompatible
identifies the input and output of the process, as well as             (whether mathematically or ontologically) and yet both be
                                                                       correct as long as they are at different levels. For example,
constraints on the types of computation done on the input to
                                                                       Bayesian and associationist models of causal learning are
get the output. The algorithmic level (also called the
                                                                       mathematically       incompatible—they       posit     different
representation level) specifies an implementation of the
                                                                       representations and different learning processes—but can
computational theory, as well as the representation of the
                                                                   2124

both be correct if one is at the computational level and the      cognitive model of an individual being asked to add two
other is at the algorithmic level (Danks, Griffiths, &            plus two, and then responding with four. A completely
Tenenbaum, 2003; Griffiths & Tenenbaum, 2005).                    minimal realist commitment for such a model would be to
  Unfortunately, Marr’s levels suffer from at least two           regard it instrumentally: one could commit only to the
significant flaws. First, and more importantly, they assume       model offering a correct characterization of the input-output
that multiple distinct aspects of theoretical commitment          function for human addition. A substantially more realist
must vary together, rather than being able to vary                commitment would claim that there are internal cognitive
independently (see also McClamrock, 1991). For example,           representations of the numbers ‘2’ and ‘4’, as well as some
suppose model M1 is a standard computational-level model          process by which the former representation (perhaps with a
of human causal learning: it characterizes the relevant inputs    copy) is manipulated so as to yield the latter representation.
and shows which (behavioral) outputs would solve the              This interpretation presupposes that there is really a
causal learning task, all while being agnostic about the          representation there (in a sense discussed below) and that
underlying representations and processes.                         there is some process corresponding to addition.
  Now consider M2 that is mathematically identical to M1,            As we see in this example, simply giving the
but which claims only that people do generate this                mathematical specification of a cognitive theory is
(behavioral) output, not that this behavior is how people         insufficient to determine the realist commitments; those are,
should solve the causal learning task. That is, M2 is a           in an important sense, outside of the scope of the
relatively standard instrumentalist model that characterizes      computational part of the model. At the same time, to fully
the human behavior without explaining precisely how or            understand how to interpret a cognitive model, one needs to
why it is generated. M2 is not a computational-level model,       know what realist commitments to attribute to it. Such
as it does not explain why people act as they do (i.e., one of    specification rarely occurs explicitly for theories in
the putative hallmarks of a computational-level model). At        cognitive science (or at least, rarely in journal papers), but is
the same time, M2 is not an algorithmic-level model, as it        nonetheless an important step. Some information about
does not characterize the underlying representations or           realist commitments can be conveyed implicitly through the
cognitive processes. There thus does not appear to be any         variables in the model, or by asserting that the theory holds
place to put M2 in the standard three Marr levels.                at some level of description. “Levels” of description are,
  More generally, Marr’s three levels force three different       however, much too coarse to convey potentially fine-
dimensions of variation in theoretical commitment—extent          grained metaphysical commitments, at least in the sense of
of realism, tightness of approximation, and (importance of)       stating what things there are held to be in the world.
closeness to optimality (all discussed in the next section)—         This dimension of variation is still under-specified, as it is
to change in lockstep when they can, in practice, vary            not yet clear which epistemological commitments—
relatively independently. This observation points towards         commitments about what we could come to learn or know—
the second concern about Marr’s levels: namely, each of           are implied by attributing “reality” to cognitive
these dimensions has many more than just three levels, as         representations or processes. We can usefully understand
theories can differ (in their commitments) in relatively fine-    epistemological commitments in terms of the predictions
grained ways. Marr’s levels are sometimes helpful for             they license, as prediction is at the core of many epistemic
providing a quick characterization of the commitments of          activities, including control, learning, inference, and even
some theory, if the theory happens to fit one of those            parts of explanation.
templates. But in general, we need a subtler characterization        By looking at constraints on prediction, we see that there
of the types of theoretical commitments we can have for a         are two different types of realist commitments in the
given cognitive model.                                            cognitive sciences—realism about processes, and about
                                                                  representations. A rough characterization of the distinction
    Dimensions of Variation in Commitments                        between representations and processes suffices for capturing
In this section, I consider in more detail these three            realist commitments: representations are the relatively
dimensions of variation in one’s theoretical commitments.         stable, persistent objects that encode information, and
At the end, I show how we can use these dimensions to             processes are dynamic operations involving those objects
better understand how Marr’s levels force these different         that can potentially (but need not) change the state of those
dimensions to vary together, though they should be                objects. That is, representations are whatever encodes
independent in theory (though not always in practice).            information stably over some reasonable timescale, and
                                                                  processes are whatever manipulate that information. This
Realist Commitments (or, What Does It Mean to Be                  high-level characterization covers most of the standard
a Cognitive Realist?)                                             accounts of cognitive representations and processes; even
                                                                  embodied (e.g., Barsalou, 2008) and dynamic systems (e.g.,
The first dimension is arguably the easiest to understand:        Port & van Gelder, 1995) theories of representation (or its
the extent of realism about the theory is simply which parts      apparent absence) fit this general schema, if we focus on the
of the theory are supposed to refer to representations or         structure of the theory rather than the language used to
cognitive processes that “really exist” in a standard             describe it.
metaphysical sense. As a simple example, consider a
                                                              2125

   Given this distinction, representation realism implies              One can make realist commitments about only some of
commitments about the stability of predictions for different        the representations or processes in one’s theory; process and
types of cognition that use the information encoded in that         representation realism are not all-or-nothing affairs. To take
representation. If the representation “really exists,” then the     a concrete example, consider associative models of
same object is presumably used for (potentially) many               contingency (or causal) learning, such as the well-known
purposes, and so predictions in these different contexts            Rescorla-Wagner model (Rescorla & Wagner, 1972). At a
should reflect that shared informational basis. For example,        high level, associative learning models posit that one learns
realism about the concept ‘DOG’ implies that behavior in a          contingencies or correlations (possibly including causal
categorization task involving dogs should be correlated (in         strengths) by updating associative strengths between various
various ways) with performance in a feature inference task          factors. Computationally, whenever one observes a new
involving dogs. More generally, representation realism              case, the cognitive agent (i) uses some of the observed
licenses us to use behavior on one task to make predictions         factors to predict the state of other factors using the
about (likely) behavior on different tasks that use the same        appropriate associative strengths, and then (ii) changes
representations, at least ceteris paribus. Importantly, realism     associative strengths based on the prediction error.
about our cognitive representations does not imply that                Most standard interpretations of associative learning
every one is available for every process; it is certainly           models are realist about the associative strengths, but not
possible that we have multiple representational stores, some        about the predictions “generated” in step (i) in order to
of which are process-specific. But if the same representation       change strengths in step (ii). That is, the former
is supposed to be available to multiple processes, then             representations “really exist” and are encoded somewhere,
representation realism implies a set of epistemological             but the latter are just a computational device. Similarly,
commitments about correlations or stabilities between               most are realist about the update process that changes the
predictions about the behaviors that the different cognitive        associative strengths, but not about the prediction process
processes generate.                                                 that uses some of the associative strengths to predict the
   Process realism similarly implies epistemological                states of other factors.
commitments of inter-prediction correlations and stabilities,
but rather for the same task given different inputs,                Degree of Approximation
backgrounds, or environmental conditions. That is, if one is        A second dimension of variation in the commitments of a
committed to the reality of a given cognitive process, then         cognitive theory is in the intended closeness (to reality) of
that process should be stable and persistent in its                 the theory’s approximations. All theories are approximate in
functioning across a range of inputs and conditions. For            some ways, in that they exclude certain factors or
example, realism about a particular process theory of               possibilities; there is no complete theory that incorporates
concept learning implies that this particular process should        everything. We can nonetheless distinguish (for a particular
be active for a variety of inputs that trigger concept              theory) different commitments about what is supposed to be
learning. Whether I am learning about the concept ‘DOG’ or          captured by that theory. We can think about this dimension
the concept ‘CAT’, the same process should be engaged               as tracking either which factors have been excluded, or the
(since that is the process that is “really there”). Of course,      intended scope of the theory.
process realism does not imply that every process is                   As a concrete example, suppose one has a model of
triggered for every input or in every condition; rather,            human addition that predicts that people will respond ’93’
process realism is the more minimal claim that there should         when asked “what is 76 + 17?” A question thus arises when
be correlations and stabilities between the predictions for         someone responds (erroneously) ‘83’: what does this
the different performances of the same task, ceteris paribus.       behavior imply for the theory? One response is to hold that
   Critically, the epistemological commitments of process           this represents a (partial) falsification of the model, as it
realism and representation realism are separable, at least in       made a prediction that was not borne out. A different
the abstract. One could think that the appropriate predictive       response is to argue that the behavior is due to some factor
correlations obtain within a cognitive task but not between         that was not included in the model because it falls outside of
them (i.e., process realism without representation realism).        the intended scope of the model (e.g., a momentary lapse of
For example, performance on a categorization task                   reason due to distraction). The mathematical or
involving dogs might not imply anything stable for                  computational specification of a theory does not include
predictions about how people do causal inference about              what was (deliberately) omitted, but that information is
dogs. Alternately, the appropriate stabilities might obtain         important when deciding how to respond to an apparent
across tasks for the same information, but not within a task        mismatch between theory and reality.
(i.e., representation realism without process realism). For            This dimension is clearly related to the performance/
example, there might be correlations between predictions            competence distinction, but it is also not identical with it.
for categorization and feature inference tasks involving            Roughly speaking, a competence theory aims to characterize
dogs, but no stable correlations between the predictions for        what people are capable of doing, while a performance
categorization involving dogs and cats.                             theory aims to describe what they actually do. Typically, the
                                                                    former is a theory that aims to explain and predict people’s
                                                                2126

ideal behavior if they did not face, for example, limits on        simply by its mathematical/computational specification.
memory and attention, cognitive processing errors, and             And clearly, variation in this dimension induces different
other deleterious factors. The latter is supposed to be a          metaphysical and epistemological commitments, as claims
theory that accounts for these various factors so as to            that some theory is optimal imply facts about the causal
capture (approximately) actual human behavior in all its           history of the cognition, and about how the cognition should
messy glory. The mathematical specification of a theory            plausibly change under variations in the environment or
does not entail that it is either a performance or competence      learning history.
theory, and some historical debates in the cognitive sciences
occurred precisely because of a misunderstanding about             Connecting the Dimensions and Marr’s Levels
whether (the mathematical specification of) a theory was           Marr’s levels force these three dimensions of variation to
intended as a competence or performance theory.                    change together, rather than allowing them to vary
   The performance vs. competence distinction can be               independently. For example, a theory at the computational
understood as picking out two possible commitments along           level is understood to have a relatively weak set of realist
this dimension of variation (i.e., about the intended scope of     commitments (particularly about processes), significant
a theory). But there are many other intended approximations        approximation (since the theory is about how the system
that one could have in mind, including ones that arise from        should solve a problem, rather than what it actually does),
abstracting away from only some human cognitive                    and a fairly strong expectation of optimality. Theories at the
limitations and peculiarities, rather than all of them (as in      implementational level, in contrast, are strongly realist
competence theories). The performance vs. competence               (since they hopefully focus on the underlying biological
theory distinction marks an important pair of possible             mechanisms), aim to minimize approximation by
intended commitments of a theory, but fails to capture the         incorporating relatively contingent influences, and
full range of possible commitments.                                emphasize causal mechanisms (“how”) rather than
                                                                   optimality (“why”).
Importance of Optimality                                              As a result, one must be careful about using Marr’s levels
The third dimension of variation in a theory’s intended            to characterize a theory. Use of the terminology can force
commitments is in the putative or claimed optimality of the        proponents of a theory into particular commitments that
theory (if any): that is, is the theory additionally claimed to    they would prefer to deny, as the levels bundle together
be optimal (or rational), and if so, for what task(s) and          commitments that should be kept separate. At the same
relative to what competitors? This additional claim is             time, anything that encourages more precise specification of
important because claims about optimality (help to) license        the extra-computational commitments for a theory is a
so-called “why-explanations.” We are often interested not          positive. The overall usefulness of Marr’s levels principally
just in how some behavior occurs (i.e., the underlying             depends on whether the theory’s proponent happens to
representations and processes that actually generate it), but      endorse one of the limited sets of possible commitments that
also in why that behavior occurs.                                  can be expressed in that trichotomy. In many actual cases in
   Actually tracing the causal history (whether ontogenetic        cognitive science, however, we have subtler, more fine-
or phylogenetic) of a process or representation can be             grained variations in our theoretical commitments.
remarkably difficult, if not impossible. An alternative path
to reach a why-explanation is to show that some cognition is                   From Reduction to Constraint
optimal relative to competitors, and that there are                Throughout this discussion, I have largely ignored one of
sufficiently strong pressures on the individual (or lineage) to    the most important uses of levels, whether Marr or
push the individual to the optimal cognition (and that those       otherwise: namely, they provide a framework in which we
pressures actually obtained in these circumstances). If these      can understand intertheoretic relationships. That is, we care
elements can be shown, then we can conclude that the               not only about the commitments of a scientific theory, but
cognition occurs because it is optimal. This alternative path      also about the ways in which theories are related to one
is a standard way to demonstrate, for example, that some           another, and “levels talk” provides an excellent way to
physical trait constitutes an evolutionary adaptation (Rose &      understand such relations.
Lauder, 1996).                                                        Of course, it is possible that there are no such (interesting)
   In practice, many optimality-based “explanations” in the        intertheoretic relations in cognitive science, as implied by
cognitive sciences fail to demonstrate all of the elements; in     various claims that psychology is “autonomous” (or other
particular, they frequently fail to show that there are actual     related term) from the underlying neuroscience (e.g., Fodor,
“selection pressures” that would suffice to drive an               1974, 1997). Proponents of rational analyses often suggest a
individual towards the optimal cognition, or even to               similar sort of disconnect, as they sometimes hold that the
maintain an individual at the optimal cognition.                   rational analysis says nothing about how the behavior is
Nonetheless, the intended closeness to optimality (relative        generated (e.g., Anderson, 1990). There are many
to a class of alternatives) of a theory—and so its ability to      theoretical concerns about the autonomy position (see, e.g.,
function in a possible why-explanation—is a critical               the long list in Bickle, 1998). In addition, it is arguably
theoretical commitment about a model that is not implied           descriptively incorrect: cognitive scientists frequently attend
                                                               2127

to the ways in which their theories matter for one another.             Towards an Account of “Constraint”
Regardless of whether it is logically necessary that there be           At a high level, one cognitive theory S constrains another
interesting intertheoretic relations, it certainly seems to be          theory T if the extent to which S has some theoretical virtue
contingently true that there are such relations.                        V (e.g., truth, predictive accuracy, explanatory power) is
   The more common way to think about intertheoretic                    relevant for the extent to which T has the same theoretical
relations in cognitive science is in terms of reduction:                virtue V. More colloquially, S constrains T just when, if we
roughly, a theory H at a higher level must (eventually,                 care about T along some dimension, then we should also
somehow) “reduce” to a theory L at a lower level. More                  care about S along that same dimension (because S could be
precisely, H reduces to L when the latter is a finer-grained            informative about T). Suppose, for example, that T reduces
version of (something approximately equivalent to) the                  to S. Reductions clearly involve constraint in terms of truth:
former. There are many different ways of explicating                    S and T plausibly have the same truth-value when T reduces
“reduction” with more precision, whether in terms of                    to S. At the same time, reductions arguably do not always
syntactic equivalence (Nagel, 1961); semantic equivalence               involve constraint in terms of explanatory power: the
(Bickle, 1998); similar causal powers (Schaffner, 1967);                explanatory powers of the two theories in a reduction can
replaceability (Churchland, 1985; Hooker, 1981a, 1981b);                vary relatively independently. Thus, it is important to
or even as implementation of a computer program (Danks,                 relativize each application of intertheoretic constraint to a
2008). In all of these cases, there is a close connection, or at        particular theoretical virtue.
least sympathy, between talk of “levels” and the focus on                 To see how a more general notion of “constraint” could
reduction as the key intertheoretic relation.                           be made precise, consider the theoretical virtue of truth. I
   At least two general concerns arise, however, for all of             propose (without argument) that: S truth-constrains T if and
these accounts of “reduction.” First, scientific practice               only if a change in belief in S from time t1 to time t2 would,
(particularly in the cognitive sciences) often does not                 for a fully-knowledgeable agent, rationally produce a
involve definite, positive, theoretical proposals to serve as           change in belief in T from t1 to t2. Note that there is no
the relata of the “reduction” relation. One might claim, for            assumption here that the change in belief in S is rational;
example, that two variables are associated, or that some                rather, this account of ‘constraint’ essentially models it as a
functional relationship falls in some (perhaps large) family,           conditional: “if an individual’s belief in S changes (for
or that some previously considered theoretical possibility is           whatever reason), then belief in T should rationally change
incorrect (but without any further information about which              as well, assuming that she understands the implications of
theoretical possibility actually is right). These different             her beliefs.”
types of theoretical claims can all imply commitments at                  This proposal clearly includes reduction as a special case
other levels even if there is no particular broad theory in             constraint: if H reduces to L given conditions C, then an
which they fit (and so no appropriate relata for reduction).            increase in belief in L&C (alternately, full acceptance of
   Second, and more importantly, “reduction” is always                  L&C) should rationally lead to an increase in belief in (or
understood as a between-level relation: H and L are theories            full acceptance of) H. For example, if some psychological
at different levels about roughly similar phenomena.1                   theory P reduces to some neuroscientific theory N, then if
Intertheoretic relations arise, however, between theories that          we come to believe N, then we should also (rationally)
do not stand in this type of “hierarchical” arrangement. For            believe P. Moreover, in some contexts, a reductive relation
example, theories of causal learning and reasoning (e.g.,               can also lead to a downward constraint: if we come to
Cheng, 1997; Griffiths & Tenenbaum, 2005) and theories of               believe H, then that can rule out certain Ls (i.e., any that H
“causal” concepts (e.g., Rehder, 2003a, 2003b) investigate              cannot reduce to).
different phenomena, and so cannot possibly stand in a                    This account of truth-constraint applies much more
reductive relationship in either direction. Nonetheless, these          broadly than just reduction. For example, causal learning
types of theories clearly constrain one another; at the very            theories and theories of causal concepts that use the same
least, they both depend on representations of causal                    representational framework (e.g., causal Bayesian networks)
structure, and so information about one theory can be                   can be understood as mutually supporting: each makes the
informative about the other. The focus on “levels of                    other more probable. More generally, one regularly finds
description” or Marr’s levels makes it easy to focus on the             arguments in cognitive science that are based on converging
hierarchically structured theories, but they are not the only           evidence from disparate domains, measurement methods, or
ones that constrain one another. Just as we needed a more               processes. In this model of truth-constraints, the theories in
sophisticated understanding of the dimensions of variation              the different domains place symmetric constraints on one
in theoretical commitment, we need a more general account               another: increases (or decreases) in belief in one theory
of intertheoretic constraints.                                          should rationally lead to increases (or decreases) in belief in
                                                                        others that point in the same direction. That is, the broader
   1
     We also sometimes speak of a more general theory “reducing”        intertheoretic relation of “constraint” enables us—in
to a more specific one at the same level in particular conditions       contrast to the more narrowly focused “reduction”—to
(e.g., general relativity reduces to Newtonian dynamics in the limit    explicate and justify one of the most common argumentative
of (v / c)2 → 0). Nickles (1973) shows how to keep this type of         techniques in cognitive science.
reduction separate from the type I have been discussing.
                                                                    2128

                        Conclusions                                  associative learning theory. Nature Neuroscience, 4,
                                                                     1043-1048.
The core idea of this paper is that the commitments that we
                                                                   Fodor, J. A. (1974). Special sciences: Or the disunity of
have about our cognitive theories extend far beyond their
                                                                     science as a working hypothesis. Synthese, 28, 97-115.
mathematical or computational specification. Instead, we
                                                                   Fodor, J. A. (1997). Special sciences: Still autonomous after
must be clear about where we are located in a multi-
                                                                     all these years. Nous, 31, 149-163.
dimensional space of theoretical commitments. Our degree
                                                                   Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and
of realist commitment, permissible degree of approximation,
                                                                     strength in causal induction. Cognitive Psychology, 51,
and intended degree of optimality all can vary relatively
                                                                     334-384.
independently, though they are tightly coupled in the
                                                                   Hooker, C. A. (1981a). Towards a general theory of
traditional Marr levels.
                                                                     reduction, part I: Historical and scientific setting.
   Moreover, we need a more fine-grained notion of
                                                                     Dialogue, 20, 38-59.
intertheoretic relations to complement this more nuanced
                                                                   Hooker, C. A. (1981b). Towards a general theory of
picture of theoretic commitments. Cognitive theories
                                                                     reduction, part II: Identity in reduction. Dialogue, 20,
sometimes reduce to one another, but more commonly they
                                                                     201-236.
inform one another only indirectly. I have suggested that a
                                                                   Marr, D. (1982). Vision. San Francisco: W.H. Freeman.
theory of intertheoretic constraints would be most
                                                                   McClamrock, R. (1991). Marr’s three levels: A re-
appropriate, but have only sketched how such constraints
                                                                     evaluation. Minds & Machines, 1, 185-196.
might look in one particular case. Substantial work remains
                                                                   Nagel, E. (1961). The structure of science: Problems in the
to be done to characterize the ways that theories can relate
                                                                     logic of scientific explanation. New York: Harcourt.
to one another, and then to show how these constraints can
                                                                   Nickles, T. (1973). Two concepts of intertheoretic
be used to guide actual practice in cognitive science.
                                                                     reduction. The Journal of Philosophy, 70, 181-201.
                                                                   Port, R. F., & van Gelder, T. (1995). Mind as motion:
                    Acknowledgments                                  Explorations in the dynamics of cognition. Cambridge,
This work was partially supported by a James S. McDonnell            MA: The MIT Press.
Foundation Scholar Award. An early version of this paper           Rehder, B. (2003a). A causal-model theory of conceptual
was presented at the 2013 Marshall Weinberg Cognitive                representation      and    categorization.     Journal   of
Science Symposium.                                                   Experimental Psychology: Learning, Memory, and
                                                                     Cognition, 29, 1141-1159.
                         References                                Rehder, B. (2003b). Categorization as causal reasoning.
Anderson, J. R. (1990). The adaptive character of thought.           Cognitive Science, 27, 709-748.
   Hillsdale, NJ: Erlbaum.                                         Rescorla, R. A., & Wagner, A. R. (1972). A theory of
Barsalou, L. W. (2008). Grounded cognition. Annual                   Pavlovian conditioning: Variations in the effectiveness of
   Review of Psychology, 59, 617-645.                                reinforcement and nonreinforcement. In A. H. Black &
Bechtel, W. (1994). Levels of description and explanation in         W. F. Prokasy (Eds.), Classical conditioning II: Current
   cognitive science. Minds & Machines, 4, 1-25.                     research and theory. New York: Appleton-Century-
Bickle, J. (1998). Psychoneural reduction: The new wave.             Crofts.
   Cambridge, MA: The MIT Press.                                   Rose, M. R., & Lauder, G. V. (Eds.). (1996). Adaptation.
Cheng, P. W. (1997). From covariation to causation: A                San Diego: Academic Press.
   causal power theory. Psychological Review, 104, 367-            Satpute, A. B., Fenker, D. B., Waldmann, M. R., Tabibnia,
   405.                                                              G., Holyoak, K. J. & Lieberman, M. D. (2005). An fMRI
Churchland, P. M. (1985). Reduction, qualia, and the direct          study of causal judgments. European Journal of
   introspection of brain states. Journal of Philosophy, 82, 1-      Neuroscience, 22, 1233-1238.
   22.                                                             Schaffner, K. (1967). Approaches to reduction. Philosophy
Danks, D. (2008). Rational analyses, instrumentalism, and            of Science, 34, 137-147.
   implementations. In N. Chater & M. Oaksford (Eds.), The
   probabilistic mind: Prospects for Bayesian cognitive
   science. Oxford: Oxford University Press.
Danks, D., Griffiths, T. L., & Tenenbaum, J. B. (2003).
   Dynamical causal learning. In S. Becker, S. Thrun, & K.
   Obermayer (Eds.), Advances in neural information
   processing systems 15. Cambridge, MA: MIT Press.
Fletcher, P. C., Anderson, J. M., Shanks, D. R., Honey, R.
   A. E., Carpenter, T. A., Donovan, T., Papadakis, N. &
   Bullmore, E. T. (2001). Responses of human frontal
   cortex to surprising events are predicted by formal
                                                               2129

