UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Constraining ACT-R Models of Decision Strategies: An Experimental Paradigm
Permalink
https://escholarship.org/uc/item/5027x4cf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Dimov, Cvetomir
Marewski, Julian
Schooler, Lael
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

    Constraining ACT-R Models of Decision Strategies: An Experimental Paradigm
      Cvetomir M. Dimov (cvetomir.dimov@unil.ch) and Julian N. Marewski (julian.marewski@unil.ch)
                                  Department of Organizational Behavior, Université de Lausanne,
                              Quartier UNIL-Dorigny, Bâtiment Internef, 1015 Lausanne, Switzerland
                                      Lael J. Schooler (schooler@mpib-berlin.mpg.de)
                                   Max Planck Institute for Human Development, Lentzeallee 94
                                                        14195 Berlin, Germany
                             Abstract                                    Yet, surprisingly there are relatively few theories of
                                                                      decision making that yield detailed quantitative predictions
  It has been repeatedly debated which strategies people rely on
  in inference. These debates have been difficult to resolve,         about process data. Instead, typically qualitative predictions
  partially because hypotheses about the decision processes           about response times and other process data are tested in
  assumed by these strategies have typically been formulated          experiments. This theoretical and methodological weakness
  qualitatively, making it hard to test precise quantitative          contributes to fuelling important scholarly debates about
  predictions about response times and other behavioral data.         which decisional processes describe behavior best: simple
  One way to increase the precision of strategies is to               non-compensatory ones, for which decisions based on some
  implement them in cognitive architectures such as ACT-R.
  Often, however, a given strategy can be implemented in
                                                                      predictors cannot be overturned by others, or complex
  several ways, with each implementation yielding different           compensatory integration processes, for which various
  behavioral predictions. We present and report a study with an       predictors can neutralize each-other’s influence (cf. Bröder
  experimental paradigm that can help to identify the correct         & Schiffer, 2003; Glöckner & Betsch, 2008; Marewski et
  implementations of classic compensatory and non-                    al., 2010).
  compensatory strategies such as the take-the-best and tallying         One way to increase the precision of theories of decision
  heuristics, and the weighted-linear model.                          making is to implement them in detailed cognitive
   Keywords: Take-the-best, tallying, weighted-linear model,          architectures such as the ACT-R theory of cognition (e.g.,
   process models, ACT-R                                              Anderson, 2007). ACT-R is a quantitative framework that
                                                                      applies to a broad array of behaviors and tasks, formally
                         Introduction                                 integrating theories of memory, perception, action, and
One important characteristic of well-developed scientific             other aspects of cognition. ACT-R also allows modeling
theories is precision. In psychology, theoretical precision           decision processes. When models of decision making are
can be achieved by complementing verbally formulated                  implemented in ACT-R, quantitative predictions about
theories with formal models. Typically, formal models are             response time distributions at the millisecond level and
specified in terms of mathematical equations or computer              other process data can be made and compared to
code. The goals, level of detail, and level of description of         experimental studies. Marewski and Mehlhorn (2011), for
such models vary as a function of the psychological                   instance, implemented several compensatory and non-
subdiscipline, research questions being asked, or the                 compensatory decision strategies in ACT-R. In doing so,
available technology, to name only a few factors.                     they modeled for each of the strategies how decisional
Computational models have become both increasingly                    processes interplay with memory, perceptual, and motor
popular and powerful, and have aided cognitive scientists in          processes, which, in turn, allowed them to quantitatively
their endeavor to shed light into the behaviorist’s black box.        predict the response time distributions associated with using
Computer models allow one to specify, on an algorithmic               each strategy in a simple two-alternative forced choice
level, the cognitive processes psychological mechanisms are           decision task.
assumed to draw on.                                                      While the architectural approach can thus help remedying
   Such process models predict not only what decision a               the aforementioned theoretical and methodological
person will make, but also how the information used to                weakness, this approach does not come without its
make the decision will be processed. The predictions made             complications. Specifically, often a given strategy can be
by these models can thus be tested not only on outcome data           implemented in numerous different ways in ACT-R (or
(e.g., what item is chosen) but also on process data,                 other cognitive architectures), with each implementation
including on patterns of information search, response times,          yielding different response time and other process
or neural activation. Such predictions can eventually                 predictions. Part of the problem is that many decision
differentiate among competing theories that make identical            strategies are—in the worst case—only formulated verbally
outcome predictions. In particular in the cognitive and               or—in the best case—specified mathematically or
decision sciences, describing cognitive processes represents          algorithmically, without spelling out the strategies’
a central goal of theorizing on its own. In fact, the past            assumptions about lower-level cognitive processes. This
decades have seen repeated calls to develop process models.           specification problem (see Lewandowsky, 1993), namely
                                                                 2201

how to translate an underspecified theory or strategy into a        alternative is called the alternative’s cue profile. TTB bases
detailed cognitive model, poses a paramount modeling                inferences on just one good cue. Specifically, TTB orders
challenge to the researcher who sets out to find out which          the cues i unconditionally according to their validity vi, with
implementation is the most adequate one. To illustrate this                              , ci being the number of correct inferences
point, Marewski and Mehlhorn (2011) actually ended up               based on cue i given that it discriminates between two
implementing over thirty ACT-R models of similar decision           alternatives (i.e., cue values are 1 & 0, respectively, or 1 & -
strategies without being able to make strong conclusions            1, respectively), and wi the number of incorrect inferences.
about which model most likely represented the correct one.          TTB’s rules for searching cues, stopping search, and making
   In this paper, we present and report a study with an             a decision can be summarized as follows:
experimental paradigm that can help to build and identify              Search: Search through cues in the order of their validity.
the correct implementations of decision strategies. In what            Stopping: Stop as soon as a cue is found that
we call the train-to-constrain-paradigm, participants are              discriminates between the alternatives.
instructed in a detailed step-by-step procedure how to apply           Decision: Infer that the alternative with the positive cue
specific strategies in a decision task. Since the experimenter         value has the higher value on the criterion of interest.
thus knows which strategies participants have relied on in          As can be seen, TTB is a non-compensatory strategy, which
the experiment, the resulting response times lend themselves        uses solely the first discriminating cue. Translated into a
to constraining ACT-R implementations of these strategies.          process prediction this implies, for example, that the time it
Specifically, as an initial step, here we focus on a variant of     takes to make decisions with TTB should depend on how
that paradigm in which participants are instructed to apply         many cues have been considered before a discriminating cue
three classic compensatory and non-compensatory                     is found.
strategies, namely the take-the-best (henceforth: TTB) and
tallying heuristics, and the weighted-linear model
(henceforth: WLM).
   The remainder of this paper is structured as follows. First,
we will explain in more detail the three decision strategies.
Second, we will present the train-to-constrain-paradigm and,
in doing so, report a study that we ran using that paradigm.
Third, we will report the results of this study, and, fourth,
briefly illustrate how these results can be used to build and
constrain ACT-R implementations of the three strategies.
                                                                        Figure 1: Illustration of the memory-based decision task
Decision Strategies
Tallying and WLM have been formulated in different ways             Tallying. In contrast to TTB and other non-compensatory
(and at times also been given different names); here we use         strategies, many decision models posit that people evaluate
Gigerenzer and Goldstein’s (1996) definitions as well as            alternatives by integrating knowledge about multiple cues.
their TTB heuristic. Gigerenzer and Goldstein specified             One such heuristic is tallying. This representative of classic
these strategies as models of inductive inference about             unit-weight linear integration models (e.g., Dawes, 1979)
unknown quantities or future events in simple two-                  simplifies decisions by treating all cues equally. For each
alternative forced choice tasks. In such tasks, a person has to     alternative, tallying simply counts the cues with positive
infer which of two alternatives (e.g., cities) has a larger         values and infers that alternatives with the larger number of
value on a given criterion (e.g., population). One variant of       positive cue values score higher on the criterion of interest.
this task that has received considerable attention during the       As a consequence, the various cues can neutralize each
past years is the memory-based decision task illustrated in         other’s influence on the final decision, thus making tallying
Figure 1. In this task, a person has to make inferences by          a compensatory model. Tallying’s search, stopping, and
relying exclusively on the contents of their memory. The            decision rules read as follows:
experimental paradigm for identifying correct ACT-R                    Search: Search through cues in any order.
implementations of TTB, tallying, and the WLM that we                  Stopping: Stop search after m out of a total of M cues
propose here extends this memory-based task.                           (with 1 < m < M) have been accessed.
                                                                       Decision: Decide for the alternative that is favored by
Take-the-best. The simple TTB heuristic stands in the                  more positive cue values. If the number of positive cue
tradition of Tversky’s (1972) classic elimination by aspects           values is the same for both alternatives, guess.
model. TTB bases inferences on the attributes of the
alternatives (e.g., whether a city has an airport), which it        Weighted-linear model. The WLM is similar to tallying in
uses as cues. A cue can have a positive (e.g., a city has an        that it integrates all the information available when choosing
airport, coded as “1”), negative (has no airport, coded as “-       an alternative. In the WLM, cue values are coded like in
1”), or an unknown (coded as “0”) value. The vector of cue          TTB. As suggested by its name however, it integrates all
values that define a person’s knowledge about a specific            cue information by multiplying the cue values by their
                                                                    validities and summing them over for each city, thus
                                                                2202

computing the weighted sum of the cues for each city. The           and, indeed, also none found. These 16 cities were
WLM’s rules can be summarized as follows:                           combined with 8 cue profiles, illustrated in Table 1. In
   Search: Search through cues in any order.                        doing so, each of the 8 cue profiles was used twice—albeit
   Stopping: Stop search after m out of a total of M cues           with different city names.
   (with 1 < m < M) have been accessed. Multiply each cue
   value with its validity and compute the weighted sum of                              Table 1: Cue profiles used
   cues for each alternative.
   Decision: Decide for the alternative that is favored by the
                                                                                  City1 City2   City3 City4  City5  City6 City7  City8
   larger weighted sum. If the weighted sum is the same for
                                                                      Airport       +     +       -     -      +      +     -      -
   both alternatives, guess.
The WLM has a long tradition in the cognitive and decision          Soccer team     -     -       -     -      -      -     +      +
sciences and beyond. For instance, variants of this model            University     -     -       +     +      +      +     +      +
have been viewed as optimal rules for preferential choice           Train station   +     -       +     -      +      -     +      -
and are often considered to define rational behavior (cf.
Payne, Bettman, & Johnson, 1993).
                                                                    Learning task. The experiment started with a learning task
                                                                    (cf. Bröder & Schiffer, 2003), in which subjects were taught
                Experimental Paradigm                               the 4 cues about the 16 British cities, corresponding to a
The train-to-constrain-paradigm builds on several earlier           total of                  facts. Specifically, during learning,
studies on TTB, tallying, and the WLM (e.g., Bröder &               cities and cues were presented repeatedly in a random order
Gaissmaier, 2007; Bröder & Schiffer, 2003; Mata, Schooler           until subjects correctly recalled at least 14 of the 16 cities’
& Rieskamp, 2007) and on approaches that teach subjects to          cue profiles perfectly. Cue profiles were assigned at random
rely on specific decision strategies (e.g., Khader et al., 2011;    to specific cities.
Marewski & Schooler, 2011).
     In our study, we implemented the training portion of our       Strategy learning task. After having learned all cues, in
paradigm in a computerized experiment, in which subjects            each of the three between-subjects conditions, subjects were
were told that they would participate in a quiz show. In that       trained how to use one of three decision strategies. The
show, they first learned fictitious facts about how British         strategy learning procedure required subjects to go through
cities would look like in the future, namely whether these          a stepwise explanation of the decision process assumed by
cities would have an international airport, a train station, a      each strategy as well as to apply that strategy correctly on
university, and/or a premier league soccer team in the year         several practice trials that mimic the actual decision task.
2100 (such facts are typically judged as useful for inferring       During practice, subjects received feedback about whether
city size; cf. Pachur, Bröder, & Marewski, 2008). In a              they had applied the strategy correctly, and the strategy was
second step, subjects learned how to employ a strategy that         practiced until subjects’ decisions concurred to 100% with
uses these facts as cues to make decisions. During the actual       the strategy’s predictions. During the strategy learning task,
quiz show, they then saw pairs of cities on the computer            subjects also memorized additional information that is
screen and were instructed to always use the strategy to            necessary for applying the strategy, such as the cue
infer which of the two cities would be larger in the year           validities in the case of TTB and WLM. The instructions on
2100. Subjects were paid according to the degree to which           how to use each strategy were crafted such that they reflect
their decisions agreed with predictions of the respective           the strategy descriptions from the literature.
decision strategy.
                                                                    Repetition of learning task. To make sure participants still
Subjects and design. A total of 141 subjects participated in        remembered the 64 facts correctly, one round of the learning
the experiment (89 male, Mage = 25.3), of which 120                 task was repeated upon completion of the strategy learning
finished it successfully. Subjects were randomly assigned to        task.
one of three between-subjects conditions. The conditions
differed in terms of the strategy participants learned to use.      Decision task. In a decision task, 72 pairs of the previously
In the first condition subjects learned TTB, in the other two       learned British cities were presented (one city on the left
conditions they learned tallying and the WLM, respectively.         side of the computer screen, the other one on the right; see
                                                                    Figure 1). To avoid inducing frequency effects, the pairs
Materials. Sixteen well-known British cities were used as           were constructed such that each city name appears equally
alternatives. These cities correspond to those that most            often. Subjects were instructed to always apply the strategy
subjects in Pachur et al.’s (2008) pre-study 1 recognized. A        to decide which of the cities will be larger in the year 2100.
pre-study suggested that subjects’ familiarity with these           For each correct application of the strategy, subjects
cities’ names aids them to learn a large number of facts            received a bonus payment of 0.5 Euros (0.68 US$). Each
about these cities. Since the degree of familiarity was             decision inconsistent with the strategy’s prediction resulted
roughly the same for all cities in both Pachur et al.’s pre-        in a penalty of 0.5 Euros (no feedback was given).
studies, no interference effects of familiarity were expected,
                                                                2203

Cue-memory task. In a cue-memory task, subjects had to                Third, WLM participants are the slowest, which is a result
reproduce the cue values they learned for the cities. The          that is consistent with Bröder and Gaissmaier’s (2007)
purpose of this task was to collect data about how well            earlier studies. Bröder and Gaissmaier reported mean
subjects remembered the cue values they were taught. This          response times between 10s and 11s in their first and
data will be used in future projects to populate the               between 15s and 23s in their second experiment, which fall
declarative memory of the ACT-R models.                            close to the time range of our participants.
                                                                       Fourth, as can be seen in Figure 2a, TTB participants’
                  Experimental Results                             response times increase as a function of most valid
Figure 2 shows the mean of the 25th, 50th and 75th response        discriminating cue. In contrast, Figures 2b and 2c show that
time percentiles for the three experimental conditions as a        for tallying and the WLM the response times do not exhibit
function of the number of cues that have to be retrieved           such an increase when they are analyzed in the same way as
from memory prior to finding the most valid discriminating         for TTB participants. This result is to a large extent
one (henceforth: most valid discriminating cue). Several           consistent with earlier work: in Bröder and Gaissmaier’s
important observations can be made. First, tallying                (2007) experiments, participants who were inferred to have
participants made the fastest decisions. Their response time       relied on TTB exhibited strong increases in mean response
varied from under 3s for the 25th percentile to almost 6s for      times as a function of the most valid discriminating cue,
the 75th percentile. This is much faster than previous             while those who were classified as likely users of tallying or
decision making experiments have reported. For example,            the WLM did not exhibit increases that were as strong.
Bröder and Gaissmaier (2007) reported mean response times
between 6.5s and 8s in their first, and between 11s and 15s                 Implementing Strategies in ACT-R
in their second experiment. It should be noted that those          In the constraining portion of our paradigm, the observed
experiments did not instruct subjects to rely on specific          response times will be used to build and constrain ACT-R
strategies, but that instead used participants’ decisions to       implementations of the three decision strategies.
infer, post hoc, by means of strategy classification               Specifically, each individual participant’s responses in the
procedures which strategies subjects have used.                    memory task can be used to model the contents of that
                                                                   subject’s declarative memory after having gone through the
                                                                   training phase. These declarative memory contents can then
                                                                   be used to model the retrieval processes associated with
                                                                   using each of the three decision strategies (cf. Marewski &
                                                                   Mehlhorn 2011, for this approach). Together with
                                                                   perceptual, motor, and other cognitive processes—all of
                                                                   which can be modeled in ACT-R—these retrieval processes
                                                                   will contribute to the response times predicted by the
                                                                   corresponding ACT-R models of the decision task.
                                                                   Overview of ACT-R
                                                                   ACT-R describes cognition as a set of modules that interact
                                                                   through a production system. The production system
                                                                   consists of production rules (i.e., if-then rules) whose
                                                                   conditions (i.e., the “if” parts) are matched against the
                                                                   contents of the modules. If a rule’s conditions are met, then
                                                                   the production rule can fire and the specified action is
                                                                   carried out. Each module implements different cognitive
                                                                   processes. The declarative module, for instance, enables
                                                                   information storage in and retrieval from memory, the
  Figure 2: Participants’ aggregate response time percentiles      intentional module keeps track of a person’s goals, while the
as a function of most valid discriminating cue. Error bars are     imaginal module holds information necessary to perform the
standard errors of the mean computed across all participants       current task. A visual module for visual perception and a
           in the respective experimental condition.               manual module for motor actions (e.g., typing on a
                                                                   keyboard) simulate interactions with the world. In
    Second, the response times of TTB participants fall in the     coordinating the modules, the production rules can only act
response time range of those reported in these previous            on information that is available in buffers, which can be
experiments. However, this resulted in participants in the         thought of as processing bottlenecks, linking the modules’
TTB condition being slower than tallying participants,             contents to the production rules. For instance, the
which also is a finding that stands in contrast to previous        production rules cannot access all contents of the declarative
studies, in which post hoc strategy classification procedures      module, but only these that are currently available in the
were used (e.g., Bröder & Gaismaier, 2007).                        retrieval buffer. ACT-R distinguishes between a symbolic
                                                               2204

 Figure 3: Processing stream of the weighted-linear model for the first and last seconds of the decision process. Production
 rules on the right hand side are stylized representations of the actual ACT-R productions for this model. Note that the
 model’s decision time predictions can vary across different decision trials, for instance, as a function of perceptual and
 motor processes, or cue activation. Also note that the same production rules fire more than once during the process.
and a subsymbolic system. The symbolic system is                  those from Marewski and Mehlhorn (2011) were used.
composed of the productions rules as well as of the modules          All models perform the same task as our experimental
and buffers. Access to the information stored in the modules      subjects: The models “read” two city names off a computer
and buffers is determined by the subsymbolic system. This         screen, process them, decide for one of them, and enter a
system is cast as a set of equations and determines, for          response by “pressing” a key. To illustrate this, Figure 3
instance, the timing of memory retrieval.                         shows the first and last seconds of an 18-seconds-long
                                                                  processing      stream of       our    preliminary     ACT-R
                                                                  implementation of the WLM. The various decisional,
                                                                  memorial, perceptual and motor processes assumed by the
                                                                  model are coordinated by production rules.
                                                                      Specifically, by first “reading” the names of both cities,
                                                                  the model tries to retrieve a memory trace of the city names
                                                                  called a chunk. Chunks are facts like “York is a city” or
                                                                  “York has an airport” which model people’s familiarity with
                                                                  city names and their cue knowledge about these cities,
                                                                  respectively. For each cue, the model retrieves its validity. If
                                                                  the cue value is positive, the model adds the validity of this
                                                                  cue to the weighted sum of the city, initiating a summation
                                                                  procedure. If the cue value is negative, the model subtracts
                                                                  the validity of the corresponding cue from the weighted sum
                                                                  of that city, initiating a subtraction procedure. Finally, the
                                                                  model compares the total weighted sums of the two cities
                                                                  and chooses the one with the larger total weighted sum by
                                                                  pressing a key. As Figure 4c shows, the predicted response
                                                                  time percentiles of 30 simulation runs of this WLM ACT-R
   Figure 4: ACT-R predictions of response time percentiles
                                                                  implementation lie close to the 75th percentile range
   of a tallying and weighted-linear model implementation.        observed in participants’ data (Figure 2c), suggesting that
 Error bars are standard errors of the mean, computed across      this implementation is not an implausible model, but also
            30 simulation runs of the ACT-R model.
                                                                  that other processes which boost participants’ response
                                                                  times, such as memorizing the weighted sum, are present in
Illustrating our ACT-R models                                     participants. Our preliminary tallying model (Figure 2b)
Figures 4a, 4b and 4c present our preliminary ACT-R               predicts response times within experimental data, while the
models, developed prior to running the experiment as a            TTB model (Figure 2a) is faster. These three models have to
source of rough predictions of participants’ eventual             be adapted to successfully capture participants’ behavior, a
behavior. All of these three models are, perhaps, the most
                                                                  more successful example of which is the tallying model
naïve implementations which follow the above mentioned
                                                                  presented on Figure 4d, which was built after the
strategy definitions and experimental instructions. In
                                                                  experiment. While the former tallying model did not include
developing these models, no parameters were fitted, but
                                                              2205

memorization of the number of positive cue values of                     Psychonomic Bulletin & Review, 14, 895–900.
already seen cities, the latter model did, which produced a           Bröder, A., & Schiffer, S. (2003). Take the best versus
response time distribution close to participants’ response               simultaneous feature matching: Probabilistic inferences
times. Exact modeling of each participant’s cue knowledge                from memory and effects of representation format.
is the next modeling step to be made. Naturally, after                   Journal of Experimental Psychology: General, 132,
identifying the most promising implementations of all                    277–293.
strategies, all models would then have to be tested in new            Dawes, R. M. (1979). The robust beauty of improper linear
experiments, this way ensuring that they can also account                models in decision making. American Psychologist, 34,
for behavior in tasks for which they were not developed.                 571–582.
                                                                      Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the
               Discussion and Conclusion                                 fast and frugal way: Models of bounded rationality.
While it goes beyond the scope of this short proceedings                 Psychological Review, 104, 650–669.
paper to present more ACT-R implementations—that is part              Glöckner A., & Betsch T. (2008). Modeling option and
of a larger research paper—one legitimate question one may               strategy choices with connectionist networks: Towards
raise is what the methodological advantages of our approach              an integrative model of automatic and deliberate
over earlier experimental work is. As mentioned above, in                decision making. Judgment and Decision Making, 3,
earlier studies including Marewski and Mehlhorn’s (2011)                 215-228.
ACT-R modeling efforts and Bröder and Gaissmaier’s                    Lewandowsky, S. (1993). The rewards and hazards of
(2007) response time analyses for TTB and other heuristics,              computer simulations. Psychological Science, 4, 236–
participants’ decisions had to be used to infer, post hoc, by            243.
means of strategy-classification and/or other model                   Khader, P.H., Pachur, T., Meier, S., Bien, S., Jost, K., &
selection procedures which strategies participants relied                Rösler, F. (2011). Memory-based decision-making with
upon in an experiment. As a result, the conclusions that                 heuristics: Evidence for a controlled activation of
could be drawn from analyses of response times crucially                 memory representations. Journal of Cognitive
hinged on the accuracy of the strategy classification and/or             Neuroscience, 23, 3540–3554.
model selection procedure. Our train-to-constrain approach,           Marewski, J. N., Gaissmaier, W., Schooler, L. J., Goldstein,
in contrast, allows identifying the response time patterns               D., & Gigerenzer, G. (2010). From recognition to
associated with a strategy without the need to use potentially           decisions: Extending and testing recognition-based
inaccurate strategy classification. To illustrate this point, the        models for multialternative inference. Psychonomic
deviations observed between Bröder and Gaissmaier’s and                  Bulletin & Review, 3, 287-309.
our findings could, besides being a product of differences in         Marewski, J. N. & Mehlhorn, K. (2011). Using the ACT-R
the stimuli and materials used, also be a result from the                architecture to specify 39 quantitative process models of
strategy classification method used by these authors. More               decision making. Judgment and Decision Making, 6,
studies with our paradigm, including experiments that make               439–519.
use of Bröder and Gaissmaier’s stimuli and materials, are             Marewski, J. N., & Schooler, L. J. (2011). Cognitive niches:
warranted to decide between these and other competing                    An ecological model of strategy selection, Psychological
explanations.                                                            Review, 118, 393-437.
   To conclude, response times such as the ones observed in           Mata, R., Schooler, L. J., & Rieskamp, J. (2007). The aging
our experimental paradigm can be used to find out which                  decision maker: Cognitive aging and the adaptive
ACT-R implementation best mirrors classic decision                       selection of decision strategies. Psychology and Aging,
strategies used by trained subjects. Once identified, these              22, 796–810.
implementations can, hopefully, be used to model behavior              Newell, B. R., & Bröder, A. (2008). Cognitive processes,
both in previously published studies as well as in new                   models and metaphors in decision research. Judgment
studies in which subjects’ decision strategies are                       and Decision Making, 3, 195–204.
unconstrained by training.                                            Pachur, T., Bröder, A., & Marewski, J. N. (2008). The
                                                                         recognition heuristic in memory-based inference: Is
                        References                                       recognition a non-compensatory cue? Journal of
                                                                         Behavioral Decision Making, 21, 183–210.
Anderson, J. R. (2007). How can the human mind occur in               Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The
    the physical universe? New York: Oxford University                   adaptive decision maker. New York: Cambridge
    Press.                                                               University Press.
Bergert, F. B., & Nosofsky, R. M. (2007). A response-time             Schulte-Mecklenbeck, M., Kühberger, A. & Ranyard, R.
    approach to comparing generalized rational and take-the-             (Eds.). (2011). A handbook of process tracing methods
    best models of decision making. Journal of                           for decision research: A critical review and user’s
    Experimental Psychology: Learning, Memory, and                       guide. New York: Taylor & Francis.
    Cognition, 31, 107–129.                                           Tversky, A. (1972). Elimination by aspects: A theory of
Bröder, A., & Gaissmaier, W. (2007). Sequential processing               choice. Psychological Review, 79, 281–299.
    of cues in memory-based multi-attribute decisions.
                                                                  2206

