UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
More Naturalistic Cross-situational Word Learning
Permalink
https://escholarship.org/uc/item/8fz765gs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Kachergis, George
Yu, Chen
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              More Naturalistic Cross-situational Word Learning
                                                  George Kachergis1 and Chen Yu2
                                      1
                                        george.kachergis@gmail.com, 2chenyu@indiana.edu
                                       1
                                         Psychology Department, Leiden University, the Netherlands
               2
                 Department of Psychological & Brain Science / Cognitive Science Program, Indiana University, USA
                                Abstract                                some form of accumulation of word-object co-occurrences.
   Previous research has found that people can use word-object
                                                                        When tested on each word and given four trained objects to
   co-occurrences from ambiguous situations to learn word               choose from, participants chose the correct object for half of
   meanings (e.g., Yu & Smith, 2007). However, most studies of          the 18 words, on average (Yu & Smith, 2007).
   cross-situational learning present an equal number of words             However, learning environments in the real world are
   and objects, which may simplify the problem by, for example,         likely not as simple: there may be objects present that go
   encouraging learners to use assumptions such as each word            unnamed, some spoken words (e.g. articles) do not refer to
   going with one object. This paper presents several conditions        particular objects, and object names may be spoken when
   in which the number of words and objects do not match:
   either additional objects appear at random, or objects appear        the intended object is not visible. These forms of noise
   sometimes without their intended words. These manipulations          likely interfere with learning to some extent. When a word
   do generally hurt learning in comparison to balanced                 is heard without the object it previously co-occurred with
   conditions, but people still learn a significant proportion of       several times, is a learner to map it to a new object? What if
   word-object pairings. The results are explored in terms of           that object already has a name? Conversely, when an object
   statistics of the training trials—including contextual diversity     is seen, but the word it previously occurred with is not
   and context familiarity—and with the uncertainty- and
                                                                        heard, will learners lose certainty about the old mapping,
   familiarity-biased associative model. Parametric differences
   between conditions hint at hidden cognitive constructs.              and even associate a new word with it?
                                                                           In this study, we take baseline conditions from Yu &
   Keywords: statistical learning; cross-situational learning;          Smith (2007) that present an equal number of words and
   language acquisition
                                                                        objects on each trial and either add or remove words or
                                                                        objects in a systematical way in order to change various co-
                            Introduction
                                                                        occurring statistics that learning may rely on. We investigate
Human infants learn words quite quickly despite many                    several critical factors that matter to learning, such as
challenges facing them, including uncertainty and ambiguity             conditional probability of words given objects during
in the language environment. Recent research has studied                learning, final test probability, and contextual diversity—the
how learners may acquire word meanings from regularities                number of other pairs each pair appears with (Kachergis,
in the co-occurrence of words and referents (e.g., objects).            Yu, & Shiffrin, 2009b). Following Fazly, Alishahi, and
Such cross-situational statistical word learning relies on two          Stevenson (2010), we also investigate additional two factors
assumptions: 1) that spoken words are often relevant to the             – age of exposure (i.e., when a pair first appears) and
visible environment, and 2) that learners can to some extent            context familiarity (the mean frequency of the objects a
remember the co-occurrence of multiple words and objects                given pair appears with). Not only are these factors likely to
in a scene. Thus, as words and their intended referents are             influence how well people learn, but likely so will the fact
observed in different situations over time, learners can                that the trials contain an unequal number of words and
apprehend the correct word-object mappings. Relying only                objects. Previous studies have also typically presented an
on the regularity of the linguistic environment and basic               equal number of words and objects on each trial, which may
memory and attention processes, this may be an important                induce participants to only consider 1-to-1 mappings
method of learning nouns for infants, and even adult                    (although see Vouloumanos, 2008 as well as mutual
travelers in a foreign country.                                         exclusivity investigations: Kachergis, 2012; Ichinco, Frank,
   In adult cross-situational learning studies (e.g., Yu &              & Saxe, 2009; Yurovsky & Yu, 2008).
Smith 2007), participants are asked to learn the meaning of                Finally, we use a recent associative model of cross-
alien words by watching a series of training trials. On each            situational learning (Kachergis, Yu, & Shiffrin, 2012) to
trial learners see an array of unfamiliar objects (e.g., four           shed light on differences between the conditions. The model
sculptures) and hear pseudowords (e.g., stigson, bosa). The             assumes that learners have access to both their familiarity
meaning of each pseudoword is ambiguous on a given trial,               and their uncertainty about the word-object pairings present
because although each word refers to a single onscreen                  on a given trial, and that attention competes for uncertain
object, the intended referent is not indicated. In a typical            stimuli and for already-strong pairings. This model matches
learning scenario, participants attempt to learn 18 word-               adult behavior in a number of previous cross-situational
object pairings from 27 trials, with four words and four                experiments (Kachergis, 2012; Kachergis, Yu, & Shiffrin,
objects given per trial. In this design, each word-referent             2013).
pair is presented six times over the five-minute training
period. Learning a correct word-object pairing requires
                                                                    710

                         Experiment                                Trial p(w|o)). The probability of seeing an object given that
                                                                   its label was heard was always 1 (Trial p(o|w)). Test p(o|w)
   Participants were asked to learn 18 word-referent pairs
                                                                   in Table 1 shows the probability of guessing the intended
from a series of individually ambiguous training trials using
                                                                   object for a given word after experiencing all of the training.
the cross-situational word learning paradigm (Yu & Smith,
                                                                      In the 2x4 condition, words appeared 6 times and objects
2007). Each training trial was comprised of a display of two
                                                                   12 times, so on each trial the probability of hearing the
or more novel objects and two or more spoken
                                                                   intended word for a given object is p(w|o)=.5. In the 2x3
pseudowords, depending on condition. With no indication
                                                                   condition, objects appear 9 times, making p(w|o)=.67. In the
of which word refers to which object, on a single trial,
                                                                   2x4 condition, each word appears 6 times and each object
learners can only guess at the correct word-referent
                                                                   appears 12 times. In the 3x3 +1w/o condition, an additional
mappings. However, since words always appear on trials
                                                                   random word and object were shown on each trial. In the
with their intended referents, the correct pairings may be
                                                                   4x4 +2w/o condition, two additional random words and
learned over the series of trials.
                                                                   objects were shown per trial. In the 3x4 condition, each
   In this study, many conditions were created by
                                                                   word appears 6 times, each object 8 times (p(w|o)=.75). In
manipulating training conditions from Yu and Smith
                                                                   the 3x4 1/.5 condition, words appear 6 times, and 12 objects
(2007)—the 2x2 (i.e., 2 word-object pairs per trial), 3x3,
                                                                   appear only with their words (p(o,w)=1), while 6 objects
and 4x4 conditions— to introduce different types of noise
                                                                   appear 12 times (p(w|o)=.5). In the 3x4 1/.66 condition,
which is arguably more in line with real-world learning,
                                                                   words appear with their objects 6 times (p(w|o)=1), but 12
such as a non-referential word, an unnamed object, or both.
                                                                   objects appear 3 additional times (p(w|o)=.66) without their
In every condition, participants experienced a series of
                                                                   words. In the 3x4 +6o condition, 18 word-object pairs co-
training trials with a total of 18 intended word-object pairs.
                                                                   occur 6 times, and 6 additional objects occur as noise.
The same pair was never allowed to appear in neighboring
                                                                      The 1x3 condition divided each trial of the 3x3 condition
trials in conditions, as previous studies have shown such
                                                                   into 3 trials with one word and 3 objects, and shuffled the
temporal contiguity improves learning (Kachergis, Yu, &
                                                                   trials so no objects (or words) repeated trial-to-trial. Thus,
Shiffrin, 2009a; Kachergis, Yu, & Shiffrin, 2013). In the
                                                                   words appeared 6 times, and objects 24 times (p(w|o) = .33).
baseline 2x2 (54 trials), 3x3 (36 trials), and 4x4 (27 trials)
                                                                   The 1x4 condition divided the 4x4 trials as 1x3 did for 3x3,
conditions, each word and object appear 6 times. Every time
                                                                   meaning that objects appeared 24 times (p(w|o) = .25).
a given object is present, the intended word is presented
                                                                      Calculated for each item per condition, Table 1 also
(p(w|o)=1), and every time a given word is presented, the
                                                                   shows the average “Age” of Exposure (trial the pair first
intended object is present (p(o|w)=1). Most conditions in
                                                                   appears), Context Familiarity (defined by Fazly, Alishahi,
Table 1 were built from these three baseline conditions. We
                                                                   and Stevenson (2010) as the mean co-occurrence with all
manipulate the number of words and objects per trial, thus
                                                                   other pairs across exposures), and Context Diversity (the
changing their frequency. This also changes the probability
                                                                   number of unique pairs a pair co-occurs with over training).
of hearing the word for a given object on a trial (in Table 1,
                    Word       Object       Trial      Test        Context        “Age” of     Context      Num.
    Condition                                                                                                         Correct
                    Freq.       Freq.      p(w|o)     p(o|w)     Familiarity      Exposure    Diversity    Subjs.
    2x2                 6           6         1         0.5           3.5          5.6            5.1        19          0.79
    2x3                 6           9       0.67       0.33           3.3          6.0            9.1        55          0.56
    2x4                 6          12        0.5       0.25           3.3          5.6           11.8        33          0.30
    3x3 +1w/o           9           9         1        0.22           5.1          4.3           12.9        39          0.17
    4x4 +2w/o          12          12         1        0.12           6.6          3.8           16.2        39          0.10
    3x3                 6           6         1        0.33           3.5          3.7            8.8        36          0.43
    1x3                 6          18       0.33       0.33           3.2          17.5           8.7        63          0.52
    3x4                 6           8       0.75       0.25           3.4          3.7           12.3        25          0.19
    3x4 +6o             6           6         1        0.25           3.5          3.7           13.6        20          0.27
    3x4 1/.5            6           8       1 / .5     0.25           4.3          3.7           11.3        25          0.22
    3x4 1/.66           6           8      1 / .66     0.25           3.6          3.7           12.1        25          0.21
    4x4                 6           6         1        0.25           3.5          2.8           12.2        77          0.31
    1x4                 6          24       0.25       0.25           3.1          19.9          12.0        40          0.19
Table 1. Summary of conditions in the Experiment.
                                                               711

Subjects                                                                 change in one factor is often correlated with changes in
                                                                         several other factors (e.g., contextual diversity and context
Participants were undergraduates at Indiana University who               familiarity).
received course credit for participating. The number of
participants in each condition are shown in Table 1 (Num.                                     0.8
Subjs. column). None had participated in previous cross-
situational experiments.
                                                                                              0.6
Stimuli
                                                                         Proportion Correct
Each training trial consisted of an array of 2-4 uncommon                                     0.4
objects (e.g., sculptures) and 2-4 spoken pseudowords,
depending on condition (see Table 1). The computer-
generated pseudowords are phonotactically-probable in                                         0.2
English (e.g., “bosa”), and were spoken by a monotone,
synthetic female voice. The words and objects used for each                                   0.0
condition were drawn from a set of 72 words and 72 objects.                                         2x2     2x3    2x4   3x3 +1w/o4x4 +2w/o    3x3      1x3      3x4    3x4 +6o   3x4 1/.5 3x4 1/.66   4x4   1x4
  Training for each condition consisted of between 27 and                                                                                            Condition
108 trials. Each training trial began with the appearance of             Figure 1: Mean accuracy by training condition. Performance
two to four objects (differing by condition) which remained              was variable, but all conditions were above chance
visible for the entire trial. After 2s of initial silence, each          (18AFC=.056). Error bars show +/-SE.
word was heard (1s per word, with 2s of silence after each).
                                                                            To better understand the effects of the various factors, we
Procedure                                                                fit a logistic mixed-effects regression model to the trial-level
Participants were told they would see a series of trials with            accuracy data using the lme4 package in R (Bates and
some objects and alien words, but that the words would be                Maechler, 2010; R Development Core Team, 2010). Mixed
presented in random order. They were also told that their                logit models are more appropriate for forced-choice data
knowledge of which words belong with which objects                       than ANOVAs, especially when different conditions yield
would be tested at the end.                                              different amounts of data, as in the present experiment
   After each training block, participants’ knowledge of                 (Jaeger, 2008). The model included subject as a random
word-object mappings was assessed using 18-alternative                   factor, and Trials/Condition, Word Frequency, Object
forced choice (18AFC) testing: on each test trial a single               Frequency, Trial p(w|o), Test p(o|w), Contextual Diversity,
word was played, and the participant was instructed to                   Age of Exposure, and Context Familiarity as fixed factors.
choose the appropriate object from a display of all 18                   All of these factors were scaled to remove collinearity.
trained objects. Each of the 18 words was tested once in a               Shown in Table 2, there was a significant negative intercept,
random order.                                                            showing that participants were less likely to choose the
                                                                         correct answer than the incorrect answer. Trials/Condition
Results & Discussion                                                     and Test p(o|w) both had significant, large positive
As shown in Fig. 1, all of the conditions had mean                       coefficients (.75 and .78), showing that longer training
performance significantly above chance (18AFC chance =                   periods were better, as well as stronger correct
.056). The 2x2 baseline condition had by far the highest                 associations—both of which occur more in the conditions
performance (M=.79). Adding another object to each trial—                with fewer pairs per trial (i.e., 2x2 rather than 4x4).
without it’s intended word—harmed learning (2x3: M=.56).
2x4 adds yet another object, further decreasing both Trial
                                                                                                          Factor                    Coefficient                         Z               p-value
p(w|o) and Test p(o|w), resulting in even lower performance
(M=.30). Adding an extra pair (3x3 +1w/o) or two (3x3                                                     (Intercept)                     -0.75                        -9.20              <.001
+2w/o) is even more harmful (M=.17, M=.10, resp.); it both                                                Trials/Cond                         0.75                     4.57               <.001
lowers Test p(o|w) and creates more possible pairings to
consider on each trial. For another example, the 1x3 and 1x4                                              Word Freq                       -0.10                        -0.92               =.36
conditions are identical in all of the other factors except that                                          Obj Freq                        -0.58                        -2.75               <.01
there were 1 word and 3 objects in the 1x3 condition (0.33)
but 1 word and 4 objects in the 1x4 condition (0.25). This                                                Trial p(w|o)                    -0.14                        -0.88               =.38
one change caused a dramatic performance difference from                                                  Test p(o|w)                         0.78                     5.67               <.001
M=.53 to M=.19. Meanwhile, it may not seem like there is a
                                                                                                          Cont. Fam.                          0.20                     2.82                <.01
dramatic difference between the 1x3 and 2x3 conditions. All
this suggest that given multiple factors that can be used to                                              Age of Exp                      -0.08                        -1.93               =.05
characterize statistical information in training data, and the                  Cont. Div.       0.17         2.24      <.05
flexibly of human statistical learning systems, it is difficult
                                                                         Table 2. Summary of logistic regression results.
to pull apart all of the effects in terms of conditions—
especially in the 3-word and 4-word conditions—as a
                                                                   712

                                            Strength & Entropy Bias:
                                                                                                 H(w) · H(o) · Mw,o · ⇥
                                                                              Mw,o = P              P
                                                                                              w   S    o S H(w) · H(o) · Mw,o
   Word frequency did not contribute 2significantlyAdditive   to     The
                                                                     Modelsinitial values
                                                                                       (not  for these  new rows and columns are k, a
                                                                                                  as good)
correctness, but object frequency had a negative coefficient,        small constant (here, 0.01).
showing that additional repetitions of an object on trials              Trial-to-trial, association strengths decay and then a fixed
without the intended word indeed inhibited  Unbiased:
                                               learning of that      amount of associative weight, χ, is distributed among the
object. Trial p(w|o) was not a significant predictor of
                                                                                                                      ⇥
                                                                     presented word-object   Mw,o =     Mw,o + and
                                                                                                     associations
                                                                                                                        2
                                                                                                                             added to the
accuracy; it seems the other (partially-correlated) factors                                                         |S|
                                                                     strengths. The rule used to distribute χ (i.e., attention)
better capture the variance. Context Familiarity and                 balances a bias for attending to unknown stimuli with a bias
Contextual Diversity both have significant  Biased: positive         for strengthening already-strong associations. When a word
coefficients (.20 and .17). Though they are correlated               and referent
                                                                                                                         · ⇥ χ) is given to
                                                                                                                Mw,o (i.e.,
                                                                                  Marew,o repeated,
                                                                                            = Mw,o extra
                                                                                                       + PattentionP
(r=.56), these two factors both help people learn words. Age         this pair: a prior knowledge bias.     w SStimuli o SM with
                                                                                                                               w,ono strong
of Exposure had a marginally significant negative                    associates also attract attention, whereas pairings between
coefficient (-.08), showing that earlier-appearing     pairs are
                                            Fixed capacity:          uncertain objects and known words, or vice-versa, draw
indeed a bit more likely to be learned.                              little attention. Stimulus uncertainty
                                                                                                       H(w) · H(o)is measured
                                                                                                                         · Mw,oby · ⇥entropy
   In total, these results offer a look at the factors that          (H),   w,o = M
                                                                         Mwhich     is w,o   + Pthe outcome
                                                                                        0 when           P        of a variable is certain
influence cross-situational word learning, and an estimate of                                                    H(w) · H(o) · Mw,o
                                                                     (e.g., a word appears wwith       S oneo S object,     and has never
their relative magnitudes. We now apply a recent associative         appeared with any other object), and maximal (log2n) when
model of cross-situational word learning Supercapacity:
                                             to see whether it       all of the n possible object (or word) associations are
can account for word-learning in these noisy environments,           equallyMlikely=(e.g.,            aH(w)    · H(o) · Mw,o · observed
                                                                                                                                    ⇥
                                                                                w,o      Mw,owhen+P     stimulus
                                                                                                             P has not been
and to see whether the recovered parameters yield any                                                                     with ·every
                                                                     before, or if a stimulus were               o S H(w)
                                                                                                        w Sto appear             H(o) other
additional insight.                                                  stimulus equally). In the model, on each trial the entropy of
                            Model           Best model (scaledeach          word (and object) is calculated from the normalized
                                                                      entropy):
                                                                     row (column) vector of associations for that word (object),
To better understand how the condition demands differ, we            p(Mw,·), like so:
introduce an associative model of cross-situational word                                              e ·(H(w)+H(o)) · Mw,o · ⇥
                                                                       Mw,o = Mw,o + P                  P           ·(H(w)+H(o)) · M
learning proposed by Kachergis, Yu, and Shiffrin (2012a).                                          w S     o Se                          w,o
   The model assumes that learners do not equally attend to
all word-object pairings on a trial (i.e., store all co-                The update
occurrences). Rather, selective attention onBest   model
                                               a trial      (scaled entropy
                                                       is drawn                   withrule     for allocating attention and adjusting
                                                                                           decay):
                                                                     strengths for the stimuli presented on a trial is:
to strengthen associations between words and objects that
have co-occurred previously. This bias for familiar pairings                                           ⇥ · e ·(H(w)+H(o)) · Mw,o
                                                                      Mw,o = Mw,o + P                    P
competes with a bias to attend to stimuli that have no strong                                       w S     o Se
                                                                                                                     ·(H(w)+H(o)) · M
                                                                                                                                          w,o
associates (e.g., as a novel stimulus). The competing
familiarity and uncertainty biases allow the model to exhibit           In this equation, α is a parameter governing forgetting, χ
                                            Entropy:
fast mapping, since a novel word-novel object combination            is the weight being distributed, and λ is a scaling parameter
will demand more attention, and mutual exclusivity: a novel          governing differential weighting of uncertainty and prior
word will only become weakly associated with an already-             knowledge (familiarity).      X n As λ increases, the weight of
known referent (Kachergis, Yu, & Shiffrin, 2012). For                uncertainty     (i.e.,
                                                                               H(Mw,· ) =    the        p(Mw,i ) ·entropy
                                                                                                  exponentiated       log(p(M  term,
                                                                                                                                 w,i ))
                                                                                                                                        which
example, suppose word w1 and object o1 have appeared                 includes both the word’si=1     and object’s association entropies)
together and are thus somewhat associated, while w7 and o7           increases relative to familiarity. The denominator
are novel. Given a trial with both pairs: {w1,o1,w7,o7}, w1-o1       normalizes the numerator so that exactly χ associative
demands more attention than w7-o1, w1-o7, or w7-o7, since            weight is distributed among the      2 potential associations on the
w1-o1 is stronger than baseline. However, attention is also          trial. Only decay operates for stimuli not on the current trial.
pulled individually to w7 and to o7, since both of these novel       After training, a learner is tested with each word and
stimuli have no strong associates. Uncertainty is measured           chooses an object from n alternatives in proportion to the
by the entropy of each stimulus’ association strengths.              association strengths of each alternative to that word.
Because of the high joint uncertainty of w7 and o7, more                In sum, this associative model learns trial-by-trial by
attention is given to the association w7-o7. Thus, attention is      distributing attention in a way that corresponds with both
mostly divided between w1-o1 and w7-o7, although the other           our intuitions about word-learning—using competing biases
pairings will be strengthened a bit.                                 for familiar pairings and uncertain stimuli—and a number of
   Formally, let M be an n word × n object association               empirical findings. Three parameters (χ, α, and λ) were fit
matrix that is incrementally built during training. Cell Mw,o        using log likelihood to each individual’s choices in each
will be the strength of association between word w and               training condition. The model achieved quite a good fit to
object o. Strengths are subject to forgetting (i.e., general         the data, with R2=.98. Figure 2 shows mean model
decay) but are augmented by viewing the particular stimuli.          performance for individuals’ model fits by condition. Figure
Before the first trial, M is empty. On each training trial t, a      3 shows individuals’ mean performance in each condition
subset S of m word-object pairings appears. If new words             versus the model’s performance. Next, we investigate the
and objects are seen, new rows and columns are first added.
                                                                 713

parameter values for each condition to see what they tell us                                                                                     example, in our model, χ is for now a learning rate per trial,
about the cognitive effects of different types of noise.                                                                                         but should likely depend on how many possible associations
                                                                                                                                                 there are on a trial and how much time there is to consider
                     0.8
                                                                                                                                                 them. If systematic differences in particular parameters were
                                                                                                                                                 required to fit performance in some of the conditions, then
                     0.6                                                                                                                         we may be able to pinpoint which factors learning rate and
                                                                                                                                                 memory decay depend on, and redefine them in more
Proportion Correct
                                                                                                                                                 meaningful units. An ANOVA by condition for each
                     0.4
                                                                                                                                                 parameter showed significant differences for all three
                                                                                                                                                 parameters (χ: F(12,482)=11.63, p<.001; λ: F(12,482)=2.13,
                     0.2                                                                                                                         p=.01; α: F(12,482)=2.70, p<.01). Table 3 shows the mean
                                                                                                                                                 parameters found for each condition. We emboldened the
                     0.0
                                                                                                                                                 highest mean values for each parameter and italicized the
                              2x2   2x3    2x4   3x3 +1w/o4x4 +2w/o   3x3       1x3      3x4    3x4 +6o   3x4 1/.5 3x4 1/.66   4x4   1x4
                                                                                                                                                 lowest in order to highlight the conditions with unusual
                                                                             Condition
                                                                                                                                                 mean parameter values.
Figure 2. Model performance closely matches human                                                                                                   For χ, the 2x2 condition has the highest value (19.47),
performance (Fig. 1) and variability in the Experiment.                                                                                          and this condition also yields the highest performance in
                                                                                                                                                 humans. 2x2 also has the lowest λ (i.e., more focus on
                                                                                                                                ●
                                                                                                                                ●●
                                                                                                                                 ●
                                                                                                                                 ●
                                                                                                                                 ●
                                                                                                                                 ●               familiarity) and α (i.e., faster decay), the latter of which
                                                                                                                           ●●
                                                                                                                            ●●
                                                                                                                             ●
                                                                                                                          ●●●●
                                                                                                                              ●●
                                                                                                                                                 may mitigate the high learning rate a bit. Conditions with
                                                      R^2 = 0.98                                                      ● ● ●
                                                                                                                          ●●●
                                                                                                                         ●●                      the next-highest learning rates—2x3 (9.87) and 1x3
                                                                                                                       ● ●●
                                                                                                                       ●
                              0.8                                                                                 ●●
                                                                                                                      ●
                                                                                                                    ●●●                          (10.32)—had the next-highest performance (.56 and .52).
                                                                                                                ●●
                                                                                                                 ●●● ●
                                                                                                                    ●●
                                                                                              ● ●●                                               1x3, along with 1x4 also had the highest mean α = .94
          Human Performance
                                                                                            ●● ● ●  ●●
                                                                                     ●● ●   ●●● ● ●
                                                                                          ●●●
                                                                                         ●●
                                                                                                                                                 (memory fidelity). These two conditions have the shortest
                              0.6                                                ●●●● ● ●●
                                                                                   ● ●●●
                                                                                   ●      ●                                                      trials (5s), along with the fewest possible associations: only
                                                                        ● ●● ●●  ● ●
                                                                                ●●●● ●● ●                                                        one word and three or four objects. The conditions with the
                                                                            ●●● ●●●●●
                                                                           ● ●●● ●●●● ●         ●
                                                                                                                                                 lowest learning rates, 3x4 (χ=.35) and 1x4 (χ=.47), have
                                                                         ●●
                                                                      ●●   ●●
                                                                            ●
                                                                            ●●●●● ●
                                                                              ●
                                                                                                                                                 fairly low performance (.19 and .19). The short trial time for
                              0.4                               ●●
                                                                ●  ● ●
                                                                    ●●
                                                                      ●
                                                                      ●●●●
                                                                       ●●
                                                                           ●
                                                                         ●●●
                                                             ● ●●  ●
                                                                                                                                                 the 1x4 condition may not give subjects enough time to pick
                                                          ●●●●●  ●●
                                                                  ●
                                                                  ●
                                                                  ●●● ●
                                                                   ●   ●
                                                                       ●
                                                   ● ●●   ●
                                                          ●●●●●●●
                                                            ●●●
                                                                 ● ●                                                                             out the single correct pairing.
                                          ●               ●   ● ●● ●
                                          ●         ●●● ●●●    ●●     ●
                                                  ●●  ●●
                                                       ●  ●●
                              0.2
                                          ●
                                          ●
                                          ●    ●●●●
                                                 ● ●
                                                    ●
                                                    ●●
                                                   ●●●
                                                         ●  ●  ●
                                                               ●  ●
                                                                                                                                                     Condition     Correct        χ          λ        α
                                          ● ●
                                          ●   ●● ●●●
                                                   ● ●● ● ● ●
                                          ● ●●
                                          ●  ●
                                          ● ●●
                                             ●
                                               ●
                                               ●●
                                              ●●●
                                                 ●
                                                 ●●●
                                                  ●●                                                                                                 2x2             0.79       19.47       5.0      0.85
                                          ●
                                          ● ●
                                          ●
                                          ●●
                                          ●
                                          ●
                                          ●
                                                                                                                                                     2x3             0.56       9.87        6.9      0.92
                                                     0.2                    0.4                0.6                 0.8                               2x4             0.30       1.73        9.3      0.88
                                                                Model Performance                                                                    3x3 +1w/o       0.17       0.91        8.6      0.89
Figure 3. Individual performance versus model fit: the                                                                                               4x4 +2w/o       0.10       3.01        8.7      0.87
model was capable of closely matching the behavior of most                                                                                           3x3             0.43       6.30        6.1      0.90
participants.
                                                                                                                                                     1x3             0.52       10.32       7.3      0.94
  We first looked at correlations between each parameter                                                                                             3x4             0.19       0.35        7.5      0.89
and performance. χ was positively correlated with learning
(Pearson’s r=.72, t(494)=22.74, p<.001), which is consistent                                                                                         3x4 +6o         0.27       5.07        9.2      0.89
with our interpretation of χ as a learning rate; how much                                                                                            3x4 1/.5        0.22       0.99        8.0      0.92
associative weight can be distributed per trial. λ was                                                                                               3x4 1/.66       0.21       1.58        9.1      0.88
negatively correlated with performance (r = -.22, t(494)=-
5.04, p<.001): greater focus on uncertain stimuli seems to                                                                                           4x4             0.31       2.80        7.9      0.87
harm learning, at least in the conditions of this Experiment.                                                                                       1x4             0.19        0.47       9.1      0.94
λ and χ were also negatively correlated (r = -.20, t(294)=-                                                                                      Table 3. Mean of best-fitting parameters for each condition.
4.64, p<.001), meaning that uncertainty-focused learners                                                                                         The largest and smallest mean values of each parameter are
tended to have slower learning rates. All other correlations                                                                                     emboldened and italicized, respectively.
were <|.03|, and not significant.
  We also investigated whether there were differences in                                                                                         In the 3x4 condition, there are again more objects than
parameters by condition. Ideally, the parameters of a                                                                                            words, and many possible associations. The other 3x4
cognitive model should be cognitively interpretable. For                                                                                         conditions also had low performance and low learning rates,
                                                                                                                                           714

except for 3x4 +6o, in which participants may have had                 In summary, cross-situational learning is robust under a
little difficulty ignoring the extraneous objects (which are        many noise conditions that more closely resemble situations
less confusing since they are occur infrequently, and never         learners may encounter in the real world than in previous
with a consistent name). It is hard to see a pattern in λ, the      studies. Moreover, we have presented a large dataset that we
relative focus on uncertainty vs. familiar pairings (roughly,       hope will inspire new experiments to test the limits of cross-
explore vs. exploit). We do not yet have any reason to              situational learning, and will constrain and inform modeling
believe λ should remain fixed; learners may well change             efforts.
it—implicitly or strategically—depending on task demands.                                     References
Moreover, previous investigations found that λ has little           Bates, D. & Maechler, M. (2010). lme4: Linear mixed-
effect on the shape of learning curves (Kachergis, Yu, &               effects models using S4 classes. R package version
Shiffrin, 2012b).                                                      0.999375-37. http://CRAN.R-project.org/package=lme4
                         Discussion                                 Fazly, A., Alishahi, A., & Stevenson, S. (2010). A
                                                                       probabilistic computational model of cross-situational
   In the language environment, many objects in a scene
                                                                       word learning. Cognitive Science, 34, 1017–1063.
may go unlabeled, whether they are novel or familiar. For
the sake of simplicity, previous studies of cross-situational       Gleitman, L. (1990). The structural sources of verb
learning presented an equal number of words and objects on             meanings. Language Acquisition, 1(1), 1–55.
each trial, and a word’s intended referent was always               Ichinco, D., Frank, M.C., & Saxe, R. (2009). Cross-
present (and vice-versa; e.g. Yu & Smith, 2007; Kachergis,             situational word learning respects mutual exclusivity. In
Yu, & Shiffrin, 2009a, 2009b). In this study, we presented             N. Taatgen, H. van Rijn, J. Nerbonne, & L. Schomaker
learners with a variety of conditions with different kinds and         (Eds.) Proceedings of CogSci 31 (pp. 749–754).
degrees of statistical noise (e.g., extra objects, mismatched       Jaeger, T. F. (2008) Categorical data analysis: Away from
words and objects). Although performance varied widely in              ANOVAs (transformation or not) and towards logit mixed
different conditions, learners performed significantly above           models. Journal of Memory and Language, 59, 434-446.
chance in all conditions.                                           Kachergis, G., Yu, C., & Shiffrin, R. M. (2009a). Temporal
   To better understand what factors influence learning, we            contiguity in cross-situational statistical learning. In N.
measured various statistics about items in each condition,             Taatgen, H. van Rijn, J. Nerbonne, & L. Schomaker
and tried to predict learning from these statistics. Greater           (Eds.) Proceedings of CogSci 31. Austin, TX: Cognitive
contextual diversity—how many pairs a pair appears with                Science Society.
during training, context familiarity—the average frequency          Kachergis, G., Yu, C., & Shiffrin, R. M. (2009b). Frequency
of pairs a pair appears with, trials per condition, and overall        and contextual diversity effects in cross-situational word
strength of the correct pairing all significantly improved the         learning. In N. Taatgen, H. van Rijn, J. Nerbonne, & L.
odds of learning a pair. Being exposed to a pair earlier in            Schomaker (Eds.) Proceedings of CogSci 31 (pp. 755-
training improved learning of that pair, but being exposed to          760).
an object more often inhibited learning, because in this            Kachergis, G., Yu, C., & Shiffrin, R.M. (2012a). An
study extra occurrences of an object were likely to be noise           associative model of adaptive inference for learning
(e.g., appearing on a trial where it goes unnamed). These              word-referent mappings. Psychonomic Bulletin & Review,
conditions and measures provide important constraints for              19(2), 317-324.
word-learning models, as well as demonstrating that cross-          Kachergis, G., Yu, C., & Shiffrin, R. M. (2012b). Cross-
situational learning is robust under a variety of types of             situational word learning is better modeled by
noise.                                                                 associations than hypotheses. IEEE Conference on
   We applied a recent associative word-learning model to              Development and Learning / EpiRob 2012.
these data, and found that it could account for individuals’        Kachergis, G., Yu, C., & Shiffrin, R. M. (2013). Actively
behavior in each of the conditions. We investigated the                learning object names across ambiguous situations.
average parameter values for individuals in each condition,            Topics in Cognitive Science, 5(1), 200-213.
and found that they differed. The learning rate parameter           Markman, E.M. & Wachtel, G.F. (1988). Children’s use of
was strongly linked to overall performance, and was high               mutual exclusivity to constrain the meanings of words.
when there were few pairings to consider on each trial (e.g.,          Cognitive Psychology, 20, 121–157.
2x2, 1x3)—unless most of them were noise, and presented             Vouloumanos, A. (2008). Fine-grained sensitivity to
quickly (e.g., 1x4). There less memory decay in conditions             statistical information in adult word learning. Cognition,
with very one word per trial, and thus few associations (1x3,          107(2), 729-742.
1x4), although the most decay occurred in the 2x2                   Yu, C. & Smith, L. B. (2007). Rapid word learning under
condition, but that was balanced by the fast learning rate.            uncertainty via cross-situational statistics. Psychological
Overall, we have a somewhat clearer idea of what the                   Science, 18, 414-420.
model’s parameters do under different noise conditions, but         Yurovsky, D. & Yu, C. (2008). Mutual exclusivity in cross-
we do not yet have a wholly satisfactory psychological                 situational statistical learning. Proceedings of CogSci 30
interpretation of them.                                                (pp. 715–720). Austin, TX: Cognitive Science Society.
                                                                715

