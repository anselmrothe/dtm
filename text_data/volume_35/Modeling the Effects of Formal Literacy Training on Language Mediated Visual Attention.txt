UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling the Effects of Formal Literacy Training on Language Mediated Visual Attention
Permalink
https://escholarship.org/uc/item/6qg1k20m
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Smith, Alastair
Monaghan, Padraic
Huettig, Falk
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                          Modeling the Effects of Formal Literacy Training on
                                        Language Mediated Visual Attention
                                           Alastair C. Smith (alastair.smith@mpi.nl)
                                       Max Planck Institute for Psycholinguistics, Wundtlaan 1,
                                                 Nijmegen, 6525 XD, The Netherlands
                                      Padraic Monaghan (p.monaghan@lancaster.ac.uk)
                                           Department of Psychology, Lancaster University,
                                                        Lancaster, LA1 4YF, U.K.
                                                Falk Huettig (falk.huettig@mpi.nl)
                                       Max Planck Institute for Psycholinguistics, Wundtlaan 1,
                                                 Nijmegen, 6525 XD, The Netherlands
                             Abstract                                  listening to speech and attract increased overt attention (Yee
                                                                       & Sedivy, 2006; Huettig & Altmann, 2005)
  Recent empirical evidence suggests that language-mediated
  eye gaze is partly determined by level of formal literacy               These types of studies leave open one important question:
  training. Huettig, Singh and Mishra (2011) showed that high-         What particular aspects of these representations affect
  literate individuals' eye gaze was closely time locked to            participants’ performance? Computational models have
  phonological overlap between a spoken target word and items          been proposed to reproduce the individual phonological and
  presented in a visual display. In contrast, low-literate             semantic effects on word processing. Allopenna et al.
  individuals' eye gaze was not related to phonological overlap,       (1998), demonstrated that fixation probabilities during
  but was instead strongly influenced by semantic relationships
  between items. Our present study tests the hypothesis that this
                                                                       spoken word processing can be predicted by lexical
  behavior is an emergent property of an increased ability to          activations in the TRACE model of spoken word
  extract phonological structure from the speech signal, as in         recognition. Mayberry, Crocker and Knoeferle (2009) and
  the case of high-literates, with low-literates more reliant on       Kukona and Tabor (2011) extended this work to predict
  more coarse grained structure. This hypothesis was tested            fixation behavior during sentence processing from the
  using a neural network model, that integrates linguistic             integration of visual and linguistic information. Until
  information extracted from the speech signal with visual and         recently, such models that simulate the interaction between
  semantic information within a central resource. We
  demonstrate that contrasts in fixation behavior similar to those     visual and linguistic information did so with representations
  observed between high and low literates emerge when models           that were unable to capture fine-grained semantic,
  are trained on speech signals of contrasting granularity.            phonological or visual feature relationships and were
                                                                       therefore limited in their ability to examine effects of
   Keywords: The Visual World Paradigm, Connectionist
   Modeling, Visual Attention, Literacy.                               multimodal interactions in language processing. A recent
                                                                       model by Smith, Monaghan and Huettig (in press) based on
                         Introduction                                  the hub-and-spoke models of semantic processing which
                                                                       integrates visual, phonological and functional information
  Eye-tracking studies in which participants are presented             within a central resource, replicated the intricate time course
simultaneously with spoken language and visual input (i.e.             dynamics of eye fixation behavior reported in Huettig and
the visual world paradigm, Tanenhaus et al., 1995) have                McQueen (2007). The model highlights the role of
shown that information retrieved via both modalities is                differences in the computational properties of each
mapped at multiple levels of representation. Allopenna et al.          modality’s representational structure, demonstrating that
(1998), for instance, presented participants with spoken               such differences are sufficient to produce behavior
words such as beaker and objects whose names contained                 consistent with multimodal effects reported in the Visual
word-initial or word-final overlapping phonological                    World Paradigm.
information (e.g., beetle, speaker) together with                         The question of how differential representational qualities
phonologically unrelated objects (e.g., carriage). They found          of phonological and semantic properties affect word
that eye-movements were more likely to be directed to the              processing can also be approached by studying individual
phonologically related objects than to unrelated objects,              differences. Specifically studying participant populations
indicating that during speech processing, phonologically               that differ in the form of representation of each modality
related representations were co-activated and mapped onto              that they bring to the task. People with different levels of
phonological representations retrieved from viewing the co-            literacy are a critically important population in this regard.
present visual objects (see Huettig & McQueen, 2007, for               There is a well-established link between fidelity of
further discussion). Related paradigms have demonstrated               phonological representations of words and development of
that semantic competitors are also co-activated during
                                                                   3420

literacy (Hulme et al., 2012). Participants who are literate         of the auditory presentation of the word to the model,
perform better at phonological segmentation or phoneme               predicting that a segmented phonological representation
awareness tasks (Bowey, 2005), and there have been                   would result in early phonological competitor effects, but
proposals both that literacy causes such improvements in             that less individuated phonological representations,
phonological processing (Castles & Coltheart, 2004;                  consistent with accounts of phoneme awareness impairment
Morais, Cary, Alegria, & Bertelson, 1979), as well as                in low-literacy groups, would result in reduced, or absent
converse views that effective phonological processing                phonological effects. We also predicted that, consistent with
results in improved reading (Muter, Hulme, Snowling, &               the behavioural data, the later semantic competitor effects
Stevenson, 2004). An influential processing model in this            would be observed for the model regardless of the
literature is that experience of written forms of words results      granularity of the auditory input to the model.
in a change in the granularity of the phonological processing          In order to isolate the effect of the granularity of auditory
of a word (Ziegler & Goswami, 2005), such that exposure to           processing of the spoken word, we controlled for the overall
written words results in greater awareness of the individual         similarity between words in terms of their auditory form,
phonemes of words, and without such exposure, listeners              but varied whether the similarity was compositional and at
are more likely to process the sound of a word without a             the phoneme level within the model, whether it was
componential, phonological decoding.                                 sublexical but not at the phonological level, or whether it
   In contrast, effects of literacy on semantic processing           was not sublexical and represented only at the word level.
have been shown to be minimal and appear to be only
quantitatively rather than qualitatively different (Da Silva et                                Method
al., 2004; Reis & Castro-Caldas, 1997). Thus, literacy
appears to affect lexical processing in a modality-specific          Model
manner.                                                              The models described in this paper are based on the model
   In a recent study, Huettig, Singh and Mishra (2011)               of language mediated eye-gaze presented in Smith,
compared phonological and semantic competitor effects for            Monaghan and Huettig (in press). The general architecture
Indian participants who had high and low levels of literacy          of the model is shown in Figure 1.
due to poverty or other socioeconomic factors (but no
known neurological or cognitive deficits), enabling a direct
test of the extent to which the granularity of the
phonological form of a word affects performance. In their
study (Experiment 1), participants viewed a scene
comprising objects representing a phonological onset
competitor, a semantic competitor, and two unrelated
distractors, and heard the target word spoken in a sentence
context. They found that participants with low levels of
literacy demonstrated no effects of phonological
competitors, but substantial effects of semantic competitors
when hearing words. In contrast, the participants with high
levels of literacy were similar to the participants in a similar
study with Dutch high literates (Huettig and McQueen,
2007) – demonstrating early looks towards objects named
by phonological competitors and later looks toward
semantic competitors.                                                                Figure 1: Network Architecture.
   We note that looks to the semantic competitors in the
Huettig et al. (2011) study were reduced for the low literacy        Architecture The network consists of four modality-
group, which is consistent with accounts of a general                specific layers which were fully connected to a central
processing deficit (cf. Salthouse, 1996), and we return to           resource consisting of 400 units (see Figure 1). The model
this issue in the Discussion section.                                implements a hub-and-spokes model of multimodal
   We adapted our previous multi-modal model of fixation             integration, with input visual, auditory and semantic
behavior in the visual world paradigm (Smith, Monaghan, &            information about words, and output behavior of an “eye”
Huettig, in press) to test the explanatory adequacy of the           layer which indicates the direction of the attentional focus of
hypothesis regarding granularity of phonological processing          the model as a consequence of the combination of the modal
relating to different levels of literacy. We simulated the           inputs.
conditions of the experimental study by presenting visual              The vision layer (80 units) simulated the extraction of
object representations of phonological and semantic                  visual information from the surrounding environment,
competitors, and two unrelated words and tracking the                providing visual input to the system. It was divided into four
model’s fixation of each of these objects as presentation of a       slots, each defined by 20 processing units. Each slot
target word unfolded. We adjusted the level of granularity           corresponded to the visual information available at each of
                                                                     four possible locations within the visual field. The vision
                                                                 3421

layer was fully connected in a forward direction to the                distinct words. Semantically similar pairs of words each
integrative layer.                                                     shared 4 of the 8 active units representing each item.
  Similarly the auditory layer provided input from the                    To simulate different grain-sizes of speech representation,
auditory modality, simulating the extraction of spoken                 three forms of auditory input were constructed, but with the
information from the speech signal over time. The auditory             overall similarity between representations controlled.
layer was also fully connected to the central integrative                 For the fine grained auditory processing, representing
layer in a forward direction.                                          phonological segmentation of the spoken word by the
  The semantic layer consisted of 160 units, allowing the              listener, words were encoded as six phonemes, with
network to represent semantic features associated with a               phonemes implemented as sets of 10 units, from which five
given object or spoken word. The semantic layer was fully              units were active. All words within the corpus were
connected to the integrative layer with activation flowing             composed of phonemes taken from an inventory of 20
both from integrative units to semantic units and also back            possible phonemes. To present the word an additional
from semantic to integrative units.                                    phoneme from the target word sequence was presented to
  The eye layer, to reflect the viewing behavior of the                the auditory layer at each time step.
system, was also fully connected in both a forward and back               To simulate sublexical representations of a coarser grain
direction to the central integrative layer. It consisted of four       size (moderate), two 30 unit binary feature vectors were
units, a unit for each location in the visual field represented        created for each word from which 15 units were active.
in the vision layer. Activation of an eye unit was taken as            Coarse grained representations were formed by 60 unit
representing the probability of fixating the location in the           binary feature vectors of which 30 units were active.
visual field associated with the given eye unit.
                                                                               Table 1: Mean cosine similarity of speech signal
Representations An artificial corpus consisting of visual,               representations calculated between targets and distractors.
auditory, and semantic representations for 200 items was
constructed to train and test the network on multiple cross-           Grain Size       Distractor             Signal Overlap (       ,σ)
modal tasks mapping between each of the modalities. A                                       Type           Onset        Rhyme            Word
fundamentalist approach (Plaut, 2002) was taken in the                 Fine            Competitor       .18 (.07)      .50 (.13)       .34 (.07)
construction of representations to ensure all aspects of the                           Unrelated        .50 (.12)      .50 (.12)       .50 (.09)
representations were controlled within the simulations.                Moderate        Competitor       .17 (.08)      .50 (.11)       .34 (.07)
  Visual representations of named objects were                                         Unrelated        .51 (.10)      .51 (.10)       .50 (.07)
implemented as 20 unit binary vectors, with each unit                  Coarse          Competitor       .34 (.10)      .34 (.10)       .34 (.07)
representing the presence or absence of a given visual                                 Unrelated        .51 (.10)      .51 (.10)       .50 (.07)
feature for the object. Each object had approximately 10
units activated, which were selected at random, and                       Visual, semantic and auditory competitors were also
balanced for their distribution across the set of all 200 items.       embedded within the corpora for 40 target items. For visual
  For the semantic representations, each item was                      competitors 10 of 20 visual features were shared with target
represented in terms of 8 units active from a set of 160               items with p = 1, with the remaining features shared with p
semantic features, such that the overall set of semantic               = 0.5. Semantic competitors shared 4 of 8 semantic features
representations were fairly sparse, simulating semantically            with target representations, while unrelated items shared a
                                                                       maximum of 1 semantic property with any other item.
   Table 2: Temporal organization of events in training. Describes input and target representations provided in training trials.
       Task               Visual Input                Auditory Input                   Semantic Layer                       Eye Layer
                        Activity         ts           Activity           ts            Activity            ts           Activity              ts
   Form to      4 items selected at    0 - 14 Time invariant noise    0 - 14  Target: Target's Semantic 3 - 14  Input: Only location of    0 - 14
   Semantics    random from corpus            provided as input               representation                    target active
   Speech to    Time invariant noise   0 - 14 Phonology of target as  0 - 14  Target: Target's Semantic 5 - 14  No constraints on              -
   Semantics    provided as input             staggered input                 representation                    activation
   Speech to    4 items selected at    0 - 14 Phonology of target as  0 - 14  No constraints on             -   Target: Only location of   5 - 14
   Location     random from corpus            staggered input                 activation                        target active
   Semantics    4 items selected at    0 - 14 Time invariant noise    0 - 14  Input: Target's Semantic  0 - 14  Target: Only location of   2 - 14
   to Location  random from corpus            provided as input               representation                    target active
                                                                   3422

Fine grained spoken word competitors were defined by an            visual field. All three categories of model displayed similar
overlap in the initial two components of their speech signal.      levels of performance across all four tasks. In mapping from
For the unrelated items, we ensured that this set of words         speech to semantics, activation of the semantic layer was
did not share more than the first component of the word and        most similar (cosine similarity) to the target item for 100%
that no items shared their initial nor final three components.     of items for all models. When mapping from visual to
For moderate grain size representations 2/3 of the initial 30      semantic representations, activation in the semantic layer
features of a competitor were shared with a target with p =        was most similar (cosine similarity) to that of the target for
1, with remaining features overlapping with p = 0.5.               98% of items in the case of coarse and fine grained models
Controls ensured all initial and final moderate grain vectors      and 97% of items in the case of moderate models. When
were unique. For coarse grain competitors 1/3 of all features      challenged to select the location of a target when presented
were shared with the corresponding target with p = 1, with         with its corresponding auditory representation, the correct
remaining features overlapping with p = 0.5. Defining              location was activated in both the coarse and fine models for
competitors in this way lead to the contrasts in levels of         96% of items and 98% of items for moderate models. All
similarity between representations across corpora as               models displayed equal performance when locating a target
described in Table 1. Although the level of similarity             indicated by the presence of its semantic representation,
between competitor-target and unrelated distractor-target is       selecting the correct location for 99% of items.
consistent across corpora at the word level, the distribution
of overlap varies between implementations as a function of         Simulating Huettig, Singh and Mishra (2011)
grain size.                                                        The following conditions remained consistent across all
                                                                   simulations. Visual input was provided at time step (ts) 0
Model Training The model was trained on four tasks (see            and remained until the end of each test trial (ts 29). We
table 2). Tasks were designed to simulate those performed          report the activation of each unit within the eye layer as a
by participants prior to testing through which associations        proportion of the total activation of all units within this
between representations are acquired. The tasks were to map        layer. This proportion is taken to represent the probability of
from visual representation to semantic representation, from        fixating p(fix), the associated location within the visual
auditory representation to the semantic representation, to         field. Word onset occurred at ts 5, with an additional
activate the eye unit corresponding to the location of the         component of the speech signal presented at each time step
item whose semantic representation is presented, and to            until the entire speech signal had unfolded (ts 10). Auditory
activate the location of the item whose auditory                   input then remains fixed until the end of the test trial.
representation is presented. Tasks were presented on a                To simulate the conditions of Huettig, Singh and Mishra
pseudo random basis with the task of mapping speech to             (2011) experiment 1, input to the models visual layer
location occurring four times less than other tasks. Items         consisted of the visual representations of the target’s
were selected from the corpus and assigned roles (target or        auditory competitor and semantic competitor along with two
distractor) and locations randomly. Initial connection             unrelated distractors. The target word’s auditory
weights were randomized and adjusted during training using         representation was presented as a staggered input to the
recurrent back-propagation (learning rate = 0.05). Training        auditory layer from ts 5. All models (fine, moderate and
was terminated after 850 000 trials.                               coarse) were tested on all 40 test sets embedded within the
                                                                   corpus (target, auditory competitor, semantic competitor and
                           Results                                 two unrelated distractors) in all 24 possible combinations of
In the following sections we report the performance of three       item and location. Figure 2 displays the change in
categories of model 1) Fine, models trained and tested on          p(fixation) from ts 0 for each category of item (Aud =
representations that simulate extraction of fine grained           auditory competitor, Sem = semantic competitor, Control =
structure within the speech signal; 2) Moderate, models            unrelated distractor), averaged across all test trials.
trained and tested on representations that simulate extraction        For analysis ratios were calculated between the proportion
of moderate structure within the speech signal; 3) Coarse,         of fixations to a given competitor and the sum of the
models trained and tested on representations that simulate         proportion of fixations to both the competitor and distractors
coarse grained structure within the speech signal. The             (see Huettig & McQueen, 2007). A value of 0.5 would
following results represent performance averaged across            indicate both items were fixated equally, a value greater
five instantiations of each model. For each instantiation a        than 0.5 would indicate increased fixation of the competitor
new corpus was constructed on which it was then trained            and lower than 0.5 increased fixation of the distractor. Mean
and tested each initialized with a different random seed.          ratios were calculated across items and instantiations.
                                                                      We conducted a 2-way ANOVA on the auditory
Pre-Test                                                           competitor-distractor ratios with model as between-subject
   Once trained all models were tested on their ability to         factor and time as within-subject factor for three
complete each of the four training tasks for all items in the      theoretically-motivated time regions (preview, early and
training corpus presented in all possible locations within the     late). No significant differences were predicted during the
                                                               3423

preview period which refers to the time between display             factor and time as within-subject factor. Again we observed
onset (ts 0) until the first time step in which auditory            a main effect of time, F(2,234) = 230.642, p < .001, eta-2 =
information relating to the target word is able to influence        .663, semantic competitor distractor ratios differed
output layers (ts 7). The remainder of test trials was divided      significantly between preview and early, F(1,238) = 59.607,
equally into two time bins, an early (ts 8 - 18) and a late (ts     p < 0.001 preview and late, F(1,238) = 243.403, p < .001
19 - 29) period as previous research had shown that auditory        and early and late time windows, F(1,238) = 80.562, p <
effects would occur (if at all) during the early but not the        .001. There was no main effect of model nor was there a
late period.                                                        significant interaction between model and time.
                                                                       We then compared whether competitor-distractor ratios
                                                                    differed from chance (0.5) for each time step using one
                                                                    sample t-tests. The probability of fixating the auditory
                                                                    competitor first differed (p < 0.001) from that of the
                                                                    distractor from time step 11 in both fine and moderate
                                                                    models and continued to differ for all subsequent time
                                                                    points. In contrast fixation of the auditory competitor by the
                                                                    coarse model only differed marginally (p < 0.1) from the
                                                                    distractor item in time steps 13 – 17. Fixation of semantic
                                                                    competitors first differed significantly (p < 0.05) from
                                                                    distractor levels at ts 12 and continued to differ for all
                                                                    remaining ts, this was the case for all models.
                                                                                             Discussion
                                                                    Our study aimed to examine the explanatory adequacy of
                                                                    the hypothesis that increased granularity of phonological
                                                                    processing, can account for the differences in fixation
                                                                    behavior between low and high literates observed in
                                                                    Huettig, Singh and Mishra (2011) Experiment 1. Our
    Figure 2: Change in fixation proportions for simulations        simulations demonstrate that increasing the grain size at
     of Huettig, Singh and Mishra (2011) Experiment 1.              which speech is processed can lead to a modulation of
                                                                    phonological effects. A model trained on representations of
   There was a significant main effect of time, F(2, 234) =         speech at the word level displayed only a marginal increase
38.155, p < .001, eta-2 = .246, with auditory competitor-           in fixation towards competitor items that overlapped in an
distractor ratios differing between preview and early time          auditory dimension, whereas models trained on
windows, F(1,238) = 39.387, p < .001, and preview and late          componential, phoneme level representations or moderate
time windows, F(1,238) = 29.202, although there was no              grain size, sublexical components did display a significant
difference between early and late time windows. There was           increase in fixation of auditory competitors. Between model
also a significant main effect of model, F(2, 117) = 4.467, p       comparisons further demonstrated that the coarse grained
= .014, eta-2 = .071, with the fine and medium models               implementation differed significantly from both fine and
resulting in significantly more fixations to the phonological       moderate grain models post word onset.
distractor than the coarse model, means = .544, .544, and              Interestingly, such comparisons did not display a graded
.508, respectively. Critically, there was a significant             effect of grain size, with fine and moderate models not
interaction between model and time, F(4, 234) = 3.582, p =          differing in fixation proportions towards auditory
.023, eta-2 = .058. The quadratic contrast effect for time was      competitors at any stage within test trials. There are two
significant in the interaction, F(2, 117) = 5.074, p = .008,        possible reasons for our failure to observe a graded effect.
eta-2 = .080, indicating that the models were more                  On the one hand, qualitative features of the data hint that
differentiated at the early time steps than during the preview      given a larger corpus and hence test set such effects may be
or later time steps. Models did not differ significantly within     observable. One sample, left tailed t-tests comparing the
the preview period. There was however a significant                 ratio between the proportion of fixations towards auditory
difference between fine and coarse models, F(1, 78) =               competitors in the moderate model and the sum of the
14.373, p < .001, and coarse and moderate models, F(1, 78)          proportion of fixations to the auditory competitor in the
= 9.544, p = .003, in the early time window. The coarse             moderate and fine model indicate a significant difference at
model also differed from the fine F(1,78) = 4.286, p = .042,        ts 13 – 16, (p<0.05), this difference can be observed in
and moderate model F(1,78) = 7.153, p = 0.009, in the later         Figure 2.
time window. No difference was found between fine and                  On the other hand, it is conceivable that illiterates and low
moderate models in any time period.                                 literates rely on very coarse grained structure within the
   A 2-way ANOVA was also conducted on semantic                     speech signal. Although previous studies have shown that
competitor-distractor ratios with model as between subject          illiterates and low literates perform slightly better on
                                                                3424

syllable awareness than on phonemic awareness tasks, they            and the visual world paradigm. Cognition, 96(1), B23-
still tend to perform far worse than proficient readers. This        B32.
may suggest that achieving even moderate granularity of            Huettig, F., and McQueen, J. M. (2007). The tug of war
phonological processing may not be rapid. The results of             between phonological, semantic, and shape information in
our simulations could be interpreted as reflecting that when         language-mediated visual search. Journal of Memory and
a moderate grain size of phonological processing is                  Language. 54, 460–482.
achieved performance improves rapidly and becomes                  Huettig, F., Singh, N., & Mishra, R. K. (2011). Language-
similar to fine-grained models.                                      mediated visual orienting behavior in low and high
   Our results also demonstrate that increased granularity           literates. Frontiers in Psychology, 2, 285.
does not necessarily lead to a decrease in semantic effects as     Hulme, C., Bowyer-Crane, C., Carroll, J.M., Duff, F.J., &
observed in Huettig, Singh and Mishra (2011). Although our           Snowling, M.J. (2012). The causal role of phoneme
simulations indicate phonological effects could be                   awareness and letter-sound knowledge in learning to read:
modulated by an increase in the grain size, an additional            Combining intervention studies with mediation analyses.
mechanism is needed to create the distinction between                Psychological Science, 23, 572-577.
semantic effects observed across populations. A reduction in       Kukona, A., & Tabor, W. (2011). Impulse processing: A
general processing speed in the illiterate population has            dynamical systems model of incremental eye movements
been offered to account for differences in performance on a          in the visual world paradigm. Cognitive Science, 35,
large variety of cognitive tasks (Salthouse, 1996). This             1009–1051.
potentially offers an explanation for a reduction in both          Mayberry, M., Crocker, M. W., & Knoeferle, P. (2009).
auditory and semantic competitor effects. A general                  Learning to attend: A connectionist model of the
processing deficit for low literates, could be implemented by        coordinated interplay of utterance, visual context, and
adding noise across sematic representations, representing a          world knowledge. Cognitive Science, 33, 449−496.
reduction in the fidelity of such representations. Adding          Morais, J., Cary, L., Alegria, J., & Bertelson, P. (1979).
noise in this manner would result in a general reduction of          Does aware- ness of speech as a sequence of phones arise
semantic competitor effects, however it is less clear whether        spontaneously? Cognition, 7, 323–331.
the introduction of noise could also lead to the elimination       Muter, V., Hulme, C., Snowling, M. J., & Stevenson, J.
rather than a general reduction of the phonological effect as        (2004). Phonemes, rimes, vocabulary and grammatical
observed in illiterate performance. As the authors                   skills as foundations of early reading development:
acknowledge, behavior observed in Huettig et al (2011)               Evidence from a longitudinal study. Developmental
suggests that the qualitative changes to the phonological            Psychology, 40, 665–681.
competitor effects and the semantic competitor effects are         Plaut, D. C. (2002). Graded modality-specific specialization
distinct. Teasing apart the factors underlying observed              in semantics: A computational account of optic aphasia.
differences in behaviour between populations is far from             Cognitive Neuropsychology, 19, 603-639.
trivial, however explicit implementations such as the one          Reis, A., and Castro-Caldas, A. (1997). Illiteracy: a bias for
described in this paper provide a means of testing the               cognitive development. Journal of the International
plausibility of proposed explanations.                               Neuropsychological Society. 3, 444–450.
                                                                   Salthouse, T. A. (1996). The processing speed theory of
                         References                                  adult age differences in cognition. Psychological Review
Allopenna, P. D., Magnuson, J. S., and Tanenhaus, M. K.              103, 403–428.
   (1998). Tracking the time course of spoken word                 Smith, A., Monaghan, P., & Huettig, F. (in press).
   recognition using eye movements: evidence for                     Multimodal interaction in a model of visual world
   continuous mapping models. Journal of Memory and                  phenomena. In Computational Models of Cognitive
   Lanugage, 38, 419–439.                                            Processes: Proceedings of the 13th Neural Computation
Bowey, J. A. (2005). Predicting individual differences in            and Psychology Workshop. World Scientific Publishing
   learning to read. In M. J. Snowling & C. Hulme (Ed.),             Company.
   The science of reading: A handbook (pp. 153–172).               Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K.
   Oxford, England: Blackwell.                                       M., & Sedivy, J. C. (1995). Integration of visual and
Castles, A., & Coltheart, M. (2004). Is there a causal link          linguistic information in spoken language comprehension.
   from phonological awareness to success in learning to             Science, 268, 1632−1634.
   read? Cognition, 91, 77–111.                                    Yee, E., & Sedivy, J. C. (2006). Eye movements to pictures
Da Silva, C., Petersson, K. M., Faísca, L., Ingvar, M., and          reveal transient semantic activation during spoken word
   Reis, A. (2004). The effects of literacy and education on         recognition. Journal of Experimental Psychology:
   the quantitative and qualitative aspects of semantic verbal       Learning, Memory, and Cognition, 32, 1−14.
   fluency.      Journal     of      Clinical    Experimental      Ziegler, J. C., & Goswami, U. (2005). Reading acquisition,
   Neuropsychology. 26, 266–277.                                     developmental dyslexia, and skilled reading across
Huettig, F., & Altmann, G. T. (2005). Word meaning and               languages: A psycholinguistic grain size theory.
   the control of eye fixation: Semantic competitor effects          Psychological Bulletin, 131, 3–29.
                                                               3425

