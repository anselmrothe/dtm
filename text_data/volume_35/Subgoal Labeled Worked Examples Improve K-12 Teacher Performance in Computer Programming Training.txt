UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Subgoal Labeled Worked Examples Improve K-12 Teacher Performance in Computer
Programming Training
Permalink
https://escholarship.org/uc/item/170185bh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Margulieux, Lauren
Catrambone, Richard
Guzdial, Mark
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Subgoal Labeled Worked Examples Improve K-12 Teacher Performance in
                                            Computer Programming Training
                                           Lauren E. Margulieux (l.marg @gatech.edu)
                                         Georgia Institute of Technology, School of Psychology
                                                       Atlanta, GA 30332-0170 USA
                                          Richard Catrambone (rc7@prism.gatech.edu)
                                         Georgia Institute of Technology, School of Psychology
                                                       Atlanta, GA 30332-0170 USA
                                              Mark Guzdial (guzdial@cc.gatech.edu)
                                  Georgia Institute of Technology, School of Interactive Computing
                                                       Atlanta, GA 30332-0760 USA
                             Abstract                                   studies, however, have been conducted with undergraduate
                                                                        students in face-to-face learning environments. These are
   Technology has become integrated into many facets of our             not the conditions that would be ideal for K-12 teacher
   lives. Due to the rapid onset of this integration, many current      professional development. The present study explores the
   K-12 teachers do not have the skills required to supply the          effectiveness of the subgoal intervention for K-12 teachers
   sudden demand for technical training. This deficit, in turn,
                                                                        interested in learning computer science in an online learning
   has created a demand for professional development programs
   that allow working teachers to learn computer science so that        environment (i.e., with no face-to-face interaction).
   they might become qualified to teach this increasingly                  Worked examples are an important instructional tool for
   important field. Subgoal labeled worked examples have been           learners in highly procedural domains like math or computer
   found to improve the performance of learners in highly               programming. Worked examples help learners because they
   procedural domains. The present study tested subgoal labeled         provide specific information about how to apply domain
   worked examples in an online learning program for teachers.          principles to problem solving (Bassok, 1990). Furthermore,
   Teachers who received the subgoal labels solved novel
   problems more accurately than teachers who received the
                                                                        worked examples provide a step-by-step solution to a
   same worked examples without the subgoal labels. These               problem from which students can learn before they are able
   findings have implications for the use of subgoal labels in          to solve problems independently (Atkinson, Derry, Renkl, &
   professional development, other types of lifelong learning,          Wortham, 2000). When learners are presented with all of the
   and online learning.                                                 steps of an example solution at once, however, they often
   Keywords: subgoal learning; worked examples; computer                have difficulty determining what information is important
   programming, K-12 teacher training.                                  for solving problems in that domain (i.e., structural
                                                                        information) and what information represents details
                          Introduction                                  relevant for solving only that problem (Catrambone, 1994).
As technology becomes ubiquitous, being technically                        Using subgoal labels to group steps of worked examples
trained is frequently necessary for individuals to be effective         into meaningful units can help learners recognize structural
in their professional and personal lives. Technology has                information in the examples. Subgoals are functional
advanced at such a rapid pace, however, that many of our                components of complex problem solutions; each subgoal is
educators are not qualified to train students in technical              a necessary part of the solution. How a subgoal is achieved
fields. Thus, it is important to train teachers, who have full          might vary between and within problems, but the subgoals
schedules and possibly no technical training, to become                 needed to complete a problem do not. Subgoals are specific
qualified to teach technical subjects. Fortunately, because             to a domain, but not to a problem; a multitude of problems
technical subjects tend to be highly procedural, methods                in a domain might have the same subgoal structure, so by
used for teaching other highly procedural subjects like                 learning the subgoals in a domain, students can learn to
mathematics can be used in technical education.                         solve problems in that domain (Catrambone, 1994).
   One of the methods that has been effective for teaching                 Learners who study materials that label the subgoals of a
procedural domains (e.g., statistics and physics) is to                 worked example are more likely to solve novel problems
manipulate the format of worked examples that students                  than learners who study the same examples without the
receive (e.g., Catrambone, 1996). Catrambone (1998) found               subgoal labels (Catrambone, 1998). There are several
that worked examples that included subgoal labels were                  possible theoretical explanations for this phenomenon.
effective for helping students learn to solve problems in a             Subgoal labels can help learners chunk problem-solving
new domain. This intervention has also been found to be                 steps which might reduce the cognitive load required to
effective for teaching computer programming (Margulieux,                learn them (Catrambone, 1994). Furthermore, subgoal labels
Guzdial, & Catrambone, 2012). Most of these subgoal                     might help learners create mental models in a domain by
                                                                    978

providing them with a framework (i.e., the set of subgoals)
that they can use to organize information in a way that can        Subgoal labeled Materials
guide transfer to future problems (Atkinson et al., 2000,             Handle Events from My Blocks
Catrambone, 1996). Moreover, apprising learners of the             1.   Click on "My Blocks" to see the blocks for components
structure of worked examples can help them recognize                    you created.
similarities among examples and promote self-explanation           2. Click on "clap"
                                                                   3. Drag out a when clap.Touched block
(Catrambone, 1998; Renkl & Atkinson, 2002).
                                                                      Set Output from My Blocks
   Expanding upon previous work (e.g., Catrambone, 1998),          4. Click on “clapSound” and
Margulieux et al. (2012) applied subgoal labeled worked            5. Drag out call clapSound.Play
examples to a previously untested domain, computer                 6. Connect it after when clap.Touched
programming. They found that subgoal labels improved
participants’ performance on novel computer programming             Conventional Materials
construction tasks (i.e., creating applications (apps) for         1.   Click on "My Blocks" to see the blocks for components
Android devices). The present study expands upon this                   you created.
work by testing the intervention in a new environment and          2.   Click on "clap"
with a new population.                                             3.   Drag out a when clap.Touched block
                                                                   4.   Click on “clapSound”
                                                                   5.   Drag out call clapSound.Play
Present Study                                                      6.   Connect it after when clap.Touched
The present study manipulated the materials that K-12
teachers received to help them teach themselves how to                     Figure 2. Sample Materials from Two Groups
program. Participants received either subgoal labeled
worked examples or conventional worked examples (i.e.,              Over four sessions participants learned to make apps
list of the steps of the solution with no labels). The            using App Inventor. In each session, participants received
conventional worked examples were adapted from material           instruction for how to make one app and assessments asking
in the projects sections of the ICE Distance Education Portal     them to modify or make new parts of an app (see Table 1).
(http://ice.cc.gatech.edu/dl/?q=node/641). The subgoals of
the examples were determined using the TAPS procedure                         Table 1: Sections of experimental sessions
developed by Catrambone, Gane, Adams, Bujak, Kline, and
Eiriksdottir (2013) and consultation with subject-matter           Session      1st section       2nd section       3rd section
experts (see Figure 1). The only difference between the            1            Introduction      Instruction       Assessment
materials that participants in the two conditions received         2, 3, 4      Assessment        Instruction       Assessment
was the added subgoal labels (see Figure 2).
                                                                    In the first session, participants learned to make an app
    Subgoal Labels                                                that played sounds when the user interacted with objects on
     1.   Create components                                       the screen. In the second session, participants learned to
                                                                  make an app that selected and displayed text when a button
     2.   Set properties
     3.   Handle events from My Blocks                            was pressed. In the third session, participants learned to
     4.   Set outputs from My Blocks                              make an app that counted the number of times the user
     5.   Define variable from Built-In                           pressed a button in a time frame. In the fourth session,
                                                                  participants learned to make an app similar to the game
     6.   Set conditions from Built-In
     7.   Emulate app                                             Pong.
                                                                    Instructional materials for each app included both a video
                                                                  demonstrating how to make an app and a text guide
      Figure 1. Subgoals Used In Instructional Material           detailing how to make an app. Palmiter and Elkerton (1993)
                                                                  found that videos demonstrating how to complete tasks
   The programming language that was used for the study is        using a direct-manipulation interface can quickly and
Android App Inventor, which is used to develop apps for           naturally teach users how to use the interface. They also
Android devices. App Inventor is a drag-and-drop                  concluded that only watching videos can lead to superficial
programming language; users are given pieces of code that         processing while reading text instructions leads to deeper
they can drag from a menu and piece together in a                 processing. Given that video demonstrations are a useful aid
programming area to make programs. Drag-and-drop                  for learning to complete tasks using an unfamiliar interface
programming languages can be useful for teaching novices          and that text instructions lead to better transfer and retention
because, instead of writing code, users select sections of        for these tasks (Palmiter & Elkerton, 1993), both types of
code and piece them together like puzzle pieces. This type        instruction were used in the present study. Subgoal labels
of code creation is easily understood by novices                  were presented in the videos as callouts to present the
(Hundhausen, Farley, & Brown, 2009).                              information succinctly without overshadowing any verbal
                                                                  instructions (see Figure 3, arrow added).
                                                              979

                                                                    but they had to replace the drum sound with the clap sound
                                                                    and the x-axis acceleration sensor with the y-axis
                                                                    acceleration sensor.
                                                                       Far transfer tasks required participants to follow the same
                                                                    general scheme that they had used in the instructional
                                                                    session but substituted blocks or components of a different
                                                                    type. For example, one task asked participants to program
                                                                    an ImageSprite to move 5 pixels to the right when touched.
                                                                    The steps to do this task were different than the steps in the
                                                                    instructional session because the type of block was different,
                                                                    but the subgoals that needed to be completed were the same.
                                                                       Participants were not permitted to use the video or text
                                                                    guides during the assessment period, but participants were
                                                                    encouraged to use the App Inventor interface to help them
                                                                    complete the assessment tasks. Participants were also
                                                                    allowed to access the apps that they had made during the
                                                                    session to serve as memory cues for the complex procedures
        Figure 3. Sample of Subgoal Callout in Video                they had learned in the session. Participants were instructed
                                                                    to not review instructional material between sessions, so
  To assess participants’ ability to solve problems using           their retention of problem solving procedures could be
App Inventor, participants were asked to write the steps that       measured consistently.
they would take to program new features of an app. These
assessment tasks were developed based on material that                                         Method
participants were exposed to during the sessions, but some
assessment tasks required participants to use aspects of App
                                                                    Participants
Inventor that they had not used before to measure their
ability to transfer their knowledge. Hints were given for           Participants were 18 K-12 teachers recruited through
tasks that required participants to use these unfamiliar            mailing lists for teachers interested in computer science
features. The hints guided participants to the correct features     education. Teachers with prior experience with Android
but did not tell them how to use that feature (see Figure 4).       App Inventor could not participate in the experiment, but
                                                                    they were not restricted by any other prior experience. The
 “1.5 Write the steps you would take to make the screen             teachers had backgrounds that varied on a number of factors
 change colors depending on the orientation of the phone;           such as education, years as a teacher, years teaching
 specifically, the screen turns blue when the pitch is              computer science, level of computer science taught, and
 greater than 2 (hint: you’ll need to make an orientation           professional development completed. There were no
 sensor and use blocks from “Screen 1” in My Blocks).”              correlations between participant performance and prior
                                                                    experience, so this issue will not be discussed further.
  “3.3 Write the steps you would take to create a list of
 colors and make the ball to change to a random color               Procedure
 whenever it collided with something.”
                                                                    The experiment was conducted online with no face-to-face
                                                                    interaction. Instructions and media for the apps were
             Figure 4. Sample of Assessment Tasks                   emailed to participants, and the sessions were hosted on
                                                                    surveymonkey.com. Each SurveyMonkey survey gave
   Two types of assessments were given. One type was                participants instructions for completing the instructional
given at the end of each session and intended to measure
                                                                    session and assessment tasks (first session survey:
participants’ ability to solve novel problems, so it included       http://www.surveymonkey.com/s/RVCWTBX, use “test” as
near and far transfer tasks. The other type was given at the        participant number). Through the survey, participants were
beginning of each session starting with the second session          asked to record how long they spent on each instructional
and intended to measure participants’ retention of problem          session and each assessment task. Participants were also
solving procedures, so it included only near transfer tasks.
                                                                    asked how difficult they thought each instructional session
   Near transfer tasks required participants to follow an
                                                                    and assessment task was on a Likert-type scale from “1-
identical procedure that they had used in the instructional         Very Difficult” to “7-Very Easy.”
session but substituted blocks or components of the same               The experiment comprised four sessions which were
type. For example, one task asked participants to program           given one week apart. The timestamp on the surveys were
the clap sound to play when the phone was tilted up. To             checked to ensure participants completed the sessions at
complete this task, participants could follow the same steps
                                                                    least six days apart. The sessions were similar to those in
that they used in the instructional session to program the          Margulieux et al. (2012) but adapted for online use. The
drum sound to play when the phone was tilted to the right,          major difference between the Margulieux et al. (2012) and
                                                                980

present administration of sessions is that the moderator            Participants were given a point for each subgoal that they
instructions were given through text instead of speech. Each        completed correctly and each subgoal that they attempted.
session taught participants how to make an app using a              Attempting a subgoal was operationally defined as listing at
video and text guide. The video guide showed participants           least one of the steps required to complete the subgoal,
how to create the app, and the text guide gave step-by-step         listing an incorrect step that would achieve a similar
instructions for creating the app. After participants made the      function, or describing the purpose of the subgoal in some
app for that session, they worked on the assessment tasks.          way. Participant responses were scored by multiple raters,
Starting with the second session, participants also completed       and interrater reliability was high with a one-way random
the retention assessment at the beginning of the session            model intraclass correlation coefficient of agreement
before they started making the app (see Table 1).                   (ICC(A)) of .87. There were 32 subgoals across the
   Completion rates for the sessions decreased during the           assessment task solutions, so participants could get a
study with a high level of participation for the demographic        maximum score of 32 for both the attempted and correct
survey and low level for the last two sessions. Though the          problem-solving measurements.
participants volunteered to be in the study, they did not
receive any compensation for their time except instruction          Correct Subgoals
about App Inventor. Additionally, the assessment tasks were         Participants in the subgoal group (n = 9) completed 81%
designed to be difficult in order to avoid a restriction of         more subgoals correctly (M = 26.6, SD = 5.08) than the
range problem caused by all participants performing well.           conventional group (n = 9, M = 14.7, SD = 6.63), F (1, 16) =
Many participants commented that they were frustrated with          18.23, MSE = 34.89, p = .001, ω2 = .53, f = 1.01. These
the tasks. The teachers might have lost motivation to               results mean that 53% of the variance for correct subgoals
complete the sessions without more compensation. Few                was accounted for by group. Furthermore, this is a very
teachers experienced unforeseeable conflicts that ended             large effect size considering the amount of instruction that
their participation. There was not a recognizable pattern that      participants received (i.e., two, 30-45 minute instructional
distinguished participants who completed the study from             sessions). These findings suggest that the subgoal labeled
those who did not. Data from only the first two sessions            worked examples, compared to conventional worked
were analyzed due to low completion rates of the last two           examples, can help people learn more efficiently to solve
sessions.                                                           programming problems.
   These attrition rates are similar to those seen in other            The difference between groups in this experiment is about
online learning environments such as Massive Open Online            twice as large as the difference between groups in
Courses (MOOCs). In an analysis of nearly 500,000 courses           Margulieux et al. (2012), f = 1.01 vs. f = .53, respectively,
taken by over 40,000 students, Xu and Jaggars (2013) found          even though the present study was conducted in a less
that many of the factors that predict success in face-to-face       controlled environment and its participants had more varied
learning environments also predict success in online                backgrounds. Participants in the present study also had as
learning environments (e.g., women were more successful,            much time as they wanted to work on the assessments
and students with higher GPAs were more successful). This           instead of being limited like in Margulieux et al. (2012).
finding suggests that attrition in online courses is similar to        One explanation for this larger effect could be that
attrition in face-to-face courses but on a larger scale.            participants in this study were teachers who volunteered
However, the number of students that online courses can             because they wanted to learn the material to further their
reach is much larger, so the number of students who                 career while participants in the Margulieux et al. (2012)
complete an online course is generally greater than the             studies were undergraduates who were less likely to be
number of students who complete an equivalent face-to-face          motivated to learn the material. Therefore, this difference
course (Whiteman, 2013).                                            could mean that the subgoal intervention is more effective
                                                                    for learners who are motivated to learn the material for the
                  Results and Discussion                            long-term than it is for lab participants who might only try
                                                                    to learn the material for the duration of the experiment.
Each solution of the assessment tasks was deconstructed                Another possible explanation is that the participants in
into the components necessary to complete the solution; that        Margulieux et al. (2012) were students whose skills for
is, the subgoals of the solution. As discussed earlier, the         learning new material were sharper than those of teachers
subgoals are inherent in the solutions, but the tasks did not       who might have been out of school for decades. The
provide any information about which subgoals were                   difference between groups for the undergraduate sample
necessary to complete the solution. Because the solutions           might be smaller than for teachers because the students had
for the assessment tasks are complex, scoring the pieces of         better strategies for studying conventional worked examples
each solution instead of scoring the entire solution as correct     than the teachers. Therefore, undergraduates who received
or incorrect allowed for more sensitivity in the                    the conventional worked examples would have performed
measurement.                                                        better than teachers who received the conventional worked
   Problem-solving performance is represented by two                examples, thereby creating a smaller difference between
scores: a “correct” score and an “attempted” score.                 groups in Margulieux et al. (2012) than the present study.
                                                                981

  For both near and far transfer tasks, the subgoal group            (M = 22.8, SD = 7.19), F (1, 16) = 4.70, MSE = 31.70, p =
completed more subgoals successfully (Near: M = 10.6, SD             .046, ω2 = .23, f = .51. By attempting a subgoal, participants
= 1.94; Far: M = 7.1, SD = 2.26) than the conventional               could be demonstrating that they know the solution needs a
group (Near: M = 5.2, SD = 3.70; Far: M = 3.3, SD = 2.35),           particular component. Therefore, this finding could mean
Near: F (1, 16) = 14.65, MSE = 8.74, p = .001, ω2 = .48, f =         that subgoal participants recognized more of the necessary
.90, Far: F (1, 16) = 12.11, MSE = 5.31, p = .003, ω2 = .43, f       components of the solutions than the conventional
= .82. These results suggest that subgoal labels help                participants regardless of whether they were able to
performance on both near and far transfer tasks. Given the           correctly complete the task.
nature of the near and far transfer tasks, these findings could
mean that the subgoal labels helped participants learn the           Time on Task and Difficulty
material better (near transfer) and apply the material to            There were no statistically reliable differences between the
novel problems (far transfer).                                       groups on the time and difficulty measures (viz., time spent
  On the first end-of-session assessment tasks, participants         on instructional periods, difficulty rating of instructional
in the subgoal group completed 223% more subgoals                    periods, time spent on assessment periods, and difficulty
correctly (M = 9.7, SD = 1.41) than the conventional group           rating of assessment periods; see Table 2). These results
(M = 3.0, SD = 3.02), F (1, 16) = 27.04, MSE = 5.56, p <             suggest that participants in the subgoal group performed
.001, ω2 = .63, f = 1.23. These results mean that 63% of the         better than the conventional group without taking longer to
variance for correct subgoals was accounted for by group.            complete the instructions or tasks and without finding the
On the second end-of-session assessment tasks, participants          instructions or tasks more difficult.
in the subgoal group completed 70% more subgoals
correctly (M = 8.0, SD = 2.83) than the conventional group            Table 2: Difference between groups for time and difficulty
(M = 4.7, SD = 3.57), F (1, 16) = 4.82, MSE = 10.38, p =              measures; time in minutes, difficulty on 7-pt. scale (1-Very
.043, ω2 = .23, f = .50. These results mean that 23% of the                            Difficult and 7-Very Easy)
variance for correct subgoals was accounted for by group.
  The two series of assessments suggest the subgoal group                                  M         M
was better at solving novel problems than the conventional               Category                                      F       p
                                                                                        subgoal     conv
group. Because the effect size of the second assessment was
                                                                         Time on
smaller than that of the first assessment (f = .50 vs. f = 1.23,                          77.3      87.8    37.8      .37     .55
                                                                        Instruction
respectively), the difference between groups might decrease
with repeated exposure to the same type of material. This              Difficulty of
                                                                                           4.9       4.5     1.0      .23     .64
decrease would be expected because as learners gain more                Instruction
knowledge, they are better able to identify important                    Time on
information and need less external guidance. This finding                                 76.6      56.7    33.1     1.44     .25
                                                                       Assessments
suggests that the subgoal labels are fulfilling the purpose for
                                                                       Difficulty of
which they are intended: to highlight the information on                                   4.3       3.8     1.1      .66     .43
                                                                       Assessments
which learners should focus so they can learn more
effectively. Over time, both groups might achieve the same
problem solving ability, but the learners who receive                   This conclusion is supported by linear regression models.
subgoal labels would reach a higher level faster than those          Group (β = .58, p = .005) and time (β = .41 p = .031) are
who do not. This finding does not mean that subgoals are             both significant predictors of correct subgoal score
not valuable later, but it suggests that they are most               suggesting that they account for different parts of the
effective when learners are first introduced to new material.        variance. When predicting attempted subgoal scores, group
  On the start-of-session assessment tasks (i.e., to measure         is no longer a significant predictor, and time (β = .54 p =
retention of problem solving procedures), participants in the        .032) becomes the sole predictor. This model accounts for
subgoal group completed 48% more subgoals correctly (M =             participants who spent relatively little time on the
9.0, SD = 1.70) than the conventional group (M = 6.1, SD =           assessment tasks and did not write solutions (i.e., who did
3.22), F (1, 16) = 6.17, MSE = 6.41, p = .024, ω2 = .27, f =         not attempt to solve the task). Furthermore, group (β = .62,
.57. These results mean that 27% of the variance for correct         p = .002) and difficulty rating (β = .42 p = .024) are both
subgoals was accounted for by group. All of the tasks in this        significant predictors of correct subgoal score suggesting
series were near transfer tasks, so to complete the tasks            that they also account for different parts of the variance in
participants had to use procedures that they had learned in          scores. When predicting attempted subgoal scores, however,
the previous session. This result suggests that the subgoal          group is no longer a significant predictor, and difficulty
intervention promotes retention of the procedures.                   rating (β = .63 p = .009) becomes the sole predictor. This
                                                                     model accounts for participants who did not attempt to solve
Attempted Subgoals                                                   the problems and rated the difficulty of the tasks as high.
                                                                     Due to a high correlation between time on task and
  Participants in the subgoal group attempted 25% more
                                                                     difficulty rating (r = .60, p = .015), these two predictors
subgoals (M = 28.6, SD = 3.50) than the conventional group
                                                                     were analyzed in different models to avoid multicollinearity.
                                                                 982

                        Conclusion                                                         References
   Subgoal labeled worked examples have been effective for          Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.
teaching students to solve problems in procedural domains             (2000). Learning from Examples: Instructional Principles
such as statistics (Catrambone, 1998) and computer                    from the Worked Examples Research. Review of the
programming (Margulieux et al., 2012). Most of these                  Educational Research, 70(2), 181-214. doi: 10.2307/
studies have taken place in a laboratory with                         1170661
undergraduates. The present study extends prior work with           Bassok, M. (1990). Transfer of Domain-specific Problem-
results that suggest subgoal labeled worked examples are              solving Procedures. Journal of Experimental Psychology:
effective for K-12 teachers learning App Inventor in an               Learning, Memory, and Cognition, 16(3), 522-533. doi:
online learning environment. These findings demonstrate               10.1037/0278-7393.16.3.522
that subgoal labels can be effective in a learning                  Catrambone, R. (1994). Improving examples to improve
environment outside of the laboratory with a different                transfer to novel problems. Memory and Cognition, 22,
population of learners.                                               605‐615. doi: 10.3758/BF03198399
   It is encouraging that the subgoal intervention improved         Catrambone, R. (1996). Generalizing solution procedures
online learners’ performance. The purpose of labeling                 learned from examples. Journal of Experimental
subgoals in worked examples is to succinctly give the                 Psychology: Learning, Memory, and Cognition, 22, 1020-
learner extra information to help them recognize the                  1031. doi: 10.1037/0278-7393.22.4.1020
structure of the example. This type of extra information is         Catrambone, R. (1998). The subgoal learning model:
what an instructor, who is an expert in the subject matter,           Creating better examples so that students can solve novel
might ideally provide to students in face-to-face instruction.        problems. Journal of Experimental Psychology: General,
Unfortunately, instructors are not always aware that they             127, 355-376. doi: 10.1037/0096-3445.127.4.355
should provide this extra information, and even if they are         Catrambone, R., Gane, B., Adams, A., Bujak, K., Kline, K.,
aware, they do not necessarily know how to impart the                 & Eiriksdottir, E. (2013). Task Analysis by Problem
information. In an online learning environment in which               Solving (TAPS): A Method for Uncovering Expert
students rarely interact with an instructor, such as the one in       Knowledge. Unpublished manuscript, Georgia Institute
this experiment, this extra information needs to be built into        of Technology, Atlanta, GA.
the instructions. Extra information could increase learning         Hundhausen, C. D., Farley, S. F., & Brown, J. L. (2009).
time. However, the present study demonstrates that, in the            Can direct manipulation lower the barriers to computer
absence of an instructor, subgoal labeled worked examples             programming and promote transfer of training?: An
provide enough extra information to help students learn               experimental study. ACM Transactions in CHI, 16(3).
more effectively without increasing the amount of time                doi: 10.1145/1592440.1592442
students take to learn.                                             Margulieux, L. E., Guzdial, M., & Catrambone, R. (2012).
   The results of the experiments also imply that the subgoal         Subgoal-labeled     instructional     material  improves
intervention can be effective for populations other that              performance and transfer in learning to develop mobile
undergraduates. The sample in the present experiment was              applications. In Proceedings of the Ninth Annual
heterogeneous in terms of age, education, and experience, so          International Conference on International Computing
the amount of variance in the participants’ performance               Education Research, 71-78. doi: 10.1145/2361276.
scores that was accounted for by experimental group (over             2361291
50% in some cases) was surprisingly large. This finding can         Palmiter, S., & Elkerton, J. (1993). Animated
justify the use of resources to implement subgoal                     demonstrations for learning procedural computer-based
interventions in professional development, classrooms, and            tasks. Human-Computer Interaction, 8(3), 193-216.
other instructional environments, including those online.             doi:10.1207/s15327051hci0803_1
   The present study demonstrates that subgoal labeled              Renkl, A., & Atkinson, R. K. (2002). Learning from
worked examples can be an effective intervention for                  examples: Fostering self-explanations in computer-based
teaching highly procedural domains outside of the                     learning     environments.        Interactive   Learning
laboratory. Additional experiments can examine the                    Environments, 10(2), 105-199. doi: 10.1076/ilee.10.2.105.
intervention in a variety of learning environments.                   7441
                                                                    Whiteman, W. (April, 2013). MOOCs in engineering
                    Acknowledgments                                   education. Presented at the meeting of American Society
   Our thanks to Georgia Tech's GVU Center and IPaT for               of Engineering Education Georgia Tech Chapter, Atlanta,
the grant that made this research possible. We also thank             GA.
Barbara Ericson for her consultation and Andrea Crews for           Xu, D., & Jaggars, S. S. (2013). Adaptability to online
help scoring data.                                                    learning: Differences across types of students and
                                                                      academic subject areas (CCRC Working Paper No. 54).
                                                                      Teachers College, Columbia University.
                                                                983

