UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gaze strategies in object identification and manipulation
Permalink
https://escholarship.org/uc/item/9hf8c6sf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Belardinelli, Anna
Butz, Martin V.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                        Gaze strategies in object identification and manipulation
                                Anna Belardinelli (belardinelli@informatik.uni-tuebingen.de)
                                        Department of Computer Science, University of Tübingen,
                                          Martin V. Butz (martin.butz@uni-tuebingen.de)
                        Department of Computer Science, Department of Psychology, University of Tübingen,
                                                      Sand 14, Tübingen, 72076 Germany
                              Abstract                                     and more complex behaviour than scanning. Strategies like
                                                                           ’look-ahead’ and ’just-in-time’ fixations (Hayhoe et al., 2003;
   Task influence has long been known to play a major role in the
   way our eyes scan a scene. Interestingly, how the task modu-            Ballard, Hayhoe, & Pelz, 1995) support the idea that vision
   lates attention when interacting with objects has been less in-         is deeply intertwined with the needs of motion planning and
   vestigated. Only few studies have contrasted the distribution of        supervising.
   eye fixations during viewing and grasping objects. How is at-
   tention differently deployed when different actions have to be             Further, in the context of the theory on the duplex nature
   planned on objects in contrast to a purely perceptual viewing           of vision (Goodale & Milner, 1992), distinct neural pathways
   condition? To investigate these issues, we conducted an eye-            subserving the different functional demands of object cate-
   tracking experiment showing participants 2D images of real-
   world objects. In blocks of trials, participants were asked ei-         gorization and object manipulation were suggested. This dis-
   ther to assign the displayed objects to one of two classes (clas-       sociation between vision-for-action and vision-for-perception
   sification task), to mimic lifting the object (lifting task), or to     has often been investigated by means of grasping tasks con-
   mimic opening the object (opening task). Mean fixation lo-
   cations and attention heatmaps show different modes in gaze             trasted to perceptual judgement tasks, with visual illusions or
   distribution around task-relevant locations, in accordance with         in covert attention settings (Goodale, 2011), but contrasting
   previous literature. Reaction times, measured by button release         evidence has emerged and it seems reasonable to assume a
   in the manual response, suggest that the more demanding the
   task in terms of motor planning the longer the latency in move-         strict interaction between the two systems.
   ment initiation. Results show that even on simplified, two di-             How the differences between perceptual and motor task are
   mensional displays the eyes reveal the current intentions of the
   participants. Moreover, the results suggest elaborate cognitive         reflected in eye-movements has been less investigated. In a
   processes at work and confirm anticipatory behavioral control.          seminal paper for eye-hand coordination, Johansson, West-
   We conclude with suggesting that the strongly predictive in-            ling, Backstrom, and Flanagan (2001) recorded both eye- and
   formation contained in eye movements data may be used for
   advanced, highly intuitive, user-friendly brain-computer inter-         hand movements data during a motor task involving grasping
   faces.                                                                  a bar, avoiding an obstacle, touching a goal position and plac-
   Keywords: Eye-tracking, object interaction, fixation distribu-          ing the bar back. Subjects almost exclusively fixated land-
   tion, eye-hand coordination, movement preparation                       mark positions on the bar or in the experimental set-up, be-
                                                                           fore making contact to them. The preparation of an action
                           Introduction                                    upon an object defines an attentional landscape (Baldauf &
Since the early works of Buswell (1935) and Yarbus (1967)                  Deubel, 2010), (covertly) encoding in parallel locations rele-
top-down, task-related guidance has been shown to strongly                 vant for the subsequent serial motor execution.
influence the way people move their gaze upon pictures. In                    This evidence suggests that visual cues are sought and
the second study, depending on the question asked, differ-                 weighted differently depending if the task is a skilled move-
ent patterns of scanning were observed. Such an influence is               ment or a perceptual judgement. Gaze behaviour in viewing
so critical that, as soon as a specific task is given, low-level,          and grasping was investigated by (Brouwer, Franz, & Gegen-
bottom-up visual saliency is basically overridden and plays                furtner, 2009) and (Desanghere & Marotta, 2011). The first
quite a minor role in explaining eye fixations w.r.t. higher-              ones used simple geometric shapes to be simply viewed or
level cognitive factors (Henderson, Brockmole, Castelhano,                 grasped, while in the latter study Efron blocks were used and
& Mack, 2007; Einhäuser, Rutishauser, & Koch, 2008). Sim-                 in the viewing condition a perceptual judgement had to be
ilarly, moving from pictures to real-world scenes and to tasks             made. In both cases, the viewing condition produced first
involving motor actions, it is even more striking how eye                  fixations closer to the center-of-gravity (COG) of the object
movements are precisely planned to provide information for                 (in accordance with (Foulsham & Underwood, 2009), among
the execution of the current piece of action. This has been                others), while the grasping condition was characterized by
shown in different settings, from tea-making (Land, Mennie,                first fixations closer to the index finger location (or to the
& Rusted, 1999) to sandwich-making (Hayhoe, Shrivastava,                   more difficult to grasp location).
Mruczek, & Pelz, 2003) to a wealth of other more or less                      In this paper, we present an experiment building on that
complex motor tasks (Land & Tatler, 2009). In this case, any-              of Brouwer et al. (2009). The main novelty of our approach
way, the nature of attention deployment is quite different. The            is the use of real object stimuli (displayed on a monitor) and
purpose of vision is here indeed less to get sense of the scene            the comparison of three simple but realistic tasks, one ’pas-
and more to direct effectors and coordinate a much slower                  sive’ (classification) and two ’active’ (lifting and opening).
                                                                       1875

We were interested in investigating to what extent eye move-
ments subserve and anticipate the task demands, in the form
of information collection for movement planning, and the re-
lation to affordances (Gibson, 1979). This relation was ex-
pected to show in different scanning strategies determined by
the different landmarks associated to each task. Even though
the interaction with real objects in our daily life heavily re-
lies on depth perception, Westwood, Danckert, Servos, and
Goodale (2002) showed how subjects can effectively program
actions to 2D pictures, suggesting that the dorsal stream does
not critically rely on binocular information for prehension
movements (see also (Kwok & Braddick, 2003)). This turned
out to be the case in this study, where indeed familiar objects
were used and the scanning patterns were similar to those de-
scribed for real objects.
                        Experiments
We conducted a main eye-tracking experiment and a paral-                    Figure 1: Stimuli pictures used in the experiment.
lel experiment aimed at extracting Regions Of Interest (ROI)
from every stimulus in every condition. This was done to
                                                                     Eye movements were recorded via a binocular remote eye-
have an objective measure of the contact point regions that
                                                                     tracker (EyeFollower, LC Technologies) working at 120 Hz.
would be chosen for an actual grasp instead of arbitrarily
                                                                     A keyboard was placed between the chin rest and the mon-
choosing some expected ROIs. Both experiments are detailed
                                                                     itor to record reaction times. Participants had to look at the
in the following subsections.
                                                                     same stimuli with three different tasks in mind – each in one
Participants                                                         block. The task order was randomized across participants, so
                                                                     was the stimulus order within each block. For each task, ev-
Eleven participants (6 women, 5 men, aged 22-41) carried out         ery object was presented five times, resulting in 210 trials per
the eye-tracking experiment in all 3 conditions (task). One          participant. For training purposes, 30 more test trials were
female participant’s data was discarded because of very bad          conducted on 2 other objects before the main experiment.
quality. All subjects were right-handed with corrected to nor-          In the classify task, participants were asked to look at the
mal vision. Ten different (4 men, 6 women, aged 18-41) par-          presented object and to decide whether it could contain liquid
ticipants carried out the ROI extraction experiment. All of          or not. The response was given by a left/right arrow key press.
them were confirmed right-handed. In both experiments par-           This served the purpose of both having participants looking
ticipants were compensated with study credits or money.              at the objects each time and making a manual response as in
Stimulus material                                                    the other conditions. In the lift condition, participants had to
                                                                     reach to the screen and to mimic lifting the presented object in
Stimuli were chosen from the ALOI dataset (Geusebroek,               front of the screen. Analogously, in the open condition, they
Burghouts, & Smeulders, 2005), containing pictures of 1000           reached to the screen and mimicked opening the object. They
daily-use objects in different light/view conditions. 14 ob-         were instructed to use only the right hand. To grasp objects,
jects (plus 2 test objects) were chosen such that all of them        they were asked to always perform a grasp frontally, either
could be easily lifted and had an opening part. They are             with the thumb rightwards or downwards or by the handle,
all portrayed in a frontal view against a black background.          where present. As to the opening, they were told to imagine
Six objects are displayed upright, six lie horizontally with the     that the objects were glued to the shelf so they could open
opening part on the right. Two objects present a handle on the       them with just one hand. They were asked to execute the
right and the opening on the top. All 14 stimuli are showed          movement as naturally as possible and to act on the object ac-
in Fig.1. Each picture is 768 × 576 pixels. In each condition        cording to the perceived size1 . In each trial, participants were
they were presented at mid-height on the right of the screen.        asked to press the spacebar until they were ready to execute
                                                                     the proper response. Each trial proceeded as follows: 1) the
Apparatus and Procedure
                                                                     task (classify/lift/open) is displayed as a reminder at the cen-
Participants sat in front of the screen, where the object stim-      ter of the screen for 1.5 s; 2) the fixation cross is presented
uli were presented. In the eye-tracking experiment their head        for at least 1 s (or as long as the space bar is not pressed); 3)
was resting on a chin rest, about 70 cm away from the mon-
                                                                         1 The
itor, 1680 × 1050 pixels, subtending 45.3◦ × 28.3◦ of field                    displayed object stimuli were all of the same size, so that
                                                                     objects were presented larger or smaller than they typically are in re-
of view. Stimulus pictures subtended 20.7 ◦ , with the center        ality. However, this scaling was not excessively pronounced so that
of the picture lying at 12.3◦ from the center of the monitor.        the action to perform was still plausibly and naturally performable.
                                                                 1876

the stimulus appears on the right side of the screen; 4) Phase                                     Results
A: eye data and reaction times are collected up to the release         Heatmaps
of the space bar; 5) Phase B: eye data collected during the
                                                                       As a first qualitative impression of the general patterns of be-
execution of the motor response; 6) the hand goes back to the
                                                                       havior observed in the three examined conditions, we com-
spacebar and the next trial starts.
                                                                       pared heatmaps obtained from fixations of phase A, from first
   In the ROI extraction experiment, the same objects were             3 fixations (in total and separated) and for the mean of the
presented to different participants. In just 2 blocks (lifting and     first 3 fixations. The same pattern was shown at different ex-
opening), they were asked to place the tips of their fingers on        tents across all maps and objects, namely a maximum left of
the object, picturing the requested action. These points were          the object center in the ’classify’ condition, a slightly higher-
recorded via a touch screen. After each trial, the participant         left of the center maximum in the ’lift’ condition and a clear
was shown the selected points and, if not satisfied, she could         maximum on the opening region in the ’open’ condition. Fig.
repeat the trial. Every object was presented 3 times per block,        2 shows the phase A maps for one of the up-right objects
resulting in 84 trials total per participant.                          and one of the horizontal objects. Already in phase A, task-
                                                                       dependent differences in eye fixations are evident.
Data Processing and Analysis
Fixations for the phase A and B were extracted for each trial
via the dispersion algorithm (Salvucci & Goldberg, 2000)
with a temporal threshold of 100 ms and a spatial disper-
sion threshold of 1.5◦ . Data collected during phase A are
supposed to be indicative of the information extraction and
motor planning preceding movement initiation. Still, since in
many cases there was just one or even no phase A fixation on
the stimulus, quantitative evaluations were done on the first 3        Figure 2: Heatmaps of the phase A fixations superimposed
fixations (or up to the third fixation) and on the mean of these       on corresponding stimuli. From left to right: ’classify’,’lift’
first three fixations. This choice was motivated by the consid-        and ’open’ condition.
eration that 3 fixations amount to about 1 s of stimulus pre-
sentation, sufficient to retrieve necessary visual information
and start the movement (according to reaction times), while
later fixations could be more arbitrary and dependent on the
subjects’ preference and interest for the object. For qualita-
tive evaluation and informative visualization, heatmaps were
computed from fixation data. These were obtained by placing
a Gaussian with σ = 1◦ , centered on each fixation and height
proportional to the duration of the fixation, so that longer fix-
ations would be weighted more in the heatmap surface. Each
map was scaled between 0 (not fixated) and 1 (longest fix-
ated) to make maps comparable. Regions of interest were
extracted considering the distribution of the finger points in
each condition. In the ’open’ condition, points were com-
pactly concentrated around the opening region, hence mean
and variance of the point coordinates sufficed to identify a
rectangle containing the underlying region. In the case of             Figure 3: Heatmaps of the first, second and third fixation (left
’lift’, points were more evidently multi-modal, resulting in           to right). From top to bottom: ’classify’,’lift’ and ’open’ con-
two major clusters one, smaller, for the thumb and one for the         dition.
rest of the fingers. To include both clusters in the ROI, points
were clustered via k-means, and a rectangle containing the                An evolution in time across the first 3 fixations/conditions
region underlying both clusters was identified (see Fig.6, left,       for one object is presented in Fig.3. If the first fixation is usu-
for an example of extracted ROIs). In most objects the two             ally close to the COG (with some undershoot) for all condi-
ROIs were well-separated. In a few cases, they were slightly           tions, already by the second fixation is possible to infer where
overlapping and just in one case there was a major overlap.            the scanpath will lead. The first fixation was a ’phase A’ fix-
This, nevertheless, did not hamper the comparison with the             ation in 90% of cases, the second fixation in 53% , while the
heatmaps.                                                              third just in 28%. Of 5733 examined fixations, 3359 were
                                                                   1877

phase A. While for the first fixation phase A fixations are                       The mean Y coordinates according to object and task are pre-
equally distributed across tasks (1832 A fixations, 34% clas-                     sented in Fig. 5. In this case the ordinate is expressed in
sify, 32% lift, 34% open), in the second the proportion is in                     image coordinates, with origin in the top left corner. Up-right
favor of lifting and opening (1037 A fixations, 24% classify,                     objects (such as the green can or the chips tube) present of
33% lift, 43% open), by the few third A fixations mostly for                      course the most extreme mean vertical location for the ’open’
the ’active’ tasks motion had not yet initiated (490 A fixa-                      task, while for horizontal objects the mean y location is al-
tions, 17% classify, 38% lift, 45% open).                                         ways at the same height with a slight tendency upwards in the
                                                                                  ’lift’ condition.
Average Fixations
The mean of the first three fixations (or up to 3) on each stim-                                                                                          object
ulus image was extracted for each trial. Often the first fixation                                                                                        spice bottle
                                                                                                                                                         basket
was in the direction of the COG of the object but landed ei-                                                                                             deo roll
                                                                                                                       400.00
                                                                                                                                                         cigarette box
ther on the black background or on the edge of the object,
                                                                                     mean Y of the first 3 fixations
                                                                                                                                                         coffee jar
                                                                                                                                                         baby food jar
hence showing some undershoot along the x-axis (we use im-                                                                                               gel tube
age coordinates since the objects are not shown in a com-                                                                                                white jar
                                                                                                                                                         orange tea pot
pletely frontal view but in perspective, hence the center of the                                                       300.00                            green can
                                                                                                                                                         chips tube
object outline would not correspond to the COG). A repeated                                                                                              juice bottle
                                                                                                                                                         ceramic pot
measures ANOVA on the x coordinate of the average fixa-                                                                                                  yellow tea pot
tion with task and object as within-subject factors showed a
                                                                                                                       200.00
main effect of task (F(2, 18) = 36.9, p < .001), a main effect
of object (F(13, 117) = 19.87, p < .001), and and interac-
tion effect of object and task (F(26, 234) = 13.73, p < .001).
The mean X coordinates according to object and task are pre-                                                           100.00
sented in Fig. 4. For most objects, the ’classify’ mean posi-                                                                   classify   lift   open
tion was the most left and the ’opening’ the most right. This                                                                              task
is of course more extreme for horizontal objects, e.g, the gel
tube, the white jar, the juice bottle, while for three up-right
objects (yellow tea pot, orange tea pot, and chips tube) the                      Figure 5: Mean Y coordinate of each object across task. Note
lifting mean position is to the right of the opening position                     that the y axis is in picture coordinates, hence the lower the
either because the handle was on the right or the plastic lid                     value the higher the location in the picture.
was best opened by exerting force with the right thumb.
                                                                                  Comparison Heatmaps-ROI
                                                                  object
                               500.00
                                                                 spice bottle
                                                                                  To gain a more specific insight regarding to what extent the
                                                                 basket           fixation map can predict the region on which the motor ac-
                                                                 deo roll
                               450.00                            cigarette box    tion is performed, we compared the ROIs extracted for the
                                                                 coffee jar
                                                                 baby food jar    two ’active’ conditions with the peak of the corresponding
    mean X first 3 fixations
                                                                 gel tube
                               400.00                            white jar        heatmaps achieved considering the first three fixations (see
                                                                 orange tea pot
                                                                 green can        Fig.6). The peak of the fixation map (where the map has value
                                                                 chips tube
                               350.00                            juice bottle
                                                                                  1) consistently falls within the corresponding ROI. The mean
                                                                 ceramic pot
                                                                 yellow tea pot
                                                                                  distance between the peak and the center of the ROI for the
                               300.00
                                                                                  ’lift’ condition was 91.1 ± 59.52 pixel, while for the ’open’
                                                                                  condition was 63.2172 ± 35.53. In both conditions the dis-
                               250.00
                                                                                  tance between the peak and the center of the corresponding                              P
                                                                                  ROI was always smaller than that to the center of the other
                                                                                  ROI (one-tailed t-test, p < .001).
                               200.00
                                        classify   lift   open                    Reaction Times
                                                   task
                                                                                  Mean reaction times in releasing the spacebar significantly
                                                                                  increase from ’classify’ to ’lift’ to the ’open’ condition. The
  Figure 4: Mean X coordinate of each object across task.                         difference is most pronounced between ’passive’ and ’active’
                                                                                  conditions (classify: 0.596 ± 0.052s, lift: 0.805 ± 0.126s,
   An analogous analysis was performed on the vertical mean                       open: 0.826 ± 0.110s). A repeated measures ANOVA on
location. Again the effect of task was significant (F(2, 18) =                    the average reaction time with task and object as within-
51.58, p < .001) as that of object (F(13, 117) = 134.02,                          subject factors showed a main effect of task (F(2, 18) = 7.04,
p < .001) and interaction (F(26, 234) = 28.13, p < .001).                         p = 0.006) and a main effect of object (F(13, 117) = 2.14,
                                                                            1878

Figure 6: Left: touched points and Regions Of Interest extracted for one of the stimuli (green: ’lift’ condition; magenta: the
’open condition’). Center: heatmap of the first 3 fixations in the ’lift’ condition (in green the center of the corresponding ROI).
Right: heatmap of the first 3 fixations in the ’open’ condition (in green the center of the corresponding ROI).
p = 0.016). The mean reaction times for object and task are            cific attentional landscape around the informative/affording
presented in Fig.7. Three objects (spice bottle, basket, and           points.
yellow tea pot) obtained shorter reaction times for opening               In the classification task, the mean position of the first three
than for lifting, in contrast to the general pattern – possibly        fixations was mostly in the direction of the COG of the object.
because of the size difference compared to the real object,            When grasping an object to lift it, fixations concentrated on a
which made the decision on how to lift the object more dif-            position to the left of and slightly higher than the COG. On
ficult, and because of the particularly obvious opening action         the one hand, it seems reasonable that instead of fixating both
for all three objects. It must be noted that longer reaction           contact points in an alternate fashion, fixating near the center
times in the active tasks may be due not only to motion plan-          of the object allows both contact points to be in the fovea and
ning and affording points selection but also to the extraction         para-fovea, as suggested in (Desanghere & Marotta, 2011).
of 3D information in absence of disparity cues.                        On the other hand, for up-right objects a preference to fixate
                                                                       more on the side of the thumb could be observed, while hori-
                                                        object
                                                                       zontal objects were on average fixated closer to the rest of the
             1.00
                                                      spice bottle     fingers. In the case of the two objects with a handle, there was
                                                      basket
                                                      deo roll         a smaller peak in the center of the object (suggesting a first
                                                      cigarette box
              .90                                     coffe jar        brief fixation there) and a higher mode on the handle, where
                                                      baby food jar
                                                      gel tube
                                                                       later, longer fixations concentrated. In both cases it is possible
                                                      white jar        that due to the objects’ reduced size, subjects first considered
                                                      orange tea pot
              .80
                                                      green can        lifting them with a power grasp and then went for the han-
   mean RT
                                                      chips tube
                                                      juice bottle     dle. In the case of opening, the fixation distribution presented
                                                      ceramic pot
              .70                                     yellow tea pot   a clear peak well localized on the opening region, which re-
                                                                       quired the most processing for the planning of the finer motor
                                                                       operation (usually performed with a precision grip). Even if
              .60
                                                                       the overall distribution of fixations is already indicative, the
                                                                       different patterns in the unfolding of the scanpath are best ap-
              .50                                                      preciable when looking at the temporal evolution of the first
                    classify    lift     open
                                                                       three fixations. The distributions of the first fixation is hardly
                                task                                   distinguishable across tasks, but already by the second fix-
                                                                       ation (at which point the reaching movement often had not
                                                                       been initiated, yet) the task ’signature’ became evident.
  Figure 7: Mean reaction times of each object across task.               These results confirm the general predictive nature of eye
                                                                       movements. Beyond that, however, our data indicate that
                                                                       tracking eye movements may be exploited in even more sub-
                         General Discussion                            tle ways, inferring the exact intention of how a user may in-
The presented experiment was aimed at assessing different              teract with an object. Such discriminability of eye scanpaths
eye movement strategies employed in identifying an object in           according to the intended interaction goal may substantially
contrast to tasks in which actual interactions had to be per-          help in devising machine learning algorithms to timely infer
formed on the object. The distinct tasks as well as the object-        the intention of impaired patients and possibly inform assis-
specific affordance points were expected to strongly influence         tive interfaces to control prosthetic devices without the need
the distribution of eye fixations on each object. Indeed, we           of cumbersome training. The reliability with which the fix-
found significant differences in the scanpath behavior in the 3        ation mode consistently fell within the specific ROI supports
conditions, suggesting for each one the construction of a spe-         considerations.
                                                                  1879

   It seems plausible that the general flow of processing is first       ity enhance distraction? saliency and eye landing position
concerned with locating the object of interest (first fixation           when searching for objects. Quarterly journal of experi-
close to the COG). Next, it moves towards the most informa-              mental psychology, 62(6), 1088–1098.
tive points – either for decision making in the case of the clas-      Geusebroek, J.-M., Burghouts, G. J., & Smeulders, A. W. M.
sification task, or for the purpose of executing anticipatory            (2005). The amsterdam library of object images. Int. J.
behavior control (Hoffmann, 2003; Butz, Sigaud, Pezzulo,                 Comput. Vision, 61(1), 103–112.
& Baldassarre, 2007) towards interaction-relevant points (for          Gibson, J. J. (1979). The ecological approach to visual per-
lifting/opening) with proper behavioral interaction routines.            ception. (Houghton Mifflin)
In the former case, just the ventral system would be involved,         Goodale, M. A. (2011). Transforming vision into action.
pooling resources for recognition and decision-making. In                Vision Research, 51(13), 1567–1587.
the latter, ’active’ conditions, also the dorsal pathway and pre-      Goodale, M. A., & Milner, A. D. (1992). Separate vi-
motor cortical regions would be substantially involved. After            sual pathways for perception and action. Trends in neu-
object localization and recognition, object-relative behavior            rosciences, 15(1), 20–25.
needs to be planned, which involves reference-frame trans-             Hayhoe, M. M., Shrivastava, A., Mruczek, R., & Pelz, J. B.
formations of position, size, and shape and planning of reach-           (2003). Visual memory and motor planning in a natural
ing and grasping motions with properly aligned hand shapes               task. J Vis, 3(1), 49–63.
(Jeannerod, Arbib, Rizzolatti, & Sakata, 1995; Cisek, 2007;            Henderson, J. M., Brockmole, J. R., Castelhano, M. S., &
Herbort & Butz, 2011). The consequentially more elaborate                Mack, M. (2007). Visual saliency does not account for eye
motion planning is also confirmed by significantly longer re-            movements during visual search in Real-World scenes. In
action times when an active motor task, different for every              R. van Gompel, M. Fischer, W. Murray, & R. Hill (Eds.),
object, has to be planned anew.                                          Eye movement research: Insights into mind and brain. El-
   In conclusion, as for more complex behavior, even for                 sevier.
single actions to be performed within the same object, the             Herbort, O., & Butz, M. V. (2011). Habitual and goal-directed
eyes extract visual information in a goal-oriented, anticipa-            factors in (everyday) object handling. Experimental Brain
tory fashion, incrementally revealing the interaction inten-             Research, 213, 371-382.
tions.                                                                 Hoffmann, J. (2003). Anticipatory behavioral control. In
                                                                         M. V. Butz, O. Sigaud, & P. Gérard (Eds.), Anticipatory
                          References                                     behavior in adaptive learning systems: Foundations, theo-
                                                                         ries, and systems (p. 44-65). Springer-Verlag.
Baldauf, D., & Deubel, H. (2010). Attentional landscapes               Jeannerod, M., Arbib, M. A., Rizzolatti, G., & Sakata, H.
   in reaching and grasping. Vision Research, 50(11), 999–               (1995). Grasping objects: the cortical mechanisms of vi-
   1013.                                                                 suomotor transformation. Trends in neurosciences, 18(7),
Ballard, D. H., Hayhoe, M. M., & Pelz, J. B. (1995). Memory              314–320.
   representations in natural tasks. J. Cognitive Neuroscience,        Johansson, R. S., Westling, G., Backstrom, A., & Flanagan,
   7(1), 66–80.                                                          J. R. (2001). Eye-Hand coordination in object manipula-
Brouwer, A.-M., Franz, V. H., & Gegenfurtner, K. R. (2009).              tion. J. Neurosci., 21(17), 6917–6932.
   Differences in fixations between grasping and viewing ob-           Kwok, R., & Braddick, O. (2003). When does the titchener
   jects. Journal of Vision, 9(1).                                       circles illusion exert an effect on grasping? two- and three-
Buswell, G. T. (1935). How People Look at Pictures.                      dimensional targets. Neuropsychologia, 41(8), 932-40.
   Chicago: University of Chicago Press.                               Land, M., Mennie, N., & Rusted, J. (1999). The roles of
Butz, M. V., Sigaud, O., Pezzulo, G., & Baldassarre, G.                  vision and eye movements in the control of activities of
   (Eds.). (2007). Anticipatory behavior in adaptive learn-              daily living. Perception, 28(11), 1311–1328.
   ing systems: From brains to individual and social behavior          Land, M., & Tatler, B. (2009). Looking and acting vision and
   (LNAI 4520). Springer-Verlag.                                         eye movements in natural behaviour. Oxford University
Cisek, P. (2007). Cortical mechanisms of action selec-                   Press.
   tion: The affordance competition hypothesis. Philosoph-             Salvucci, D., & Goldberg, J. (2000). Identifying fixations
   ical Transactions of the Royal Society B: Biological Sci-             and saccades in eye-tracking protocols. Proc. of the 2000
   ences, 362(1485), 1585-1599.                                          symposium on Eye tracking research & applications, 71–
Desanghere, L., & Marotta, J. (2011). ” graspability” of                 78.
   objects affects gaze patterns during perception and action          Westwood, D. A., Danckert, J., Servos, P., & Goodale,
   tasks. Experimental Brain Research, 1–11.                             M. (2002). Grasping two-dimensional images and three-
Einhäuser, W., Rutishauser, U., & Koch, C. (2008). Task-                dimensional objects in visual-form agnosia. Experimental
   demands can immediately reverse the effects of sensory-               Brain Research, 144, 262-267.
   driven saliency in complex visual stimuli. Journal of Vi-           Yarbus, A. L. (1967). Eye movements and vision (1st ed.).
   sion, 8(2).                                                           Plenum Press. Hardcover.
Foulsham, T., & Underwood, G. (2009). Does conspicu-
                                                                   1880

