UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Written Version of Sign Language can Enhance Signing Deaf Individuals’
Comprehension and Learning from Texts

Permalink
https://escholarship.org/uc/item/51z6d3zj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Vendrame, Mara
Cutica, Iaria
Bucciarelli, Monica

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Written Version of Sign Language
can Enhance Signing Deaf Individuals’ Comprehension and Learning from Texts
Mara Vendrame (mara.vendrame@unito.it)*
Ilaria Cutica (ilaria.cutica@unimi.it)°
Monica Bucciarelli (monica.bucciarelli@unito.it)*
*Department of Psychology, Via Po 14, 10123 Turin, Italy
°Department of Economy, Management and Quantitative Methods, Via Conservatorio 7, 20132 Milan, Italy

Abstract
Deaf individuals have difficulties in comprehending written
text, as well as oral language. As a consequence, learning from
text is compromised in deaf individuals. We hypothesized that
a transposition of the Italian Sign Language to its written
counterpart could enhance signing deaf individuals’
comprehension and learning from text. We confirmed our
prediction for comprehension and learning for technical texts
in Experiment 1 and for narrative texts in Experiment 2;
signing deaf individuals’ text comprehension and learning
therefore benefit from a written language whose structure
reflects the structure of their visual-spatial sign language. We
speculate that, for signing deaf individuals, practice in reading
written sign language texts might positively affect the ability
to comprehend the written oral language texts.
Keywords: deaf individuals; text comprehension; learning;
Italian Sign Language

Introduction
Those who are unfamiliar with deafness may assume that
the deaf individuals’ auditory deficit can easily be
circumvented through the use of written communication: if
you have hearing problems, we can easily communicate
through written texts. This naïve assumption disregards the
nature of profound deafness. The ability to understand
written texts presupposes high linguistic competence such
as the ability to integrate information from different parts of
a text and to derive its inner coherence. Due to their
profound hearing loss, prelingually deaf individuals, who
have never experienced oral language, have difficulties in
comprehending the lexical, morphosyntactic, and pragmatic
aspects of written verbal language (Van Hoogmoed et al.,
2011). In addition, compared to hearing individuals, deaf
individuals are less able to comprehend and remember
details from a written text and to reason about the
information contained in it (Marschark & Wauters, 2008).
Their specific difficulty in comprehending the holistic
meaning of written texts seems to derive from difficulties in
connecting different information together and in drawing
inferences (Miller, 2002). Indeed, prelingually and
profoundly deaf individuals possess adequate single-word

reading ability and vocabulary knowledge (Oakhill & Cain,
2000). More generally, deaf individuals’ poor linguistic
competence must be imputed to their atypical cognitive
development (Marschark & Hauser, 2008). For a start, in
hearing individuals, sound plays a role from the earliest
months of life in organizing visual attention: when a new
event is signaled by sound, visual attention may be shifted
appropriately (Smith et al., 1998). Hearing people use
audition to monitor both their immediate and distant
environment for changing events, while allowing vision to
focus narrowly on the task at hand. In deaf individuals, the
limited access to auditory information alters the way visual
attention skills are deployed: visual attention becomes
responsible for both focusing on the task at hand and
monitoring events elsewhere in the visual field (Mitchell &
Maslin, 2007). As a consequence, deaf individuals tend to
adaptively develop a more spatially distributed visual
attention, whereas highly selective visual attention tends to
prove difficult (Bavelier, Dye & Hauser, 2006).
Auditory deprivation also has a direct impact on memory
capacity: when hearing individuals are requested to
remember simple stimuli such as words, pictures, or
numbers, they tend to use a verbal-sequential coding of a
phonological or acoustic nature (Marschark & Mayer,
1998). Deaf individuals appear instead to rely heavily on
visuo-spatial coding: their incomplete mastery of language
skills detracts from using language as an effective cognitive
tool. Consequently, deaf people tend to have a shorter
memory span for linguistic materials, compared to hearing
people (Logan, Mayberry & Fletcher, 1996). By contrast,
deaf people perform as well as or even better than hearing
people on tasks that involve visual or spatial processing
(Cattani, Clibbens & Perfect, 2007).
Furthermore, it has been shown that deaf individuals, in
comparison to hearing individuals, have more difficulty
with abstract reasoning (Marschark & Hauser, 2008). In
particular, they have difficulties in verbal analogical
reasoning, which requires high-level linguistic skills, and
the ability to understand not simple items but complex
structures (Edwards et al., 2010). By contrast, deaf people

3663

are not impaired at perceptually based reasoning: they
perform as well as hearing people on non-verbal cognitive
tasks that do not require the overt use of verbal language,
such as figural-geometric analogy tasks, and in visualspatial information processing (Marschark & Hauser, 2008).
However, deaf individuals’ moderate skills with abstract
reasoning are also due to their broader difficulty with verbal
language (Easterbrooks & Scheetz, 2004).
All this considered, providing deaf individuals with
suitable forms of written materials to support their
comprehension and learning from texts in educational
contexts, is a very important challenge. The focus of our
investigation are signing deaf individuals, who are exposed
to a natural sign language at birth. Sign languages exhibit
grammatical structure at all linguistic levels. However, the
acquisition of sign languages features constraints unique to
the visual modality (Morgan, Barrett-Jones & Stoneham,
2007).

A Written Form of Sign Language
Sign language is visuo-spatial in nature and has no written
counterpart. Some attempt were made to devise appropriate
means for representing sign languages: examples are
Stokoe-based notations for notating single, decontextualised
and standard signs (Pizzuto, Rossini & Russo, 2006), and
Sign Writing, a writing formalism based on transcription of
manual and also non-manual elements of non-standard signs
and complex units through symbols (Sutton, 1999). These
methods require a training to learn to interpret the proposed
notations.
Within a less ambitious perspective, we reasoned that
some of sign language’s features could, however, be
reflected in its transposition to a written form. We assumed
that such a written sign language might improve signing
deaf individuals’ comprehension and learning from text by
promoting the activation of the visual thought schemata that
are activated by the sign language itself (Wilbur, 2000). In
particular, our assumption is based on considerations
concerning the structural features of written sign language
along with the particular cognitive functioning of signing
deaf individuals.
First, the written form of sign language offers deaf
individuals the possibility to process written linguistic
information provided in a syntactic structure that reflects the
structure of the corresponding sign language. In sign
languages, space has a grammatical function, i.e. it is used
to create and maintain cohesion among the different parts of
the discourse (Morgan et al., 2008). Thus, for example,
sentences in sign languages begin by identifying one or
more loci in the spatial mapping, “the process used by the
signer to reflect mental representations in physical space for
reference and subsequent coreference in discourse as a
cohesive device” (Winston, 1995, p.87). Subsequently,

signers point to a precise locus in space in order to evoke to
the interlocutors the element that was originally ‘placed’
there. The particular function of space in sign languages
generates a different discourse structure that has no
counterpart in oral languages (Pyers et al., 2010).
Second, the text of a phrase in an oral language is longer
than the corresponding text in the written sign language
version: the written sign language text, like the sign
language itself, lacks articles, prepositions, conjunctions,
pronouns, and verbal auxiliaries. This claim holds at least
for Italian Sign Language (LIS), which makes little use of
finger spelling. As signing deaf individuals have a shorter
memory span for linguistic material than do hearing
individuals, they should benefit from this feature of the
written sign language.
Third, signing deaf individuals, as compared to hearing
individuals, have a more spatially distributed visual
attention; this cognitive peculiarity, along with the
consideration that a phrase in written sign language is
shorter than the corresponding written phrase from the oral
language, leads to the hypothesis that signing deaf
individuals can extract in a glance more information from
the written sign language text than from the written oral
language text.
We tested the prediction derived from our assumptions on
Italian signing deaf individuals.

Experiment 1: Does Written LIS Facilitate Text
Comprehension in Signing Deaf Individuals?
The deaf participants in the experiment were invited to
carefully read two texts; they were then invited to recall as
much information as they could. Each participant was
presented with one text in Italian and another in LIS. We
predicted a better recall for the LIS text. Hence, although we
did not measure the participants’ reading abilities, we made
each participant act as his/her own control in the two
experimental conditions.

Method
Participants Twelve signing deaf adult individuals (5
females and 7 males; mean age: 26 years) with a prelingual
and profound hearing deficit (>90 dB hearing loss) and no
other disabilities voluntarily took part in the experiment.
They were all university students who learned the LIS as
their first language from their first year of life.
Materials and Procedures The experimental materials
comprised two technical written Italian texts, one
concerning the principles of how airplanes fly (Airplane
flight, 312 words), and one about the effect on individuals
produced by color perception (Responses to color, 315
words) (for excerpt see Appendix 1). For each text, we
produced a written LIS version, parallel to the written

3664

Italian version (266 and 243 words for Airplane flight and
Responses to color, respectively). To create the written LIS
version, a native-speaking signing deaf Italian university
student read each Italian text carefully several times and was
then video-recorded while translating the text into LIS. She
then transcribed the signs produced in the translation into
Italian words. The punctuation was introduced for each
pause, in order to segment the different phrases, taking into
account both manual (signs) and non-manual (facial
expressions and body movements) markers occurring
simultaneously. Consider, for example, the following
excerpt from the Airplane flight written Italian text: “When
an aeroplane is in flight, the air divides as it hits the front of
the wing. Some of it flows over the upper part of the wing,
and the rest over the lower part. The two air flows come
together again behind the wing.” As an example of the
results of the translation, consider the parallel written LIS
version of the excerpt above: “Example, plane flies, wing air
hits wing in front of, then air divided 2, to go wing over, to
go wing under, after air together to go wing behind.”
Obviously, the English translation of the written LIS texts is
not equivalent to the result of transposing the British Sign
Language or American Sign Language texts to their written
counterparts.
The translations of the two Italian texts to written LIS
were evaluated individually by a LIS interpreter and by a
LIS deaf teacher to ascertain that the translations as
provided by a native signing deaf individual were also
acceptable on behalf of them. For the goal of our
investigation, it is important to test the beneficial effect of
the written sign language when realized by a native signing
deaf individual, naïve with respect to trainings and
education to become either an interpreter or a deaf teacher.
At first, the interpreter and the deaf teacher were invited to
watch carefully the two videos, one at a time, and
afterwards they considered each single sign produced,
taking into account both the manual and the non-manual
components. For each semantic unit they were invited to
evaluate the appropriateness and comprehensibility of the
LIS translation through the following judgments: “Not at all
adequate”, “Barely adequate”, “Adequate on the average”,
“Adequate”. On average, the 93% of the semantic units
from the Airplane flight text, and the 96% of the semantic
units from the Responses to color text were judged as at
least “adequate on the average”; none of the translations
were judged as not adequate at all.
The participants encountered both texts (Airplane flight
and Responses to color), one in Italian and the other in LIS.
In each group, half of the participants dealt first with the
Airplane flight text and the other half with the Responses to
color text, so that, overall, the occurrence of each text in the
Italian version and the LIS version was counterbalanced.
The participants were invited to read each text carefully, one
at a time, with no time limits; as soon as they finished
reading each text, they were asked to recall as much

information as they could. The recollection was in LIS. All
of the participants were video-recorded.
To code the results, each text was divided into 41 semantic
units, corresponding to as many main concepts as the hearer
could recall. For each text, there is a strict correspondence
between the semantic units in the two versions (Italian and
written LIS). Two independent judges coded the
participants’ recollections individually; the judges reached a
significant level of agreement on their first judgments for
the overall group of participants in the two experimental
conditions, calculated using Cohen’s K (Cohen’s K ranging
from .87 to .97, p always <.001). For the final score, the
judges discussed each item on which they disagreed, until
they reached full agreement. Each concept (i.e., semantic
unit) recalled by the participants was evaluated according to
the following coding schema (see also Cutica & Bucciarelli,
2008; 2011, Vendrame, Cutica & Bucciarelli, 2010):
Correct recollection: a semantic unit recollected either
literally or as a paraphrase;
Discourse-based inference: a recollection in which the
participant gives explicit information that was originally
implicit in the semantic unit;
Elaborative inference: a semantic unit recollected with the
addition of plausible details;
Error: a recollection whose meaning is inconsistent with the
semantic unit.
Each participants’ recollection was coded as pertaining to
just one category. Correct recollections and discourse-based
inferences were considered indicators of comprehension and
learning from text. Consider, for example, the following
semantic units in the Italian color text: “He observed that
the function deteriorated in low light but increased in bright
light” and the following recollection by a participant:
“Example: bright light finger to tap fast; low light finger to
tap slow; finger to tap normal normal light”. According to
the coding schema, we considered the statements
“Example: bright light finger to tap fast” and “low light
finger to tap slow” as correct recollections, and the
statement: “finger to tap normal normal light” as a
discourse-based inference.
As a further example, considering the semantic unit in the
Written LIS aeroplane text “Wing over this is pressure less”,
the recollection “the air under pressure to increase, it makes
a support, an help” has been coded as a discourse-based
inference, whereas the sentence “the pressure to increase
wing over” has been coded as an error.
Results and Discussion The two texts were comparable in
difficulty; considering each type of recollection separately,
we found no differences in performance with the two texts
in either the LIS or the Italian versions (unpaired T-test:
t(22) comprised between .0 and 1.48, p comprised between
.15 and .1). Hence, we pooled together the results for the
two Italian versions and those for the two LIS versions.

3665

Table 1 illustrates the mean types of recollection for both
the LIS and the Italian versions of the texts. The results
show that they produced more correct recollections and
fewer errors in the written LIS version than in the written
Italian version (T-test: t(11)=3.43, tied p=.003, and
t(11)=3.095, p=.01, respectively), whereas there was no
difference in production of discourse-based (T-test:
t(11)=.82, tied p=.22) and elaborative (T-test: t(11)=0, p=1)
inferences.
Table 1: Mean types of recollection (and standard
deviation in parenthesis) by the participants in Exp. 1.
Signing
deaf
(N=12)
Written
LIS
Written
Italian

Correct
recollections
21.42
(6.00)
16.75
(3.67)

Discoursebased
inferences
.58
(.67)
.33
(.49)

Elaborative
inferences
.08
(.29)
.08
(.29)

Errors

.75
(.75)
2.25
(1.87)

The results of Experiment 1 confirmed our predictions.
Signing deaf individuals benefited from the written LIS
version of the technical texts. However, maybe because of
the considerable technical content of the two texts, we did
not observe a benefit from the LIS versions in terms of
discourse-based inferences, which denote a deep
comprehension of the text (Cutica & Bucciarelli, 2008). A
related, more general question is whether the observed
facilitatory effect of the written LIS versions depends on the
discourse content, be it technical or narrative in nature. The
aim of Experiment 2 was to replicate the findings of
Experiment 1 with narrative texts.

Experiment 2: Does Written LIS Facilitate
Comprehension Independently on the Text
Content?
Experiment 2 set out to replicate Experiment 1 with
narrative texts.

Method
Participants Twelve signing deaf individuals (4 females
and 8 males; mean age: 26 years), university students with a
prelingual profound hearing deficit (>90 dB hearing loss),
took part in the experiment voluntarily. They had learned
LIS as their first language since their first year of life. None
of them had other disabilities, nor had they taken part in
Experiment 1.
Materials and Procedures The experimental materials
comprised two texts, one about the Savannah and one about
Mammals (each text contained 346 words) (for excerpts see
Appendix 2). For each text, we created a written LIS version

(183 and 204 words for the Savannah and the Mammals
texts, respectively), following the same procedures used in
Experiment 1.
As for Experiment 1, the translations of the two Italian
texts to written LIS were evaluated individually by a Italian
LIS interpreter and by a LIS deaf teacher, the same as in
Experiment 1. On average, the 100% of the semantic units
from the Mammals text, and the 99% of the semantic units
from the Savannah text were judged as at least “adequate on
the average”; none of the translations were judged as not
adequate at all.
Each participant dealt with both the Savannah and the
Mammals text, one in Italian and the other in LIS. Half of
the participants dealt first with the Savannah text and the
other half with the Mammals text, so that, overall, the
occurrence of each text in the Italian and the LIS version
was counterbalanced. The participants were invited to read
each text carefully, one at a time, with no time limits. As
soon as they finished reading each text, they were invited to
recall in LIS as much information as they could, during
which time they were video-recorded.
To code the results, the two versions of both texts were
divided into 38 semantic units, corresponding to as many
main concepts as the hearer could recall. As for Experiment
1, for each text (Savannah and Mammals), there is a strict
correspondence between the semantic units in the two
versions (Italian and Written LIS). Two independent judges
coded the participants’ recollections individually; the judges
reached a significant level of agreement on their first
judgments for the overall group of participants with the two
versions of the texts, calculated using Cohen’s K (Cohen’s
K ranging from .82 to .89, p always <.01). For the final
score, the judges discussed each item on which they
disagreed, until they reached full agreement. Each concept
(i.e., semantic unit) recalled by the participants was
evaluated according to the same coding schema used in
Experiment 1. Consider, for example, the following
semantic unit in the written LIS Savannah text: “Food gives
animal which? Giraffe”; according to the coding schema,
the statement: “Acacia leaves to serve as food giraffe” has
been coded as correct recollection, the statement: “Plant
acacia serves for improving existence, growth giraffe” as
elaborative inference, and the statement: “Animals do not
eat acacia” as an erroneous recollection. As a further
example, the recollection “Mother pecks egg, exit with help
mother” has been coded as a discourse-based inference with
respect to the semantic unit in the Italian text “(The shell is
to tough) that the mother ostrich sometimes needs to help
the chicks to break out”.
Results and Discussion The two texts were comparable in
difficulty; considering each type of recollection separately,
we found no differences in performance with the two texts
in either the LIS or the Italian versions (unpaired T-test:
t(10) ranging from 0 to 1, p ranging from 1 to .34). Hence,

3666

we pooled together the results of the two Italian versions
and those of the two LIS versions. Table 2 illustrates the
mean types of recollection for each coding category for both
versions of the texts.
Table 2: Mean types of recollection (and standard
deviation in parenthesis) by the participants in Exp. 2.
Signing
deaf
(N=12)
Written
LIS
Written
Italian

Correct
recollections
11.17
(5.24)
8.50
(4.36)

Discoursebased
inferences
.58
(.67)
.33
(.49)

Elaborative
inferences
.25
(.45)
.08
(.29)

Errors

1.00
(.74)
1.50
(1.38)

The results show that signing deaf individuals produced
significantly more correct recollections in the LIS than in
the Italian version (T-test: tied t(11)=2.13, p<.03), yet they
produced comparable numbers of discourse-based
inferences in the two versions (T-test: tied t(11)=1, p=.17).
Furthermore, the differences in production of elaborative
inferences and errors in the two versions were not
statistically significant (T-test: t(11)=1 and 1.15, p=.34 to
.28, respectively).
The results of Experiment 2 replicated those of
Experiment 1: written LIS facilitated deep comprehension
and learning from text, in terms of an increase in correct
recollections. The conclusion holds independently of the
nature of the text, be it technical or narrative. A possible
reason why we failed to detect a beneficial effect for written
LIS in terms of discourse-based inferences is that deaf
individuals have difficulty in drawing inferences (see also
Easterbrooks & Scheetz, 2004).

General Discussion
When reading and processing written texts of vocal
languages, deaf individuals are more likely to treat written
information as unrelated pieces rather than seeking
commonality. Crucial features of all sign languages are the
spatial arrangement of the signs, the highly characteristic,
marked facial expressions or postures, and the gaze
direction. Unlike the sequential ordering of the sentence
elements in verbal languages, the rich morphosyntactic
structure of visual-gestural languages is organized in spatial
terms. We assumed that signing deaf individuals’
comprehension and learning benefit from a written text that
reflects the structure of their sign language, because such
written texts might be comprehended using categories that
belong to the sign language organization rather than the
natural language organization. The results of our
experiments on 24 profoundly deaf individuals confirmed
the predictions derived from our assumptions. In particular,
in both experiments we observed the beneficial effects of
the written LIS compared to the written Italian in terms of

an increase in correct recollections by the signing deaf
participants.
These results are in line with our assumptions: the written
form of sign language offers deaf individuals the possibility
to process written linguistic information provided in a
syntactic structure that reflects the structure of the
corresponding sign language; signing deaf individuals, who
have a shorter memory span for linguistic material than do
hearing individuals, benefit from the lack of articles,
prepositions, conjunctions, pronouns, and verbal auxiliaries
in the written sign language; signing deaf individuals, who
compared to hearing individuals have a more spatially
distributed visual attention, can extract in a glance more
information from the written sign language text which is
shorter than the written oral language text.
Our finding has strong implications; as deaf people have
difficulties in comprehending the written versions of oral
languages, their opportunities to learn from written texts –
and therefore to benefit from school and university
education – are heavily restricted. Providing them access to
written texts reflecting their sign language would be a step
towards an improvement of their ability to comprehend the
written versions of oral languages. Consistent, Oakhill and
Cain (2000) already hypothesized that for deaf individuals
who are fluent in signing, “it would be possible to present
written texts via sign language in order to teach skills such
as inference making, comprehension monitoring, and the
planning and structuring of stories” (ib., p.58). On the basis
of the results of our study, we argue that a written version of
LIS could be used as an educational tool, in order to
approach signing deaf children onto written verbal
languages and improve their comprehension skills. Further
studies would be useful to investigate in depth the
effectiveness of trainings on texts comprehension exploiting
written sign language both on adult signing deaf individuals,
as well as on signing deaf children.

Acknowledgments
The authors were supported in this research by Regione
Piemonte of Italy, ATLAS project ID 44.

References
Bavelier, D., Dye, M.W.G., & Hauser, P. (2006) Do deaf
individuals see better? Trends in Cognitive Sciences, 10,
512-518.
Cattani, A., Clibbens, J., & Perfect, T.J. (2007). Visual
memory for shapes in deaf signers and nonsigners and in
hearing signers and nonsigners. Neuropsychology, 21,114121.
Cutica, I., & Bucciarelli, M. (2008). The deep versus the
shallow. Cognitive Science, 32, 921-935.
Cutica, I., & Bucciarelli, M. (2011). “The more you gesture,
the less I gesture": Co-speech gestures as a measure of

3667

mental model quality. Journal of Nonverbal Behavior, 35,
173-187.
Easterbrooks, S.R., & Scheetz, N.A. (2004). Applying
critical thinking skills to character education and values
clarification with students who are deaf or hard of hearing.
American Annals of the Deaf, 149, 255-263.
Edwards, L., Figueras, B., Mellanby, J., & Langdon, D.
(2010). Verbal and spatial analogical reasoning in deaf
and hearing children: the role of grammar and
vocabulary. Journal of Deaf Studies and Deaf Education,
16, 189-197.
Logan, K., Mayberry M., & Fletcher, J. (1996). The shortterm memory of profoundly deaf people for words, signs,
and abstract spatial stimuli. Applied Cognitive Psychology,
10, 105-119.
Marschark, M., & Hauser, P.C. (Eds.) (2008). Deaf
cognition: Foundations and outcomes. New York : Oxford
University Press.
Marschark, M., & Mayer, T.S. (1998). Interactions of
language and memory in deaf children and adults.
Scandinavian Journal of Psychology, 39, 145-148.
Marschark, M., & Wauters, L. (2008). Language
comprehension and learning by deaf students. In M.
Marschark & P.C. Hauser (Eds.), Deaf cognition:
Foundations and outcomes (pp. 309-350). New York:
Oxford University Press.
Miller, P. (2002). Communication mode and the processing
of printer words. Journal of Deaf Studies and Deaf
Education, 7, 312-329.
Mitchell, T.V., & Maslin, M.T. (2007). How vision matters
for individuals with hearing loss. International Journal of
Audiology, 46, 500-511.
Morgan, G., Barrett-Jones, S., & Stoneham, H. (2007). The
first signs of language: Phonological development in
British Sign Language. Applied Psycholinguistics, 28, 322.
Morgan, G., Herman, R., Barriere, I., & Woll, B. (2008).
The onset and mastery of spatial language in children
acquiring British Sign Language. Cognitive Development,
23, 1-9.
Oakhill, J.V., & Cain, K.E. (2000). Children's difficulties in
text comprehension. Journal of Deaf Studies and Deaf
Education, 5, 51-59.
Pizzuto, E., Rossini, P., Russo, T. (2006). Representing
signed languages in written form: questions that need to be
posed. In C. Vettori (Ed.), Proceedings of the
2nd Workshop on the Representation and Processing of
Sign Languages: "Lexicographic matters and didactic
scenarios" (LREC 2006 - Fifth International Conference
on Language Resources and Evaluation) (pp. 1-6). Paris:
ELRA.
Pyers, J., Shusterman, A., Senghas, A., Spelke, E., &
Emmorey, K. (2010). Evidence from an emerging sign
language reveals that language supports spatial cognition.
PNAS, 107, 12116-12120.

Smith, L.B., Quittner, A.L., Osberger, M.J., & Miyamoto,
R. (1998). Audition and visual attention. Developmental
Psychology, 34, 840-850.
Sutton, V. (1999). Lessons in SignWriting. Textbook &
workbook. La Jolla, CA: Deaf Action Committee for Sign
Writing.
Van Hoogmoed, A.H., Verhoeven, L. Schreuder, R., &
Knoors, H. (2011). Morphological sensitivity in deaf
readers of Dutch. Applied Psycholinguistics, 32, 619-634.
Vendrame, M., Cutica, I., & Bucciarelli, M. (2010).
Learning by Videos: Peculiarities of Being Deaf
Individuals. International Association for the Scientific
Knowledge (IASK), Proceedings of the International
Conference Teaching and Learning 2010, Seville, Spain,
29 November - 1 December 2010, p. 107-116.
Wilbur, R.B. (2000). The use of ASL to support the
development of English and literacy. Journal of Deaf
Studies and Deaf Education, 5, 81-104.
Winston, E.A. (1995). Spatial mapping in comparative
discourse frames. In K. Emmorey & J. Reilly (Eds.),
Language, gesture and space (pp.87-114), Mahwah, NJ:
Lawrence Erlbaum Associates.

Appendix 1. Material from Experiment 1
(Semantic Units are Separated by Slashes)
Excerpts from Responses to colour (translated to English)
Written Italian version The idea that the various colours
can arouse emotions/ is well known./ Red is considered
exciting,/ because in our minds it evokes fire,/ blood/ and
revolution./ Green brings relaxing thoughts of nature;/ blue
is refreshing, like water./
Written LIS version People many think what?/ Colours
various to give emotion./ Colour red to give excitation,/
reason what? We remember fire,/ blood,/ revolution./
Colour green to give relaxation reason? To view nature,/
colour blue to give feeling fresh like water./

Appendix 2. Material from Experiment 2
(Semantic Units are Separated by Slashes)
Excerpts from The savannah (translated to English)
Written Italian version Thirty million years ago,/ tropical
Africa was covered in jungle. Things have since changed./
In eastern Africa, the forest has disappeared,/ and the new
landscape is very different from its predecessor./ Everything
began in the forest./ Chimpanzees are perfectly adapted to
life in the trees./
Written LIS version Million thirty years ago where?/ Africa
tropical forest covered./ Now Africa eastern forest there is
not,/ landscape new, instead past different./ Forest now
begins/ tree, area monkeys suitable live they where? Trees./

3668

