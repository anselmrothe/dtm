UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Incremental processing in the pragmatic interpretation of contrastive prosody
Permalink
https://escholarship.org/uc/item/07j8h4rj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Kurumada, Chigusa
Brown, Meredith
Bibyk, Sarah
et al.
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                     University of California

     Incremental processing in the pragmatic interpretation of contrastive prosody
               Chigusa Kurumada                                Meredith Brown                                Sarah Bibyk
           kurumada@stanford.edu                        mbrown@bcs.rochester.edu                   sbibyk@bcs.rochester.edu
                Dpt. of Linguistics                 Dpt. of Brain and Cognitive Sciences       Dpt. of Brain and Cognitive Sciences
               Stanford University                         University of Rochester                     University of Rochester
                                Daniel F. Pontillo                                     Michael K. Tanenhaus
                       dpontillo@bcs.rochester.edu                                   mtan@bcs.rochester.edu
                     Dpt. of Brain and Cognitive Sciences                       Dpt. of Brain and Cognitive Sciences
                             University of Rochester                                   University of Rochester
                               Abstract
   We present an eye-tracking experiment investigating the time
   course with which listeners derive pragmatic inferences from
   contextual information. We used as a test case the construc-
   tion “It looks like an X” pronounced either with (a) a nuclear
   pitch accent on the final noun, or (b) a contrastive L+H* pitch
   accent and a rising boundary tone, a contour that can sup-
   port a complex contrastive inference (e.g., It LOOKS like a
   zebra...(but it is not)). The contrastive intonational contour
   elicited higher proportions of fixations to non-prototypical tar-
   get pictures (e.g., a zebra-like animal) during the earliest mo-
   ments of processing the target noun. Further, when the display
   only contained a single related pair of pictures, effects of the      Figure 1: A sample visual display used in Sedivy et al.
   contrastive accent on “looks” emerged prior to the target noun,       (1999) for an instruction “Pick up the tall glass”
   indicating that efficient referential resolution is supported by
   rapidly generated inferences based on visual and prosodic con-
   text.
   Keywords: Prosody, contrastive accent, pragmatic inferences,          and resource-demanding processes, such as inference (e.g.,
   eye-tracking.                                                         Fodor, 1983).
                                                                            This modularity hypothesis, however, lacks an explanation
                           Introduction                                  for cases in which expectations based on context can effec-
Few, if any, would question the claim that addressees must               tively constrain parsing decisions. In fact, there is now a
make use of context to infer the intentions of a speaker                 large body of research demonstrating that listeners rapidly
(speaker meaning). Herb Clark (1992) gives a lovely ex-                  use information from the linguistic and visual context to re-
ample to illustrate the richness of context-based inferences.            solve ambiguity (e.g., Altmann 1998; Chambers, Tanenhaus
Clark describes a situation in which he addressed the utter-             & Magnuson, 2004; Snedeker & Trueswell, 2003). In this
ance, “I’m hot”, to his school-age son, Damon. After go-                 constraint-based approach, the context of language use is in-
ing through the plausible pre-compiled senses, Clark notes               tegral to effective and incremental language processing in
that none captures his intended (and immediately understood)             guiding expectations (e.g., Levy, 2008). Furthermore, Pianta-
meaning of his utterance, which could only be inferred from              dosi, Tily and Gibson (2012) propose that inherent ambiguity
the specific context. Herb and Damon were playing poker                  in the linguistic signal is in fact a design feature of an efficient
and Damon was about to make a large bet. Herb was warning                encoding system, given the assumption that listeners can inte-
Damon that he should think twice about it.                               grate context information to inferentially resolve ambiguity.
   Despite countless everyday examples of this sort, there is               Consistent with these accounts, a number of studies using
also a widely held view that pragmatic inference is external             online measures have shown that listeners can, and do, in-
to the core mechanism of language comprehension. For ex-                 corporate visual information to process linguistic input incre-
ample, this assumption underlies Levinson’s (2000) influen-              mentally. For example, Sedivy et al. (1999) examined listen-
tial proposal that common inferences might be pre-compiled               ers’ processing of prenominal adjectives during incremental
as automatically generated defaults, by-passing the need for             language processing. They asked participants to manipulate
making a slow and resource intensive inferences (e.g., Neely,            objects based on spoken instructions such as “Pick up the tall
1977; Posner & Snyder, 1975; Shiffrin & Schneider, 1977).                glass”. In Figure 1, the pitcher on the lower left is the tallest
This idea receives support from the hypothesis that the re-              object, but the glass on the upper left is both tall by compari-
markable speed and ease of real-time language processing                 son to glasses in general, and taller than the other glass in the
is possible, in part, because of its modularity in the pro-              upper right-hand corner. Sedivy et al. found that the partial
cessing system. A syntactic module, for example, performs                instruction “Pick up the tall —” elicited fixations to the tall
computations on restricted inputs without appealing to slow              member of the contrast pair (e.g., the tall glass) rather than
                                                                     846

the other tall object (e.g., the pitcher) in the display. This sug-
gests that listeners rapidly integrate context-specific contrast
information to begin resolving referential ambiguity prior to
the head noun.
   Nonetheless, it remains to be understood how readily lis-
teners can derive more complex inferences such as conversa-
tional implicature. For example, some experimental studies
                                                                        Figure 2: Examples of Noun-focus prosody (left) and Verb-
on the English quantifier some (but not all) have concluded
                                                                        focus prosody (right).
that even the basic scalar implicature is indeed slow and
costly, compared with computing its logical meanings (i.e., at
least one, possibly all) (e.g., Bott & Novek, 2004; Huang &
                                                                       1. Can listeners integrate visually represented contrasts with
Snedeker, 2009). On the other hand, there is a recent body of
                                                                           prosodic information to guide pragmatic interpretation?
work (e.g., Grodner et al., 2010, Degen & Tanenhaus, under
review) suggesting that delays arise only when use of some
                                                                       2. Do listeners process intonational contours and develop
in the particular context is less natural than another rapidly
                                                                           pragmatic expectations incrementally?
available alternative.
   In this current study, we approach this problem by examin-
ing the time course of English speakers’ comprehension of                                  Experiment overview
contrastive prosody. In English, the pitch accent L+H* is               We examined the time course of pragmatic intonation in-
known to evoke an alternative set of referents and invites a            terpretation using the visual world paradigm (Tanenhaus et
contrastive inference (e.g., Katie did not win a TRUCK L+H∗             al., 1995). Participants listened to the construction “It looks
(but won a motorcycle), Ito & Speer, 2008). Previous work               like an X” produced with either Noun-focus or Verb-focus
has found that the use of L+H* in an appropriate discourse              prosody, and they were asked to click on the corresponding
context restricts the domain of reference during incremental            referent in a four picture display. In each display, there was
language comprehension. For instance, the L+H* in “Give                 at least one pair of visually similar items (e.g., a zebra and an
me the red ball. Now give me the GREENL+H∗ —” triggers                  okapi; Figure 3-a, bottom row). We assumed based on pre-
anticipatory eye-movements to a green object of the same                vious work that Noun-focus prosody would bias responses
type as the preceding referent (i.e., a green ball).                    toward the more prototypical member of each pair (e.g., a ze-
   While this contrast-evoking function of L+H* is known                bra for “It looks like a ZEBRA”), while Verb-focus prosody
to be robust (Weber et al., 2006), previous experimental                would bias responses toward the less prototypical member
work has almost exclusively focused on prenominal adjec-                (e.g., an okapi for “It LOOKS like a zebra”). Thus, our first
tives highlighting color or size contrast. Moreover, studies so         hypothesis is that listeners should integrate the contrasting re-
far have found incremental processing of contrastive prosody            lation between the prototypical and non-prototypical target
only when a member of the relevant contrast set was linguis-            pictures in their interpretation of the utterance intonation.
tically mentioned in prior discourse. These limitations make               A previous study has shown that listeners can develop a
it difficult to scale up previous findings to cases where con-          similar contrastive inference in a visual search task (Dennison
trastive accent triggers complex, and hence allegedly costly,           & Schafer, 2010). Their study used the construction “X HAD
conversational implicatures.                                            Y” (e.g., “Lisa HAD a bell...” (but she no longer has one)),
   To address this, we used a different linguistic construc-            but they found no evidence of incremental processing. They
tion, “It looks like an X”, which can support two opposing              proposed that the contrastive inference requires both the pitch
pragmatic interpretations depending on its prosodic realiza-            accent and the boundary tone, and hence occurs only after the
tion. A canonical declarative prosodic contour, with a nu-              sentence offset.
clear pitch accent on the final noun (as illustrated in Figure             In the current study, we hypothesize that listeners can com-
2, left panel, henceforth Noun-focus prosody), typically elic-          pute an implicature incrementally, based on the prosodic and
its an affirmative interpretation (e.g., It looks like a zebra          visual context. We tested this hypothesis by comparing the
and I think it is one). When the verb “looks” is lengthened             time course of eye movements in a display with a single pair
and emphasized with a contrastive L+H* accent and the ut-               of contrasting items, to those in a display with two pairs. In
terance ends with a rising L-H% boundary tone (Figure 2,                the one-contrast display, we predicted that participants would
right, Verb-focus prosody), it can trigger a negative interpre-         be able to use the contrastive pitch accent to infer that the
tation (e.g., It LOOKS like a zebra but its actually not one            likely referent is a member of the contrast pair (more specifi-
(Kurumada, Brown, & Tanenhaus, 2012).                                   cally, the less prototypical member) prior to the processing of
   In the current study, we tested if and how the listen-               the target word. In the two-contrast display, the target referent
ers develop the two different interpretations as they receive           cannot be determined until it has been explicitly mentioned,
prosodic information. Specifically, we asked the following              which should result in effects of prosody emerging later, i.e.,
questions:                                                              during the processing of the target word.
                                                                    847

                                                                       condition) (Figure 3). Singletons in 1-contrast trials consisted
                                                                       of one easily nameable picture and one less-nameable picture
                                                                       to equate the complexity of the visual display across trials.
                                                                       Procedure
                                                                       Participants were first presented with a cover story in which
                                                                       a mother and a child are looking at a picture book. The
                                                                       mother is helping the child to identify various objects and
                                                                       animals by verbally commenting on them. Each trial began
       (a) 1-contrast condition        (b) 2-contrast condition        with the presentation of a visual display containing four pic-
                                                                       tures. After 1 second of display preview, participants heard
                Figure 3: Sample visual displays
                                                                       a spoken sentence over Sennheiser HD 570 headphones and
                                                                       clicked on a picture described by the sentence. Their mouse-
                                                                       clickng responses were collected while their eye movements
                             Methods
                                                                       were tracked using a head-mounted SR Research EyeLink II
Participants                                                           system sampling at 250 Hz, with drift correction procedures
Twenty-four students from University of Rochester were paid            performed after every fifth trial.
($10) to take part in the experiment. They were native speak-             Eight lists were constructed by crossing the 1) item presen-
ers of American English with normal or corrected-to-normal             tation order, 2) the location of the prototypical and the non-
vision and normal hearing.                                             prototypical items on the display, and 3) the prosodic con-
                                                                       tour (Noun-focus vs. Verb-focus). All lists started with three
Stimuli                                                                example items to familiarize participants with the task. The
We selected 16 imageable high-frequency nouns and embed-               mean duration of the experiment was 12 minutes.
ded them in the sentence frame “It looks like an X”. A native                              Results and discussion
speaker of American English recorded two tokens of each
item with the Noun-focus and the Verb-focus prosodic pat-              We analyzed three dependent measures to obtain converging
terns. The same speaker also recorded 44 filler items in which         evidence about the role of prosody and visual display charac-
a target referent was described (e.g., “Can you find the one           teristics in the processing of critical items: response choices
with white fur?”).                                                     in the picture selection task, response times, and proportions
   We selected 16 more items to form pairs with the 16 target          of fixations to different alternatives within the display. Each
nouns. In each pair, the items were visually similar to each           variable was assessed with multi-level generalized linear re-
other (e.g., a zebra and an okapi) and one item (e.g., a zebra)        gression models implemented using the lmer function within
was always more common. Hereafter, the picture from each               the lme4 package in R (R Development Core Team, 2010;
pair that is more common (e.g., a zebra, Figure 3, bottom left)        Bates et al. 2008)1 .
is referred to as the prototypical target picture, and the other          We first confirmed that participants selected a correct tar-
(e.g., an okapi, Figure 3, bottom left) is referred to as the non-     get picture in 96% of filler trials, indicating that participants
prototypical target picture.                                           did not have difficulty completing or attending to the picture
                                                                       selection task. We then analyzed their responses in the 16
Prototypicality and nameability norming To create vi-                  critical trials to ask if they encoded the visual contrasts of
sual stimuli, we ran two types of norming studies using Ama-           items on the screen and associated them with the two prosodic
zon Mechanical Turk, an online crowd-sourcing platform. In             contours. Participants selected the prototypical target pic-
the first study, 40 subjects provided names and nameability            ture 65.6% of the time in the Noun-focus prosody condition,
ratings (on a seven-point rating scale) for each of the 240 im-        but only 25.5% of the time in the Verb-focus prosody condi-
ages. In a second norming study, we presented 40 subjects              tion. A multilevel logistic regression model of responses con-
with the images along with a label and collected ratings of            firmed that depending on the prosodic contour, participants
referential fit for both adult-directed speech and, as a sep-          reliably chose either a prototypical or a non-prototypical item
arate response, child-directed speech. The non-prototypical
                                                                           1 Logistic regression models of response choices were fit by the
pictures (e.g., okapi) were always presented with the names
                                                                       Laplace approximation, whereas linear regression models of re-
of their respective prototypical items (e.g., zebra) in order to       sponse times and fixation proportions were fit using restricted max-
establish an empirical measure of prototypicality.                     imum likelihood estimation. Fixed effects included prosody condi-
   Based on this information we constructed 60 visual scenes           tion (Noun- vs. Verb-focus), display type (one- vs. two sets of re-
                                                                       lated pictures), and standardized trial number. Analyses of fixation
(16 critical trials and 44 filler trials). Each of the scenes con-     proportions additionally included picture type. We also included
sisted of four pictures including one pair of target pictures          random by-subject and item intercepts as well as slopes for the in-
described in an auditory stimulus. We created two types of             teraction between prosody condition and picture type. To minimize
                                                                       the risk of over-fitting the data, fixed effects were removed stepwise
visual scenes: a) 1 target pair + 2 singletons (1-contrast con-        and each smaller model was compared to the more complex model
dition), and b) 1 target pair and 1 distractor pair (2-contrast        using the likelihood ratio test (Baayen, Davidson, & Bates, 2008).
                                                                   848

                                                                     the visual contrasts.
                                                                        Next we analysed the eye-tracking data to examine the time
                                                                     course of processing the contrastive prosody. Our analysis
                                                                     focused on two regions, which were both defined with re-
                                                                     spect to the point at which segmental information from the
                                                                     target word would be expected to influence processing. The
                                                                     first region, which we termed the pre-target region, was de-
                                                                     fined as the region beginning at 200 ms after the offset of
                                                                     “looks” and ending at 200 ms after the onset of the target
                                                                     word. This roughly corresponds to the region indicated with
                                                                     the caption “like a” in Figure 4, shifted to the right by 200ms.
                                                                     Because it takes approximately 200 ms to program and exe-
                       (a) 1-contrast condition                      cute an eye movement, fixations within this window should
                                                                     not be influenced by segmental information from the target
                                                                     word. The only information that would be expected to in-
                                                                     fluence eye movements within this window, then, is informa-
                                                                     tion from preceding prosody (e.g. the contrastive accent on
                                                                     “looks”).
                                                                        The second region, the early target-word region, began at
                                                                     200 ms after target word onset and ended at 200 ms after the
                                                                     offset of the first syllable of the target word. This roughly cor-
                                                                     responds to the region indicated with the caption “ze-” in Fig-
                                                                     ure 4, shifted to the right by 200ms. Fixations within this win-
                                                                     dow were expected to reflect the integration of expectations
                                                                     based on preceding prosody and initial effects of incremen-
                                                                     tally presented target word information. Within each window,
                       (b) 2-contrast condition                      mean proportions of fixations to each picture were calculated
                                                                     and then transformed using the empirical logit function (Cox,
Figure 4: Proportions of fixation to pictures in response to the
                                                                     1970) for the purposes of linear regression analysis.
Noun-focus (solid line) and to the Verb-focus (dashed line).
The lines are aligned at the onset of the final noun.                Pre-target fixations We analyzed logit-transformed pro-
                                                                     portions of fixations averaged across the pre-target region in
                                                                     two linear mixed-effects regression models. The first model
(β = 6.37, z = 4.394, p < .0001). Thus, without any explicit         examined effects of prosody contour, display type (i.e., one-
mention of a contrasted item, participants encoded a relevant        vs. two contrast sets), and trial number on logit-transformed
contrast set in the visual field and developed a contrastive in-     mean proportions of fixations to the distractor pictures vs. ei-
ference based on the Verb-focus prosody.                             ther member of the target contrast set (e.g. the zebra and
   Response times indicated that Verb-focus prosody elicited         okapi). The goal of this analysis was to assess prosody- and
slower responses (mean RT=2204 ms) than Noun-focus                   display-wise differences in anticipating the target contrast set.
prosody (mean RT=1969 ms, β = −.242, t = −2.09,p < .05).             We predicted that Verb-focus prosody would bias participants
However, the effect of prosody was dependent on whether              to fixate members of the target contrast set in one-contrast tri-
the prototypical or non-prototypical target picture was se-          als but not in two-contrast trials.
lected (β = .509, t = 2.94, p < .005). On trials with Noun-             Results from the regression analysis revealed that the pre-
focus prosody, RTs were significantly faster when a proto-           dicted three-way interaction between prosody condition, pic-
typical picture was selected (mean RT=1762 ms) than when             ture type, and display type was significant (β = .754, t = 1.98,
a non-prototypical picture was chosen (mean RT=2364 ms,              p < .05). Analyzing proportions of fixations by display type
β = −.272, t = −3.20, p < .005). On trials with Verb-                revealed that effects of prosody condition were dependent on
focus prosody, however, there was a numerical trend in               picture type in one-contrast trials (β = −.322, t = −2.61,
the opposite direction (mean RT=2540 ms for prototypi-               p < .01). Participants were no more likely in the Noun-
cal target responses vs. 2089 ms for non-prototypical target         focus condition to fixate the target picture (mean untrans-
responses,(β = .201, t = 1.10, p > .10). This finding suggests       formed proportion of fixations=.209) and the distractor pic-
that responses deviating from the expected association be-           tures (mean=.186, β = .007, t = .068, p > .1), but they ex-
tween prosody and picture type were associated with greater          hibited a significant bias toward the target contrast set in
processing difficulty, further supporting the hypothesis that        response to Verb-focus prosody (mean=.245 vs. .167, β =
participants were interpreting the prosodic contour based on         −.315, t = −3.34, p < .001). This interaction was not sig-
                                                                 849

nificant in two-contrast trials (β = −.058, t = −.529, p > .1).
   The second linear mixed-effects regression model exam-
                                                                                                                          1-contrast
                                                                                 Mean proportion of fixation
ined effects of prosody condition, display type, and trial num-                                                0.45       2-contrast
ber on logit-transformed mean fixation proportions to proto-
typical vs. non-prototypical target pictures. We predicted that                                                0.40
the difference between fixations to non-prototypical pictures
and fixations to prototypical pictures would be greater in re-                                                 0.35
sponse to Verb-focus prosody than Noun-focus prosody. In-
                                                                                                               0.30
deed, the regression model revealed a marginal two-way in-
teraction between prosody condition and picture type (β =                                                      0.25
.138, t = 1.71, p = .087). In the Noun-focus prosody
condition, fixations to bad target pictures (mean=.238) did                                                           pre-target       early-target
not differ significantly from fixations to good target pic-
tures (mean=.181, β = −.124, t = −1.20, p > .1). In                       Figure 5: Mean fixation proportions to the non-prototypical
the Verb-focus condition, however, participants were signifi-             item in response to the Verb-focus prosody. Error bars repre-
cantly more likely to fixate the bad target picture (mean=.300            sent standard errors.
vs. .190, β = −.243, t = −2.69, p < .01).
   Taken together, these findings suggest that participants
                                                                          tion. In addition, display type was no longer predicted to sig-
rapidly encode the visual attributes of and relations between
                                                                          nificantly influence patterns of fixations, since the segmental
potential referents, and rapidly integrate this visual informa-
                                                                          information from the initial sounds of the target word should
tion with the incoming prosodic input. When a single contrast
                                                                          restrict the domain of reference to the target contrast set.
set is present in the display, contrastive Verb-focus prosody
                                                                             The second linear mixed-effects regression model indeed
biases listeners to fixate members of that set. This trend is il-
                                                                          revealed a two-way interaction between prosody condition
lustrated in Figure 4. In the 1-contrast condition (Figure 4-a),
                                                                          and picture type (β = −.472, t = −4.02, p < .0001). In the
the fixation proportions to the non-prototypical target based
                                                                          Verb-focus condition, participants were significantly more
on the Verb-focus prosody begins to diverge in the pre-target
                                                                          likely to fixate non-prototypical target pictures (mean=.374)
region. On the other hand, such divergence is delayed in the
                                                                          than prototypical target pictures (mean=.222, β = −.335,
2-contrast condition (Figure 4-b).
                                                                          t = −3.97, p < .0001). In the Noun-focus condition,
Early target-word fixations For the early target-word re-                 however, there was a non-significant trend in the oppo-
gion, we again analyzed logit-transformed mean proportions                site direction, with more fixations to prototypical target
of fixations in two linear mixed-effects regression models,               pictures (mean=.293) than non-prototypical target pictures
to compare effects of prosody condition, display type, and                (mean=.231, β = .138, t = 1.49,p > .1). This interaction be-
trial number on (a) target-picture fixations to distractor fix-           tween prosody condition and picture type suggests that listen-
ations, and (b) prototypical target-picture fixations to non-             ers rapidly integrated incoming segmental information from
prototypical target-picture fixations.                                    the target word with their pragmatic expectations for a pro-
   For the analysis comparing logit-transformed mean pro-                 totypical vs. non-prototypical referent based on preceding
portions of fixations to target pictures vs. distractor pictures,         prosodic information.
we predicted that the three-way interaction between prosody                  Figure 5 summarizes mean fixation proportions to the non-
condition, picture type, and display type would no longer be              protptypical item based on the Verb-focus prosody. Within
significant. Instead, the main prediction was that fixations to           the pre-target region, participants were looking at the non-
both target pictures would be significantly higher than fixa-             prototypical item more when they were in the 1-contrast con-
tions to distractors across trial types.                                  dition than in the 2-contrast condition. This trend was even
   The results of the analysis indicated that neither display             more magnified when the segmentatal information of the tar-
type nor prosody condition accounted for a significant propor-            get noun becomes available. This demonstrates that the con-
tion of variance in target vs. distractor fixations in the early          trastive pitch accent was processed incrementally under the
target-word region. Instead, the main finding was that partic-            constraints of the visual context.
ipants were significantly more likely to fixate target pictures
(mean=.280) than distractor pictures (mean=.127, β = −.240,                                                              Conclusion
t = −4.12, p < .0001), reflecting their early use of incoming             The results show that participants generated complex prag-
segmental information to restrict the referential domain to the           matic interpretations in an incremental manner. In a con-
two target pictures.                                                      text with only one contrast pair, listeners began to launch eye
   The analysis of fixations to the two target pictures was pre-          movements to a less prototypical target picture even before
dicted to show that the difference between non-prototypical               segmental cues to the final noun become available. This is
target picture fixations and prototypical target picture fixa-            of particular interest because, unlike in previous studies, the
tions would continue to be greater in the Verb-focus condi-               contrastive accent in the current study was used with the verb.
                                                                    850

The contrast was not simply based on individual visual fea-          Huang, Y. T., & Snedeker, J. (2009). Online interpretation of
tures of objects (e.g., color or size); rather, it was mediated          scalar quantifiers: insight into the semantics-pragmatics
by the implicature based on different predicates. Namely, “It            interface. Cognitive Psychology, 58, 376–415.
LOOKS like an X” is contrasted with “It IS an X”, and there-         Ito, K., & Speer, S. R. (2008). Anticipatory effects of into-
fore interpreted as “It is not an X”. Our results demonstrate            nation: Eye movements during instructed visual search.
that such complex pragmatic reasoning can develop online.                JML, 58, 541–573.
   The results also highlighted the facilitative roles of visual     Kurumada, C., Brown, M., & Tanenhaus, M. K. (2012).
context in intonation interpretation. The early timing of the            Prosody and pragmatic inference: It looks like speech
prosody effect in the 1-contrast condition suggests that listen-         adaptation. Proceedings of the 34th Annual Conference
ers made use of visually represented contrast to guide their in-         of the Cognitive Science Society.
ference. This enabled us to demonstrate that inferences based        Levinson, S. C. (2000). Presumptive meanings: The theory of
on contrastive prosody do not require explicit previous men-             generalized conversational implicature. MIT Press.
tion of a contrasting item and can be made incrementally on
                                                                     Levy, R. (2008). Expectation-based syntactic comprehension.
the basis of partial prosodic contour as well as visual informa-
                                                                         Cognition, 106, 1126–1177.
tion. These findings together advance our knowledge about
                                                                     Neely, J. H. (1977). Semantic priming and retrieval from lex-
the remarkably rapid and robust inferential mechanisms sup-
                                                                         ical memory: Roles of inhibitionless spreading activation
porting online language comprehension and pragmatic com-
                                                                         and limited-capacity attention. JEP: G., 106, 226–254.
munication.
                                                                     Piantadosi, S. T., Tily, H., & Gibson, E. (2012). The com-
                    Acknowledgements                                     municative function of ambiguity in language. Cognition,
                                                                         122, 280 –91.
Thanks to Eve V. Clark, Christine Gunlogson and T. Florian
Jaeger for valuable discussion, and to Dana Subik for support        Pierrehumbert, J. & Hirschberg, J. (1990) The meaning of
with participant testing. This research was supported by the             intonational contours in the interpretation of discourse.
NICHD grant HD27206 (MKT).                                               In P. Cohen, J. Morgan, and M. Pollack (eds), Intentions
                                                                         and plans in communication and ciscourse (pp. 271–311).
                          References                                     MIT Press.
Altmann, G.T.M. (1998). Ambiguity in Sentence Processing.            Posner, M. I., & Snyder, C. R. (1975). Facilitation and inhibi-
    Trends in Cognitive Sciences, 2, 146–152.                            tion in the processing of signals. In P. M. A. Rabbitt & S.
Baayen, R., Davidson, D., & Bates. D., (2008). Mixedeffects              Dornic (Eds.), Attention and performance (pp. 669–682).
    modeling with crossed random effects for subjects and                New York: Academic Press.
    items. JML, 59, 390–412.                                         R Development Core Team. (2010). R: A language and envi-
Bates, D.M., Maechler, M., & Dai, B. (2008). lme4: Linear                ronment for statistical computing. R Foundation for Sta-
    mixed-effects models using S4 classes.                               tistical Computing, Vienna, Austria.
                                                                     Tanenhaus, M. K., Spivey-Knowlton, M., Eberhard, K., & Se-
Bott, L., & Noveck, I. (2004). Some utterances are underin-
                                                                         divy, J. (1995). Integration of visual and linguistic infor-
    formative: The onset and time course of scalar inferences.
                                                                         mation in spoken language comprehension. Science, 268,
    JML, 51, 437–457.
                                                                         1632–1634.
Chambers, C. G., Tanenhaus, M. K., & Magnuson, J. S.
                                                                     Tanenhaus, M. K., Magnuson, J. S., Dahan, D., & Chambers,
    (2004). Actions and affordances in syntactic ambiguity
                                                                         C. G. (2000). Eye movements and lexical access in spoken
    resolution. JEP:LMC, 30, 687 –696.
                                                                         language comprehension: Evaluating a linking hypothe-
Clark, H. H. (1992). Arenas of language use. Chicago: Uni-               sis between fixations and linguistic processing. Journal of
    versity of Chicago Press.                                            Psycholinguistic Research, 29, 557–580.
Cox, D.R. (1970). The analysis of binary data. London:               Sedivy, J. C., Tanenhaus, M. K., Chambers, C. G., & Carl-
    Methuen.                                                             son, G. N. Achieving incremental semantic interpretation
Degen, J., & Tanenhaus, M. K. (under review). Processing                 through contextual representation. Cognition, 71, 109–
    scalar implicature: A constraint-based approach.                     147.
Dennison, H. Y., & Schafer, A. (2010). Online construction of        Shiffrin, R. M., & Schneider, W. (1977). Controlled and auto-
    implicature through contrastive prosody. Speech prosody              matic human information processing. Psychological Re-
    2010 conference.                                                     view, 84, 127–190.
Fodor, J. A. (1983).The modularity of mind: An essay on fac-         Snedeker, J., & Trueswell, J. (2003). Using prosody to avoid
    ulty psychology. MIT Press.                                          ambiguity: Effects of speaker awareness and referential
Grodner, D. J., Klein, N. M., Carbary, K. M., & Tanenhaus,               context. JML, 48, 103–130.
    M. K. (2010). Some, and possibly all, scalar inferences          Weber, A., Braun, B., & Crocker, M. W. (2006). Finding ref-
    are not delayed: Evidence for immediate pragmatic en-                erents in time: Eye-tracking evidence for the role of con-
    richment. Cognition, 116, 42–55.                                     trastive accents. Language and Speech, 49, 367–392.
                                                                 851

