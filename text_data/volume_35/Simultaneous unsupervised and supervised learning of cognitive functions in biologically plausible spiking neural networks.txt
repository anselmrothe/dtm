UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simultaneous unsupervised and supervised learning of cognitive functions in biologically
plausible spiking neural networks
Permalink
https://escholarship.org/uc/item/9k64b389
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Bekolay, Trevor
Kolbeck, Carter
Eliasmith, Chris
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

        Simultaneous unsupervised and supervised learning of cognitive functions
                              in biologically plausible spiking neural networks
                                             Trevor Bekolay (tbekolay@uwaterloo.ca)
                                             Carter Kolbeck (ckolbeck@uwaterloo.ca)
                                            Chris Eliasmith (celiasmith@uwaterloo.ca)
                                      Center for Theoretical Neuroscience, University of Waterloo
                                          200 University Ave., Waterloo, ON N2L 3G1 Canada
                              Abstract                                 overcomes these limitations. Our approach 1) remains func-
                                                                       tional during online learning, 2) requires only two layers con-
   We present a novel learning rule for learning transformations
   of sophisticated neural representations in a biologically plau-     nected with simultaneous supervised and unsupervised learn-
   sible manner. We show that the rule, which uses only infor-         ing, and 3) employs spiking neuron models to reproduce cen-
   mation available locally to a synapse in a spiking network,         tral features of biological learning, such as spike-timing de-
   can learn to transmit and bind semantic pointers. Semantic
   pointers have previously been used to build Spaun, which is         pendent plasticity (STDP).
   currently the world’s largest functional brain model (Eliasmith
   et al., 2012). Two operations commonly performed by Spaun              Online learning with spiking neuron models faces signifi-
   are semantic pointer binding and transmission. It has not yet
   been shown how the binding and transmission operations can          cant challenges due to the temporal dynamics of spiking neu-
   be learned. The learning rule combines a previously proposed        rons. Spike rates cannot be used directly, and must be esti-
   supervised learning rule and a novel spiking form of the BCM        mated with causal filters, producing a noisy estimate. When
   unsupervised learning rule. We show that spiking BCM in-
   creases sparsity of connection weights at the cost of increased     the signal being estimated changes, there is some time lag
   signal transmission error. We also demonstrate that the com-        before the spiking activity reflects the new signal, resulting in
   bined learning rule can learn transformations as well as the        situations during online learning in which the inputs and de-
   supervised rule and the offline optimization used previously.
   We also demonstrate that the combined learning rule is more         sired outputs are out of sync. Our approach is robust to these
   robust to changes in parameters and leads to better outcomes        sources of noise, while only depending on quantities that are
   in higher dimensional spaces, which is critical for explaining      locally available to a synapse.
   cognitive performance on diverse tasks.
   Keywords: synaptic plasticity; spiking neural networks; unsu-          Other techniques doing similar types of learning in spik-
   pervised learning; supervised learning; Semantic Pointer Ar-
   chitecture; Neural Engineering Framework.                           ing neural networks (e.g., SpikeProp [Bohte, Kok, & Poutre,
                                                                       2002], ReSuMe [Ponulak, 2006]) can learn only simple op-
   In this paper, we demonstrate learning of cognitively rele-         erations, such as learning to spike at a specific time. Oth-
vant transformations of neural representations online and in           ers (e.g., SORN [Lazar, Pipa, & Triesch, 2009], reservoir
a biologically plausible manner. We improve upon a tech-               computing approaches [Paugam-Moisy, Martinez, & Bengio,
nique previously presented in MacNeil and Eliasmith (2011)             2008]) can solve complex tasks like classification, but it is not
by combining their error-minimization learning rule with an            clear how these approaches can be applied to a general cogni-
unsupervised learning rule, making it more biologically plau-          tive system. The functions learned by our approach are com-
sible and robust.                                                      plex and have already been combined into a general cognitive
   There are three weaknesses with most previous attempts at           system called the Semantic Pointer Architecture (SPA). Pre-
combining supervised and unsupervised learning in artificial           viously, the SPA has been used to create Spaun, a brain model
neural networks (e.g., Backpropagation [Rumelhart, Hinton,             made up of 2.5 million neurons that can do eight diverse tasks
& Williams, 1986], Self-Organizing Maps [Kohonen, 1982],               (Eliasmith et al., 2012). Spaun accomplishes these tasks by
Deep Belief Networks [Hinton, Osindero, & Teh, 2006]).                 transmitting and manipulating semantic pointers, which are
These approaches 1) have explicit offline training phases              compressed neural representations that carry surface seman-
that are distinct from functional use of the network, 2) re-           tic content, and can be decompressed to generate deep se-
quire many layers with some layers connected with super-               mantic content (Eliasmith, in press). Semantic pointers are
vised learning and others with unsupervised learning, and 3)           composed to represent syntactic structure using a “binding”
use non-spiking neuron models. The approach proposed here              transformation, which compresses the information in two se-
                                                                       mantic pointers into a single semantic pointer. Such repre-
BCM Bienenstock, Cooper, Munro learning rule; Eq (7)                   sentations can be “collected” using superposition, and col-
hPES Homeostatic Prescribed Error Sensitivity; Eq (9)                  lections can participate in further bindings to generate deep
NEF Neural Engineering Framework; see Theory                           structures. Spaun performs these transformations by using
PES Prescribed Error Sensitivity; Eq (6)                               the Neural Engineering Framework (NEF; Eliasmith & An-
SPA Semantic Pointer Architecture; see Theory                          derson, 2003) to directly compute static connection weights
STDP Spike-timing dependent plasticity (Bi & Poo, 2001)                between populations. We show that our approach can learn
                                                                       to transmit, bind, and classify semantic pointers.
                                                                   169

                               Theory                                   Transforming semantic pointers through connection
Cognitive functions with spiking neurons                                weights The encoders and decoders used to represent se-
                                                                        mantic pointers also enable arbitrary transformations (i.e.,
In order to characterize cognitive functions at the level of            mathematical functions) of encoded semantic pointers. If
spiking neurons, we employ the methods of the Semantic                  population A encodes pointer X, and we want to connect it to
Pointer Architecture (SPA), which was recently used to create           population B, encoding pointer Y , a feedforward connection
the world’s largest functional brain model (Spaun; Eliasmith            with the following connection weights transmits that seman-
et al., 2012), able to perform perceptual, motor, and cogni-            tic pointer, such that Y ≈ X.
tive functions. Cognitive functions in Spaun include work-
ing memory, reinforcement learning, syntactic generalization,                                        ωi j = α j e j di ,                (5)
and rule induction.
   The SPA is implemented using the principles of the Neu-              where i indexes the presynaptic population A, and j indexes
ral Engineering Framework (NEF; Eliasmith & Anderson,                   the postsynaptic population B. Other linear transformations
2003), which defines methods to 1) represent vectors of num-            are implemented by multiplying di by a linear operator. Non-
bers through the activity of populations of spiking neurons, 2)         linear transformations are implemented by solving for a new
transform those representations through the synaptic connec-            set of decoding weights. This is done by minimizing the dif-
tions between those populations, and 3) incorporate dynam-              ference between the decoded estimate of f (x) and the actual
ics through connecting populations recurrently. In the case              f (x), rather than just x, in Equation (4).
of learning, we exploit NEF representations in order to learn
transformations analogous to those that can be found through            Supervised learning: PES rule
the NEF’s methods.                                                      MacNeil and Eliasmith (2011) proposed a learning rule that
                                                                        minimizes the error minimized in Equation (4) online.
Representing semantic pointers in spiking neurons Rep-
resentation in the NEF is similar to population coding, as pro-                                    ∆di = κEai
posed by Georgopoulos, Schwartz, and Kettner (1986), but
                                                                                                  ∆ωi j = κα j e j · Eai ,              (6)
extended to n-dimensional vector spaces. Each population of
neurons represents a point in an n-dimensional vector space             where κ is a scalar learning rate, E is a vector representing
over time. Each neuron in that population is sensitive to a             the error we wish to minimize, and other terms are as before.
direction in the n-dimensional space, which we call the neu-                When put in terms of connections weights (ωi j ), the rule
ron’s encoder. The activity of a neuron can be expressed as             resembles backpropagation. The quantity α j e j · E is analo-
                                                                        gous to the local error term δ in backpropagation (Rumelhart
                       a = G[αe · x + Jbias ],                  (1)
                                                                        et al., 1986); they are both a means of translating a global
where G[·] is the nonlinear neural activation function, α is            error signal to a local error signal that can be used to change
a scaling factor (gain) associated with the neuron, e is the            an individual synaptic connection weight. The key difference
neuron’s encoder, x is the vector to be encoded, and Jbias is           between this rule and backpropagation is that the global-to-
the background current of the cell.                                     local mapping is done by imposing the portion of the error
   The vector (i.e., semantic pointer) that a population repre-         vector space each neuron is sensitive to via its encoder. This
sents can be estimated from the recent activity of the popu-            limits flexibility, but removes the dependency on global infor-
lation. The decoded estimate, x̂, is the sum of the activity of         mation, making the rule biologically plausible. We will refer
each neuron, weighted by an n-dimensional decoder.                      to Equation (6) as the Prescribed Error Sensitivity (PES) rule.
                                                                        Unsupervised learning: Spiking BCM rule
                          x̂(t) = ∑ di ai (t),                  (2)
                                  i                                     A Hebbian learning rule widely studied in the context of
                                                                        the vision system is the BCM rule (Bienenstock, Cooper, &
where di is the decoder and ai is the activity of neuron i.             Munro, 1982). This rule has been used to explain orientation
   Neural activity is interpreted as a filtered spike train; i.e.,      selectivity and ocular dominance (Bienenstock et al., 1982).
                                                                        Theoretically, it has been asserted that BCM is equivalent to
              ai (t) = ∑ h(t − ts ) = ∑ e−(t−ts )/τPSC ,        (3)     triplet-based STDP learning rules (Pfister & Gerstner, 2006).
                        s                 s
                                                                            The general form is
where h(·) is the exponential filter applied to each spike, and
s is the set of all spikes occurring before the current time t.                                  ∆ωi j = ai a j (a j − θ),              (7)
   The decoders are found through a least-squares minimiza-
tion of the difference between the decoded estimate and the             where θ is the modification threshold. When the postsynap-
actual encoded vector.                                                  tic activity, a j , is greater than the modification threshold, the
                                Z                   Z                   synapse will be potentiated; when the postsynaptic activity
        d = ϒ−1 Γ       Γi j =    ai a j dx    ϒj =     a j xdx (4)     is less than the modification threshold, the synapse will be
                                                                        depressed.
                                                                    170

   The modification threshold reflects the expectation of a              any method. However, for clarity, we will use hPES to refer
cell’s activity. It is typically calculated as the temporal av-          to the specific form in Equation (9).
erage of the cell’s activity over a long time window (on the
order of hours). The intuition behind BCM is that cells driven                                      Methods
above their expectation must be playing an important role in
a circuit, so their afferent synapses become potentiated. Cells          We performed three experiments in order to test our hypothe-
driven less than normal have synapses depressed. If either of            ses about the hPES rule. Experiments were implemented
these effects persists long enough, the modification threshold           in the Nengo simulation environment, in which we imple-
changes to reflect the new expectation of the cell’s activity.           mented the PES, spiking BCM, and hPES learning rules.
   However, BCM as originally formulated is based on non-                All experiments use leaky integrate-and-fire neurons with de-
spiking rate neurons. We implement BCM in biologically                   fault parameters. The scripts used to implement and an-
plausible spiking networks by interpreting neural activity as            alyze these experiments are MIT licensed and available at
spikes that are filtered by a postsynaptic current curve.                http://github.com/tbekolay/cogsci2013.
                                                                         Experiment 1: Unsupervised learning We constructed a
            ∆ωi j = κα j ai a j (a j − θ)
                                                                         network composed of two populations connected in a feed-
             θ(t) = e−t/τ θ(t − 1) + (1 − e−t/τ a j (t)),        (8)     forward manner such that one population provides input to
                                                                         the other. The network can be run in a “control” regime, in
where a, the activity of a neuron, is interpreted as a filtered          which the weights between the two populations are solved for
spike train, as in Equation (3), and τ is the time constant of           with the NEF’s least-squares optimization and do not change,
the modification threshold’s exponential filter.                         or in a “learning” regime, in which the weights are the same
   With our spiking BCM implementation, we aim to test the               as the control network, but change over time according to the
claim that BCM is equivalent to triplet STDP rules. Func-                hPES rule (9) with S = 0 (i.e., according to the spiking BCM
tionally, we hypothesize that unsupervised learning will have            rule [8]). This experiment tests the hypothesis that the unsu-
a small detrimental effect on the function being computed by             pervised component of the hPES rule increases sparsity of the
a weight matrix, but will result in weight sparsification.               connection weight matrix.
Simultaneous supervised and unsupervised                                 Experiment 2: Supervised learning We constructed a net-
learning: hPES rule                                                      work composed of two populations connected in a feedfor-
The PES rule gives us the ability to minimize some provided              ward manner, and one population that provides an error signal
error signal, allowing a network to learn to compute a trans-            to the downstream population. The network can be run in a
formation online. However, biological synapses can change                “control” regime, in which the weights between the two pop-
when no error signal is present. More practically, transforma-           ulations are computed to transmit a three-dimensional seman-
tion learning may be easier in more sparse systems. For these            tic pointer, or to bind two three-dimensional semantic point-
reasons, we propose a new learning rule that combines the                ers into one three-dimensional pointer. The network can be
error-minimization abilities of the PES rule with the biolog-            run in a “learning” regime, in which the weights between the
ical plausibility and sparsification of the spiking BCM rule.            two populations are initially random and are modified over
The rule is a weighted sum of the terms in each rule.                    time by the hPES rule. This experiment tests the hypothesis
                                                                         that the hPES rule can learn to transmit and bind semantic
          ∆ωi j = κ α j ai (S e j · E + (1 − S) a j (a j − θ)) , (9)     pointers as well as the control network and the supervised
where 0 ≤ S ≤ 1 is the relative weighting of the supervised              learning rule (i.e., hPES with S = 1).
term over the unsupervised term. Note that this rule is a gen-           Experiment 3: Digit classification In order to investi-
eralization of the previously discussed rules; if we set S = 1,          gate how simultaneous supervised and unsupervised learn-
this rule is equivalent to PES, and if we set S = 0, this rule is        ing scales in higher dimensional situations, we constructed
equivalent to spiking BCM.                                               a network similar to that in Experiment 2, but whose in-
   We hypothesize that the unsupervised component helps                  put is handwritten digits.∗ In order to be computationally
maintain homeostasis while following the error gradient de-              tractable, the 28-by-28 pixel images were compressed to a 50-
fined by the supervised component. Because of this, we call              dimensional semantic pointer using a sparse deep belief net-
the rule the homeostatic Prescribed Error Sensitivity (hPES)             work that consists of four feedforward Restricted Boltzmann
rule. We hypothesize that this rule will be able to learn the            Machines trained with a form of contrastive divergence (full
same class of transformations that the PES rule can learn, and           details in Tang & Eliasmith, 2010). Those 50-dimensional
that this class includes operations critical to cognitive repre-         pointers were projected to an output population of 10 dimen-
sentation, such as semantic pointer binding.                             sions, where each dimension represents the confidence that
   Note that a similar combination can be done with other su-            the input representation should be classified into one of the 10
pervised learning rules that modify connection weights. A                possible digits. The classified digit is the one corresponding
more general form of Equation (9) would replace the local er-
ror quantity e j · E with δ, which could be determined through               ∗ Digits from MNIST: http://yann.lecun.com/exdb/mnist/
                                                                     171

to the dimension with the highest activity over 30 ms when
a 50-dimensional input is presented. 60,000 labeled train-
                                                                                                                       Replicated STDP curve
ing examples were shown to the network while the hPES rule                                                  100     Simulation
                                                                          Change in connection weight (%)
was active. The network was then tested with 10,000 training                                                        Experiment
examples in which the label was not provided. The results
are compared to an analogous control network, in which the                                                  50
50-dimensional pointers are classified with a cleanup mem-
ory whose connection weights are static, as in Eliasmith et al.
(2012). This experiment examines how well the hPES rule                                                      0
scales to high-dimensional spaces.
Learning parameters While there are many hundreds of                                                        -50
parameters involved in each network simulation, the vast ma-
jority are randomly selected within a biologically plausible
range without significantly affecting performance. Some pa-                                                  -100     -50           0         50   100
rameters, especially those affecting the learning rule, can                                                                 Spike timing (ms)
have a significant performance effect. These significant pa-
rameters and the values used in specific simulations are listed
in Tables 1 and 2. These parameters were optimized with                  Figure 1: STDP curve replicated by two neurons connected
a tree of Parzens estimators approach, using the hyperopt                with the hPES rule, S = 0. Solid and dashed lines are best fits
package (Bergstra, Yamins, & Cox, 2013).                                 of the curve a e−x/τ for the experimental and simulated data,
                                                                         respectively. Experimental data from Bi and Poo (2001).
Table 1: Parameters used for transmitting semantic pointers
   Parameter     Description                   Value                     hPES encourages sparsity while increasing signal
   N/D           Neurons per dimension           25                      transmission error
   κ             Learning rate              3.51 × 10−3                  When the hPES rule is applied to a network that has been opti-
   S             Supervision ratio             0.798                     mized to implement semantic pointer transmission, the hPES
   κ for S = 1 Learning rate (PES)          2.03 × 10−3                  rule with no supervision (S = 0) increases signal transmission
                                                                         error at a rate proportional to the learning rate. Figure 3 (top)
  Table 2: Parameters used for binding and classifying SPs               shows the gradual decrease in accuracy over 200 seconds of
    Parameter    Description                   Value                     simulation with an artificially large learning rate. Figure 3
    N/D          Neurons per dimension           25                      (bottom) shows that the sparsity of the weight matrix, as mea-
    κ            Learning rate              2.38 × 10−3                  sured by the Gini index, increases over time. Therefore, the
    S            Supervision ratio             0.725                     hPES rule with S = 0 increases network sparsity at the cost of
    κ for S = 1 Learning rate (PES)         1.46 × 10−3                  an increase in signal transmission error.
                                                                         hPES can learn cognitive functions
                                                                         The error in the learned networks relative to the mean of 10
                           Results                                       control networks can be seen decreasing over time in Fig-
                                                                         ure 4. The parameters used for Figure 4 are listed in Tables 1
hPES replicates STDP results                                             and 2. The transformations are learned quickly (approxi-
                                                                         mately 25 seconds for transmission, 45 seconds for binding).
Previously, Pfister and Gerstner (2006) have theorized that              Therefore, the central binding and transmission operations of
BCM and STDP are equivalent. Our experiments support this                the SPA are learnable with the hPES rule.
theory. Varying the amount of time between presynaptic and                  Critically, while hPES without error sensitivity introduces
postsynaptic spikes results in an STDP curve extremely simi-             error while increasing sparsity (see Figure 3), with error sen-
lar to the classical Bi and Poo (2001) STDP curve (Figure 1).            sitivity, this error can be overcome. Interestingly, binding, the
   However, these STDP curves do not capture the frequency               intuitively more complex operation, is more reliably learned
dependence of STDP. In order to capture those effects, mod-              than transmission. This is due to how effectively the NEF
ellers have created STDP rules that take into account triplets           can optimize weights to perform linear transformations like
and quadruplets of spikes, rather than just pre-post spike pair-         transmission in the control networks.
ings (Pfister & Gerstner, 2006). These rules are able to repli-             As a proof of concept that the hPES rule scales to high-
cate the frequency dependence of the STDP protocol. Fig-                 dimensional spaces, Table 3 shows that the learned handwrit-
ure 2 shows that, despite being a much simpler rule, the hPES            ten digit classification network classifies digits more accu-
rule with S = 0 also exhibits frequency dependence.                      rately than Spaun’s cleanup memory (Eliasmith et al., 2012).
                                                                   172

                                             Frequency dependence of STDP                                                        1.0
                                                                                                                                       Unsupervised learning in control network
                                                                                                         Transmission accuracy
                                                                                                                                 0.8
 Change in connection weight (%)
                                   20
                                                                                                                                 0.6
                                   10                                                                                            0.4
                                                                                                                                 0.2
                                    0                                                                                            0.0
                                                                                                   Weight sparsity
                                                               Low activity (simulation)                                   0.60
                                   -10                         Low activity (experiment)                                   0.55
                                                               High activity (simulation)
                                                               High activity (experiment)                                  0.50
                                   -20                                                                                     0.45
                                         1             5      10 20          50     100
                                                  Stimulation frequency (Hz)                                                       0         50              100            150   200
                                                                                                                                                  Simulation time (seconds)
Figure 2: STDP frequency dependence replicated by two neu-
                                                                                                  Figure 3: Data gathered from 50 trials of Experiment 1; filled
rons connected with the hPES rule, S = 0. This also demon-
                                                                                                  region represents a bootstrapped 95% confidence interval.
strates the effect of different θ values on the frequency depen-
                                                                                                  (Top) Accuracy of signal transmission. Accuracy is propor-
dence curve. Experimental data from Kirkwood et al. (1996).
                                                                                                  tional to negative mean squared error, scaled such that accu-
                                                                                                  racy of 1.0 denotes a signal identical to that transmitted by
This supports the suggestion that the hPES rule scales to                                         the NEF optimal weights with no learning, and accuracy of
high-dimensional spaces. While the hPES rule with S < 1                                           0.0 represents no signal transmission (i.e., the error is equal
achieved higher classification accuracy than hPES with S = 1,                                     to the signal). (Bottom) Sparsity of the connection weight
not enough trials were attempted to statistically confirm a                                       matrix over time, as measured by the Gini index. This demon-
benefit to combined unsupervised and supervised learning for                                      strates the expected tradeoff between sparsity and accuracy.
classifying handwritten digits.
                          Table 3: Classification accuracy of handwritten digits
                                                                                                                                                   Discussion
                                         Classification technique    Accuracy                     In this paper, we have presented a novel learning rule for
                                         Cleanup memory (Spaun)      94%                          learning cognitively relevant transformations of neural repre-
                                         hPES learning, S = 1        96.31%                       sentations in a biologically plausible manner. We have shown
                                         hPES learning               98.47%                       that the unsupervised component of the rule increases sparsity
                                                                                                  of connection weights at the cost of increased signal transmis-
                                                                                                  sion error. We have also shown that the combined learning
hPES is less sensitive to parameters                                                              rule, hPES, can learn transformations as well as the super-
The parameters of the hPES rule were optimized with S fixed                                       vised rule and the offline optimization done in the Neural En-
at 1 for 50 simulations of binding and transmission. A sep-                                       gineering Framework. We have demonstrated that the com-
arate parameter optimization that allowed S to change was                                         bined learning rule is more robust to changes in parameters
done for 50 simulations of binding and transmission.                                              when learning nonlinear transformations.
   Surprisingly, despite optimizing over an additional dimen-                                        However, it is still the case that the parameters of the learn-
sion, when S was allowed to change, error rates were lower                                        ing rule were optimized for each transformation learned. This
during the optimization process for the binding network but                                       is a challenge shared by all learning rules, but in the context
not the transmission network. In both cases, the interquartile                                    of biologically plausible simulations, there is the additional
range of the hPES rule’s performance when S was allowed                                           question of the biological correlate of these parameters. It
to change is lower. Figure 5 summarizes the performance                                           could be the case that these parameters are a result of the
of all 200 networks generated for parameter optimization.                                         structure of the neuron, and therefore act as a fixed prop-
While in all four cases parameters were found that achieve                                        erty of the neuron. However, it could also be the case that
error rates close to the control networks, hPES was more ro-                                      these parameters are related to the activity of the network,
bust to changes in parameters when S was allowed to change.                                       and are modified by each neuron’s activity, or by the activity
This suggests that unsupervised learning may be beneficial in                                     of some external performance monitoring signal. Examining
high-dimensional nonlinear situations.                                                            these possibilities is the subject of future work.
                                                                                            173

                                             Learning binding                Learning transmission                                                                  Error rates for all parameter sets
                                  1.6                                                                     10                                           1.5
                                                                  hPES                            hPES                                                                                                    2.5
                                  1.5                             PES                             PES                                                  1.4
                                                                                                                      Error relative to control mean
                                                                                                          8
 Error relative to control mean
                                  1.4
                                  1.3                                                                                                                  1.3                                                2.0
                                                                                                          6
                                  1.2                                                                                                                  1.2
                                  1.1                                                                     4                                                                                               1.5
                                                                                                                                                       1.1
                                  1.0
                                                                                                          2
                                  0.9                                                                                                                  1.0                                                1.0
                                  0.8                                                                      0
                                        0    20        40      60        0   5 10 15 20 25               30                                            0.9
                                            Learning time (seconds)           Learning time (seconds)
                                                                                                                                                         Bind PES            S           S            S
                                                                                                                                                                     Bind hPE Transmit PE Transmit hPE
Figure 4: Error of learning networks over time compared to
the mean error of 10 control networks. Each type of network                                                          Figure 5: Summary of error rates for networks used to op-
is generated and simulated 15 times. For the binding net-                                                            timize learning parameters. Each column summarizes 50 ex-
work, every 4 seconds, the learning rule is disabled and error                                                       periments of the labeled condition. Boxes indicate the median
is accumulated over 5 seconds. For the transmission network,                                                         and inter-quartile range, and whiskers indicate the inner fence
every 0.5 seconds, the learning rule is disabled, and error is                                                       (i.e., Q1 − 1.5 IQR and Q3 + 1.5 IQR). Outliers are not shown.
accumulated over 2 seconds. Filled regions are bootstrapped
95% confidence intervals. Time is simulated time, not com-                                                             scale model of the functioning brain. Science, 338(6111),
putation time.                                                                                                         1202–5.
                                                                                                                     Georgopoulos, A. P., Schwartz, A. B., & Kettner, R. E.
                                                                                                                       (1986). Neuronal population coding of movement direc-
                                                       Acknowledgments
                                                                                                                       tion. Science, 233(4771), 1416–1419.
This work was supported by the Natural Sciences and En-                                                              Hinton, G., Osindero, S., & Teh, Y. (2006). A fast Learn-
gineering Research Council of Canada, Canada Research                                                                  ing Algorithm for Deep Belief Nets. Neural computation,
Chairs, the Canadian Foundation for Innovation and the On-                                                             1554, 1527–1554.
tario Innovation Trust. We also thank James Bergstra for cre-                                                        Kirkwood, A., Rioult, M. G., & Bear, M. F. (1996).
ating the hyperopt tool and assisting with its use.                                                                    Experience-dependent modification of synaptic plasticity
                                                                                                                       in visual cortex. Nature, 381(6582), 526–528.
                                                              References                                             Kohonen, T. (1982). Self-organized formation of topologi-
Bergstra, J., Yamins, D., & Cox, D. D. (2013). Making a                                                                cally correct feature maps. Biological Cybernetics, 43(1).
  Science of Model Search: Hyperparameter Optimization in                                                            Lazar, A., Pipa, G., & Triesch, J. (2009). Sorn: a self-
  Hundreds of Dimensions for Vision Architectures. In 30th                                                             organizing recurrent neural network. Frontiers in Compu-
  international conference on machine learning.                                                                        tational Neuroscience, 3(23).
Bi, G.-Q., & Poo, M.-M. (2001). Synaptic modification by                                                             MacNeil, D., & Eliasmith, C. (2011). Fine-tuning and the
  correlated activity: Hebb’s postulate revisited. Annual Re-                                                          stability of recurrent neural networks. PloS One, 6(9).
  view of Neuroscience, 24(1), 139–66.                                                                               Paugam-Moisy, H., Martinez, R., & Bengio, S. (2008). De-
Bienenstock, E. L., Cooper, L. N., & Munro, P. (1982). The-                                                            lay learning and polychronization for reservoir computing.
  ory for the development of neuron selectivity: orientation                                                           Neurocomputing, 71(7), 1143–1158.
  specificity and binocular interaction in visual cortex. Jour-                                                      Pfister, J.-P., & Gerstner, W. (2006). Triplets of spikes in
  nal of Neuroscience, 2(1), 32.                                                                                       a model of spike timing-dependent plasticity. Journal of
Bohte, S. M., Kok, J. N., & Poutre, H. L. (2002). SpikeProp:                                                           Neuroscience, 26(38), 9673–82.
  Backpropagation for networks of spiking neurons. Neuro-                                                            Ponulak, F. (2006). Supervised learning in spiking neural
  computing, 48(1-4), 17.                                                                                              networks with ReSuMe method. Phd thesis, Poznan Uni-
Eliasmith, C. (in press). How to build a brain: A neural ar-                                                           versity of Technology.
  chitecture for biological cognition. New York, NY: Oxford                                                          Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986).
  University Press.                                                                                                    Learning representations by back-propagating errors. Na-
Eliasmith, C., & Anderson, C. H. (2003). Neural engineer-                                                              ture, 323(6088), 533–536.
  ing: computation, representation, and dynamics in neuro-                                                           Tang, Y., & Eliasmith, C. (2010). Deep networks for robust
  biological systems. Cambridge, MA: MIT Press.                                                                        visual recognition. In 27th international conference on ma-
Eliasmith, C., Stewart, T. C., Choo, X., Bekolay, T., DeWolf,                                                          chine learning. Haifa, Il: ICML.
  T., Tang, Y., Tang, C., & Rasmussen, D. (2012). A large-
                                                                                                               174

