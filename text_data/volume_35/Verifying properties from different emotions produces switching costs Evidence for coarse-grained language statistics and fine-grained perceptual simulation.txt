UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Verifying properties from different emotions produces switching costs: Evidence for coarse-
grained language statistics and fine-grained perceptual simulation
Permalink
https://escholarship.org/uc/item/69w9r6fc
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Tillman, Richard
Hutchinson, Sterling
Jordan, Sara
et al.
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Verifying properties from different emotions produces switching costs: Evidence for
          coarse-grained language statistics and fine-grained perceptual simulation
                                                 Richard Tillman (rntllman@memphis.edu)
                          Department of Psychology/ Institute for Intelligent Systems, University of Memphis
                                              365 Innovation Drive, Memphis, TN 38152 USA
                                               Sterling Hutchinson (schtchns@memphis.edu)
                          Department of Psychology/ Institute for Intelligent Systems, University of Memphis
                                              365 Innovation Drive, Memphis, TN 38152 USA
                                                     Sara Jordan (sara.jordan@mlh.org)
                  Department of Rehabilitation Services, Speech Language Pathologist/ Methodist North Hospital,
                                                      Methodist LeBonheur Healthcare
                                           3960 New Covington Pike Memphis, TN 38128 USA
                                               Max M. Louwerse (maxlouwerse@gmail.com)
                          Department of Psychology/ Institute for Intelligent Systems, University of Memphis
                                              365 Innovation Drive, Memphis, TN 38152 USA
                             Tilburg Centre for Cognition and Communication (TiCC), Tilburg University,
                                             PO Box 90153, 5000 LE, Tilburg, The Netherlands
                              Abstract                                 sentence compatibility effect whereby language processing
                                                                       is facilitated when a congruent response motion is used to
  We investigated whether emotions are activated during
  comprehension of emotion words. In the first part of the             respond to sentences describing motion away from or
  study, an experiment was conducted in which participants             towards the body. That is, sentences describing motion
  read sentence pairs each describing an emotional state and           away from the body (e.g., close a drawer) were processed
  then engaged in a judgment task. Sentences were paired to            faster when response motions were also moving away from
  either match or mismatch in emotion (happy, sad, or angry).          the body, and vice versa. These results and findings similar
  We predicted that the sentences that mismatch in emotion             to these demonstrate that linguistic processing is facilitated
  produced longer reaction times than those where the emotion          through perceptual-motor information (see Leventhal, 1982
  was the same, and that shifts between negative emotions had          for an overview).
  less of an impact. In the second part of the study, we
                                                                          Similar to action related sentences, sentences with
  calculated the frequency of first-order co-occurrences of
  nouns and adjectives related to happy, sad, and angry                emotional content have also provided support for an
  emotional states. This analysis demonstrated emotion words           embodied cognition account. Mouilso, Glenberg, Havas,
  are more often accompanied by similar emotion words.                 and Lindeman (2007) found that reading ‘angry’ sentences
  Match and mismatch of emotion explained RTs as did                   resulted in faster movements away from the body and
  statistical linguistic frequencies of the words. The                 reading ‘sad’ sentences resulted in faster movements toward
  combination of these two studies contributes to a growing            the body. In other words, when people read angry content,
  body of research that supports the importance of both                they processed the sentence faster with an aggressive action
  symbolic and perceptual processing of emotion.                       toward it, whereas ‘sad’ sentences evoke a withdrawal
                                                                       action, suggesting that emotional language can affect bodily
  Keywords: emotion; embodied cognition;                 symbolic      responses.
  cognition; statistical linguistic frequencies.
                                                                          Embodied responses have also been linked to cognition
                                                                       through the facial feedback hypothesis (Strack, Martin, &
                           Introduction                                Stepper, 1988; Zajonc, Murphy, & Inglehart, 1989). The
Theories of embodied cognition claim that cognition is                 facial feedback hypothesis demonstrates that facial
fundamentally based in perceptual experiences. That is,                expressions might influence emotional assessments. For
concepts only become meaningful through comprehenders                  example, when participants were instructed to smile,
mentally reenacting prior physical and perceptual                      cartoons were perceived as more humorous than when
experiences with the concept in the real world (Barsalou,              subjects were not smiling (Strack et al., 1988), showing that
1999; Barsalou, Simmons, Barbey, & Wilson, 2003;                       bodily states can affect both judgments and cognition.
Glenberg & Kaschak, 2002; Pecher & Zwaan, 2005; Havas,                    Most literature supporting an embodied cognition
Glenberg, & Rinck, 2007; Semin & Smith, 2008). For                     account, however, demonstrates evidence without physical
instance, Glenberg and Kaschak (2002) proposed the action-             manipulation. For example, Pecher, Zeelenberg, & Barsalou
                                                                  3551

(2003) found that subjects read sentences describing               information; 2) language users rely both on language
features within the same modality faster than sentences            statistics and perceptual simulation in cognitive processes;
describing features of differing modalities. When                  3) the relative dominance of language statistics and
participants read a sentence like apples can be tart followed      perceptual simulation factors is modified by stimulus type
by the sentence apples can be sweet (describing the same           and task.
gustatory modality) response times were faster for the                Although modality shifts have been shown to support the
second sentence when the second sentence did not describe          Symbol Interdependency Hypothesis (Louwerse & Connell,
a shift in modality, such as is the case when a visual             2011), the question can be raised whether the finding for
modality was presented in strawberries can be red or radios        modality shifts can be extended to other semantic domains
can be loud. The modality of the target words impacted how         that have shown embodiment effects, such as emotions. In
those words were perceived. Processing costs incurred from         the current study we investigated whether (a) verifying
the mismatched sentences resulted from a perceptual                properties from different emotions for concepts produces
modality shift, suggesting that perceptual embodied features       switching costs, similar to the modality shifts; (b) whether
indeed impact language processing times.                           language has encoded the emotions of words, similar to the
   Recently, the modality switching costs have been                modality of words; (c) whether emotion shifts can be
explained by language statistics (Louwerse & Connell,              explained by a language statistics account.
2011). By computing the word frequencies of the co-                   To explore these questions we applied Pecher et al.’s
occurrences of modality words from a large corpus of               (2003) modality shift paradigm to emotions. Emotional
English, Louwerse and Connell were able to identify                sentences shifted from happy to sad, sad to happy, happy to
modality shifts similar to Pecher et al. (2003). This analysis     angry, angry to happy, sad to angry, and angry to sad.
was not only applicable to the adjectives (e.g., tart – sweet      According to an embodied cognition account, switches
being more frequent than tart – red or sweet – red), but also      between emotions should take longer to process than non-
to concept words (e.g., apples – strawberries being more           switches       (happy-happy,      sad-sad,      angry-angry).
frequent than apples – radio or strawberries – radio).             Alternatively, according to a language statistics account, co-
Louwerse and Connell (2011) showed that these frequencies          occurrence frequencies of word pairs should be able to
explained the response times that were attributed to an            equally account for subject RTs. We thereby made two
embodied cognition account. That is, faster response times         hypotheses: (1) as with modality shifts, emotion shifts
were best explained by language statistics, slower response        would take longer to process than non-shift sentence pairs,
times were best explained by perceptual simulations.               which would be in support of an embodied cognition
Louwerse and Connell’s explanation was that the linguistic         account and (2) the same pattern of emotion shift cost would
system offers a ’quick and dirty’ shallow heuristic that can       emerge from language such that emotion words that
provide good enough performance in cognitive tasks                 matched in valence would co-occur more frequently than
without recourse to deeper conceptual processing in a              the words that did not match in valence, which would be in
perceptual simulation system. On the other hand, ultimately        support of a linguistic account.
concepts are grounded and can be perceptually simulated.
The explanation by Louwerse and Connell can be captured                         Experiment 1: Emotion Shift
in the Symbol Interdependency Hypothesis, which proposed
that conceptual processing can be explained by both symbol         Method
and embodied mechanisms (Louwerse, 2007; 2008; 2011).              Participants Thirty-three undergraduate students enrolled
When we encounter a word, we garner a rough meaning                in an introductory psychology course participated for course
from its linguistic (symbolic) neighbors using language            credit.
statistics, but to fully ground the word, we perceptually             Materials Sixty emotion sentences were created,
simulate its physical and somatosensory features. Thus,            following the method described in Pecher et al. (2003) with
words can rely on other words to establish a fuzzy sense of        each sentence in the format X can be Y. There were 3
meaning without necessarily always being grounded                  experimental types of emotions depicted in the sentences:
themselves. In other words, perceptual information is              angry, happy, and sad. For example, birthdays can be happy
encoded in language, such that mental representations are          (happy emotion), and insults can be devastating (sad
both perceptual and linguistic. Human beings can rely on           emotion).
such a linguistic short-cut when processing language in real          The reason we selected angry, happy, and sad emotions
time. However, if a deeper meaning or understanding is             was motivated by work from Isenhower et al. (2003) who
needed, grounding the world in perceptual experiences              found that people tend towards more positive states of
provides rich sensorimotor information about meaning.              emotion. That is, switching from positively valenced to
Importantly, language has encoded sensorimotor                     negatively valenced emotions yields a greater disruption and
information, such that language users can utilize these cues       requires additional cognitive processing. Further motivation
in cognitive processes.                                            came from a more recent study by Stein and Sterzer (2012).
   In short, the Symbol Interdependency Hypothesis                 In this study, Stein and Sterzer demonstrated that people
proposes the following: 1) language encodes perceptual             identify happy faces more quickly than angry faces. We
                                                               3552

therefore selected happy, sad, and angry words, and thus             In summary, a shift from happy to sad, happy to angry,
had one positively valenced emotion (happy) and two               sad to angry, and angry to happy yielded significant results,
negatively valenced emotions (sad and anger).                     while the shift from sad to happy was not significant. Figure
                                                                  1 shows the means and standard deviations for each emotion
   Procedure Participants were seated at a computer in a          shift pair.
standard computer lab. The instructions for the experiment           Even though no overall effect for emotion shift was
were presented on the screen and read aloud by the                found, patterns for specific emotion transitions did show
experimenter. Five practice items preceded the experimental       shift effects, with specific emotion to emotion shifts
phase to ensure participants understood the task.                 resulting in longer RTs than non-shifts. More specifically,
Participants saw sentences one at a time in the center of the     the shifts from happy to the two negative emotions, shows a
screen and then were asked to respond to the question Is the      significant increase in RT. The emotion shift from angry to
characteristic true of the items it described? Participants       happy was also significant, but showed a decrease in RT
pressed designated yes or no keys on the keyboard. RT and         from angry followed by angry. This is in line with Stein and
accuracy were recorded.                                           Sterzer (2012), who found that people are quicker to
                                                                  identify happy faces, rather than angry faces. We interpret
Results                                                           this decrease in RT in terms of the nature of the shift. Angry
Incorrect responses were not included in the analyses. RT         followed by angry produces the longest RT, while happy
outliers were defined as 2.5 SD above the mean per subject        followed by happy produces the shortest RT. As there is a
per condition and were removed from the analysis. This            tendency to prefer to shift toward a more positive state
removal affected less than 3.6% of the data.                      (Isenhower, Frank, Kay, & Carello, 2010), the reaction
   A mixed-effect analysis was conducted on RTs with              times for the non-shifts reflected this. Moreover, the shift
emotion shift as the fixed factor and participants and items      from angry to happy decreases from its origin (angry
as random factors (Baayen, Davidson, & Bates, 2008). The          followed by angry), because of the natural tendency to shift
model was fitted using the restricted maximum likelihood          to the more positive state. This is supported by the
estimation (REML) for the continuous variable (RT). F-test        significant differences when emotion shifts took place
denominator degrees of freedom were estimated using the           between angry and happy, angry and sad, and sad and angry.
Kenward-Roger’s degrees of freedom adjustment to reduce              However, we still are unable to determine whether an
the chances of Type I error (Littell, Stroup, & Freund,           embodiment effect exists for emotion switching, as there
2002). Participants and items were treated as random factors      was no overall effect for shifts as there were for Pecher et al.
in the analysis.                                                  (2003), but only specific emotion to emotion effects.
   For the factor emotion shift no differences were found in
RT, F(1,114) = .431, p = .513. This is somewhat surprising
given that an emotion shift was predicted to increase RTs
akin to the modality shifts. However, when individual
emotion pairs were separated by transition (e.g., happy-sad,
happy-angry), RT differences were obtained with an
emotion shift from happy sentences to sad sentences,
F(1,421) = 30.41, p < .001, with slower RTs for the shift
than no-shift (i.e., a happy sentence followed by a happy
sentence). Also, when shifting from happy sentences to
angry sentences a significant difference was found between
the two conditions, F(1,380) = 20.82, p < .001, there were
slower RTs for the emotion shift sentences than no-shift.
When the sad to angry sentences were compared, again a
difference approaching significance was found between
emotion shift and no-shift conditions, F(1,455) = 5.88, p <
.056, where the shift between sentences yielded longer RTs
than no-shift. In contrast, the comparison of sad to happy
sentences yielded no significant differences between
emotion shift and no-shift sentences, F(1,395) = .02, p <
                                                                     Figure 1. Emotion shifts, means, and standard deviations.
.89. When switching from angry to happy sentences, a
                                                                     ** p < .01, * p < .05, n.s. not significant. The means and
significant effect was found, F(1,485) = 20.69, p < .001,
                                                                  standard deviations located at the emotion words indicate no
again with faster RTs for the emotion shift sentences than
                                                                    emotion shift (e.g., a happy sentence followed by a happy
no-shift. Finally, a significant effect was found when
                                                                                              sentence).
switching from angry to sad sentences, F(1,430) = 5.05, p <
.03, however with faster RTs for the emotion shift sentences
                                                                     To determine whether or not overall shifts for emotions
than the no-shift sentences.
                                                                  occurred, we ran a second experiment whereby the
                                                              3553

embodiment effect would be enhanced by an embodied                   sadness and anger; it would stand to reason why there were
facial feedback paradigm.                                            no significant differences between these two conditions as
                                                                     they are both negative emotions and the motor system
   Experiment 2: Facial Feedback Hypothesis                          necessary for their simulation was already active,
In order to determine if emotion switching indeed supports           facilitating the effect. Figure 2 shows the means and
an embodied cognition account, we examined the effects of            standard deviations for each emotion shift pair, the shift
the facial feedback hypothesis (Strack, et al., 1988; Zajonc,        direction, and the no shift means and standard deviations.
et al., 1989) by assessing the effects different conditions
(frowning or smiling) had on RTs when judging emotion
shift sentences. We hypothesized that neither frowning nor
smiling would produce a significant effect between the
negative emotions (sadness and anger), due to the trend
towards positive (Isenhower et al., 2010). In addition, we
hypothesized that the specific emotion to emotion shifts
found in Experiment 1 would show similar patterns.
Method
Participants Twenty-six undergraduate students enrolled in
an introductory psychology course participated for course
credit.
   Materials The same materials were used as in
Experiment 1.
   Procedure The procedure was the same as that used in
Experiment 1, with one important addition. Participants
were also randomly assigned to one of two facial feedback
conditions (Strack et al., 1988). In the one condition, the
participants held a pen in their lips (n = 15) to simulate               Figure 2. Emotion shifts, means, and standard deviations
frowning; in the other, the participants held a pen in their           for frowning facial feedback condition. ** p < .01, * p <
teeth (n = 11) to simulate smiling.                                                       .05, n.s. not significant.
Results                                                                 Smiling Facial Feedback When participants held the pen
As in Experiment 1, emotion shifts did not yield a                   in their teeth to simulate smiling, the shift from happy to sad
significant difference in RT, F(1, 117.27) = .16, p =.70.            was significant, F(1,168) = 8.98, p < .003, with higher RT
Furthermore, there seemed to be no main effect of the facial         for the shift sentences than no-shift . The shift from happy
feedback conditions, F(2, 78.24) = .73, p = .49. Next, we            to angry was significant, F(1,164) = 15.48, p < .0001, with
investigated the emotion transitions per facial feedback             higher RTs for the shift sentences than no-shift . The shift
condition (smiling vs. frowning).                                    from sad to happy approached significance, F(1,134) = 3.81,
                                                                     p < .053, with lower RT for the shift sentences than no-shift.
   Frowning Facial Feedback When participants held the               Finally, the shift from angry to happy was also significant,
pen in their lips to simulate frowning, the shift from happy         F(1,179) = 17.84, p < .001, with lower RT for the shift
to sad was significant as it was in the previous experiment          sentences than no-shift . Again, the decrease in RT for angry
without the facial feedback task, F(1,236) = 6.69, p = .01,          to happy is in accord with Stein and Sterzer (2012). The
with higher RTs for the shift sentences than no-shift. The           shifts from sad to angry and angry to sad were not found to
shift from happy to angry was also significant as found in           be significant. Figure 3 shows the means and standard
the previous experiment, F(1,202) = 8.36, p < .004, with             deviations for each emotion shift pair, the shift direction,
higher RTs for the shift sentences than no-shift. Also the           and the no shift means and standard deviations. The main
shift from angry to happy was significant as previously              difference between the smiling condition and the previous
found in Experiment 1, F(1,248) 4.31, p < .04, with lower            frowning condition is the significant difference found in the
RT for the shift sentences than no-shift. Again, this is in line     sad to happy shift, which was not found in Experiment 1, or
with Isenhower et al. (2010) and Stein and Sterzer (2012), in        the frowning facial feedback condition. This difference
that the preference is to shift from a negative state to a           supports the findings by Isenhower et al. (2010), in that
positive state. This is especially true given the fact that          since people have a tendency to tend towards a positive
participants were frowning due to the facial feedback task.          state, which they have in part done by smiling.
The shifts from sad to angry and angry to sad were found to
be non-significant, unlike the findings in Experiment 1.
These results lend support to the facial feedback hypothesis,
in that frowning (pen held in lips) is associated with both
                                                                 3554

                                                                   emotion shift was present (M = 1.11, SE = .054). This
                                                                   pattern was also found for just the nouns F(1, 3479) =
                                                                   148.11, p < .001, with word pairs where there was no
                                                                   emotion shift (M = 4.29, SE = .08) being more frequent than
                                                                   word pairs where an emotion shift was present (M = 2.60,
                                                                   SE = .11). Again, this pattern was found for adjectives, F(1,
                                                                   3598) = 279.17, p < .001, with word pairs where there was
                                                                   no emotion shift (M = 2.53, SE = .05) being more frequent
                                                                   than word pairs where an emotion shift was present (M =
                                                                   1.00, SE = .07).
                                                                      In addition, we also compared the log frequencies of each
                                                                   of the word pairs to the experimental RT over the collapsed
                                                                   match and mismatch conditions (extracted from
                                                                   Experiments 1 and 2). Language statistics significantly
                                                                   predicted RTs, F(1, 113.564) = 34.53, p < .001. However,
                                                                   language statistics did not predict emotional transitions.
                                                                   Statistical linguistic frequencies explained RTs of general
                                                                   emotion shifts, but not RTs of specific emotion transitions.
    Figure 3. Emotion shifts, means, and standard deviations
 for smiling facial feedback condition. ** p < .01, * p < .05,                        General Discussion
                       n.s. not significant
                                                                      Previous studies have found that two sentences that elicit
                                                                   a modality shift produce cognitive switching costs,
                Corpus Linguistic Study                            compared to sentences that describe the same modality
                                                                   (Pecher et al., 2003). This finding has been reported as
So far, the results seem to suggest that emotional states can      evidence for an embodied cognition account, because the
be based in embodied cognition, as some emotion to                 increased RTs are an indication that comprehenders
emotion shifts seem to indicate that emotion switching             perceptually simulate the sentences. Others have shown that
usually incurs some sort of processing cost. However, this is      modality is encoded in language. Based on language
not the whole picture, as it does not take into consideration      statistics, concepts and their features can be categorized in
the linguistic nature of the words. We therefore investigated      visual, auditory, olfactory and gustatory modalities
whether emotion shifts are encoded in language (Louwerse,          (Louwerse & Connell, 2011). Moreover, when the RTs for
2008; Louwerse & Connell, 2011). To do this we calculated          modality shifts were investigated with both language
the frequency of first-order co-occurrences of all the             statistics and perceptual simulation as independent
possible combinations of the nouns and adjectives in the           variables, fast RTs were best explained by language
present study by utilizing the Web 1T 5-gram corpus                statistics and slower RTs were best explained by perceptual
(Brants & Franz, 2006). This corpus consists of 1 trillion         simulation. Louwerse and Connell (2011) concluded that
word tokens (13,588,391 word types) from 95,119,665,584            language statistics serves as a coarse-grained system that
sentences. The volume of the corpus allows for an extensive        serves as a shallow heuristic. Perceptual simulation, on the
analysis of patterns in the English language. The frequency        other hand, serves deeper conceptual processing. The idea
of co-occurrences of the word pairs was computed for               that language encodes perceptual information and that these
bigrams, trigrams, 4-grams and 5-grams. For instance, the          linguistic cues can be used by language users in shallow
frequency of the phrase birthdays can be happy {happy,             comprehension tasks is predicted by the Symbol
birthday} was determined by considering these words next           Interdependency Hypothesis and supported by various
to one another {happy birthday}, with one word in between          studies (Louwerse, 2008; Louwerse & Hutchinson, 2012;
{happy w1 birthday}, with two {happy w1 w2 birthday},              Louwerse & Jeuniaux, 2008; 2010).
three intervening words {happy w1 w2 w3 birthday}, and so             The current study investigated whether emotion shifts
on.                                                                mimicked the patterns found for previous studies
   A mixed effects analysis was conducted on the frequency         investigating modality shifts. Even though across three
of co-occurrences of the emotion adjectives and the noun           experiments no general effect was found for shifts, specific
referents. The independent variable was whether the                transitions between emotions did yield differences in RTs.
emotion words were the same or different emotion, and the          Moreover, evidence was found that language encodes
log frequency of the word pair was the dependent variable.         emotion shifts, and language statistics explained RTs for
   For all possible combinations of both nouns and                 these general shifts.
adjectives, the log frequency of the co-occurrences were              The findings of the current study are supported by the
found to be significant, F(1, 7078) = 212.76, p < .001, with       Symbol Interdependency Hypothesis as well as by findings
word pairs where there was no emotion shift (M = 2.08, SE          reported in other studies. Language statistics explained
= .04) being more frequent than word pairs where an                coarse-grained emotion shifts. However, language statistics
                                                               3555

did not explain fine-grained shifts. On the other hand,           Louwerse, M. M. (2008). Embodied relations are encoded in
assuming that a perceptual simulation system is responsible         language. Psychonomic Bulletin & Review, 15, 838-844.
for the other RT differences that were obtained in the two        Louwerse, M. M. (2011). Symbol interdependency in
experiments, the perceptual system did not explain the              symbolic and embodied cognition. TopiCS, 3, 273-302.
coarse-grained differences in general emotion shifts, but did     Louwerse, M. M., and Connell, L. (2011). A taste of words:
explain the fine-grained shifts between specific emotions.          linguistic context and perceptual simulation predict the
  These results provide further evidence for the theory that        modality of words. Cognitive Science, 35, 381–398.
conceptual processing is both linguistic and embodied,            Louwerse, M. M., & Jeuniaux, P. (2010). The Linguistic
whereby less precise linguistic processes account for general       and Embodied Nature of Conceptual Processing.
patterns in processing, whereas perceptual simulation               Cognition, 114, 96-104.
provides the fine-tuning.                                         Louwerse, M. M. & Jeuniaux, P. (2008). Language
                                                                    comprehension is both embodied and symbolic. In M. de
                        References                                  Vega, A. Glenberg, & A. C. Graesser (Eds.), Symbols and
                                                                    Embodiment: Debates on Meaning and Cognition.
Baayen, R. H., Davidson, D., & Bates, D. (2008). Mixed-             Oxford, England: Oxford University Press.
  effects modeling with crossed random effects for subjects       Mouilso, E., Glenberg, A. M., Havas, D. A., & Lindeman,
  and items. Journal of Memory and Language, 59, 390-               L. M. (2007). Differences in action tendencies distinguish
  412.                                                              anger and sadness after comprehension of emotional
Barsalou, L. W. (1999). Perceptual symbol systems,                  sentences. Proceedings of the 29th Annual Cognitive
  Behavioral and Brain Sciences, 22, 577–660.                       Science Society, 14, 1325-1330.
Barsalou, L. W., Simmons, W.K., Barbey, A.K., & Wilson,           Pecher, D., & Zwaan, R. (Eds.) (2005). Grounding
  C.D. (2003). Grounding conceptual knowledge in                    cognition: The role of perception and action in memory,
  modality-specific systems, Trends in Cognitive Sciences,          language, and thought. New York: Cambridge University
  7, 84–91.                                                         Press.
Brants, T., & Franz, A. (2006). Web 1T 5-gram version 1.          Pecher, D., Zeelenberg, R., & Barsalou, L.W. (2003).
  Philadelphia: Linguistic Data Consortium.                         Verifying different-modality properties for concepts
Brysbaert, M. (2007). The language-as-ﬁxed-effect fallacy:          produces switching costs. Psychological Science, 14, 119-
  Some simple SPSS solutions to a complex problem                   124.
  (version 2.0). Royal Holloway, University of London.            Semin, G. & Smith, E. (Eds.) (2008). Embodied grounding:
  Technical report.                                                 Social, cognitive, affective, and neuroscientific
Ekman, P., & Rosenberg, E. L. (2004). What the face                 approaches. New York: Cambridge University Press.
  reveals: basic and applied studies of spontaneous               Stein, T., & Sterzer, P. (2012). Not just another face in the
  expression using the facial action coding system (FACS),          crowd: Detecting emotional schematic faces during
  New York: Oxford University Press.                                continuous flash suppression. Emotion, 12, 988-996.
Glenberg, A. M. (2007). Language and action: creating             Strack, F., Martin, L. & Stepper, S. (1988). Inhibiting and
  sensible combinations of ideas. In G. Gaskell (Ed.) The           facilitating conditions of the human smile: A
  Oxford handbook of psycholinguistics (pp. 361-370).               nonobtrusive      test    of    the     facial    feedback
  Oxford, UK: Oxford University Press.                              hypothesis. Journal     of    Personality     and    Social
Glenberg, A. M., & Kaschak, M. P. (2002). Grounding                 Psychology, 54, 768-777.
  language in action. Psychonomic Bulletin & Review, 9,           Zajonc, R. B., Murphy, S. T., & Inglehart, M. (1989).
  558-565.                                                          Feeling and facial efference: Implications for the vascular
Havas, D., Glenberg, A. M., & Rinck, M (2007). Emotion              theory of emotion. Psychological Review, 96(3), 395-416.
  simulation during language comprehension. Psychonomic
  Bulletin & Review, 14, 436-441.
Isenhower, R. W., Frank, T. D., Kay, B. A., & Carello, C.
  (2010). Capturing and quantifying the dynamics of
  valenced emotions. Nonlinear Dynamics Psychology and
  Life Sciences, 16(4), 397-427.
Leventhal, H. (1982). A perceptual motor theory of
  emotion. Social Science Information, 21, 819-845.
Littell, R. C., Stroup, W. W., & Freund, R. J. (2002). SAS
  for Linear Models, 4th Edition. Cary, NC: SAS
  Publishing.
Louwerse, M. M. (2007). Symbolic embodied
  representations: A case for symbol interdependency. In T.
  Landauer, D. McNamara, S. Dennis, & W. Kintsch (Eds.),
  Handbook of latent semantic analysis. Mahwan, NJ:
  Erlbaum.
                                                              3556

