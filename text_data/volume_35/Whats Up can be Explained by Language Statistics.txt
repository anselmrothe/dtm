UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
What’s Up can be Explained by Language Statistics
Permalink
https://escholarship.org/uc/item/4h97698p
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Hutchinson, Sterling
Louwerse, Max
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             What’s Up can be Explained by Language Statistics
                                          Sterling Hutchinson (schtchns@memphis.edu)
                         Department of Psychology/ Institute for Intelligent Systems, University of Memphis
                                             365 Innovation Drive, Memphis, TN 38152 USA
                                          Max M. Louwerse (maxlouwerse@gmail.com)
                         Department of Psychology/ Institute for Intelligent Systems, University of Memphis
                                             365 Innovation Drive, Memphis, TN 38152 USA
                              Tilburg Centre for Cognition and Communication (TiCC), Tilburg University
                                             PO Box 90153, 5000 LE, Tilburg, The Netherlands
                              Abstract                                  experimental tasks cue participants to refer to relevant
                                                                        perceptual representations, language processing is
  Embodied cognition studies have demonstrated that when
  words found in high physical locations (e.g., bird) are               facilitated (Glenberg & Kaschak, 2002; Kaschak et al.,
  positioned at the top of a screen they are processed faster           2005; Pecher, van Dantzig, Zwaan, & Zeelenberg, 2009).
  than when they are positioned at the bottom of the screen.            For example, Zwaan and Yaxley (2003) demonstrated that
  The reverse effect is obtained for words found in low                 when word pairs appeared in their expected physical
  physical locations (e.g., fish). This concept-location                locations on a computer screen (e.g., ceiling presented at
  facilitation effect has been argued to demonstrate that               the top of the screen and floor presented at the bottom of
  cognitive processing is fundamentally perceptual in nature.           the screen), comprehension was faster than when pairs
  However, questions can be raised with regards to the                  appeared in unexpected physical locations on a computer
  absolute or relative location of these concept-location words         screen (e.g., floor presented at the top of the screen while
  We investigated whether semantic judgments were made
                                                                        ceiling was presented at the bottom of the screen). That is,
  with respect to an absolute location on the screen (embodied
  explanation) or with respect to a relative location in                it is easier to process a word when the expected physical
  comparison to other words included in the experimental                properties of the word match its actual physical properties.
  session (statistical linguistic explanation). In a response time      Accumulating research like this tends to suggest that
  experiment we presented participants with physical-location           individuals rely on perceptual representations, especially in
  words from existing studies at the top or bottom, top or              everyday language comprehension.
  center, and center or bottom of the screen. For animate words            This embodied cognition account of semantic
  we found a concept location facilitation effect for words             representations is often contrasted to an amodal (or
  presented at the top of the screen, at the center of the screen,      symbolic) account of cognition, whereby language is
  and at the bottom of the screen. In addition, however,                represented amodally. A classical symbolic account of
  language statistics explained RTs to center words. Findings
                                                                        language representation argues that semantic information is
  indicated that participants made judgments relative to other
  words on the screen and not relative to their absolute                seated in language and can be derived from relationships
  location on the screen, lending support to a statistical              that exist between symbols instead of from the mental
  linguistic explanation of the findings.                               reenactment of biomechanical and perceptual experiences.
                                                                        In other words, meaning is represented in a linguistic
  Keywords: concepts; embodied cognition; symbolic                      structure within the brain encoded in a formal abstract
  cognition; concept-location facilitation; perceptual
                                                                        language, and words are understood from their natural
                                                                        linguistic context instead of from their perceptual features.
                          Introduction                                     Recently, several studies have argued that an extreme
Embodied cognition theories state that language is                      symbolic or an extreme embodied cognition account is
understood through perceptual representations that are                  untenable, and that a more plausible cognitive model
grounded in modality-specific somatosensory experience                  includes both perceptual and symbolic processes in
(Barsalou, 1999; Glenberg, 1997; Semin & Smith, 2008).                  language comprehension (Barsalou, Santos, Simmons, &
Words become meaningful only after mentally reenacting                  Wilson, 2009; Louwerse, 2008; 2011a; Paivio, 1986). For
external perceptions and experiences associated with that               instance, Louwerse (2008; 2011a) proposed the Symbol
word. Thus, the patterns of neural activity that occur when             Interdependency Hypothesis. This hypothesis predicts that
comprehending a particular word would be similar to those               language encodes the perceptual information we tend to
patterns that occur when actually perceiving its referent               simulate. Consequently, language statistics allows for
(Hauk, Johnsrude, & Pulvermüller, 2004). In other words,                bootstrapping meaning with only minimal symbol
according to embodied cognition theories mental                         grounding in perceptual experiences. Put differently,
representations are couched in the physical and perceptual              according to the idea of symbol interdependency embodied
experiences of the body.                                                simulations and symbolic relationships are complementary
  There is a wealth of evidence supporting the embodied                 in conceptual processes.
cognition account, with evidence showing that when
                                                                   2596

   We also know from previous research that language                Šetić and Domijan (2007) study, t(153.37) = 0.64, p = .52.
statistics and perceptual simulations explain cognitive             Consequently, the concept-location word results only seem
processes to different extents under different conditions.          to support an embodied cognition account and are argued
For example, linguistic representations are relatively more         to be due to the congruency of the presentation location and
prominent early during processing whereas complete                  the perceptual features of the word: butterfly is processed
perceptual representations take longer to generate                  quickly at the top of the screen because a mental simulation
(Louwerse & Connell, 2010; Louwerse & Hutchinson,                   of a butterfly involves perceptual and spatial information
2012). Louwerse & Jeuniaux (2010) found that both task              about where a butterfly is found in the actual world (above
and stimulus influenced whether participants were more              the ground/at the top). This poses a challenge to an account
likely to rely on linguistic or perceptual information. Thus,       that argues for both linguistic and perceptual simulations
findings reporting effects for word pairs attributed to             factors in conceptual processing, such as proposed by the
embodied cognition (e.g., Zwaan & Yaxley, 2003) might               Symbol Interdependency Hypothesis.
likely also be explained by a statistical linguistic account.          Although it seems straightforward to conclude that these
For example, when participants were asked to make a                 effects must be due to the mental simulation of words,
semantic judgment about word pairs, the statistical                 there are alternative explanations. Lakens (2011a; 2011b)
linguistic frequency of the word pair best predicted RTs            argues that such effects might instead be due to polarity
whereas when participants were asked to make an iconic              correspondence. Proctor and Cho (2006) found that in
judgment about image pairs, perceptual ratings about the            binary classification tasks, concepts can be processed faster
pair better accounted for RTs (Louwerse & Jeuniaux,                 when their polarity matches the response polarity. In other
2010). Although both the linguistic and perceptual                  words, when a stimulus and a response are coded as either
information about the word pair showed to be relevant in            both positive or both negative, processing is facilitated,
both cognitive tasks, with both verbal and non-verbal               e.g., butterfly is processed quickly at the top of the screen
stimuli, different types of information were more, or less,         because its location is positive (up), as is the response to
important across different conditions.                              whether or not it is found in the sky (yes). In order to rule
    These studies demonstrate that both language statistics         out a polarity correspondence explanation for the results, in
and perceptual simulation must be taken into consideration          a similar experiment, Pecher, van Dantzig, Boot, Zanzolie,
together. After all, the Symbol Interdependency Hypothesis          and Huber (2010) asked participants to respond to the
argues that language encodes perceptual information,                question Is it usually found in the ocean? or to the question
making it difficult to disentangle the two variables. That is,      Is it usually found in the sky?. They argued that for a
effects attributed to statistical linguistic frequencies could      polarity correspondence explanation to be valid, yes
also be attributed to perceptual simulation and vice versa.         responses would be expected to be processed faster at the
Furthermore, studies demonstrating a language statistics            top of the screen, regardless of the question being asked,
effect use word pairs as stimuli (e.g., Louwerse &                  and regardless of word meaning. For instance, when being
Hutchinson, 2012; Louwerse & Jeuniaux, 2010; Tse,                   asked if an animal is found in the ocean, one would expect
Kurby, & Du, 2010).                                                 butterfly to be processed faster at the bottom of the screen
   However, evidence supporting an embodied cognition               because it is not found in the ocean, a hypothesis contrary
account also comes from single words, presented in                  to an embodied cognition explanation and a hypothesis that
different locations on a computer screen. For example,              was not supported. Instead, the results showed just the
Šetić and Domijan (2007) presented ‘up’ and ‘down’ words            opposite, i.e., when being asked if the animal is found in
one at a time either in an expected physical location or in         the ocean, butterfly was still processed faster at the top of
an unexpected physical location (e.g., butterfly would              the screen. In a response, Lakens (2011b) still suggested
either appear at the top of the screen (expected location) or       that perhaps butterfly is processed faster at the top of the
at the bottom of the screen (unexpected location)).                 screen, even when participants are making an ocean
Participants were asked to determine if the word they saw           judgment because the judgment becomes a relative
was something animate (living animal) or something                  assessment with down as the default response (as all
inanimate (non-living entity). As expected, patricipants            comparisons are made with reference to the ocean, which is
were faster to process concept-location matches (e.g.,              down).
butterfly presented at the top of the screen) than concept-            Lakens (2011b) goes further to point out that alternative
location mismatches (e.g., butterfly presented at the bottom        explanations for data explained solely by perceptual
of the screen). Unlike experiments comparing word pairs,            simulations should not be overlooked. In addition, Lakens
findings for words in isolation, such as those in Šetić and         (2011b) and Louwerse (2011b) both suggest that results
Domijan (2007), are more difficult to also explain with a           from Pecher et al. (2010) might likely also be explained by
statistical linguistic account. That is, unigram word               a statistical linguistic account. That is, although Pecher et
frequency does not explain congruency effects, as the set of        al. (2010) concludes that mental simulation accounts for
‘up words’ are not all more orless frequent than the set of         responses in the sky/ocean task, linguistic frequencies do
‘down words’. In fact, when comparing how frequently the            contribute to word meaning and should also be considered.
‘up words’ and ‘down words’ occurred in a massive corpus            To illustrate, Louwerse (2011b) found that ocean animal
of the English language (the Web 1T 5-gram corpus; Brants           names paired with the word ocean occur more frequently
& Franz, 2006), no difference was obtained between the              than ocean animal names paired with the word sky (and
frequencies of ‘up words’ and ‘down words’ inform the               vice versa for sky animal names) and that these frequencies
                                                               2597

account for subject RTs. In sum, findings previously                  presented at the top of the screen. In essence, if concept-
attributed to mental simulation accounts can also be                  location facilitation is found when words are presented in
explained by a statistical linguistic account, as was also            relative positions on the screen (i.e., above/below one
demonstrated in earlier research (Louwerse & Jeuniaux,                another) as opposed to absolute positions on the screen
2010). These findings illustrate that task instructions might         (i.e., at the top/bottom of the screen), it might be the case
influence response times because ocean and sky are more               that perceptual simulation (concept-location facilitation
or less linguistically associated with the stimuli. In other          effect) is not entirely accounting for RTs but rather,
words, linguistic explanations for these findings should              participants are making decisions about words presented in
also be explored.                                                     isolation by comparing those words to the group of words
   But it remains difficult to offer a linguistic explanation         included in the experiment.
for results when words are presented in isolation. Although
task instructions might influence the speeded responses, the                                     Method
frequency of butterfly – sky is only able to account for
faster RTs for congruent word categories and tasks while              Participants
still leaving mental simulations to offer the only
                                                                      Eighty-seven undergraduate native English speakers at the
explanation for the facilitative effect of the congruency of
                                                                      University of Memphis participated for extra credit in a
the presentation location and the perceptual features of the
                                                                      Psychology course. Participants were randomly assigned to
word (as unigram word frequency cannot account for these
                                                                      each of the three conditions (words presented at either a)
RTs). Perhaps linguistic information might play a role
                                                                      the top of the screen and the center of the screen, b) the
explaining these concept-location effects for isolated words
                                                                      center of the screen and the bottom of the screen, or c) the
after all. Although words are presented in isolation on the
                                                                      top of the screen and the bottom of the screen).
screen (i.e., one word is presented at a time), it is possible
that decisions might be made relative to the other words
presented in the other trials of the experiment. Such an              Materials
explanation would suggest that instead of making                      The experiment consisted of 48 living animal words that
judgments relative to the congruency between the concept              could be found in a low spatial location, (such as the
and the absolute position of the word on the screen (i.e., top        ground or ocean, n=24) or found in the sky (a high spatial
of the screen or the bottom of the screen), participants are          location, n=24). The remaining 48 words consisted of non-
making judgments relative to the other words in the                   living objects that could also be found in either high (n=24)
experiment. That is, participants might show a concept-               or low (n=24) physical locations. Words were extracted
location facilitation effect not because the words are                from both Pecher et al. (2010) and Šetić and Domijan
presented on the top and bottom of the screen, but rather             (2007).
because words are asynchronously presented relatively
above and below one another throughout the duration of                Procedure
the experiment.
   To explore this possibility, in this study we presented            The procedure was almost identical to Pecher et al. (2010)
participants with isolated words at either the top or bottom          and Šetić and Domijan (2007). Participants were asked if
(to replicate the original results), top or center, or center or      words presented on a 1280x1024 computer screen were
bottom of the screen. According to an embodied cognition              either living or nonliving. This task has the advantage that
account, if responses are faster because word meaning and             it does not bias participants to consciously judge the
world location are congruent, we would expect the same                physical location of a word. The center of the screen was
high and low words, presented in the center of the screen to          positioned at eye level. Similar to Pecher et al. (2010) and
show no concept-location facilitation effect because the              Šetić and Domijan (2007), each trial began with the
presentation location is not congruent with the physical and          presentation of three fixation crosses appearing on the
spatial properties of the simulated word. In other words,             screen for 300ms. Fixation crosses were presented either at
when butterfly is presented in the center of the screen,              the top, center, or bottom of the screen, depending on
processing should not be facilitated.                                 where the proceeding word would appear on the screen.
Alternatively, if decisions are based on the relationship             This occurred in order to notify participants where the next
between one word relative to the other words in the                   word would appear.
experiment (as opposed to being relative to the presentation             Words were presented at either the top and the center of
location of the word; a linguistic explanation), then we              the screen, the center and bottom of the screen, or – as in
might find that high words presented in the center of the             the original Šetić and Domijan (2007) study the top and
screen (concept-location mismatch) will still show a                  bottom of the screen, depending upon the between
concept-location facilitation effect if low words are                 participants condition. Upon presentation of a word,
presented at the bottom of the screen. That is, when                  participants indicated whether the word was living or not
butterfly is presented in the center of the screen, processing        living by pressing designed counterbalanced keys on the
will be facilitated if other words in the experiment are              keyboard (f and j keys). All words were seen once and
‘below’ a butterfly. Similarly, we might find that low                were counterbalanced for each participant where half the
words presented at the center of the screen would show a              high spatial location words were presented in the upper
concept-location facilitation effect if high words are                position (relative to the other presentation location, i.e., top
                                                                      relative to center/bottom or center relative to bottom) and
                                                                 2598

half in the lower position (i.e., bottom relative to center/top
or center relative to top), likewise for the low spatial
location words.
   If responses were slower than 2,500 ms a message
reading ‘TOO SLOW’ would appear. Participants were
asked to try to be as quick and as accurate as possible in
their responses. The next trial began immediately after the
subject’s response or after the feedback message.
                 Results and Discussion
Eleven participants were removed from the analysis
because >40% of their answers were incorrect. All
remaining participants were split evenly between
conditions. In all analyses, we used the parameters found in
Pecher et al. (2010) for outlier identification and removal.
Outliers were identified as those correct responses greater
than three standard deviations from the mean per subject             Figure 1: Average RTs in ms for the words appearing at
per item. Outlier removal (as described above) resulted in a                          the top of the screen.
loss of 2.8% of the data. All error trials were removed,
resulting in a loss of an additional 8.7% of the data.
   A mixed-effect regression analysis was conducted on
RTs with match/mismatch (match or mismatch between
word category (low or high spatial location word) and
relative presentation location (relatively high location of
top or center or relatively low location of center or
bottom)) as a fixed factor and participants and items as
random factors (Baayen, Davidson, & Bates, 2008). The
model was fitted using the restricted maximum likelihood
estimation (REML) for the continuous variable (RT). F-test
denominator degrees of freedom were estimated using the
Kenward-Roger’s degrees of freedom adjustment to reduce
the chances of Type I error (Littell, Stroup, & Freund,
2002).
   In addition to the location presentation manipulation, we
investigated the source of the RT differences in this task,
linguistic or embodied. An embodied account would be
predict a concept-location facilitation effect, whereas a            Figure 2: Average RTs in ms for the words appearing at
linguistic account would suggest these same effects are                             the center of the screen.
driven by language statistics. To further explore if
participants were relying on language statistics, we ran
analyses using word frequency as a fixed factor to
determine if a possible additional explanation for any
concept-location facilitation effects may exist. The word
frequency factor was calculated as the log frequency of
each word being presented obtained using the Web 1T 5-
gram corpus (Brants & Franz, 2006).
   Unlike Šetić and Domijan (2007), no significant concept-
location facilitation effect was found for words appearing
at the top of the screen, F(1, 2330)=1.46, p=.23, at the
center of the screen, F(1, 1599)=.10, p=.75, nor at the
bottom of the screen, F(1, 2395)=1.76, p=.19. Just as in
Pecher et al., (2010) these findings also fail to replicate the
concept-location facilitation effect found in Šetić and
Domijan (2007). In fact, there was no interaction between
location and word category for any of the three word
presentation locations and experimental conditions. Pecher
et al. (2010) offered the explanation that the concept
location facilitation effect is not well understood, with            Figure 3: Average RTs in ms for the words appearing at
some factors causing facilitation and others causing                               the bottom of the screen.
interference. The linguistic frequency factor did not explain
                                                                2599

the results either, with no significant main effects for words         In addition, in all conditions, words appearing relatively
appearing at the top of the screen, F(1, 2330)=.0001, p=.99,        below other words (M= 767.45, SD=267.40) were
the center of the screen, F(1, 1599)=.19, p=.66, nor the            processed significantly slower than words appearing
bottom of the screen, F(1, 2395)=.11, p=.74. These current          relatively above other words (M= 889.36, SD=421.41),
results seem to support neither an embodied cognition               t(4926) = 15.36, p <.001. That is, regardless of the absolute
account (as there was no concept-location facilitation for          location of the word on the screen, where-ever the bottom
the top-bottom condition) nor an alternative linguistic             position was (i.e., center of the screen or bottom of the
account (as there was no concept-location facilitation for          screen), words presented in that location were processed
either condition including the center location nor was              slower than the same words presented in a relatively higher
linguistic frequency significant). In the absence of a              location. Consider the case of the center presentation
replication in both the current study and in Pecher et al.          location: when words were presented in either the center of
(2010), perhaps the effects reported in Šetić and Domijan           the screen or the bottom of the screen, words took longer to
(2007) might be attributed to linguistic differences in the         process at the bottom and less time to process at the center.
Hungarian stimuli. Alternatively, such concept-location             However, when those same words were presented in the
facilitation effects might simply be relevant for certain           center or the top, they took longer to process in the center
groups of words and not others.                                     and less time to process at the top. This means that the
   To further explore the results of the current experiment,        same words presented in the same location are processed
and the possibility that words are processed relative to the        faster or slower simply due to whether other words are
words around them, we analyzed our findings mixed                   appearing above or below them. This at least suggests that
effects model but for animate versus inanimate words.               comparisons between high and low positions are biased
Words that were inanimate again showed no interactions              given that the center represents both the relative top and
for words appearing at the top of the screen, F(1, 1172)=.          bottom in different conditions.
003, p=.96 (see Figure 1), the center of the screen, F(1,              Finally, to explore whether participants indeed made
787)=.07, p=.80 (see Figure 2), or the bottom of the screen,        comparative judgments for words, we assessed whether
F(1, 1072)=.92, p=.34 (see Figure 3). Linguistic frequency          bigram frequencies were able to account for the response
was also not significant for words appearing at the top of          times of center words. As in previous studies (Louwerse,
the screen, F(1, 1172)=1.53, p=.22, the center of the screen,       2008) we operationalized the bigram linguistic frequencies
F(1, 787)=.62, p=.43, nor the bottom of the screen, F(1,            as the log frequency of a-b (e.g., owl-lizard) or b-a (e.g.,
1072)=.002, p=.96.                                                  lizard-owl) order of word pairs. Because words were
   However, words that were animate did show significant            presented individually on the screen, pairs were determined
interactions. Words appearing in any given location (top,           by the randomized presentation order. The bigram
center, and bottom) were processed faster when that                 frequency of each pair was assigned to the second word in
location was relatively the same as the word category. ‘Up          the randomly presented pair. The order frequency of all
words’ presented in the center were processed faster in the         word pairs within 3-5 word grams was obtained using the
center-bottom condition, whereas ‘down words’ presented             large Web 1T 5-gram corpus (Brants & Franz, 2006). A
in the center were processed faster in the top-center               mixed-effect regression analysis was conducted on RTs to
condition, F(1, 789)=6.10, p<.02. Figure 2 clearly                  center words with the bigram frequency as a fixed factor
illustrates RTs for matched and mismatched up and down              and participants and items as random factors (Baayen,
words presented in the center of the screen, showing that           Davidson, & Bates, 2008). Bigram frequency was a
words with a concept-location match are processed faster            significant predictor of RTs for center words only,
than words with a concept-location mismatch. Similarly,             F(1,906)=3.99, p=.05. This was true for all center words
‘up words’ presented in the top of the screen were                  regardless of experimental condition, implying that
processed faster in both the top-bottom and top-center              participants consider past trials while making judgments
conditions, F (1, 1134)=6.80, p<.01, (see Figure 1). Finally,       about the current word in question, and implying that a
‘down words’ presented in the bottom of the screen were             linguistic frequencies explain RTs during a concept-
processed faster in both the top-bottom and center-bottom           location facilitation task.
conditions, F(1, 1067)=10.97, p=.001, (see Figure 3).
   In addition, to further explore the impact of linguistic                             General Discussion
frequency also significantly explained RTs to words
presented at the bottom of the screen, F(1, 1067)=5.08, p=.         In three presentation location conditions (top and center,
02, but only marginally for words presented in the center of        bottom and center, or top and bottom) we failed to replicate
the screen, F(1, 789)=3.22, p=.07, with no effects for              a concept-location facilitation effect as found in Šetić and
words presented at the top of the screen, F(1, 1134)=2.58,          Domijan (2007) for inanimate words. However, when
p=.10. These findings seem to be consistent with the idea           considering animate words, words matched between the
that decisions are based on the relationship between one            relative presentation location and word category resulted in
word relative to the other words in the experiment, as ‘up          faster RTs than words with a mismatch. This finding
words’ presented relatively above ‘down words’ still                suggests that participants make judgments about individual
showed a concept-location facilitation effect despite these         words they see on the screen with respect to other words
words being presented in the center of the screen.                  they see throughout the duration of an experiment. The
                                                                    absolute location of a word on a screen does not seem to
                                                                    impact the concept-location facilitation effect, but rather
                                                               2600

the relative location appears to be what is important. This          Louwerse, M. M. (2008). Embodied relations are encoded
finding suggests that decisions are based on the relationship          in language. Psychonomic Bulletin & Review, 15, 838–
between one word relative to the other words in the                    844.
experiment, not only based on the relationship between one           Louwerse, M. M., (2011a). Symbol interdependency in
word and the embodied physical and spatial properties of               symbolic and embodied cognition. TopiCS in Cognitive
that simulated word. In addition, across all three                     Science, 3, 273-302.
conditions, we found a main effect of location, such that            Louwerse, M. M. (2011b). Stormy seas and cloudy skies:
words presented below other words were processed slower.               conceptual processing is (still) linguistic and perceptual.
This finding suggested that participants made judgments                Frontiers in Psychology, 2, 1-4.
relative to other words, not only relative to their location on      Louwerse, M. M., & Connell, L. (2010). A taste of words:
the screen. To further determine whether participants made             Linguistic context and perceptual simulation predict the
comparative judgments between words presented                          modality of words. Cognitive Science, 35, 381–398.
asynchronously over the duration of an experiment we also            Louwerse, M., & Hutchinson, S. (2012). Neurological
showed that bigram frequencies can predict subject RTs.                evidence linguistic processes precede perceptual
These findings together indicate that it might be the case             simulation in conceptual processing. Frontiers in
that participants are making decisions about words                     psychology, 3: 385.
presented in isolation by comparing those words to the               Louwerse, M. M., & Jeuniaux, P. (2010). The linguistic and
group of words included in the experiment, suggesting that             embodied nature of conceptual processing. Cognition,
findings that are easily attributed to embodied cognition              114, 96–104.
(Pecher et al., 2010; Šetić & Domijan, 2007) can also be             Paivio, A. (1986). Mental representations: A dual coding
attributed to language statistics.                                     approach. New York, NY: Oxford University Press.
                                                                     Pecher, D., van Dantzig, S., Boot, I., Zanolie, K., & Huber,
                        References                                     D. E. (2010). Congruency between word position and
                                                                       meaning is caused by task Induced spatial attention.
Baayen, R. H., Davidson, D. J., & Bates, D. M. (2008).                 Frontiers in Psychology, 1, 1–8.
   Mixed-effects modeling with crossed random effects for            Pecher, D., van Dantzig, S., Zwaan, R. A., & Zeelenberg,
   subjects and items. Journal of Memory and Language,                 R. (2009). Language comprehenders retain implied shape
   59, 390–412.                                                        and orientation of objects. The Quarterly Journal of
Barsalou, L. W. (1999). Perceptual symbol systems.                     Experimental Psychology, 62, 1108–1114.
   Behavioral and Brain Sciences, 22, 577–660.                       Proctor, R. W., & Cho, Y. S. (2006). Polarity
Barsalou, L. W., Santos, A., Simmons, W. K., & Wilson, C.              correspondence: A general principle for performance of
   D. (2008). Language and simulation in conceptual                    speeded binary classification tasks. Psychological
   processing. In M. de Vega, A. M. Glenberg, & A. C.                  Bulletin, 132, 416.
   Graesser (Eds.), Symbols, embodiment, and meaning                 Semin, G. R., & Smith, E. R. (Eds.). (2008). Embodied
   (pp. 245–283). Oxford, England: Oxford University                   g ro u n d i n g : S o c i a l , c o g n i t i v e , a f f e c t i v e , a n d
   Press.                                                              neuroscientific approaches. New York, NY: Cambridge
Brants, T., & Franz, A. (2006). Web 1T 5-gram Version 1.               University Press.
   Philadelphia, PA: Linguistic Data Consortium.                     Šetić, M., & Domijan, D. (2007). The influence of vertical
Glenberg, A. M. (1997). What memory is for. Behavioral                 spatial orientation on property verification. Language
   and Brain Sciences, 20, 1–55.                                       and Cognitive Processes, 22, 297–312.
Glenberg, A. M., & Kaschak, M. P. (2002). Grounding                  Tse, C., Kurby, C.A., & Du, F. (2010). Perceptual
   language in action. Psychonomic Bulletin & Review, 9,               simulations and linguistic representations have
   558–565.                                                            differential effects on speeded relatedness judgements
Hauk, O., Johnsrude, I., & Pulvermüller, F. (2004).                    and recognition memory. The Quarterly Journal of
   Somatotopic representation of action words in human                 Experimental Psychology, 63, 928-941.
   motor and premotor cortex. Neuron, 41, 301–307.                   Zwaan, R. A., & Yaxley, R. H. (2003). Spatial iconicity
Kaschak, M. P., Madden, C. J., Therriault, D. J., Yaxley, R.           affects semantic relatedness judgments. Psychonomic
   H., Aveyard, M. E., Blanchard, A. A., & Zwaan, R. A.                Bulletin & Review, 10, 954–958.
   (2005). Perception of motion affects language
   processing. Cognition, 94, B79–B89.
Lakens, D. (2011a). High skies and oceans deep: Polarity
   benefits or mental simulation? Frontiers in Psychology,
   2, 1-2.
Lakens, D. (2011b). Polarity correspondence in metaphor
   congruency effects: Structural overlap predicts
   categorization times for bi-polar concepts presented in
   vertical space, Journal of Experimental Psychology, 38,
   726-736.
Littell, R. C., Stroup, W. W., & Freund, R. J. (2002). SAS
   for linear models. Cary, NC: SAS Publishing.
                                                                2601

