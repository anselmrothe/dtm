UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Individual Differences, Imagery and the Visual Impedance Effect

Permalink
https://escholarship.org/uc/item/11n377xb

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Gazzo Castaneda, Lupita Estefania
Knauff, Markus

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Individual Differences, Imagery and the Visual Impedance Effect
Lupita Estefania Gazzo Castañeda (Estefania.Gazzo@psychol.uni-giessen.de)
Justus-Liebig University, Experimental Psychology and Cognitive Science, Otto-Behaghel-Str. 10F,
35394 Giessen, Germany

Markus Knauff (Markus.Knauff@psychol.uni-giessen.de)
Justus-Liebig University, Experimental Psychology and Cognitive Science, Otto-Behaghel-Str. 10F,
35394 Giessen, Germany

Abstract
The visual impedance effect describes the fact that
unnecessary visual information can impede reasoning (Knauff
& Johnson-Laird, 2002). We explored how this effect is
modulated by individual differences in reasoning styles. The
main hypothesis of the present work is that the magnitude of
the impedance effect depends on the degree to which people
use visual mental images during thinking. We conducted two
experiments with participants with highly imagistic and
highly verbal reasoning strategies. The relational inferences
differed in how easily they could be visualized. Our results
indicate that (1) verbalizers do not show the visual impedance
effect, and (2) that people with a high preference for mental
imagery try to imagine even non-visual information visually,
always showing the strongest impedance by visualization.
Keywords: Reasoning, individual differences, cognitive
styles, visual impedance effect

Introduction
Many theories have been developed to explain human
reasoning (Clark, 1969; Johnson-Laird & Byrne, 1991;
Oaksford & Chater, 2009; Rips, 1994). A problem common
to these theories is that they often exclude the possibility of
individual differences in reasoning (Bacon, Handley, &
Newstead, 2003; Ford, 1995). If people are asked how they
solve reasoning problems, they usually report different ways
of reasoning. While some people report the use of visual
imagery (e.g. Egan & Grimes-Farrow, 1982; Richardson,
1977), others report more language based approaches like
rehearsal (Polk & Newell, 1995), and yet others to think in a
more abstract manner (Egan & Grimes-Farrow, 1982).
Based on such observations, Richardson (1977) proposed
the differentiation between verbalizers and visualizers. Both
were conceptualized as the extremes of a continuum.
Visualizers were described as people with high visual
imagery, but with poor verbal abilities, and verbalizers were
described with the reverse tendencies. Over the years this
dichotomy was expanded in accordance with newer
neurological findings, and visualizers were divided into
object- and spatial- visualizers (e.g. Kozhevnikov, Kosslyn,
& Shepard, 2005). While object visualizers are described as
being able to construct vivid, high resolution images, spatial
visualizers are described as being especially good in the
processing of spatial information (Blazhenkova &
Kozhevnikov, 2009). Such differences in cognitive styles
are important because unlike strategies, cognitive styles
should be understood as relatively stable and durable

(Blazhenkova & Kozhevnikov, 2009; Riding & Cheema,
1991).
The influence of cognitive styles on tasks like anagrams
and mental rotation (e.g. Just & Carpenter, 1985) has
already been investigated. Also, individual differences in
spatial abilities and mechanical reasoning have been
examined (Hegarty & Sims, 1994). Nevertheless, only few
studies analyzed the influence of individual differences on
deductive reasoning (e.g. Bacon et al., 2003; Ford, 1995;
Sternberg & Weil, 1980). With the help of verbal protocols,
Ford (1995) and Bacon et al. (2003) argued that people
resolve syllogisms in two different ways. Some of the
participants used a “verbal” strategy and resolved the
syllogism via substitution of the terms. Other participants
used a “spatial” strategy and resolved the syllogism with the
help of schematic drawings which closely resembled Euler
circles. However, almost no differences in performance
were found (Bacon et al., 2003). Sternberg and Weil (1980)
trained their participants to use either visual or rule based
strategies in resolving relational inferences. One group of
participants received no training. They found an interaction
between skill and strategy: the effectiveness of the strategy
depended on the verbal or spatial skills of the participant.
More importantly, in the same study Sternberg and Weil
found that a rule-based strategy lead to the fastest response
times. Beyond these initial results, the question of the
influence of individual differences based on imagery on
other reasoning tasks like relational reasoning problems still
remains open. This is surprising, insofar as the role of visual
imagery on relational reasoning has been a topic of much
controversy (Knauff, 2013).

The Visual Impedance Effect
For a long time, the role of visual imagery during reasoning
was not clear. While some researchers reported imagery as a
helpful tool for reasoning (Clement & Falmagne, 1986;
Shaver, Pierson, & Lang, 1975), others reported opposite
results (Johnson-Laird, Byrne, & Tabossi, 1989;
Richardson, 1987; for a detailed review see Knauff 2013;
Knauff & Johnson-Laird, 2002). In search of clarification,
Knauff and Johnson-Laird (2002) postulated that these
discrepancies are based on a confounding in the items.
Many items which are called “visual” are visual as well as
spatial. Thus, in order to investigate the role of imagery
during reasoning, it is important to disentangle the visual

2374

from the spatial features of a given reasoning problem. By
doing this, Knauff and Johnson-Laird (2002) showed that
unnecessary visual information is an unnecessary cognitive
load in working memory that leads to longer reaction times.
They called this effect the visual impedance effect. They
adapted their findings to the Theory of Mental Models
(Johnson Laird & Byrne, 1991) and proposed that mental
models are spatial and not visual, as other groups propose
(e.g. De Soto, London, & Andel, 1965; Huttenlocher, 1968).
This visual impedance effect has been corroborated in
experiments with blind persons (Knauff & May, 2006).
The visual impedance effect and the existence of more or
less imagery-based cognitive styles motivated us to assume
that people with different abilities in imagery should also
perform differently in logical reasoning. We expected that
the magnitude of the visual impedance effect would depend
on the ability to use imagery during reasoning. Thus, the
visual impedance effect should be increased for people with
high visual imagery compared to those without a special
preference for visual imagery or with a more linguistic
cognitive style. Because of their cognitive style, this last
group should hardly be affected by unnecessary visual
information in tasks and thus show a better performance in
relational problems compared to people with high visual
imagery, especially in items with unnecessary visual
information. To investigate these assumptions we conducted
two experiments. In both experiments participants with
different preferences for imagery had to solve relational
problems. The content of these problems was manipulated
in such way that problems were easy or hard to visualize.

Experiment 1
In the first experiment, we measured the differences in
cognitive style with a German version of the VerbalizerVisualizer Questionnaire (VVQ) from Richardson (1977). In
a pilot study, we administered a German Version of the
VVQ to 120 undergraduate psychology students at the
University of Giessen. Using cut-off points at 5 and 12
points we found clearly distinguishable groups of
verbalizers and visualizers (the scale ranged from 0 to 15
points).

Method
Participants 22 participants (18 female, 4 male) from the
pilot study participated in the experiment. Half of them were
visualizers, the other half were verbalizers. The mean age
was 22.8 years (SD = 4.55) and they participated for
academic credit points.
Materials and Design We created 32 relational inferences.
All of them described the same relation (left-right), but the
term was either easy (fruits, tools, cutlery or office
implements) or hard (nonsense syllables) to visualize. Half
of the problems had valid conclusions; the other half had
invalid conclusions. Here is an example for an easily
visualizable problem with a valid conclusion:

Premise 1: Apple left of Kiwi
Premise 2: Kiwi left of pear
Conclusion: Pear right of apple
The design was a 2 x 2 design. The cognitive style of the
participants was treated as a between-subjects factor. The
ease of visualization for the terms was treated as a withinsubjects factor.
Procedure The experiment took place on a computer in a
quiet room, and was programed in Cedrus SuperLab™. The
participants were tested individually. Premises and
conclusions were presented on separate slides. The premises
were written in black while the conclusion was written in
red. The background was white. By pressing the space bar,
participants decided when to pass from one premise to the
next premise or to the conclusion. The task for the
participants was to decide whether the conclusion was valid
or not. They gave their decision by pressing one of two keys
for “correct” or “false”. Between each item, the participants
had the opportunity to take a break. Before starting the
actual experiment, the participants practiced on four items.
To avoid learning effects the terms of these problems were
abstract (the letters A, B, C). Dependent measures were
premise reading times (not reported here), the mean number
of logically correct responses, and the decision times for
conclusion-evaluations.

Results and Discussion
We first analyzed the percentage of correct responses 1.
Examining the problems that were easy to visualize,
verbalizers responded correctly to 95.75% (SD = 5.39) of
them, while visualizers responded correctly only to 90.91%
(SD = 11.65) (U-Test, z = -1.095, p = .273). Examining the
problems that were hard to visualize, verbalizers responded
correctly to 95.15% (SD = 7.94), while visualizers scored
92.73% (SD = 9.17) (U-Test, z = -.643, p = .520). The main
effect did not reach statistical significance, which is in
accordance with our pervious results (Knauff & JohnsonLaird, 2002). In the second step, we analyzed the decision
times for correct responses. The results are illustrated in
figure 1. As expected, visualizers (M = 6212 ms, SD =
1550) needed more time to resolve problems that were easy
to visualize compared to verbalizers (M = 4917 ms, SD =
1769). This effect was marginally significant (U-Test, z = 1.937, p = .053). For the problems that were hard to
visualize, verbalizers (M = 5700 ms, SD = 2310) were not
significantly faster than visualizers (M = 6053 ms, SD =
1703), (U-Test, z = -.624, p = .533). But contrary to what is
implied by the visual impedance effect, decision times for
problems that were hard to visualize were no smaller than
the ones for problems that were easy to visualize. On the
contrary, verbalizers were significantly slower solving
problems that were hard to visualize compared to those that
were not (Wilcoxon test, z = -1.956, p = .050). Visualizers
showed no difference between both types of problems
1
Because of technical problems, two of the 32 items had to be
eliminated from all computations.

2375

(Wilcoxon test, z = -.533, p = .594). So there was something
like a visual impedance effect for verbalizers, but not for
visualizers. This unexpected result can be explained in two
ways. One possible reason might be that nonsense syllables
are not only hard to visualize, but also unknown and
therefore probably also hard to memorize. This difficulty in
memorizing the terms may have led to more cognitive load
in working memory and thus to longer decision times
compared to items which are known. This would explain the
sudden increase in decision time for verbalizers. However,
another reason for this unexpected result can be found in the
reports many participants made after the experiment.
Visualizers in particular, reported visualizing even the
nonsense syllables. They reported that the nonsense
syllables were visualized as phantasy creatures or names of
foreign persons. Obviously, visualizer are so strongly biased
towards using visual imagery, that even in tasks where no
such visual information is available they transform the given
information in such a way that they can use their typical
visual thinking style. If so, then visualizers should not show
the typical visual impedance effect, but instead of it
something like a visual impedance effect on the subjects
level. Thus visualizers should always have problems with
relational problems, because all problems would be treated
as highly visual problems. To test this hypothesis, it is
important to use problems with familiar terms which are
known, but which are still not easy to visualize. Therefore,
in the second study we used the original material from
Knauff and Johnson-Laird (2002).

In a pilot study we administered the German Version of
the OSIVQ to 148 students at the University of Giessen. We
selected our participants on the basis of their scores on the
three scales contained within the OSIVQ: the visual scale,
the spatial scale, and the verbal scale. We considered a
participant as belonging to one of the three cognitive styles,
if she or he scored above the sample mean of one scale, but
below the sample means of the other scales2. Participants
with higher deviations were preferred over those with fewer
deviations. We selected 13 object visualizers, 6 spatial
visualizers and 10 verbalizers. Additionally to these three
experimental groups, we also selected a control group,
whose scores on the scales did not differ from the sample
scale means. The control group consisted of 10 participants.

Method

Figure 1: Mean decision times for the conclusion. Error bars
represent standard errors.

Experiment 2
In the second experiment, we decided to measure the
differences in cognitive style with the German version of
Blazhenkova and Kozhevnikov’s (2009) Object-Spatial
Imagery and Verbal Questionnaire (OSIVQ). This
questionnaire has the benefit that it accounts for the
difference between visual imagery and spatial imagery.
Thus the OSIVQ makes the same distinctions as the items
used by Knauff and Johnson-Laird (2002).

Participants All selected participants from the pilot study
participated in the experiment. All object visualizers were
female (n = 13), with a mean age of M = 22.54 (SD = 2.3).
The group of the spatial visualizers consisted of 3 female
and 3 male participants. Their mean age was M = 22.67 (SD
= 3.14). The group of the verbalizers consisted of 9 female
and 1 male participant. Their mean age was M = 22.8 (SD =
8.16). Finally, the control group consisted of 7 female and 3
male participants. Their mean age was M = 22.6 (SD =
2.59). The participants participated for academic credit
points or candies.
Materials and Design We used the relational inferences
from Knauff and Johnson-Laird (2002; see table 1). These
relations have been evaluated empirically (Knauff &
Johnson-Laird, 2002) and differ in the relative degree to
which they can be imagined either visually or spatially.
Using these relational terms it is possible to create 32 items.
All items consisted of the same terms (dog, cat, ape). Again,
half of the problems had valid conclusions; the other half
had invalid conclusions. An example for a valid visual
problem is:
Premise 1: The dog is cleaner than the cat
Premise 2: The ape is dirtier than the cat
Conclusion: The ape is dirtier than the dog
The design was a 4 x 4 design. The cognitive style of the
participants was treated as a between-subjects factor. The
ease of visualization was treated as a within-subjects factor.
Additionally to the inference task, we also measured
spatial, verbal and visual abilities of the participants. The
idea was to validate the cognitive style of our participants.
A similar procedure was also used by the developers of the
OSIVQ (Blazhenkova & Kozhevnikov, 2009). As a measure
for visual abilities we used the Vividness of Visual Imagery
Questionnaire (VVIQ: Marks, 1973). It consists of 16 items
which examine how easily the participant is able to imagine,
visually and vividly, different scenes with open and with
closed eyes. As a measure of spatial ability we used a
2

In five exceptional cases people were also accepted, whose
scores between the corresponding scale and the other scales
differed around one scale unity.

2376

mental rotation task, based on the one by Shepard and
Metzler (1971). It consisted of the presentation of a target
3D figure, in combination with another similar figure which
was either the same in one of six rotated degrees, or a
rotated mirror image. The task for the participant was to
decide whether both images were the same or not. This task
consisted of 48 items. Finally, as a measure of verbal ability
we used the subtest “Masselon” from the Berliner
Intelligenzstruktur Test (BIS: Jäger, Süß, & Beauducel,
1997). In this test the participant is confronted with three
words (human, feeling, technology) and must then create as
many sentences as they can with these three words. For
better comparisons with experiment 1, we also administered
a German Version of Richardson’s (1977) VVQ.
Procedure The experiment always began with the relational
inference task, which was programed in SuperLab™. The
procedure for the relational inference task was the same as
experiment 1. After completing the relational task, the
VVIQ tasks, the rotation task, and the Masselon tasks were
presented in a random order. Finally, the participants
answered the VVQ and provided written comments on how
they believed they solved the tasks. Again, we measured the
reading time for each premise (not reported here), the
decision time for the conclusion, and whether the task was
solved correctly or not.
Table 1: Relations used in Experiment 2, with a
description of how easy they were to imagine either as a
visual image or a spatial array (adapted from Knauff and
Johnson-Laird (2002; p. 368)).
Relations
Visual
cleaner-dirtier
fatter-thinner
Control
better-worse
smarter-dumber
Visuospatial
above-below
front-back
Spatial
north-south
ancestor-descendant

Description
Ease to envisage visually, but hard
to envisage spatially
Hard to envisage visually and
spatially
Easy to envisage visually and
spatially
Hard to envisage visually, but easy
to envisage spatially

Results and Discussion
VVIQ, mental rotation, and verbal abilities The results
from the three tasks indicate that our selection of the
exponents of the different cognitive styles was successful.
The VVIQ was computed in such a way that high scores
(max. 80 points) indicated good visual abilities, whereas
low scores (min. 16 points) indicated a lack of it. Object
visualizers (M = 51.08, SD = 5.61) reached a higher score
than verbalizers (M = 39.75, SD = 8.72) on the VVIQ (UTest, z = -3.072, p = .002). They also reached a higher score
than spatial visualizers (M = 40.83, SD = 13.45) and the
control group (M = 43.70, SD = 6.87), but these last two

differences did not reach the adjusted alpha level (U-Test, z
= -1.931, p = .053 for the comparison with spatial
visualizers; U-Test, z = -2.576, p = .01 for the comparison
with the control group).
Even if there was no significant main effect on the time
needed to solve the items in the mental rotation task
(Kruskal Wallis, Chi2 = 5.440, p = .142), descriptively it
was possible to see that, across all items, spatial visualizers
(M = 4.99 s, SD = 1.88) were faster than verbalizers (M =
7.54 s, SD = 3.87), than object visualizers (M = 8.15 s, SD =
2.85) and the control group (M = 6.80 s, SD = 3.41).
Poltrock and Brown (1984) proposed that the linear
regression slopes of the latencies are an indicator of the
rotation speed, in that the smaller the slope, the faster the
rotation was performed. As expected, spatial visualizers
rotated faster (b = 29.55, SE = 8.39) than verbalizers (b =
72.00, SE = 16.42), object visualizers (b = 55.79, SE = 9.75)
and the control group (b = 48.16, SE = 16.77). The groups
did not differ in the amount of errors made (Kruskal Wallis,
Chi2 = 2.641, p = .450).
Our analysis of the Masselon test was based on the
amount of written words in valid sentences. Verbalizers (M
= 43.30, SD = 11.37) wrote significantly more words than
object visualizers (M = 30.54, SD = 7.93; U-Test, z = -2.86,
p = .004) and spatial visualizers (M = 25.17; SD = 7.11; UTest, z = -2.71, p = .007), but they did not differ from the
control group (M = 34.70, SD = 12.60; U-Test, z = -1.34, p
= .182).
The VVQ The comparison of the scores on the VVQ
showed that the VVQ is only able to differentiate correctly
between verbalizers (M = 7.20, SD = 2.35) and object
visualizers (M = 10.46, SD = 2.22; U-test, z = -2.875, p =
.004). Given that the VVQ does not consider spatial
visualizers, spatial visualizers (M = 7.67, SD = 3.98) scored
similar to verbalizers (U-test, z = -.174, p = .869) on the
VVQ.
Relational inferences Similar to Knauff and Johnson-Laird
(2002), we encountered some problems with the spatial
relations. On the one hand, several participants reported that
they still imagined them in a visual way (e.g. as animals on
maps). On the other hand, the spatial terms created
“illogical” constellations (e.g. the dog is descendant of the
cat), whose difficulty probably confounded the decision
times. Therefore, the spatial relational terms were not purely
spatial and had to be removed from our analysis. The
reported results are based solely on the correct responses to
the other three kinds of relational terms.
Based on the results of experiment 1, we assumed that
people with a high preference for imagery would not only
have difficulties in visual relational problems, but also in
non-visual relational problems. Because of their cognitive
style, object visualizers would try to imagine even non
visual information visually, regardless of how difficult this
is, and be impeded by this visualization. To analyze these
hypotheses we first considered the percentage of errors
made by our participants. As in experiment 1, there were no
significant differences between the participants with

2377

different cognitive styles in the percentage of correct
answers (Kruskal Wallis, Chi2 = 2.060, p = .560). However,
there was a significant main effect in the response times
when we compared the groups of object-visualizers, spatial
visualizers, and verbalizers (Kruskal Wallis, Chi2 = 6.855, p
= .032). Pairwise comparisons showed that, as expected,
object visualizers (M = 4608 ms, SD = 2671) took longer to
resolve the tasks compared to verbalizers, (M = 2777 ms,
SD = 645). This difference was also significant (U-test, z = 2.481, p = .012). Object visualizers were not significantly
slower than spatial visualizers (M = 3857ms, SD = 1159; Utest, z = -0.614, p = .579) and verbalizers still tended to
answer faster than spatial visualizers (U-test, z = -1.735, p =
.093). As can be seen in figure 2, neither object visualizers
nor verbalizers showed the classical visual impedance
effect. In neither group a main effect on decision times for
the different kinds of items could be found (Friedman Test,
Chi2 = 1.077, p = .584 for object visualizers; Chi2 = .200, p
= .905 for verbalizers). The only group that showed a
pattern resembling the classical visual impedance effect
were the spatial visualizers. However, because of the small
sample size (n = 6), the main effect did not reach
significance (Friedman Test, Chi2 = 3.000, p = .223). This
trend was not expected and should be investigated in further
studies. Nevertheless, the missing visual impedance effect
for verbalizers and the long decision times of object
visualizers confirm our suppositions derived from
experiment 1: while object visualizers do indeed try to
visualize even nonvisual information, verbalizers never
visualize anything. This leads to a lack of visual impedance
effects on the item level, but instead causes visual
impedance effects on the subject level.

Figure 2: Mean decision times for the conclusion. Error bars
represent standard errors.

General Discussion
Our findings indicate that, depending on their cognitive
style and how easily they are able to use imagery during
reasoning, people are influenced in different ways by the
imageability of the content of reasoning problems: On the
one hand, verbalizers are typically not impeded by visual

characteristics of reasoning problems. They seem to be
immune to the visual impedance effect. On the other hand,
people who tend to imagine the content of reasoning
problems try to visualize even non-visual problems and
therefore show a visual impedance effect on all problems,
whether the problems are highly visual or not. These results
notwithstanding, we are aware of the limitations of our
study. In order to strengthen our results, it would be
necessary to conduct studies with a greater sample size and
to control for gender differences. An additional task for the
future is to investigate during which phase of the inference
individual differences take effect. Particularly, it remains
unclear whether these individual differences play a role only
during interpretation and encoding of the reasoning problem
premises, or if the individual differences also have an effect
on the reasoning process itself. Knauff (2009, 2013)
proposes that relational reasoning problems are solved in
three steps among which only the first step involves the
construction of visual mental images and the other two steps
comprise the “real” reasoning processes. However, in this
work we did not distinguish between different cognitive
styles and so it is still unclear how verbalizers solve such
tasks. Do they also create such (irrelevant) initial picturelike representations? One approach that we took previously
is to use functional brain imaging to study the neural basis
of individual differences in reasoning (Ruff, Knauff,
Fangmeier, & Spreer, 2003). By testing people with
different cognitive styles in the scanner it might be possible
to see during which phases of the reasoning process these
cognitive styles take effect. By doing this, it would also be
possible to see to what extent the steps proposed by Knauff
(2009, 2013) are generalizable to all cognitive styles. The
same could be also done with other individual differences.
For example, it might be of interest to investigate whether
people with either a holistic or an analytic cognitive style
(see Riding & Cheema, 1991) differ in the construction of
mental models.
Another task for the future is to replicate the present
results using different formats of presentation. In both
studies reported here our items were presented in written
form. Considering that verbalizers are often described as
having fun and being good at reading and language based
tasks (see the relevant items of the VVQ and the OSIVQ), it
seems possible that the superior performance of verbalizers
resulted not only because they did not use imagery, but also
because verbalizers might feel more comfortable with a task
presented in their preferred format. Thus, in further studies
it is important to present items in other formats, for example
acoustically or in an iconic way.
In conclusion, our results support the visual impedance
effect. Irrelevant visual details can be a nuisance in
reasoning. However, the effect seems to be modulated by
the different cognitive styles of individuals. Object
visualizers are so profoundly driven by their visual thinking
style that they try to visualize almost everything. Thus they
show a visual impedance effect even for non-visual
reasoning problems. Verbalizers, in contrast, are only

2378

marginally affected by the visual characteristics of
reasoning problems. They use more abstract reasoning
styles and therefore have no problems with disruptive visual
images. We were also able to identify differences between
object visualizers and spatial visualizers. Comparing both
groups, our findings indicate that the use of spatial
representations and processes is the most effective way to
solve relational reasoning problems. However, individuals
using spatial layout models (Knauff, 2013) seem not to be
immune to irrelevant and side-tracking visual details and
can therefore be impaired in solving highly visual inference
problems. We will continue to explore this effect more
thoroughly. A final important corollary of our study is that
effects found in general populations (without considering
differences in cognitive style) do not necessarily apply to
every single person: visual items do not always impede
reasoning, they only impede if subjects represent visual
features in their mental representation of the task. That is
why it is important to incorporate individual differences into
theories of reasoning and to highlight such differences in the
predictions and assumptions of those theories. Disregarding
these
differences
may
lead
to
unjustified
overgeneralizations.

Acknowledgments
This work was supported by DFG grant KN 465/10-1 to
Markus Knauff.

References
Bacon, A. M., Handley, S. J., & Newstead, S. E. (2003).
Individual differences in strategies for syllogistic
reasoning. Thinking and Reasoning, 9, 133-168.
Blazhenkova, O., & Kozhevnikov, M. (2009). The new
object-spatial-verbal cognitive style model: Theory and
measurement. Applied Cognitive Psychology, 23, 638663.
Clark, H. H. (1969). Linguistic processes in deductive
reasoning. Psychological Review, 76, 387-404.
Clement, C. A., & Falmagne, R. J. (1986). Logical
reasoning, world knowledge, and mental imagery:
Interconnections in cognitive processes. Memory &
Cognition, 14, 299-307.
De Soto, L. B., London, M., & Andel, M. S. (1965). Social
reasoning and spatial paralogic. Jorunal of Personality &
Social Psychology, 2, 513-521.
Egan, D. E., & Grimes-Farrow, D. D. (1982). Differences in
mental representations spontaneously adopted for
reasoning. Memory & Cognition, 10, 297-307.
Ford, M. (1995). Two modes of mental representation and
problem solution in syllogistic reasoning. Cognition, 54,
1-71.
Hegarty, M., & Sims, V. K. (1994) Individual differences in
mental animation during mechanical reasoning. Memory
and. Cognition, 22, 411–430.
Huttenlocher, J. (1968). Constructing spatial images: A
strategy in reasoning. Psychological Review, 75, 550-560.

Jäger, A. O., Süß, H. -M. & Beauducel, A. (1997). Berliner
Intelligenzstruktur - Test. Form 4. Göttingen: Hogrefe.
Johnson-Laird, P. N., & Byrne, R. M. J. (1991). Deduction.
Hove, U.K.: Erlbaum.
Johnson-Laird, P. N., Byrne, R. M. J., & Tabossi, P. (1989).
Reasoning by model: The case of multiple quantification.
Psychological Review, 96, 658-673.
Just, M. A., & Carpenter, P. A. (1985). Cognitive coordinate
systems: Accounts of mental rotation and individual
differences in spatial ability. Psychological Review, 92,
137-172.
Knauff, M. (2009). A neuro-cognitive theory of deductive
relational reasoning with mental models and visual
images. Spatial Cognition and Computation, 9, 109-137.
Knauff, M. (2013). Space to Reason. Cambridge, MA: MIT
Press.
Knauff, M., & Johnson-Laird, P. N. (2002). Visual imagery
can impede reasoning. Memory & Cognition, 30, 363371.
Knauff, M., & May, E. (2006). Mental imagery, reasoning,
and blindness. Quarterly Journal of Experimental
Psychology, 59, 161-177.
Kozhevnikov, M., Kosslyn, S., & Shephard, J. (2005).
Spatial versus object visualizers: A new characterization
of visual cognitive style. Memory and Cognition, 33, 710726.
Marks, D. F. (1973). Visual imagery differences in the recall
of pictures. British Journal of Psychology, 64, 17-24.
Oaksford, M., & Chater, N. (2009). Précis of bayesian
rationality: The probabilistic approach to human
reasoning. Behavioral and Brian Sciences, 32, 69-120.
Polk, T. A., & Newell, A. (1995). Deduction as verbal
reasoning. Psychological Review, 102, 533-566.
Poltrock, S. E., & Brown, P. (1984). Individual differences
in visual spatial ability. Intelligence, 8, 93-138.
Richardson, A. (1977). Verbalizer-Visualizer: a cognitive
style dimension. Journal of mental Imagery, 1, 109-126.
Richardson, J. T. E. (1987). The role of mental imagery in
models of transitive inference. British Journal of
Psychology, 78, 189-203.
Riding, R., & Cheema, I. (1991). Cognitive styles – an
overview and integration. Educational Psychology, 11,
193-215.
Rips, L. J. (1994). The psychology of proof. Cambridge,
MA: MIT Press.
Ruff, C. C., Knauff, M., Fangmeier, T., & Spreer, J. (2003).
Reasoning and working memory: Common and distinct
neuronal processes. Neuropsychologia, 41, 1241-1253.
Shaver, P., Pierson, L., & Lang, S. (1975). Converging
evidence for the functional significance of imagery in
problem solving. Cognition, 3, 359-375.
Shepard, R. N., & Metzler, J. (1971). Mental rotation of
three-dimensional objects. Science, 171, 701-703.
Sternberg, R. J., & Weil, E. M. (1980). An aptitude X
strategy interaction in linear syllogistic reasoning. Journal
of Educational Psychology, 72, 226-239.

2379

