UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A computational exploration on the role of semantic memory in episodic future thinking
Permalink
https://escholarship.org/uc/item/01b1k6cw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Ito, Yuichi
Ueno, Taiji
Kitagami, Shinji
et al.
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                    A computational exploration on the role of semantic memory
                                                 in episodic future thinking
                        Yuichi Ito (ito.yuichi@nagoya-u.jp), Taiji Ueno (taijiueno7@gmail.com),
       Shinji Kitagami (kitagami@cc.nagoya-u.ac.jp), and Jun Kawaguchi (kawaguchijun@nagoya-u.jp)
                    Department of Psychology, Graduate School of Environmental Studies, Nagoya University,
                                    Furo-cho, Chikusa-ku, Nagoya City, Aichi 4648601, JAPAN
                            Abstract                                     constructive episodic simulation hypothesis was proposed,
                                                                         which assumes that imagining future events requires a
  Episodic future thinking refers to a human cognitive process
  which generates successive predictions of events that are              system that can retrieve detailed information stored in
  likely to occur in a cue-specific context in the future. An            episodic memory and flexibly recombine them into coherent
  emerging view is that semantic memory as well as episodic              representations of future events (Schacter, Addis, & Buckner,
  memory contributes to this process, but the exact mechanism            2008). Further support for this idea comes from
  remains unclear. We built a computational model that learned           experimental psychology. For example, both retrieving an
  to predict the next event upon a presented event (sequence             episode and imagining a future event are affected by a
  prediction model). After learning the statistical structure in the
  training sequence, the model was tested for generating
                                                                         temporal distance factor in the same manner. Specifically,
  successive self-predictions of events triggered by a cue. The          Addis, Wong, & Schacter (2008) collected both the past
  generated      sequence     of    events      captured      some       events that participants recalled and the future events they
  phenomenological features of patients with semantic                    generated, and classified detailed information in these
  dementia when the semantic system of the model was                     outputs as either internal or external. Internal details are
  damaged. The role of semantics in episodic future thinking             “episodic” information, meaning specific in time and place
  and the usefulness of a sequence prediction model are                  and related to the central events (i.e., the main event
  discussed.
                                                                         described by the participant). In contrast, external details are
   Keywords: episodic future thinking; semantics; parallel-              not specific in time and place. It was found that, in both
   distributed processing model; sequence learning                       recalling of past episodes and thoughts about future
                                                                         episodes, internal details lessened as participants were
                         Introduction                                    required to produce farther events from the present in both
We can project ourselves into the future despite the fact that           directions. This means that as episodic future thinking goes
we have never experienced it. The term episodic future                   farther in terms of temporal distance from the present, the
thinking refers to a human ability to envision a plausible               time and place (context) of the generated events deviates
future event in a specific time and place (i.e., a specific              from those of the central events (central topic).
context) (Atance & O’Neill, 2001; Schacter, Addis &
Buckner, 2008). Over the last decade, researchers from                   Role of Semantic Memory
various fields, including psychology, neuropsychology, and               More recently, the role of semantic memory in episodic
neuroimaging, have investigated episodic future thinking,                future thinking has also captured attention (Irish et al., 2012).
focusing mainly on the contribution of episodic memory to                D’Argembeau and Mathy (2011) suggest that construction
constructing episodic future thought. More recently, data                of episodic future thought typically involves progressive
from patients with semantic dementia have suggested that                 conversion from general to more specific information such
semantic memory may also play a role (Irish, Addis, Hodges,              that access to general knowledge (semantics) precedes
& Piguet, 2012). The current study used a computational                  retrieval of time-specific episodic information. In other
model to investigate the mechanism by which semantic                     words, semantic memory provides a “framework” for
memory supports episodic future thinking.                                construction of episodic future event representations, and
                                                                         then episodic information from the past is integrated to form
Role of Episodic Memory                                                  a coherent and elaborated sequence of future events. A key
The role of episodic memory has been suggested in various                support for this idea came from a study with neurological
studies. For example, some neuroimaging studies have                     patients with semantic dementia, characterized by the
revealed a common neural network involved in the                         progressive and insidious loss of conceptual knowledge
remembering of past, and in imagining future events                      about objects, facts and the meaning of words, yet preserved
(Szpunar, Watson, & McDermott, 2007). These data are                     non-verbal episodic memory (Irish et al., 2012). Specifically,
consistent with neuropsychological studies with amnesic                  Irish et al. (2012) found that although their patients were as
patients (e.g., hippocampal amnesia or Alzheimer’s disease)              good at remembering past episodes as controls, their
who showed simultaneous impairments in both                              episodic future thoughts lacked internal details. In other
remembering past episodes and imagining future events                    words, the sequence of events they generated did not
(e.g., Irish et al., 2012). Based on these findings, the                 maintain the time and place information (context) that was
                                                                     2626

cued by an investigator. Note that this was not due to a           structure in the sequence. In later studies, human
difference in task difficulty because Alzheimer’s disease          participants were trained for the same task and were able to
patients in this study showed simultaneous impairments in          use their statistical knowledge after training in order to
both measures. Thus, this dissociative pattern suggests that       generate successive predictions about the next letter
even if episodic memory is relatively intact, loss of              following their own previous predictions upon a presented
conceptual knowledge has an impact on episodic future              cue (Perruchet & Amorim, 1992). Returning back to the
thinking.                                                          current study, it would be possible to assume that a
  Motivated by these findings, we employed a parallel-             statistical structure exists even in the event sequence
distributed processing (PDP) modelling approach to                 (episode) within the real world. For example, we reasonably
investigate the mechanism by which semantic memory                 guess that the next event would be to blow the candle when
contributed to episodic future thinking. As we reviewed            a birthday cake is served to the dinner table. Also, we know
above, human experiments have provided significant                 that someone will cut cake into pieces before biting into a
insights, but each has its own limitation: It is relatively        whole cake. Thus, there is some statistical structure in the
difficult to separate the contribution of episodic memory          sequence of events in real world, and our working
from that of semantic memory in healthy controls. Semantic         hypothesis is that the order of successive cue-specific
dementia patients are the best test cases but their verbal         predictions in episodic future thinking should be to some
outputs are limited such that it is difficult to probe their       extent constrained by this statistical structure in real world.
cognitive processing in detail. In contrast, computational         Once we assume the similarity between the future prediction
modelling provides an ideal situation where we can directly        of the next letter in a given language (Elman, 1990) and the
look at the nature of computation/representations in the           future prediction of the next event in real life, then it is
model to glean further insights into how semantic memory           natural to adopt Elman’s approach for modelling episodic
supports other cognitive processing (e.g., Woollams,               future thinking (see below in detail). As we admit above,
Joanisse, & Patterson, 2009).                                      episodic future thinking is a complex cognitive process, but
                                                                   this approach is promising to capture at least the two core
Future Prediction Model                                            characteristics of episodic future thinking mentioned above.
Given there is no computational model for episodic future
thinking in the literature, the initial step is to make some                                   Method
simplified assumptions so that the target cognition can be
implemented in a computational model. A standard                   Model Architecture, Tasks, and Representations
paradigm to probe episodic future thinking involves a              Figure 1 shows the architecture of the model. Four
presentation of a cue such as time/location/object (e.g., next     peripheral layers (input layer, output layer, semantic layer,
year’s birthday, or 50th birthday, etc.), and a participant        and recognition layer) were connected bidirectionally
successively generates cue-specific predictions on what is         through a single hidden layer. The hidden layer and each of
likely to happen (e.g., a birthday cake is on a plate in a         the five output layers were connected to themselves. The
dining room → I blow the candle → my friend will pick out          input layer was sub-divided into five layers, each of which
the candle → the friend will cut the cake → the friend will        represented one of the five elements of the current event
serve me a cake on a plate, etc.). The nature of this              (Figure 1). For example, the first layer represented the
generation is successive such that the order of these example      context information of the current event. If this context layer
sentences cannot be at random. In other words, future              was hard-clamped to the binary vector of [1 0 0 0 0 0], then
thinking includes at least two aspects - computing cue-            it meant the current event occurred in Context 1 (e.g.,
specific information and successively generating future            school). The remaining four layers represented the
predictions based on the corresponding previous prediction.        Agent/Action/Object/Instrument of the current event. Thus,
Of course, these two aspects are not enough to account for         if the whole input layer was hard-clamped to the 18-bit
the whole episodic future thinking processing. However,
once we assume that episodic future thinking taps at least an                                Output layers (18 units)
ability to generate successive predictions based on the                           Context    Agent Action Object Instrument
corresponding previous prediction upon a time-/location-
/object-specific cue, then there is an existing computational
model by Elman (1990) that we can adopt and modify for              Recognition                                          Semantics
the current purpose. This model was trained for predicting            (1 unit)           Hidden layer (80 units)         (15 units)
the next alphabetic letter in an artificial language.
Specifically, the model received a 6-bit binary vector, which
represented one of the alphabetic letters, and the model was                      Context    Agent Action Object Instrument
trained for predicting the next 6-bit binary input vector. The
                                                                                              Input layers (18 units)
presented sequence was not random, but there was a
statistical structure regarding what was likely to come next
(artificial grammar). The model learned this statistical             Figure 1: The architecture of the model (Hinton diagram).
                                                               2627

                                            Table 1: Sequence structure of the training set.
                                    context                                        other information
          sequence      contex                                                 pattern                  predictability
                                            predictabilit
                           t      pattern                                                     instrumen with without
                                                 y             agent      action     object
                         label                                                                     t   context context
          event (1)                                            010         100        010         100
                                                                                                           17, 83,
          event (2)                                            100         010        001         100
                          1      100000       constant                                                       or
             …                                                                    …
                                                                                                           100%
          event (i)                                            010         001        010         010
        event (i + 1)                                          001         010        001         010      33, 50,
                                                                                                                   6 ~ 45%
             …            6      000001       constant                            …                          or
          event (j)                                            100         100        100         010      100%
        event (j + 1)                                          001         001        001         001
        event (j + 2)     3      001000       constant         010         010        100         100       100%
             …                                                                    …
vector of [(Context) 0 1 0 0 0 0 (Agent) 1 0 0 (Action) 0 0 1          information. Taking these assumptions together, we created
(Object) 1 0 0 (Instrument) 0 0 1], then the current event             the target semantic representations such that the bit-patterns
was ‘In Context 2 (e.g., home), Agent 1 (e.g., John) did               in the context/action/object/instrument input layers were
Action 3 (e.g., cut) to Object 1 (e.g., cake) with Instrument 3        systematically related to part of the target vectors in the
(e.g., knife)’. The layers in the output side had the same             semantic layer (i.e., mapping was not completely arbitrary).
structure, and when presented with the input pattern of the            Then, when presented with the current event pattern in the
current event, the model was trained to activate the units in          input layer, the network was trained for generating the
the output layer that consisted of the next event (the input           correct pattern in the semantic layer in addition to predicting
18-bit vector of the next trial). The sequence structure will          the next event in the output layer. Irish et al. (2012)
be explained later.                                                    demonstrated that semantic dementia patients were less
  Next, the semantic layer consisted of 15 units whose                 accurate than controls for ‘knowing (semantic)’ non-
activation patterns represented the ‘conceptual knowledge’             personal events over the past/future 10 years. Thus, we
of the current event (interpretation of the event) in a                damaged this layer in simulation of the patients’ behaviour.
distributed manner. Following many parallel-distributed                   A recognition trial was occasionally inserted during
processing (PDP) models that incorporated a ‘conceptual                training, in which the network was trained for judging
knowledge’ system in their models (Woollams et al., 2009),             whether the presented event pattern had been experienced
no attempt was made to design semantic representations that            before or not. The single unit in the recognition layer served
captured the actual meanings of the input pattern (e.g., input         to represent the network’s recognition judgment.
words, action, event, etc.). Instead, like past models,                Specifically, the input layer was hard-clamped to the value
artificial semantic representations were created that,                 of an event representation, and then the network was trained
nonetheless, captured core characteristics of the meaning of           to activate this recognition unit (1.0) if the presented event
an event. Specifically, we assumed that the meaning of an              representation had appeared (‘old’) before, as part of the
event would be to some extent related to the action,                   main task. In contrast, the recognition unit should be turned
instrument, and object information of that event (e.g., not an         off (0.0) if the presented episode representation had never
arbitrary mapping). Once we hear these pieces of                       appeared before (‘new’).
information, we can guess what happened in that event with
some confidence. In contrast, the meaning of an event                  Sequence Structure of the Training Set
would be less strongly related to information on who
(Agent) did that action. For example, the meaning of cutting           Sequence Structure of Context Information The sequence
an apple with a knife is invariant irrespective of who did             in the main trial was semi-random. Table 1 shows the
that action. Next, the context information also constrains the         structure of the sequence. First, as the left half of Table 1
meaning of the event. We know that certain kinds of events             shows, the context information (i.e., first 6-bit of the 18-bit
rarely occur in a certain context. For example, passing a              input vector) was kept constant for several successive events
ball should not occur in a restaurant. Of course, Agent                in order to mimic the real world, where we experience
information would also constrain the meaning of an event               successive events in the same context then move to another
(e.g., we might know that John would never eat an apple),              one. By presenting the first 6-bit information in this way, we
but to a lesser extent than context/action/object/instrument           can more safely argue that this 6-bit information represents
                                                                 2628

the context information of an event. Thus, the predictability                          100
of the next context information was 100% in most trials
unless it was the boundary of a context-block. After several                           80
events, the context information changed into another context
                                                                        Accuracy (%)
semi-randomly (33%-50% predictability).                                                60
Sequence Structure of Agent/Action/Object/Instrument
                                                                                       40
Information The sequence of the remaining 12-bit
information of an event was also semi random. There were                                                          Event prediction
81 possible input patterns, formed by crossing 3 (Agent) by                            20
                                                                                                                  Recognition trained-items
3 (Action) by 3 (Object) by 3 (Instrument). When the                                                              Recognition untrained-items
context information was not considered, the predictability of                           0
the next event (i.e., next agent/action/object/instrument                                    0     3 6 9 12 15 18 21 24 27 30
information) varied from 4% to 45% depending on a trial.                                         Number of epochs (1 epoch = 540,000 trials for
When the context was considered together, the predictability                                      event prediction & 360,000 for recognition)
increased such that it varied from 33% to 100% depending
on a trial. We implemented the constraint from context                  Figure 2: Learning curves for event prediction, recognition
information to mimic the real world. For example, it is more               of trained-items, and recognition of untrained-items.
difficult to predict what will happen if we see a ball
bouncing at a restaurant, but it is less difficult to predict at a
park.                                                                Training Parameters
                                                                     In each trial, 18 units in the input layer were hard-clamped
Recognition Trials After every nine trials for event                 to their input values, and the network was allowed to cycle
prediction (and simultaneous computation of meaning), six            10 times. In each time step, the activation spread to the next
trials were inserted to train the model for event recognition.       layer gradually being scaled by the values of the
The network received a 18-bit input pattern, and was                 interconnecting weights, and the network settled into the
required to judge whether or not this pattern had been               steady state (called as an attractor). After 10 cycles of
presented before as part of the main task by                         updates, the discrepancy between the output activation
activating/deactivating the recognition unit. In order not to        patterns (output event layer and semantic layer) generated
bias the network’s response, ‘old’ and ‘new’ trials were             by the network and the correct target pattern was calculated,
evenly distributed (3 trials, each) within each recognition          and the connection strength was adjusted to reduce the
block. The ‘old’ events were randomly sampled from the               discrepancy. In recognition trials, only the discrepancy in
main training trials that the network had experienced during         the recognition unit was considered. A learning rate of 0.01
event prediction. The ‘new’ event-set was created in the             was set at the beginning of the training. Then, every 10
following steps. First, when we had created the sequence of          epochs of training, the learning rate was gradually reduced
the main trials, we had ensured that not all the 81 possible         by 0.001. A decay parameter was set to 0.0000001 at the
input patterns (formed by combining agent, object, action, &         beginning and gradually reduced by 0.00000001 as the
instrument) appeared in every one of the 6 possible contexts.        learning rate was reduced. When we evaluated the network’s
Specifically, in each context, 20-27 possible combination of         performances during/after training, we used a strict criterion
agent/object/action/instrument information had been                  such that the output was scored correct if the discrepancy
randomly sampled and removed from the training set such              was within 0.5 in every unit of the target layer after the 10 th
that these patterns never appeared in that particular context        cycle (i.e., the activation is less/more than 0.5 if the target is
during the main task. These pre-removed patterns served as           0.0/1,0. for each unit respectively).
‘new’ events. To be clear, it was possible that these patterns
appeared in another context. For example, the network                                                        Results
might have received the 18-bit vector of [1 0 0 0 0 0, 1 0 0,
1 0 0, 1 0 0, 1 0 0 (comma denotes the boundary of layers)]          Trained Tasks
but not received that of [0 1 0 0 0 0, 1 0 0, 1 0 0, 1 0 0, 1 0      Figure 2 shows the learning curves for the event prediction
0]. Then, the network would have to activate the recognition         task and the recognition task averaged across 10
unit when presented with the former pattern but would have           independent simulations (initiated with different random
to deactivate the same unit in the case of the latter. Thus, the     seeds). The network successfully learned to predict the next
network was trained for recognition of a particular event            event, thus acquiring the statistical structure which existed
involving a particular context/agent/object/action/instrument.       in the event sequence as well as recognizing the presented
We also ensured that not all the possible ‘old’ trials and           event pattern, which was generalized to untrained items.
‘new’ trials were presented during training, such that we            Accuracy for computing the meaning of an event quickly
were able to probe the generalization performance of the             reached 100% after the training was initiated.
network to the untrained ‘old’/’new’ patterns.
                                                                 2629

Episodic Future Thinking                                                                                     330
                                                                     Length of successive predictions in a
As explained in the introduction, the current model focused
to capture at least the ability to compute cue-specific events
                                                                                                             290
successively following its own previous event prediction, a
core characteristic of episodic future thinking. Thus, we first
presented cues (e.g., Context = home, Agent = john, Action                                                   250
= cut, Object = cake, Instrument = knife). Then, once the
                                                                     coherent-context (maximum = 1,000)
network generated an output (i.e., prediction of next event),                                                210
we presented this output vector pattern as the input of the
next event, and the network generated the next output                                                        170
(prediction of the next event following its own prediction,
see Botvinick & Plaut, 2004, for the same approach in
action learning). This cycle was reiterated 1000 times, and                                                  130
the generated 1000-event sequence was regarded as an                                                               0%     20%      40%     60%      80% 100%
approximation of the network’s episodic future thinking. As                                                                Proportion of links removed
a result, the network successfully kept the presented context                                                           (severity of semantic inpairments)
information (Context 1) constant for the first 829 events
(average of 10 simulations), but lost this context                                       Figure 3: Numbers of successive events in which the
information after this point.                                                           network maintained the cued-context information as a
                                                                                                     function of disease severity.
Simulation of Semantic Dementia
Following past simulations on semantic cognition, we              future thinking (Irish et al., 2012). This is consistent with
simulated the episodic future thinking of patients with           the idea that the semantic system provides the framework of
semantic dementia by removing some of the links between           the event (D’Argembeau & Mathy, 2011).
the semantic layer and the hidden layer (e.g., Woollams et          How does the semantic system affect the maintenance of
al., 2009). Figure 3 shows how long (how many successive          context-coherent event sequences? This can be explained in
events) the network maintained the cued-context                   terms of one of the general principles of PDP models.
information as a function of disease severity (in terms of the    During training, a PDP network finds a unique attractor state
proportion of links removed). This ‘lesioning’ simulation          (= unique abstract pattern in the hidden layer) associated
was reiterated 50 times with different links being sampled        with each of the input patterns. Once an input value is fed
and removed, and the outcomes were averaged in order to           into the model, the activation gradually spreads, and the
avoid an idiosyncratic result. We found that, as the damage       internal activity of the hidden layer gradually settles onto
became more severe, the network was increasingly unable to        this unique status, as if it is falling into its unique attractor
maintain the event sequence of the cued-context (NB., The         basin. They are unique, but similar inputs are associated
intact model kept the context for 829 events). Thus, future       with similar attractor basins. In the current model, the input
thinking deviated into another context/topic. Moreover, the       patterns that share the same context information will fall
proportion of the links removed was negatively correlated         into similar/neighbouring attractors, thus producing the
with the number of event predictions that maintained the          same context output information to keep a context-coherent
cued-context [r(17) = .-75, p < .01], suggesting that             episode. However, if the internal representation of the model
semantics had a causal role in generating a coherent episode      changes due to an impaired computation at some part of the
in future thinking. Importantly, event recognition accuracy       model, then the network may settle into a wrong attractor
was intact (more than 95% accurate) after this lesioning. All     basin, generating a wrong output. The diagnostic analysis
of these are consistent with the data from semantic dementia      suggests that this is certainly the case in our model.
patients (Irish et al., 2012).                                    Specifically, we presented six events in different contexts to
                                                                  the network, and the activation pattern in the hidden layer
                        Discussion                                on which the network settled was measured with/without
                                                                  semantics. Figure 4 shows the similarity structure of these
The current model successfully acquired the statistical
                                                                  patterns found by a multi-dimensional scaling analysis. With
structure within the training set, and used this knowledge to
                                                                  the intact semantic information (filled-markers), the network
generate a context-coherent sequence of events triggered by
                                                                  settles onto the context-specific attractor basins such that the
cues (episodic future thinking). Moreover, when the
                                                                  network does not confuse one context with another.
computation of semantic knowledge was impaired, the
                                                                  However, when the semantic system was damaged (open-
model could not generate a context-coherent event sequence,
                                                                  markers), the network’s internal status drifted away from its
yet preserved its recognition ability of event patterns.
                                                                  correct attractor, thus generating a different/wrong context
Importantly, the number of the events generated in a specific
                                                                  representation (e.g., The open-circle is closer to the filled-
context was negatively correlated with the severity of
                                                                  diamond rather than filled-circle). In other words, semantic
damage, suggesting the causal role of semantics in episodic
                                                                  representations contribute to “binding” a time-varying event
                                                              2630

                                                                     captures the phenomenological and neuropsychological
                                                                     features of episodic future thinking. Certainly, this model
                                                                     does not capture the whole aspects of episodic future
                                                                     thinking, and in this sense, this is a proto-episodic future
                                                                     thinking model. In future work, implementation of essential
                                                                     factors for episodic future thinking is required such as the
                                                                     concepts of “self” or “temporal distance”.
                                                                                         Acknowledgments
                                                                       This study was supported by Grant-in-Aid for Challenging
                                                                     Exploratory Research (23653224) to J. Kawaguchi, and for
   Figure 4: The similarity structure in the activation patterns     JSPS Fellows (24008998) to Y. Ito.
     of the hidden layer as a function of the input context
          information and of with/without semantics.                                          Reference
                                                                     Addis, D. R., Wong, A. T., & Schacter, D. L. (2008). Age-
sequence such that it forms a context-coherent episode. One             related changes in the episodic simulation of future events.
might describe this as a framework within which episodic                Psychological science, 19, 33-41.
details are integrated (D’Argembeau & Mathy, 2011).                  Atance, C. M., & O’Neill, D. K. (2001). Episodic future
Interestingly, Schapiro et al. (2013) has recently                      thinking. Trends in cognitive sciences, 5, 533-539.
demonstrated that temporally-close stimuli that form one             Botvinick, M., & Plaut, D. C. (2004). Doing without schema
coherent event are similarly represented (in terms of voxel-            hierarchies: A recurrent connectionist approach to normal
based neural patterns) in the inferior/superior anterior                and impaired routine sequential action. Psychological
temporal lobe and inferior frontal gyrus, both of which are             Review, 111, 395-429.
the damaged areas in semantic dementia patients. Damage              D’Argembeau, A., & Mathy, A. (2011). Tracking the
in this area might disrupt in computation of such similar               construction of episodic future thoughts. Journal of
neural patterns, and bound stimuli might fall apart.                    experimental psychology: General, 140, 258-271.
  Then, the question is why collapsed semantic knowledge             Elman, J. L. (1990). Finding Structure in Time. Cognitive
has little effect on episodic recognition accuracy, as was              Science, 14, 179-211.
demonstrate in this model as well as in patients with                Irish, M., Addis, D. R., Hodges, J. R., & Piguet, O. (2012).
semantic dementia (Irish et al., 2008). This is because                 Considering the role of semantic memory in episodic
recognition of a particular event is both context-specific and          future thinking: evidence from semantic dementia. Brain,
agent/action/object/instrument-specific. In other words, it is          135, 2178-2191.
crucial not to confuse a new event with an old one, even if          Perruchet, P. & Amorim, M. A. (1992). Conscious
part of the information contained in that new event is                  knowledge and changes in performance in sequence
semantically familiar (e.g., you have ever used that                    learning: Evidence against dissociation. Journal of
instrument before and/or have seen the same action                      Experimental Psychology: Learning, Memory, and
conducted by the same agent, yet in a different context).               Cognition, 18, 785-800.
Therefore, it is possible that event recognition is not              Schacter, D. L., Addis, D. R., & Buckner, R. L. (2007).
influenced by degradation of semantic knowledge (or at                  Remembering the past to imagine the future: the
least not detected with a standard test).                               prospective brain. Nature reviews Neuroscience, 8, 657-
  Admittedly, the ability to generate context-specific event            661.
predictions could be simulated if the modules representing           Schacter, D. L., Addis, D. R., & Buckner, R. L. (2008).
schemas or scripts were explicitly built-in by a modeller a             Episodic simulation of future events: concepts, data, and
priori. However, the model implemented symbolic system                  applications. Annals of the New York Academy of Sciences,
must have assumptions about schematic knowledge                         1124, 39-60.
preliminarily (further discussions, Botvinick & Plaut, 2004).        Schapiro, A. C., Rogers, T. T., Cordova, N. I., Turk-Browne,
The present sequential model did not have that symbolic                 N. B., & Botvinick, M. M. (2013) Neural representations
system and developed by learning the statistical structure in           of events arise from temporal community structure.
the event sequence. This implies that learning sequential               Nature Neuroscience, 16, 486-492.
structure enables the model to compute schema-like                   Szpunar, K. K., Watson, J. M., & McDermott, K. B. (2007).
representation (Botvinick & Plaut, 2004), and can capture               Neural substrates of envisioning the future. Proceedings
the behaviour of semantic dementia patients..                           of the National Academy of Sciences of the United States
  In summary, we have clarified the mechanism by which                  of America, 104, 642-647.
semantics contribute to episodic future thinking. The                Woollams, A. M., Joanisse, M., & Patterson, K. (2009).
sequence prediction model (Elman, 1990) is a useful                     Past-tense generation from form versus meaning:
computational framework that can be extended to an event                Behavioural data and simulation evidence. Journal of
sequence triggered by a cue such that it successfully                   Memory and Language, 61, 55-76.
                                                                 2631

