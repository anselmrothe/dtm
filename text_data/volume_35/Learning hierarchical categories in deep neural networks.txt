UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning hierarchical categories in deep neural networks
Permalink
https://escholarship.org/uc/item/2fv5q3hn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Saxe, Andrew M.
McClellans, James L.
Ganguli, Surya
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                Learning hierarchical category structure in deep neural networks
                                               Andrew M. Saxe (asaxe@stanford.edu)
                                                    Department of Electrical Engineering
                                           James L. McClelland (mcclelland@stanford.edu)
                                                           Department of Psychology
                                               Surya Ganguli (sganguli@stanford.edu)
                                                         Department of Applied Physics
                                               Stanford University, Stanford, CA 94305 USA
                                Abstract
   Psychological experiments have revealed remarkable regulari-
                                                                                                                 W 21
   ties in the developmental time course of cognition. Infants gen-
   erally acquire broad categorical distinctions (i.e., plant/animal)                           W 32
   before finer ones (i.e., bird/fish), and periods of little change
   are often punctuated by stage-like transitions. This pattern of
   progressive differentiation has also been seen in neural net-
   work models as they learn from exposure to training data. Our
   work explains why the networks exhibit these phenomena. We
   find solutions to the dynamics of error-correcting learning in                     y ∈ R N3        h ∈ R N2          x ∈ R N1
   linear three layer neural networks. These solutions link the
   statistics of the training set and the dynamics of learning in the        Figure 1: The three layer network analyzed in this work.
   network, and characterize formally how learning leads to the
   emergence of structured representations for arbitrary training            Here we analyze the learning dynamics of a linear three
   environments. We then consider training a neural network on            layer network and find, surprisingly, that it can exhibit highly
   data generated by a hierarchically structured probabilistic gen-
   erative process. Our results reveal that, for a broad class of         nonlinear learning dynamics, including rapid stage-like tran-
   such structures, the learning dynamics must exhibit progres-           sitions. Furthermore, when exposed to hierarchically struc-
   sive, coarse-to-fine differentiation with stage-like transitions       tured data sampled from a hierarchical probabilistic model,
   punctuating longer dormant periods.
                                                                          the network exhibits progressive differentiation of concepts
   Keywords: neural networks; hierarchical generative models;
   semantic cognition; learning dynamics                                  from broad to fine. Since such linear networks are sensitive
                                                                          only to the second order statistics of inputs and outputs, this
                            Introduction                                  yields the intriguing result that merely second order patterns
Our world is characterized by a rich, nested hierarchical                 of covariation in hierarchically structured data contain statis-
structure of categories within categories, and one of the most            tical signals powerful enough to drive certain nontrivial, high
remarkable aspects of human semantic development is our                   level aspects of semantic development in deep networks.
ability to learn and exploit this structure. Experimental work               We outline our approach here in brief. We begin by de-
has shown that infants and children acquire broad categorical             composing the training set to identify important dimensions
distinctions before fine categorical distinctions (Keil, 1979;            of variation using the singular value decomposition (SVD),
Mandler & McDonough, 1993), suggesting that human cat-                    which will turn out to be fundamental to our analysis. Next,
egory learning is marked by a progressive differentiation of              we examine the equations governing gradient descent learn-
concepts from broad to fine. Furthermore, humans can ex-                  ing and show that they can be solved in terms of the SVD
hibit stage-like transitions as they learn, rapidly progress-             of the training set. This solution analytically expresses the
ing through successive levels of mastery (Inhelder & Piaget,              weight values of the neural network at any point in time dur-
1958; Siegler, 1976).                                                     ing learning as a function of the input training set. Finally, we
   Many neural network simulations have captured aspects of               consider generating the training set from a hierarchical prob-
these broad patterns of semantic development (Rogers & Mc-                abilistic generative model. We analytically calculate the SVD
Clelland, 2004; Rumelhart & Todd, 1993; McClelland, 1995;                 of training sets so generated, which in combination with our
Plunkett & Sinha, 1992; Quinn & Johnson, 1997). The inter-                previous results gives a formal grounding for how neural net-
nal representations of such networks exhibit both progressive             works will learn about hierarchical categorical structure. We
differentiation and stage-like transitions. However, the the-             show that networks must exhibit progressive differentiation of
oretical basis for the ability of neuronal networks to exhibit            categorical structure and stage-like transitions for any train-
such strikingly rich nonlinear behavior remains elusive. What             ing set generated by a class of hierarchical generative models.
are the essential principles that underly such behavior? What
aspects of statistical structure in the input are responsible for                      Decomposing the training set
driving such dynamics? For example, must networks exploit                 Our fundamental goal is to understand the dynamics of learn-
nonlinearities in their input-output map to detect higher order           ing in neural networks as a function of the training set. To-
statistical regularities to drive such learning?                          ward this goal, in this section we introduce the singular
                                                                      1271

value decomposition, which identifies important dimensions                               Items                        Modes               Modes                  Items
                                                                                     C   S O     R                1    2 3            1     2   3           C    S O     R
of variation in the training set. The SVD will turn out to be                                                                                                                 1	  
                                                                             M                            M
fundamentally linked to learning dynamics, a connection we                                                                    Modes                 Modes                     0	  
                                                                        Properties                   Properties
develop in the next section. We wish to train a neural network
to learn a particular input-output map from a set of P training         B S F
                                                                                                     =
                                                                                                     B S F                                                                    -­‐1	  
examples {xµ , yµ } , µ = 1, . . . , P. These P pairs of vectors con-        P                            P
stitute the training set. In the model of semantic development
introduced by Rumelhart and Todd (1993), for instance, ele-                              Σ31         =                U                    S                      VT
                                                                                  Input-output           Feature synthesizer                                Object analyzer
ments of xµ correspond to input units representing items such                   correlation matrix             vectors
                                                                                                                             Singular values
                                                                                                                                                                vectors
as Canary or Rose. The elements of yµ correspond to out-                Figure 2: First three modes of the singular value decompo-
put units representing possible predicates or attributes such           sition of a toy dataset. Left: The learning environment is
as can Fly or has Petals that may or may not apply to each              specified by an input-output correlation matrix. Right: The
item. Hence each example links a particular item to a set of            SVD decomposes Σ31 into modes that link a set of coherently
properties, and the training set contains the semantic content          covarying items (object analyzer vectors in the rows of V T ) to
in the world to be learned by the network.                              a set of coherently covarying properties (feature synthesizer
   For concreteness, we consider a simple example dataset               vectors in the columns of U). The overall strength of this
with four items (Canary, Salmon, Oak, and Rose) and five                link is given by the singular values lying along the diagonal
properties. The two animals share the property that they can            of S. In this toy example, mode 1 distinguishes plants from
Move, while the two plants cannot. In addition each item has            animals; mode 2 birds from fish; and mode 3 flowers from
a unique property: can Fly, can Swim, has Bark, and has                 trees.
Petals, respectively. In a more natural data set, the plant-
animal, bird-fish, and tree-flower distinctions are based on
clusters of covarying properties, for which the single proper-             The N3 × N3 orthogonal matrix U 33 can be interpreted as a
ties identified here serve as proxies.                                  feature synthesizer–it contains those features typical of a par-
   An important function of the training set is the input-output        ticular dimension in each column. Hence the feature synthe-
correlation matrix                                                      sizer associated with the animal-plant dimension has positive
                                                                        values for can Move, since animals typically can move while
                             P
                                                                        plants cannot.
                     Σ31 ≡   ∑ yµ xµ ≡ E[yxT ].                  (1)
                             µ=1                                           Finally the N3 × N1 association strength matrix S31 cap-
                                                                        tures the overall strength of the association between an in-
For our example dataset, this matrix is shown in Fig. 2. Each           put dimension and output dimension. It is nonzero only on
column corresponds to an item, and denotes the properties               the diagonal; these elements are the singular values sα , α =
possessed by that particular item.                                      1, . . . , N1 ordered so that s1 ≥ s2 ≥ · · · ≥ sN1 . The large as-
   Our example dataset contains important shared structure.             sociation strength for the animal-plant dimension reflects the
The Canary and Salmon, for instance, both can Move, and                 fact that this one dimension explains more of the training set
hence may naturally be grouped together. Intuitively, they are          than the finer-scale dimensions like bird-fish and flower-tree.
both animals, and as a consequence have certain properties                 In a larger training set, the SVD will extract modes that
in common that are typical of animals. How can we identify              capture patterns of coherent covariation in the properties of
these coherently covarying groups of items and their proper-            items in the training set. The quantities defining each mode,
ties? We will show that the singular value decomposition of             {sα , uα , vα }, are connected to the learning dynamics of neural
the input-output correlation matrix accomplishes exactly this.          networks in the next section.
   The singular value decomposition (SVD)
                                         N1
                                                                                     Gradient descent dynamics in multilayer
                31      33 31 11 T             α αT                                             neural networks
              Σ      =U S V          =   ∑ sα u   v   ,          (2)
                                         α=1
                                                                        We examine learning in a three layer network (input layer
decomposes any matrix into the product of three matrices.               1, hidden layer 2, and output layer 3) with linear activation
Each of these matrices has an important real world interpre-            functions, simplifying the network model of Rumelhart and
tation. We call the N1 × N1 orthogonal matrix V 11 the object           Todd (1993). Let Ni be the number of neurons in layer i, W 21
analyzer–it determines the position of a particular item along          be an N2 × N1 matrix of synaptic connections from layer 1
a number of important dimensions of the training set. The               to 2, and similarly, W 32 an N3 × N2 matrix of connections
                 T
first row of V 11 , for instance, determines where items sit on         from layer 2 to 3. The input-output map of the network is
an animal-plant dimension, and hence has positive values for            y = W 32W 21 x, where x is an N1 dimensional column vector
the Canary and Salmon and negative values for the plants. In            representing inputs to the network, and y is an N2 dimensional
our example dataset, the three dimensions identified by the             column vector representing the network output (see Fig. 1).
SVD are animal-plant, bird-fish, and flower-tree.                          Training is accomplished in an online fashion via stochas-
                                                                    1272

tic gradient descent; each time an example µ is presented, the          have shown that relaxing this assumption to incorporate more
weights W 32 and W 21 are adjusted by a small amount in the             complex input correlations leaves intact the basic phenom-
                                                                  2
direction that minimizes the squared error yµ −W 32W 21 xµ              ena of progressive differentiation and stage-like transitions
between the desired feature output, and the network’s feature           in learning. Nevertheless, understanding the impact of input
output. This gradient descent procedure yields the standard             correlations is an important direction for further work.
back propagation learning rule                                             Second, the form of Eqns. (7)-(8) highlights the coupling
                                                                        between the two equations: to know how to change W 21 we
                                       T
                ∆W 21     = λW 32 (yµ − ŷµ ) xµT               (3)     must know W 32 , and visa versa, since each appears in the
                ∆W   32             µ     µ
                          = λ (y − ŷ ) h , µT
                                                                (4)     update equation for the other. This coupling is the crucial
                                                                        element added by the addition of a hidden layer, and as we
for each example µ, where ŷµ = W 32W 21 xµ denotes the output          shall see, it qualitatively changes the learning dynamics of
of the network in response to input example xµ , hµ = W 21 xµ           the network compared to a “shallow” network with no hid-
is the hidden unit activity, and λ is a small learning rate.            den layer. Intuitively, this coupling complicates the learn-
            T                                                           ing procedure since both weight matrices must cooperate to
Here W 32 (yµ − ŷµ ) in (3) corresponds to the signal back-
propagated to the hidden units through the hidden-to-output             produce the correct answer; but crucially, it enables knowl-
weights. These equations emphasize that the learning pro-               edge sharing between different items, by assigning them sim-
cess works by comparing the network’s current output ŷµ to             ilar hidden unit representations. Without this coupling, the
the desired target output yµ , and adjusting weights based on           network would learn each item-property association indepen-
this error term.                                                        dently, and would not be sensitive to shared structure in the
   By a substitution and rearrangement, however, we can                 training set.
equivalently write these equations as                                   The temporal dynamics of learning To understand the
                               T                                        connection between learning dynamics and training set statis-
          ∆W 21   = λW 32        yµ xµT −W 32W 21 xµ x µT
                                                           
                                                                (5)     tics, then, we can solve Eqns. (7)-(8). We have found a class
                                                           T
          ∆W 32   = λ yµ xµT −W 32W 21 xµ xµT W 21 .                    of exact solutions (whose derivation will be presented else-
                                                    
                                                                (6)
                                                                        where) that describe the weights of the network over time
This form emphasizes two crucial aspects of the learning dy-            during learning, as a function of the training set. In partic-
namics. First, it highlights the importance of the statistics           ular, the composite mapping at any time t is given by
of the training set. In particular, the training set enters only
                                                                                                         N2
through two terms, one related to the input-output correla-
                                                                                    W 32 (t)W 21 (t) =  ∑ a(t, sα , a0α ) uα vαT ,   (9)
tions yµ xµT and the other related to the input correlations                                            α=1
xµ xµT . Indeed, if λ is sufficiently small so that weights change
only a small amount per epoch, we can rewrite these equa-               where the function a(t, s, a0 ) governing the strength of each
tions in a batch update form by averaging over the training             input-output mode is given by
set to obtain the mean change in weights per learning epoch,
                                                                                                              se2st/τ
              d 21                                                                       a(t, s, a0 ) =                    .        (10)
           τ    W       = W 32
                                 T
                                      Σ31 −W 32W 21 Σ 11
                                                         
                                                                (7)                                     e2st/τ − 1 + s/a0
             dt
              d                                         T               That is, the network learns about the N2 strongest input-
           τ W 32             Σ31 −W 32W 21 Σ11 W 21 ,
                                                 
                        =                                       (8)     output modes identified by the singular value decomposi-
             dt
                                                                        tion, progressively incorporating each mode into its repre-
where Σ11 ≡ ∑µ=1 xµ xµT ≡ E[xxT ] is an N1 × N1 input corre-            sentation. The coefficient a(t, sα , a0 ) describes how strongly
lation matrix, Σ31 is the N3 × N1 input-output correlation ma-          input-output mode α has been learned by time t, starting
trix defined previously, and τ ≡ Pλ . Hence we see that linear          from some small initial value of a0 . As can be seen from
networks are sensitive only to the second order statistics of           Fig. 3, this function is a sigmoidal curve, capturing the fact
inputs and outputs. In general the learning process is driven           that the network initially knows nothing about a particular
by both the input and input-output correlation matrices. Here           dimension (the animal-plant dimension, say), but over time
we take the simplifying assumption that these input corre-              learns the importance of this dimension and incorporates it
lations are insignificant; formally, we assume Σ11 = I, the             into its representation, ultimately reaching the correct asso-
identity matrix. Concretely, this assumption corresponds to             ciation strength sα . At this point the network correctly maps
the supposition that input representations for different items          items onto the animal-plant dimension using the object an-
are highly differentiated from, or orthogonal to each other.            alyzer vector vαT , and generates the corresponding correct
While this is unlikely to hold exactly in any natural domain,           features using the feature synthesizer vector uα .
we take this assumption for two reasons. First, it was used in             Eqns. (9)-(10) describe the fundamental connection be-
prior simulation studies (Rogers & McClelland, 2004), and               tween the structure of a training set and learning dynamics.
hence our attempt to understand their results is not limited            In particular, the dynamics depends on the singular value
by this assumption. Second, Rogers and McClelland (2004)                decomposition of the input-output correlation matrix of the
                                                                    1273

                                                                                           sharp stage-like transitions. Importantly, we can prove that
Input−output mode strength
                             150                                                           networks with only direct input-output connections and no
                                                                    Simulation
                                                                    Theory
                                                                                           hidden layer are not capable of such stage-like transitions.
                             100                                                           Their existence is an emergent property of nonlinear learning
                                                                                           dynamics in deep networks with at least one hidden layer.
                                                                                              The result in (9) is the solution to (7)-(8) for a special class
                              50
                                                                                           of initial conditions on the weights W 21 and W 32 . However
                                                                                           this analytic solution is a good approximation to the time evo-
                               0                                                           lution the network’s input-output map for random small ini-
                                   0   100   200       300    400    500     600           tial conditions, as confirmed in Fig. 3.
                                                   t (Epochs)
                                                                                           Summary of learning dynamics The preceding analyses
Figure 3: Close agreement between theoretically predicted                                  have established a number of crucial features of gradient de-
time course and numerical simulations. Simulations were                                    scent learning in a simple linear network, making explicit the
performed with a dataset sampled from the hierarchical diffu-                              relationship between the statistical structure of training exam-
sion process described in detail in a later section, with D = 3                            ples and the dynamics of learning. In particular, the learning
hierarchical levels, binary branching, flip probability ε = 0.1,                           dynamics depend crucially on the singular values of the input-
and N = 10, 000 sampled features. This data set had 3 unique                               output correlation matrix. Each input-output mode is learned
singular values. Red traces show ten simulations of the singu-                             in time inversely proportional to its associated singular value,
lar value dynamics of W 32 (t)W 21 (t) in Eqns. (7)-(8) starting                           yielding the intuitive result that stronger input-output associ-
from different random initializations, and blue traces show                                ations are learned before weaker ones.
theoretical curves obtained from (10).
                                                                                                    The singular values and vectors of
training set. Further, they reveal important properties of these                                      hierarchically generated data
learning dynamics.
                                                                                           In this section we introduce a hierarchical probabilistic gen-
   First, each input-output mode is learned on a different time
                                                                                           erative model of items and their attributes that, when sam-
scale, governed by its singular value sα . To calculate this
                                                                                           pled, produces a dataset that can be supplied to our neural
time scale, we can assume a small initial condition a0 = ε
                                                                                           network. By analytically calculating the SVD of this data, we
and ask when a(t) in (10) rises to within ε of the final value
                                                                                           will be able to explicitly link hierarchical taxonomies of cat-
sα , i.e. a(t) = sα − ε; then the timescale of learning in the
                                                                                           egories to the dynamics of network learning. A key result in
limit ε → 0 is
                                  τ sα                                                     the following is that our network must exhibit progressive dif-
                        t(s, ε) = ln .                      (11)                           ferentiation with respect to any of the underlying hierarchical
                                 sα   ε
                                                                                           taxonomies allowed by our generative model.
Hence up to a logarithmic factor, the time required to learn
an input-output mode is inversely related to its association                               Hierarchical feature vectors from a branching diffusion
strength, quantified through its singular value.                                           process We propose a simple generative model of hierar-
   Second, these dynamics reveal stage-like transitions in                                 chical data {xµ , yµ }, and compute for this model the input-
learning performance. Intuitively, this property arises from                               output modes (sα , uα , vα ) which drive learning. The hierar-
the sigmoidal transition in (10) from a state in which the net-                            chical structure in the generative model is represented by a
work does not represent a particular input-output relation at                              tree (see e.g. Fig. 4). Each leaf node of this tree corresponds
all, to a state in which the network fully incorporates that rela-                         to an item in the dataset. Our generative process assigns fea-
tion. Because of the sigmoidal shape, the solution can remain                              tures to these items such that items with more recent common
very small for a long period of time before rapidly transition-                            ancestors are more likely to share features. For instance, our
ing to mastery. To formalize this, we note that the time it                                example dataset might have been generated by a three level
takes to reach half mastery (i.e. a(thalf ) = s/2) is                                      binary tree with four leaf nodes. The top level would separate
                                                                                           the animals from the plants, while the next level would sepa-
                                                τ
                                                     
                                                        s
                                                                                          rate the birds from the fish and the flowers from the plants.
                                         thalf = log      −1 .                   (12)         In detail, to sample one feature’s value across items, the
                                                2s     a0
                                                                                           root node is randomly set to ±1 with equal probability 21 ;
In contrast, the duration of the transition period in which the                            next this value diffuses to children nodes, where its sign is
weights change rapidly is ttrans = 2τs (using a linear approx-                             flipped with a small probability ε. This process continues
imation). Thus, by starting with a very small initial condition                            until the leaf nodes have been assigned values. These assign-
for the weights (i.e. a0 ≈ 0), it is clear that one can make                               ments yield the value of this feature on each item.
the ratio ttrans /thalf arbitrarily small, i.e., the transition pe-                           Under this process, the can Move feature, for example,
riod can be very brief relative to the long initial period of                              might have arisen as follows: randomly the root node of the
dormancy. Hence the learning dynamics of (7)-(8) exhibit                                   three level binary tree was assigned a value of 1. This value
                                                                                        1274

diffused down to the two second level nodes, maybe in this in-
stance changing sign to −1 for the parent node of the plants,
but not changing for the parent node of the animals. Then
these values diffused down to the leaf nodes representing the
individual items, perhaps not flipping sign for any of them.
                                                                                                                (a)
Hence the ultimate feature assignment would be +1 on the                                                                                   1	  
Canary and Salmon and −1 on the Flower and Tree. This                                   1   +1   +1   +1   +1         +1   +1   +1   +1
is just one possible sample from the generative model, but                              2   +1   +1   +1   +1         -1   -1   -1   -1
serves to illustrate how hierarchical structure arises from the                         3   +1   +1   -1   -1         0    0    0    0
                                                                                Modes
feature generation process. To generate more features, the                              4   0    0    0    0          +1   +1   -1   -1
process is repeated independently N times.                                              5   +1   -1   0    0          0    0    0    0
   For simplicity, we consider trees with a regular branching                           6   0    0    +1   -1         0    0    0    0
structure. The tree has D levels indexed by l = 0, . . . , D −                          7   0    0    0    0          +1   -1   0    0
1, with Ml total nodes at level l. Every node at level l has                            8   0    0    0    0          0    0    +1   -1
exactly Bl descendants. Thus Ml = M0 Πl−1   k=0 Bl . The tree has                           1    2    3    4          5    6    7    8
                                                                                                                                          -­‐1	  
a single root node at the top (M0 = 1), and again P leaves at                                              Items
the bottom, one per example in the dataset (MD−1 = P).                                                       (b)
                                                                                                                                           1	  
   We have thus far described the output feature vectors yµ . To                        1
complete the specification of the training set, we assume that                          2
the input vectors xµ are simply chosen to be highly distinct                            3
(i.e., orthogonal). One such choice is a localist coding scheme
                                                                                Items
                                                                                        4
in which a different element is active to represent the presence                        5
of each item.                                                                           6
Input-output modes of hierarchical data How will our                                    7
neural network learn about training sets generated as just de-                          8
                                                                                                                                          0.3	  
scribed? To understand this, we calculate the SVD of such                                   1    2    3    4          5    6    7    8
                                                                                                           Items
training sets. We will see that the input-output modes identi-
                                                                                                             (c)
fied by the SVD exactly mirror the tree structure used to gen-
erate the dataset. The feature generation process described         Figure 4: Statistical structure of hierarchical data. (a) Ex-
in the previous section generates a training set with N fea-        ample hierarchical diffusion process with D = 4 levels and
tures. In the limit of large numbers of features, we obtain the     branching factor B = 2. (b) Analytically derived input singu-
following (the full derivation to be presented elsewhere):          lar vectors, or modes, (up to a scaling) of the resulting data,
   The object analyzer vectors exactly mirror the tree struc-       ordered top-to-bottom by singular value. Besides mode 0,
ture, as shown in Fig. 4. One mode will correspond to a             each mode, or object analyzer, can discriminate objects, or
broad, high level distinction (e.g., animal-plant) near the root    leaves of the tree, whose first common ancestor arises at a
of the tree, while another will correspond to a more detailed       given level of the tree. This level is 0 for mode 2, 1 for modes
distinction (e.g., bird-fish). For binary trees, each object an-    3 and 4, and 3 for modes 5 through 8. Singular modes cor-
alyzer vector will have positive weights on all items on one        responding to broad distinctions (higher levels) have larger
side of a binary distinction, and negative weights on all items     singular values, and hence will be learned earlier. (c) The co-
on the other side. The rest of the entries will be zero. Hence      variance matrix between pairs of objects in the output feature
this object analyzer vector will only be able to tell items apart   space consists of hierarchically organized blocks.
with respect to this one distinction. It contains no information
about higher or lower level distinctions in the tree. For trees
with other branching factors, the situation is the same: ad-           While this equation gives the correct quantitative value for
ditional object analyzer vectors are introduced to permit dis-      the association strength in terms of the parameters of the
tinctions between more than two options, but these vectors          generative process, its most important property is its qual-
contain no information about distinctions at other levels in        itative behavior: it is a decreasing function of the hierar-
the tree.                                                           chy level l (see, e.g., Fig. 5). Crucially, this means that the
   The association strength or singular value sl associated         input-output modes corresponding to broader distinctions like
with level l of the binaryvtree is                                  animal-plant have a stronger association strength than those
                          u                !
                                   D−1                              corresponding to finer distinctions like bird-fish. Since we
                          u             ∆l
                     sl = NP ∑
                          t                  ,               (13)   have previously shown that modes with stronger association
                                   k=l Ml
                                                                    strengths are learned more quickly, this immediately implies
where qk = (1 − 4ε(1 − ε))D−1−k and ∆l ≡ ql − ql−1 , with the       that broader distinctions among examples will be learned
caveat that q−1 ≡ 0.                                                faster than fine-grained distinctions among examples.
                                                                1275

                         50
                                                         Simulation         By connecting probabilistic models and neural networks,
                         40                              Theory
                                                                         our framework quantitatively links structured environments
        Singular value
                                                                         to learning dynamics. In future work, it will be important to
                         30
                                                                         compare the features of our neural network learning model
                         20                                              with those of structured probabilistic learning models (e.g.,
                                                                         Kemp and Tenenbaum (2008). Like structured models, neu-
                         10                                              ral networks can learn a range of different structure types, but
                                                                         unlike structured models, networks can learn without prior
                          0                                              enumeration of such structures. Furthermore, networks can
                              0   1       2      3        4     5
                                       Hierarchy level                   easily learn to represent data that are approximations or hy-
Figure 5: Agreement between theoretically computed singu-                brids of different structure types–features that, we believe,
lar values in the limit of large numbers of features (obtained           characterize natural domains, such as the domain of living
from (13)) and simulation for hierarchically structured data.            things considered here.
The simulations show singular values arising from sampling                                  Acknowledgments
200 features from a hierarchical generative model with six               S.G. thanks DARPA, BioX, Burroughs-Wellcome, and Sloan
levels, binary branching, and ε = 0.1. The singular values               foundations for support. J.L.M. was supported by AFOSR.
are a decreasing function of the hierarchy level, implying               A.S. was supported by a NDSEG Fellowship and MBC
that finer distinctions among examples will be learned more              Traineeship. We thank Juan Gao and Jeremy Glick for useful
slowly.                                                                  discussions.
                                                                                                 References
Summary of the statistics of hierarchical data Thus we
                                                                         Inhelder, B., & Piaget, J. (1958). The growth of logical
have shown that the singular vectors of data from a hierarchi-
                                                                           thinking from childhood to adolescence. New York: Ba-
cal diffusion process correspond exactly to the hierarchical
                                                                           sic Books.
distinctions in the underlying tree, and furthermore, that sin-
                                                                         Keil, F. (1979). Semantic and conceptual development: An
gular vectors corresponding to broader hierarchical distinc-
                                                                           ontological perspective. Cambridge, MA: Harvard Univer-
tions have larger singular values than those corresponding to
                                                                           sity Press.
finer distinctions (Fig. 4AB). In combination with the preced-
                                                                         Kemp, C., & Tenenbaum, J. B. (2008, August). The discovery
ing analysis of neural network learning dynamics, this result
                                                                           of structural form. Proceedings of the National Academy of
shows that our deep neural network must exhibit progressive
                                                                           Sciences of the United States of America, 105(31), 10687–
differentiation on any dataset generated by an instance of this
                                                                           92.
class of hierarchical, branching diffusion processes.
                                                                         Mandler, J. M., & McDonough, L. (1993). Concept Forma-
                                      Discussion                           tion in Infancy. Cognitive Development, 8, 291–318.
Our results explore the rich dynamics arising from gradient              McClelland, J. L. (1995). A Connectionist Perspective on
descent learning in a deep neural network, despite a com-                  Knowledge and Development. In T. Simon & G. Halford
pletely linear input-output mapping. We have shown that                    (Eds.), Developing cognitive competence: New approaches
these dynamics, driven solely by second order statistics, iden-            to process modeling. Hillsdale, NJ: Erlbaum.
tify coherently covarying input and output modes in the learn-           Plunkett, K., & Sinha, C. (1992). Connectionism and de-
ing environment, and we expressed the full time course of                  velopmental theory. British Journal of Developmental Psy-
learning in terms of these modes. Finally, we moved beyond                 chology, 10(3), 209–254.
particular datasets to extract general principles by analyzing           Quinn, P., & Johnson, M. (1997). The emergence of percep-
the covariance structure of hierarchical probabilistic models,             tual category representations in young infants: A connec-
showing that progressive differentiation is a general feature of           tionist analysis. Journal of Experimental Child Psychology,
learning hierarchically structured training data in deep neural            66, 236–263.
networks.                                                                Rogers, T., & McClelland, J. (2004). Semantic cognition: A
   We have focused our analysis on a few notable features of               parallel distributed processing approach. Cambridge, MA:
the learning dynamics–progressive differentiation and stage-               MIT Press.
like transitions–but our framework yields insights (to be pre-           Rumelhart, D., & Todd, P. (1993). Learning and connectionist
sented elsewhere) into many other phenomena in semantic                    representations. In D. Meyer & S. Kornblum (Eds.), Atten-
development such as, erroneous “illusory correlations” early               tion and performance xiv: Synergies in experimental psy-
in learning, familiarity and typicality effects, inductive prop-           chology, artifical intelligence, and cognitive neuroscience.
erty judgements, and the impact of perceptual correlations on              Cambridge, MA: MIT Press.
learning dynamics. Moreover, this approach enables quanti-               Siegler, R. (1976). Three aspects of cognitive development.
tative definitions of important intuitive notions like “category           Cognitive Psychology, 8, 481–520.
coherence”, and yields precise theorems delineating how cat-
egory coherence controls network learning rates.
                                                                      1276

