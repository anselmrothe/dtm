UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The missing baselines in arguments for the optimal efficiency of languages
Permalink
https://escholarship.org/uc/item/7738n7cz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Moscoso del Prado, Fermin
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                     University of California

        The missing baselines in arguments for the optimal efficiency of languages
                             Fermı́n MOSCOSO DEL PRADO (fmoscoso@linguistics.ucsb.edu)
                                                          Department of Linguistics
                                                  University of California, Santa Barbara
                                                    Santa Barbara, CA 93106-3100 USA
                                Abstract                                graphically– called an “intermittent silence” process. The
                                                                        validity and importance of Zipf’s original observations on
   I argue that linear correlations between log word frequency,and
   lexical measures, cannot be taken as evidence for a “Princi-         the distribution of word frequencies and word lengths is be-
   ple of Minimum Effort”. The Principle of Maximum Entropy             yond doubt, as is evidenced for instance in a whole family of
   indicates that such relations are in fact the ones most proba-       power-law distributions and phenomena across many unre-
   ble to be found. For such claims, one needs to compare the
   correlations with adequate baselines reflecting what would be        lated fields of science being currently named in Zipf’s honor
   expected in a purely random system. I then introduce a way           (e.g., Zipf’s Laws, Zipfian distributions, Zipf-Mandelbrot dis-
   of computing such baselines, and use it to show that the cor-        tribution). However, Zipf’s interpretation that such properties
   relations found in a corpus are actually weaker than what one
   would expect to find by chance. Therefore, if an argument            reflect the optimization of human language structure is dis-
   were to be made based on them, it would paradoxically be that        confirmed by the fact that those very same properties are also
   language is worse for communication than what one would ex-          found in systems that are not the result of any optimization
   pect to find in a random system. More appropriately however,
   what these results reflect is that such correlations are not the     process. The properties are therefore not informative about
   best places to look for linguistic optimality.                       the optimality of the process that generated them. This high-
   Keywords: Corpus Study; Lexical Ambiguity; Principle of              lights a problem that is exhibitted by many claims on lan-
   Maximum Entropy; Zipf’s Law of Abbreviation                          guage properties that reflect some form of optimization: The
                                                                        lack of a non-optimal baseline against which to test whether
                           Introduction                                 such inferences are perhaps non sequiturs.
Arguments about language being optimal for communication                   Let us consider a non-linguistic example. Suppose I put
have a long tradition within the cognitive sciences, dating at          forward a theory on the processes governing the outcome ob-
least as far back as Zipf (1935). Zipf observed that, across            tained when throwing two particular dice. The dice them-
many texts, there is an inverse correlation between a word’s            selves would be beyond my possible observations (e.g., in-
frequency of occurrence and its length in characters, which is          side a black box), but I would have access to the sum of their
now referred to as Zipf’s Law of Abbreviation (ZLA). This               outcome. My theory could state that the dice are loaded so
observation led him to his “Principle of Least Effort” (Zipf,           that they strongly favor a non-extreme (or optimal) outcome
1949): Humans prefer shorter words to refer to frequent con-            of three or four dots. In order to test my theory, I would col-
cepts, so that the overall length of utterances will be mini-           lect data from many dice throws (with access only to their
mized, and so will the effort required to produce them. In this         summed values). After obtaining a few thousand throws, if I
form, from the speaker’s (or writer’s) point of view, the opti-         found that the average value of the sum is seven (with some
mality of human language would be measured by the amount                preset degree of precision), which is fully consistent with my
of effort required by a speaker to produce an utterance. Zipf           theory. As it happens, however, seven would also be the most
also realized that, from the comprehender’s perspective, opti-          likely value of the sum, even if the dice were not loaded.
mality would not be so much concerned with the length of an             Therefore, I could not take the evidence from the average
utterance as it would with the ease with which it can be unam-          value as support for my theory, as it would also be consis-
biguously decoded. Jointly considering both the perspective             tent with the a priori more likely theory that the dice are not
of the speaker and that of the comprehender, the structure of           loaded. As we will see below, one can objectively say that the
language would be subject to a trade-off between utterance              unloaded theory is more probable a priori using mere proba-
length and degree of ambiguity. Zipf was somewhat vague                 bilistic arguments (the Principle of Maximum Entropy).
with respect to how such trade-off could be measured, but his              In the example above, the prediction used to test the hy-
general idea is considered valid ever since.                            pothesized property holds trivially for the most probable out-
   As compelling as Zipf’s arguments seem, very early on,               come. One can of course design situations in which the seven
researchers in Information Theory and Psychology noticed                sum property does not hold (e.g., by loading the sixes on
that they may not be as informative as Zipf thought. Both               dice). Still, even if it is possible to artificially design such
Mandelbrot (1953) and Miller (1957) realized that the neg-              a scenario, it is still the case that the most probable outcome,
ative correlation between a word’s frequency of occurrence              whether or not any optimization is at work, is that the prop-
and its length in characters (i.e., ZLA) would also arise in            erty will hold (i.e., the dice will sum up to seven). However,
randomly generated texts that lack any linguistic structure or          even if the property were less evident than the one used in
communicative value whatsoever; what Mandelbrot dubbed                  this example, testing it also on a few non-optimal baselines
a “typing monkeys” process, and Miller –somewhat less                   would enable us to see that such property does not signal the
                                                                    1032

presence of optimization.                                             trigram) model, those words with the highest probability cor-
   This discussion is motivated by the recent publication of          respond to those that provide a more prototypical example of
several papers making claims on the optimality of human lan-          the phonotactics of a language. Those words that conform
guage which suffer from the same lack of baseline problem.            better to the phonotactic constraints of the language will be
In what follows, I begin by summarizing four of these re-             easier to pronounce and recognize. Following the “least ef-
cent arguments for language optimality. I then introduce the          fort” argument, they predict that words with high phonotactic
Principle of Maximum Entropy, and use it to show analyti-             predictability should be associated with more meanings (or
cally that the findings presented as evidence for communica-          word lemmas) than words with lower phonotactic probabil-
tive optimality turn out to be trivial predictions that will also     ity.
be observed in the most probable non-optimized baselines. In
the data section, I analyze a corpus of English to assess the                  The Principle of Maximum Entropy
strength of the effects used to argue for optimality. The re-         Before making any claims that a particular distribution of lin-
sults show that these effects are in fact significantly weaker        guistic probabilities (of words, words lengths, degrees of am-
than what one would expect to find by mere chance. In other           biguity, etc.) constitutes evidence for language being “op-
words, if one took such correlations as evidence for optimiza-        timized for human communication”, one should check what
tion, one would have to conclude that human languages are             kind of such distributions one would expect to observe by
actually less optimized than one would expect by chance. I            mere chance, irrespective of the presence any hypothetical
conclude with a discussion of how Information-Theory can              optimization process. The relevant properties of the distribu-
be used to make predictions on the optimality of human lan-           tion (e.g., ambiguous words being more frequent, etc.) should
guages that do indeed survive the non-optimal baselines tests.        be found to be significantly more (or less) marked in actual
                                                                      linguistic data than one would expect them to be.
  Some Information Theoretical Arguments for                             This raises the problem of how to determine, among the
               Communicative Efficiency                               infinite possible discrete probability distributions that words
                                                                      could have, which ones are the most probable a priori. The
In a recent study, Piantadosi, Tily, and Gibson (2012) extend
                                                                      Principle of Maximum Entropy (PME; Jaynes, 1957a, 1957b)
ZLA to the domain of lexical ambiguity. Following Zipf,
                                                                      states that, among all probability distributions satisfying a set
they argue that short words require less effort to be produced
                                                                      of constraints, the most probable one will be the one that
than longer words would. Therefore, by a similar principle of
                                                                      has the highest entropy. The entropy (Shannon, 1948) of a
economy, it would be beneficial to encode as many meanings
                                                                      probability distribution defined over a discrete set of words
as possible using the shorter words, and then use the redun-
                                                                      W = {w1 , w2 , w3 , . . .} is given by
dancy present in the context to disambiguate them. They sup-
port this claim by showing that, in corpora of three languages,                   H(W ) = −
there is indeed a negative correlation between word ambigu-
                                                                                                 ∑ P(W = w) log P(W = w),
                                                                                                w∈W
ity and word length when other factors (e.g., frequency) are
considered.                                                           where P(W = w) denotes the probability of encountering
   A second prediction of Piantadosi et al. (2012) considers          word w in a corpus of text (i.e., its relative frequency of oc-
the fact that more frequent words have a more accessible lex-         currence). In what follows, I will use the abbreviated notation
ical representation, as is evidenced by the fact that they elicit     pi = P(W = wi ). The most probable assignment of values for
shorter reaction times and lower error rates in a broad range         the pi is the one leading to the highest value of H(W ), with
of lexical processing experiments (e.g., Oldfield & Wingfield,        the obvious constraint that the values of the pi must all sum
1965). That a word is easy to access makes it a desirable             to one, so that they form an actual probability distribution.1
candidate to carry many meanings (or be associated to many               If no additional constraints were present (i.e., any assign-
uninflected word lemmas) in a system that is optimized to             ment of probabilities could be considered), then, for a finite
make the production and comprehension of words as effort-             set N probabilities, the maximum entropy would be the uni-
less as possible. Therefore, they predict a positive correlation      form distribution with pi = 1/N. Of course, when one con-
between a word’s frequency and the number of distinct mean-           siders the probabilities of words, not all probability distribu-
ings (or lemmas) associated with it. Their analyses of several        tions are valid assignments. Rather, these distributions need
corpora indeed find this correlation.                                 to satisfy some basic constraints. These specific constraints
   As convincing as these arguments might seem, I will ar-            can be requirements such as the existence of a mean word
gue below that the findings are but trivial consequences of           length or an average degree of ambiguity. Constraints of this
ZLA, and do not provide support the communicative hypoth-             type can be expressed as values of the means of some given
esis that is put forward. I will further discuss, ZLA is itself       functions. For instance, one such function can be the length
a trivial property of most symbolic sequences, irrespective of        of a word (measured in either characters, phonemes, or sylla-
whether they are optimized.                                           bles), which maps words into natural numbers (` : W 7→ N),
   Piantadosi et al. (2012) also argue that, if one computes the          1 The general validity of the PME is demonstrated using simple
probability of a word according to a triphone (i.e., phoneme          combinatorics (cf., Jaynes, 2003).
                                                                  1033

and another function can the degree to which words are am-                log word frequency and word length is more negative than
biguous, which maps words into the non-negative real num-                 λ1 . This finding complements the previous arguments of
bers (A : W 7→ R+ ). The constraints would then be expressed              Mandelbrot (1953), Miller (1957), or Ferrer i Cancho and
as the existance of a mean word length (h`(w)iW = L) and a                Moscoso del Prado (2011) that random processes also exhibit
mean degree of ambiguity (hA (w)iW = A).                                  ZLA. It provides a baseline to assess whether the ZLA ob-
   The most probable distribution that satisfies the constraints          served in a real corpus is stronger than what one would have
would then be the solution to the maximization problem:                   expected by mere chance.
                                                                              Similarly, λ2 indexes the relation between log word fre-
                      arg max −     ∑    pi log pi ,                      quency and degree of ambiguity. Piantadosi et al. (2012)’s
                                   wi ∈W
                                                                          finding of a positive correlation between a word’s ambiguity
subject to                                                                and its frequency of occurrence (i.e., frequent words are more
                                                                         ambiguous) can only be interpreted as evidence for optimality
                                 ∑wi ∈W pi           =1                  if the regression coefficient found for the degree of ambiguity
                h`(w)iW = ∑w∈W pi `(wi ) = L                      (1)     is more positive than λ2 .
                hA (w)iW = ∑w∈W pi A (wi ) = A                                A simple rewrite of Eq. 3 results in
            
Notice that I have added one constraint to indicate that the re-                                     λ0 − log pi + λ1 `(wi )
                                                                                           A (wi ) =                         .          (4)
sulting probability distribution must be normalized. The solu-                                                −λ2
tion to such a problem is found analitically using the method             This indicates that, when word frequency is kept constant or
of Laplace multipliers. It must have the form of a Boltzmann              controlled for, one should also expect to find a linear rela-
canonical distribution,2                                                  tionship between a word’s length and its degree of ambiguity
                                                                          (with a regression coefficient −λ1 /λ2 ), as was documented
                     pi = eλ0 +λ1 `(wi )+λ2 A (wi ) ,             (2)
                                                                          by Piantadosi et al. (2012). As before, in order to accept Pi-
where the parameters λ0 , λ1 , and λ2 are Laplace multipliers             antadosi and colleagues’ interpretation that their finding is in-
whose value is uniquely determined by the individual values               dicative of some form of communicative efficiency, one needs
of the word lengths `(wi ), ambiguities A (wi ) as well as their          to ensure that such relation is less marked than −λ1 /λ2 .
average values L and A.                                                       Although, for reasons of space I do not detail it here, it
                                                                          is easy to show that a word’s frequency of occurrence in a
Implications of the PME                                                   corpus is expected to be directly proportional to that word’s
Taking logs on both sides of Eq. 2 reveals that a priori –                phonotactic probability as computed from an n-phone (e.g.,
assuming the existence of a mean word length (L) and an                   diphone, triphone, . . . ) model whose parameters were com-
average degree of ambiguity (A)– the most probable relation               puted on that same corpus. If we denote a word’s triphone-
between our variables of interest is                                      based probability as Ti , we can therefore say that k pi ≈ Ti for
                                                                          some value 0 < k ≤ 1 constant across all words. If we substi-
                log pi = λ0 + λ1 `(wi ) + λ2 A (wi ).             (3)     tute on Eq. 3, we obtain
This equation already makes important predictions. We                                 log Ti − log k ≈ λ0 + λ1 `(wi ) + λ2 A (wi ).     (5)
should expect that –everything else being equal– the log prob-
                                                                          Dividing both sides of Eq. 5 by `(wi ) with a simple rearrange-
ability of a word (i.e., its log frequency) should be linearly
                                                                          ment results in
related to both its length and to its degree of ambiguity. No
assumptions about language being optimized for communi-                                 log Ti          log k + λ0 + λ2 A (wi )
                                                                                                ≈ λ1 +                          .       (6)
cation are necessary to make this prediction, it just happens                           `(wi )                  `(wi )
to be to most probable type of relation. The signs and val-               Therefore, when the degree of ambiguity is controlled for,
ues of the Laplace multipliers λ1 and λ2 will determine the               a word’s log triphone (or diphone, . . . ) probability normal-
strength and direction of the correlations. They therefore pro-           ized by its length, is expected to be non-linearly related to
vide baselines for any effects whose presence is argued to                word length itself (i.e., linearly related to the reciprocal of
reflect a form of efficiency or optimality. Without any need              word length). One would therefore expect to find the non-
for efficiency, we should expect to find correlations with the            linearities that Piantadosi et al. (2012) found. Hence, such
strengths given by λ1 and λ2 .                                            non-linear relation –by itself– cannot be interpreted to be the
   A negative value of λ1 would indicate that ZLA is in fact              product of an optimization process, contrary to what was ar-
the most likely relation that one should expect to find be-               gued by Piantadosi and his colleagues.
tween word frequency and word length. Therefore, in or-                       In summary, I have shown that the linear relationships be-
der to claim that ZLA provides evidence for communica-                    tween log word frequency, word length, and word ambigu-
tive efficiency, one should observe that the relation between             ity –by themselves– do not warrant an interpretation that lan-
    2 The general form of the solution is due to L. E. Boltzmann. For     guage is optimized for communicative efficient. In the fol-
a sketch ot the derivation, see, e.g., Moscoso del Prado (2011).          lowing section, I will estimate the values of the parameters
                                                                      1034

λ0 , λ1 , and λ2 from corpus data, and I will assess whether                 whether or not any optimization is at work. Similarly, λ2 > 0
or not they provide evidence for (or against) any sort of opti-              implies that we should expect a priori a positive correlation
mization.                                                                    (all other factors equal) between a word’s frequency and its
                                                                             degree of ambiguity. As suspected –by itself– the positive
                         Corpus Study                                        relation between frequency and ambiguity does not warrant
In order to test whether the values of the Laplace multipli-                 the interpretation of optimization, it is rather what one should
ers (λ1 , λ2 ) provide support for the hypothesis that language              expect, contrary to Piantadosi et al. (2012).
is optimized for communicative efficiency, I selected the
29,025 most frequent English content words (adjectives, ad-                                             β                                            β
verbs, nouns, and verbs) present in WordNet (Miller, 1995).3
The selection was done using their surface word spoken                                       0.5                                      0.5
frequency according the CELEX lexical database (Baayen,
                                                                                             0.0                                      0.0
                                                                             log(Ti) l(wi)                            log(Ti) l(wi)
Piepenbrock, & Gulikers, 1995), from where the correspond-
                                                                                             -0.5                                     -0.5
ing word length in phonemes was obtained.4 For each word I
counted its number of distinct senses (i.e., ‘synsets’) listed in                            -1.0                                     -1.0
WordNet (Miller, 1995). The log of the number of senses was                                  -1.5                                     -1.5
taken as the measure of a word’s ambiguity (A (wi ) = log Ni ,                                      5       10   15                          0   1   2     3   4
where Ni is the number of distinct senses of wi ).5                                                     l.w                                          A.w
   I normalized the word frequency counts into relative fre-
quencies adding up to one, and estimated the mean word                                                  λ                                            λ
length as the weighted average                                                               2                                        2
                                                                                             0                                        0
                  L = h`(wi )iW =       ∑      pi `(wi ),
                                                                             log(pi) l(wi)                            log(pi) l(wi)
                                       wi ∈W                                                 -2                                       -2
with pi being the corpus based relative frequency of wi . Sim-                               -4                                       -4
ilarly, the average degree of ambiguity was estimated as                                     -6                                       -6
                                                                                                    5       10   15                          0   1   2     3   4
       A = hA (wi )iW =      ∑      pi A (wi ) =    ∑       pi log Ni .                                 l.w                                          A.w
                            wi ∈W                  wi ∈W
Using these estimates of L and A, and the individual values of
`(wi ) and A (wi ), the values of the multipliers λ0 , λ1 , and λ2           Figure 1: Non-linear effects of word length (left pan-
were estimated by nonlinear maximization (using a Newton-                    els) and degree of ambiguity (right panels) on the length-
type algorithm) of                                                           normalized log triphone probability (top panels) and the
                                                                             length-normalized log a priori frequency (bottom panels).
                   H(W ) = −λ0 − λ1 L − λ2 A
                                                                                 To see the actual values of these correlations in the corpus
subject to the constraints of Eq. 1. In order to keep the results            itself, I performed a linear regression predicting a word’s log
comparable to those of Piantadosi and colleagues, additional                 probability from its length and its degree of ambiguity (once
parameters were added to separate the different grammatical                  more, I also included additional parameters to separate the
categories.                                                                  grammatical categories). As Piantadosi et al. (2012), I found
   The values of the Laplace multipliers were estimated to be                significant effects of both word length and degree of ambigu-
λ0 = −10.37, λ1 = −.14, and λ2 = 1.07. As I discussed in                     ity (both with p < .0001). Interestingly, the estimated coef-
the previous section, that λ1 < 0 indicates that ZLA (a neg-                 ficient for word length (β = −.05 ± .003) constitutes a much
ative correlation between word length and word frequency)                    weaker effect than the one we would have expected by chance
is the most likely relationship between these two variables,                 (λ1 = −.14). This means that the supposed optimization from
    3 The same effects reported here were also replicated for other          ZLA is actually weaker than what one should have expected,
corpora of English and French. These additional analyses are not             not supporting any optimization. In a similar vein, the coeffi-
reported here for brevity reasons.                                           cient estimated for the effect of ambiguity (β = .84 ± .01) is
    4 Piantadosi et al. (2012) report effects on length in syllables. I
                                                                             also a weaker effect than the chance level (λ2 = 1.07). Again,
use phoneme-based lengths instead as these are more sensitive, but           it seems that the negative relation between frequency and am-
I also replicated the same effects using syllable-based lengths. Con-
versely, Piantadosi and colleagues also report that their effects also       biguity that was claimed by Piantadosi and his colleagues to
held when measuring length in phonemes.                                      reflect optimization, is actually significantly weaker than the
    5 The log number of senses provides a better approximation to
                                                                             expected chance level. This illustrates the importance of hav-
the psychologically relevant magnitude than does the raw count (cf.,
Moscoso del Prado, 2007). Note however that doing the calculation            ing meaningful baselines before interpreting lexical statistics.
on raw counts of word senses did not result on different results.                As discussed in the previous section the ratio −λ1 /λ2 = .13
                                                                          1035

indexes the strength of the correlation between word length          expected effects are much stronger than those observed in the
and word ambiguity (after controlling for word frequency)            corpus. In short, the effects that allegedly reflect optimization
that we should expect by chance. Indeed, we should there-            of language for communicative efficiency are actually much
fore expect by chance a positive correlation between a word’s        weaker than we should have expected them to be.
length and its degree of ambiguity, irrespective of any opti-
mization process. The strength of this relationship in the data                               Conclusion
is given by the ratio between the corresponding regression co-
                                                                     These results do not question either ZLA or Piantadosi et
efficients β[length]/β[ambiguity] = .05, which is once more
                                                                     al. (2012)’s effects, rather the effects themselves are indeed
weaker than what we would have expected by chance.
                                                                     replicated here. What is questioned is the interpretation of
   In order to assess the non-linear effects of a word’s phono-
                                                                     such effects as evidence for optimization. I have shown that –
tactic probability, I trained a triphone model using the Brown
                                                                     by themselves– the linear relationships between log word fre-
corpus of English (Kucera & Francis, 1967) after transcribing
                                                                     quency, word length, and degree of ambiguity, do not warrant
all the words into the phonemic forms using the CMU Pro-
                                                                     the interpretation that language is optimized for communica-
nouncing Dictionary.6 I used this triphone model to estimate
                                                                     tive efficiency. The shape and direction of the effects reported
the phonotactic probability of each word (Ti ). For each the
                                                                     in Piantadosi et al. (2012), as well as ZLA, are precisely what
length-normalized log trigram probabilities (log Ti /`(wi )) and
                                                                     one would expect to obtain by chance (i.e., by a random as-
the length-normalized log a priori probabilities estimated us-
                                                                     signment of probabilities). Furthermore, if anything, I find
ing the λ (log pi /`(wi )), I fitted a generalized additive model
                                                                     that the effects present in a corpus are actually weaker than
with a linear predictor for log word frequency (estimated for
                                                                     what one would obtain by chance. Following the classical
the corpus or a priori) and penalized spline smoothers terms
                                                                     “Principle of Least Effort” interpretation is therefore not war-
for word length and degree of ambiguity. Fig. 1 plots the es-
                                                                     ranted by this type of correlations.
timated curves. As predicted, the shape and strength of the
non-linear relations is basically the shame for the actual tri-         These findings complement previous studies showing that
phone probabilities (top-panels), as it is for the word prob-        mere random typing processes (e.g., Mandelbrot, 1953;
abilities that would be predicted a priori (bottom panels).          Miller, 1957; Ferrer i Cancho & Moscoso del Prado, 2011)
Once more, the shape of the relation does not warrant the            also exhibit ZLA. More generally, the most likely observa-
interpretation of optimization.                                      tion is that a word’s log probability of occurrence is linearly
   The values of the Laplace multipliers can be used with            related with any property of the word for which a mean value
Eq. 3 to compute what should be the a priori distribution            exists. Therefore, in order to claim that observations of this
of words, considering only their length and degrees of am-           kind are indicative of any type of process (optimization or
biguity. The log relative frequencies predicted by the method        otherwise) giving rise to the word frequency measures are not
exhibit a remarkably strong correlation with the relative log        warranted, unless the effects are explicitly found to be signifi-
frequencies actually observed (r = .45, t[29004] = 86.41, p <        cantly the stronger than the effects one should find by chance.
.0001). This suggest that the frequency distribution of words        In other words, such effects are meaningless unless compared
is not that different from the distribution one would expect to      to random baselines.
find by chance. In other words, it does not appear to reflect           Notice that the same conclusions would be reached if, in-
much specific optimization.                                          stead of unigram word frequencies, I had considered the a
   It could be argued that, by using the actual values of word       priori distribution of word bigrams or trigrams. It would
length and word ambiguity as estimated from the corpus, I            merely be a question of applying the PME to the whole ma-
am covertly exploiting the possible correlations that are al-        trix of n-grams and we would expect to obtain the same type
ready present in their distributions, even before considering        of linear relations between log n-gram frequencies and lexi-
word frequency. To control for this possible confound, I used        cal measures. Thus, similar arguments as those expressed in
a Jackknife technique. New values of word lengths and am-            Piantadosi, Tily, and Gibson (2011), would suffer from ex-
biguity were randomly assigned to each word by randomly              actly the same problems I discussed above.
sampling (with replacement) from the original distributions.            By this I do not intend to claim that language is not op-
In this way, one obtains distributions of word length and am-        timized for human communication. Rather the opposite, I
biguity which are fully uncorrelated, but retain their origi-        am strongly convinced that this is indeed the case. How-
nal distributional shapes. I repeated this process two hundred       ever, pure correlational values between lexical measures (or
times, re-estimating the values of the Laplace multipliers in        for that matter n-gram measures) are not sufficient evidence
each case. Fig. 2 compares the original λ estimates (blue            to support such claims. Of course, there is a certain common-
dots), the distribution of λ values obtained in the resampling       sensical aspect to the claim that human language is optimal
(box and whiskers plots), and the β parameters of the regres-        for communication: It would be difficult to find a cogni-
sions on the actual corpus (red crosses). As it can be seen,         tive scientist who disagrees with such a statement. However,
even after fully decoupling word length and ambiguity, the           claims on optimization of human language should rely on
                                                                     specific mechanisms by which the optimization takes place,
    6 http://www.speech.cs.cmu.edu/cgi-bin/cmudict                   together with explicit mathematical (e.g., variational) de-
                                                                 1036

            Length on log Frequency                  Ambiguity on log Frequency                      Length on Ambiguity
   -0.05
                       x
                                                                                           0.25
                                              1.05
   -0.10                                                                                   0.20
                                              1.00
   -0.15                                      0.95                                         0.15
   -0.20                                      0.90
                                                                                           0.10
   -0.25                                      0.85               x                                            x
                                                                                           0.05
Figure 2: Estimated relations between log word frequency, word length, and degree of ambiguity. The red crosses indicate
the magnitude of the effects observed in the corpora. The blue dots plot the magnitude that we should expect to observe a
priori. The box and whisker plots plot the distribution of the a priori predictions once word length and ambiguity have been
decoupled using Jackknife. The leftmost and middle panels respectively plot the effects of word length and ambiguity of log
word frequency. The rightmost panel plots the direct relation between word length and word ambiguity. Notice the different
vertical scales between the panels.
scriptions of how such an optimization proceeds, as exem-              munication Theory (p. 503512). New York, NY: Academic
plified by some recent studies (e.g., Ferrer i Cancho & Solé,         Press.
2003; Ferrer i Cancho & Dı́az-Guilera, 2007).                        Miller, G. A. (1957). Some effects of intermittent silence.
                                                                       The American Journal of Psychology, 70, 311–314.
                           References                                Miller, G. A. (1995). WordNet: A lexical database for En-
                                                                       glish. Communications of the ACM, 38, 39–41.
Baayen, R. H., Piepenbrock, R., & Gulikers, L. (1995). The           Moscoso del Prado, F. (2007). Co-occurrence and the effect
  CELEX lexical database (CD-ROM). University of Penn-                 of inflectional paradigms. Lingue e Linguaggio, 2, 247–
  sylvania, Philadelphia, PA: Linguistic Data Consortium.              263.
Ferrer i Cancho, R., & Dı́az-Guilera, A. (2007). The global          Moscoso del Prado, F. (2011). Macroscopic thermodynamics
  minima of the communicative energy of natural communi-               of reaction times. Journal of Mathematical Psychology, 55,
  cation systems. Journal of Statistical Mechanics: Theory             302–319.
  and Experiment, 2007, P06009.                                      Oldfield, R. C., & Wingfield, A. (1965). Response laten-
Ferrer i Cancho, R., & Moscoso del Prado, F. (2011). In-               cies in naming objects. Quarterly Journal of Experimental
  formation content versus word length in random typing.               Psychology, 17, 273–281.
  Journal of Statistical Mechanics: Theory and Experiment,           Piantadosi, S. T., Tily, H. J., & Gibson, E. (2011). Word
  2011, L12002.                                                        lengths are optimized for efficient communication. Pro-
Ferrer i Cancho, R., & Solé, R. V. (2003). Least effort and           ceedings of the National Academy of Sciences of the USA,
  the origins of scaling in human language. Proceedings of             108.
  the National Academy of Sciences of the United States of           Piantadosi, S. T., Tily, H. J., & Gibson, E. (2012). The com-
  America, 100, 788 –791.                                              municative function of ambiguity in language. Cognition,
Jaynes, E. T. (1957a). Information theory and statistical me-          122, 280–291.
  chanics. Physical Review, 106, 620–630.                            Shannon, C. E. (1948). A mathematical theory of communi-
Jaynes, E. T. (1957b). Information theory and statistical me-          cation. The Bell System Technical Journal, 27, 379—423,
  chanics II. Physical Review, 108, 171–190.                           623–656.
Jaynes, E. T. (2003). Probability Theory: The Logic of Sci-          Zipf, G. K. (1935). The Psychobiology of Language; an In-
  ence. Cambridge, UK: Cambridge University Press.                     troduction to Dynamic Philology. Boston, MA: Houghton-
Kucera, H., & Francis, W. N. (1967). Computational analysis            Mifflin.
  of present-day American English. Providence, RI: Brown             Zipf, G. K. (1949). Human Behavior and the Principle of
  University Press.                                                    Least Effort. Reading, MA: Addison-Wesley.
Mandelbrot, B. B. (1953). An information theory of the sta-
  tistical structure of language. In W. Jackson (Ed.), Com-
                                                             1037

