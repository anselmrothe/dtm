UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Logical Consistency and Objectivity in Causal Learning
Permalink
https://escholarship.org/uc/item/9dt3m7pp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Cheng, Patricia
Liljeholm, Mimi
Sandhofer, Catherine
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                          Logical Consistency and Objectivity in Causal Learning
                                            Patricia W. Cheng (cheng@lifesci.ucla.edu)
                                                    Department of Psychology, UCLA
                                                 Mimi Liljeholm (mlil@caltech.edu)
                            Computation and Neural Systems Program, California Institute of Technology
                                        Catherine M. Sandhofer (sandof@psych.ucla.edu)
                                                    Department of Psychology, UCLA
                               Abstract                                    observations only. Because causal relations are inferred and
                                                                           inherently unobservable (Hume, 1739), defining invariance
   Logical consistency and objectivity are cornerstones of science
that distinguish it from cult and dogma. Scientists’ concern with          on causal relations seems objectionable.
objectivity has led to the dominance of associative statistics, which         Thus, for the respective purposes of scientific causal
define the basic concept of independence on observations. The              discovery and of justifying the application of causal
same concern with avoiding subjective beliefs has led many                 knowledge, there are two distinct definitions of invariance:
scientific journals to favor frequentist over Bayesian statistics. Our     the associative and the causal. The associative conception
analysis here reveals that to infer causes of a binary outcome, (1)        defined on observable events traces its inspiration to the
the associative definition of independence results in a logical            philosophical works of Hume (1739), who questioned the
inconsistency -- even for data from an ideal experiment -- for both        grounds for our compelling belief that causation exists in
frequentist and Bayesian statistics, and (2) removing the logical
                                                                           the world. The causal conception defined on causal
error requires defining independence on counterfactual causal
events. The logically coherent causal definition is the one                influences rests on Kant’s (1781) argument that an
intuitively adopted by humans. Our findings have direct                    ontological commitment to causation is essential for a
implications for more consistent and generalizable causal                  coherent interpretation of the world. We use “causal
discoveries in medicine and other sciences.                                influence” here in the sense of capacity or power, which
                                                                           when realized explains the occurrence of the outcome.
   Keywords: Causal inference, rationality, cognition, statistics.
                                                                              There is a discrepancy between the two conceptions, but
                          Introduction                                     the discrepancy has not seemed problematic: The unspoken
                                                                           consensus is that while causal invariance justifies
Whenever we humans or other animals apply causal                           generalization, it plays no role in causal discovery.
knowledge to achieve a desired outcome, we implicitly                      Accordingly, using associative statistics to test experimental
assume that the future resembles the past. Without the                     data is standard practice, and is viewed as appropriate as
assumption that the course of nature remains invariant, all                long as the experimental manipulation, which disambiguates
experience becomes useless (Hume, 1739). But what is the                   causal direction, succeeds in eliminating confounding.
course of nature if not change (e.g., seeds sprout, species                   The consensus opinion, however, is mistaken. Here we
evolve, oceans warm, stars implode)? What we assume to                     show that even in the ideal case in which there are no
remain invariant in nature are -- instead of events -- the                 confounding variables, the definition of invariance
forces of change, namely, causation (Kant, 1781; Kitcher,                  incorporated in a measure can affect the statistical output.
1995). The fact that we routinely base actions on our causal               Moreover, with regard to causes of a binary outcome, a type
knowledge (e.g., I strike this match because I expect it to                of outcome prevalent in medical and business research (e.g.,
ignite) is indubitable evidence that we hold the causal                    a tumor cell being malignant or not, a consumer buying an
invariance assumption across the learning and application                  item or not), only the definition based on counterfactual
contexts. The present paper examines a previously                          causal events, the Kantian causal power definition, is
unsuspected role that this assumption should play in                       logically consistent. Notably, the coherent definition is the
scientific causal inference, leading to implications for more              seemingly less objective one.
rational evaluations of hypotheses regarding causes of a                      To explain the inferential problem, we step back and
binary outcome (e.g., a student graduating or not, an                      examine the nature and definitions of causal invariance from
organism being dead or alive).                                             a cognitive-science perspective, in particular, within the
   To test causal hypotheses based on data from experiments                broader issue of how an intelligent agent with access to
or quasi-experiments, the statistics in typical scientific use             inherently limited information can construct a representation
define invariance (often termed “independence” or “no                      of the world that best enables desired outcomes. From this
interaction”) on observations (Fienberg, 1980/2007; Jaynes,                perspective we examine the implications of conceptions of
2003; Wickens, 1989). Objectivity would seem to dictate                    causal invariance for the experimental sciences and
this definition, given that the input necessarily consists of              everyday causal inference.
                                                                       2034

Causal Invariance and its Implications                               leap plays a central role in rational causal discovery, in
   Under the premise that all changes are caused, one way of         particular, why an associative definition of invariance,
stating causal invariance is: a cause c of an effect e retains       omitting this leap, is irrational for causal discovery.
the same capacity to affect e regardless of the temporal or             We classify models as causal or associative depending on
spatial context, in which alternative (often unobserved)             whether or not they have a definition of independence on
causes of e may occur with different probabilities. That is,         causal influences. Whereas the ontological commitment to
the causal power of c is independent of the occurrence of            the existence of causation under the causal view enables this
alternative causes of e, as if those alternative causes were         view to define independence on causal influences (e.g.,
not there. A change in the capacity of a cause to produce its        Cartwright, 1989; Cheng, 1997; Lu, Yuille, Liljeholm,
effect is an indication of the causal mechanism operating            Cheng & Holyoak, 2008; Pearl, 2000; Sheps, 1958; Sloman,
differently. As we show later, this interpretation of causal         2005; Yuille & Lu, 2008), the lack of this a priori
invariance applying the concept of independence (i.e., “no           assumption confines the associative view to defining
interaction”) to causal powers enables logical implications          independence on observations only (e.g., the cross product
of the assumption to emerge, by enabling a mathematical              ratio; Fienberg, 1980/2007; Wickens, 1989). These two
definition of causal invariance (Eq. 4). (Causal invariance is       views differ most clearly for causes and effects that are
the simpler of two conceptions that are equivalent with              represented by binary variables with a “present” value and
respect to our conclusions; the other conception is that             an “absent” value; our argument therefore uses this variable
although c interacts with enabling conditions in the                 type. For this variable type, observable events consist of the
background, the enabling conditions occur just as frequently         values of candidate cause c and of effect e. We denote the
in the learning and application contexts [Cheng, 2000].)             “present” and “absent” values by “1” and “0” respectively.
   The concept of causal invariance serves two distinct
functions. First, as a working hypothesis, a defeasible              The Associative View The associative view defines
default assumption, it justifies causal generalization and           independence on observations of c and e (we use c and e as
prediction. By rendering inference compositional, it enables         variables or values depending on context): if c occurs
the generation of logically consistent answers to an                 independently of e, then
unlimited variety of questions regarding an outcome’s                       P(c =1, e =1) = P(c =1) • P(e =1)            (Eq. 1),
occurrence in an unlimited range of application contexts             where P(c =1, e =1) is the probability of the joint occurrence
(Cheng et al., 2007). Second, as a definition of what it             of c and e. This view computes associations, and leaves
means for the nature of a cause to remain the same (rather           causal inference to a separate and subsequent interpretation
than as a description of a particular causal mechanism),             of the associative output, for example, according to
causal invariance serves as a criterion for hypothesis               scientists’ principles of experimental design or as Hume’s
revision. Thus, if a generalization proves wrong, as would           “habit of mind”. To enable predictions, this view typically
often happen in the dynamic mental construction of our               amends Eq. 1 with additional assumptions, often variations
complex causal world, the deviation from expectation                 of linearity or additivity. This amendment implicitly extends
signals a need to better capture invariance. In this second          the definition of independence; deviation from linearity is
role, causal invariance is a navigation device that orients          what signals the need for interaction terms.
hypothesis testing towards its goal of formulating the                  We illustrate the linear combination of associative
simplest explanation of a phenomenon that allows                     strengths with the ΔP model (Jenkins & Ward, 1965;
invariance to obtain (Carroll & Cheng, 2010).                        Salmon, 1965),
   Consider the alternative, the non-uniformity of nature, as                ΔP = P(e =1 | c =1) − P(e =1 | c =0)        (Eq. 2),
the default. Not only would predictions and applications be          where P(e =1 | c =1) and P(e =1 | c = 0), respectively, denote
impossible, so would hypothesis revision -- given no                 the probability that e occurs given that c occurs and given
expectation, there is no deviation from expectation to guide         that c does not occur. Eq. 1 is a special case of Eq. 2, the
revision towards causal invariance. Thus, the choice is a)           case in which ΔP=0. To tease apart the influence of c from
inapplicable and stagnant causal knowledge or b) risky               all other influences on e, our analysis partitions all direct
causal inference with the potential for effective                    causes of e into c and a, where a represents a composite of
generalization and hypothesis revision. In its two roles, as a       alternative causes of e in the context. When c is absent, the
default and a criterion for revision, causal invariance              occurrence of e is explained by a. Let wc represent the
embodies the conviction that the world is knowable, that             weight (i.e., strength) of the association between c and e, and
one can tease things apart, comprehend them, and mentally            wa represent that between a and e. ΔP has been shown to be
recompose them at will.                                              a maximum-likelihood estimator of wc in the Bayesian
                                                                     framework (Griffiths & Tenenbaum, 2009; Tenenbaum &
Defining Causal Invariance: Hume versus Kant                         Griffiths, 2001).
   Assuming causal invariance requires two leaps of faith.              When there is no confounding (i.e., a occurs just as often
The first is apparent: faith that the future resembles the past.     whether or not c occurs), ΔP estimates wc. Thus, replacing
The second is subtler: faith in the existence of causation, a        ΔP with wc and P(e =1 | c =0) with wa, Eq. 2 can be rewritten
faith Hume (1739) resisted. Here we show why the second              and rearranged to give the linear equation:
                                                                 2035

             P(e =1 | c =1) = wc+ wa           (Eq. 3).                        P(ce, ae) = P(ce) • P(ae)              (Eq. 4).
That is, when multiple causes are present, the occurrence of e     P(ce) is the probability of c causing e; it corresponds to
according to this model is explained by a sum of the               the theoretical probability that e would occur if c is present
associative strengths of the causes. Bayesian structure-           but no other (observed or unobserved, generative or
learning models can likewise adopt the linear definition (Lu       preventive) cause of e were present. The probability is
et al., 2008; Yuille & Lu, 2008; Tenenbaum & Griffiths,            theoretical because it is impossible to know that a context
2001).                                                             has no unobserved causes. Note that P(ce) is not a
   Similarly, generalized linear models (GLMs [Fienberg,           conditional probability involving two random variables, but
2007; McCullagh & Nelder, 1989]), some process models in           instead the probability associated with a single random
psychology (e.g., Rescorla & Wagner, 1972), and prominent          variable. Likewise, P(ae) is the probability of a causing
causal models in epidemiology (Rothman et al., 2008) also          e, and P(ce, ae) is the probability of one of the two
adopt the definition in Eq. 1 amended with variants of             causes, c or a, producing e and the other cause also
linearity. For example, logistic regression, likely the most       producing e if e had not been already produced. (“No
commonly used model for evaluating causal hypotheses in            interaction” between the occurrences of c and e, as defined
medical research and widely used in business research as           in Eq.1, is a special case of the independence of causal
well, amends Eq. 1 with a logistic scale transformation to         powers as defined in Eq. 4 when there is no confounding
better justify the linearity. A feature common across the          and ΔP=0.)
generalizations in GLMs is “the presence in all the models of         Notice that the definition in Eq. 4 centers on conjunctive
a linear predictor based on a linear combination of                causation in an “occlusion” event. The conjunctive causal
explanatory or stimulus variables” (McCullagh & Nelder,            event (e.g., a dead car-accident victim being killed by a
1989, p. xvi).                                                     second car) can never occur (rather than happen to not have
   Now, consider a situation in which representation in terms      occurred). Our “” notation serves as a reminder that the
of observable events alone cannot capture the constancy of a       causal events denoted are nonexistent and theoretical.
causal relation across contexts. When effect e is binary, a           Although none of the events in Eq. 4 is observable, the
factor’s capacity to influence e may have no observable            intervening causal explanation of the data (e.g., when e
manifestations, even when there is no confounding. Suppose         occurred in the presence of c, it occurred because c caused it
c is a cause of e that does not interact with any other cause of   or a caused it) maps observable event frequencies (e.g., how
e. Yet, whenever e is already present (regardless of which         often e occurred when c was present) onto their theoretical
other cause produced it), introducing c will yield no change       causal probabilities [e.g., P(ce OR ae)].             Thus,
in the state of e, indistinguishable from introducing a            P(e=1|c=1) estimates P(ce OR ae). The latter in turn
noncausal factor. For example, suppose someone is already          can be expressed in terms of the constituent events in Eq. 4:
dead (the binary outcome in question) from being hit by a
car. Being hit by another car will show no change in the           P(ce OR ae)= P(ce)+ P(ae)−P(ce, ae) (Eq. 5),
outcome (the person is still dead), despite the sameness of the    where the final term equals the product, P(ce) • P(ae),
forces underlying car accidents (the second car would have         if c and a produce e independently (Eq. 4).
killed the person too). In such occlusion events, unobservable        Under this view, causal interpretation is integral to the
causal capacities lose their mapping onto observable changes.      computation of the numerical output (e.g., Cheng, 1997;
Given the lack of constancy in this mapping, postulating           Griffiths & Tenenbaum, 2009), rather than subsequent to it.
capacities becomes crucial for representing a stable causal        Data analysis incorporates causal invariance.
world; observable changes, as used in associative models, or          The difference between the two views and its implications
even actual causation in an episode, as used in                    for rational scientific causal inference has not received
epidemiological causal models (Rothman, Greenland & Lash,          attention. Like frequentist statistics for the experimental
2008), would be inadequate. Just as objects occluded in the        sciences, causal Bayes nets adopt the separation of statistics
2-d visual input on our retinas are assumed to continue to         and causal inference. The “generic” parameterization most
exist in the world, so should occluded causal capacities.          commonly adopted in causal Bayes nets uses neither the
                                                                   associative nor the causal definition, and the “noisy OR”
The Causal View The causal view builds on Hume’s                   parameterization in Eq. 5 is used for efficiency rather than
insight – that causal knowledge is induced from noncausal          rationality. In a similar vein, Bayesian causal models allow
data – but goes beyond it: Intervening between the                 both the associative and causal definitions (Griffiths &
observable input and the causal output is a causal                 Tenenbaum, 2009; Lu et al., 2008; Yuille & Lu, 2008).
explanation of the data. This explanation, under Kant’s
domain-general a priori causal framework, posits the               The Rationality of the Two Views Is it rational to define
existence of such things as causal relations: theoretical          causal invariance on unobservable, imaginary events, as the
events that yield observed phenomena. We denote “causing”          causal view does? Ceteris paribus, it is objectionable to use
by “” (e.g., “ce” denotes “c causing e”). Once causal            unobservable events. What is at stake, however, is logical
events are assumed to exist, the definition of their               consistency. What it means for the nature of a cause in our
independence analytically follows:                                 physical world to remain invariant across contexts is non-
   if ce is independent of ae, then                              arbitrary. There is only one way for a causal mechanism in
                                                               2036

a coherent world to operate the same way, without change.          wc increases, an increasing amount is subtracted from the
For binary causes and effects that are “present” or “absent,”      linear sum).
Eqs. 4 and 5 specify the only logically consistent definition         Without the a priori postulate that causal relations exist,
of causal invariance (e.g., so that c causes e with indeed the     associative models cannot coherently define independence
same probability in one context as in another). In other           on the missing relations, hence cannot justify the application
words, systematic deviation from independence as specified         of causal knowledge. They cannot, even when ideal
in these equations indicates causal interaction. (Note that        experiments are concerned, because the error is logical.
for other variable types and combinations of variable types,       An Illustration of the Associative and Causal Views
the singular meaning of causal invariance in the world is          Arriving at Opposite Conclusions We return to the
captured by other mathematical functions.)                         mutual-exclusivity definition of causal invariance in
   We first explain the correlated influences inherent in          associative statistics. In a story presented to preschoolers in
associative amendments by illustrating how the linear model        our experiment, two brothers -- a farmer and a zookeeper –
in Eq. 3 deviates from causal invariance. The additivity in        try to figure out what prevents red dots from appearing on
Eq. 3 holds only if the capacities of c and of a to cause e are    the faces of animals at their farm and at zoo. The candidate
mutually exclusive [i.e., P(ce, ae) = 0; there are no            preventive causes of red dots are two treats: a grain and a
occlusion events]. But, to define independence as mutual           type of leaves. At the farm, the brothers gave the grain to
exclusivity (i.e., to define “no correlation” as a negative        all 10 animals there: 9 of them had red dots before eating
correlation) is self-contradictory.                                the grain, and 6 did so afterwards. At the zoo, the brothers
   To see the self-contradiction without the abstraction of        gave both treats -- grain and leaves -- to all 10 animals
causal inference, consider a simple concrete example               there: 4 of them had red dots before eating the two treats,
involving two events regarding a deck of playing cards:            and only one had red dots afterwards. The question is:
drawing a diamond and drawing a face card. (Assume that            which treat is one’s best bet for removing red dots from the
the deck has diamonds and face cards, among other cards.)          faces of farm and zoo animals?
Defining independence between the two events as mutual                Regardless of how “sameness” is defined, the rationale
exclusivity of the events would entail asserting that the          underlying the choice is: Assuming the grain operates “the
chance of drawing a face card is the same for diamonds as          same way” across contexts (i.e., farm and zoo), if the
for other suits if and only if face cards and diamonds are         influence of the intervention (grain at farm vs. both treats at
mutually exclusive: when there are no face cards that are          zoo) remains invariant across contexts, one’s best guess
diamonds. The chance of drawing a face card then would             would be that leaves had no effect – grain alone would
be 0 for diamonds but not for other suits. The mutual-             already explain the outcome. But, if the influence of the
exclusivity definition therefore implies a logical                 intervention varies across contexts, one would attribute the
contradiction: “the chance of drawing a face card is the           difference to leaves.
same across suits only if it is not the same across suits.”           According to the causal view, the grain operating with the
   Our analysis so far may seem irrelevant to current              same causal mechanism across contexts implies that for
frequentist statistics: nonlinear GLMs, which avoid a logical      every animal (all 20), grain has the same causal power to
shortcoming of linear models for analyzing data with binary        remove red dots. We denote the two interventions by
outcome variables, have long replaced linear models for that       “farm_iv” and “zoo_iv” respectively and “red dots on the
purpose (Fienberg, 1980/2007; Wickens, 1989). But, GLMs            face” by “red” in the calculations below. The causal power
in fact do not sidestep the contradiction in other associative     of candidate cause c to prevent effect e, pc, is estimated
models. First, GLMs concur with the ΔP model in adopting           according to (Cheng, 1997):
the mutual-exclusivity definition for special cases involving                  P(e = 1| c = 0) ! P(e = 1| c = 1)
data that have the feature of symmetry. We illustrate this             pc =                                                  (Eq. 6)
                                                                                         P(e = 1| c = 0)
agreement presently with a logistic-regression analysis of
                                                                      Thus,
fictitious data in a story in an experiment designed for
preschool children. Second, GLMs more generally carry the
                                                                                              9 10 ! 6 10
                                                                       p farm _ iv = pgrain =                 =1 3           (Eq. 7)
broader contradiction of defining independence as                                                  9 10
interaction. Because P(e =1|c =1) estimates P(ce OR ae),            Likewise,
Eqs. 3 and 5 can be directly compared. They differ by the                           4 10 !1 10
final (negative) term in Eq. 5 being omitted in Eq. 3. A scale         pzoo _ iv =                =3 4                       (Eq. 8)
                                                                                       4 10
transformation that would avert the contradiction would
                                                                      But, according to causal invariance (Eqs. 4 and 5),
therefore need to result in subtracting the product, wc• wa,
from the right-hand-side of Eq. 3. But this is neither the             pzoo _ iv = pgrain + pleaves ! pgrain " pleaves       (Eq. 9)
intent nor the result of the transformations in GLMs. The             It follows that
logistic function, for example, is symmetric (see s-shaped             3 4 = 1 3+ pleaves !1 3" pleaves                     (Eq. 10)
curve in Figure 1), as is characteristic of associative models.       Therefore, pleaves = 5 8. Because 5/8 is greater than 1/3
In contrast, for every value of wa, subtracting wc• wa from the    (i.e., the leaves treat is a stronger cure than grain), the causal
sum, wc+ wa, yields an asymmetric concave function of wc (as       view prescribes choosing leaves.
                                                               2037

   Associative models, whether Bayesian or frequentist, all                                                                   by enabling a coherent definition of causal invariance in our
reach the opposite conclusion, prescribing grain instead.                                                                     representation. Coherence is essential because there are
The mutual-exclusivity definition implies that the set of                                                                     infinitely many possible representations of the world based
animals with “no red dots” due to grain, 3 out of 10 animals,                                                                 on available observations, only some of which support
has no overlap with the set due to the contextual cause at                                                                    generalization to new contexts. Reasoners use logical
each place: grain should therefore heal 3 animals both at the                                                                 consistency and, more generally, parsimony of the
farm and at the zoo. Because 3 animals indeed had their red                                                                   represented explanations to prune the vast search space and
dots “go away” at each place, leaves must have no effect.                                                                     efficiently converge on truth, if truth exists (Kelly, 2007).
The ΔP model therefore prescribes grain.                                                                                      Causal discovery should therefore require general-purpose
   Logistic regression is a GLM used for predicting the                                                                       Sherlock Holmeses, who make use of coherence to infer
probability of the occurrence of a dichotomous outcome                                                                        how things work.
(e.g., red_dots vs no red_dots) by fitting data to a logistic                                                                                         Discussion
function of a linear combination of input variables (e.g.,                                                                       In summary, noting a simple logical consequence of
grain, leaves, background causes at the farm and at the zoo).                                                                 Kant’s a priori assumption of causation for rational causal
For the farm-and-zoo scenario (see Figure 1), because the                                                                     inference, we have shown that -- contrary to the unspoken
pattern of events is symmetrical around the probability of .5,                                                                consensus among scientists -- the causal invariance
the same reduction in P(red_dots) occurs at the farm and at                                                                   assumption critically affects causal discovery. To evaluate a
the zoo (see vertical dashed lines) at symmetrical segments                                                                   causal relation involving a binary outcome variable that is
of the logistic curve. Therefore, the grain (see heavy                                                                        “present” or “absent”, only invariance defined on causal
horizontal dashed lines) -- which explains the reduction in                                                                   capacities is logically consistent and supports generalization
the probability of animals with red dots at the farm –                                                                        to new contexts. Thus, associative statistics, for which
explains the entire reduction at the zoo as well. That is,                                                                    invariance is only defined on observations, may arrive at a
logistic regression detects no influence at all from leaves,                                                                  fallacious conclusion even when applied to data from a
either by itself or in an interaction, concurring with the ΔP                                                                 perfect experiment.
model. Increasing sample size does not change this                                                                               The potential for the associative and causal views to
conclusion.                                                                                                                   arrive at opposing recommendations has obvious
                                                                                                                              implications. For example, a critical linear-regression
                                                    /),7((,                              /),./$0,
                            1!                                                                                                analysis in the influential Seven Countries Study (Keys,
                                                                                                             5234, !
                                                                                                                              1980), a large longitudinal study on how diet affects
                                                                                                                  !
                                                                                                               "#$%&#!        coronary heart disease and other health outcomes, shows
 f(z)!"#$%&'&()*+,
                                                                                                             '&#(')#*'!!
                                                                                                                              that controlling for saturated fat, consumption of sugar is
                                                                                                             6234,!
                                                                                                                  !
                                                                                                                              unrelated to death (a binary outcome). Medical and public-
                         0.5!
                                                                                                                (+#&!
                                                                                                             '&#(')#*'!!      health dietary advice in the U.S. based on this and other
                      1234,
                          !
                           !                                                                                                  analyses in the study (Keys et al., 1984; Menotti et al.,
                       "#$%&#! ,
                     '&#(')#*'!!,
                                ,
                                                                                                                              2003), using linear models as was common practice, has
                             ,-%.($%,
                      3234,
                       !
                       !
                                                                                                                              created a food industry that produces low-fat but high-sugar
                        (+#&!
                     '&#(')#*'!!                                                                                              foods (e.g., fat-free salad dressings with added sugar to
                                                                           wfarm+wgrain=2.2-1.8= 0.4!                         compensate for taste). More generally, these associative
                            0!
                                 -6!         -4!         -2!          0!            2!          4!          6!                analyses formed the foundation for three decades of dietary
                                                                                    wfarm=2.2 !
                                        wzoo+wgrain+wleaves! wzoo=-0.4!                                                       advice to adhere to a low-fat diet, without special attention
                                        = -0.4-1.8+0 =-2.2!
                                                                 z=2.2 farm -1.8 grain -0.4 zoo +0 leaves                     to sugar intake (as distinct from caloric content). There is
                                                                                     !                                        currently no causal analogue of logistic regression, which
      Figure 1. A schematic explanation of the probability of the                                                             allows predictor variables that are continuous (e.g.,
outcome according to logistic regression: the probability of                                                                  consumption of sugar) as well as discrete. As we have
having red dots at the farm and at the zoo, before and after                                                                  shown for binary outcome variables, coherent causal
the respective interventions in the scenario, as a logistic                                                                   generalization requires a causal framework, and applying
function of the weighted sum of the four predictor variables.                                                                 causal instead of associative statistics to evaluate the
  Preschoolers in our experiment chose leaves, in                                                                             influences of fat and sugar intake could potentially reverse
accordance with the causal view. Recall that the causal view                                                                  estimates of the magnitude of their harm or change their
avoids the incoherence of the associative view by defining                                                                    assessed causal status. The researchers could have found
causal invariance on counterfactual causal events. Note that                                                                  that consumption of sugar causes coronary heart disease,
the causal explanations involve no prior domain-specific                                                                      diabetes, cancer and other diseases constituting the
knowledge; the causal-invariance assumption is domain-                                                                        metabolic syndrome, as recent evidence indeed suggests. A
general and the input consists of data alone. This view                                                                       more rational statistical approach could have profoundly
thereby achieves objectivity without sacrificing coherence.                                                                   altered the course of the obesity epidemic in the U.S. and
  If the world happens to be causal, then a leap of faith to                                                                  worldwide.
assume unobservable causal capacities would be adaptive,
                                                                                                                           2038

  Note that one interpretation of associative models that          Keys A (ed, 1980) Seven countries: a multivariate analysis
would remove the incoherence we noted is to posit a                  of death and coronary heart disease (Harvard,
mediating continuous variable and to assume that the causes          Cambridge).
operate independently on this continuous variable rather           Keys A, Menotti A, Aravanis C, Blackburn H, Djordevic
than on the observed binary outcome variable. The linear             BS, Buzina R, Dontas AS, Fidanza F, Karvonen MJ,
definition of causal invariance holds for continuous                 Kimura N, Mohacek I, Nedeljkovic S, Puddu V, Punsar S,
outcome variables, thereby removing the incoherence.                 Taylor HL, Conti S, Kromhout D & Toshima H (1984)
Regardless of the plausibility of the revised hypothesis with        The Seven Countries Study: 2,289 Deaths in 15 Years,
the mediating variable, note that it is deviation from the           Preventive Medicine, 13: 141-154.
criterion of causal invariance that signals the need to revise     Kitcher P (1995) Revisiting Kant's epistemology:
the simple hypothesis (Carroll & Cheng, 2010), the                   Skepticism, apriority, and psychologism. Noûs, 29: 285-
tenacious goal being to achieve causal invariance.                   315.
                                                                   Lu H, Yuille A, Liljeholm M, Cheng PW, Holyoak, KJ
                   Acknowledgments                                   (2008) Bayesian generic priors for causal learning,
                                                                     Psychological Review, 115: 955-984.
  The research reported in this article was supported by
                                                                   Lustig RH (2012) The toxic truth about sugar. Nature, 482:
AFOSR FA 9550-08-1-0489. We thank Chris Carroll, Tom
                                                                     27-29.
Wickens, and Ying Nian Wu for helpful discussion.
                                                                   McCullagh P, Nelder JA (1989). Generalized linear models
                        References                                   (2nd edition, CRC Press, Boca Raton).
                                                                   Menotti A, Pudd, PE, Lanti M, Kromhout D, Blackburn H
Carroll CD, Cheng PW (2010) The induction of hidden                  & Nissinen A (2003) Twenty-five-year coronary mortality
  causes: Causal mediation and violations of independent             trends in the seven countries study using the accelerated
  causal influence. In Proceedings of the 32nd Annual                failure time model. European Journal of Epidemiology,
  Conference of the Cognitive Science Society, eds Ohlsson           18: 113–122.
  S, Catrambone R (Austin, Texas: Cognitive Science                Pearl J (2000) Causality: Models, reasoning, and inference
  Society), pp. 913-918.                                             (Cambridge Univ Press, Cambridge).
Cartwright N (1989) Nature’s capacities and their                  Rescorla RA, Wagner AR (1972) A theory of Pavlovian
  measurement (Clarendon Press, Oxford).                             conditioning: Variations in the effectiveness of
Cheng PW (1997) From covariation to causation: A causal              reinforcement and nonreinforcement. In Classical
  power theory. Psychological Review, 104: 367-405.                  conditioning II: Current theory and research, eds Black
Cheng PW (2000) Causality in the mind: Estimating                    AH, Prokasy WF (Appleton-Century Crofts, New York),
  contextual and conjunctive causal power. In Explanation            pp. 64-99.
  and Cognition, eds Keil F, Wilson R. (MIT Press,                 Rothman KJ, Greenland S, Lash TL (2008) Modern
  Cambridge), pp. 227-253.                                           epidemiology (3rd edition, Lippincott, Williams &
Cheng PW, Novick LR, Liljeholm M, Ford C (2007)                      Wilkins, Philadelphia).
  Explaining four psychological asymmetries in causal              Salmon WC (1965) The status of prior probabililities in
  reasoning: Implications of causal assumptions for                  statistical explanation. Philosophy of Science, 32:137-146.
  coherence. In Topics in contemporary philosophy, Volume          Sheps MC (1958) Shall we count the living or the dead?
  4: Causation and explanation, ed O’Rourke M (MIT                   The New England Journal of Medicine, 259: 1210-1214.
  Press, Cambridge), pp. 1 – 32.                                   Sloman S (2005) Causal models: How we think about the
Fienberg SE (1980/2007) The analysis of cross-classified             world and its alternatives. (Oxford Univ Press, New
  categorical data (2nd edition (MIT Press, Cambridge;               York).
  Spring, New York).                                               Spirtes P, Glymour C, Scheines R (1993/2000) Causation,
Griffiths TL, Tenenbaum JB (2009) Theory-based causal                prediction and search (2nd edition, MIT Press,
  induction. Psychological Review, 116 (4): 661-716.                 Cambridge).
Hume D (1739/1987) A treatise of human nature (2nd                 Tenenbaum JB, Griffiths TL (2001) Structure learning in
  edition, Clarendon Press, Oxford).                                 human causal induction. In TK Leen, TG Dietterich, & V
Jaynes ET (2003) Probability theory: The logic of science.           Tresp (eds), Advances in neural processing systems, 13:
  (Cambridge Univ Press, Cambridge).                                 59–65 (MIT Press, Cambridge).
Jenkins HM, Ward WC (1965) Judgment of contingency                 Wickens TD (1989) Multiway contingency tables analysis
  between responses and outcomes, Psychological                      for the social sciences (Erlbaum Associates, Hillsdale).
  Monographs: General and Applied, 79 (1, Whole No.                Yuille A, Lu H (2008) The noisy-logical distribution and its
  594).                                                              application to causal inference. In Advances in neural
Kant I (1781/1965) Critique of pure reason, trans Smith NK           processing systems, vol. 20 (MIT Press, Cambridge).
  (Macmillan, London).
Kelly K (2007) Ockham’s razor, empirical complexity, and
  truth-finding efficiency, Theoretical Computer Science,
  383: 270-289.
                                                               2039

