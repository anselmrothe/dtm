UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Watching Gestures during Learning about Movements with Dynamic Visualization Activates
the Human Mirror Neuron System: A fNIRS Study
Permalink
https://escholarship.org/uc/item/52j2v001
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Imhof, Birgit
Ehlis, Ann-Christine
Häußinger, Florian B.
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Watching Gestures during Learning about Movements with Dynamic Visualization
                     Activates the Human Mirror Neuron System: A fNIRS Study
                                              Birgit Imhof (b.imhof@iwm-kmrc.de) a
                             Ann-Christine Ehlis (ann-christine.ehlis@med.uni-tuebingen.de) b
                            Florian B. Häußinger (florian.haeussinger@med.uni-tuebingen.de) b
                                             Peter Gerjets (p.gerjets@iwm-kmrc.de) a
                         a
                           Knowledge Media Research Center, Schleichstrasse 6, 72076 Tuebingen, Germany
   b
     Department of Psychiatry & Psychotherapy, University Hospital Tuebingen, Calwerstr. 14, 72076 Tuebingen, Germany
                              Abstract                                 but also context factors, such as, the knowledge domain,
   This study investigates whether viewing human gestures
                                                                       task requirements, or additional instructional support,
   facilitates learning about non-human biological movements           influence the effectiveness of dynamic visualizations (e.g.,
   and whether correspondence between gesture and to-be-               Höffler & Leutner, 2007; Lowe, Schnotz, & Rasch, 2011;
   learned movement is superior to non-correspondence.                 Tversky, Morrison, & Bétrancourt, 2002). These context
   Functional near-infrared-spectroscopy was used to address           factors have become a focus of research on dynamic
   whether gestures activate the human mirror-neuron-system            visualizations.
   (hMNS) and whether this activation mediates the facilitation
   of learning. During learning participants viewed triples of
   visualizations (animation – gesture video – animation).
                                                                       Learning with Gestures
   Results showed that for low-visuospatial-ability learners           One idea on how to support learning about movements with
   corresponding gestures led to higher cortical activation in the     dynamic visualizations that is based on the embodied
   inferior-frontal cortex (part of the hMNS) and better learning      cognition approach and proposed by De Koning and
   outcomes, whereas for high-visuospatial-ability learners the        Tabbers (2011) is the active and passive use of gesture.
   type of gesture had no influence. Furthermore, results showed
   that – if presented with non-corresponding gestures – only          Empirically, Hegarty et al. (2005) showed that gestures are
   low-visuospatial-ability learners who activated their inferior-     naturally used to express movements of depicted
   parietal cortex (also part of the hMNS), improve their              components and thereby also the depicted processes in
   learning. Thus, activating the hMNS facilitates learning about      mental animation problems. Moreover, it has already been
   movements and stimulating the hMNS via gestures seems to            shown that the production of gestures during learning is
   be an adequate instructional strategy to enhance learning with      beneficial for acquiring knowledge about different scientific
   dynamic visualizations for low-visuospatial-ability learners.
                                                                       topics and spatial problem solving (e.g., Chu & Kita, 2011;
   Keywords:        Learning     about    movements;     dynamic       Cook & Goldin-Meadow, 2006; Scheiter et al., 2012).
   visualizations; human mirror-neuron-system;           gestures;     However, learners can either produce gestures on their own
   functional near-infrared-spectroscopy.                              or they can perceive gestures that are performed by others.
                                                                       In line with the proposal of De Koning and Tabbers (2011),
                Learning about Movements                               it is also beneficial for learning to perceive gestures that
               with Dynamic Visualizations                             illustrate the depicted contents, for instance, performed by
Many contents in the Natural Sciences as well as in other              teachers (e.g., Valenzeno, Alibali, & Klatzky, 2003).
domains, such as different sport disciplines or scene                     Underlying this gesture watching effect might be the
perception, comprise the understanding of changes in space             activation of brain areas (i.e., the human mirror-neuron-
over time. Dynamic visualizations can easily depict such               system [hMNS]; Fogassi & Ferrari, 2011; Rizzolatti &
changes and they may be particularly suited for instructional          Craighero, 2004) that are typically used to observe,
purposes if these changes do not occur in a discrete or linear         understand and imitate the actions of other persons. In a
way, but rather involve more complex continuous aspects                related line of research, a current hypothesis that has
(e.g., acceleration). However, they were not always superior           recently received considerable attention (e.g., Ayres et al.,
to static visualizations to convey dynamic information (e.g.,          2009; Van Gog et al., 2009) is that the stimulation and
Imhof et al., 2012). Thus, it is crucial to understand when            involvement of this hMNS might be beneficial for learning
and for whom dynamic visualizations are beneficial to use              about complex continuous aspects with dynamic
them effectively and to exploit their potential for learning.          visualizations. The hMNS is typically activated by human
Until now, research on the instructional use of dynamic                movements, but may be more generally used to also
visualizations has yielded rather heterogeneous results: Not           represent other biological or even non-biological
only design factors and individual learner characteristics,            movements, if the observer is able to anthropomorphize
                                                                   2608

these movements (cf. De Koning & Tabbers, 2011; Engel et            viewing of these gestures is helpful for learning about
al., 2008). Thus, in the domain of learning about biological        biological movements because learners map the human
movements, one effective instructional strategy to activate         movements to the non-human biological movements.
the hMNS might be to show learners not only the to-be-                 However, maybe solely the circumstance that learners see
learned movements via dynamic visualizations, but also              a human during learning activates the hMNS and is thus
gestures displaying the to-be-learned dynamics in order to          sufficient to facilitate learning about biological motions. In
trigger an anthropomorphized encoding. Hence, only                  other words, it might be also helpful for learners to see
showing gestures that map onto the to-be-learned                    gestures that have nothing to do with the to-be-learned
movements should benefit learning about those movements.            content. Thus, this study investigated whether viewing
   This study addresses whether perceiving gestures in              gestures that correspond to the to-be-learned non-human
addition to dynamic visualizations is also beneficial for           movements facilitate learning about these movements better
learning. Moreover, to investigate the role of the hMNS, the        than unrelated non-corresponding gestures. Additionally, the
underlying cognitive processes during learning were                 moderating role of learners’ visuospatial ability was
investigated with neurophysiological methods in this study          addressed. Furthermore, this study tested whether the
(i.e., functional near-infrared-spectroscopy [fNIRS]). Until        activation of the MNS mediates the facilitation of learning.
now, to the best of our knowledge, there is no direct test of          We hypothesize that viewing corresponding gestures
the assumption that learners’ ability to recruit their hMNS         facilitates learning more than viewing unrelated non-
during processing dynamic visualizations may influence the          corresponding gestures. This might be particularly true for
effectiveness of the visualizations. Moreover, it still has not     low-visuospatial-ability learners, whereas high-visuospatial-
been investigated whether hMNS activation can be induced            ability learners might not need this type of
by gesture-based interventions and then transferred to non-         anthropomorphization to learn about the depicted dynamic
human movements because of mapping processes. This                  processes (cf., ability-as-compensator hypothesis; e.g.,
approach might easily facilitate the understanding of               Höffler, 2010). Moreover, we hypothesize that learners
complex dynamic phenomena by implementing embodied                  differ with regard to recruiting the hMNS for processing and
visualizations that activate specific brain areas into              that higher hMNS activation is associated with better
instructional materials.                                            learning outcomes than lower hMNS activation. This might
                                                                    again be particularly true for low-visuospatial-ability
Learners’ Visuospatial Ability                                      learners, as they do not have available this ability to
Beyond context factors also individual learner                      compensate for such a hMNS actication.
characteristics may play a role during learning about
biological movements. Because processing continuous                                            Methods
changes requires visuospatial ability (cf. Hegarty, 1992), it
is likely that learners’ visuospatial ability will determine        Participants and Design
how much the learners profit from visualizations (cf.               Forty-five university students (M = 24.98 years, SD = 4.57;
Hegarty & Waller, 2005). Often the continuous processes do          31 females) were asked to learn how to classify different
not occur only in two-dimensional but rather in three-              fish according to their movements based on visualizations
dimensional space. Thus not only visual, but also spatial           that illustrated four different movement patterns of fish. For
aspects are important. Previous research on visuospatial            each movement pattern the participants saw three
ability has revealed two important results, namely that (a)         visualizations: Firstly, they saw an animation of the specific
learners with higher visuospatial ability outperform learners       movement pattern. Secondly, they saw a video of a person
with lower visuospatial ability during learning with                performing gestures with his hands and arms. These
visualizations (see Höffler, 2010, for a meta-analysis) and         gestures either did correspond or did not correspond (i.e.,
moreover, there is some evidence, that (b) visuospatial             were unrelated) to the fish movement patterns. Therefore, at
ability may moderate the effectiveness of learning with             this point the experimental manipulation with the between-
different visualization formats. Higher visuospatial ability        subjects factor type of gesture took place. Thirdly, the
may compensate for “poor” instructions (i.e., in our case           learners saw the initial fish animation again.
unrelated non-corresponding gestures, cf. methods section),            An expert regarding fish movements performed the
whereas learners with lower visuospatial ability suffer from        gestures. For the corresponding gestures this expert was
such instructions (cf. ability-as-compensator hypothesis;           instructed to display with his hands and arms
e.g., Hays, 1996; Hegarty & Kriz, 2008; Höffler, 2010).             representations of the respective movements as clearly as
                                                                    possible (see figure 1 left). For the non-corresponding
Research Questions and Hypotheses                                   gestures the expert was instructed to perform gestures with
This study addressed by using neurophysiological methods            his hands and arms that were unrelated to the fish movement
(i.e., functional near-infrared-spectroscopy [fNIRS], which         patterns (i.e., waving, circulating the forearms around each
is a non-intrusive approach to gather data about cortical           other, drumming, and pointing, see figure 1 right).
activation of humans) the research question whether the                Each visualization was depicted for 30 s and was
hMNS is activated during viewing gestures and whether the           followed by pauses of 30 s (black screen) between all
                                                                2609

visualizations. The learners were instructed to relax in these      test comprised 21 dynamic multiple-choice items consisting
pauses. In the pauses, the activations of the brain areas of        of underwater videos of real fish performing one of the four
interest are supposed to decay to the baseline level before         to-be-learned movement patterns. To choose for each item
the next visualization was displayed.                               the kind of movement pattern that was depicted, learners
                                                                    had to identify the body parts relevant for propulsion and
                                                                    their way of moving. Each item was presented 7 s to the
                                                                    participants and immediately afterwards they had 3 s time to
                                                                    choose the correct answer by pressing a corresponding
                                                                    button. The possible answers were indicated as static
                                                                    screenshots from the learning animations of the four
                                                                    movement patterns. Each item was awarded one point for
                                                                    the correct answer (max. 21 points). The test items were
                                                                    presented in blocks of 30 s so that 3 items were grouped
                                                                    together. Pauses of 30 s (black screen) followed each block.
                                                                    Learners’ Visuospatial Ability Learners’ visuospatial
  Figure 1: Learning visualizations in triples: corresponding       ability was assessed with a short version of the paper
    gestures (left) and non-corresponding gestures (right).         folding test (PFT, Ekstrom et al., 1976). This test measures
                                                                    the ability to form representations of “object location,
Materials                                                           movement, spatial relationships, and transformations”
Participants had to learn to discriminate four different            (Blazhenkova & Kozhevnikov, 2009, p. 640) and thus is
patterns of fish movements. These movement patterns differ          well suited to cover the domain of fish movements. The
in terms of the body parts that generate propulsion (i.e., the      short version of the PFT consists of ten multiple-choice
body itself or several fins) and also in the manner of how          items, where participants have to choose the correct answer
these body parts move in the three-dimensional space (i.e.          out of five options. The stimuli are depictions of stepwise
different wave-like or paddle-like movements). The four             folded papers that were punched in the folded state, whereas
different movement patterns were: 1. undulation of the              the answer options depict the punches of various unfolded
body; 2. undulation of the dorsal and anal fins; 3. oscillation     papers with the punches being either in the correct or
of the dorsal and anal fins (and undulation of the pectoral         incorrect positions. A maximum of three minutes is
fins); and 4. oscillation of the pectoral fins. One major           assigned to work on the items, and each correct answer is
challenge in identifying these movement patterns is that fish       worth one point (max. 10 points).
may deploy other movements in addition (e.g., to navigate),
that can easily be confused with movements used for                 Cortical Activation During viewing the gestures in the
propulsion in another movement pattern.                             learning phase, cortical activation was conducted via fNIRS
   Animations were rendered based on typical fish                   measurements with an ETG-4000 (Hitachi). As probe set we
performing the four movement patterns. These animations             used a 2x22 channel array, that was placed over the fronto-
were standardized in terms of the perspective, background,          temporo-parietal regions centered at the T3-T4 and C3-C4
position in the frame, and the swimming direction of the            positions (not exactly terminating on these positions
fish. Moreover, in these deliberately designed visualizations,      because of the fixed interoptode distances) according to the
we were able to only show the movements performed for               standard locations of the 10-20 system. Changes of
propulsion and omit other irrelevant movements. Beside              absorbed near-infrared light were transformed into relative
that, the depicted movements were highly realistic, thus            concentration changes of oxygenated (O2Hb) and
representing the movements of real fish adequately. The             deoxygenated haemoglobin (HHb). Local increases of O2Hb
movement cycles of the movement patterns were presented             as well as decreases of HHb are indicators of cortical
in loops in the animations (30 s per movement pattern, 25           activity (Obrig & Villringer, 2003).
fps, size: 640 x 480 pixels) in the center of the screen.
   For each movement pattern, videos of an expert regarding         Procedure
to fish movements were recorded who performed either a              Participants were tested individually. They first received a
corresponding or a non-corresponding gesture. These                 printed overview in which they were informed about the
gestures were presented in the respective conditions in loops       procedure on the different parts of the study. Subsequently,
in the videos (30 s per movement pattern, 25 frames per s,          they had to answer the PFT and a demographic
size: 640 x 480 pixels) in the center of the screen. The            questionnaire. Subsequently, the fNIRS probe set was
presentation of all visualizations was system-controlled.           placed on the scalp of the participants and adjusted with the
                                                                    help of the experimenter. Then, the learning phase started
Measures                                                            and the computer-based learning materials were presented.
Learning Outcomes To assess learning outcomes, a                    For each of the four to-be-learned movement patterns
movement pattern classification test was administered. This         learners were presented with the triples of visualizations
                                                                2610

(fish animation – gesture video – fish animation). In the          gestures were better for learning than non-corresponding
learning phase the experimental manipulation took place.           gestures (p = .04). Thus, the corresponding gestures are
Learners saw either the corresponding or the non-                  beneficial for low-visuospatial-ability learners.
corresponding gestures. Following the learning phase (12
min) learners performed a filler task (8 min), in which they       Cortical Activation
listened to music. Subsequently, learners completed the            To analyze the cortical activation we defined two regions of
movement classification test (8 min). To answer the test           interest (ROIs) on the left hemisphere for the hMNS among
items participants were instructed to put both their               the respective channels. The two ROIs were the left inferior-
forefingers and both their middle fingers on predefined            frontal cortex (IFC) and the left inferior-parietal cortex
keys. These keys were labeled with screenshots from the            (IPC, cf. figure 3). To analyze cortical activation we
corresponding fish animations on the screen. In total, a           conducted two multiple regression analyses with the
single experimental session lasted approx. 50 minutes.             predictors type of gesture and learners’ visuospatial ability.
                                                                   We had to exclude additional eight participants from these
                           Results                                 analyses because the data quality of these participants was
                                                                   too poor resulting in a total number of 33 participants in
Learning Outcomes                                                  these analyses. For cortical activation on IPC the predictors
To analyze learning outcomes we conducted a multiple               in the regression analysis did not explain a significant
regression analysis with the categorical predictor type of         portion of variance (p = .96, ns).
gesture and the continuous predictor learners’ visuospatial
ability. We had to exclude four participants because of
technical reasons (data loss) resulting in a total number of
41 participants in this analysis. Further, we had to exclude
eight test items from the learning outcome measure, because
participants answered them with a response rate of more
than 95 %. The reliability analysis of the remaining 13 test             Figure 3. Spatial arrangement of the left probeset.
items achieved a good to excellent cronbach’s α of .85.
   For learning outcomes the predictors in the regression          For cortical activation on IFC the predictors in the
analysis explained a significant portion of variance (p =          regression analysis explained a significant portion of
.01). Results showed no effect of type of gesture on learning      variance (p < .001). Results showed an effect of type of
outcomes (p = .41, ns), whereas there was an effect for            gesture on IFC activation (p < .001) and an effect for
learners’ visuospatial ability on learning outcomes (p = .04).     learners’ visuospatial ability on IFC activation (p < .001).
This effect has to be interpreted in terms of the significant      These effects have to be interpreted in terms of the
interaction between type of gesture and learners’                  significant interaction between type of gesture and learners’
visuospatial ability on learning outcomes (p = .04; figure 2).     visuospatial ability on IFC activation (p < .01; see figure 4).
                                                                         Figure 4. Effects of type of gesture (G) and learners’
  Figure 2. Interaction between learners’ visuospatial ability       visuospatial activities (VSA) on cortical activation (left).
          and type of gesture on learning outcomes.
                                                                   Again a simple slopes analysis was conducted (cf. Aiken &
This interaction was resolved by a simple slopes analysis          West, 1991). It revealed that for participants with high
(cf. Aiken & West, 1991). It revealed that for participants        visuospatial ability (defined as one standard deviation above
with high visuospatial ability (defined as one standard            the sample mean) the type of gesture had no influence on
deviation above the sample mean) the type of gesture had no        IFC activation (p = .14, ns). For participants with low
influence on learning outcomes (p = .34, ns). As expected,         visuospatial ability (defined as one standard deviation below
for participants with low visuospatial ability (defined as one     the sample mean) corresponding gestures resulted in a
standard deviation below the sample mean) corresponding            higher IFC activation than non-corresponding gestures (p <
                                                               2611

.001). Thus, the corresponding gestures helped low-                  predicted learning outcomes (p = .001). Thus, for learners
visuospatial-ability learners to activate the hMNS in terms          who saw non-corresponding gestures, but have had high
of IFC activation.                                                   visuospatial abilities at their disposal IPC activation is
                                                                     detrimental for learning. However, for learners who did
Effects of Cortical Activation                                       neither have corresponding gestures nor high visuospatial
on Learning Outcomes                                                 abilities at their disposal, activation of their hMNS in terms
Finally, to address the question whether higher hMNS                 of the IPC during processing the unrelated non-
activation is directly associated with better learning               corresponding gesture improves their learning.
outcomes, we conducted two multiple regression analyses
with the three predictors type of gesture, learners’                                           Discussion
visuospatial ability and cortical activation in terms of IFC         This study tested whether viewing gestures performed by
activation or IPC activation respectively.                           others is helpful for learning about non-human movements
   For learning outcomes the predictors in the regression            and whether these gestures stimulate anthropomorphization
analysis with IFC activation did not explain a significant           via an activation of the hMNS. The anthropomorphization is
portion of variance (p = .12, ns). Interestingly, the predictors     stimulated by an external video and is not accomplished by
in the regression analysis with IPC activation did explain a         the learners on their own. Our results showed that viewing
significant portion of variance for learning outcomes (p <           corresponding gestures activated the hMNS particularly for
.01). There was a three-way interaction between the                  low-visuospatial-ability learners. These learners achieved
predictors type of gesture, learners’ visuospatial ability, and      the same learning outcomes as high-visuospatial-ability
IPC activation on learning outcomes (p = .03; see figure 5).         learners. Low-visuospatial-ability learners seem to profit
                                                                     from being demonstrated a connection between non-human
                                                                     biological movements and movements of the human body
                                                                     that correspond to these movements. Thus, learning about
                                                                     biological movements can be facilitated by gesture-based
                                                                     interventions activating parts of the hMNS: Gestures that
                                                                     correspond to the to-be-learned movements and activate the
                                                                     inferior-frontal cortex (IFC). This activation seems to
                                                                     compensate missing viusospatial ability.
                                                                        Furthermore, our results indicate another way of
                                                                     improving learning about biological movements: When
                                                                     looking at participants who neither have high visuospatial
                                                                     ability, nor received the benefit of viewing corresponding
                                                                     gestures, – namely, the group of low-visuospatial-ability
   Figure 5. Three-way interaction between type of gesture,          learners who processed non-corresponding gestures – the
 learners’ visuospatial ability, and IPC activation on learning      result pattern was rather heterogeneous: Only participants
                           outcomes.                                 who activated another part of the hMNS (i.e., the inferior-
                                                                     parietal cortex [IPC]) were able to dramatically improve
This triple interaction was resolved by simple slopes                their learning, whereas participants who did not activate this
analyses (cf. Aiken & West, 1991). Firstly, this approach            area achieved only poor results. This indicates that the
revealed that for learners who saw corresponding gestures            activation of the inferior-parietal cortex helps participants to
there was no two-way interaction between participants’               learn about biological movements, particularly if they have
visuospatial ability and IPC activation (p = .59, ns). The           no access to other facilitating factors. In line with this
following simple slopes analyses revealed that IPC                   reasoning, learners who have available two facilitating
activation did not predict learning outcomes for learners            factors, namely high visuo-spatial abilities and an activation
who saw corresponding gestures: neither for high-                    of the IPC, performed worse when they saw non-
visuospatial-ability learners (p = .47, ns), nor for low-            corresponding gestures. In this case, the two facilitators
visuospatial-ability learners (p = .40, ns). However, for            might compete and interfere with each other resulting in
learners who saw non-corresponding gestures there was an             inferior learning outcomes. Nevertheless, higher hMNS
interaction between participants’ visuospatial ability and           activation is associated with better learning outcomes – at
IPC activation (p < .01). We further resolved this two-way           least for low-visuospatial-ability learners: for IFC activation
interaction between participants’ visuospatial ability and           it seems that there is a rather stepwise connection in that a
IPC activation for learners who saw non-corresponding                certain value has to be reached, whereas for IPC activation it
gestures. The simple slopes analyses revealed that in the            seems that it follows the more activation the better learning.
group of learners who saw non-corresponding gestures IPC                Stimulating the hMNS by means of gestures seems to be a
activation negatively predicted learning outcomes for high-          promising strategy to enhance learning with dynamic
visuospatial-ability learners (p = .04), whereas for low-            visualizations for low-visuospatial-ability learners because
visuospatial-ability learners IPC activation positively              this intervention leads to higher activation in their IFC as
                                                                 2612

part of the hMNS. However, further research needs to                 Fogassi, L., & Ferrari, P.F. (2011). Mirror systems. Wiley
replicate these findings with a larger sample size and                 Interdisciplinary Reviews: Cognitive Science, 2, 22-38.
continue to disentangle the effects of this study. Particularly,     Hegarty, M. (1992). Mental animation: Inferring motion
our findings have to be replicated with other examples of              from static diagrams of mechanical systems. Journal of
gestures in different domains, as gestures about fish                  Experimental Psychology: Learning, Memory and
movements might not be a typical example of gestures.                  Cognition, 18, 1084-1102.
Furthermore, it is very important to investigate how the             Hegarty, M., & Kriz, S. (2008). Effects of knowledge and
activation of the IPC can also be fostered by instructions.            spatial ability on learning from animation. In R. Lowe &
   Furthermore, gesture-based instructions that support                W. Schnotz (Eds.), Learning with animation: Research
anthropomorphization should be investigated in different               implications for design. Cambridge, England: Cambridge
instructional domains and settings that involve learning               University Press.
about continuous movements and processes to prove                    Hegarty, M., Mayer, S., Kriz, S., & Keehner, M. (2005).
whether they are in general a suitable method to enhance               The role of gestures in mental animation. Spatial
learning about processes with dynamic visualizations.                  Cognition and Computation, 5, 333-356.
   Further research should also investigate whether effective        Hegarty, M., & Waller, D. (2005). Individual differences in
and less effective dynamic visualizations differ in their              spatial ability. In P. Shah, & A. Miyake (Eds.), Handbook
ability to activate the MNS, thereby potentially explaining            of Visuospatial Thinking. Cambridge University Press.
inconsistent results on the effectiveness of dynamic                 Höffler, T.N. (2010). Spatial ability: Its influence on
visualizations (e.g., Höffler & Leutner, 2007; Tversky et al.,         learning with visualizations—a meta-analytic review.
2002). The present study is one first step into this field of          Educational Psychological Review, 22, 245-269.
research and our results suggest that it is important to not         Höffler, T.N., & Leutner, D. (2007). Instructional animation
only put further effort into designing better dynamic                  versus static pictures: A meta-analysis. Learning and
visualizations, but also in providing learners with suitable           Instruction, 17, 722-738.
strategies to adequately process these visualizations.               Imhof, B., Scheiter, K., Edelmann, J., & Gerjets, P. (2012).
                                                                       How temporal and spatial aspects of presenting
                         References                                    visualizations affect learning about locomotion
Aiken, L.S., & West, S.G. (1991). Multiple regression:                 patterns. Learning and Instruction, 22, 193-205.
   Testing and interpreting interactions. Newbury Park:              Lowe, R.K., Schnotz, W., & Rasch, T. (2010). Aligning
   Sage.                                                               affordances of graphics with learning task requirements.
Ayres, P., Marcus, N., Chan, C. & Qian, N. (2009).                     Applied Cognitive Psychology, 25, 452–459.
   Learning hand manipulative tasks: When instructional              Obrig, H., & Villringer, A. (2003). Beyond the visible –
   animations     are    superior    to    equivalent     static       Imaging the human brain with light. Journal of Cerebral
   representations. Computers in Human Behavior, 25, 348-              Blood Flow & Metabolism, 23, 1-18.
   353.                                                              Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron
Blazhenkova, O. & Kozhevnikov, M. (2009). The new                      system. Annual Review of Neuroscience, 27, 169–192.
   object-spatial-verbal cognitive style model: Theory and           Scheiter, K., Arndt, J., Imhof, B., & Ainsworth, S. (2012).
   measurement. Applied Cognitive Psychology, 23, 638-                 Move like a fish: Do gestures aid learning from
   663.                                                                photographs and videos? In E. de Vries, & K. Scheiter
Chu, M., & Kita, S. (2011).The Nature of Gestures’                     (Eds.), Proceedings EARLI Special Interest Group Text
   Beneficial Role in Spatial Problem Solving. Journal of              and Graphics: Staging knowledge and experience: How
   Experimental Psychology: General, 140, 102-116.                     to take advantage of representational technologies in
Cook, S.M., & Goldin-Meadow, S. (2006). The role of                    education and training? Grenoble, France: Université
   gesture in learning: Do children use their hands to change          Pierre-Mendès-France.
   their minds? Journal of Cognition and Development, 7,             Tversky, B., Morrison, J., & Bétrancourt, M. (2002).
   211 - 232.                                                          Animation: Can it facilitate? International Journal of
De Koning, B.B., & Tabbers, H.K. (2011). Facilitating                  Human-Computer Studies, 57, 247-262.
   understanding of movements in dynamic visualizations:             Valenzeno, L., Alibali, M.W., & Klatzky, R. (2003).
   An embodied perspective. Educational Psychology                     Teachers’ gestures facilitate students’ learning: A lesson
   Review, 23, 501-521.                                                in symmetry. Contemporary Educational Psychology, 28,
Engel, A., Burke, M., Fiehler, K., Bien, S., & Rösler, F.              187–204.
   (2008). What activates the human mirror neuron system             Van Gog, T., Paas, F., Marcus, N., Ayres, P., & Sweller, J.
   during observation of artificial movements: bottom-up               (2009). The mirror-neuron system and observational
   visual      features      or     top-down        intentions?        learning: Implications for the effectiveness of dynamic
   Neuropsychologia, 46, 2033-2042.                                    visualizations. Educational Psychology Review, 21, 21-
Ekstrom, R., French, J., Harman, H., & Dermen, D. (1976).              30.
   Manual for Kit of Factor-Referenced Cognitive Tests.
   Princeton: Educational Testing Service.
                                                                 2613

