UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Perceiving sounds: analytic and synthetic listening, global-local processing and possible
links with empathy and self-construal

Permalink
https://escholarship.org/uc/item/1x40r10v

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Tsoumani, Olga
Postma-Nilsenova, Marie

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Perceiving sounds: analytic and synthetic listening, global-local processing and
possible links with empathy and self-construal
Olga Tsoumani (olga.tsoumani@kuleuven.be)
Department of Marketing and Organisation
KU Leuven, Bus 3545, 3000 Leuven, Belgium

Marie Postma-Nilsenová (m.nilsenova@tilburguniversity.edu)
Department of Communication and Information Sciences,
Tilburg University, P.O. Box 9013, 5000 LE Tilburg, The Netherlands
Abstract
In two experiments we examined the effects of training on
auditory perception bias (Experiment 1), the relationship
between auditory perception bias and global-local processing
(Experiment 2), as well as the relationship between globallocal auditory processing, empathy and self-construal
(Experiment 2). The present findings are discussed in relation
to their implications for research in auditory perception and
the perception of others’ emotional states.

Introduction
“C'est quoi, le pitch?” used to be the favorite question of the
famous French TV talk show host, Thierry Ardisson, when
he was interviewing writers, film makers and politicians
alike. Knowing what the pitch is may not just be important
on French television but plays an important role in our
development of linguistic abilities as well. Starting in early
infancy, our early auditory ability to process pitch and detect
pitch contour deviations appears to be tightly linked to our
ability to extract linguistic rules (Mueller, Friederici, &
Männel, 2012). Pitch pattern perception has been shown to
be an important predictor of reading performance both in
skilled readers and children with developmental dyslexia
(Foxton et al., 2003; Ziegler et al., 2012) and to play a role
in L2 acquisition (Wong & Perrachione, 2007). However,
pitch processing and production play an important social
role in two ways: First, pitch modulation is a carrier of
information about speakers' emotions and attitudes (Scherer
et al., 1991; Juslin & Laukka, 2003). Second, pitch imitation
is exploited in promoting social convergence and status
accommodation (Gregory, 1983; Gregory & Hoyt, 1982;
Gregory, Webster, & Huang, 1993; Gregory & Webster,
1996; Gregory, Dagan, & Webster, 1997; Gregory &
Gallagher, 2002) and expressing ingroup-outgroup bias
(Babel, 2009). In sum, an early assessment and training of a
listener's ability to process rapid pitch changes in the speech
signal could contribute to the development of tools for
diagnosis and remediation of different types of language and
communication disorders.
What makes pitch detection difficult? Pitch is, roughly, the
perceptual correlate of fundamental frequency, produced
primarily by the vibrations of vocal chords. It is both the
most prominent and most elusive component of the complex
sound produced by human articulators because its

perception is influenced both at the level of primary
auditory mechanisms in the ear (which, mainly due to the
nonlinearities in the cochlea, may supply input in the
fundamental frequency region; Moore, 2003) and at the
level of neural processing in the auditory cortex (Schneider
et al., 2005). Interestingly, the way complex sounds are
perceived seems to differ systematically between
individuals: Some listeners – known as f0 or
synthetic/holistic listeners - focus primarily on the region
between 50-500 Hz, the region where the fundamental
frequency can be found. Others – known as spectral/analytic
listeners - rely on analyzing the harmonic constituents of the
sound and focus on the spectrum “as a whole” (e.g. von
Helmholtz, 1885). A neurological basis has been suggested
for this difference, according to which there is a leftward vs.
rightward asymmetry of the lateral Heschl’s gyrus for
synthetic and analytics listeners, respectively (e.g. Schneider
et al., 2005). The auditory perception bias has been almost
exclusively analyzed in the context of musical training, but
the results of individual studies indicate that it may also
affect linguistic performance (Wong & Perrachione, 2007;
Wong et al., 2008), as well as pitch imitation (PostmaNilsenová & Postma, 2012).
Most of the research on the synthetic and analytic listener
types suggests that their auditory perception bias is a stable
individual difference, possibly caused by genetic factors
(Dediu & Ladd, 2007; Wong, Chandrasekaran, & Zheng,
2012). However, musical competence and training can
affect the listening mode and lead to a shift from spectral to
fundamental listening (Seither-Preisler et al., 2007). Also,
repeated exposure to stimuli with a missing fundamental
frequency over the course of several months appears to
facilitate the synthetic listening mode and thus, presumably,
to improve pitch perception (Seither-Preisler et al., 2007;
Postma-Nilsenová & Postma, 2012).
In the first part of our study, we explore the possible
effect of training on auditory perception bias. More
specifically, we aim to find out whether training subjects
into perceiving changes in pitch direction according to
changes in fundamental frequency or changes in the
spectrum can affect their subsequent listening mode. In the
second part of the study, we explore the link between the
auditory perception bias and listeners' sensitivity to local

3587

and global pitch changes, roughly mirroring local and global
perception in the visual domain (Ziegler et al., 2012).
Simply put, global processing refers to the perception of a
stimulus as a whole, whereas local processing corresponds
to the perception of its parts. With respect to auditory
stimuli, global processing corresponds to the perception of
the pitch direction or contour, while local processing stands
for the perception of the intervals between the notes
comprising a sound (Bouvet et al, 2011; Justus & List, 2005;
Sanders & Poeppel, 2007). Research in the visual domain
has provided some support for stronger right hemisphere
activation during global processing and stronger left
hemisphere activation during local processing (e.g. Fink et
al, 1996). So far, the link between auditory local and global
processing and the auditory perception bias has not been
explored experimentally.

Global vs. Local Precedence and its Correlates
In the visual domain, processing at the global level usually
takes precedence over processing at the local level, a
tendency described as the Global Precedence Effect (GPE)
(Navon, 1977). A similar pattern has been demonstrated in
the auditory domain as well (Bouvet et al., 2011; List,
Justus, Robertson & Bentin, 2007). Contrary to this general
effect, processing at the local level can also precede global
processing when stimuli features are altered (e.g. Kimchi,
1992), or, even more importantly, in case of developmental
differences. For instance, in the auditory domain, children
with developmental dyslexia show a stronger tendency for
local auditory processing (Ziegler, Pech-Georgel, George, &
Foxton, 2011); in the visual domain, individuals diagnosed
with Autistic Spectrum Disorders, such as autistic children
(Jollife & Baron-Cohen, 2006) and women diagnosed with
Anorexia Nervosa (Southgate et al, 2008) show a local
processing bias as well. In the case of autism, Baron-Cohen
(2002) describes the tendency for local processing as
systemizing and differentiates it from empathizing, which
reflects the ability to share others’ mental and emotional
states. Autistic children perform poorly in tasks requiring
Theory of Mind (ToM) and show empathic deficits from a
very early age (Baron-Cohen, 1995; Yirmiya, Sigman,
Kasari, & Mundy, 1997, a.o.). Impaired ToM is also itself
associated with low empathy scores (Shamay-Tsoory et al.,
2005). The above findings indicate that the presence of a
local processing bias is, in autism at least, accompanied by
the presence of impaired empathy. A more direct
examination of the link between global-local visual
processing and empathy in normal subjects has shown, on
the contrary, a link between local processing and greater
empathy (Woltin, Corneille, Yzerbyt, & Förster, 2011). This
last finding was attributed to the facilitating role that local
processing plays in self-other awareness, a prerequisite for
the experience of empathy (Decety & Jackson, 2004).
In the present research, we also aim to examine the
relationship between empathy and global-local auditory
processing. In the auditory domain, personal distress, an
affective component of empathy, has been associated with

the ability to perceive prosody (Aziz-Zadeh, Sheng, &
Gheytanchi, 2010). Prosody perception is impaired in
children diagnosed with the Asperger syndrome (Korpilahti
et al., 2007). Furthermore, autistic children have difficulties
in inferring mental states from the other’s voice (Rutherford,
Baron-Cohen, & Wheelwright, 2002). If we take into
account the processing preferences of autistic individuals,
impaired prosody perception and decreased empathy seem
to accompany the local processing bias. Considering that
similar processing types are exhibited across modalities, we
might expect a local processing preference to be
accompanied by impaired prosody perception and empathy
in the auditory domain as well.
To strengthen the proposed relationship between globallocal processing and empathy, we will also examine the role
of self-construal (Markus & Kitiyama, 1991).
Interdependent self-construal has been associated with
global processing, whereas independent self-construal with
local processing (Kühnen & Oyserman, 2002; Lin et al,
2008, 2009). Moreover, interdependent self-construal is
related to higher empathy (Cross et al., 2000). In addition to
these two types of self-construal, we are also considering
the relational-interdependent self-construal, a type of
interdependence found in rather individualistic cultures
(Cross et al., 2000). According to the above, we expect
interdependent and relational-interdependent self-construal
to be positively related to global auditory processing and
empathy, while independent self-construal to be negatively
related.

Current Study
Experiment 1
Participants
Sixty-eight students (15 males and 54 females) from Tilburg
University were recruited for an experimental session in
exchange for course credit. Participants’ age ranged from 17
to 27 years old (mean = 22.2, ± 2.6). One participant
reported non-normal hearing ability; the participant was not
excluded from the analyses given that (s)he performed
similarly to the rest of the participant group. The
participants were randomly divided into the three betweenparticipant experimental conditions.
Stimuli and procedure
A total of 72 pairs of complex harmonic tones consisting of
two, three or four harmonics were constructed for the pitch
discrimination task, following the procedure described in
Laguitton et al. (1998), including the addition of noise in
order to minimize the effects of combination tones (which
arise at the cochlear level and may interfere with the
measurements of individual differences on the neural level).
Thirty-six tone pairs were ambiguous, meaning that the
second tone sequence would be judged as higher vs. lower
than the first one depending on the participant’s listening
mode. For 18 ambiguous tone pairs, the second sequence
would be judged as lower-higher based on a fundamental

3588

frequency listening mode. For the rest of 18 tone pairs, the
second sequence would be judged as higher-lower based on
a spectral listening mode. The remaining 36 tone pairs were
unambiguous and were used as control stimuli. Each tone
pair was 2000 ms long. All stimuli were displayed using EPrime (Psychology Software Tools, Inc., www.pstnet.com).
Training phase: During the training phase, participants
were presented with 36 ambiguous tone pairs. They were
instructed to listen to the tone pair and were asked to
indicate whether they perceived the tone pair as rising or
falling. After each response, they were provided with
feedback about the tonal progression, aiming to train their
listening mode. In the fundamental frequency mode
condition, participants were told that the tone pair was rising
(falling) according to rises (falls) of the fundamental
frequency. In the spectral listening mode condition, the
feedback depended on rises (falls) of the spectrum. In a
control condition, no feedback was provided. The response
key order was counterbalanced between the participants.
Testing phase: During the testing phase, participants were
presented with 18 ambiguous and 18 non-ambiguous tone
pairs. Similarly to the training phase task, they were
instructed to indicate whether they perceived the tone pair as
rising or falling, they were not provided with feedback
about the tonal progression.

Results
A one-way analysis of variance showed no effect of training
on the Coefficient of Sound Perception Preference in the
testing phase. The participants in the fundamental frequency
mode condition, the spectral mode condition and the control
condition also did not differ with respect to their mean
reaction times and correct responses to the non-ambiguous
stimuli. The distribution of the ∂p values across the three
conditions is shown in Figure 1.
Discussion
The results of the first experiment indicate that simple
feedback is not sufficient to train participants in such a way
that they focus either on the fundamental frequency in the
signal or on its harmonic components. The results confirm
the findings of Ladd et al. (2013) and others who found that
auditory perception bias is robust in test-retest. Contrary to
their study, we found a relatively normal distribution of
listener types in our experimental group, compared to the
prevalence of holistic (fundamental) listeners in their
experiment. The difference is most likely due to the use of
masking noise in our stimulus material which helped to
exclude effects of combination tones (Plomp, 1976).

Experiment 2

Measurements
Based on the participants' answers, we calculated their
individual ‘Coefficient of Sound Perception Preference’ (∂p)
using the formula ∂p = (F-Sp)/(F+Sp), where F is the
number of virtual fundamental classifications and Sp the
number of spectral classifications in the testing phase. We
calculated the ‘Listener Attention Coefficient’ (∂A) as the
proportion of correctly categorized unambiguous stimuli.

Figure 1: Distribution of the Coefficient of Sound
Perception Preference across the three experimental
conditions.

Participants
Forty-nine students (7 males and 42 females) from Tilburg
University, drawn from the same participant group as in
Experiment 1, were recruited for an experimental session in
exchange for course credit. Participants’ age ranged from 18
to 27 years old (mean = 22.5, ± 1.8).
Stimuli and procedure
Auditory global-local processing task
To measure global-local auditory processing, a total of 96
pairs of 4-tone sequences (48 same and 48 different) stimuli
were used. The stimuli were constructed following the
procedure suggested by Ziegler, Pech-Georgel, George, &
Foxton (2011). The sequences contained pure tones, each of
250 ms duration with 20 ms gating windows, with
frequencies from an atonal scale taken from a division of an
octave into seven equally spaced logarithmic steps. The
starting frequencies were taken from the interval between
250 to 354 Hz. The third or fourth note in the second
sequence was altered so that it was two steps lower or
higher than the note in the first sequence (see Figure 2). In
the local stimuli, the second sequence would remain
rising/falling, in the global stimuli, the global melody would
change. Each tone pair was 1000 ms in duration. All stimuli
were displayed using E-Prime (Psychology Software Tools,
Inc., www.pstnet.com) in a random order.
Auditory affective processing task
To measure participants’ performance in auditory affective
processing, we used the Montreal Affective Voices stimuli
(Belin, Fillion-Bilodeau, & Gosselin, 2008). The corpus
includes 90 vocal affect bursts (expressed as the vowel /a/),

3589

which express the emotions of anger, disgust, fear,
happiness, pain, pleasure, sadness, surprise and a neutral
expression. Participants heard each vocal expression once
and were asked to select one of the above emotions.

construal, we constructed three subscales: relational selfconstrual (Cronbach's alpha (11) = .76), interdependent selfconstrual (Cronbach's alpha (12) = .47) and independent
self-construal (Cronbach's alpha (12) = .73).
Table 1: Nonparametric Spearman's correlations for
measures collected in Experiment 1 and 2.

Note: * p < .05, ** p < .001
d'G = Global pitch processing (d'), d'L = Local pitch
processing (d') , ∂p = Coefficient of Sound Perception
Preference, ∂A = Listener Attention Coefficient, Aff =
Affective Voices, Emp = Empathy Measurement, SC = Self-

Figure 2: Illustration of the local and global
types of stimuli used in Experiment 2
(from Ziegler et al. (2011)).

Construal.

Empathy measurement
To measure empathy, we used the Interpersonal Reactivity
Index, developed by Davis (1980). It measures individual
differences in empathy and consists of four dimensions
(perspective taking, fantasy scale, empathic concern and
personal distress) each one tapping a different aspect of
empathy. Participants were asked to indicate, on a five-point
scale, to what extent each statement described themselves.

Results
The Shapiro-Wilk test of normality showed a significant
non-normal distribution for several of the measures,
therefore, we used non-parametric tests throughout. In Table
1, the results of nonparametric correlations for the measures
of global and local pitch perception, emotion perception,
affective empathy and self-construal are reported, including
the Coefficient of Sound Perception Preference collected in
the first experiment. The analysis shows a significant
relation between global pitch perception processing and the
auditory affective processing measure: participants who
were better in perceiving changes in the global pitch contour
were also better in identifying vocalized emotions.

Self-construal measurement
To assess the role of self-construal, we used the SelfConstrual Scale developed by Singelis (1994). The scale
consists of 24 items which measure the interdependent and
independent images of the self. We also included the
relational-interdependent self-construal scale (Cross et al.,
2000). The scale consists of 11 items. For both measures,
participants were asked to indicate their agreement or
disagreement on a seven-point scale.

Discussion

Measures
Following Ziegler et al. (2011), we used d' measures to
calculate the participants' performance in the auditory
global-local pitch processing task (d'G and d'L, respectively).
Both measures were not normally distributed with MdG = .
427, MdL = .312. For the auditory affective processing task,
we calculated the scores as the total number of correctly
identified emotions (Aff). The mean score of correctly
identified emotions (90 in total) was 61.6 (SD = 9.3, Md =
64); the distribution of answers was not normal with most
participants performing above chance (t(47) = 36.56, p < .
001). For the empathy measurement, the Cronbach's alpha
coefficient was .73; the items were reduced to a single
empathy score (Emp) for further calculations. For self-

The results of the second experiment indicate that global
auditory processing is related to auditory affective
processing. This suggests that being able to identify
emotions in voice is associated with the ability to perceive
pitch globally.

General discussion and Conclusion
The present studies aimed to: a) investigate the possibility
of altering individuals’ auditory perception bias through
training, b) to illustrate experimentally the existence of a
relation between auditory global-local processing and
auditory perception bias, and c) to examine the link between
global-local auditory processing on one hand and empathy
and self-construal on the other hand. Our findings show that
auditory perception bias cannot be altered by simple
training/feedback. This finding adds to the existing evidence

3590

according to which the mode of listening (synthetic or
analytic) constitutes a rather stable individual difference.
With respect to its relation with auditory global-local
processing, our findings cannot support an association
between processing type and perception bias. We do find,
though, an association between global auditory processing
and auditory affective processing. To put it differently,
perceiving the contour in sounds is related to the ability to
recognize emotions in voice. No evidence is provided for
the link of empathy with processing when using self-report
measures. It is quite possible that, especially for perceived
emotions, behavioral measures of emotional empathic
responses may yield different results.

References
Aziz-Zadeh, L., Sheng, T., & Gheytanchi, A. (2010).
Common premotor regions for the perception and
production of prosody and correlations with empathy and
prosodic ability. PLoS ONE, 5(1), e8759.
Babel, M. (2009). Phonetic and social selectivity in speech
accommodation. Doctoral dissertation. University of
California, Berkeley.
Baron-Cohen, S. (1995). Mindblindness: An essay on
autism and theory of mind. MIT Press: Bradford Books.
Baron-Cohen, S. (2002). The extreme male brain theory of
autism. Trends in Cognitive Sciences, 6(1), 248-254.
Belin, P., Fillion-Bilodeau, S., & Gosselin, F. (2008). The
Montreal affective voices: A validated set of nonverbal
affect bursts for research on auditory affective processing.
Behavior Research Methods, 40(2), 531-539.
Bouvet, L., Rousset, S., Valdois, S., & Donnadieu, S.
(2011). Global precedence effect in audition and vision:
Evidence for similar cognitive styles across modalities.
Acta Psychologica, 138, 329-335.
Cross, S. E., Bacon, P. L., & Morris, M. L. (2000). The
relational interdependent self-construal and relationships.
Journal of Personality and Social Psychology, 78(4), 791808.
Davis, M. H. (1980). A multidimensional approach to
individual differences in empathy. JSAS Catalog of
Selected Documents in Psychology, 10, 85.
Decety, J., & Jackson, P. L. (2004). The functional
architecture of human empathy. Behavioral and Cognitive
Neuroscience Reviews, 3, 71−100.
Dediu, D., & Ladd, D.R. (2007). Linguistic tone is related to
the population frequency of the adaptive haplogroups of
two brain size genes, ASPM and Microcephalin. PNAS,
104, 10944-10949.
Fink, G. R., Halligan, P. W., Marshall, J. C., Frith, C. D.,
Frackowiak, R. S., & Dolan, R. J. (1996). Where in the
brain does visual attention select the forest and the trees?
Nature, 382(6592), 626–628.
Foxton, J.M., Talcott, J.B., Witton, C., Brace, H., McIntyre,
F., & Griffiths, T.D. (2003). Reading skills are related to
global, but not local, acoustic pattern perception. Nature
Neuroscience, 6, 343-344.

Förster, J., & Higgins, E. T. (2005). How global versus local
perception fits regulatory focus. Psychological Science,
16, 631–636.
Gregory, S.W. Jr. (1983). A quantitative analysis of temporal
symmetry in microsocial relations. American Sociological
Review, 48, 129-135.
Gregory, S.W. Jr., & Hoyt, B.R. (1982). Conversation
partner mutual adaptation as demonstrated by Fourier
series analysis. Journal of Psycholinguistic Research, 11,
35-46.
Gregory, S.W. Jr., Webster, S.W., & Huang, G. (1993). Voice
pitch and amplitude convergence as a metric of quality in
dyadic interviews. Language and Communication, 13,
195-217.
Gregory, S.W. Jr., & Webster, S.W. (1996). A nonverbal
signal in voices of interview partners effectively predicts
communication accommodation and social status
perceptions. Journal of Personality and Social
Psychology, 70, 1231-1240.
Gregory, S.W. Jr., Dagan, K., & Webster, S.W. (1997).
Evaluating the relation of vocal accommodation in
conversation partners’ fundamental frequencies to
perceptions of communication quality. Journal of
Nonverbal Behaviour, 21, 23-43.
Gregory, S.W. Jr., & Gallagher, T.J. (2002). Spectral
analysis of
candidates’
nonverbal
vocal
communication: Predicting
U.S.
presidential
election outcomes. Social Psychological Quarterly, 65,
298-308.
Jolliffe, T., & Baron-Cohen, S. (1997). Are people with
autism and Asperger syndrome faster than normal on the
embedded figures test? Journal of Child Psychology and
Psychiatry, 38, 527–534.
Justus, T., & List, L. (2005). Auditory attention to frequency
and time: an analogy to visual local-global stimuli.
Cognition, 98(1), 31-51.
Juslin, P.N., & Laukka, P. (2003). Communication of
emotions in vocal expression and music performance: d
Different channels, same code? Psychological Bulletin,
129, 770-814.
Kimchi, R. (1992). Primacy of wholistic processing and
global/local paradigm: A critical review. Psychological
Bulletin, 112(1), 24–38.
Korpilahti, P., Jansson-Verkasalo, E., Mattila, M. L.,
Kuusikko, S., Suominen, K., Rytky, S., Pauls, D. L.,
Moilanen, I. (2007). Processing of affective speech
prosody is impaired in Asperger syndrome. Journal of
Autism and Developmental Disorders, 37(8), 1539-1549.
Kühnen, U., & Oyserman, D., (2002). Thinking about the
self
influences
thinking
in
general:Ccognitive
consequences of salient self-concept. Journal of
Experimental Social Psychology, 38, 492–499.
Laguitton, V., Demany, L, Semal, C., & Liégeois-Chauvel,
C. (1998). Pitch perception: A difference between rightand left-handed listeners. Neuropsychologia, 36, 201-207.

3591

Macrae, C. N., & Lewis, H. L. (2002). Do I know you?
Processing
orientation
and
face
recognition.
Psychological Science, 13, 194–196.
Markus, H. R., & Kitayama, S. (1991). Culture and the self:
implications for cognition, emotion, and motivation.
Psychological Review, 98, 224–253.
Mueller, J.L., Friederici, A.D., & Männel, C. (2012).
Auditory perception at the root of language learning.
PNAS 109, 15953-15958.
Ladd, D., Turnbull, R., Browne, C., Caldwell-Harris, C.,
Ganushchak, L., Swoboda, K., Woodfield, V., & Dediu, D.
(2013). Patterns of individual differences in the perception
of missing-fundamental tones. Journal of Experimental
Psychology: Human Perception and Performance, 39, in
press.
Lin, Z., Lin, Y., & Han, S. (2008). Self-construal priming
modulates visual activity underlying global/local
perception. Biological Psychology, 77, 93-97.
Lin, Z., & Han, S. (2009). Self-construal priming modulates
the scope of visual attention. The Quarterly Journal of
Experimental Psychology, 62(4), 802-813.
List, A., Justus, T., Robertson, L. C., & Bentin, S. (2007). A
mismatch negativity study of local-global auditory
processing. Brain Research, 1153, 122–133.
Moore, B.C.J. (2003). An Introduction to the Psychology of
Hearing. Academic Press.
Navon, D. (1977). Forest before trees: The precedence of
global features in visual perception. Cognitive Psychology,
9, 353–383.
Postma-Nilsenová, M., & Postma, E.O. (2012). Individual
differences in F0 imitation: Causes and effects.
Proceedings of Measuring Behavior 2012, Utrecht
University.
Plomp, R. (1976). Aspects of Tone Sensation. New York:
Academic Press.
Rutherford, M. D., Baron-Cohen, S., & Wheelwright, S.
(2002). Reading the mind in the voice: A study with
normal adults and adults with Asperger syndrome and high
functioning autism. Journal of Autism and Developmental
Disorders, 32(3), 189-194.
Sanders, S. D., & Poeppel, D. (2007). Local and global
auditory processing: Behavioral and ERP evidence.
Neuropsychologia, 45, 1172-1186.
Schneider, P., Sluming, V., Roberts, N., Scherg, M., Goebel,
R., Specht, H. J., Günter Dosch, H., Stippich, C., & Rupp,
A. (2005). Structural and functional asymmetry of lateral
Heschl’s gyrus reflects pitch perception preference. Nature
Neuroscience, 8(9), 1241-1247.

Scherer, K.R., Banse, R., Wallbott, H.G., & Goldbeck, T.
(1991). Vocal cues in emotion encoding and decoding.
Motivation and Emotion, 15, 123-148.
Seither-Priesler, A., Krumbholz, K., Patterson, R., Johnson,
L., Nobbe, A., Seither, S., & Lütkenhöner, B. (2007). Tone
sequences with conflicting fundamental pitch and timbre
changes are heard differently by musicians and
nonmusicians. Journal of Experimental Psychology:
Human Perception and Performance, 33(3), 743-751.
Shamay-Tsoory, S. G., Tomer, R., Berger, B. D., Goldsher,
D., & Aharon-Peretz, J. (2005). Impaired “affective
theory of mind” is associated with right ventromedial
prefrontal damage. Cognitive and Behavioral Neurology,
18(1), 55-67.
Singelis, T. M. (1994). The measurement of independent
and interdependent self-construals. Personality and
Social Psychology Bulletin, 20, 580-591.
Southgate, L., Tchanturia, K., & Treasure, J. (2008).
Information processing bias in anorexia nervosa.
Psychiatry Research, 160(2), 221-227.
Woltin, K. A., Corneille, O., Yzerbyt, V., & Förster, J.
(2011). Narrowing down to open up for other people's
concerns: Empathic concern can be enhanced by inducing
detailed processing. Journal of Experimental Social
Psychology, 47, 418-424.
Wong, P.C.M., & Perrachione, T.K. (2007). Learning pitch
patterns in lexical identification by native Englishspeaking adults. Applied Psycholinguistics, 28, 565-585.
Wong, P.C.M., Warrier, C.M., Penhune, V.B., Roy, A.K.,
Sadehh, A., Parrish, T.B., & Zatorre, R.J. (2008). Volume
of left Heschl's gyrus and linguistic pitch learning.
Cerebral Cortex, 18, 828-836.
Wong, P.C.M., Chandrasekaran, B., & Zheng, J. (2012). The
derived allele of ASPM is associated with lexical tone
perception. PloS One, 7, e34243.
Yirmiya, N., Kasari, C., Sigman, M., & Mundy, P. (1989).
Facial expressions of affect in autistic, mentally retarded
and normal children. Journal of Child Development,
63(1), 150-160.
Ziegler, J. C.., Pech-Georgel, C., George, F., & Foxton, J.
M. (2012). Global and local pitch perception in children
with developmental dyslexia. Brain & Language, 120(3),
265-270.

3592

