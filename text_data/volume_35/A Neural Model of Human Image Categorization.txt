UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Neural Model of Human Image Categorization
Permalink
https://escholarship.org/uc/item/68b8r86q
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Hunsberger, Eric
Blouw, PEter
Bergstra, James
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             A Neural Model of Human Image Categorization
                                        Eric Hunsberger (ehunsberger@uwaterloo.ca)
                                               Peter Blouw (pblouw@uwaterloo.ca)
                                            James Bergstra (jbergstra@uwaterloo.ca)
                                           Chris Eliasmith (celiasmith@uwaterloo.ca)
                                                   Centre for Theoretical Neuroscience
                                       University of Waterloo, Waterloo, ON, Canada N2L 3G1
                             Abstract                                  does not use raw percepts as input). Many researchers now
                                                                       recognize that object perception and conceptual cognition are
   Although studies of categorization have been a staple of psy-
   chological research for decades, there continues to be substan-     not distinct (Palmeri & Gauthier, 2004), making it important
   tial disagreement about how unique classes of objects are rep-      that models integrate both perception and cognition.
   resented in the brain. We present a neural architecture for            In this paper, we argue that advances in our understanding
   categorizing visual stimuli based on the Neural Engineering
   Framework and the manipulation of semantic pointers. The            of the visual system and new principles for the design of neu-
   model accounts for how the visual system computes semantic          ral architectures can be used to overcome many of the difficul-
   representations from raw images, and how those representa-          ties in providing a viable, neurally grounded, computational
   tions are then manipulated to produce category judgments. All
   computations of the model are carried out in simulated spiking      model of image categorization. We use the techniques of the
   neurons. We demonstrate that the model matches human per-           Neural Engineering Framework (NEF) (Eliasmith & Ander-
   formance on two seminal behavioural studies of image-based          son, 2003) to develop a model of category representation that
   concept acquisition: Posner and Keele (1968) and Regehr and
   Brooks (1993).                                                      connects retinal activity to high level cognitive judgments us-
   Keywords: category representation; image categorization;
                                                                       ing a class of vector-symbolic representations called semantic
   neural engineering framework; vector symbolic architecture          pointers (Eliasmith et al., 2012). The model receives natural
                                                                       images as input, produces category judgments as output, and
                          Introduction                                 carries out intermediate processing in simulated neurons. The
                                                                       proposed model replicates human performance on two inde-
Although studies of categorization have been a staple of psy-          pendent studies of human judgment in prototype-based and
chological research for decades, there continues to be sub-            exemplar-based image categorization, with no changes to the
stantial disagreement about how the mind represents informa-           model. Semantic pointer architectures have been shown to
tion about unique classes of objects. Theories involving pro-          support several important cognitive capacities (e.g. Stewart
totypes, exemplars, and explanatory schemas have all been              & Eliasmith, 2011; Eliasmith et al., 2012). Our study ex-
shown to account for only a subset of known categorization             tends this line of research, showing that semantic pointers
phenomena, and progress toward a unified theory of cate-               computed by a plausible visual system model can be used to
gory representation has been limited (for reviews, see Mur-            replicate human category judgments.
phy, 2002; Machery, 2009; Smith & Medin, 1981). Histori-
cally, the difficulty in modelling category representation has
                                                                                           Model Description
been to balance generality and accuracy.
   On one hand, many of the models developed from these                We developed a model of human image categorization that
theories have a fairly narrow scope of application. Con-               consists of a feed-forward visual perception model (similar to
sider, for instance, similarity-based accounts of concept ref-         Hinton & Salakhutdinov, 2006) driving a vector-symbolic as-
erence; these models produce impressive results at matching            sociative memory (see Gayler, 2003; Plate, 2003). The model
human behaviour in tasks that involve feature comparisons              was first constructed using a rate approximation of the spik-
(see Smith & Medin, 1981), but they do not generalize well             ing leaky integrate-and-fire (LIF) neuron model for the visual
to other tasks that require the use of deeper category knowl-          system and explicit vector computations for the associative
edge or explanatory inferences (see Murphy, 2002).                     memory. The model was then implemented fully in spiking
   On the other hand, approaches with greater scope tend to            neurons using the principles of the NEF.
pay a price in terms of predictive accuracy or viability. For             The visual system component of the model is a sequence
example, Barsalou’s (1999) theory of perceptual symbol sys-            of feed-forward neural populations that compresses high di-
tems is a more or less unified account of category repre-              mensional input images into comparatively low dimensional
sentation, but it lacks a corresponding computational model            vectors, which we refer to as semantic pointers. The first pop-
(Dennett & Viger, 1999). Rogers and McClelland’s (2004)                ulation, analogous to the retina and lateral geniculate nucleus
account of semantic cognition provides a powerful model that           (LGN), is a rasterized image, as would be captured by a con-
performs well across a range of categorization tasks, but em-          ventional digital camera. Like the retina, a camera adapts to
ploys both an idealized neural architecture and an idealized           global lighting conditions and provides an image with stan-
set of inputs (i.e. it is an abstract connectionist network that       dard intensity levels. Our (small) LGN population corre-
                                                                   633

sponds to a square 30 × 30 image region that is best com-
pared to a small portion from the centre of the visual field.
The second population, analogous to visual area V1, com-
prises 2500 neurons with local connectivity: each neuron re-
sponds to a randomly chosen 9 × 9 patch in LGN. Neurons
in the third (V2), fourth (V4), and fifth (inferotemporal (IT)
cortex) populations (with size 900, 400, and 225 respectively)       Figure 1: Filters from the first layer of the visual system, after
are connected to all neurons in the previous population. The         autoencoder training on natural images. Like neurons in area
activation pattern in the fifth population (with latency similar     V1, our model neurons detect luminance edges at a variety of
to visual area IT) is the semantic pointer representing the im-      frequencies and orientations.
age stimulus. Representations generated in this manner are
stored in an associative memory as category exemplars (dur-
ing training), and used to probe the associative memory to              Like Hinton and Salakhutdinov (2006), each layer of the
yield a category judgment during testing (see Figure 2).             autoencoder was pretrained individually; however, layers
                                                                     were pretrained as autoencoders, not restricted Boltzmann
Adaptation to Natural Images                                         machines, allowing us to use an LIF response function for
A large fraction of neuron cells in visual area V1 are well          the neuron nonlinearity. The layers were then combined into
modelled as luminance edge detectors (Hubel & Wiesel,                a deep autoencoder and trained together using backpropaga-
1968; DiCarlo, Zoccolan, & Rust, 2012). There is mount-              tion.
ing evidence that visual system neurons behave as they do
                                                                     Semantic Pointers: Memory and Retrieval
because they continuously adapt to statistical patterns in vi-
sual stimuli (Olshausen & Field, 1996; Hyvärinen, 2009).            We refer to the vectors processed by the model as seman-
Computer vision systems inspired by principles of adaptation         tic pointers because they function as compressed symbol-like
to unlabelled visual images are among the best-performing            representations that encode the statistically relevant aspects
computer vision systems, and reproduce several phenomena             of the information they represent (Eliasmith, in press). In the
discovered by electrode recordings (Lee, Ekanadham, & Ng,            non-visual component of the architecture, semantic pointers
2008; Le et al., 2012). One strategy for adaptation to un-           representing the compressed images are bound with category
labelled images is the autoencoder (Ackley, Hinton, & Se-            labels using the mathematical operation of circular convolu-
jnowski, 1985; Rumelhart, Hinton, & Williams, 1985), which           tion (see e.g. Plate, 2003). Subsequently, the bound repre-
was first applied to images by Cottrell, Munro, and Zipser           sentations are added to the memory via superposition. This
(1987).                                                              process is captured formally by Equation 2:
   The connection weights of our visual system model were                                           N
trained as a deep autoencoder, with an additional `1 penalty                                  M = ∑ (Pi ∗ Li )                      (2)
on the hidden node activation rates to model the energy cost                                       i=1
of spiking and encourage sparser activation patterns. The ob-        where Pi is a semantic pointer produced by the visual system
jective function for one layer is given by                           from the ith raw image, Li is a vector representing the category
                 1  (k)         (k) 2
                                                                    label associated with the image, M is the memory pointer,
             O = ∑ xi − yi             +λ∑ qj −ρ             (1)     and ∗ is the circular convolution operator.
                 K i,k                     j
                                                                        Once the memory is built up with a number of learned cat-
         (k)                                               (k)       egory exemplars, it can be used to produce categorization
where xi is the value of visual node i for example k, yi is          judgments in response to novel input images via the use of
the autoencoder’s reconstruction of node i example k, q j is a       an inverse of the convolution operation. This inverse oper-
running average of the activation of hidden node j, and λ and        ation probes the memory for the category label that is most
ρ control the importance of sparsity and the desired sparsity        likely to fit the input image on the basis of prior learning. As
level, respectively. Uniquely, our autoencoder used an LIF           a whole, the categorization process conforms to the following
response function as the feature activation function.                mathematical description:
   The autoencoder was trained on random 30 × 30 natural
image patches chosen from the first 10 images of the van                                c = argmaxc (P−1 ∗ M) · Lc
                                                                                                                    
                                                                                                                                    (3)
Hateren Natural Image Database (van Hateren & van der
Schaaf, 1998). with each patch normalized to zero mean and           where c refers to the resulting category judgment, P−1 refers
unit variance. We trained only on un-whitened images, which          to the pseudoinverse of the semantic pointer corresponding
contain the full spectrum of spatial frequencies. We found           to the test image, Lc refers to the label pointer of category c,
that whitening was not required to extract Gabor-like filters        and a · b refers to the dot product of a and b. For the rate
from the statistics of the natural images (Figure 1), and was        model, these operations were implemented directly in vec-
in fact undesirable since it removed some low-frequency fea-         tors; for the spiking model, the operations were implemented
tures important for classification.                                  in spiking LIF neurons using the NEF.
                                                                 634

Visual System                                                                                Storage
                              LGN Output
                                                                    label: Builder                         label: Builder                       label: Digger
               V1 Population
                                                              *                                        *                                     * Circular
                                                                                                                                             Convolution
               V2 Population
                                                 Perceptual Task
                                                                                                       Σ   Summation
                                                                             Visual System
                                                                                                                            label: Builder
              Semantic Pointer
                                                                                                       /                               Argmax
                                                                                                Deconvolution               label: Digger
Figure 2: The schematic of our visual categorization model has three components. Left: The visual system comprises four
populations of leaky integrate-and-fire neurons corresponding to the LGN, visual areas V1, V2, V4, and IT, which we take to
represent a semantic pointer. The connections between these populations are adapted to natural scene statistics by unsupervised
learning. Upper Right: The memory of our model is encoded as a single semantic pointer, which is the sum of several labelled
training patterns (three are shown here). Labels have been bound to their corresponding image representations through the
mathematical operation of circular convolution. Lower Right: At test time, our model labels visual stimuli by deconvolving the
activity patterns of IT with the memory vector, and matching the result against several possible label decisions.
   In short, the model builds category representations by stor-         terns without feedback: patterns from the training phase (2
ing compressed and labelled percepts, and produces catego-              per prototype, 6 total), the prototype patterns (3), prototype
rization judgments by evaluating the similarity between an              patterns with a smaller degree of distortion (6), new highly
input percept and the exemplars stored in memory. How-                  distorted prototype patterns (6), and entirely random new pat-
ever, since all labelled percepts are compressed into the same          terns (3). Subjects were tested on these patterns on two con-
vector, there is significant interaction between stored per-            secutive days, in terms of both accuracy and reaction time.
cepts; this can be likened to creating a prototype based on                The protocol for evaluating our categorization model was
the percepts. The model categorization system thus falls part           nearly identical. We presented the model with the twelve
way in between pure exemplar-based categorization and pure              training images, and it stored the semantic pointers associ-
prototype-based categorization; it has elements of both.                ated with the labels and the images into the model’s memory
                                                                        (see Figure 2). Then we presented our model with each of
Experiment 1: Prototype-based Categorization                            the twenty-four testing patterns. Figure 4 compares the accu-
                                                                        racy of our model to the classification accuracy of the human
To account for the sort of phenomena that have traditionally            subjects. Since our model lacks motor output, we did not
motivated prototype theories of category representation, we             evaluate it on reaction time. Figure 4 shows the results of
tested the model on a task from Posner & Keele’s (1968) clas-           our model; in sum, the model performs much like the human
sic study of pattern classification. We chose to model Exper-           subjects.
iment 3 of the study, which was designed to test whether hu-
man subjects are learning about class prototypes when they
                                                                        Experiment 2: Exemplar-based Categorization
only ever see distorted examples. In the study, subjects are
trained to classify classify random dot patterns into three mu-         To account for effects more commonly aligned with exemplar
tually exclusive categories. Each pattern consists of nine dots         theories of category representation, we tested the model on a
dispersed over a 30 × 30 grid, with each dot occupying one              task from Regehr & Brook’s (1993) study of the comparative
cell in the grid. The patterns used for training are gener-             influence of analytic and non-analytic processes on catego-
ated from three prototypes; each training pattern is created by         rization behaviour. The study involves a number of experi-
choosing a prototype pattern, and moving each dot according             ments in which subjects are asked to classify simple drawings
to a random distortion rule (see Figure 3.) Thirty (30) sub-            of imaginary animals into one of two categories. The animals
jects were trained by corrective feedback to classify twelve            all possess an analytic structure that varies along five binary
‘high distortion’ patterns (four from each category). After             dimensions (e.g. a round vs. angular body), but the exact
training, the subjects were asked to classify twenty-four pat-          perceptual manifestation of a particular dimension value (i.e.
                                                                  635

    Prototype Low Distortion High Distortion
Figure 3: Sample stimuli for Experiment 1, modelling a clas-
sic study by Posner & Keele (1968). The dot patterns are
created by distorting three randomly drawn prototype images
(left) with low (centre) and high (right) levels of noise. Sub-
jects are trained to classify a set of twelve high-distortion pat-
terns and tested without feedback on the same prototypes at
different distortion levels.
feature) can vary across animals. For example, two animals
might have round bodies, and thus be analytically equivalent           Figure 4: Comparison of human and model performance for
to some extent, but the actual roundness of their respective           Experiment 1. The model is able to account for human results
bodies might be quite distinct (see Figure 5). This allows             when presented with the schema, low distortion (5), and high
for the construction of stimuli sets that possess drawings that        distortion (7) patterns. Occasional random errors by human
are analytically equivalent but perceptually dissimilar, along         subjects may explain the discrepancy on training examples.
with drawings that are analytically distinct but perceptually          Error bars indicate 95% confidence intervals. Human data
similar. By training subjects through corrective feedback to           from Posner & Keele (1968).
classify these images into categories defined by an analytic
rule, Regehr & Brooks were able to test hypotheses regarding
the relative importance of perceptual similarity and analytic          jects attend primarily to the analytic structure of the images
structure during categorization.                                       during testing, then they should make relatively few errors on
   In the experiment 1C of Regehr & Brooks’ study, 32 sub-             the new bad transfer items (because both analytic structure
jects are placed into one of two conditions and then trained to        and perceptual similarity favour the correct judgment). Alter-
classify a set of eight images into two categories. For subjects       natively, if subjects attend primarily to similarity to past ex-
in the first condition, the perceptual manifestations of a given       emplars, then they should make relatively more errors on the
dimension are constant across the images (See Figure 5, left).         bad transfer items (because perceptual similarity and analytic
For subjects in the second condition, the perceptual manifes-          structure favour opposing judgments). The study is designed
tations of a given dimension vary across images (See Fig-              to test the effect of appearance on subjects’ use of structural
ure 5, right). Every subject was trained to learn one of four          vs. perceptual mental representations.
labelling rules based on analytic structure. The rules had the            We model experiment 1C of Regehr & Brooks’ study with
form: An image is a ‘builder’ if it has at least two of X, Y, and      the same model that we used in Experiment 1. We presented
spots, otherwise it is a ‘digger’. The criteria X and Y referred       our model with the same eight training images used in the
to things like “long neck”, “angular body”, “short legs” and           original experiment (though downsampled to fit in a 30 × 30
so on (see Regehr & Brooks, 1993, for details). Training oc-           patch), drawn either in the composite style or in the indi-
curs through corrective feedback and is considered complete            viduated style. The semantic pointers created by the visual
after five runs through the image set.                                 system, together with semantic pointers for the correspond-
   During the transfer phase of the experiment, subjects are           ing image labels, were stored into the model’s memory, as
asked to classify a set of sixteen images, eight of which are          described by Equation 2 shown in Figure 2. We tested the
from the training set and eight of which are qualitatively sim-        representations of our visual system by classifying the good-
ilar, but new. The new images have been designed to pair up            transfer and bad-transfer test images, as well as the original
with a specific training image, and only differ on the dimen-          training images. The accuracy of our model in each case is
sion of “spots on body.” Half of the new images belong in the          presented in Figure 6. Our model provides a good match to
same category as their twin from the training set, while the           human performance, and replicates the effect that perceptu-
other new images have a different category from their twin.            ally individuated stimuli foster substantially different error
The idea motivating this experimental design is that if sub-           profiles than perceptually un-individuated stimuli.
                                                                   636

                      Composite Parts       Individuated Parts                                      Discussion
                        Train     Test        Train      Test              Posner & Keele’s (1968) study is considered to be seminal
                                                                           in the development of prototype theory, and the result that
Good Transfer Pairs
                                                                           subjects categorize the training patterns and prototype pat-
                                                                           terns equally well is taken to indicate that the subjects are ab-
                        Builder   Builder     Builder    Builder
                                                                           stracting information about the prototypes during the training
                                                                           phase. Our model’s replication of this performance provides
                                                                           good evidence that our approach is capable accounting for
                                                                           the sort of prototype effects that the study uncovered. Inter-
                                                                           estingly, the spiking version of the model performs slightly
                        Digger    Digger      Digger     Digger
                                                                           worse than humans on the prototypes, indicating that it might
                                                                           be performing a more exemplar-based classification. How-
Bad Transfer Pairs
                                                                           ever, we hypothesize that adding more neurons to the asso-
                                                                           ciative memory will attenuate this effect.
                        Digger    Builder     Digger     Builder              Regehr & Brooks’ (1993) study is more easily located in
                                                                           the tradition of exemplar theories of category representation.
                                                                           The fact that the model replicates the effects of interference
                                                                           from exemplar memories on more analytic categorization ap-
                        Builder   Digger      Builder    Digger            proaches suggests that it is well-equipped to deal exemplar-
                                                                           based phenomena. Moreover, the architecture of the model
  Figure 5: Sample stimuli for Experiment 2, modelling ex-                 almost trivially assures that this is true—the contents of the
  periment 1C of Regehr and Brooks (1993). (Left) Images                   associative memory essentially are exemplars produced from
  are composed of interchangeable (composite) feature mani-                visual experience. It is thus reasonable to expect that phe-
  festations. (Right) Images expressing the same attributes are            nomena found in studies using different kinds exemplars will
  drawn in a more coherent (individuated) style. Regehr &                  be reproducible with the model.
  Brooks (1993) drew a distinction between good transfer and                  Overall, the results of the simulations indicate that our
  bad transfer test stimuli. A test stimulus is a good transfer            model is able to account for an important set of phenomena
  case when the addition or removal of spots matches a training            closely associated with exemplar and prototype theories of
  case with the same label, and a bad transfer case if adding              category representation. The fact that the simulation employs
  or removing spots matches a training case with the opposite              a neural architecture for all stages of processing, and that it
  label. (Adapted from Regehr & Brooks (1993) Figure 2A).                  begins with raw image input, provides an important contribu-
                                                                           tion to the current literature.
                                                                              However, the model has several limitations as it stands.
                                                                           Nevertheless, we believe it is reasonable to expect that the
                                                                           architecture is capable of capturing an even wider range of
                                                                           phenomena. We identify two requirements of scaling that an
                                                                           architecture utilizing semantic pointers can likely achieve.
                                                                              For one, it is possible to incorporate a more realistic ac-
                                                                           count of category learning into the model. In the actual exper-
                                                                           iments, subjects learn the relevant categories through correc-
                                                                           tive feedback, and the feedback process continues either for a
                                                                           set number of trials, or until the subjects can accurately clas-
                                                                           sify all of the items without error. By comparison, our model
                                                                           learns by memorizing a set of training images labelled with
                                                                           the correct category. In the model, the label/image relation-
                                                                           ships are forgotten when the model is shown another set of
                                                                           stimuli. However, the recent development of methods for in-
                                                                           troducing biologically plausible learning rules into the neural
                                                                           framework we employ indicates that this simplification could
  Figure 6: Comparison of human and model performance for
                                                                           be removed in the future. Other cognitive models that make
  Experiment 2. Our model accounts for the key difference
                                                                           use of semantic pointers have already incorporated a form of
  in human performance on the good transfer (GT) versus bad
                                                                           reinforcement learning using such rules (e.g. Eliasmith et al.,
  transfer (BT) pairs for the individuated stimuli. Error bars in-
                                                                           2012).
  dicate 95% confidence intervals. Human data from Regehr &
                                                                              Second, we believe it is possible to account for a broader
  Brooks (1993).
                                                                           range of categorization phenomena. The architectural prin-
                                                                     637

ciples used in our model have also been used to construct             Eliasmith, C., Stewart, T., Choo, F.-X., Bekolay, T., DeWolf,
what is currently the world’s largest functional brain model,           T., Tang, Y., et al. (2012). A large-scale model of the
able to account for tasks involving serial-order recall, syn-           functioning brain. Science, 338(6111), 1202-1205.
tactic induction, and the manipulation of numerical con-              Gayler, R. (2003). Vector symbolic architectures answer
cepts (Eliasmith et al., 2012). The fact that other large-scale         Jackendoffs challenges for cognitive neuroscience. In
cognitive models make use of the same representations and               P. Slezak (Ed.), ICCS/ASCS (p. 133-138).
processes as this model provide good reason to think that             Hinton, G. E., & Salakhutdinov, R. R. (2006). Reducing the
a similar scale of functionality can achieved with models               dimensionality of data with neural networks. Science (New
specifically focused on category representation. These two              York, N.Y.), 313(5786), 504–7.
extensions will be the focus of future work.                          Hubel, D., & Wiesel, T. N. (1968). Receptive fields and
                                                                        functional architecture of monkey striate cortex. Physiol-
                          Conclusion                                    ogy, 195(1), 215-43.
This paper has presented a neural architecture for categoriz-         Hyvärinen, A. (2009). Statistical models of natural images
ing visual stimuli using a semantic pointer architecture. Our           and cortical visual representation. Topics in Cognitive Sci-
model replicates human behaviour on two important stud-                 ence, 2, 251–264.
ies of visual categorization: Posner & Keele’s (1968) and             Le, Q. V., Ranzato, M. A., Monga, R., Devin, M., Chen, K.,
Regehr & Brooks’ (1993). Modelling efforts have tradition-              Corrado, G. S., et al. (2012). Building high-level features
ally had to face the dilemma of choosing between plausibil-             using large scale unsupervised learning. In Proc. ICML 29
ity and scope. The end-to-end neural model described here               (pp. 81–88).
takes a suggestive first step in addressing this dilemma. Over-       Lee, H., Ekanadham, C., & Ng, A. Y. (2008). Sparse deep
all, this promise of scalability adds further theoretical signif-       belief net model for visual area V2. In Proc. NIPS 20 (pp.
icance to the empirical results we describe. The combination            873–880).
of a hierarchical visual model and a neurally implemented             Machery, E. (2009). Doing without concepts. Oxford, UK:
vector-symbolic architecture yields a new, effective approach           Oxford University Press.
to building models of category representation that are scal-          Murphy, G. (2002). The big book of concepts. Cambridge,
able, biologically plausible, and comprehensive, in that they           MA: MIT Press.
capture the stages of processing from perception to judgment.         Olshausen, B. A., & Field, D. J. (1996). Emergence of
                                                                        simple-cell receptive field properties by learning a sparse
                    Acknowledgments                                     code for natural images. Nature, 381, 607-691.
                                                                      Palmeri, T. J., & Gauthier, I. (2004). Visual object under-
We gratefully acknowledge the financial support of NSERC,
                                                                        standing. Nature reviews. Neuroscience, 5(4), 291–303.
SSHRC, Canada Research Chairs, the Canadian Foundation
                                                                      Plate, T. (2003). Holographic reduced representation: Dis-
for Innovation, the Ontario Innovation Trust, and the Banting
                                                                        tributed representation for cognitive structure. Stanford,
Postdoctoral Fellowships Program.
                                                                        CA: CSLI Publications.
                                                                      Posner, M., & Keele, S. (1968). On the genesis of abstract
                          References
                                                                        ideas. Experimental Psychology, 77, 653-663.
Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A            Regehr, G., & Brooks, J. (1993). Perceptual manifestations
   Learning Algorithm for Boltzmann Machines. Cognitive                 of analytic structure - the priority of holistic individuation.
   Science, 9(1), 147–169.                                              Experimental Psychology: General, 122(1), 92-114.
Barsalou, L. (1999). Perceptual symbols systems. Behavioral           Rogers, T., & McClelland, J. (2004). Semantic cognition: A
   and Brain Sciences, 22, 577-660.                                     parallel distributed processing approach. Cambridge, MA:
Cottrell, G., Munro, P., & Zipser, D. (1987). Learning inter-           MIT Press.
   nal representations from gray-scale images: An example of          Rumelhart, D., Hinton, G., & Williams, R. (1985). Learning
   extensional programming. In Proc. COGSCI 9 (pp. 462–                 internal representations by error propagation (Tech. Rep.
   473).                                                                No. ICS-8506). UCSD Institute for Cognitive Science.
Dennett, D., & Viger, C. (1999). Sort-of symbols? Behav-              Smith, E., & Medin, D. (1981). Categories and concepts.
   ioral and Brain Sciences, 22(4), 613.                                Cambridge, MA: Harvard University Press.
DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How               Stewart, T., & Eliasmith, C. (2011). Neural cognitive mod-
   does the brain solve visual object recognition? Neuron, 73,          eling: A biologically constrained spiking neuron model of
   415-34.                                                              the tower of hanoi task. In Proc. COGSCI 33 (p. 656-661).
Eliasmith, C. (in press). How to build a brain: A neural              van Hateren, J. H., & van der Schaaf, A. (1998). Independent
   architecture for biological cognition. Oxford, UK: Oxford            component filters of natural images compared with simple
   University Press.                                                    cells in primary visual cortex. Proc. Biological Sciences,
Eliasmith, C., & Anderson, C. (2003). Neural engineering:               265(1394), 359-366.
   Computation, representation, and dynamics in neurobio-
   logical systems. Cambridge, MA: MIT Press.
                                                                  638

