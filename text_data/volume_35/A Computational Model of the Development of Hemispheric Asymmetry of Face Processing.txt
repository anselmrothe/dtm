UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Model of the Development of Hemispheric Asymmetry of Face Processing
Permalink
https://escholarship.org/uc/item/12v535dm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Wang, Panqu
Cottrell, Garrison
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

  A Computational Model of the Development of Hemispheric Asymmetry of Face
                                                                  Processing
                                                    Panqu Wang (pawang@ucsd.edu)
                       Department of Electrical and Computer Engineering, University of California San Diego
                                               9500 Gilman Dr 0407, La Jolla, CA 92093 USA
                                                   Garrison Cottrell (gary@ucsd.edu)
                        Department of Computer Science and Engineering, University of California San Diego
                                               9500 Gilman Dr 0404, La Jolla, CA 92093 USA
                               Abstract                                   Hsiao, Shieh, and Cottrell (2008) implemented this DFF the-
                                                                          ory using a computational hemispheric model, and showed
   Extensive research effort has been invested in building neuro-         that the model could account for the left-side bias in face
   computational models for face and object recognition. How-
   ever, the relationship between the recognition model and the           recognition.
   development of the visual system is rarely considered. Re-                All neurocomputational models so far investigate the ef-
   search on the development of contrast sensitivity shows that           fects of structural constraints, such as the visual field split, the
   human infants can only perceive low spatial frequency infor-
   mation from visual stimuli, but their acuity improves gradu-           interaction between the two hemispheres, and the localized
   ally with age. Also, the right hemisphere (RH) develops earlier        nature of the FFA. Temporal constraints, such as the develop-
   than the left hemisphere (LH), and is dominant in infants. Here        ment of the brain through childhood, are rarely considered in
   we show that these constraints, coupled with a desire on the
   part of the infant to individuate its caretakers and family, leads     these models. By including consideration of the developmen-
   naturally to the right hemisphere bias for face processing. We         tal changes, we may generate new hypotheses concerning the
   propose a developmental model for face and object recognition          lateralization of face processing.
   using a modular neural network based on Dailey and Cottrell
   (1999). This neural network represents the two hemispheres                We consider two main constraints. First, studies in hu-
   using two modules, with a competitive relationship between             man infants have shown that the right hemisphere develops
   them mediated by a gating mechanism. The strong RH and                 its function earlier than the left hemisphere (Chiron et al.,
   low spatial frequency bias for face recognition emerges natu-
   rally in the model from the interaction of the slow development        1997). By measuring the regional cerebral blood flow (rCBF)
   of acuity and the early dominance of the right hemisphere. Re-         changes at rest using single photon emission computed to-
   markably, this strong asymmetry does not appear to hold for            mography (SPECT), Chiron et al. observed a right hemi-
   the other object categories that we tried.
                                                                          sphere predominance of the blood flow between 1 and 3 years
   Keywords: face recognition; developmental model; contrast
   sensitivity; modular neural network.                                   of age, with the asymmetry shifting to the left hemisphere af-
                                                                          ter 3 years.
                                                                             The second constraint has to do with the development of
                           Introduction                                   visual acuity. Studies have shown that the contrast sensitivity
Computational models have been used extensively to instan-                function (CSF), a measure of the ability to distinguish be-
tiate hypotheses regarding face and object perception from                tween different levels of luminance in static images, changes
a neurocomputational perspective (Dailey & Cottrell, 1999;                radically over time. The CSF of a 3-month-old infant is over
O’Reilly & Munakata, 2000; Riesenhuber & Poggio, 1999).                   1.0 log units lower than the adult (Peterzell, Werner, & Ka-
Due to their social importance and frequency, faces as a stim-            plan, 1995). By age 4, children’s contrast sensitivity is still
ulus class have been studied most extensively. fMRI studies               reduced by about 0.5 log units when compared to that of
have shown that the fusiform face area (FFA) is activated in              adults (Atkinson, Braddick, & Moar, 1995; Gwiazda, Bauer,
response to faces more than other stimuli, and this activation            Thorn, & Held, 1997). The studies regarding the time of con-
is found to be stronger in the right hemisphere (Kanwisher,               trast sensitivity maturity have obtained somewhat disparate
McDermott, & Chun, 1997). This right hemisphere lateral-                  results. They range from claims of maturity between 6 to 10
ization is supported by electrophysiological studies, which               years of age (Bradley & Freeman, 1982; Mayer, 1977), to
show a stronger face-specific wave 170 ms after the stimu-                evidence of immaturity in 8-15 year old children (Arundale,
lus onset over the right hemisphere (Bentin, Allison, Puce,               1978). More recent studies suggest that contrast sensitivity
Perez, & McCarthy, 1996). In addition, according to neu-                  attains adult levels in all frequencies by age 7 (Ellemberg,
ropsychological data, the lesioning of the right FFA will re-             Lewis, Liu, & Maurer, 1999), or 8 (Leat, Yadav, & Irving,
sult in prosopagnosia, a deficit in face recognition (Bouvier             2009).
& Engel, 2006). To account for such hemispheric asymme-                      Combining these two constraints, we propose a neurocom-
try, Ivry and Robertson (1998) proposed the Double Filter-                putational developmental model for object and face recog-
ing by Frequency (DFF) model which postulates differential                nition. The model is based on a previous study of the de-
frequency filtering on task-relevant frequency bands in each              velopment of hemispheric asymmetry by Dailey and Cottrell
hemisphere, with a bias for low spatial frequency in the RH.
                                                                      3735

(1999). Dailey & Cottrell used a mixture of experts archi-
tecture (Jacobs, Jordan, & Barto, 1991), a neural network
with two modules to represent the two hemispheres. The out-
put of the modules is gated based on their contribution to the
overall performance. Dailey & Cottrell also suggested that
low acuity, and the need to individuate faces, would lead to
right hemisphere dominance. However, in their model, they
assumed the right hemisphere would receive low spatial fre-
quencies, and the left hemisphere high spatial frequencies,
which is an unrealistic assumption. Furthermore, their model
did not change its visual acuity over time. Here, we model
the changes in children’s contrast sensitivity by low-pass fil-
tering the data set, and gradually improving the fidelity of
inputs over training iterations (i.e., as the model ”ages”). To
model the asymmetric developmental pattern of the brain, we
give the two modules different learning rates over time. A            Figure 1: Architecture of Dailey and Cottrell’s (1999) modu-
detailed description of this methodology will be given in next        lar neural network model.
section. In the result section, we will discuss the network’s
general performance on different objects, and the strong right        Because the labels to be discriminated have a strong influ-
hemisphere bias for face processing which emerges naturally           ence on the hidden layer representation through the learning
from the interaction of the developmental trends.                     process, the discrimination level of the output layer will drive
                                                                      the representation developed by the hidden layer through er-
                          Methods                                     ror feedback. The gating layer has two nodes whose activity
We will first describe the structure of the modular neural net-       modulates the output of the hidden layers by multiplying the
work, and then discuss the modifications to create the devel-         connection weights from the hidden layer to the output layer.
opment model.                                                         We use a softmax function at the output of the gating net-
                                                                      work to ensure that the gating weights always sum to one.
The Model                                                             The network is trained using online backpropagation. Dur-
Each input image goes through a two-step preprocessing                ing learning, the gating nodes act like a competitive selection
stage: Gabor filtering and Principal Component Analy-                 mechanism and direct more information (error feedback) to
sis (PCA). The biologically motivated 2-D Gabor filter                the module that has more contribution to performance and
(Daugman, 1985) is constructed by using a two-dimensional             better ability to process a given pattern. For example, if the
sinusoid localized by a Gaussian envelope. By tuning to               task is better performed by module 1, the gating network will
particular spatial frequency and orientations, the Gabor filter       learn to weight the module 1 outputs more highly, and the
magnitudes can be used to simulate the responses of com-              hidden units of module 1 will also receive more training as a
plex cells in primary visual cortex (V1). Following Gabor             result. Thus there is a ”rich get richer” effect.
filtering, PCA reduces the dimensionality of the information             Dailey and Cottrell (1999) trained this modular neural net-
by simulating the information extraction mechanism beyond             work to account for the development of the FFA. Based on the
V1, up to the lateral occipital regions level. After these pre-       evidence that the right hemisphere has a relatively low spatial
processing steps, each image is represented by a vector of            frequency preference and the left hemisphere has a relatively
relatively low dimension to be fed into the modular neural            high spatial frequency bias (Sergent, 1982), they gave differ-
network.                                                              ent spatial frequency information from each stimulus to each
    The mixture of experts architecture has been in develop-          module by weighting the frequency component differently in
ment since 1990 (Dailey & Cottrell, 1999; Jacobs, Jordan,             the PCA step. When the model’s goal was to individuate dif-
& Barto, 1991; Jacobs, Jordan, Nowlan, & Hinton, 1991).               ferent faces while categorizing the other classes of stimuli,
Our particular variant of the model is presented in Figure 1.         they observed a strong specialization of the low spatial fre-
The modular neural network has three components: two side-            quency module to processing faces; no other tasks showed a
by-side hidden layers (the ”modules”), an output layer and            similar specialization. Hence, they took these results as sup-
a gating layer. The hidden layers are used to learn features          port for the hypothesis that the FFA developed as a natural
for a given task adaptively, and develop more sophisticated           consequence of the infant’s low visual acuity, and the need to
representations for the input stimuli; if the task is face recog-     individuate faces.
nition, we can consider the hidden layer as corresponding to
                                                                      Modeling Infant’s Developmental Patterns
FFA. There is one hidden layer for each of the hemispheres.
There are sufficient hidden units in each network to perform          Although Dailey and Cottrell (1999) successfully modeled
the tasks. The output layer provides us with the labels of the        the right hemisphere lateralization of FFA for face recogni-
input stimulus to perform the final object recognition task.          tion, their consideration of the developmental facts is inade-
                                                                  3736

quate. First, although the right hemisphere (RH) has a low          this change of children’s contrast sensitivity over time, we
spatial frequency (LSF) bias, both the left and right hemi-         low-pass filtered the dataset before sending them to the Ga-
spheres should receive the same frequency information from          bor filter in the modular neural network model. We gradu-
the input stimuli, as psychophysical results show equal CSF’s       ally improved the fidelity of the input as the training iteration
in the two visual fields. We hypothesize that the selectivity       increases. To be more specific, we used a 2-D circular aver-
arises as a consequence of competition during the develop-          aging filter with decreasing radius r to filter the dataset. We
mental period, rather than assuming it is already in force dur-     set the largest radius be 6 pixels, and gradually decreased the
ing development. Hence, instead of manually weighting the           radius by a same interval till it reached zero (unfiltered). Fig-
information provided by each spatial frequency differently in       ure 3 shows the result of a image filtered by a disk filter with
each module, in this work we give both modules the same im-         high to low radius.
ages over time. Instead of manipulating the spatial frequen-
cies so that they are different, we give the modules different
learning rates, in accord with the data that the right hemi-
sphere is dominant during the first three years (Chiron et al.,
                                                                    Figure 3: Result of a sample image filtered by disk filter with
1997). We model this as a wave of plasticity in each hemi-
                                                                    radius decrease from 6 (leftmost) to 0 (rightmost).
sphere that is slightly out of phase, as in Figure 2. The right
hemisphere will thus do more learning earlier than the left.
This will drive the right hemisphere network to reach conver-
gence more quickly, which in turn will make it win the com-                         Experiments and Results
petition and obtain a higher gating node value in the gating        Face/Object Stimuli and Preprocessing
network. We used two Gaussians with different mean values
and the same variance followed by a straight line to represent      Our studies used four category of objects: faces, books, cups,
the evolution of the learning rate. At earlier epochs, module       and handwritten digits. For the faces, books and cups, we col-
1 has a higher learning rate than module 2. After a certain         lected the images from 12 different individuals for each cate-
number of iterations, the learning rate of module 2 starts to       gory from the Cottrell and Metcalfe (1991) database. For dig-
increase and prevails over module 1. Finally, both learning         its 0-9, we utilized the MNIST handwritten database (LeCun,
rates drop to a small constant value until the end of training.     Bottou, Bengio, & Haffner, 1998) and sampled 20 images
This represents the maturity of both hemispheres, but they          for each digit. Each image was transformed to grayscale and
continue to learn into ”adulthood.”                                 cropped to size of 64 × 64. In the Gabor filtering step, we
                                                                    adopted the classical Gabor filter bank (Lades et al., 1993)
                                                                    with 5 different scales and 8 orientations ranging from 0 to
                                                                    7π/8. This step resulted in a 40-dimensional vector at each
                                                                    point in the image. After normalizing the response values
                                                                    across orientations and subsampling these vectors in a 8 × 8
                                                                    grid, we computed the magnitude of the complex numbers
                                                                    and got a 2560-dimensional vector to represent the image. To
                                                                    extract a smaller number of features and maintain a segre-
                                                                    gation of responses from each scale of Gabor filter, we per-
                                                                    formed PCA separately on each spatial frequency component
                                                                    of the pattern vectors. Since we had 5 different scales, we ex-
                                                                    tracted the subvectors corresponding to each scale from every
                                                                    pattern in the training set, computed the eigenvectors of the
                                                                    covariance matrix, and projected these subvectors onto these
                                                                    basis vectors. Here we used the Turk and Pentland trick (Turk
                                                                    & Pentland, 1991) to reduce the computational cost. We re-
Figure 2: Learning rate example. Module 1 (dashed line)             tained the eight most significant coefficients of each scale ac-
learns earlier than module 2 (solid line) and they converge to      cording to the eigenvalue, reassembled the pattern and finally
same value after 30 iterations.                                     obtained a 40-dimensional vector for each input image.
   Since the contrast sensitivity of infants is relatively low      Network Training
(Atkinson et al., 1995; Gwiazda et al., 1997; Peterzell et al.,     Based on the task manipulations performed by Dailey & Cot-
1995), they can only obtain the low spatial frequency infor-        trell, we trained the modular neural network to perform three
mation of a given visual stimuli instead of receiving the full      tasks:
frequency details. As they grow older, their contrast sensi-
tivity will reach adult levels, and then they will receive the     1. 4-Class basic-level classification on faces, books, cups and
full spatial frequency information from the input. To model            digits: 4 outputs in total.
                                                                3737

2. Face expert: subordinate classification on 10 different
    faces, together with basic-level classification on books,
    cups and digits: 13 outputs in total.
3. Non-face expert: subordinate classification on 10 different
    digits (0-9), cups or books, together with basic-level clas-
    sification on other 3 categories: 13 outputs in total.
 For each task, we performed two experiments. As a control
 condition, we used the same learning rate λ for both modules.
 In the experimental condition, we assigned different learning (a) 4-way classification (control)     (b) 4-way classification (split learn-
 rate over time to each module to model the asymmetric de-                                            ing rate)
 velopment pattern over 30 iterations, as in Figure 2:
            λmodule1   = 0.015 × G (iteration, 10, 5)
            λmodule2   = 0.015 × G (iteration, 20, 5)
 where G (iteration, 10, 5) means a Gaussian distribution with
 mean 10 and variance 5 evaluated at iteration. After 30 iter-
 ations, we set the constant learning rate λ = 1.5 × 10−4 for
 both modules. In all experiments, we considered module 1 to
                                                                       (c) Face expert (control)      (d) Face expert (split learning rate)
 be the right hemisphere, which learns earlier, and module 2 to
 be the left hemisphere. To model the development of contrast
 sensitivity, we utilized 9 different filtered datasets from low
 to full spatial frequency (see Figure 3), changing the dataset
 every three epochs. While the mapping is arbitrary, we as-
 sume for now that three epochs correspond to a year, so that
 the contrast sensitivity matures around the ”age” of 9, or 27
 epochs. At that point, the dataset with full spatial frequency
 is used to train the model to convergence.
    We used stochastic gradient descent (online learning) to        (e) Number expert (control)       (f) Number expert (split learning
 train the neural network. We used a small momentum term,                                             rate)
 set to 0.01 in all experiments. The number of output nodes
 equals the number of categories to be classified. We per-
 formed a 10-fold cross validation on the training set to find
 the optimal settings for the number of nodes in hidden units
 and the stopping criteria based on the model’s performance
 on the hold-out set. In the 4-way classification task, we used
 48 images from each class to form the training set, and 12 im-
 ages to form the test set. We determined that a mean squared
 error (MSE) of 0.001 was an adequate threshold to stop train-
 ing: the value of the gating nodes was stable and the network         (g) Cup expert (control)        (h) Cup expert (split learning rate)
 reached good performance on the test set. For the face expert
 and non-face expert experiments, due to limitations on how          Figure 4: Average weights assigned to each module for each
 many images we had of individual faces, we reduced each             stimulus class. In control condition (left column), each mod-
 class to have 20 training images and 4 testing images, and the      ule receives the same learning rate. We can see the average
 MSE threshold was set to 0.02 to avoid overtraining. Both           weights are almost symmetric in all tasks. In the experimen-
 hidden layers are determined to have 15 nodes as the model’s        tal condition(right column), each module receives different
 performance is good and stable when we set it between 10            learning rate. We can see a strong RH bias for face expert
 and 20. The connection weights between input layer, hidden          task, but no such bias exists in number and cup expert task.
 layer and output layer were set randomly, while the weights         The error bar denotes the standard deviation.
 between input to gating layer were all set to have the same
                                                                     the lateralization of each module for different classes of ob-
 value to give the softmax layer of the two gating nodes the
                                                                     jects. Figure 4 displays the result for three of the tasks.
 same initial value of 0.5.
                                                                        In the control condition, both modules receive the same
    For each of the 3 × 2 experimental conditions, we ran the
                                                                     learning rate, so it is expected that there is no preference for
 experiment 12 times and recorded the softmax output of the
                                                                     either module over any class of stimuli. Even if at certain
 gating layer for each class after convergence. This indicated
                                                                 3738

time one module wins for a given category, the average gat-
ing value for each module will be equal when averaged over
many runs. As a result, no matter what the task is, no bias
exists in the control task, so the average weights should be
symmetric, as can be seen in the left column of Figure 4.
   When we assigned different learning rate for each module,
the task of recognizing different faces (face expert) shows
a consistently strong bias for module 1 (right hemisphere).
From Figure 4 (d), the average weight of RH reaches 0.96, 24
times higher than the LH weight value. However, this strong                (a) Face expert                    (b) Book expert
hemisphere lateralization does not occur on the task of dif-
ferentiating the non-face objects, where the average weights
for both hemispheres are close. We have also performed the
equivalent experiment with a book expert, and this experi-
ment only shows the weak right hemisphere bias (See Fig-
ure 5). Additionally, we have also performed the experiment
using different learning rates and training epochs per dataset,
and this RH lateralization for face recognition appeared very
robust.
                                                                           (c) Cup expert                    (d) Number expert
Brain Development, Contrast Sensitivity and RH
Bias for Faces                                                      Figure 5: Gating node value vs. time for all objects in the ex-
                                                                    periments. We took the average value across all individuals
The finding of a strong RH bias for face recognition directly
                                                                    in the same category to get the result for the corresponding
raises two questions: at which point during the learning pro-
                                                                    expert tasks. The solid line represents the node value of RH
cess (brain development) did the bias appear? What is the dif-
                                                                    and the dashed line represents the node value of LH. The dot-
ference between face recognition and object recognition? To
                                                                    ted line set a middle threshold of 0.5. We set the maximum
investigate the relationship between brain development and
                                                                    value at horizontal axis as 100 because the node value is sta-
RH bias, we ran another face expert experiment, and kept
                                                                    ble afterwards.
track of the softmax value of the gating nodes for each class
separately until they are stable. The result of gating node
                                                                    or greater increments, we varied the rate of development.
value vs. time is shown in Figure 5.
                                                                    We built different numbers of filtered datasets ranges from
   We observed some interesting phenomena. First, for all
                                                                    6 to 14 to test the effect on the degree of bias. All filtered
non-face objects, the value of the gating node for the RH
                                                                    datasets have the same range of filtering coefficients, and a
increases rapidly before the 10th epoch. This is consistent
                                                                    larger number of dataset means a smaller interval step. We
with the fact that the learning rate for the RH is much higher
                                                                    ran the training 12 times on each group of filtered datasets
than the LH (see Figure 2). In addition, a significant drop
                                                                    and recorded the value of RH and LH nodes when the net-
for RH value and an increase for LH value appear between
                                                                    work converges. We computed the mean value and standard
10-20th iteration for these same objects, when the learning
                                                                    deviation of both hemispheres. The results are shown in Ta-
rate switches to the LH. Thus these objects track the learning
                                                                    ble 1.
rate closely. However, the impact of the increased learning
rate for the left hemisphere does not affect the allocation of      Table 1: Relationship between age of contrast sensitivity ma-
face processing to the RH, as the gating node value for RH          tures and the RH bias for face recognition
remains high and stable. Considering the hidden layer of the
RH network to be analogous to the FFA, these findings are              ”Age”       RH Value    std(RH)     LH Value      std(LH)
also consistent with the fact that the FFA is RH lateralized               6         0.7908     0.0908       0.2654       0.0968
(Kanwisher et al., 1997). Combined with the fact that we                   8         0.8088     0.0269       0.1912       0.0269
mainly utilized the low spatial frequency (LSF) information               10         0.8989     0.0241       0.1011       0.0333
to train the RH network before 10th iteration, and full spa-              12         0.8467     0.1042       0.1533       0.0709
tial frequency thereafter, we’ve shown that in our model, face            14         0.8352     0.0533       0.1648       0.0525
recognition has a strong LSF preference. The hypothesis then
is that this strong LSF and RH lateralization of face recogni-
tion is a natural result of the interaction between children’s         The result shows the RH bias for face recognition is ob-
brain development and contrast sensitivity maturity.                vious regardless of rate of contrast sensitivity changes. How-
   Finally, we investigated the relationship between the rate       ever, we can observe a peak in the lateralization at 10 ”years.”
of contrast sensitivity development and RH bias for faces. By       This suggests that there could be an ”optimal” age of CSF
varying the step size of our circular filter to make smaller        maturity with respect to lateralization.
                                                                3739

                          Conclusion                                 Daugman, J. G. (1985). Uncertainty relation for resolution in
In summary, we built a face and object recognition model, us-          space, spatial frequency, and orientation optimized by two-
ing a developmentally-inspired implementation. Our model               dimensional visual cortex filters. Journal of the Optical
suggests that the strong right hemisphere lateralization for           Society of America A, 2, 1160–1169.
face processing can arise from the interaction of two develop-       Ellemberg, D., Lewis, T. L., Liu, C. H., & Maurer, D. (1999).
mental facts: That the right hemisphere matures earlier than           Development of spatial and temporal vision during child-
the left, and that visual acuity increases gradually over devel-       hood. Vision Research, 39, 2325-2333.
opment. We should also note that, as in Dailey & Cottrell’s          Gwiazda, J., Bauer, J., Thorn, F., & Held, R. (1997). Devel-
1999 model, there is a strong effect of task as well. Simply           opment of spatial contrast sensitivity from infancy to adult-
categorizing faces as faces does not lead to right hemisphere          hood: psychophysical data. Optometry and Vision Science,,
specialization. Hence the drive by the infant to individuate           74, 785–789.
its parents, other caretakers, family and friends, leads to the      Hsiao, J. H., Shieh, D. X., & Cottrell, G. W. (2008). Con-
right hemisphere specialization. In addition, as we observe a          vergence of the visual field split: Hemispheric modeling of
mild right hemisphere lateralization more or less for all ex-          face and object recognition. Journal of Cognitive Neuro-
pert experiments, we predict that both the task and the low            science, 22, 2298–2307.
spatial frequency nature of certain objects should contribute        Ivry, R. B., & Robertson, L. C. (1998). The two sides of
to the RH bias. Future work includes doing more analysis of            perception. Cambridge, MA: MIT Press.
the model to discover why the strong RH bias happens for             Jacobs, R. A., Jordan, M. I., & Barto, A. G. (1991). Task
faces, investigating the relationship between CS development           decomposition through competition in a modular connec-
and RH bias in more detail, and extending the model to other           tionist architecture: The what and where vision tasks. Cog-
important classes of stimuli, such as word recognition, which          nitive Science, 15, 219-250.
shows a left hemisphere bias.                                        Jacobs, R. A., Jordan, M. I., Nowlan, S., & Hinton, G. E.
                                                                       (1991). Adaptive mixtures of local experts. Neural Com-
                     Acknowledgments                                   putation, 3, 1-12.
                                                                     Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The
This work was supported in part by NSF grants SMA-
                                                                       fusiform face area: a module in human extrastriate cortex
1041755 and IIS-1219252 to G. W. Cottrell. We thank Gary’s
                                                                       specialized for face perception. Journal of Neuroscience,
Unbelievable Research Unit (GURU) for comments on this
                                                                       17, 4302–4311.
work.
                                                                     Lades, M., Vorbrggen, J., Buhmann, J., Lange, J., Malsburg,
                                                                       C. von der, Wrtz, R. P., et al. (1993). Distortion invariant
                          References
                                                                       object recognition in the dynamic link architecture. Com-
Arundale, K. (1978). An investigation into the variation of            puters, IEEE Transactions on, 42(3), 300–311.
   human contrast sensitivity with age and ocular pathology.         Leat, S. J., Yadav, N. K., & Irving, E. L. (2009). Development
   British Journal of Ophthalmology, 62, 213-215.                      of visual acuity and contrast sensitivity in children. Journal
Atkinson, J., Braddick, O., & Moar, K. (1995). Contrast sen-           of Optometry, 2, 19-26.
   sitivity of the human infant for moving and static patterns.      LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998).
   Vision Research, 17, 1045–1047.                                     Gradient-based learning applied to document recognition.
Bentin, S., Allison, T., Puce, A., Perez, A., & McCarthy, G.           Proceedings of the IEEE, 86(11), 2278–2324.
   (1996). Electrophysiological studies of face perception in        Mayer, M. (1977). Development of anisotropy in late child-
   humans. Journal of Cognitive Neuroscience, 8, 551-565.              hood. Vision Research, 17, 703-710.
Bouvier, S. E., & Engel, S. A. (2006). Behavioral deficits and       O’Reilly, R., & Munakata, Y. (2000). Computational explo-
   cortical damage loci in ceberal achromatopsia. Cerebral             rations in cognitive neuroscience: Understanding the mind
   Cortex, 16, 183–191.                                                by simulating the brain. Cambridge, MA: MIT Press.
Bradley, A., & Freeman, R. D. (1982). Contrast sensitivity in        Peterzell, D. H., Werner, J. S., & Kaplan, P. S. (1995). In-
   children. Vision Research, 22, 953-959.                             dividual differences in contrast sensitivity functions: lon-
Chiron, C., Jambaque, I., Nabbout, R., Lounes, R., Syrota,             gitudinal study of 4-, 6-, and 8-month-old human infants.
   A., & Dulac, O. (1997). The right brain hemisphere is               Vision Research, 35, 961–979.
   dominant in human infants. Brain, 120, 1057–1065.                 Riesenhuber, M., & Poggio, T. (1999). Hierarchical models
Cottrell, G. W., & Metcalfe, J. (1991). Empath: face, gender           of object recognition in cortex. Nature Neuroscience, 2,
   and emotion recognition using holons. In R. P. Lippman,             1019–1025.
   J. Moody, & D. S. Touretzky (Eds.), Advances in neural            Sergent, J. (1982). The cerebral balance of power: confronta-
   information processing systems (Vol. 3, pp. 564–571). San           tion or cooperation? Journal of Experimental Psychology.
   Mateo, CA: Morgan Kaufmann.                                         Human Perception and Performance, 8, 253–272.
Dailey, M. N., & Cottrell, G. W. (1999). Organization of face        Turk, M., & Pentland, A. (1991). Eigenfaces for recognition.
   and object recognition in modular neural network models.            The Journal of Cognitive Neuroscience, 3, 71–86.
   Neural Networks, 12, 1053–1073.
                                                                 3740

