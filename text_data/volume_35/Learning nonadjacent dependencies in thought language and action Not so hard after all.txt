UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning nonadjacent dependencies in thought, language, and action: Not so hard after all.
Permalink
https://escholarship.org/uc/item/1382h0j6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Willits, Jon
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             Learning nonadjacent dependencies in thought, language, and action:
                                                Not so hard after all…
                                            Jon A. Willits (jwillits@indiana.edu)
              Indiana University, Department of Psychological and Brain Sciences, 1101 E. 10th St.
                                                Bloomington, IN 47405 USA
                            Abstract                              based representations are necessary for human
   Learning to represent hierarchical structure and its           cognition (Bever et al., 1968). In early artificial
   nonadjacent dependencies (NDs) is thought to be
   difficult. I present three simulations of ND learning          intelligence, arguments about the limitations of
   using a simple recurrent network (SRN). In Simulation          associative systems led to a focus on symbolic, rule-
   1, I show that the model can learn distance-invariant          based systems (Newell & Simon, 1961).
   representations of nonadjacent dependencies. In                   However, recent research has questioned the need
   Simulation 2, I show that purely localist SRNs can
   learn abstract rule-like relationships. In Simulation 3, I     for rule-based representations of nonadjacent structure.
   show that SRNs exhibit facilitated learning when there         A number of studies have demonstrated or modeled
   are correlated perceptual and semantic cues to the             simple learning of nonadjacent structure in memory
   structure (just as people do). Together, these                 (Cleeremans & McClelland, 1991), goals and event
   simulations show that (contrary to previous claims)
   SRNs are capable of learning abstract and rule-like            structure (Botvinick & Plaut, 2004; visual sequences
   nonadjacent dependencies, and show critical                    (Fiser & Aslin, 2002), and artificial grammars using
   perceptual- and semantics-syntax interactions during           linguistic stimuli (Gomez, 2002; Newport & Aslin,
   learning. The studies refute the claim that neural
   networks and other associative models are                      2004). These results have changed the nature of the
   fundamentally incapable of representing hierarchical           debate concerning the extent to which knowledge of
   structure, and show how recurrent networks can                 nonadjacent dependencies requires a rule-based or an
   provide insight about principles underlying human              association-based explanation. Although there are
   learning and the representation of hierarchical structure.
                                                                  many specific examples of learning or failing to learn
   Keywords:        hierarchical     structure;     recurrent     in particular situations, what is lacking is a general
   connectionist networks; nonadjacent dependencies               account of nonadjacent dependency learning. As a
                                                                  result, the many subfields of cognitive science (such as
                        Background                                linguistics, cognitive psychology, and artificial
   Human concepts, languages, goals, and patterns of              intelligence) continue working on the problem
action are all describable in terms of complex                    separately, without a clear theory or explanation for
hierarchical structures, but our experience of them as            some of the most foundational human behaviors.
inputs, and our production of them as outputs, is often              The current work aims to make progress toward a
arranged in linear strings that unfold over time. A               general account by examining whether a fairly simple
necessary consequence of this transformation of                   neural network model, the simple recurrent network
complex structure into linear strings is that most                (SRN; Elman, 1990) can provide a general model of
human knowledge involves many nonadjacent                         nonadjacent dependency learning. An SRN was used
dependencies, where one element predicts another                  because previous research (Botvinick & Plaut, 2006;
element, but at a distance. These nonadjacent                     Cleeremans & McClelland, 1991; Elman, 1991)
dependencies, whether in thought, language, or action,            suggests that SRNs and other recurrent networks are
enormously expand the computational complexity of                 capable of learning nonadjacent structure. However,
representing the structure of the world.                          there is controversy about whether they can serve as
   In several subfields of cognitive science, difficulty          general solution for all cases, especially those
learning and representing nonadjacent dependencies                involving abstract, rule-like relationships (Marcus,
has generated considerable theoretical controversy. In            2000) or complex interactions between structure and
linguistics, the limitation of simple associative                 meaning (Fodor & Pylyshyn, 1988).
structures has been a cornerstone of arguments for                   In the service of testing the viability of SRNs, the
abstract syntactic structures (Chomsky, 1957). In                 current work had two distinct sub-goals. First, to be a
cognitive psychology, researchers argued that                     general model of nonadjacent dependency learning,
associative mechanisms cannot learn the vast range of             SRNs ought to be able to learn nonadjacent
nonadjacent dependencies in the world, and thus rule-             dependencies of the types that exist in the natural
                                                              1605

world. This includes abstract, rule-like nonadjacent          items is usually fixed, with one intervening item
dependencies, such as learning “distance-invariant”           separating dependent items. However, in many real-
representations (for example, learning the link between       world cases (such as the distance between
the and a noun, independent of how many adjectives            nonadjacently related events in the world, or words in
come between them). Second, SRNs ought to capture             language) the distance between dependent items
behavioral phenomena observed in laboratory                   varies. In fact, learning a “distance-invariant”
experiments, such as facilitated learning in the              representation of a nonadjacent dependency has been
presence of perceptual (Newport & Aslin, 2004) and            considered a critical phenomenon, proving the need
semantic (Willits, Lany, & Saffran, 2013) cues. Close         for a rule-based mechanism.
analysis of model behavior can then shed light on the            In Simulation 1, I attempted to train an SRN to learn
bases of the empirical effects. The following three           distance-invariant representations of nonadjacent
studies test SRNs’ abilities to satisfy these criteria.       dependencies by exposing them to the same
                                                              nonadjacent dependency at multiple spans of distance
                 General Methodology                          between the related items. A second issue of interest
  The three studies shared three core features common         was whether SRNs would show facilitation in learning
in connectionist-modeling approaches (Rumelhart &             longer-distance dependencies if they also had
McClelland, 1986). First, all simulations used sets of        experience with the dependency at a shorter distance, a
interconnected units and weights specifying how               learning effect that has been demonstrated in both
strongly each unit was connected to each other unit.          infants and adults (Lany & Gomez, 2008).
The units in the model were divided into an input
group, used to specify the input stimulus in each             Stimuli and Design
sequence; an output group, used to specify the output            The models in Study 1 were trained on sequences
response (which also served as a prediction about the         where the first element (hereafter the A item) perfectly
next item in the sequence); and a hidden group that           predicted the last element in each sequence (hereafter
mediated between the input and output groups.                 the B item), with the sequences having a number of
Second, the models featured recurrent connectivity,           items (hereafter the X items) intervening between
allowing the model to feed back information about its         them. The sequences were of lengths 2 to 5, resulting
own previous internal state in ways critical to forming       in distances between the A and B items spanning from
internal representations of sequential structure. Third,      zero (adjacent dependencies) to three. There were two
the models all made use of weight-based encoding,             AB pairs (A1 & B1, A2 & B2) and six possible
where the network’s knowledge was encoded in the              intervening X-items (X1…X6). The x-items were
weighted connections between units.                           distributed across trials such that they provided zero
  The goal of the network was to learn a set of weights       predictive value for which B would occur. The only
such that, for any given input, the model’s weights led       way to predict the correct B (B1 or B2) was to have
to activation in the output layer that was a correct          stored which A (A1 or A2) initiated the sequence. The
prediction of the next item in the sequence. During           full set of stimuli used in Study 1 is shown in Table 1.
training, a model was given an input, its output                 Thirty different networks (starting from different
activation was treated as a prediction of what the next       randomly initialized weights) were trained in each of
input would be. This prediction was compared to the           six different training conditions: (1) only Span 0 trials;
target output, and divergence error was calculated            (2) only Span 1 trials; (3) only Span 2 trials; (4) only
across each unit and was used to adjust the weights of        Span 3 trials; (5) a mixture of all Span trials; (6) a
the model, using a version of recurrent                       mixture of all Span trials except Span 3.
backpropagation through time. For each simulation, 30            Over the course of training, networks from all six
different randomly initialized models were trained.           conditions were tested on stimuli from all Span
Each model was trained until it reached a                     conditions (without updating the network weights
predetermined level of overall error, corresponding to        during those test trials), to assess the network’s
optimal prediction performance in the task. The               performance on strings of various spans. Networks
critical test in each simulation was the relative rate of     were compared at points where they had experienced
learning across the different conditions in that study.       the same number of trials, controlling for the amount
                                                              of experience the networks had with each AB pair.
            Study 1: Distance Invariance
  In experiments on nonadjacent dependencies using            Network Architecture
artificial grammars, the distance between dependent              The network had 10 input and output units (one for
                                                          1606

each A, B, and X) and 25 hidden units. A simplification           trained on only a single Span, when tested on the same
of the network architecture is shown in Figure 1.                 Span. Networks showed strong effect of taking longer
                                                                  to learn, as the distance between the dependent items
 Table 1. Stimulus inputs used in Study 1.
 Span 0               Span 1
                                                                  increased. Figure 3 shows the average performance on
 A1 B1                A 1 x1 B 1 A 2 x1 B 2                       items of Span3 distance, for networks (1) trained on
 A2 B2                A 1 x2 B 1 A 2 x2 B 2                       Span3, compared to (2) networks trained on a mixture
 Span 2               Span 3                                      of all the spans (SpanX) and (3) to networks trained on
 A 1 x1 x3 B 1        A 1 x1 x3 x5 B 1    A 2 x1 x3 x5 B 2        all the spans except Span3 (SpanX-3). At the earliest
 A 1 x1 x4 B 1        A 1 x1 x4 x5 B 1    A 2 x1 x4 x5 B 2        stages of training (trials 0-1000), the networks that
 A 1 x2 x3 B 1        A 1 x2 x3 x5 B 1    A 2 x2 x3 x5 B 2        experienced more variability showed slight decrements
 A 1 x2 x4 B 1        A 1 x2 x4 x5 B 1    A 2 x2 x4 x5 B 2        in performance on Span3 test items, relative to
 A 2 x1 x3 B 2        A 1 x1 x3 x6 B 1    A 2 x1 x3 x6 B 2        networks trained on Span3 alone. However, at later
 A 2 x1 x4 B 2        A 1 x1 x4 x6 B 1    A 2 x1 x4 x6 B 2        stages of training, both SpanX and SpanX-3 networks
 A 2 x2 x3 B 2        A 1 x2 x3 x6 B 1    A 2 x2 x3 x6 B 2
                                                                  outperformed the Span3 network on Span3 items.
 A 2 x2 x4 B 2        A 1 x2 x4 x6 B 1    A 2 x2 x4 x6 B 2
                                                                                            1	

                                                                      Correct Output Unit
                                                                                       0.8	

                                                                                       0.6	

                                                                                       0.4	

                                                                                                                       Span0	

                                                                          Activation	

                                                                                       0.2	
                          Span1	

                                                                                                                       Span2	

                                                                                                                       Span3	

                                                                                            0	

                                                                                               t20	

                                                                                  t820	
 t1620	
 t2420	
 t3220	
 t4020	
 t4820	

                                                                                                    Trial	

                                                                  Figure 2. Average SRN performance for networks trained
                                                                  on a single span between nonadjacently dependent items,
                                                                  when tested on items of the same span. The y-axis is the
                                                                  network’s softmax activation level of the correct B unit,
Figure 1. A simplified depiction of the network architecture
                                                                  when the network was presented with the preceding X item.
used in Study 1. The actual model had 8 X-units (X1…X8)
                                                                            1	

                                                                           Correct Output Unit
and 25 units in the hidden layer.
Hypotheses                                                                                       0.8	

  Three main hypotheses were under investigation.
                                                                                                 0.6	

First, do networks trained on longer-distance
                                                                               Activation	

dependencies (bigger Spans) take longer to learn the                                         0.4	
                         Span3	

dependency, as people do? Second, do networks
                                                                                                                            SpanX	

trained in more variable conditions (Conditions 5 & 6)                                           0.2	

learn more slowly due to increased variability and                                                                          SpanX-3	

                                                                                                    0	

noise? Or do they, like people (e.g. Lany & Gomez,
                                                                                                       t20	

                                                                                    t820	
 t1620	
 t2420	
 t3220	
 t4020	
 t4820	

2008) show facilitated learning of more distant
                                                                                                      Trial	

dependencies due to experience with shorter
dependencies? Third, are SRNs capable of learning a               Figure 3. Average SRN performance for networks trained
                                                                  on Span 3, a mixture of all Span conditions (SpanX), or all
distance-invariant representation? Specifically, do the
                                                                  Span conditions except Span3 (SpanX-3).
networks that are trained only on Spans of 0, 1, and 2,
predict the correct B item on Span 3 trials, even                   Thus, in Study 1 I show that SRNs display three
though they have never before experienced the                     critical features of human learning: (1) they show
dependency at that distance?                                      increased difficulty with longer dependencies; (2) they
                                                                  show facilitated learning when they have had
Results & Discussion                                              experience with shorter-distance variations of that
  Figure 2 shows the average SRN performance                      dependency; (3) they learn distance-invariant
predicting the correct B (the network’s activation level          representations of nonadjacent dependencies, making
for the correct B output, on X trials) for networks
                                                               1607

the correct prediction for Span3 items even in the
SpanX-3 condition, where they had no training with
dependencies of that span. This evidence that SRNs
can learn a distance-invariant representations of
nonadjacent dependencies is a critical finding, as it
undercuts one of the fundamental arguments against
association-based representations of knowledge, and in
favor of rule-based explanations of cognition.
               Study 2: Abstract Rules
  Marcus et al. (1999) performed a learning study with
infants, where the infants where played sequences of
syllables following either an ABB repetition pattern
(e.g. “go-la-la”) or an ABA alternation pattern (e.g.
“go-la-go”). After hearing many examples repeated
multiple times, infants then heard novel test sequences
that either followed or violated that rule, and showed      Figure 4. A depiction of the architecture in Study 2. The
                                                            actual model had 12 A- and B-units and 25 hidden units.
evidence of discriminating the legal and illegal
sequences. Marcus argued that because no items were         Figure 4) were trained on the exact design from
co-present at training and test, associative accounts       Marcus et al., shown in Table 2. During the first
were inadequate and only rule-based models could            training phase, models were trained in one of two
explain behavior. Marcus (2000) further argued that         conditions: (1) an ABA condition, where the first item
SRNs (like in Figure 4), could not in principle account     perfectly predicted the last item, and predicted that it
for this finding. A number of researchers (Altmann &        would be repetition of itself; (2) an ABB condition,
Dienes, 1999; Christiansen & Curtin, 1999) presented        where the middle item perfectly predicted the last
distributed SRN models of this phenomenon, where            item, again a repetition of itself. These ABA and ABB
microfeatures (but not items) were co-present at            strings were composed of six possible A’s and B’s,
training and test. Marcus, however, argued that             which all occurred in all possible combinations, thus
resorting to such microfeatures was proof that SRNs         making all transition probabilities uninformative, and
and other network models are fundamentally incapable        leaving the item-independent ABA or ABB rule as the
of learning abstract, algebraic rules, which some           only way to correctly predict whether the final element
believe to be fundamental to human cognition.               should be an A or B. The models were then given a
  In Study 2, I show that a simple, localist SRN            second training phase, where they were trained on a
without any distributed microfeature information            new ABA or ABB sequences using new A and B
learns to represent abstract, rule-like structure.          items, and tested to see if they learned these sequences
Marcus’s (2000) characterization of SRNs was correct;       more quickly if the new rule was consistent with the
a localist SRN trained in the manner he described           rule on which they had been trained in phase 1.
cannot show transfer of the rule-like knowledge. That
                                                            Table 2. Stimulus inputs used in Study 2.
is because the network learns (during the initial
                                                            ABA1          ABB1             ABA2              ABB2
training) that the elements in the test items never
                                                            A 1B 1A 1     A 1B 1B 2        A 7B 7A 7         A 7B 7B 7
occur, and thus their weights are set to zero, making       A 1B 2A 1     A 1B 2B 2        A 7B 8A 7         A 7B 8B 8
them unable to make use of any information about the        A 1B 3A 1     A 1B 3B 3        A 7B 9A 7         A 7B 9B 9
previous items’ sequential structure that may have          …             …                …                 …
been learned and stored in the network’s recurrent or       A 1B 6A 1     A 1B 6B 6        A7B12A7           A7B12B12
output connections. However, there is no reason to          …             …                …                 …
restrict training in this way; one could instead allow      A 6B 6A 6     A 6B 6B 6        A12B12A12         A12B12B12
the model to continue learning during the test phase,       Results & Discussion
and again determine whether the model learns about             The results from Study 2 are shown in Figure 5.
the rule consistent test strings more quickly than the      When the model was allowed to continue learning
rule-violating ones.                                        during the second training phase, it shows facilitated
Stimuli and Design                                          learning if the new items follow the same structural
The models in Study 2 (using the architecture in            sequence as the items in the first phase. Follow-up
                                                        1608

analyses of the network’s weight configurations show                                                 The question, then, is whether SRNs also exhibit
this is because the network’s recurrent and output                                               facilitated learning from correlated cues, thus
weights are effectively learning the abstract structural                                         broadening their appeal as a general model of
order of the sequence. Because of this, if the new set                                           dependency learning, and whether they provide any
of items are following the same structural rule, all the                                         insights as to why learning might be easier under these
network needs to do is learn to adjust the input weights                                         circumstances. This was investigated in Study 3.
for the new items so that they work well with the
                                                                                                 Stimuli and Design
already-learned recurrent and output weights.
                                                                                                      The models in Study 3 were trained using the
                            1	
                                                                 architecture in Figure 4. This architecture allowed for
   Correct Output Unit
                                                                                                 tests of whether correlated similarity structure affected
                         0.8	

                                                                                                 learning by allowing each input to activate two units:
                         0.6	
                                                                  (1) one item-specific unit (either an AN, XN, or BN),
                                                                                                 where the letter refers to which category the item is
       Activation 	

                         0.4	
                                                                  from); (2) a category-specific unit (either CategoryA,
                                                                                                 CategoryX, or CategoryB), where the category unit
                         0.2	
                                      Rule Consistent	
          turned on for all inputs that came from that category.
                                                                     Rule Inconsistent	

                            0	

                                   t10	
   t110	
   t210	
   t310	
   t410	
   t510	

                              Trial	

Figure 5. Average SRN performance during the second
stage of learning in Study 2.
  These findings have very significant implications, as
they (along with the findings in Simulation 2), refute
claims that associative models are not capable of
learning the abstract and rule-like knowledge that
seems fundamental to human cognition.
 Study 3: Perceptual/Semantic Bootstrapping
     Previous research on nonadjacent dependencies
has mainly focused on learning to represent sequences
of events, actions, or words independent of other cues                                           Figure 6. A depiction of the architecture used in Study 3.
about those entities, such as perceptual or semantic                                             The actual model had 25 hidden units.
features or similarity. Learning structure in such a                                                 The models were trained in one of three conditions
purely symbolic way would be hard. However, there is                                             (shown in Table 3). In the Consistently Same
no reason to limit attention to this type of                                                     condition, the nonadjacently dependent items were
impoverished input, which is uncharacteristic of                                                 always from the same category (e.g. the first item in
naturalistic conditions.. Studies that have examined the                                         each sequence would activate the A1 unit and the
use of correlated perceptual cues (Newport & Aslin) or                                           CategoryA unit, and third item would activate the A3
semantic cues Willits et al.), have found that under                                             unit and the CategoryA unit). In the Consistently
these circumstances nonadjacent dependencies are                                                 Different condition, the nonadjacently dependent items
significantly easier to learn. For example, Willits et al.                                       were consistently from opposite A & B categories. In
found that when the items to be learned are from the                                             the Inconsistent condition, the dependent items’
same category (e.g. nonadjacently related items both
foods), both infants and adults learn the dependency                                             Table 3. Stimulus inputs used in Study 3
more easily. Learners even learn the nonadjacent                                                   Consistently       Consistently Different    Inconsistent
dependency if the two words form a consistent                                                     Same Category             Categories           Categories
mapping between categories (e.g. across set of                                                      A 1 Xn A 3               A 1 Xn B 3           A 1 Xn A 3
                                                                                                    A 2 Xn A 4               A 2 Xn B 4           A 2 Xn B 4
nonadjacent pairs, foods are always paired with an
                                                                                                     B 1 Xn B 3              B 1 Xn A 3           B 1 Xn B 3
animals). These findings are critical, because many of                                               B 2 Xn B 4              B 2 Xn A 4           B 2 Xn A 4
the nonadjacent dependencies people need to learn
                                                                                                 categories were not predictable in terms of the other
have these kinds of correlated perceptual and semantic
                                                                                                 unit in the dependency. Across training trials, the
attributes.
                                                                                              1609

models were compared to see if any of the conditions                                            References
showed facilitated learning.                                               Altmann, G.T.M. and Dienes, Z. (1999). Rule learning
                                                                             by seven-month-old infants and neural networks.
Results & Discussion
                                                                             Science. 284, 875.
  The results for Study 3 are shown in Figure 7. SRNs
                                                                           Bever, T. G., Fodor, J., A., & Garrett, M. (1968). A
showed facilitated learning in both consistent
                                                                             formal limitation of associationism. . In T. R. Dixon
conditions, but not the inconsistent conditions, results
                                                                             & D. L. Horton’s Verbal Behavior and General
similar to behavioral experiments with infants and
                                                                             Behavior Theory. Englewood Cliffs: Prentice Hall.
adults. Follow-up analyses of network behavior show
                                                                           Botvinick, M., & Plaut, D.C. (2004). Doing without
this is because the network has an easier time learning
                                                                             schema hierarchies: A recurrent connectionist
the category sequences, an intriguing hypothesis to test
                                                                             approach to normal and impaired routine sequential
in future work with human learners.
                                                                             action. Psychological Review, 111, 395– 429.
                        1	

                                    Consistently Same	
                   Chomsky, N. (1957). Syntactic Structures. The Hague.
  Correct Output Unit
                    0.8	
          Consistently Different	
              Christiansen, M. H., & Curtin, S. L. (1999). The power
                                    Inconsistent	
                          of statistical learning. In Proceedings of the twenty-
                    0.6	

                                                                             first conference of the Cognitive Science Society.
                                                                           Cleeremans, A., & McClelland, J. L. (1991). Learning
      Activation	

                    0.4	

                                                                             the structure of event sequences. Journal of
                    0.2	
                                                   Experimental Psychology: General, 120, 235-253
                        0	
                                               Elman, J. (1990). Finding structure in time. Cognitive
                           t40	

                 t840	
 t1640	
 t2440	
 t3240	
 t4040	
 t4840	
        Science, 14, 179-211.
                                   Trial	
                                Elman, J. (1991). Distributed representations, simple
Figure 7. Average SRN performance for the three training                     recurrent networks, and grammatical structure.
conditions in Study 3.                                                       Machine Learning, 7, 195-225.
                                        Conclusions                        Fiser, J., & Aslin, R.N. (2002). Statistical learning of
  Nonadjacent dependencies are a necessary                                   higher-order temporal structure from visual shape-
consequence of experiencing a hierarchically                                 sequences. Journal of Experimental Psychology:
structured world though a linear sequence of inputs                          Learning, Memory, and Cognition, 28, 458-467.
and actions. The current studies support the notion that                   Fodor, J., & Pylyshyn, Z. (1988). Connectionism and
SRNs and other recurrent networks are viable models                          cognitive architecture: A critical analysis. Cognition,
of the representation of hierarchical knowledge. They                        28, 3-71.
are capable of learning to represent abstract, rule-like                   Gómez R.L. (2002). Variability and detection of
structure (Study 1 & 2), and they show critical                              invariant structure. Psychological Science, 13, 431-36.
learning effects that people exhibit, such as the                          Lany, J., & Gómez, R. (2008). Twelve-month-old
interaction between structure and similarity (Study 3).                      infants benefit from prior experience in statistical
  In addition, these simulations also provide evidence                       learning. Psychological Science, 19, 1247-1252.
for the hypothesis that many learning situations that                      Marcus, G. F., Vijayan, S., Bandi Rao, S., and
are thought to be especially difficult (of which the                         Vishton, P. M. (1999). Rule-learning in seven-
learning of nonadjacent dependencies is but one                              month-old infants. Science, 283, 77-80.
example) are only difficult because the problem has                        Marcus, G. F. (2000). Rethinking eliminative
been underepresented. Many cues learners might use                           connectionism. Cognition, 37, 243-282.
are stripped away in overly controlled experiments,                        Newell, A. & Simon, H. A. (1972). Human Problem
making the problem harder than it is in the real world.                      Solving. Prentice Hall.
Complexity is not the same thing as noise, if that                         Newport, E. L., & Aslin, R. N. (2004). Learning at a
complexity provides learners with useful cues to the                         distance: I. Statistical learning of nonadjacent
structure of the world.                                                      dependencies. Cognitive Psychology, 48, 127-162.
                                                                           Rumelhart, D. E., McClelland, J. L., & the PDP
                                    Acknowledgments                          research group. (1986). Parallel distributed
This work was funded by NICDC F31-DC00936-02 to                              processing: Volume I. Cambridge, MA: MIT Press.
Jon Willits. The work received much useful input from                      Willits, J. A., Lany, J., & Saffran, J. R. (in review).
Mark Seidenberg, Jenny Saffran, Maryellen                                    Semantic cues facilitate nonadjacent dependency
MacDonald, and Timothy Rogers, and Jessica Montag.                           learning in infancy.
                                                                        1610

