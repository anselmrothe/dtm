UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gesture and Language Production in Communication through Bar Graphs

Permalink
https://escholarship.org/uc/item/4523s8zg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Alacam, Ozge
Habel, Christopher
Acarturk, Cengiz

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Gesture and Language Production in Communication through Bar Graphs
1
1

Özge Alaçam (alacam@informatik.uni-hamburg.de)

Christopher Habel (habel@informatik.uni-hamburg.de)
2

1

Cengiz Acartürk (acarturk@metu.edu.tr)

Department of Informatics, University of Hamburg, Hamburg/Germany
2
Cognitive Science, Middle East Technical University, Ankara/Turkey

Abstract
Bar graphs and line graphs are commonly used ways of
graphical communication. Due to the difference in their
perceptual
visuo-spatial
properties,
they
facilitate
comprehension of different events. Bar graphs are commonly
used in the domain of precipitation although the data
intrinsically carry information that is averaged over long time
spans. In this study, we investigate how the presence of
incongruence between consecutive graph pairs influences
conceptualization of the represented information about
precipitation. For this, we analyzed gestures and verbal
descriptions produced by the participants as indicators of
event conceptualizations. The results of the experimental
investigation reveals that when incongruent graph pairs are
presented, the participants show tendency to produce
directional gestures that accompany the verbal descriptions of
the specific regions represented by one/two bars, indicating
that bar graphs presented in consecutive order facilitates
comprehension of trend information as well as of discrete
entities. Additionally, the presence of incongruence seems to
enhance the production of comparative words accompanied
with non-directional gestures.
Keywords: Gesture production; language production; bar
graph comprehension; multimodal communication

Visualization – Bar and Line Graphs
The primary goal of visualizing data is to (re-)present them
in a format more suitable for using them in thinking,
problem solving and communication (This view is taken
implicitly or explicitly in most seminal publications on
graphs, as well as on visualization during the last decades,
see, e.g., Tufte 1983, Kosslyn 1989, 2006, Hegarty 2011).
Line graphs and bar graphs are successful means to present
data, both in the task of analyzing the data and in the task of
communicating the results of data analysis. Communicating
visualized data using bars or lines is used extensively in
scientific publications, textbooks, magazines and newspapers; Zacks, Levy, Tversky, & Schiano’s (2002) study on
the use of graphs in the print media shows that line graphs
and bar graphs are the dominant, i.e. most frequently used,
types of graphs in addressing non-experts in communication
through graphs.
The primary gain in using graphs is not to make
individual data points visible but to provide visual access to
relations between data points (‘x1-y1 has a larger y-value
than x2-y2’) or to second-order entities as ‘trends’. This
advantage can be ascribed to humans’ pattern perception
processes, in particular visual chunking (see, Shah, Mayer

& Hegarty, 1999). Beyond these commonalities, there seem
to be functional differences between bar graphs and line
graphs. Zacks and Tversky (1999) investigate the bar–line
message correspondence, which considers the systematic
relations between the type of graph used and the type of
message intended to be communicated. Zacks and Tversky
point to a preferred “use of bar graphs to depict comparisons
among discrete data points, and line graphs to depict trends”
(p. 1073). On the other hand, participants in their
experiments had a strong tendency for relational
descriptions (e.g., “A is higher than B”) after
comprehending bar graphs and for process-oriented secondorder descriptions as ‘trends’ (e.g., “X increases from A to
B”) in the of line graphs (p. 1078). Shah, Meyer and
Hegarty (1999) report—with respect to these tendencies—a
comparable view, but in presenting their perceptual
organization hypothesis they lay an additional focus on
Gestalt principles realizable in the graph types in question.
In addition to text-graphics documents, in many
professional communication settings as well as in classroom
settings, graphs, spoken language, and often gestures,
accompany each other forming multimodal communication.
In dynamic communication of this type, often recipients
have to integrate messages communicated by a sequence of
graphs. The present study investigates participants’ verbal
descriptions of pairs of succeeding bar graphs and the
gestures produced during these descriptions. The first graph
of each pair depicts averages (monthly precipitation over
three decades) whereas the second graph depicts instances
(monthly precipitation of a specific year). Due to the
average-instance
constellation,
commonalities
and
differences, which we regard as ‘incongruences’, between
the graphs play a major role in comprehending the graphs
and in following production of verbal descriptions; in this
setting the within-the-bar bias (Newman & Scholl, 2012)
did not occur.

Gesture and Language
The studies on gesture-language interaction are mainly
based on the assumption that concepts are sensorimotor, by
emphasizing that they are grounded in physical world and
based on perceptual experience (Barsalou, 1999; Garbarini
& Adenzato, 2004). There are several frameworks that
investigate gestures from various perspectives, but all of
them agree on that gestures rely on spatial representations.
According to the GSA framework (‘Gesture-as-simulated-

1714

action’, Hostetter & Alibali, 2008), one of the frameworks
that focus on how gestures are produced, gestures are
byproduct of speech. In particular, linguistic planning
involves simulation of visuo-spatial events; this activation
during articulation is considered as a source of speech
accompanying gestures. Another framework, that is closely
aligned with the GSA framework and that focuses on how
gesture and language production are integrated is the
“Interface Hypothesis” (Kita & Özyurek, 2003). The
preparation for language production requires organization of
rich and comprehensive information into small packages
that contain appropriate amount of informational complexity
within a processing unit. According to the “Interface
Hypothesis”, this processing unit may correspond to a
clause for speech production, and the contents of a
representational gesture are affected by the organization of
these information-processing units, which are prepared for
speech production. Therefore this close relationship between
the gestures and language makes gestures an effective tool
in the assessment of the reader’s conceptualization of event,
which is simultaneously described verbally (GoldinMeadow & Beilock, 2010).
Although the interaction between language and gesture
has been investigated for the past several decades in a
variety of domains (Goldin-Meadow, 2003; Hostetter &
Alibali, 2008; Hostetter & Sullivan, 2011; McNeill, 1992;
2005) specific investigations of graph comprehension in
interaction with language and gesture, has been one of the
scarce topics in the field of multimodal interaction. Gestures
and graphical communications are visuo-spatial modalities,
and they share similar perceptual visuo-spatial features to
convey meaning such as quantity, direction and relations.
(Tversky, 2011). Therefore during describing a visualization
with an accompanying gesture, the places (or punctual
events in the domain of our interest) become “fleeting
positions” while marks and forms on the visualization
become “fleeting actions” (Tversky et. al., 2009). Following
this idea originated from the resemblance between two
modalities, the vocabularies of gestures, speech and
diagrams can be considered as parallel (Tversky, 2011).
For instance, within the context of communication
through graphs, a fluctuating increase in a line graph may be
verbally described by the term “increase” and it may be
simultaneously accompanied by a gesture that represents the
fluctuation in the increase. One of the studies focused on
communication through line graphs (Acartürk & Alaçam,
2012), showed that the perceptual features of the annotation
that highlights the event presented in the sub-region of the
graph (e.g., a graphical cue such as an arrow) have an effect
on the conceptualization of the event, and this effect is
observable in the gestures produced by graph readers. The
results of this study indicated that in order to emphasize
processes (e.g., increase, decrease) more vertical and
diagonal gestures were produced by humans, whereas more
pointing gestures were produced for emphasizing punctual
states (e.g., a peak).

To sum-up, gestures can be used as a tool to assess how
the graph reader interprets the graph and conceptualizes the
event represented by the graph, because gestures provide
additional information which is aligned with the visuospatial aspects of the graphical communication. Therefore
gesture analysis helps to detect the hard-to-encode
information and disambiguates, that are generally
highlighted with the presence of accompanying gestures.
In the domain of bar graph comprehension and in
communication through bar graphs, differences in gesture
production are expected due to perceptual properties of bar
graphs that contrast to those of line graphs. Bar graphs
enhance comprehension of discrete events, since each bar on
the graph perceptually corresponds to a single entity in the
domain of discourse, while line graphs facilitate
comprehension of trends. On the other hand, although the
perceptual properties of graphs are crucial in the
conceptualization, the comprehension is still highly
dependent on their conceptual properties too (Zacks &
Tversky, 1999). Our goal in this study is to investigate the
conceptualization of events that belong to average data (in
the domain of precipitation, which is frequently represented
with bar graphs), by analyzing the gestures produced during
the description of the represented events.
We hypothesize that relations between events of the same
domain that are represented with the same graph type (bar
graphs) may be conceptualized differently when a
perceptual change regarding small areas on the graph (in the
case of incongruence) is introduced. In our experimental
design, comparisons between regions of two consecutive
graphs are required, rather than a comparison between two
discrete entities in one graph. Therefore, in addition to
discrete comparisons, trend evaluation may also play a
major role during comprehension. Moreover, the differences
in event conceptualization are examined by analyzing the
speech accompanied gestures produced by the graph readers
during the verbal description.

Experiment
Participants, Materials and Design
Twelve participants (university students at the Department
of Human Computer Interaction, University of Hamburg, 4
female, Mean age = 24.2, SD = 3.21) participated in the
study. The experiment was conducted in German, the native
language of all participants.
Each participant was presented six precipitation graph
pairs (two additional pairs of the graphs were employed for
the familiarization part). The graphs represented average
precipitation data of various cities. In the first graph of each
graph pair, a bar graph that represented the monthly
precipitation data average for the time period between 1970
and 2011 was shown for 10 seconds on a computer screen
(the data were retrieved from Turkish State Meteorological
Service). After the graph disappeared, the participant was
asked to present a single-sentence verbal description of the
first graph to a hypothetical audience. After then, the second

1715

graph of the graph pair was presented. The second graph
represented monthly precipitation data for the specific year
(2011 for all stimuli) for the same city presented before,
again for 10 seconds. The participant was asked to give a
verbal description by taking into account both the first graph
and the second graph. This procedure was applied for 6
graph pairs. The first graph in each graph pair was always
the representation of the monthly precipitation data
averaged over 1970-2011, whereas the second graph was
always the representation of the monthly precipitation data
for 2011 only (see Figure 1 and Figure 2). Participants’
spontaneous gestures for 6 precipitation-graph pairs were
video-recorded. The participants were informed only about
producing verbal descriptions, therefore the gestures
produced by the participants were spontaneous gestures.
The second within-subject condition in the experiment
design was the congruency between the two graphs in each
graph pair. In three graph pairs, the second graph was the
same as the first graph, thus leading to a congruent graph
pair (Figure 1). In the other three graph pairs, the second
graph involved deviant bars (compared to the first graph),
thus leading to an incongruent graph pair (Figure 2). The
deviant bars were obtained by either increasing or
decreasing the value of two/three bars drastically. The
motivation for testing the congruency effect was to
investigate how conceptualization differed when the
congruency between the two related stimuli was
systematically changed, even in the same domain and same
graph type.

participants produced 144 sentences in verbal descriptions,
547 time period phrases in the sentences and 165 gestures
that accompanied the verbal descriptions.

Gesture Annotation. The coding scheme was based on
both McNeil’s (2005) semantic gesture classification and
syntactic features. The ANVIL software tool was employed
for gesture annotation. In the first classification, the gestures
were categorized according to their semantic classifications,
such as beat gestures and representational gestures. Then
each representational gesture was classified in terms of its
directionality:
non-directional,
and
directional
(vertical/diagonal/horizontal).
According
to
this
classification, the hand movements conducted in small
space without having any directed trajectory were
categorized as non-directional gesture, whereas the hand
movements with aimed trajectory on the air were classified
as directional gestures.

Spoken Language Transcription. The sentences
produced by the participants were transcribed and then the
parts of the sentences were segmented into phrases. After
this process, the phrases, which referred to temporal
information on the graph, were classified into two
categories in terms of the size of time interval. The time
phrases that referred to multiple bars (such as in “summer”
and “towards to winter”) were classified into the “longterm” category. The second group covered the time phrases
for specific time intervals (such as “in May” or “in July and
August”). Finally, the phrases that referred to the previous
graph in the comparative context were classified into the
“comparatives” category.

Results

Figure 1: Sample graph for the average data (left) and the
data for “instance” year with congruent graph (right)

The results revealed similar time spent for the description
for the overall-data graph (i.e., the graph that represented
monthly data averaged over 1970-2011, M = 30.2 seconds,
SD = 10.6) and for the specific-year graph (M = 30.6
seconds, SD = 11.3; t = -0.38, p > .05. As for the
congruency, the participants spent similar time both for the
congruent graphs (M = 28.4 seconds, SD = 10.9) and for the
incongruent graphs (M = 32.8, SD = 11.7; t = -0.93, p >
.05). Sample pairs of participants’ verbal descriptions are
presented in Table 1 and Table 2 below.
Table 1: Sample description for a congruent graph
(translated from German)
Precipitation averaged over 30 years:
Looking at the past 30 years in Antalya there was almost
no rain in the months of summer, but instead very very
much in winter, it falls and then rises from the winter
to the summer very strongly, in August I believe no
rain at all, in the adjacent months only very very little.

Figure 2: Sample graph for the average precipitation
data (left) and the data for “instance” year with anomaly
in the distribution (right)

Coding
The main experiment session consisted of six pairs of
stimuli, all presented to each participant. Twelve

1716

The overall results that focuses on the difference between
overall and instance graphs showed that the participants
tend to produce the same amount of gesture for the first
stimuli corresponding to overall precipitation amount for 30
years (N=64) and for the second stimuli corresponding to
specific year 2011 (N=82), χ2(1) = 2.22, p > .05.
Additionally, the number of non-directional gestures (N=78)
and directional gestures (N=68) produced during the course
of verbal descriptions were similar. see Table 4 (χ2(1) =
.65, p > .05).

The specific year:
Also in Antalya 2011 reflects the past 30 years, because
here we also have relatively little rain in the summer
and in contrast very much in the winter and it is a quite
steady decline and increase in the months in between.
Table 2: Sample description for an incongruent graph
(translated from German)
Precipitation averaged over 30 years:
In this graph, again in June, July and August, in the
months of summer we have the least precipitation and it
increases from August to September/December and
January, where the highest point is reached and from
January it decreases again slightly until it reaches the
lowest point.
The specific year:
In this graph it is striking, that does not look like the
average at all, because at the point where the lowest
point should be we now have a little deflection upwards
with much precipitation and also have less precipitation
than expected in the months where a lot of rain falls.

Table 4: Number of gestures produced during the verbal
description for “Overall” and “Instance” Graphs (NDir:
Non-Directional, Dir.: Directional)

Overall
Instance

In order to understand the underlying differences and
similarities induced by the congruency, the speech parts
accompanied by the gestures were focalized. The gestures
were classified according to temporal information (“specific
time” and “long term time” interval) referred in the
accompanied speech parts as explained in the “Coding”
section. Eight of 12 participants (2 female, Mean age =
24.3, SD = 0.98) produced gestures during verbal
description of the graphs. Five of those eight participants
produced representational gestures (N=146) classified
according to scheme presented above. Two coders analyzed
and classified the data. Interrater reliability between coders
was calculated by Cohen’s kappa. The results revealed an
agreement value of .77. According to Landis and Koch
(1977), a value above .61 indicates substantial interrater
agreement. The results of Chi-square test revealed that
during the congruent graph description, the gestures
accompanied to “specific time” phrases (N=25) were
observed more than that for “long term” phrases (N=7),
χ2(1) = 10.1, p < .05. On the other hand, in the description
of the incongruent graphs, similar usage of gesture
accompanied “specific” (N=30) and “long-term” phrases
(N=20) was observed (χ2(1) = 2.0, p > .05). The production
of non-directional and directional gestures were similar
within congruency conditions, see Table 3.

Specific
Long-Term

4

3

Incongruent
NDir.
Dir.
19
11
9

Incongruent
NDir.
Dir.
18
10
28
22

Since the congruency is always presented in the second
stimulus (“Instance” graph), more detailed analysis was
conducted on the scores of second stimulus (see Table 4).
The results of a Chi-Square test, conducted to compare the
overall number of gesture accompanied time phrases across
different congruency groups, showed that more gestures
were produced during incongruent graph description (N =
50) than that during congruent graph description (N = 32),
χ2(1) = 3.95, p < .05. On the other hand, the results of the
test, which compared the number of directional gestures (N
= 40) and non-directional gestures (N = 42) that
accompanied the phrases, revealed no significant difference,
χ2(1) = .05, p > .05. Similarly, there was also no difference
within the incongruent graphs (χ2(1) = .72, p > .05) and
congruent graphs (χ2(1) = .50, p > .05) in terms of the
directionality of the gesture. However, in the description of
the incongruent graphs, the participants produced more
directional gestures compared to their previous description
about overall data, indicating that incongruence on the data
had a positive effect on the directional gesture production,
(χ2(1) = 4.5, p < .05, while it had no effect on the
production of non-directional gestures (see Figure 3). For
the description of the congruent graphs, no such a
significant difference in the production of non-directional
and directional gestures was observed.

Table 3: Number of gestures classified w.r.t. temporal
information (NDir: Non-Directional, Dir.: Directional)
Congruent
NDir.
Dir.
10
15

Congruent
NDir.
Dir.
18
18
14
18

*	  	  	  	  	  

Figure 3: Gestures that accompany the description of the
overall graph and the incongruent graph

11

1717

More detailed analysis on the sub-regions with the
incongruent data revealed the source of the increase in the
directional gestures. The results of Chi-square test showed
that for the description of the incongruent regions, more
directional gestures (N = 12) were observed than nondirectional gestures (N = 3), χ2(1) = 5.40, p < .05. See Table
5 for the examples of produced sentences and Figure 2 for
the corresponding graphs. These regions represented with
one or two bars on the graph, their descriptions were
accompanied with directional gestures.
Table 5: Directional Gestures that accompany the
descriptions for the regions that present incongruence
(translated from German)
Overall Rainfall over 30 years (see Figure 2 – Left for
the corresponding graph):
Ok, so here we have seen in the first months the
rainfall was quite … (non-directional), while in the
months of summer relatively fast, quite low at about 20
and within the year the rainfall increased really
significantly to about 30 I assume (directional).
The specific year (see Figure 2 – Right for the
corresponding graph) :
We have seen, that in this year the rainfall came off a
little more steady (horizontal). They have decreased
from month to month and overall in the first months
came off smaller (diagonal) in general but in the
months of summer the rainfall increased a little, but not
so much, as now the rainfall in the former months
have won (non-directional), especially not this time
relatively steady decreasing from the average rainfall
(diagonal) and in the end again there was a little
increase.
Additionally, the verbal data that belongs to twelve
participants (regardless of the accompaniment of the
gesture) were also analyzed in order to examine the use of
comparatives across the two congruency conditions. For
each participant, the number of descriptions that referred to
the overall graph at least once was counted for each
congruency condition. The analysis showed that the
participants tend to refer to the first graph in the graph pair,
the overall precipitation graph, more in the description of
the incongruent graph (M = 2.4, SD = 1.0) than in the
description of congruent graph (M = 1.9, SD = 1.1), Z = 2.12, p < .05, indicating that the incongruence between the
overall graph and the specific-year graph enhanced the
production of the comparative phrases. A similar pattern
was observed for the comparatives accompanied by
gestures: more comparative phrases in the incongruent
graph description (N = 14) were accompanied by a gesture
than in the congruent graph description (N = 5), χ2(1) =
4.26, p < .05. Additionally, the comparative speech parts are
mainly accompanied with the non-directional gestures
(N=14), χ2(1) =5.56, p < .05. 	  

Discussion
The goal of the experimental investigation was to analyze
the role of congruency between two graphs in a set of graph
pairs in conceptualization of bar graphs. The first graph in
the graph pair was always a monthly representation of 30year average of precipitation data. The second graph was
always a monthly representation of precipitation for a
specific year. The results were analyzed in terms of the
analysis of verbal descriptions of the participants, as well as
the gestures produced by the participants. The results of the
experimental investigation revealed that, in general, the
participants spent similar amount of time to describe the
congruent and incongruent situations with respect to overall
graph (i.e., the graph which represented monthly
precipitation data averaged over 30 years). On the other
hand, a more frequent use of comparatives was observed in
the incongruent condition during the course of the
description of the second graph in the graph pair. This
finding indicates that the participants noticed the difference
between the overall graph and the specific-year graph and
they found this anomaly worth mentioning in their verbal
descriptions. Moreover, the comparatives were accompanied
by non-directional gestures that aimed at referring to the
previous graph in the graph pair.
As for the production of gestures, there was no difference
in the type of the gestures that accompanied the speech
parts. However, while gestures during congruent graph´s
description mainly were correlated with specific time
phrases, during incongruent graph´s description, gestures for
“specific” and “long term” phrases were similar. This may
indicate that unlike congruent graphs´ description,
description of two relational but incongruent events
represented with bar graphs requires “as-a-whole”
comprehension of the events as well as focusing on the
specific regions of the graphs. Additionally, the number of
gestures produced during incongruent graph description was
higher than that during congruent graph description.
Furthermore,	   when the incongruence was presented,
differences in the event description between the incongruent
graph and the overall graph were observed in the production
of directional gestures: the participants produced more
directional gestures for the specific-year graph compared to
the overall graph, whereas there was no significant
difference in the production of non-directional gestures. The
increase in the number of directional gestures was
considered as a likely indicator of a different
conceptualization. Therefore, a more detailed analysis was
conducted on the small region in the graph where the
incongruence was presented. In the descriptions of those
regions, the graph readers tended to use more directional
gestures, indicating that those regions were interpreted as a
trend, although those regions referred to a specific time
period on the bar graph representation.

1718

Conclusion and Future Work
In this study, we investigated the conceptualization of
events by focusing on the gesture production and verbal
descriptions in the precipitation domain represented by bar
graphs. Although the previous research on graph
comprehension provides evidence that bar graphs are
preferred to emphasize discrete entities, rather than trends,
experts in specific domains, in our case meteorology,
frequently use them. As the current study demonstrates as
well, bar graphs are highly effective to communicate trends.
The specific regions, where the incongruence is presented,
are conceptualized as trends and the descriptions are
accompanied by directional gestures. The perceptual
properties of bar graphs that emphasize the entities may be
helpful to catch the incongruence, but it also seems that the
events are interpreted as “processes”, similar to typical
comprehension of the events represented by line graphs
(Zacks & Tversky, 1999). In order to understand the
underlying mechanism in more detail, our future research
will address the preference of the terms used to emphasize
two different events, “process” such as increase or
fluctuating and “state” such as peak, maximum, and their
co-existence with the gestures in the case the congruency
was systematically changed. Moreover, applying same
experimental design with line graphs will also shed light
into the effect of graph type on the conceptualization of the
event that requires extrinsically comparison and also
requires intrinsically trend evaluation.
Furthermore, the analysis of gestures seems as an
effective tool to assess the graph reader`s comprehension
and to obtain the important aspects considered as worth to
mention in verbal descriptions. In addition to the rich data
provided by verbal descriptions, the gestures point out the
hard-to-encode information and conceptually salient points,
as well as perceptually salient regions and entities of the
graph.
Acknowledgments. We thank our student assistants Lena
Andreeßen and Neele Stoeckler for their valuable effort.
The study reported in this paper has been partially supported
by DFG (German Science Foundation) in ITRG 1247
‘Cross-modal Interaction in Natural and Artificial Cognitive
Systems’ (CINACS).

References
Acartürk, C., Alaçam, Ö. (2012). Gestures in
communication through line graphs. In N. Miyake, D.
Peebles, & R. P. Cooper (Eds.), Proceedings of the 34th
Annual Conference of the Cognitive Science Society (pp.
66–71). Austin, TX: Cognitive Science Society.
Barsalou, L.W. (1999). Perceptual symbol systems.
Behavioral and Brain Sciences, 22, 577–660.
Garbarini, F., & Adenzato, M. (2004). At the root of
embodied
cognition:
Cognitive
science
meets
neurophysiology. Brain and Cognition, 56, 100–106.

Goldin-Meadow, S. (2003). Hearing gesture: How our
hands help us think. Cambridge, MA: Harvard University
Press.
Goldin-Meadow, S. & Beilock, S. L. (2010). Action’s
influence on thought: The case of gesture. Perspectives on
Psychological Science, 5(6) 664–674.
Hegarty, M. (2011). The cognitive science of visual-spatial
displays: Implications for design. Topics in Cognitive
Science, 3, 446–474.
Hostetter, A.B., & Alibali, M.W. (2008). Visible
embodiment: Gestures as simulated action. Psychonomic
Bulletin and Review, 15, 495–514.
Hostetter, A. B., & Sullivan, E. L. (2011). Gesture
production during spatial tasks: Its not all about difficulty.
In L. Carlson, C. Hoelscher & T. F. Shipley (Eds.),
Proceedings of the 33rd Annual Meeting of the Cognitive
Science Society. Austin, TX: Cognitive Science Society
Kita, S., & Özyürek, A. (2003). What does cross-linguistic
variation in semantic coordination of speech and gesture
reveal?: Evidence for an interface representation of spatial
thinking and speaking. Journal of Memory and Language,
48, 16-32.
Kosslyn, S. M. (1989). Understanding charts and graphs.
Applied Cognitive Psychology, 3. 185–226.
Kosslyn, S. M. (2006). Graph design for the eye and mind.
New York: Oxford University Press.
McNeill, D. (1992). Hand and mind: What gestures reveal
about thought. Chicago: University of Chicago Press.
McNeill, D. (2005). Gesture and thought. Chicago:
University of Chi- cago Press.
Newman, G. E., & Scholl, B. J. (2012). Bar graphs
depicting averages are perceptually misinterpreted: The
within-the-bar bias. Psychonomic Bulletin & Review, 19,
601-607.
Shah, P., Mayer, R. E., & Hegarty, M. (1999). Graphs as
aids to knowledge construction: Signaling techniques for
guiding the process of graph comprehension. Journal of
Educational Psychology, 91, 690-702.
Tufte, E. R. (1983). The visual display of quantitative
information. Cheshire CT: Graphic Press.
Tversky, B. (2011). Visualizing Thought. Topics in
Cognitive Science, 3(3), 499-535.
Tversky, B., Heiser, J., Lee, P., & Daniel, M.P. (2009). Explanations in gesture, diagram, and word.
In K.
R.
Coventry, T.
Tenbrink,
& J.
A.
Bateman (Eds.), Spatial language and dialogue (pp. 119–
131). Oxford, England: Oxford University Press.
Zacks, J., Levy, E., Tversky, B., & Schiano, D. (2002).
Graphs in print. In M. Anderson, B. Meyer, & P. Olivier
(Eds.), Diagrammatic representation and reasoning. (pp.
187–206). London: Springer-Verlag.
Zacks, J., & Tversky, B. (1999). Bars and lines: A study of
graphic communication. Memory & Cognition, 27(6),
1073-1079.

1719

