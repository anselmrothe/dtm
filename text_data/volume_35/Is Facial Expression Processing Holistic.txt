UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Is Facial Expression Processing Holistic?
Permalink
https://escholarship.org/uc/item/2br1g195
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Omigbodun, Akinyinka
Cottrell, Garrison
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                     Is Facial Expression Processing Holistic?
                                       Akinyinka O. Omigbodun (aomigbodun@ucsd.edu)
                                Electrical and Computer Engineering, University of California San Diego
                                                          La Jolla, CA 92093 USA
                                             Garrison W. Cottrell (gary@eng.ucsd.edu)
                                  Computer Science and Engineering, University of California San Diego
                                                          La Jolla, CA 92093 USA
                               Abstract                                     Holistic processing of facial stimuli is generally mea-
   Most studies examine holistic processing with respect to fa-
                                                                         sured with composite face paradigms, where chimeric faces
   cial identity, but at least one study has also looked at holis-       are constructed from the top and bottom halves of different
   tic processing of facial expressions (Calder, Young, Keane, &         “source” faces. Subjects are asked to identify face halves of
   Dean, 2000). However, this work used the partial composite            chimeric faces or to judge whether two halves of a pair of
   paradigm, which is known to exhibit bias effects (Richler, Che-
   ung, & Gauthier, 2011). The complete composite paradigm               chimeric faces are the same or different. Misalignment of
   (Gauthier & Bukach, 2007) provides a bias-proof way to                the top and bottom halves generally leads to an increase in
   quantitatively measure holistic processing. In this paper, we         the subjects’ accuracy and/or a decrease in reaction time rela-
   perform the corresponding experiment in our face process-
   ing model (EMPATH, (Dailey, Cottrell, Padgett, & Adolphs,             tive to the aligned condition, demonstrating that faces are pro-
   2002)) to predict whether holistic processing of facial expres-       cessed holistically. We test our model with simulations based
   sions will be found if the corresponding human experiments            on the complete composite paradigm (Gauthier & Bukach,
   are performed, and our prediction is that it will. We also com-
   pared our model’s performance to the participants in recent ex-       2007), an improvement upon what Gauthier & Bukach call
   periments in facial expression recognition in humans (Tanaka,         the partial design, which is what is classically used (Young,
   Kaiser, Butler, & Le Grand, 2012). Tanaka et al. (2012) con-          Hellawell, & Hay, 1987). The complete composite paradigm
   cluded that expression recognition is not always holistic, but
   our results suggest that it is.                                       eliminates the effects of response bias (for example, a prefer-
   Keywords: holistic processing                                         ence towards answering “same” for misaligned stimuli). our
                                                                         results predict that a facial expression recognition experiment
                           Introduction                                  with humans based on the complete composite paradigm will
Is all facial processing holistic? For example, when we are              indicate holistic processing.
judging whether a person is trustworthy, tired, middle-aged,                We then use our model to account for experimental results
or happy, is our decision based on a global percept of the               in Tanaka et al. (2012). Tanaka et al. used their own nonstan-
face rather than constituent parts? One might suspect that               dard composite paradigm in one of their experiments that we
the answer is no, at least in some cases. Holistic process-              simulated and a variation on the partial design in another that
ing might depend upon the task. The evidence from face in-               we also simulated. They inferred from their experimental re-
version, composite, and parts-wholes experiments weighs in               sults that facial expression processing is holistic when there is
favor of holistic over parts-based processing for face iden-             a clash between parts of a facial expression (e.g. angry-happy
tity (Yin, 1969; Tanaka & Farah, 1993; Cheung, Richler,                  composite) but analytic or parts-based when there is little or
Palmeri, & Gauthier, 2008; Richler, Tanaka, Brown, & Gau-                no conflict between the parts (e.g. normal happy face). They
thier, 2008). Less research has focused on understanding the             posit an earlier stage where a stimulus is rapidly assessed for
nature of facial expression recognition. One reason to suspect           parts that clash to determine the processing pathway to be
that expression recognition is different is the categorization of        used. However, we achieved similar results with our model
expressions into just seven categories – happy, sad, surprised,          which (1) has one processing pathway for all stimuli, (2) does
angry, disgusted, fearful, and neutral – in line with the “six           not have an earlier stage for quick appraisals, and (3) is not
basic expressions” theory (Ekman & Friesen, 1976), at least              trained to combine decisions on parts of a stimulus into an
as practiced in most psychology experiments. Previous work               overall decision. Our results suggest that one holistic pro-
in our lab has shown that the basic level processing of objects          cessing pathway is sufficient to account for their data.
(e.g., into an overall category, such as chairs or lamps), does
not behave in the same manner as subordinate level process-                     Complete Composite Paradigm (CCP)
ing in our models, and does not engage our model’s equiv-                In composite paradigms, participants in experiments are pre-
alent of the Fusiform Face Area. One consideration is that               sented with two composite faces, and asked to make same-
the holistic processing of faces may be induced if there is any          different judgments about the cued face halves (top or bot-
variation in identity, regardless of the task being performed.           tom) while ignoring the other face halves. The complete
In our modeling work, we tested the hypothesis that without              composite paradigm (CCP) (Gauthier & Bukach, 2007) pro-
any variation in identity, the processing of facial expressions          vides a bias-proof way to quantitatively measure the inter-
is holistic.                                                             action between a subject’s decision and the presence or ab-
                                                                     3187

                                                                               orientations (W = j π/8 for j = 0, . . . , 7) for a total of 40 differ-
                                                                                                                                                  √
                                                                               ent Gabor filters. S was related to F as follows: S = 3F/ 2π.
                                                                               S was chosen such that each filter had the characteristic form
                                                                               of biological two-dimensional receptive field profiles (Hubel,
                                                                               1988; Daugman, 1988). The filters were centered and applied
                                                                               at the 1080 points in a 36 by 30 grid on each image.
                                                                                   We then use PCA to map the Gabor filter features from a
                                                                               43200-dimensional space to a space with many fewer dimen-
                                                                               sions. In forming the PCA projection matrix, we retained
Figure 1: Schematic showing the complete composite
                                                                               enough eigenvectors to account for 90% of the variance. For
paradigm. The subject must decide whether the top face
                                                                               classification, a single-layer perceptron was trained with gra-
halves are the same or different. In the congruent condi-
                                                                               dient descent using a cross-entropy error function.
tion, the top and bottom face halves would generate the same
answer, while in the incongruent condition, they would not.                    Network Training and Testing
Holistic processing is measured as a congruency effect.                        70 gray-scale images were selected from the Pictures of Fa-
                                                                               cial Affect (POFA) (Ekman & Friesen, 1976). These were
sence of a change in the unattended face halves (see Fig. 1).                  cropped to 240 × 292 pixels and adjusted to ensure that there
If the answer is the same for the top and bottom halves, it                    was uniformity in the upright frontal face views; to allow for
is a congruent trial, otherwise, it is incongruent. A congru-                  shifting, the input images were 1.5 times as wide as the face
ency effect, difference in sensitivity, d 0 , between congruent                images (i.e. images of size 360 × 292) with the faces flush
and incongruent trials, is indicative of holistic processing: the              against the left or right edge, as shown in Fig. 3a. Misaligned
unattended face half is obligatorily processed. The partial de-                face halves are shown in Fig. 3b.
sign only has trials where the unattended halves are different,                    The POFA dataset includes seven facial expressions
and holistic processing is measured as a difference in perfor-                 (Happy, Sad, Surprised, Angry, Disgusted, Fearful, and Neu-
mance between aligned and misaligned trials. This is a flawed                  tral) for each of 14 actors. We selected 10 of these for our ex-
measure; using it, researchers concluded holistic processing                   periments (em, gs, jj, mf, mo, nr, pe, pf, sw, wf). We trained
was unrelated to performance on the Cambridge Face Mem-                        on 9 and tested on 1, repeating this 10 times with each actor
ory Test (CFMT). The relationship is found to be strong using                  getting a chance to be tested. For the remaining 9 actors, we
the complete design (Richler et al., 2011).                                    trained on 8 and used the 9th as a hold-out to stop training.
                                                                               This was repeated 9 times with each of the 9 actors having a
                                 Methods                                       turn as the hold-out; so we ended up with 9 networks predict-
                                                                               ing the expression on each stimulus. The consensus of the
The Model                                                                      9 instances was taken as the model’s decision for an experi-
Each input image goes through a two-step preprocessing                         mental run. We averaged the results of the 10 runs.
stage: Gabor filtering and Principal Component Analysis                            Experimental tasks in our simulations involving the iden-
(PCA). The biologically motivated 2-D Gabor filter is con-                     tification of top and bottom face halves necessitated training
structed by using a two-dimensional sinusoid localized by a                    the model to classify vectors of Gabor features corresponding
Gaussian envelope (Daugman, 1985). By tuning to particu-                       to images with only half of a face. We modeled attention to
lar spatial frequency and orientations, the Gabor filter magni-                half a face by using a transformation of the Gabor features
tudes can be used to simulate the responses of complex cells                   that reduced the contribution of the top or bottom of a face to
in primary visual cortex (V1). Following Gabor filtering,                      the total training set covariance. The transformation that we
PCA reduces the dimensionality of the information, simulat-                    used for this and a proof that the contribution of transformed
ing the information extraction mechanism beyond V1. Af-                        Gabor features to the total covariance is reduced is beyond the
ter these preprocessing steps, each image is represented by a                  scope of this paper. In modeling the process of identifying top
vector with relatively low dimension to be input to the per-                   and bottom face halves in testing and in the experiments, we
ceptron.                                                                       simulated giving more attention to half of a face using this
   We computed each Gabor filter using the following equa-                     transformation.
tion:                                                                              The PCA projection matrix was generated from the Gabor
                                                                               feature vectors designated for training the model. Both before
   G(x, y, S, F,W ) =
                                                                               and after the projection of the training stimuli by the matrix,
                    2 (x2 +y2 )                                      F 2
           k · e−πS             · (e j (2πF(x cosW +y sinW )) − e−π( S ) )     the projections were z-scored in order to put each input to the
                                                                               perceptron on the same scale (LeCun, Bottou, Orr, & Mueller,
where S is a scaling parameter, (F, W ) is the polar frequency                 1998). The stimuli for cross-validation were rescaled as one
of the complex sinusoid, (x, y) are the spatial coordinates and                set of vectors, and the stimuli for testing and the experiments
k is a constant (Dias, 2007; Movellan, 2002). There were five                  were rescaled as another set; with the new sample variances
spatial frequencies (F = 1/2i for i = 2, . . . , 6) and eight spatial          for these sets equal to the ratio of the set sizes to the size of
                                                                           3188

    Figure 2: The real components of Gabor filters are shown relative to the size of an image at five scales and orientations.
                                                                   holistic processing was then measured as the difference in
                                                                   sensitivity, d 0 , between congruent and incongruent trials.
                                                                      Simulation 2: Experiment 1 of Tanaka et al. (2012)
                                                                   In experiments performed by (Tanaka et al., 2012), subjects
                                                                   were asked to decide if the cued half of the stimulus was
                a                               b                  happy or angry. Tanaka et al. (2012) measured the subjects’
Figure 3: (a) left- and right-shifted images and (b) top-left-     percentage accuracies and reaction times (in milliseconds).
bottom-right (TLBR) and TRBL images                                They based their experimental design on the observation that
                                                                   happy expressions are bottom biased (meaning it is easier to
                                                                   recognize a happy expression from the bottom of a happy
the training set. This was done to ensure that the rescaling       face than it is from the top half) and angry expressions are
was as uniform as possible across all the feature vectors.         top biased (Calder et al., 2000); they only counted trials in
   All composites were constructed from the same individ-          which the correct responses for the cued lower halves were
ual (ten times, once for each test individual, as described        happy, and those for the cued upper halves were angry. In
above), which ensured that expression and identity recog-          their first experiment, Tanaka et al. (2012) compared subjects’
nition were not confounded. The networks were trained              performance for a happy lower half face in four pairings: (1)
as described above, to classify each (whole, unaltered) face       with a happy top half face (normal), (2) with an angry top
into one of seven expression categories. In order to ob-           half face (angry-happy), (3) without a top half face (isolated),
tain a same/different judgment from a network that only pro-       and (4) with a neutral top half face (neutral).1 There were
cessed one face at a time, we presented the network with the       four corresponding pairings for an angry top half face (see
two stimuli (with attention on the queried half, as described      Fig. 4). Their reasoning was that if happy expressions in
above), one at a time. Since there were actually nine networks     the lower face half and/or angry expressions in the top face
for each test face (as described above), we compared the con-      half of normal, neutral, and isolated stimuli were recognized
sensus of the networks on one stimulus with the consensus          equally easily, then this was evidence for parts-based process-
on the other. If they match, the overall response is “same”;       ing (since this would suggest that the other face half is be-
otherwise the response is “different”.                             ing “ignored”); and if recognition of angry-happy stimuli was
   To obtain reaction times, we appeal to the well-established     worse than that of neutral and isolated stimuli, then this was
inverse relationship between reaction time and confidence rat-     evidence for holistic processing. To assess whether our model
ings (Audley, 1960; Baranski & Petrusic, 1998) in mind, we         could account for their observations (some of which were in-
computed a measure of confidence for our model which was           terpreted as indicating parts-based processing), we simulated
the ratio of the number of network instances in agreement          their experiment with POFA (Ekman & Friesen, 1976) (Fig-
with the consensus to the total number of instances for each       ure 7b–c).
decision made (when the consensus was the correct decision).          Simulation 3: Experiment 3 of Tanaka et al. (2012)
To model reaction time, we subtracted these values from one.       Tanaka et al. (2012) looked at the performance of subjects in
   For the experiments by Tanaka et al. (2012) (described          identifying happy and angry expressions in the lower and up-
shortly), since there are no comparisons between two images        per face halves respectively with two different stimuli types:
(all the subjects had to do was decide if the cued half of the     (1) normal (happy + happy, angry + angry), and (2) angry-
stimulus was happy or angry), we simply use a consensus of         happy (happy lower half + angry top half), under two dif-
the nine networks.                                                 ferent conditions of alignment: aligned and misaligned (see
                                                                   Fig. 5). We note that their third experiment was based on the
Simulations                                                        partial design which we explained previously has drawbacks.
Simulation 1: The CCP on expression recognition The first          Their reasoning was that equal performance in the aligned
simulation used the CCP (Fig. 1) to test whether our model             1 We have chosen to label as normal and angry-happy the stimuli
predicts that facial expression recognition is holistic. Same-     types that they called congruent and incongruent to avoid confusion
different judgments were obtained (as described above), and        in this paper.
                                                               3189

  Figure 4: Stimuli types from Exp. 1(Tanaka et al., 2012).
                                                                      Figure 6: sensitivity (d 0 ) in aligned and two misaligned con-
                                                                      ditions for congruent and incongruent trials of the complete
                                                                      composite paradigm. Error bars indicate standard error of the
                                                                      mean.
                                                                      or reaction time for the normal, isolated and neutral stimuli
                                                                      in the experiments and in modeling. From their observations,
                                                                      Tanaka et al. (2012) concluded that the recognition of lower
                                                                      half face happy expressions is analytic when there is little or
                                                                      no conflict between the face halves (e.g. normal, isolated and
  Figure 5: Stimuli types from Exp. 3 (Tanaka et al., 2012).          neutral stimuli) but holistic when their is a clash between the
                                                                      face halves (e.g. angry-happy stimuli). However, we made
                                                                      similar observations in the model which possesses a single
and misaligned conditions for the normal stimuli would in-            pathway of holistic processing.
dicate parts-based processing and better performance in the              For angry expressions, Tanaka et al. (2012) found that the
misaligned condition relative to the aligned condition for the        percent accuracy on isolated stimuli was less than the accu-
angry-happy stimuli would indicate holistic processing. Once          racy on normal and neutral stimuli, and that the accuracy on
again, to assess whether our model could account for their ob-        angry-happy stimuli was less than the accuracy on the other
servations (some of which they attributed to parts-based pro-         three stimuli types; no other differences were observed for
cessing), we simulated their experiment with POFA (Ekman              accuracy or reaction time. They concluded from their obser-
& Friesen, 1976).                                                     vations that the recognition of top half face angry expressions
                                                                      was not purely analytic and in fact benefited from the pres-
                  Results and Discussion                              ence of whole-face information. While we did not observe
In Simulation 1, the sensitivity, d 0 , for the incongruent trials    any statistically significant differences between accuracy or
was less than the sensitivity for the congruent trials (Fig. 6).      reaction time for the four stimuli types in the model, we -
This observation of the congruency effect confirmed that the          once again - observed a similar trend with the model (Fig. 7–
model processes facial expressions holistically. It is now            8).
left for an experiment in expression recognition with humans             In their third experiment, Tanaka et al. (2012) found a
based on the CCP to be conducted; we expect that a congru-            lower percent accuracy and greater reaction time for angry-
ency effect will be observed.                                         happy stimuli in the aligned condition relative to the mis-
   In their first experiment, Tanaka et al. (2012) found that,        aligned condition, and attributed this to holistic processing. In
for happy expressions, the percent accuracy on angry-happy            contrast, for normal stimuli, there was no difference between
stimuli was reliably less than the accuracy on the other stimuli      the accuracy in the aligned and misaligned conditions. They
types. In the case of the model, while there were no statisti-        expressed surprise at seeing a shorter reaction time in the mis-
cally significant differences between the four stimuli types,         aligned relative to the aligned condition. They attributed the
we observed a very similar trend. The reaction time for the           absence of a holistic facililation for aligned normal stimuli to
angry-happy stimuli was reliably greater than the reaction            analytic processing. Yet once again, we observed very sim-
time for the other three stimuli types in the experiment. In          ilar trends in the model, suggesting that holistic processing
modeling, the difference in reaction time for angry-happy and         suffices for explaining the experimental results (Fig. 9–10).
normal stimuli approached statistical significance, and was              Our modeling work emphasizes the importance of model-
reliable for angry-happy and isolated stimuli. Notably, there         ing in cognitive science. Without a model, inferences from
were no significant differences between the percent accuracy          experimental results can be misleading. While we cannot
                                                                  3190

                                a                                                               b
           Figure 7: percent accuracy in simulation 2 with our model (a) and experiment 1 in Tanaka et al. (2012) (b).
                                a                                                               b
  Figure 8: “reaction time” in simulation 2 with our model (a) and reaction time in experiment 1 of (Tanaka et al., 2012) (b).
claim - based on our model - that facial expression processing       termine confidence. Journal of Experimental Psychology:
in humans is purely holistic, we can conclude that Tanaka et         Human Perception and Performance, 24, 929–945.
al.’s experiments do not show that it has analytic attributes.     Calder, A. J., Young, A. W., Keane, J., & Dean, M. (2000).
                                                                     Configural information in facial expression perception.
                    Acknowledgments                                  Journal of Experimental Psychology: Human Perception
                                                                     and Performance, 26(2), 527–551.
This work was supported in part by NSF grants SMA-
                                                                   Cheung, O. S., Richler, J. J., Palmeri, T. J., & Gauthier, I.
1041755 and IIS-1219252 to G.W. Cottrell. We thank the
                                                                     (2008). Revisiting the role of spatial frequencies in the
Perceptual Expertise Network (PEN) and Gary’s Unbeliev-
                                                                     holistic processing of faces. Journal of Experimental Psy-
able Research Unit (GURU) for discussion and comments,
                                                                     chology: Human Perception and Performance, 34, 1327–
and Jim Tanaka for permission to use his data.
                                                                     1336.
                                                                   Dailey, M. N., Cottrell, G. W., Padgett, C., & Adolphs, R.
                         References                                  (2002). Empath: a neural network that categorizes facial
Audley, R. J. (1960). A stochastic model for individual choice       expressions. Journal of Cognitive Neuroscience, 14(8),
   behavior. Psychological Review, 67, 1–15.                         1158–1173.
Baranski, J. V., & Petrusic, W. M. (1998). Probing the locus       Daugman, J. G. (1985). Uncertainty relation for resolution in
   of confidence judgments: Experiments on the time to de-           space, spatial frequency, and orientation optimized by two-
                                                               3191

                            a                                                      b
          Figure 9: percent accuracy in simulation 3 with our model (a) and experiment 3 of Tanaka et al. (2012) (b).
  dimensional visual cortex filters. Journal of the Optical
  Society of America A, 2, 1160–1169.
Daugman, J. G. (1988). Complete discrete 2-d gabor trans-
  forms by neural networks for image analysis and compres-
  sion. IEEE Transactions on Acoustics, Speech, and Signal
  Processing, 36(7), 1169–1179.
Dias, S. S. (2007). Improved 2d gabor filter. Available
  from      http://www.mathworks.com/matlabcentral/
  fileexchange/13776-improved-2d-gabor-filter
  (Retrieved May 7, 2011)
Ekman, P., & Friesen, W. (1976). Pictures of facial affect.
  Palo Alto, CA: Consulting Psychologists Press.
Gauthier, I., & Bukach, C. (2007). Should we reject the
  expertise hypothesis? Cognition, 103, 322–330.
Hubel, D. H. (Ed.). (1988). Eye, brain, and vision. New
  York, NY: Scientific American Library.
LeCun, Y., Bottou, L., Orr, G. B., & Mueller, K. Robert.                              a                                  c
  (1998). Efficient backProp. In G. Orr & K. Mueller (Eds.),
  Neural networks: tricks of the trade. New York: Springer.
Movellan, J. R. (2002). Tutorial on gabor filters (Tech. Rep.).
  La Jolla, CA: University of California San Diego.
Richler, J. J., Cheung, O. S., & Gauthier, I. (2011). Holistic
  processing predicts face recognition. Psychological Sci-
  ence, 22(4), 464–471.
Richler, J. J., Tanaka, J. W., Brown, D. D., & Gauthier, I.
  (2008). Why does selective attention to parts fail in face
  processing? Journal of Experimental Psychology: Learn-
  ing, Memory and Cognition, 34, 1356–1368.
Tanaka, J. W., & Farah, M. J. (1993). Parts and wholes in
  face recognition. The Quarterly Journal of Experimental                             b                                  d
  Psychology Section A, 46, 225–245.
Tanaka, J. W., Kaiser, M. D., Butler, S., & Le Grand, R.            Figure 10: “reaction time” in simulation 3 with our model in
  (2012). Mixed emotions: holistic and analytic perception          identifying happy (a) & angry (b) facial expressions and re-
  of facial expressions. Cognition & Emotion, 26(6), 961–           action time in experiment 3 of Tanaka et al. (2012) for happy
  977.                                                              (c) & angry (d) facial expressions.
Yin, R. (1969). Looking at upside-down faces. Journal of
  Experimental Psychology, 81, 141–145.
Young, A., Hellawell, D., & Hay, D. (1987). Configural
  information in face perception. Perception, 16, 747–759.
                                                                3192

