UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Linguistic structure is an evolutionary trade-off between simplicity and expressivity
Permalink
https://escholarship.org/uc/item/8j64g39c
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Smith, Kenny
Tamariz, Monica
Kirby, Simon
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                       University of California

          Linguistic structure is an evolutionary trade-off between simplicity and
                                                               expressivity
                         Kenny Smith (kenny@ling.ed.ac.uk), Monica Tamariz & Simon Kirby
         Language Evolution and Computation Research Unit, School of Philosophy, Psychology & Language Sciences,
                  University of Edinburgh, Dugald Stewart Building, 3 Charles Street, Edinburgh, EH8 9AD, UK
                              Abstract                                   that cultural selection for learnability leads to the evolution
                                                                         of structure, under certain assumptions about the nature of
   Language exhibits structure: a species-unique system for ex-
   pressing complex meanings using complex forms. We present             transmission and the biases of language learners. Under a
   a review of modelling and experimental literature on the evo-         strong interpretation of this account, language’s function for
   lution of structure which suggests that structure is a cultural       communication could be seen as an epiphenomenon: struc-
   adaptation in response to pressure for expressivity (arising dur-
   ing communication) and compressibility (arising during learn-         tured language provides a powerful medium for communica-
   ing), and test this hypothesis using a new Bayesian iterated          tion, but language structure is not ‘for’ communication.
   learning model. We conclude that linguistic structure can and            Here we present a new model of iterated learning, moti-
   should be explained as a consequence of cultural evolution in
   response to these two pressures.                                      vated by recent experimental work, which goes some way to
   Keywords: language; structure; cultural evolution; learning;          reconcile these two viewpoints. We draw from the biologi-
   communication                                                         cal account the insight that the alignment between language’s
                                                                         apparent function as a system for expressing propositions and
                         Introduction                                    its structure, tailor-made for just such a purpose, is unlikely
Human language is unique among the communication sys-                    to be a fortuitous coincidence. We draw from cultural evo-
tems of the natural world in that it is exhibits a rich combina-         lutionary account two insights: 1) biological evolution is not
torial and compositional structure: language provides a gen-             the only evolutionary process which might act to shape lan-
erative system for productively combining meaningless ele-               guage: cultural evolution, a necessary consequence of the fact
ments (e.g. speech sounds) to form meaning-bearing units                 that language is socially learned, is a second such mechanism;
(morphemes), which are further recombined to yield com-                  2) selection for learnability will impact on language during its
plex units (phrases) whose meaning is derived in a predictable           transmission. This model suggests that structure arises from
manner from the meaning of their component parts and their               cultural evolution when language is under pressure to be ex-
manner of composition. This allows us massive expressive                 pressive and learnable: pressure for expressivity arises from
potential: at least at a first approximation, anything you can           language use in communication, language learning by naive
think you can express in language. No other species has a                individuals introduces a pressure for simplicity arising from
communication system providing anything approaching this                 domain-general preferences for compressibility in learning.
expressive power: why do humans?                                         Crucially, both must be in play: pressure for expressivity or
   One explanation for the presence of structure1 in human               simplicity alone does not lead to structure. Structure in lan-
language appeals to biological evolution under natural selec-            guage is a linguistic adaptation, not a biological adaptation,
tion (Pinker & Bloom, 1990): language is fundamentally a                 in response to competing pressures for expressivity and learn-
biological trait, being underpinned by some innate language-             ability (Kirby, Cornish, & Smith, 2008; Steels, 2012).
specific apparatus; the ability to communicate propositions
which a structured language provides is adaptive, since it                Cultural evolution of structure: previous work
facilitates social interaction and ultimately increases fitness;         Models of the cultural evolution of linguistic structure typ-
therefore, structure in language represents a biological adap-           ically emphasise the role of learnability constraints in driv-
tation to facilitate communication. A second account explains            ing the evolution of compositionality. Specifically, language
structure in language as a consequence of cultural, rather than          is under pressure to be compressible: to allow the forma-
biological, evolution (Christiansen & Chater, 2008). Rather              tion of compressed mental representations, i.e. simple gram-
than language structure reflecting an evolved domain-specific            mars. This pressure for compressibility is inherent in learn-
learning apparatus, the idea is that languages have adapted              ing (Chater & Vitanyi, 2003), and can be amplified by other
over repeated episodes of learning and production (a process             constraints acting on language transmission (e.g. the mis-
sometimes called iterated learning) in response to weaker,               match between the infinite expressivity of languages and the
domain-general constraints arising from the biases of lan-               finite set of data from which such languages must be learned).
guage learners. We have previously termed this evolutionary              Learning and transmission therefore favour languages which
process cultural selection for learnability (Brighton, Kirby,            admit to compressed representations, i.e. which permit gen-
& Smith, 2005). A range of models and experiments show                   eralisations. Recursive compositionality is one such general-
    1 We use the term structure as a shorthand for combinatoriality      isation (e.g. Steels, 1998; Kirby, 2002; Brighton, Smith, &
and/or compositionality.                                                 Kirby, 2005), and therefore represents an adaptation by lan-
                                                                     1348

guage in response to pressures inherent in transmission and           compositional structure: colour, shape and motion came to be
learning. However, compressibility is not the only constraint         encoded in separate ‘morphemes’ of multi-morphemic words.
on learnability in these models: they typically include some          These structured languages are both learnable and expressive,
learner bias in favour of languages which embody a one-to-            allowing all distinctions between objects to be encoded lin-
one mapping between meaning and form (which happen to be              guistically.
communicatively functional mappings), e.g. by implement-                  Garrod, Fay, Lee, Oberlander, and MacLeod (2007)
ing indirect (Kirby, 2002) or direct (Steels, 1998) competi-          present a task in which participants are required to commu-
tion between meanings which map to a single form. Brighton,           nicate a set of pre-specified concepts using drawings. Par-
Smith, and Kirby (2005) show that, if this bias against one-to-       ticipants who repeatedly play the game together develop an
one mappings is absent, the pressure for compressibility act-         expressive system of symbol-like graphical representations to
ing in isolation leads to degenerate, not structured, languages,      communicate these concepts. This system of communication
where all meanings map to a single maximally-ambiguous                is holistic: each symbol is an idiosyncratic, stand-alone en-
form. While this might suggest that such a one-to-one bias            tity. Theisen-White, Kirby, and Oberlander (2011) present
would be adaptive, Smith (2004) shows that such a bias is             a modified version of this paradigm, integrating the dyadic
unlikely to evolve for its (eventual) communicative payoff,           context for communication with the diffusion-chain method
and concludes that the one-to-one bias must be a product of           from Kirby et al. (2008). An initial pair play a variant of
domain-general cognitive biases. Again, this suggests that the        the communication game from Garrod et al., using a modi-
utility of language for communication might be a side-effect          fied set of concepts designed to provide a basis for system-
of learnability pressures alone.                                      atic structure (e.g., teacher, school, teaching; firefighter, fire
   Diffusion-chain experiments with adult human participants          station, fire-fighting). The drawings produced by that pair
have also been used to investigate the impact of cultural se-         during communication are then observed by a fresh pair of
lection for learnability. Kirby et al. (2008) report two ex-          participants, who go on to communicate together, and so on.
periments in which participants are trained on a miniature            The system of communication is therefore under pressure to
language which provides labels for objects (coloured moving           be both expressive (communicatively functional) and learn-
shapes, e.g. a red square bouncing), and are then prompted to         able (by the naive individuals during the observation phase).
produce labels for a further set of objects. Participants are or-     Theisen-White et al. find that the sets of drawings become
ganised into a diffusion chain, such that the labels produced         more structured over these chains of transmission: the draw-
by the nth participant in a given chain provide the training          ings develop component parts which refer to the domain (e.g.
data for participant n + 1 in that chain. The first participant in    teaching, fire-fighting) and the category (e.g. person, build-
each chain is trained on a unstructured holistic system, where        ing, activity).
each object is associated with a unique random label (and                 These experimental results are therefore consistent with the
therefore shared elements of meaning do not map to shared             modelling literature reviewed above and suggest a three-way
components of form).                                                  contrast: pressure for compressibility alone results in degen-
                                                                      erate languages (Kirby et al., 2008, Experiment 1); pressure
   Across two experiments, Kirby et al. (2008) show that lan-
                                                                      for expressivity but not learnability (Garrod et al., 2007) leads
guages change as a result of their transmission to be more
                                                                      to holistic systems; pressure for expressivity (from artificial
learnable: the languages produced later in a chain of trans-
                                                                      filtering or, better, communication) leads to structure (Kirby
mission are learnt with greater accuracy. In their Experiment
                                                                      et al., 2008; Theisen-White et al., 2011). However, no one
1, this is achieved by the languages becoming simple: the lan-
                                                                      model or experimental paradigm completely decouples learn-
guages lose distinctions. In the most extreme case, this results
                                                                      ability and expressivity: below, we present a model which
in a degenerate language in which all objects (with one excep-
                                                                      does this, and which demonstrates this link between expres-
tion) are associated with a single, highly-ambiguous label.
                                                                      sivity, learnablity and structure more conclusively.
Simplification facilitates learning at the expense of expres-
sivity: while the initial holistic languages have high expres-                                  The model
sive potential, the languages which ultimately emerge allow
                                                                      We model individuals as rational learners who infer a dis-
only a few contrasts between objects to be signalled linguis-
                                                                      tribution over possible languages (meaning-form mappings),
tically. However, there is no pressure for expressivity in this
                                                                      and use those languages to communicate. Learners have
experiment: the language is under pressure to be learnable,
                                                                      a (parameterised) prior preference for simple, compressible
but given the lack of a communicative task, under very little
                                                                      languages, and during interaction a (parameterised) tendency
pressure to provide distinct labels for distinct objects.
                                                                      to avoid utterances which are ambiguous in context.
   In their Experiment 2, an artificial pressure for expressiv-
ity was introduced: homonyms (labels paired with multiple             Model of languages
objects) were eliminated during the process of sampling from          A language consists of a system for expressing meanings us-
the nth participant’s productions to yield the training data for      ing forms. We consider the simplest possible meanings and
participant n + 1. As in Experiment 1, the languages became           forms which are nonetheless capable of evidencing system-
more learnable, but this was achieved by the development of           atic structure: meanings are vectors of length v, where each
                                                                  1349

element in the vector takes one of w possible values. Sim-
                                                                              Table 1: Example languages from three important classes.
ilarly, forms are of length l, where each character is drawn
from some alphabet Σ. We take v = w = l = |Σ| = 2, which                                                          Form
yields a set of meanings M = {00, 01, 10, 11} and a set of                       Meaning       degenerate       holistic compositional
forms F = {aa, ab, ba, bb}. This gives a space of 256 possi-                       00              aa             aa         aa
ble languages, including degenerate, compositional and holis-                      01              aa             ba         ab
tic mappings: see Table 1 for examples.2                                           10              aa             ab         ba
Hypotheses                                                                         11              aa             bb         bb
Learners infer a distribution over languages: the space of hy-
potheses is therefore the space of possible distributions over                  0.08
all 256 languages.3 Following Burkett and Griffiths (2010),                            4                               1 form, degenerate
                                                                                                                       2 forms
we use a Dirichlet process prior (Ferguson, 1973), charac-                                                             2 forms
terised by concentration parameter α and base distribution                      0.06                                   2 forms
                                                                                                                       2 forms
                                                                                                                       2 forms
G0 . The parameter α determines how many languages feature                                                             3 forms
in this distribution: low alpha (we use α = 0.1) corresponds                    0.04
                                                                                                                       3 forms
                                                                                                                       3 forms
to an a priori belief that the majority of the probability mass                                                        4 forms, holistic
                                                                                                                       4 forms
will be on a single language. The base distribution is a distri-
                                                                                0.02
                                                                                                                       4 forms, compositional
bution over languages, and would be the prior if learners only                                         32
                                                                                                            8
considered single-language hypotheses.                                                     4   24 16             64 48 32 12      8     4
   Our base distribution encodes a preference for simplicity,                   0
operationalised as a preference for languages whose descrip-
tion is compressible. Intuitively, degenerate languages permit             Figure 1: Probability in G0 for individual languages in each
more compressed descriptions than compositional languages;                 class, arranged by number of distinct forms, and (within a
holistic languages are, by definition, incompressible. The                 given number of forms) increasing compressibility. Anno-
prior used in Kirby, Dowman, and Griffiths (2007) captures                 tations give the number of languages per class, all of which
this intuition: it assigns higher probability to languages in              have equal prior probability.
which fewer forms are used to convey a given set of mean-
ings. We simply apply this metric both over the full set of
meanings and specific feature values (see Appendix). This                  in C. P( f |h,C,t) = P(l|h) · P( f |l,C,t): we simply sample a
prior splits the space of 256 possible languages into 12 lan-              language l from the speaker’s hypothesis, then given that lan-
guage classes, based on the number of forms in the language                guage and the context, sample an utterance. We include a pa-
and the regularity with which feature of meaning are mapped                rameterisable preference to avoid ambiguity during this latter
to components of form: the priors for individual languages                 step, following the model of pragmatics provided by Frank
are depicted in Fig. 1, with example languages from some                   and Goodman (2012). Assuming some small probability of
pertinent classes in Table 1. The prior yields the desired rank-           error on production ε:
ing of languages: more compressible languages (i.e. with                                   ( 1 γ
fewer forms) are preferred, but within those languages with                                     a (1 − ε) if t is mapped to f in l
a given number of forms, there is a preference for languages                P( f |l,C,t) ∝       ε
                                                                                                                                          ,
                                                                                              |S |−1         if t is not mapped to f in l
which consistently map feature values in the meaning to a
single character in the corresponding position in the form.                where we normalise over all possible forms from F . a is am-
                                                                           biguity, the number of meanings in C that map to form f in l,
Likelihood
                                                                           and γ specifies the extent to which utterances which are am-
We sample a form f from the distribution P( f |h,C,t), which               biguous in context are penalised. If a = 1 ( f is unambiguous
specifies the probability of f given hypothesis h, a context               in this context) and/or γ = 0 then this yields a model of pro-
of utterance (a set of meanings) C, and topic t ∈ C, which                 duction where the ‘correct’ form is produced with probability
the speaker attempts to discriminate from the other meanings               1 − ε. However, when γ > 0 and f is ambiguous in context
    2 We assume that the first meaning feature is expressed in the         (i.e. a > 1), then the ‘correct’ mapping from t to f is less
first form character. Without this constraint, it is impossible to spec-   likely to be produced, and the remaining probability mass is
ify holistic languages given this small form space: e.g. the holistic      spread equally over the other possible forms. Therefore, γ > 0
language in Table 1 is compositional if we allow the first meaning
feature to map to the second form character. It would be possible          introduces a penalty for languages whose utterances are am-
to distinguish between holistic and compositional systems without          biguous in context. We use ε = 0.05, |C| = 3, and vary γ.
this constraint given |Σ| > 2, but to minimise runtimes we opted for
|Σ| = 2 and a constrained definition of compositionality.                  Inference
    3 Inferring a distribution over languages, rather than a single lan-
guage, allows learners to track changes in their partners’ linguistic      Exact inference over this hypothesis space in intractable: in-
behaviour over time.                                                       stead, following Burkett and Griffiths (2010), we use a Gibbs
                                                                       1350

sampler based on the Chinese Restaurant Process to sample                     as the training data for the pair at generation n + 1.5
a hypothesis direct from the posterior. As described below,
learners acquire an expanding set of observed utterances dur-                                               Results
ing their lifetime: we run the inference over the most recent                 The results (Fig. 2) match the predictions of our hypothe-
r = 80 observations, in order to improve simulation runtimes.                 sis, and are consistent with the experimental results described
                                                                              above. When there is pressure for learnability arising from
Transmission in populations                                                   transmission to naive individuals, but no pressure for expres-
                                                                              sivity (achieved by using the chain population model and set-
                                                                              ting γ for interaction to 0), the final distribution is dominated
Following the experimental methods employed by Theisen-
                                                                              by degenerate languages, as in Kirby et al. (2008), Experi-
White et al. (2011) and Garrod et al. (2007), we compare two
                                                                              ment 1. Note that this preference for degenerate languages
types of population: in chains, simulated agents are organ-
                                                                              is even stronger than that seen in the prior: given the pa-
ised into pairs, are trained on data produced by the previous
                                                                              rameters of the model, in particular the low concentration
pair (see below), and then interact, producing data which the
                                                                              parameter for the Dirichlet process prior, this exaggeration
next generation in the chain (a new, naive pair of simulated
                                                                              of the prior is as predicted by Burkett and Griffiths (2010).
individuals) are trained on. In dyads exactly the same regime
                                                                              In contrast, in the condition where there is expressivity pres-
of training and interaction is observed. However, naive indi-
                                                                              sure but little pressure for learnability (dyads, γ = 3), the ini-
viduals are not introduced at each generation: rather, the same
                                                                              tial holistic languages, (expressive but not compressible) per-
individuals are trained on their own productions from the pre-
                                                                              sist. Members of the dyad constantly replenish their own ev-
vious phase of interaction.4 The contrast between chains and
                                                                              idence that the language is holistic: consequently, the initial
dyads allows us to manipulate the pressure for learnability:
                                                                              holistic language is locked in. This matches the experimen-
in chains, where naive individuals are introduced at every
                                                                              tal results obtained for dyads (Garrod et al., 2007): due to the
generation, the pressure for learnability (i.e. the influence of
                                                                              lack of transmission to new individuals, there is little pressure
the prior preference for simplicity) is likely to be relatively
                                                                              for compressibility to counteract lock-in and expressivity re-
strong. In dyads, in contrast, there is only one episode of
                                                                              quirements during interaction, and structure does not emerge.
transmission to naive individuals (at generation 1), and con-
                                                                              Note also that this result holds despite the fact that we set
sequently the pressure for simplicity arising from the prior is
                                                                              a fairly low memory limit for individuals (r = 80). Finally,
substantially diminished.
                                                                              when there is pressure for both learnability and expressivity
Training During training, the pair are presented with a                       (chains, γ = 3), we see structured languages emerge: the fi-
shared set of 20 form-meaning pairs, produced by the pre-                     nal distribution is dominated by a priori unlikely expressive
ceding pair during interaction or (for the first generation                   languages, but among these it is the a priori most likely lan-
only) a shared set of 20 form-meaning pairs generated from                    guages, the compositional languages, that dominate. Again,
a randomly-selected fully-expressive holistic language (this                  this matches our hypothesis and the experimental data from
initialisation with holistic languages is inspired by the ex-                 Theisen-White et al. (2011).
perimental work discussed above). This data is added to
each agent’s memory (which will be empty for individuals in                                               Discussion
chains), and then a hypothesis is sampled from the posterior.                 Our model shows that pressure for expressivity or simplic-
Interaction After training, the pair interact for 40 rounds.                  ity alone does not lead to the emergence of structure: only
At each round of interaction, one individual acts as teacher                  when both pressures are at play does structure emerge. Fur-
and the other as learner. The teacher is prompted with a                      thermore, only cultural evolution is required for structure: we
randomly-selected context and topic, and samples a form                       can explain why language is structured without recourse to
from their hypothesis. The learner adds the observed form-                    invoking an evolved, domain-specific faculty of language.
meaning-context triple to its memory, and samples an updated                     As well as corresponding closely with existing modelling
hypothesis. The roles of teacher and learner then switch, and                 and experimental data, these findings make sense of the dis-
a new round is played.                                                        tribution of structure in the communication systems of non-
Transmission The 20 form-meaning pairs produced by one                        human animals. Many small but expressive communication
randomly-selected member of the pair at generation n is used                  systems exist in nature, a classic example being alarm calling
                                                                              systems, which allow the discrimination of several referents
                                                                              (predators), but do so using vocalisations which are holistic
    4 Training dyads on their own productions ensures that the con-
                                                                              and unlearned (Fitch, 2000). Learned vocal communication
figuration of the model is identical for dyads and chains. We ran
an additional set of dyad simulations with a modified transmission            systems are witnessed in many species of bird, as well as be-
regime, such that pairs are trained on the initial target language and        ing patchily distributed among mammals (Fitch, 2000): strik-
go on to interact repeatedly but are not retrained on their productions
from the last round of interaction (i.e. there is no training phase after         5 In accordance with an ongoing set of human experiments based
generation 1): this produces results which are highly similar to dyads        on these models, the context is stripped from these observations: in
with transmission at every generation, showing that the retraining            other words they contain only form-meaning pairs, with a context
step does not introduce some additional conservative tendency.                consisting solely of the topic.
                                                                          1351

                                                                        Learnability, no expressivity
    1                                                                                                             0.8
                                                                                                                        1 form, degenerate
                                                                                                                        2 forms
    0.8                                                  ●
                                                                                                                        2 forms
          ●                                             ● ●
                                                       ● ● ● ●●
                                                                        ●● ●       ● ●
                                                                       ● ● ●●●●●●● ● ●
                                                                                                                  0.6   2 forms
                                                                                                                        2 forms
                                              ● ●●          ● ●●●                 ●
                                                                                    ● ●●●●● ●●
    0.6                                    ● ●● ●● ●
                                                   ●●
                                                                   ●●●●                       ●● ●●                     2 forms
                                          ● ●        ●           ●●                             ●●● ●                   3 forms
          ●                              ● ●                                               ●
                              ●●                                                                     ●                  3 forms
                           ● ● ●●●●●●●
    0.4                               ●                                                                           0.4   3 forms
                      ●● ● ● ●●
                        ●● ●                                                                                            4 forms, holistic
                     ●
    0.2     ● ●
                  ●●●                                                                                                   4 forms
                                                                                                                        4 forms, compositional
             ●● ●
            ●●                                                                                                    0.2
    0     ●● ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
          0                 20                  40          60                          80                 100    0
                                                  Generation
                                                                         Expressivity, no learnability
    1                                                                                                             1
                                                           ●●
            ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●● ●●●●●●● ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
          ●●                                       ●
    0.8                                                                                                           0.8
          ●
    0.6
                                                                                                                  0.6
    0.4
                                                                                                                  0.4
    0.2
    0     ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●   0.2
          0                 20                  40          60                          80                 100    0
                                                  Generation
                                                                        Learnability and expressivity
    1                                                                                                             0.6
    0.8
    0.6
          ●
           ●                                                                                                      0.4
              ●
    0.4      ● ●
              ● ●
               ●
                  ●●
    0.2                ●
                    ●●● ●                                                                                         0.2
                             ●
                         ●● ● ●●●
                           ●     ● ●● ●          ●
                        ●●●       ● ●● ● ●● ●●●●●●●●● ●                        ●●                  ● ●●●●●●● ●●
    0      ●  ●
          ● ●● ●●●●●●●●●   ●●●●●●●●●●●●●●●●                     ●●●●●●●
                                           ●●● ●● ●●●●●●● ●●●●●●●      ●●●●●●
                                                                      ●●    ●●●●● ●●●●●●●●
                                                                                ●●●          ●●
                                                                                          ●●●●
                                                                                         ●●   ●●●   ● ●●●●
                                                                                                ●●●●●       ●●●
          0                 20                  40          60                          80                 100    0
                                                  Generation
Figure 2: Time courses (left: mean probability of each language class in the last sampled hypothesis of each individual in
multiple chains/dyads) and final distributions (right: mean probability as in time courses, averaged over the final 50 genera-
tions of those same simulation runs). When learnability is the only pressure (top: average of 20 simulation runs), degenerate
languages dominate the final distribution. When expressivity is the only pressure (middle: 50 runs), the original expressive but
holistic languages are preserved. When both pressures are at play (bottom: 50 runs), expressive but compositionally-structured
languages emerge.
                                                                                              1352

ingly, song, the classic example of (combinatorial, not com-        Kirby, S. (2002). Learning, bottlenecks and the evolution of
positional) structure in animal communication, occurs in pre-          recursive syntax. In E. Briscoe (Ed.), Linguistic evolution
cisely these species, whose communication system is under              through language acquisition: Formal and computational
cultural selection to be learnable but expressive. This is en-         models (pp. 173–203). Cambridge: Cambridge University
tirely consistent with the predictions of our model, although          Press.
we would suggest that the expressivity pressures inherent in        Kirby, S., Cornish, H., & Smith, K. (2008). Cumulative cul-
communication in these species must be rather different from           tural evolution in the laboratory: an experimental approach
the expressivity pressure in language, with a focus on sig-            to the origins of structure in human language. PNAS,
nalling e.g. individual quality, rather than communicating             105(31), 10681-10686.
propositions.                                                       Kirby, S., Dowman, M., & Griffiths, T. L. (2007). Innateness
                                                                       and culture in the evolution of language. PNAS, 104, 5241–
                        Conclusions                                    5245.
The results from our model support the hypothesis drawn             Pinker, S., & Bloom, P. (1990). Natural language and natural
from our review of the modelling and experimental litera-              selection. Behavioral and Brain Sciences, 13(4), 707–784.
ture on the evolution of communication systems: structure           Smith, K. (2004). The evolution of vocabulary. Journal of
emerges when a system of communication is under pressure               Theoretical Biology, 228(1), 127–142.
to be both expressive (due to communicative interaction) and        Steels, L. (1998). The origins of syntax in visually grounded
simple (due to domain-general preferences for compressibil-            robotic agents. Artificial Intelligence, 103, 133–156.
ity imposed during language learning). Crucially, both these        Steels, L. (2012). Self-organization and linguistic selection
pressures must be in play: pressure for expressivity or sim-           in language evolution. In L. Steels (Ed.), Experiments in
plicity alone does not lead to structure. Linguistic structure         cultural language evolution. Amsterdam: John Benjamins.
therefore can and should be explained as a consequence of           Theisen-White, C., Kirby, S., & Oberlander, J. (2011). Inte-
cultural evolution: structure in language is a linguistic adap-        grating the horizontal and vertical cultural transmission of
tation, not a biological adaptation, and it is an adaptation in        novel communication systems. In L. Carlson, C. Hoelscher,
response to competing pressures for expressivity and learn-            & T. F. Shipley (Eds.), Proceedings of the 33rd Annual
ability inherent in language transmission and use.                     Conference of the Cognitive Science Society (pp. 956–961).
                                                                       Austin, TX: Cognitive Science Society.
                         References
Brighton, H., Kirby, S., & Smith, K. (2005). Cultural se-                                      Appendix
   lection for learnability: Three principles underlying the        For a given set of forms F (where members of the set are
   view that language adapts to be learnable. In M. Taller-         either complete forms, e.g. aa, or partially-specified forms,
   man (Ed.), Language origins: Perspectives on evolution           e.g. a∗, indicating a string-initial a) and a set of mean-
   (pp. 291–309). Oxford: Oxford University Press.                  ings M, we can count the number of mappings in a lan-
Brighton, H., Smith, K., & Kirby, S. (2005). Language as an         guage for which forms from F are associated with mean-
   evolutionary system. Physics of Life Reviews, 2, 177–226.        ings from M: we denote this quantity n(M, F). For instance,
Burkett, D., & Griffiths, T. L. (2010). Iterated learn-             n({00, 10, 11, 10}, aa) = 4 for the degenerate language in Ta-
   ing of multiple languages from multiple teachers. In             ble 1, since the form aa is associated with all 4 of these
   A. D. M. Smith, M. Schouwstra, B. de Boer, & K. Smith            meanings, but 1 for the compositional and holistic languages;
   (Eds.), The Evolution of Language: Proceedings of the 8th        n(0∗, a∗) = 2 for the degenerate and compositional languages
   International Conference (p. 58-65). Singapore: Word Sci-        but 1 for the holistic language, since there is only a single
   entific.                                                         mapping where meaning-initial 0 maps to form-initial a. Our
Chater, N., & Vitanyi, P. (2003). Simplicity: a unifying prin-      base probability for language l characterised is then:
   ciple in cognitive science. Trends in Cognitive Science, 7,
                                                                    G0 (l) ∝ P(l, M , F ). ∏ P(l, m, {a∗, b∗}). ∏ P(l, m, {∗a, ∗b})
   19-22.
                                                                                        m∈{0∗,1∗}             m∈{∗0,∗1}
Christiansen, M., & Chater, N. (2008). Language as shaped
   by the brain. Behavioral and Brain Sciences, 31, 489–509.           where we normalise over all possible languages and
Ferguson, T. (1973). A Bayesian analysis of some nonpara-           P(l, M, F) is the prior from Kirby et al. (2007),
   metric problems. The Annals of Statistics, 1, 209-230.                                    Γ(|F|σ)
Fitch, W. T. (2000). The evolution of speech: a comparative             P(l, M, F) =
                                                                                       Γ(σ)|F| Γ(m + |F|σ)
                                                                                                             ∏ Γ(n(M, f ) + σ),
                                                                                                             f ∈F
   review. Trends in Cognitive Science, 4(3), 258–267.
Frank, M. C., & Goodman, N. D. (2012). Predicting prag-             where Γ(x) = (x − 1)! and m is the number of meanings
   matic reasoning in language games. Science, 336, 998.            from M that unify with M. The parameters σ determines
Garrod, S., Fay, N., Lee, J., Oberlander, J., & MacLeod, T.         the strength of the preference for simplicity: low σ (we use
   (2007). Foundations of representation: where might graph-        σ = 1, the lowest possible value) strengthens the preference
   ical symbol systems come from? Cognitive Science, 31(6),         for more compressible languages, higher σ leads to a weaker
   961–987.                                                         preference for such languages.
                                                                1353

