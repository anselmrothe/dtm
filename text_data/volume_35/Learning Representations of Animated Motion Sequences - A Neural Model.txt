UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Representations of Animated Motion Sequences - A Neural Model
Permalink
https://escholarship.org/uc/item/03m6x7vd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Layher, Georg
Giese, Martin
Neumann, Heiko
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

      Learning Representations of Animated Motion Sequences - A Neural Model
               Georg Layher (georg.layher@uni-ulm.de) Martin Giese (martin.giese@uni-tuebingen.de)
                   Institute of Neural Information Processing                     Section for Computational Sensomotorics
                                  Ulm University                                         University Clinic Tübingen
                   James-Franck Ring, 89069 Ulm, Germany                      Frondsbergstraße 23, 72074 Tübingen, Germany
                                            Heiko Neumann (heiko.neumann@uni-ulm.de)
                                                   Institute of Neural Information Processing
                                                                    Ulm University
                                                   James-Franck Ring, 89069 Ulm, Germany
                               Abstract                                      poses. Sequence-selective representations of articulated mo-
                                                                             tions in cortical STS are driven jointly by input activations
   The detection and categorization of animate motions is a cru-             from both motion and form prototypes. In addition, feed-
   cial task underlying social interaction and perceptual decision-
   making. Neural representations of perceived animate objects               back connections are learned to enable STS neurons predict-
   are built in the primate cortical region STS which is a region of         ing expected input from form selective IT and motion sensi-
   convergent input from intermediate level form and motion rep-             tive MST. We argue that for inputs presenting articulated pos-
   resentations. Populations of STS cells exist which are selec-
   tively responsive to specific animated motion sequences, such             tures without continuing motion, STS representations are fed
   as walkers. It is still unclear how and to which extent form              by the corresponding snapshot prototype activations (Jellema
   and motion information contribute to the generation of such               & Perrett, 2003). In turn, STS will send feedback to stages
   representations and what kind of mechanisms are involved in
   the learning processes. The paper develops a cortical model               in the segregated pathways for form as well as motion pro-
   architecture for the unsupervised learning of animated motion             cessing. Stationary images which depict articulated pos-
   sequence representations. We demonstrate how the model au-                tures, consequently generate effects of implied motion, which
   tomatically selects significant motion patterns as well as mean-
   ingful static form prototypes characterized by a high degree of           have been shown in functional magnetic resonance imaging
   articulation. Such key poses are selectively reinforced during            (fMRI) studies (Kourtzi & Kanwisher, 2000). We will argue
   learning through a cross-talk between the motion and form pro-            here, that this can be accomplished by the proposed model
   cessing streams. Next, we show how sequence selective repre-
   sentations are learned in STS by fusing static form and motion            through the action of fusing bottom-up input, driven by snap-
   input from the segregated bottom-up driving input streams.                shot representation only, and the activated sequence repre-
   Cells in STS, in turn, feed their activities recurrently to their in-     sentations sending feedback to both form and motion repre-
   put sites along top-down signal pathways. We show how such
   learned feedback connections enable making predictions about              sentations, thus amplifying motion representations even if no
   future input as anticipation generated by sequence-selective              direct motion input is present.
   STS cells. Network simulations demonstrate the computa-                   Several computer vision approaches have been proposed
   tional capacity of the proposed model by reproducing several
   experimental findings from neurosciences and by accounting                for performing action recognition using different processing
   for recent behavioral data. Keywords: animated motion repre-              strategies of combining form and motion information. These
   sentation; implied motion; neural model; unsupervised learn-              approaches build upon the hierarchical architecture proposed
   ing; feedback.
                                                                             by Poggio and coworkers which aims at defining a frame-
                                                                             work for form processing in the cortical ventral pathway
                           Introduction                                      (Riesenhuber & Poggio, 1999). Extensions of the form pro-
Animated movements in actions, like walking, turning, etc.,                  cessing model to analyze motion information responses in a
can be robustly detected from video sequence input and pre-                  separate pathway, like the Giese-Poggio model, have been
dictions about future occurrences can be derived from such                   suggested in e.g. (Schindler & Van Gool, 2008). Here, the
spatio-temporal patterns. Giese & Poggio (Giese & Pog-                       relative contributions of form and motion features to the clas-
gio, 2003) proposed a hierarchical feedforward network ar-                   sification of actions have been investigated. Details of the
chitecture that aims at explaining the computational mecha-                  motion processing cascade alone have been studied in more
nisms underlying the perception of biological motion, mainly                 detail in (Escobar & Kornprobst, 2012). Here the authors
from impoverished stimuli such as point-light walkers. In                    contributed further evidence that detecting motion contrasts
this paper, we propose a new learning-based hierarchical                     in sequences of animated motion is useful to distinguish ac-
model for analyzing animated motion sequences. Prototypes                    tion classes. In all these proposed models, the mechanisms
in the form and motion pathways are established using a                      for hierarchical motion (and form) processing are predefined
modified Hebbian learning scheme. We suggest how snap-                       and learning only occurs at the level of a final classifier to
shot prototypes are automatically selected from continuous                   distinguish given categories. It still remains unclear to a large
input video streams utilizing features from the motion path-                 extent, how the motion and form prototypes (e.g., in cortical
way which are indicative for the occurrence of specific snap-                areas MST and IT, respectively) and the sequence-selective
shots with strongly articulated configurations, serving as key               pattern representations in STS interact and which features are
                                                                         870

                                                      excitatory / FF              collaborators (Rolls & Milward, 2000), in which the authors
                                                      modulatory / FB              have suggested that layered neuronal structures arranged in
      STS                                             inhibitory / lateral         a hierarchy with increasingly larger connectivity kernels can
               motion
             sequences                                modulatory / gating          learn invariant representations of objects and specific motion
                                                                                   patterns. Here, we propose how such learning in a hierar-
               motion pathway             form pathway                             chy can be utilized for learning sequence-selective represen-
                                                                                   tations of animated movement prototypes from convergent
           optic flow                                    static       IT
MST         patterns                                                               form and motion input. In addition, we suggest how a motion-
                                                      prototypes
                                   g(●)                                            driven reinforcement mechanism automatically selects rele-
                           ∫
       optic flow                                      contours    V2              vant snapshots in the form path from video input streams. The
 MT     features                                       junctions
                                                                        V1         activities of the prototypical form and motion cells converge
      V1                  local            local                                   in the model complex STS, where correlated temporal activa-
                         motion             form                                   tions for specific sequences are learned. Sequence-selective
                        features          feature
       LGN                                                                         representations are established by combined bottom-up and
                                                                                   top-down learning, both based on modified Hebbian mecha-
       retina                                             input
                                                                                   nisms. An overview of the model is shown in Fig. 1. The
                                                        sequence
                                                                                   details are outlined below.
                                               time
                                                                                   Form and Motion Processing
Figure 1: Overview of the model architecture. The model                            Processing the raw input data utilizes an initial stage of ori-
consists of two separate processing streams, the motion and                        entation and direction selective filtering (in model area V1).
the form pathway, both converging into model area STS.                             These responses are fed into separated pathways which are
Static form prototypes in area IT, as well as optic flow pat-                      selective to static form representations (areas V2 and IT) and
terns in area MST are learned using an unsupervised Hebbian                        characteristic optical flow patterns (areas MT and MST). We
mechanism. A motion driven reinforcement signal between                            use single compartment model neurons with gradual activa-
the two pathways is used to steer the learning of the IT pro-                      tion dynamics. The membrane potential of individual model
totypes. After the suppression of cells with low activities,                       neurons is calculated by conductance-based mechanisms of
IT and MST cells propagate into area STS, where sequence-                          feed-forward integration of excitatory and inhibitory feeding
selective cells learn corresponding spatio-temporal activity                       input and a passive leakage. The potential can be enhanced
patterns using a similar Hebbian learning rule. In addition,                       by a gating mechanism to amplify the efficacy of the current
the sequence-selective cells learn the output weights back to                      potential by a matching top-down feedback signal. The mem-
the segregated form and motion prototypes, that stabilizes the                     brane potential is finally regulated by a gain control mecha-
input processing and activity fusion.                                              nism that leads to activity normalization for a pool of neu-
                                                                                   rons through mutual divisive inhibition. These mechanisms
                                                                                   are summarized in a three-stage hierarchy of processing that
used for learning. How can feature representations be learned                      includes input filtering, modulatory feedback, and pool nor-
automatically from given input streams at different levels of                      malization. The output of a cell is defined by a signal function
the distributed action sequence representations? Also no top-                      which converts the membrane potential into a firing rate, or
down influences have been considered so far and how such                           activity. Such model cells are grouped into layers which form
connectivity patterns may transfer different information be-                       abstract models of cortical areas.
tween pathways to generate proper predictions concerning fu-
ture input configurations.                                                         Learning of Form and Motion Prototypes
                                                                                   First, we investigated how intermediate level feature repre-
                        Model Architecture                                         sentations can be learned in a biologically plausible fashion
The hierarchical model proposed here consists of two sep-                          by exposing the network architecture with realistic input se-
arate visual pathways for segregated form and motion pro-                          quences. In order to generate feature representations of com-
cessing as inspired by the work of (Giese & Poggio, 2003)                          plex form and motion patterns we employ an unsupervised
and extends it by combining it with models for the hierar-                         learning mechanism based on a modified Hebbian learning
chical feedforward and feedback processing of motion and                           scheme. The modification stabilizes the learning such that
form along the dorsal and the ventral pathway (Bayerl & Neu-                       the growing of weight efficacies is constrained to approach
mann, 2004; Weidenbacher & Neumann, 2009). Intermediate                            (bounded) activity levels of the input or the output activation.
level form representations (in model IT) and prototypical op-                      Motivated by the invariance properties observed by (Wallis
tical flow patterns (in model MST) are established using a                         & Rolls, 1997) we combined the modified Hebbian learning
modified competitive Hebbian learning scheme with conver-                          mechanism with a short-term memory trace of prolonged ac-
gent weight dynamics. The two separate hierarchical learn-                         tivity of the pre- or the post-synaptic cells (trace rule). The
ing approaches are influenced partly by the work of Rolls and                      adaptation of weightings is controlled by post-synaptic cells
                                                                             871

which, in turn, mutually compete for their ability to adjust
                                                                                                                                          activation [au]
their incoming connection weights. The particular details as                                      IT             MST
                                                                                                        g(●)
well as the particular variations of the core architecture are
explained below.                                                                                 V2               MT
                                                                             ||motion||smmoth
   Hebbian learning in the form and motion pathways. In
                                                                                                                            g(●)=const                                            t [frames]
order to select the image regions that are fed to the learning
                                                                                                                                          activation [au]
of prototype representations a region of interest (ROI) is de-
fined which represents a bounding box around the target ob-
ject. Features within the target region are selected for learn-                                               t [frames]
ing feedforward connection weights in the form and the mo-
tion pathway, respectively. We employ the modified Hebbian                                                                  g(●)≠const                                            t [frames]
learning rule
                              post      pre     post
           ∆wFF,s
             ji   = ηs · v̄i         · (u j − v̄i      · wFF,s
                                                          ji )   (1)         Figure 2: IT prototypes trained using disabled and enabled
                                                                             reinforcement signal. Minima and maxima in motion energy
   where ∆wFF,s
              ji   represents the discretized rate of change in              correspond to articulated and non-articulated postures (bot-
the efficacy of the weighted connections with the learning                   tom left). Continuous learning of IT prototypes leads to acti-
rate ηs ; s ∈ { f orm, motion} indicates that the same core                  vation profiles with low selectivity (top right). Motion driven
mechanisms are devoted to learning in the form and mo-                       reinforcement leads to IT prototypes which signal snapshot
                                                  pre                        poses in synchrony with the gait (bottom right; for details,
tion pathway, respectively. The variables u j = f (x j ) and
  post
vi = f (yi ) are the firing rates driven by the membrane po-                 see text).
tential of pre- and post-synaptic cells, henceforth denoted as
activity. The activity v̄i of the post-synaptic cell is calculated           with Λ(•) denoting a spatial kernel for weighting the relative
by the temporal trace rule v̄ti = (1 − λ)v̄t−1
                                           i     + λvti , 0 < λ < 1          contribution of motion responses uφ (•) at spatial locations x
(Földiák, 1991). The trace rule (see also (Wallis & Rolls,                 in the 2-D image plane and with direction selectivity φ.1 The
1997; Rolls & Milward, 2000)) has been proposed to incor-                    motion energy signal itself is a function of time which is used
porate a short-term memory function for the cells to keep their              to steer the instar learning in the form pathway. We suggest
activation over a short temporal window while adapting their                 that different subpopulations of static form, or snapshot, rep-
weights. The term in brackets on the r.h.s. of learning equa-                resentations can be learned that correspond to either weakly
tion 1 serves as a biologically plausible mechanism to bound                 or strongly articulated postures. Here, we focus on snapshot
the growth of the cells’ input synaptic weights (Oja, 1982).                 poses corresponding to highly articulated postures with sig-
                                            post
The post-synaptic cells (with activity v̄i ) which gate the                  natures of maximum limb spreading. Motion energy at limbs
learning of their respective input weights are arranged in a                 drops during phases of high articulation when their appar-
competitive layer of neurons competing for the best matching                 ent direction of motion reverses. We incorporate the function
response and their subsequent ability to adapt their kernel of               g(•) to control a vigilance in snapshot learning to favor form
spatial input weights. In a nutshell, the layer of post-synaptic             inputs which co-occur with local motion energy minima, i.e.
neurons competes to select a winning node for a given in-                    when ∂t me = 0, given that ∂tt me > 0. In the weight adapta-
put presentation which, in turn, is allowed to automatically                          FF, f orm
                                                                             tion, ∆w ji        in Eqn.1, the learning rate is now gated by the
adapt their incoming (instar) synaptic weights. The tempo-
                                                                             motion dependent reinforcement, η f orm ·g(me ) which leads to
ral trace (or short-term memory) establishes that categories
                                                                             the revised learning rule
learn their average input over a short temporal interval thus
allowing small pertubations for the changing input signals.                          ∆w ji
                                                                                                FF, f orm                          post
                                                                                                            = η f orm · g(me ) · v̄i        · (u j − v̄i
                                                                                                                                                            pre   post       FF, f orm
                                                                                                                                                                         · w ji          ).
   Reinforcing snapshot learning. The Giese-Poggio model                                                                                                                                 (3)
(Giese & Poggio, 2003) suggests that sequence selectivity for
biological motion recognition is driven by sequences of static               Learning of Sequence-Selective Representations
snapshots. While the original model relies on snapshots that                 Categorial representations in the form and motion pathway,
were regularly sampled temporally, we suggest a mechanism                    namely in IT and MST, which were learned at the previ-
of how snapshots corresponding to strongly articulated poses                 ous stage, feed forward their activations to the stage of STS.
can be selected automatically. Such snapshot representations                 In order to stabilize the representations and activity distribu-
are learned in the form channel by utilizing a gating reinforce-             tions, even in the case of partial loss of input signals, the STS
ment signal which is driven by the complementary represen-                   sequence-selective representations send top-down signals to
tation of motion in the dorsal stage MT/MST. Formally, the                   their respective input stages.
weighted integration of motion energy over a given neighbor-
                                                                                            1 For
                                                                                      whole body motion considered here, we simply integrated
hood is calculated by
                          Z                                                  the motion energy over the entire ROI without subdividing the image
                                                                             region. An analysis at smaller scales might necessitate an integration
                   me =        uφ (x) · Λ(x)dxdφ                 (2)         over smaller overlapping patches.
                          Ω
                                                                       872

model area protoypes                                                                                         activities                           input
                                  1                                                                                                                 forward
   STS                                                                                                                                              recall
                                0.5
                                  0
                                                                                                                                                    opposite
                                  1
     IT                         0.5
                                  0
                                                                                                                                                    reverse
                                  1
   MST                          0.5
                                  0
                                                                                                               t [frames]
Figure 3: Response behavior of IT snapshot neurons, MST motion pattern neurons, and sequence-selective STS cells trained
by video input for a walker moving from left to right. Activations in the model areas are shown for different input conditions
for recall of the training sequence (top), opposite walker movement (middle), and walker displayed in reverse motion (bottom).
Line styles and colors encode the input test cases on the right. For details and brief discussion, see text.
   Learning of feedforward connections. Prototypical rep-                                rule. In steady-state each of the connection strengths em-
resentations with spatio-temporal sequence selectivity are                               anating from STS cells assumes a value corresponding to
suggested to exist in the cortical STS complex where both                                the post-synaptic activity distribution, which defines the cur-
                                                                                                                                                       pre
form and motion pathways converge. The selectivities of                                  rent input activation. Given an STS cell with attraction v̄i ,
model STS neurons are learned by again using a modified                                                                             post     out,FB
                                                                                         the top-down weight vector approaches u         = wi       , thus
Hebbian instar learning mechanism similar to the separate                                learning the expected average input. Combined with the tem-
learning of form and motion prototypes (Eqn.1),                                          poral trace, this establishes a representation in which each
                             post          pre          post
                                                                                         STS sequence-selective prototype encodes and memorizes in
       ∆win,FF
          ji   = ηseqFF · v̄i       · (u j − v̄i               · win,FF
                                                                   ji   ).   (4)         its weight pattern the expected driving input activity pattern
                                                                                         configuration from the form and motion pathway. Such a top-
The weighting kernel win,FFji  represents convergent IT → STS                            down weighting pattern can then be used to generate predic-
and MST → STS bottom-up input to a post-synaptic STS cell                                tions concerning the expected future input given the current
(instar). ηseqFF denotes the learning rate and u j and vi are the                        maximally activated prototype at the STS level.
firing rates of the pre- and post-synaptic neurons, respectively
(the post-synaptic activity is again calculated via a temporal                                                      Results
trace mechanism). The pre-synaptic activity for the receiv-
ing model STS cells are generated by concatenating form and                              The model has been tested in various computational experi-
motion output activations, namely u = uIT ∪ uMST .                                       ments, not all of which we can present here. In a first exper-
   Learning feedback connections. An important compo-                                    iment, we probed the properties of snapshot selection from
nent is that sequence-selective prototypes in STS in turn learn                          the input streams and their signature concerning static articu-
the output weights back to the segregated form and motion                                lations. The latter property has been motivated by the fact that
prototype representations, namely STS → IT + MST. Unlike                                 extremal articulation indicates configurations of implied mo-
the FF learning mechanisms, the learning here is gated by the                            tion, in turn, predictive for future motions. Results shown in
pre-synaptic cell (in STS) for their top-down weights, which                             Fig. 2 demonstrate that input activations (in V2) with strongly
reads                                                                                    articulated shapes cohere with local motion minima. Such
                                                                                         minima drive the reinforcement signal for learning whole
                                    pre          post
          ∆wout,FB
            ji     = ηseqFB · v̄i         · (u j        − wout,FB
                                                           ji     )          (5)         body form prototypes. Temporal response signatures for IT
                                                                                         prototypes are shown for disabled reinforcement (g(me ) = 1,
with the same components as in the bottom-up learning for-                               and when it is enabled (g(me ) monotonically decreasing func-
malism in Eqn.4. Bottom-up and top-down learning schemes                                 tion of me ).
slightly differ in the definition of the competitive terms (in                             We studied the response properties of STS representations
brackets). In the feedback learning we employ a differ-                                  and their motion sequence selectivity. There, a prototypical
ence term between post-synaptic activity and the weighting,                              sequence-selective representation is learned for a walker that
  post
u j − wout,FB
          ji    , omitting the additional weighting of the con-                          is traversing from left to right. After training of form, mo-
nectivity strength via the pre-synaptic activity as in the Oja                           tion and sequence representations, the network is probed by
                                                                                   873

                                                  input                                          IT & MST & Feedback
                                                                                             1
      40°            0°                -40°                                                0.5                                      activity
                                              activities
                                                                                             0
                                                           IT                                                             t [frames]
  1
                                                           MST
                                                           STS                                   IT & Feedback
0.5                                                                                          1
                                                                                           0.5                                      activity
  0                                                                                          0
      -40° -20° -10° -5° 0° 5° 10° 20° 40°                                                                                t [frames]
                       direction Φ
                                                                                STS       IT Prototype 01         IT Prototype 02
Figure 4: Response tunings of models cells in area IT (snap-                              MST Prototype 01        MST Prototype 02
shots), MST (motion patterns), and STS (sequence-selective
patterns) after training. Category representations have been              Figure 5: Selective removal of interconnections (lesioning).
learned for a walker moving along horizontal direction for                The model was trained using the same walking sequence
φ = 0◦ . Activities of prototypical cells are shown (bottom)              as in the second experiment (see Fig. 3 / forward recall).
which were probed by different inputs with varying move-                  The model was left untouched to provide a reference (top).
ment directions, i.e. walkers approaching or receding at dif-             Bottom-up (feedforward) connections between area MST and
ferent angles with respect to the horizontal reference axis               STS were removed, preventing any motion-related signal be-
(top). Data has been summarized into box plots showing the                ing propagated to STS (bottom). The amplitude of the IT
response variabilities of models cells as well as the monotonic           prototype activities remains almost the same, whereas the
decline in response for deviations from the target tuning. The            sequence-selective STS cell responds only at about half-
tuning width at half maximum response is around ±40◦ . The                magnitude (because of the missing support from the motion
variance of the MST / IT prototypes decreases towards larger              pathway). Note the feedback activities propagated from STS
deviations, depicting the loss of response selectivity of proto-          to MST optical flow pattern prototypes. We argue that this
types to different parts of a walkers gait.                               reflects the induction of increased fMRI BOLD response in
                                                                          human MT+ following the presentation of static implied mo-
                                                                          tion stimuli.
three different movement scenarios: a forward moving walker
with same profile and movement direction as in the training               a much larger variability.
phase (recall), a forward moving walker traversing from right                In an additional experiment we selectively lesioned of the
to left (opposite), and a backward moving walker (reverse).               model architecture, particularly investigating the effects of
Form/motion prototypes and the sequence representation are                extinguishing connections between model areas and the ac-
triggered maximally in the recall case while in the opposite              tivity flow between learned representations (Fig.5). The fully
case form and motion prototypes only respond minimally, and               connected model with learned IT / MST and STS feedfor-
so do the sequence-selective cells. In the reverse case the               ward and feedback connections was used as reference. When
form prototypes selectively match the input at high articula-             bottom-up connections from motion input (MST) were cut
tion configurations, while the motion responses remain min-               off the sequence-selective neuron responses in STS drop to
imal. As a consequence, the sequence-selective representa-                approximately half their response amplitude. Feedback from
tions respond at an intermediate level (Fig. 3). This evidence            STS invokes an amplification of activities in IT and MST rep-
is in line with the experimental findings by (Oram & Perrett,             resentations. We observe that FF activation from IT alone can
1996) and recent observations by (Singer & Sheinberg, 2010).              drive sequence neurons. Snapshot representations in IT drive
   We further investigated the direction tuning of the                    the STS sequence neurons which, in turn, send feedback sig-
sequence-selective prototypes. Here, we configured different              nals to the stages of IT and MST prototype representations. In
walkers with varying movement directions and speeds with                  the motion pathway such feedback elicits an increase in pre-
reference to a previously learned representation of a right-              synaptic activation. We argue that this reflects the induction
ward moving walker at a speed of 1 m/s. Walking directions                of increased fMRI BOLD response in human MT+ following
in the test cases were rotated by ±{5◦ , 10◦ , 20◦ , 40◦ }. Model         the presentation of static implied motion stimuli (Kourtzi &
simulations result in a direction tuning of STS cells with half           Kanwisher, 2000).
amplitude of approximately ±40 deg (Fig. 4). IT and MST
cells, on the other hand, also show a drop in response but have
                                                                    874

               Discussion and Conclusion                                                    Acknowledgements
                                                                       GL and HN have been supported by the SFB Transregio 62
We propose a biologically plausible model for the learning             funded by the German Research Foundation (DFG).
of animated motion sequences. The model builds upon neu-
rophysiological evidence about the cortical sites and specific                                   References
neuronal representations which contribute to articulated mo-
                                                                       Bayerl, P., & Neumann, H. (2004). Disambiguating visual
tion and implied motion perception. The main contributions
                                                                         motion through contextual feedback modulation. Neural
of the paper are several-fold: First, we suggest how prototype
                                                                         Comput, 16(10), 2041–2066.
representations in the form and motion pathways, namely in
                                                                       Escobar, M., & Kornprobst, P. (2012). Action recognition
model cortical areas IT and MST, can be established on the
                                                                         via bio-inspired features: The richness of center–surround
basis of probing the model architecture by sequences con-
                                                                         interaction. Comput Vis Image Und, 116(5), 593–605.
taining animated motions. Learning mechanisms are based
                                                                       Földiák, P. (1991). Learning invariance from transformation
on modified Hebbian schemes which are stabilized through
                                                                         sequences. Neural Comput, 3(2), 194–200.
a trace mechanisms and the incorportion of an objective
                                                                       Giese, M., & Poggio, T. (2003). Neural mechanisms for the
function taking the weight kernel saturation into account.
                                                                         recognition of biological movements. Nat Rev Neurosci,
Second, we suggest that sequence-selective cells in model
                                                                         4(3), 179–192.
area STS are learned by using the same learning mechanisms
                                                                       Jellema, T., & Perrett, D. (2003). Cells in monkey STS re-
but now by combining the responses of intermediate level
                                                                         sponsive to articulated body motions and consequent static
representations in the form and motion pathways. Third, the
                                                                         posture: a case of implied motion? Neuropsychologia,
learning of articulated poses (snapshots) is controlled by a
                                                                         41(13), 1728–1737.
reinforcement mechanism that enables Hebbian learning in
                                                                       Kourtzi, Z., & Kanwisher, N. (2000). Activation in human
the form pathway through cross-pathway motion-form inter-
                                                                         MT/MST by static images with implied motion. J Cogni-
action. Given an animated motion sequence, snapshots are
                                                                         tive Neurosci, 12(1), 48–55.
automatically selected as key poses corresponding to strong
                                                                       Oja, E. (1982). Simplified neuron model as a principal com-
body pose articulations. Finally, the sequence-selective cells
                                                                         ponent analyzer. J Math Biol, 15(3), 267–273.
in model STS project to their respective input representations
                                                                       Oram, M., & Perrett, D. (1996). Integration of form and
in the form and motion pathways. These feedback connec-
                                                                         motion in the anterior superior temporal polysensory area
tions are again learned by a Hebbian mechanism. Together,
                                                                         (STPa) of the macaque monkey. J Neurophysiol, 76(1),
the feedforward and the feedback interactions establish a
                                                                         109–129.
loop of recurrent processing to stabilize the patterns of form,
                                                                       Perrett, D., Harries, M., Bevan, R., Thomas, S., Benson, P.,
motion, and sequence representation. Via feedback, model
                                                                         Mistlin, A., . . . Ortega, J. (1989). Frameworks of analysis
STS cells generate a predictive signal through the backward
                                                                         for the neural representation of animate objects and actions.
connections’ weights to encode the expected matching input
                                                                         J Exp Biol, 146(1), 87–113.
that is suitable to match the currently activated sequence
                                                                       Riesenhuber, M., & Poggio, T. (1999). Hierarchical models
pattern. Together with the newly proposed feedback mecha-
                                                                         of object recognition in cortex. Nat Neurosci, 2, 1019–
nism the model is able to account for various experimental
                                                                         1025.
findings, in particular, the ability to infer and predict future
                                                                       Rolls, E. T., & Milward, T. T. (2000, November). A
motion sequence development from articulated postures
                                                                         model of invariant object recognition in the visual system:
(implied motion). Importantly, cells in STS are responsive to
                                                                         Learning rules, activation functions, lateral inhibition, and
both motion as well as static form (Oram & Perrett, 1996).
                                                                         information-based performance measures. Neural Comput,
The model predicts that the presentation of static key poses
                                                                         12(11), 2547–2572.
from previously learned sequences alone leads to enhanced
                                                                       Schindler, K., & Van Gool, L. (2008). Action snippets: How
activation in STS sequence selective neurons as observed in
                                                                         many frames does human action recognition require? In
(Jellema & Perrett, 2003). The model also hypothesizes how
                                                                         CVPR 2008 (pp. 1–8).
the presentation of static articulated poses leads to the emer-
                                                                       Singer, J., & Sheinberg, D. (2010). Temporal cortex neurons
gence of predictive motion perception and enhanced neural
                                                                         encode articulated actions as slow sequences of integrated
activations in the motion pathway (Kourtzi & Kanwisher,
                                                                         poses. J Neurosci, 30(8), 3133–3145.
2000). Furthermore, learned sequence-selective prototype
                                                                       Wallis, G., & Rolls, E. (1997). Invariant face and object
representations have direction tunings in response to walkers
                                                                         recognition in the visual system. Prog Neurobiol, 51(2),
in the range of ±40, similar to those reported in (Perrett et al.,
                                                                         167–194.
1989)). Once again, the model makes a testable prediction
                                                                       Weidenbacher, U., & Neumann, H. (2009). Extraction of
that articulated poses represent the snapshot frames that have
                                                                         surface-related features in a recurrent model of V1-V2 in-
been suggested by (Giese & Poggio, 2003) and that have
                                                                         teractions. PloS ONE, 4(6), e5909.
recently been tested experimentally by (Singer & Sheinberg,
2010).
                                                                   875

