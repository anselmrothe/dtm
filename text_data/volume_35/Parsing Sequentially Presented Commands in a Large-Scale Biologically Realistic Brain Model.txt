UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Parsing Sequentially Presented Commands in a Large-Scale Biologically Realistic Brain
Model
Permalink
https://escholarship.org/uc/item/69b5x2xh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Stewart, Terrence
Eliasmith, Chris
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                    Parsing Sequentially Presented Commands
                             in a Large-Scale Biologically Realistic Brain Model
                                          Terrence C. Stewart (tcstewar@uwaterloo.ca)
                                           Chris Eliasmith (celiasmith@uwaterloo.ca)
                                      Centre for Theoretical Neuroscience, University of Waterloo
                                   200 University Avenue West, Waterloo, Ontario N2L 3G1 Canada
                              Abstract                                                  Parsing Visual Commands
   We present a neural mechanism for interpreting and executing         To provide new instructions to a model that only has a
   visually presented commands. These are simple verb-noun              visual input, we need the model to process a sequential set
   commands (such as WRITE THREE) and can also include                  of images and convert that into an internal representation of
   conditionals ([if] SEE SEVEN, [then] WRITE THREE). We
   apply this to a simplified version of our large-scale functional
                                                                        a command. This is a simplified language comprehension
   brain model “Spaun”, where input is a 28x28 pixel visual             task, within a fairly restricted domain.
   stimulus, with a different pattern for each word. Output                Basic commands can be thought of as verb-noun pairs,
   controls a simulated arm, giving hand-written answers.               such as WRITE NINE. However, because the visual system
   Cortical areas for categorizing, storing, and interpreting           is limited to 28x28 pixels, it does not have the visual acuity
   information are controlled by the basal ganglia (action              to interpret full words at a time. Rather than flashing each
   selection) and thalamus (routing). The final model has
                                                                        letter in each word up individually (a fairly non-typical
   ~100,000 LIF spiking neurons. We show that the model is
   extremely robust to neural damage (40% of neurons can be             reading strategy), we use a single symbol for each word, and
   destroyed before performance drops significantly).                   present those symbols sequentially. So, for the command
   Performance also drops for visual display times less than            WRITE NINE, we present a “W” followed by a “9”.
   250ms.      Importantly, the system also scales to large                Valid commands are limited by the set of basic actions
   vocabularies (~100,000 nouns and verbs) without requiring an         that the model knows how to do. While the full Spaun
   exponentially large number of neurons.                               model can perform many operations including mental
   Keywords: neural engineering; parsing; cognitive control;            arithmetic, keeping track of elements in a list, and pattern
   spiking neurons; whole-brain systems; cognitive architecture         completion, for simplicity in this paper we only consider the
                                                                        actions WRITE (W), REMEMBER (R), and INCREASE
      Large-Scale Functional Brain Modelling                            (C). For example, the model could be told to remember a
Our goal is to produce models of human cognition that are               two, increase it, and write the result (“R 2, C #, W #”, where
specified down to the neural level. That is, we want to                 # is a general-purpose indexical referring to the number
know how the low-level neural details (including spikes and             currently being remembered, and a comma is a slight pause
various neurotransmitters) give rise to human behaviour via             between instructions). The correct result from this command
their complex interconnections and interactions. We have                would be the written number 3.
previously published our first step in this direction, which is            Furthermore, instructions can also include conditional
currently the world's largest functional brain model                    clauses based on what the model can currently SEE (“S”).
(Eliasmith et al., 2012). This model, “Spaun”, has 2.5-                 For example, “S 4, W 9” is interpreted as “if you see a four,
million spiking neurons, includes twenty different brain                then write a nine”. To do this, the model must be capable of
areas, and can perform eight different cognitive tasks                  representing structured relationships.
(including digit recognition, list memory, addition, and                   The goal of this work is to give a spiking neuron
pattern completion). Input is through a single eye with a 28            implementation of this parsing process, integrated within an
by 28 retina, and the output controls a simulated three-joint           existing spiking neuron model of the rest of the brain
six-muscle arm, allowing it to write its answers. Spaun is              (including vision, motor, working memory, and cognitive
told what task to perform via its visual input, so it must              control areas). To argue that this is a plausible model, we
selectively re-route information between brain areas as                 show that a) its performance degrades gracefully as neurons
appropriate for different tasks. This uses the cortex-basal             die, b) it fails on uninterpretable grammatical structures, and
ganglia-thalamus loop, where the basal ganglia performs                 c) it scales to human-sized vocabularies, dealing with the
action selection by comparing the current brain state to the            exponential growth of vocabulary combinations.
ideal brain state for each action, and the chosen action                   That said, there are considerable limitations to this work.
activates cortical communication channels via the thalamus.             It does not deal with token separation, since the symbols are
   One limitation with Spaun is that it cannot learn new                shown to it one at a time. It also does not handle ambiguous
tasks. The eight tasks it can perform are set by the synaptic           terms (all symbols have exactly one meaning). We are also
connections between cortex and basal ganglia. To address                not specifying the full developmental and learning process
this, the work presented here adds a new general-purpose                that results in this model (although existing learning rules
task for Spaun: one where it can be visually presented with             could be used, given a detailed error signal and large
commands for it to follow.                                              amounts of time).
                                                                    3460

           The Neural Engineering Framework                         brain). In general, discontinuous functions are very difficult
                                                                    for neurons to approximate.
The Neural Engineering Framework (NEF; Eliasmith &
Anderson, 2003) transforms a high-level description of the           Symbol-Like Processing with Spiking Neurons
variables being represented and the operations on those
variables into a detailed spiking-neuron model subject to           While the NEF allows us to convert algorithms that use
neurobiological constraints.                                        vectors and functions into spiking neuron models, a further
   In the NEF, neurons are organized into groups, and each          technique is needed to handle the symbol manipulation that
group forms a distributed representation of a particular            is the hallmark of cognitive activity. This is especially
variable. Different patterns of activity across the group           important for parsing and representing complex commands.
correspond to different values for that variable. These                The core idea is to have a particular vector for each
values are, in general, vectors, so a particular group of 2,000     atomic symbol that can be represented. For this paper, these
neurons might represent a 64-dimensional variable. While            vectors are chosen randomly, but they can also be chosen
the NEF supports any neuron type, for this paper we use             such that semantically related symbols have similar vectors.
standard leaky integrate-and-fire (LIF) neurons whose               To combine symbols, we perform computations on these
parameters (refractory period, capacitance, neurotransmitter        vectors, giving new vectors that represent the combination.
time constant, etc.) are set to be consistent with the details         There are a variety of computations that can be used to
of the particular brain regions being modelled.                     combine these vectors (Gayler, 2003), but for our model we
   Within a population of neurons, each neuron has a                follow Plate (2003). Here, symbols can be combined by
particular preferred direction vector. This is the vector for       vector addition (+) and circular convolution (⊛). Both
which that neuron will fire most strongly. These vectors e          operations are accurately approximated by the NEF method.
are randomly chosen along with the neuron gain α and bias              To demonstrate how this system works, consider
Jbias to produce a heterogeneous population of neurons. The         representing the command “If you see a 9, write an 8”. A
current flowing into a neuron when representing a vector x          simplistic approach would be to take vectors for all the
is given by Equation 1.                                             atomic concepts (SEE, NINE, WRITE, and EIGHT) and add
   Given a pattern of activity, we can estimate the currently       them together to represent the full sentence
                                                                    (SEE+NINE+WRITE+EIGHT). However, this does not
represented x value as        ∑d a  i i where ai is the neuron      work, since the resulting sentence loses all order
activity and d is a decoder given by Equation 2. This is the        information. In particular, the command “If you see an 8,
optimal least-squares linear estimate of x (the value being         write a 9” would result in exactly the same vector.
represented) given a (the current activity of the neurons).            To deal with this, we use circular convolution (⊛) and
   The key part of the NEF is that this decoder also allows us      introduce new vectors for denoting structural information.
to determine the synaptic connection weights between                The ⊛ operator takes two vectors and produces a new
neural groups that will force them to compute a desired             vector that is highly dissimilar to the original two. So
function. For example, if we want to connect a neural group         instead of WRITE+EIGHT we can do VERB⊛WRITE+
representing x to a neural group representing y such that           NOUN⊛EIGHT. Furthermore, we can nest this process to
y=Mx (where M is an arbitrary matrix), then the synaptic            make more complex phrases. The full command can be
connection weights between neuron i in the first population         represented by the vector S=CONDITION⊛(SEE⊛NINE)+
and neuron j in the second are given by Equation 3.                 VERB⊛WRITE+NOUN⊛EIGHT.
   For connections that compute nonlinear functions, we                Importantly, given this vector S that represents a full
adjust Equation 2 slightly as given in Equation 4. This finds       command, we can extract out the individual components.
a decoder that approximates the arbitrary function f(x).            Plate (2003) showed that a simple re-arranging of the
                                                                    elements of a vector makes an approximate inverse
    J=αe⋅x+J bias                                           (1)     operation. For example, if we want to know the main verb
    d=Γ       −1
                 Υ Γ ij =∫ ai a j dx Υ j =∫ a j xdx                 in S, we compute S⊛inv(VERB). The result will be
                                                            (2)     approximately WRITE. The accuracy of this approximation
    ωij =α j e j Md i                                       (3)     depends on the number of terms being added and the
       f ( x)                                                       dimensionality of the vectors. In particular, as the number
    d         =Γ  −1
                     Υ Γ ij =∫ ai a j dx Υ j =∫ a j f ( x ) dx      of dimensions increases, there is an exponential growth in
              (4)                                                   representational capacity.
                                                                       We refer to these vectors as semantic pointers. They are
It should be noted that the accuracy with which neurons will        semantic in that the vector itself has meaning about the
perform the desired computation using this technique is             whole. Most usefully, the similarity between vectors
dependent on many factors. This includes the neuron                 indicates the similarity of the full structure. WRITE
properties such as overall firing rate and their membrane           commands will have a higher degree of similarity to each
time constant. Accuracy can be increased arbitrarily by             other than to other commands. Furthermore, they are
increasing the number of neurons (but, of course, to be             pointers in the computer science sense because they can be
realistic we are constrained by the number of neurons in the        dereferenced, recovering (an approximation of) the original
                                                                3461

data. Semantic pointers are compressed representations, in        f(x)=x⊛VERB. Similarly, the noun population's connection
the same way that vision models can be thought of as              is optimized for the function f(x)=x⊛NOUN. As with all
compressing an image into a high-level representation.            synaptic connections in this model, this optimization is
                                                                  performed using Equations 3 and 4.
                          Vision
For vision, we adapt a Deep Belief Network (Hinton, 2010).
The input is a 28 by 28 pixel retinal image, which is then
processed by four different cortical layers. Each layer
learns to extract and compress the regular patterns in the        Figure 2: 5760 spiking neurons combining two arbitrary 64-
layer before it. We convert this model to spiking neurons         dimensional vectors (noun and verb) into a single 64-
by simulating each neuron in the DBN with ten realistic           dimensional vector phrase=verb⊛VERB+noun⊛NOUN.
spiking neurons and using Equations 3 and 4 to solve for the
connection weights that approximate the original model.              In order for this system to work in the context of an
   The output from the DBN (inferior temporal cortex) must        overall brain model, we need a mechanism to selectively
then be mapped to a semantic pointer. One way to perform          route information from visual areas to the two populations.
this mapping would be to use an associative cleanup               When the system sees WRITE it should pass this vector into
memory (Stewart, Tang, & Eliasmith, 2011), which scales           the verb neurons, and when it sees THREE it should pass
to hundreds of thousands of items but requires additional         that vector to the noun neurons. This sort of selective
neurons to recognize each item. For simplicity, here we use       routing of information is exactly what the cortex-basal
no additional neurons, but rather compute an approximate          ganglia-thalamus loop is believed to perform. We use our
mapping between the compressed representation of the              existing model for this loop, which is based on our spiking
visual stimulus and the desired semantic pointers (Equation       version of a model of action selection in the basal ganglia
5), where vi is the average output of the Deep Belief             (Stewart, Choo, & Eliasmith, 2010).
Network for a particular category (all the 3's, for example),        The basal ganglia selects between two actions. One
and si is the corresponding semantic pointer (THREE). As          action is to route information from the vision system to the
always, Equations 3 and 4 give the synaptic connections.          noun population, and the other is to route that same
                                                                  information to the verb population. To perform these
                                                       (5)        actions the output from the basal ganglia goes to the
                                                                  thalamus, where it releases the inhibition on the desired
                                                                  communication channel. (A communication channel is a
                                                                  connection that computes the function f(x)=x). If this is
                                                                  inhibited, the neurons do not fire, and so no information is
                                                                  passed.     Selecting the action releases the inhibition,
                                                                  allowing the information to flow.
                                                                     To decide which action to perform, the inputs to the basal
                                                                  ganglia must compute the utility of the two actions. For the
                                                                  first action, this is a function that outputs a 1 if there is a
                                                                  noun in vision, and a 0 otherwise. The second action is
                                                                  similar, but for identifying verbs. This is a simple classifier
                                                                  and can again be expressed as a function whose connection
                                                                  weights are computed with Equations 3 and 4.
                                                                     The resulting system is capable of taking a stream of
                                                                  visual stimulus as input and keeping track of the most recent
Figure 1: Converting visual input into the correct semantic
                                                                  noun and the most recent verb seen. This verb and noun are
pointer. For example, showing an image of a 7 to the retina
                                                                  then combined into a single vector representing that pair.
will produce the vector SEVEN in the vision population.
                     Simple Parsing
A first step towards parsing commands is to identify and
store noun-verb pairs. That is, given a visual input of
WRITE followed by THREE, we need one group of neurons
to represent the verb (WRITE) and another to represent the
noun (THREE). The outputs from these groups then drive a
third group of neurons to represent the full phrase
VERB⊛WRITE+NOUN⊛THREE. This is accomplished by
connecting the verb population to the phrase population
with connection weights optimized to perform the function
                                                              3462

Figure 3: Routing information from vision to the correct
noun and verb populations, depending on whether the visual
stimulus is categorized as a noun or a verb. Once routed,
the correct combined phrase is computed as in Figure 2.
                                                           3463

              Responding to Commands
Once the model has formed a single representation of the
command itself, we also need to show that it can execute
that command correctly. That is, not only can the
representation be encoded by spiking neurons, but it can
also be decoded by spiking neurons to perform a task.
   Since the focus of this paper is the parsing of a command,
we use a very simple system for executing commands. In
other work we show how to process significantly more
complex commands, (Choo & Eliasmith, submitted), but
those commands are directly injected into the brain model,                      Figure 4: Executing a WRITE action
rather than being presented visually and parsed.
   In this case, performing a command occurs via a new            correctly interpreting TWO WRITE as a command.
action added to the basal ganglia. It has a high utility when     However, as demonstrated in the section on Conditional
there is no visual input and when the phrase is similar to        Statements, word order does matter for complex commands.
VERB⊛WRITE.         When selected, this action routes the           The spike patterns shown in Figure 5 provide some
information from phrase to motor while convolving it with         insight into the performance of the model. In the vision
the inverse of NOUN.              Thus, if the phrase is          row, we can see different patterns of activity for each visual
VERB⊛WRITE+NOUN⊛FOUR,                 the semantic pointer        input, as expected. The pattern for “W” and the pattern for
inv(NOUN)⊛(VERB⊛WRITE+NOUN⊛FOUR)                      will be     seeing nothing at all are quite distinct. Similarly, the spike
routed to the motor area. Since NOUN and inv(NOUN)                patterns in the noun and verb populations change depending
approximately cancel, the value set to the motor area will be     on which term is currently being memorized, and these
close to the ideal vector for FOUR. This is mapped to a           patterns in turn affect the phrase population.
series of hand positions using the same method as Eq. 5.            Another feature that can be seen in Figure 5 is the
   The behaviour of the model is shown in Figure 5. The           cognitive reaction time. Each symbol is shown for 0.5
visual input is shown in the top row, and the written             seconds, but the motor output is clearly delayed slightly. For
responses are shown in the bottom row. The other rows             example, the visual input is cleared at t=1.0s, but the spiking
show the spiking behaviour of 50 neurons from each of the         behaviour in motor doesn't change until t=1.05s. This is the
key brain areas in the model.                                     time required for the model to notice the change in visual
   The first thing to note is that the model performs             input, perform action selection in the basal ganglia, release
accurately. The correct response is given for each case.          the inhibition in the thalamus, and allow the information
Furthermore, it should be noted that the two words in the         from the phrase neurons to pass to the motor neurons. The
command can be given in either order (WRITE FIVE versus           exact amount of time required is a function of the
TWO WRITE). This is because we have not imposed a                 connectivity and neurotransmitter time constants, all of
particular grammatical order. While it would be possible to       which are taken from neurological data (so they are not free
do so, we note that English speakers are quite capable of         parameters). For more analysis of this feature of the basal
                                                                  ganglia model, see (Stewart, Choo, & Eliasmith, 2010).
           Figure 5: Behaviour of the model given three commands: WRITE THREE, WRITE FIVE, and TWO WRITE.
                                                              3464

                          Memory                                   Model Performance
To demonstrate that this system can parse commands other           The behaviour of this model in a variety of conditions is
than WRITE <number>, we add a memory action. If the                shown in Figure 7. For each condition, new neurons (with
model is told to REMEMBER 4 (“R 4”), the phrase will be            preferred direction vectors, gains, and background currents)
similar to VERB⊛REMEMBER. We add an action for this                were generated, and Equations 3 and 4 were used to solve
condition that routes the phrase information to the memory         for all the synaptic connection weights.
while transforming it by inv(NOUN). As with the WRITE                 First, the maximum vocabulary size (the largest number
action, this extracts the FOUR from the phrase. For this           of nouns such that there is still a 95% chance of correctly
action, the output vector is routed to a working memory            responding) scales exponentially as the number of neurons
area. This is a group of neurons that stores a vector (like        per population increases. This is an expected consequence
every other group of neurons in the model), but that has a         of vector representations (e.g., Plate, 2003), as the number
communication channel back to itself. This recurrent               of dimensions accurately represented scales linearly with the
connection causes the neurons to maintain their own state          number of neurons, while the volume of a hypersphere
after the input is removed. This structure has been shown to       scales exponentially with the number of dimensions.
match neural behaviour of visual working memory (Singh                Second, the model is robust to destruction of neurons. To
and Eliasmith, 2006), and is stable over long periods of time      simulate neural death, we randomly delete neurons from
(tens of seconds).                                                 every population, and then re-use Equations 3 and 4 to
   Finally, we show that we can extract information from           compute new connection weights between the remaining
working memory by adding a special write action WRITE              neurons. Performance decreases, but remains above well
NUMBER (“W #”). This action has a high utility when the            above chance until less than 40% of the neurons remain.
phrase is VERB⊛WRITE+NOUN⊛NUMBER and causes the                    This shows a gradual degradation in behaviour, rather than
information in working memory to be routed to the motor            catastrophic failure.
system.                                                               Finally, we show the model performs well for varying
   The result (Figure 6) is a system that can respond              stimulus presentation times, but poor performance when
correctly to two different verbs and ten nouns (only ZERO          symbols are seen for less than 250 milliseconds.
through NINE were implemented). Importantly, adding the
new action did not require any modifications to the phrase
population. This is due to the fact that the semantic pointers
used to represent the phrase are simply fixed-length vectors,
and the phrase population is capable of storing any vector.
No modifications to that population are needed to let it store
a new vector like VERB⊛REMEMBER+NOUN⊛THREE,
even if it has never seen it before.
   In other words, the model does not require an exponential
growth in numbers of neurons in order to handle the
exponential growth in possible phrases that it can correctly
interpret. Adding new actions only requires adding the
neural populations needed to perform that action (in this
case, the working memory population) and new connections
between existing populations (in this case, phrase) and the
basal ganglia and thalamus.
                                                                    Figure 7: Model performance for varying vocabulary sizes,
                                                                     neural destruction, and display times. Input is of the form
Figure 6: A model with REMEMBER and WRITE actions.                  “R <number>, W #”, and an output is judged correct if the
Given an input REMEMBER SIX <long pause> WRITE                       model writes the correct number. Shaded area is the 95%
NUMBER it will write the number 6.                                           bootstrap confidence interval over 50 trials.
                                                               3465

                 Conditional Statements                                                         Conclusion
The method used to add the REMEMBER action can be used                 We have shown how a model consisting of spiking leaky-
to add many new actions. For instance, an INCREMENT                    integrate-and-fire neurons with properties and connection
action can be added which increases the number stored in               patterns that match the human brain can take a visually
memory. However, to show that this method extends to more              presented input command, parse it, and perform the correct
complex rules, we now consider the parsing of a conditional            action. This works for simple verb-noun commands and for
rule such as “if you see a six, write a one”. Using “S” to as          more complex conditional commands, and also scales up to
the symbol for SEE, we can present this to the model as “S 6           a vocabulary size of hundreds of thousands of terms. The
W 1”. We then add actions to the basal ganglia such that a             majority of the neural components are identical those in our
phrase of VERB⊛SEE will cause that phrase to be routed                 previous models (e.g. Eliasmith et al., 2012).
to a new condition group of neurons. A global state                       To perform this parsing, the model builds a single
population is created, which gets inputs from all cortical             combined vector representation of the command. This
areas that could be used as part of a condition (in this case,         resulting structured representation is of exactly the same
just vision), so that if vision is TWO then the value                  form as those we have used in other neural models. As
TWO⊛SEE will be added to state.               The state and            such, this model provides a potential explanation as to how
condition vectors are then compared (by computing the dot              brains can form and manipulate these symbol-like structures
product) in a similarity population. Finally, the go/nogo              that are found throughout cognition.
population uses the similarity and condition values to                    That said, the current model has many limitations. It does
compute a penalty to be applied to the utilities of actions in         not impose particular grammatical rules (other than avoiding
the basal ganglia. That is, it decreases the utility if there is a     center embedding). Perhaps relatedly, it does not address
condition but condition does not match the current state.              the problem of ambiguous classifications. It also does not
   Importantly, once the condition is stored in a separate             perform token separation, as it requires that the input be
neural population, we can now combine the condition and                already sequentially arranged. Fortunately, these problems
the phrase into a single semantic pointer. For this case, the          have been addressed by other researchers, and our ongoing
resulting vector would be CONDITION⊛(SEE⊛SIX)                          work is to adapt their solutions to the constraints of a
+VERB⊛WRITE+NOUN⊛ONE. This is a single vector                          biologically realistic spiking model. In particular, Ball
representing a complex, syntactically structured command               (2011) provides an extensive project to process natural
that can be successfully executed by this model. In (Choo              language speech using the ACT-R cognitive architecture,
& Eliasmith, submitted), we develop a model capable of                 which may be adaptable to our neural framework.
following a collection of rules of this form, but the model
presented here is the first biologically realistic spiking                                      References
model capable of taking the sequential input “S 6 W 1” and             Ball, J. (2011). A Pseudo-Deterministic Model of Human
parsing it to create the correct semantic pointer vector.               Language Processing. 33rd Cog. Sci. Society Conference.
   Interestingly, the model supports some syntactic variation,
such as “6 S 1 W” or “6 S W 1”. However, it will not                   Choo, X and Eliasmith, C. (submitted). General Instruction
perform correctly when one phrase is embedded in the                      Following in a Large-Scale Biologically Plausible Brain
center of the other (“S W 6 1”, for example). This difficulty             Model. 35th Cog. Sci. Society Conference.
with center embedding is a well-studied feature of natural
languages, and appears naturally in this model from the                Eliasmith, C. (2013). How to build a brain. Oxford
processing available to neural populations.                               University Press, New York, NY.
   Finally, in order to successfully respond to a condition            Eliasmith, C. & Anderson, C. (2003). Neural Engineering.
instruction in the other order (“W 1 S 6”), we must also add              Cambridge: MIT Press.Eliasmith et al., 2012
an extra action rule which stores the initial phrase                   Gayler, R. (2003). Vector Symbolic Architectures Answer
(VERB⊛WRITE+NOUN⊛ONE)                 in     memory        before         Jackendoff’s Challenges for Cognitive Neuroscience, in
processing the conditional phrase. This extra cognitive load              Slezak, P. (ed). Int. Conference on Cognitive Science,
indicates this model finds it easier to process “If you see a             Sydney: University of New South Wales, 133–138.
six, write a one” than “Write a one if you see a six”.                 Hinton, G.E. (2010). Learning to represent visual input.
                                                                          Phil. Trans. Roy. Soc. B, 365, 177-184.
                                                                       Plate, T. (2003). Holographic Reduced Representations,
                                                                          CSLI Publications, Stanford, CA.
                                                                       Singh, R., & Eliasmith, C. (2006). Higher-dimensional
                                                                       neurons explain the tuning and dynamics of working
                                                                       memory cells. Journal of Neuroscience, 26, 3667-3678.
                                                                       Stewart, T.C., Choo, X., and Eliasmith, C. (2010). Dynamic
                                                                          Behaviour of a Spiking Model of Action Selection in the
   Figure 8: Additions needed for conditional instructions.               Basal Ganglia. 10th Int. Conf. on Cognitive Modeling.
                                                                   3466

Stewart, T. C., Tang Y., & Eliasmith C. (2011). A
  Biologically Realistic Cleanup Memory: Autoassociation
  in Spiking Neurons. Cog.Systems Research. 12(2), 84-92.
                                                          3467

