UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Discovering Pronoun Categories using Discourse Information
Permalink
https://escholarship.org/uc/item/2t16h7np
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Orita, Naho
McKeown, Rebecca
Feldman, Naomi
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    Discovering Pronoun Categories using Discourse Information
                                                       Naho Orita (naho@umd.edu)
                                             Rebecca McKeown (rmckeown@umd.edu)
                                                  Naomi H. Feldman (nhf@umd.edu)
                                                       Jeffrey Lidz (jlidz@umd.edu)
           Department of Linguistics, 1401 Marie Mount Hall, University of Maryland, College Park, MD 20742 USA
                                            Jordan Boyd-Graber (jbg@umiacs.umd.edu)
             College of Information Studies, South Hornbake, University of Maryland, College Park, MD 20742 USA
   University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742 USA
                               Abstract                                                                     S
   Interpretation of a pronoun is driven by properties of syntactic
   distribution. Consequently, acquiring the meaning and the dis-                                 NP              VP
   tribution are intertwined. In order to learn that a pronoun is re-
   flexive, learners need to know which entity the pronoun refers                                              V       NP
   to in a sentence, but in order to infer its referent they need                            Det       N
   to know that the pronoun is reflexive. This study examines
   whether discourse information is the information source that                           Alice’s    sister   saw    herself
   the learner might use to acquire grammatical categories of pro-
   nouns. Experimental results demonstrate that adults can use            Figure 1: Syntactic tree showing a c-command relationship
   discourse information to accurately guess the referents of pro-
   nouns. Simulations show that a Bayesian model using guesses            between the antecedent Alice’s sister and the pronoun herself.
   from the experiment as an estimate of the discourse informa-
   tion successfully categorizes English pronouns into categories
   corresponding to reflexives and non-reflexives. Together, these        contexts where reflexives do not appear: approximately con-
   results suggest that knowing which entities are likely to be re-       texts in which the antecedent is either non-local, not in a c-
   ferred to in the discourse can help learners acquire grammatical
   categories of pronouns.                                                commanding position, or both (Chomsky, 1973). This means
   Keywords: language acquisition; Bayesian modeling
                                                                          that the relationship between the grammatical positions of an-
                                                                          tecedents and pronouns, as characterized by locality and c-
   English speakers know that the sentence in (1) means that              command, defines the distribution of grammatical categories
Alice saw Alice in the mirror and the sentence in (2) means               of pronouns in English.
that Alice saw someone else in the mirror.                                   Critically, these grammatical constraints concern the rela-
                                                                          tionship between a pronoun and its antecedent. This means
(1) Alice saw herself in the mirror.
                                                                          that syntactic knowledge alone is insufficient for acquiring
(2) Alice saw her in the mirror.                                          pronouns, because it cannot be applied without knowing the
These interpretations reflect adults’ knowledge that reflexives           intended antecedent of a pronoun. In order to learn that her-
like herself require different syntactic relations with their an-         self is reflexive, learners need to interpret the sentence in (1)
tecedents than non-reflexives like her. Evidence shows that               as ‘Alice saw Alice’, recognizing that Alice and herself co-
children acquiring various languages have knowledge of the                refer to the same entity. However, in order to interpret the
grammatical distributions of pronouns (Jakubowicz, 1984;                  meaning of the sentence, they need to use the knowledge that
Crain & McKee, 1985, among many). However, it is not yet                  herself is a reflexive pronoun, whereas her is a non-reflexive
known how children acquire this knowledge.                                pronoun. This circularity poses a potentially difficult problem
   In English, the distribution of pronouns is governed by                for children acquiring language.
two constraints on the pronoun-antecedent relation: locality                 In this paper we show that discourse information can help
and c-command. Locality refers to the domain of the syn-                  learners categorize pronouns into appropriate distributional
tactic relation between the pronoun and its antecedent. Re-               classes. If learners use discourse information to predict that
flexive pronouns must have their antecedents in the local do-             the pronoun herself in (1) is likely to refer to Alice and the
main, corresponding approximately the same clause in En-                  pronoun her in (2) is likely to refer to someone else, this pro-
glish (Chomsky, 1973). The second constraint is that re-                  vides information that can help them categorize these pro-
flexive pronouns must be c-commanded by their antecedent                  nouns into different classes. We examine (i) to what extent
(Reinhart, 1976). In the sentence ‘Alice’s sister saw herself’,           discourse context is informative for determining the referent
English speakers know that the antecedent of herself is not               of a pronoun and (ii) whether this estimate of a pronoun’s
Alice, but Alice’s sister. That is, when the hierarchical struc-          reference is sufficient for learning to classify pronouns.
ture of the sentence is represented as a tree in Figure 1, the re-           The paper is organized as follows. Our next section de-
flexive herself is contained in the sister node of its antecedent         scribes a behavioral experiment that measures the discourse
Alice’s sister. Non-reflexive pronouns appear in exactly those            information available to listeners. The following section
                                                                      3193

presents Bayesian modeling results showing that this dis-              25 were lexical NPs (names – including Mommy or Daddy
course information can help bootstrap grammatical knowl-               – and definite descriptions). This led to a total of 75 test
edge of pronoun categories. Finally, the last section addresses        items. Within the test items, frequencies of corresponding
open questions and implications.                                       non-reflexive and reflexive pronouns were matched (e.g., me
                                                                       was matched in frequency with myself, etc).
           Experiment 1: Human Simulation                                 The dialogues were chosen randomly from all adult utter-
To test to what extent language contexts are informative about         ances in CHILDES that used the relevant verbs with the rele-
the referents of pronouns, we used a variant of the human sim-         vant type of NP object, with the exception that we threw out
ulation paradigm (Gillette, Gleitman, Gleitman, & Lederer,             utterances that were direct repetitions of a previous line or
1999). In this paradigm, adult participants guess the identity         that were well-known quotations. Finally, the materials were
of a missing word on the basis of linguistic and/or situational        chosen to balance, as much as possible, the person of the pro-
data. Because participants know there is a word, but not what          noun object of the verb (though due to an imbalance in the
it is, they are simulating what it is like to be a language learner    available CHILDES data we were still left with more second-
who hears a word but does not know its meaning. A goal of              person objects than first or third person). In addition to the
the human simulation paradigm is to see what can be inferred           lines of dialogue, each item in the experiment provided a list
about the meaning of a word based on information present ei-           of participants in the conversation and the age of the child in
ther in the linguistic input or in the scene. Past experiments         the conversation. No information was given about the situa-
using the human simulation paradigm have examined the de-              tion or context in which the conversation took place.
gree to which adults (Gillette et al., 1999; Kako, 2005) or               After each excerpt, participants were given a list of 15
older children (Piccin & Waxman, 2007) can guess identities            choices for what NP could have gone in the blank. The
of common nouns and/or verbs.                                          choices always included the same five reflexive pronouns
    In our experiment, adult participants were shown text ex-          (yourself, myself, ourselves, himself, themselves) and non-
cerpts of conversations between adults and children. Their             reflexive pronouns (you, me, us, him, them). They also in-
task was to guess the identity of a word or phrase that had            cluded five lexical NPs which would have been prominent
been blanked out, which was either a reflexive pronoun, a              in the conversation: e.g., the names of the participants (in-
non-reflexive pronoun or a lexical noun phrase. The goal was           cluding Mommy or Daddy) and prominent people or objects
to determine whether conversational context provides suffi-            mentioned in the conversational excerpts. If the actual sen-
cient information for adults to guess what is being referred to.       tence contained a lexical NP then this lexical NP was one of
If so, this would provide evidence in favor of the idea that lan-      the five lexical NPs provided. The NPs were presented in
guage learners can determine the referents of pronouns they            alphabetical order.
do not yet know based on conversational context.                       Procedure Participants were given an hour in a quiet room
                                                                       to complete the experiment. Test items were presented on
Methods
                                                                       paper, one per page. Participants were instructed to read the
Participants Participants were 40 undergraduates at the                dialogues, which were real conversations between adults and
University of Maryland, College Park (11 men, 29 women).               children, and pick the word or phrase (from the list of 15
All were native English speakers and all were at least 18              choices) they thought belonged in the blank. Participants
years old. Participants were enrolled in introductory linguis-         wrote answers on a separate answer sheet. The test items
tics courses and received course credit for their participation.       were presented in random order. Twenty participants received
Materials Text excerpts of real recorded conversations                 the first 38 test items, and the remaining twenty participants
between adults and young children were taken from the                  received the remaining 37 test items.
ENG-USA section of the CHILDES database (MacWhinney,
                                                                       Results and Discussion
2000). In each excerpt, one line was bolded. This bolded line
had a noun phrase (NP) that had been deleted and replaced              Overall, participants were highly accurate at guessing the cor-
with a blank. The deleted noun phrase always came from                 rect word from a list of 15 choices. The first row in Ta-
an adult utterance. There were 12 lines of dialogue before             ble 1 breaks up guesses of the correct word by syntactic
the bolded line and six lines afterwards. Every deleted noun           category of the NP (reflexive pronouns, non-reflexive pro-
phrase was the object of one of five verbs: hurt, see, help, dry,      nouns, or lexical NPs). Individual participants chose the cor-
and cover. Using the same verbs in all contexts allowed us             rect NP out of 15 choices an average of 63.8% of the time.
to factor out any possible contribution of verb knowledge to           This ranged from 32.4% for the least accurate participant to
determining which pronoun was intended. The deleted noun               84.2% for the most accurate participant, with a standard de-
phrases belonged to one of three categories: 25 were reflexive         viation of 10.6%, and was significantly better than chance
pronouns (4 tokens of myself, 1 token of ourselves, 7 tokens           (t(39) = 34.19, p < 0.0001). These results show that adults
of himself, 10 tokens of yourself, and 3 tokens of themselves),        can usually guess the identity of a missing NP given only a
25 were non-reflexive pronouns (4 tokens of me, 1 token of             small amount of linguistic context.
us, 7 tokens of him, 10 tokens of you, 3 tokens of them), and             However, these results underestimate participants’ ability
                                                                   3194

                      Lexical NP   Non-reflexive    Reflexive       formation for acquiring grammatical categories of pronouns.
        % correct
          word          61.75           70.25         64.25         To explore this possibility, we formalize a Bayesian model
       % plausibly                                                  that learns to categorize pronouns.
      correct word      66.75           81.25          68
                                                                                 Experiment 2: Bayesian Model
Table 1: Percentage of correct answers and answers with a
plausibly correct referent in Experiment 1                          In this section, we develop a Bayesian model that inte-
                                                                    grates the discourse information measured in Experiment 1.
                       Lexical NP     Non-reflexive   Reflexive     This model investigates whether the information in discourse
     % Lexical NP                                                   could be sufficient to learn the grammatical categories of
         guesses           71.8           23.4          15.8        English pronouns in principle (a computational-level model;
    % Non-reflexive
         guesses           23.2           73.4           16         Marr, 1982). The model discovers:
       % Reflexive
         guesses            5              3.2          68.2       1. how many pronoun categories there are in a language
                                                                   2. the distribution of pronouns in each category
      Table 2: Confusion matrix obtained in Experiment 1           3. which syntactic position of an antecedent is associated with
                                                                       each pronoun category
to guess what is being referred to. The second row in Ta-           This ideal learner is assumed to have (a) discourse knowledge
ble 1 shows guesses of a plausibly correct word, a word that        that helps define the distribution of the potential antecedents,
plausibly had the same intended referent as the correct word        (b) syntactic knowledge relevant to pronoun categories (de-
(for instance, a pronoun with the same gender/number fea-           tails follow), and (c) lexical knowledge that is sufficient for
tures as the name that had actually been used, or vice versa).      distinguishing pronouns from lexical noun phrases. Other
These results show that adults are good at guessing which en-       linguistic information relevant to pronouns, such as gender
tity is referred to given a context, irrespective of grammatical    and number, is not represented in our model; we ask simply
knowledge relevant to pronouns.                                     whether our ideal learner can acquire two categories corre-
   Table 2 breaks up the results by syntactic category of the       sponding to reflexive and non-reflexive pronouns.
NP. Participants’ guesses were usually of the same category            Regarding (b) above, this ideal learner is assumed to al-
that the actual word had been. Importantly, adults usually          ready know locality and c-command before learning pro-
guessed correctly whether the missing word had been a re-           noun categories, and is further assumed to know that
flexive pronoun—when the word actually had been reflexive,          these are relevant for categorizing pronouns. Thus, the
participants guessed a reflexive 68.2% of the time. When the        learner is able to identify the syntactic position of each
word had been a lexical NP or a non-reflexive pronoun, they         potential antecedent. The model distinguishes four syn-
almost never guessed that it had been a reflexive.                  tactic positions based on the knowledge of locality and
   This task parallels that of a child identifying an unfamil-      c-command; [+local,+c-command], [+local,-c-command],
iar word. Of course, the parallel is not complete. In some          [-local,+c-command], and [-local,-c-command]. In English,
ways, adult participants were provided with less information        if an antecedent is in a syntactic position described by
than the children they were meant to simulate: they only re-        [+local,+c-command], that pronoun must be a reflexive pro-
ceived a small excerpt of the conversation and did not receive      noun. If the potential antecedent is elsewhere, that pro-
any visual information. In other ways, the participants had         noun must be a non-reflexive pronoun. However, the learner
more data: they already knew the meanings of all of the             does not know in advance which syntactic position is associ-
other words in the conversation, they had full syntactic and        ated with which pronoun category, and needs to acquire this
discourse knowledge where children might only have par-             knowledge from the input. We return to this issue of prior
tial knowledge (e.g., Arnold, Brown-Schmidt, & Trueswell,           syntactic knowledge in the Discussion.
2007), and they were limited to 15 choices of possible mean-
                                                                    Generative Model
ing. Furthermore, choosing an answer in this experiment was
not subject to any time pressures, whereas in actual acquisi-       Our model assumes the following generative process. For
tion processing speed could potentially impact the learner’s        each pronoun, an antecedent in one of the four syntactic posi-
ability to use the discourse context as an information source.      tions described above is chosen given prior discourse knowl-
However, to the extent that the adult simulation reflects the       edge (D ). Then a pronoun category is chosen based on the
prior information presented in the discourse, it provides an        syntactic position of the antecedent, and a pronoun is gener-
estimate of the information that children might have access         ated from the chosen pronoun category.
to. Where adults (who already know the distribution of re-             Figure 2 illustrates this process with a graphical model.1
flexives) can guess that a missing word is reflexive, a child       Each antecedent category distribution θ j is a random variable
might be able to guess that a missing word co-refers with               1 This model is a nonparametric extension to the author-topic
a specific NP. Together with syntactic knowledge of locality        model (Rosen-Zvi, Griffiths, Steyvers, & Smyth, 2004) that allows
and c-command, this should provide learners with useful in-         for an infinite number of categories (called topics in their model).
                                                                3195

                                   Given the set of entities             Prior Knowledge
                                   in discourse:
                                                                         The observed discourse knowledge D defines a prior distri-
             γ                     1. Choose an antecedent in a          bution over potential antecedents in the discourse. Recall that
                    α         x       syntactic position x
                                                                         our ideal learner maps each antecedent in the discourse deter-
                                   2. Choose a pronoun category          ministically to its syntactic position (defined in terms of local-
            θ0      θ         z       z given the syntactic              ity and c-command), and in this way D defines a distribution
                       J              position x of the antecedent       over syntactic positions x for each pronoun’s antecedent.
             β      ϕ       w      3. Choose a pronoun w given              Rather than specify a parametric form for this prior distri-
                      ∞         N     the pronoun category z             bution, we estimate it directly from participants’ responses
                                                                         from Experiment 1. In one experimental item, for exam-
                    Figure 2: Graphical Model                            ple, participants guessed the identity of the missing word in
                                                                         the sentence “You drying off?”. Nine out of 20 partici-
                                                                         pants guessed that the missing word is yourself, six out of 20
 that encodes the distribution over pronoun categories favored           guessed him, three out of 20 guessed me, and two out of 20
 by an antecedent in syntactic position j. For example, the              guessed Seth. Under the assumption that experimental par-
 category reflexive would have high probability in the distri-           ticipants have sampled their responses from a shared prior
 bution θ[+local,+c-command] . (Here we use the category name            distribution over entities in the discourse, these guesses pro-
 reflexive for exposition, but the model does not associate any          vide an estimate of participants’ beliefs about how likely each
 labels with the pronoun categories it recovers.) Each cate-             entity is to be referred to in the discourse.
 gory word distribution φk is a distribution over words that en-            Where participants chose yourself, the antecedent of this
 codes the probability distribution over pronouns in pronoun             pronoun is you, which is a local and c-commanding an-
 category k. For example, pronouns such as herself and my-               tecedent. Where participants chose him and me, the an-
 self would have high probabilities in the distribution φreflexive .     tecedents could be in any of the remaining three syntac-
 In addition to learning this distribution, our model learns the         tic positions, but in this particular dialogue the only poten-
 number of pronoun categories needed to describe the data.               tial antecedents for non-reflexives are neither local nor c-
 For each pronoun in the corpus, an antecedent in a syntac-              commanding.2 We ignored responses in which participants
 tic position x is assumed to be sampled from a distribution             chose lexical NPs (here Seth) based on the assumption that
 we refer to as discourse knowledge D (see the next section              learners distinguish pronouns from lexical NPs. We then nor-
 for the details). A pronoun category z is then sampled from             malized each count by the total number of pronoun guesses.
 the multinomial distribution with parameter θ associated with           The resulting prior distribution over syntactic positions for
 the syntactic position x of the antecedent and a pronoun w is           antecedents in this example is p(x[+local,+c-command] |D ) = 0.5
 sampled from a multinomial distribution with parameter φ as-            and p(x[−local,−c-command] |D ) = 0.5. In this way the results
 sociated with pronoun category z.                                       from Experiment 1 provide us with an informative prior dis-
    To learn the number of pronoun categories based on the               tribution regarding which entities are likely to be referred to
 observed data, we use the hierarchical Dirichlet process (Teh,          in the discourse, and through simulations we can test whether
 Jordan, Beal, & Blei, 2006). The advantage of this model is             this prior knowledge helps an ideal learner acquire pronoun
 that it allows the model to flexibly learn how many categories          categories3.
 are present in the data, while still allowing categories to ap-
 pear across multiple grammatical contexts. The summary of               Inference
 the generative process follows.                                         Given this generative process, we can use Bayesian infer-
                                                                         ence to recover the learner’s beliefs about pronoun categories.
                                                                         We use the Gibbs sampling algorithm from Rosen-Zvi et al.
1. Draw a distribution over pronoun categories θ0 ∼ GEM(γ),
                                                                         (2004) to estimate latent variables: the antecedent-category
    where GEM is the Griffiths, Engen, McCosky distribution
                                                                         parameter θ, the category-word parameter φ, the antecedent’s
    (Pitman, 2002).
                                                                         syntactic position x, and the pronoun category z. The as-
2. For each antecedent syntactic position j = 1 . . . 4, draw a
                                                                         signments of x and z for a particular token are sampled as a
    pronoun category distribution θ j ∼ DP(α, θ0 ).
                                                                         block, conditioned on everything else, so that in each iteration
3. For each pronoun category k = 1 . . . ∞, draw a distribution
                                                                         we compute the conditional distribution p(xi , zi |wi , x−i , z−i )
    over tokens φk ∼ Dir(β).
                                                                         where x−i and z−i denote all syntactic position and category
4. For each pronoun in the corpus n = 1 . . . N
                                                                             2 In cases of non-reflexive guesses where potential antecedents
  (a) Draw an antecedent syntactic position from the dis-
                                                                         appeared in multiple syntactic positions, we assumed the prior prob-
       course knowledge xn ∼ D                                           ability for each syntactic position to be proportional to the number
  (b) Draw a pronoun category zn ∼ Mult(θxn ).                           of potential antecedents in that position.
  (c) Draw a word wn ∼ Mult(φzn ).                                           3 This prior distribution differs from the distribution seen in Ta-
                                                                         bles 1 and 2 because it is based on individual experimental items
                                                                         rather than on aggregated data.
                                                                     3196

                                                                                   Category 1                       Category 2
assignments not including the ith pronoun. This is propor-                         Word         p(word|category)    Word          p(word|category)
tional to                                                                          him          0.5                 yourself      0.4
                                                                                   me           0.29                himself       0.28
                                                                                   them         0.21                myself        0.16
       p(wi |xi , zi , x−i , z−i ) · p(zi |xi , x−i , z−i ) · p(xi |D )            us           0.0                 themselves    0.12
                                                                                   you          0.0                 us            0.04
                                                                                   myself       0.0                 me            0.0
where the first term is the likelihood function from Rosen-                        yourself     0.0                 you           0.0
                                                                                   himself      0.0                 him           0.0
Zvi et al. (2004), the second is defined by the hierarchical                       themselves   0.0                 them          0.0
                                                                                   ourselves    0.0                 ourselves     0.0
Dirichlet process (Teh et al., 2006), and the third is estimated
directly from participants’ responses in Experiment 1.                                             Category 3
                                                                                                   Word          p(word|category)
                                                                                                   you           0.91
Simulations                                                                                        ourselves     0.09
                                                                                                   me            0.0
In order to test the effectiveness of discourse information                                        us            0.0
                                                                                                   him           0.0
for the categorization of pronouns, our simulations compare                                        them          0.0
three models: a Baseline model, a Discourse model, and a                                           myself        0.0
                                                                                                   yourself      0.0
Strong syntax model. The Baseline model has information                                            himself       0.0
                                                                                                   themselves    0.0
about locality and c-command, but it lacks information about
which entities are likely to be referred to in the discourse. It
assumes that potential antecedents are sampled uniformly, so                                  Table 3: Baseline model results
that p(xi |D ) is defined by counting the number of discourse
                                                                            puted pairwise F-scores using the final samples from each
entities that appear in each syntactic position. The Discourse
                                                                            chain. The Baseline model consistently failed to learn the
model is identical to the Baseline model, but it contains the
                                                                            correct categories, achieving a mean pairwise F-score of 0.55
adult-like discourse knowledge estimated in Experiment 1,
                                                                            across the 10 sampling chains. In all 10 chains, the model
as described above. Comparing the performance of the Dis-
                                                                            learned 3-4 categories, where the correct number of cate-
course model to the Baseline model allows us to quantify the
                                                                            gories is two. Table 3 shows the distribution over pronouns
degree to which discourse information helps an ideal learner
                                                                            belonging to each category obtained at the 2000th iteration of
acquire pronoun categories.
                                                                            the sampling run with the highest likelihood. The maximum
   The Strong syntax model is similar to the Baseline model
                                                                            likelihood estimate p(word|category) gives the proportion of
in that it assumes that potential antecedents are sampled uni-
                                                                            times each pronoun occurs in a category, based on a single
formly, but it additionally incorporates built-in knowledge
                                                                            sample from the posterior distribution over z and x.
of the grammatical constraints on reflexive and non-reflexive
                                                                               The Discourse model performed much better than the
pronouns in English. This model knows there are two gram-
                                                                            Baseline model, achieving a mean pairwise F-score of 0.97
matical categories of pronouns. Furthermore, it knows that
                                                                            across the 10 sampling runs. In seven of the 10 runs,
pronouns that have local c-commanding antecedents are re-
                                                                            the model perfectly categorized English pronouns into two
flexive pronouns and that pronouns that do not have local
                                                                            classes. In two additional runs, the model learned two cate-
c-commanding antecedents are non-reflexive pronouns (i.e.,
                                                                            gories, but the membership was not consistent. In the final
the antecedent-category parameter θ is observed). Thus, the
                                                                            run, the model learned three categories. Table 4 shows the
model only needs to learn the distribution of each category
                                                                            pronouns belonging to each category, obtained at the 2000th
over pronouns. Comparing this Strong syntax model to the
                                                                            iteration of the Gibbs sampling run which had the highest
Baseline model allows us to examine whether this type of
                                                                            likelihood. The pronouns associated with each category are
strong prior syntactic knowledge is sufficient to help learn-
                                                                            reflexive pronouns and non-reflexive pronouns, respectively.
ers categorize pronouns.
                                                                            This model also learned that there are exactly two categories,
   Each model was trained on 50 dialogues from Experi-
                                                                            as expected. These results indicate that discourse information
ment 1, 25 with reflexive and 25 with non-reflexive pronouns.
                                                                            can help an ideal learner categorize pronouns.
For each dialogue, the model was provided with the pronoun,
                                                                               Although the Baseline model has prior knowledge of c-
a prior distribution over possible antecedents for that pro-
noun, and the syntactic positions of those antecedents rela-                command and locality, it is still possible that the low perfor-
tive to the pronoun. Through the unsupervised learning pro-                 mance in this model might result from insufficient syntactic
                                                                            knowledge. For this reason, we compare the Strong syntax
cedure described above, the models recovered a distribution
over categories associated with each syntactic position and a               model with the Baseline model to see whether even stronger
distribution over pronouns for each category.                               prior syntactic knowledge is sufficient for categorizing pro-
                                                                            nouns. The mean F-score was 0.56 for this model. Table 5
Results For each model, we ran 10 independent Gibbs                         shows the pronouns in each category, obtained at the 2000th
chains for 2000 iterations each. Hyperparameters α, β, and                  iteration of a Gibbs sampling run which had the highest like-
γ were fixed at 1.0, 0.01, and 0.001, respectively4. We com-                lihood. The lack of improvement of the Strong syntax model
    4 We chose the best parameter values based on multiple runs, but        over the Baseline model suggests that simply having strong
results were qualitatively consistent across a range of parameter val-      prior syntactic knowledge is not sufficient for acquiring gram-
ues. The same parameter values were used for all three models.              matical categories of pronouns.
                                                                        3197

       Category 1                    Category 2                               Category 1                    Category 2
       Word         p(word|category) Word       p(word|category)              Word         p(word|category) Word       p(word|category)
       yourself     0.4              you        0.4                           yourself     0.29             you        0.63
       himself      0.28             him        0.28                          him          0.21             me         0.25
       myself       0.16             me         0.16                          himself      0.21             us         0.06
       themselves   0.12             them       0.12                          myself       0.12             ourselves  0.06
       ourselves    0.04             us         0.04                          them         0.09             him        0.0
       you          0.0              yourself   0.0                           themselves   0.09             them       0.0
       him          0.0              himself    0.0                           me           0.0              myself     0.0
       me           0.0              myself     0.0                           us           0.0              yourself   0.0
       them         0.0              themselves 0.0                           you          0.0              himself    0.0
       us           0.0              ourselves  0.0                           ourselves    0.0              themselves 0.0
                  Table 4: Discourse model results                                     Table 5: Strong syntax model results
   These simulation results suggest that knowing which enti-          command are neither necessary nor sufficient for defining the
ties are likely to be referred to in the discourse can help learn-    distributions of grammatical categories of pronouns. Future
ers acquire grammatical categories of pronouns. On the other          modeling work will explore the potential role of discourse
hand, simply having strong prior knowledge about the gram-            as an evidentiary source not only in discovering categories
matical distribution of pronouns is not sufficient to support         of pronouns, but also in determining which grammatical fea-
the acquisition of pronoun categories.                                tures are relevant for anaphoric dependencies.
                                                                      Acknowledgments. We thank Viet-An Nguyen, Ke Zhai, Motoki
                             Discussion                               Shiga, and members of the UMD Computational Psycholinguistics
This study examined the potential utility of discourse infor-         group for helpful comments and discussion. This research was sup-
mation as a cue to the acquisition of pronoun categories. We          ported by NSF IGERT 0801465 and NSF grant 1018625 (JBG).
showed that discourse information can help adults accurately
guess the identities of missing pronouns, and that a Bayesian                                      References
model with prior knowledge of discourse information can ac-           Arnold, J., Brown-Schmidt, S., & Trueswell, J. (2007). Children’s
                                                                         use of gender and order of mention in pronoun processing. Lan-
curately recover grammatical categories of pronouns without              guage and Cognitive Processes, 22, 527–565.
knowing in advance how many categories are present in a               Chomsky, N. (1973). Conditions on Transformations. In S. R. An-
language. This supports a role for discourse information in              derson & P. Kiparsky (Eds.), A festschrift for Morris Halle. New
                                                                         York: Holt, Rinehart & Winston.
helping learners acquire grammatical knowledge of pronoun             Crain, S., & McKee, C. (1985). The acquisition of structural re-
categories and shows one way in which they can overcome                  strictions on anaphora. In S. Berman, J. Choe, & J. McDonough
the circularity problem inherent to language acquisition at the          (Eds.), Proceedings of NELS (Vol. 15). Amherst, Mass: GLSA.
                                                                      Gillette, J., Gleitman, H., Gleitman, L., & Lederer, A. (1999). Hu-
syntax-semantics interface.                                              man simulations of vocabulary learning. Cognition, 73, 135–176.
   While it is possible that hearing a few unambiguous sen-           Jakubowicz, C. (1984). On markedness and the binding principles.
tences could also be sufficient for acquiring pronoun cate-              In Proceedings of NELS (Vol. 14, pp. 154–182).
                                                                      Kako, E. (2005). Information sources for noun learning. Cognitive
gories, our analysis shows that this type of unambiguous data            Science, 29, 223–260.
may not be required. Instead, an ideal learner can achieve the        Lidz, J., & Musolino, J. (2002). Children’s command of quantifica-
same outcome by relying on the discourse information that is             tion. Cognition, 84, 113–154.
                                                                      MacWhinney, B. (2000). The CHILDES Project: Tools for ana-
actually present in child-directed speech. The data used in our          lyzing talk. Third Edition. (Tech. Rep.). Mahwah, NJ: Lawrence
analysis were taken from CHILDES, and therefore provide                  Erlbaum Associates.
a good characterization of input a child receives. However,           Marr, D. (1982). Vision. San Francisco, CA: W. H. Freeman.
                                                                      Piccin, T. B., & Waxman, S. R. (2007). Why nouns trump verbs in
one limitation of our work is that distributions of verbs and            word learning: New evidence from children and adults in the Hu-
pronouns were balanced in our experimental stimuli, whereas              man Simulation Paradigm. Language Learning & Development,
they may not be balanced in the input. To ensure that the                3(4), 295–323.
                                                                      Pitman, J. (2002). Poisson-Dirichlet and GEM invariant distribu-
true distributions of verbs and pronouns support learning, it            tions for split-and-merge transformations of an interval partition.
will be important to replicate our modeling results on more              Combinatorics, Probability and Computing, 11, 501–514.
extensive corpora.                                                    Reinhart, T. (1976). The Syntactic Domain of Anaphora. Unpub-
                                                                         lished doctoral dissertation, MIT.
   Our model assumed that learners have prior knowledge of            Rosen-Zvi, M., Griffiths, T., Steyvers, M., & Smyth, P. (2004). The
the relevance of syntactic locality and c-command relations to           author-topic model for authors and documents. In 20th Confer-
the acquisition of pronouns, but we do not know the degree to            ence on Uncertainty in Artificial Intelligence.
                                                                      Sutton, M., Fetters, M., & Lidz, J. (2012). Parsing for Principle
which this parallels children’s acquisition. Children appear             C at 30 months. In Proceedings of the 36th Boston University
to have acquired relevant locality constraints on pronouns               Conference on Language Development (pp. 581–593).
by age five at the latest (Zukowski, McKeown, & Larsen,               Teh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M. (2006). Hier-
                                                                         archical Dirichlet processes. Journal of the American Statistical
2008), though we do not know when knowledge of the do-                   Association, 101.
mains themselves becomes available to learners. Knowledge             Zukowski, A., McKeown, R., & Larsen, J. (2008). A tough test
of c-command also appears to be available to children at this            of the locality requirement for reflexives. In Proceedings of the
                                                                         32nd Boston University Conference on Language Development
age or even earlier (Lidz & Musolino, 2002; Sutton, Fetters,             (pp. 586–597).
& Lidz, 2012). However, cross-linguistically, locality and c-
                                                                  3198

