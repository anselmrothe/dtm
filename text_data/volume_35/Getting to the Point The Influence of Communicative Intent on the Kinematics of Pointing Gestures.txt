UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Getting to the Point: The Influence of Communicative Intent on the Kinematics of Pointing
Gestures
Permalink
https://escholarship.org/uc/item/51j2106d
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Peeters, David
Chu, Mingyuan
Holler, Judith
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

  Getting to the Point: The Influence of Communicative Intent on the Kinematics of
                                                        Pointing Gestures
                                             David Peeters (david.peeters@mpi.nl)
                              Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
                 International Max Planck Research School for Language Sciences, Nijmegen, The Netherlands
            Radboud University, Donders Institute for Brain, Cognition, and Behaviour, Nijmegen, The Netherlands
                                            Mingyuan Chu (mingyuan.chu@mpi.nl)
                              Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
                                              Judith Holler (judith.holler@mpi.nl)
                              Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
                                  School of Psychological Sciences, University of Manchester, UK
                                              Aslı Özyürek (asli.ozyurek@mpi.nl)
                          Radboud University, Center for Language Studies, Nijmegen, The Netherlands
                              Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
                                             Peter Hagoort (peter.hagoort@mpi.nl)
                              Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands
            Radboud University, Donders Institute for Brain, Cognition, and Behaviour, Nijmegen, The Netherlands
                             Abstract                                 one’s hand when talking about a basketball game. Typically,
                                                                      such studies have varied aspects of the communicative
  In everyday communication, people not only use speech but
  also hand gestures to convey information. One intriguing            context, such as the visibility of gestures or the knowledge
  question in gesture research has been why gestures take the         speaker and listener mutually share. Amongst other things,
  specific form they do. Previous research has identified the         these studies have shown that speakers design their gestures
  speaker-gesturer’s communicative intent as one factor               for particular recipients and produce more (e.g., Alibali,
  shaping the form of iconic gestures. Here we investigate            Heath, & Myers, 2001; Bavelas et al., 2008) as well as
  whether communicative intent also shapes the form of                larger and more precise gestures when communicative
  pointing gestures. In an experimental setting, twenty-four          intentions are enhanced (e.g., Gerwing & Bavelas, 2004;
  participants produced pointing gestures identifying a referent      Holler & Stevens, 2007). Thus, iconic co-speech gestures
  for an addressee. The communicative intent of the speaker-
                                                                      seem closely linked to the speaker’s specific communicative
  gesturer was manipulated by varying the informativeness of
  the pointing gesture. A second independent variable was the         intent, and the particular form an iconic gesture takes
  presence or absence of concurrent speech. As a function of          depends on the context-bound communicative relation
  their communicative intent and irrespective of the presence of      between speaker and addressee (see Holler & Wilkin, 2011).
  speech, participants varied the durations of the stroke and the        In contrast, it is unclear how the form of pointing gestures
  post-stroke hold-phase of their gesture. These findings add to      changes as a function of the gesturer’s communicative
  our understanding of how the communicative context                  intent. Pointing is a foundational building block of human
  influences the form that a gesture takes.                           communication (Kita, 2003) and allows us to directly
   Keywords: Pointing Gesture; Communicative Intent; Gesture          connect our communication to the material world that
   Production; Action Planning; Deixis.                               surrounds us (Clark, 2003). Pointing has received much
                                                                      attention in the literature from an ontogenetic viewpoint
                        Introduction                                  because of its role in paving the way for the acquisition of
In everyday communication, people not only use speech but             language (Butterworth, 2003; Carpenter, Nagell, &
also meaningful hand gestures to convey information. One              Tomasello, 1998; Tomasello, Carpenter, & Liszkowski,
of the most intriguing questions in gesture research has been         2007), as well as from a phylogenetic viewpoint with
why such gestures take the physical form they do (Bavelas             respect to declarative pointing being a uniquely human form
et al., 2008; Gerwing & Bavelas, 2004; Krauss, Chen, &                of communication in a natural environment (Call &
Gottesman, 2000). The main focus so far in answering this             Tomasello, 1994; Kita, 2003; Tomasello et al., 2007). In
question has been on gestures iconic in nature, i.e., gestures        contrast, the exact form parameters that people vary in the
that in form and manner of execution visually resemble the            production of pointing gestures in human adult
simultaneously expressed meaning of the linguistic part of            communication remain largely unknown. Therefore, the
an utterance (McNeill, 1985), such as moving up and down              present study aims at contributing further to our
                                                                  1127

understanding of why adults’ index-finger pointing gestures          presence of speech interacts with our manipulation of
take the particular physical form they do in a                       communicative intent.
communicative context.                                                  The current study looks at different subcomponents (or:
   There are some preliminary indications that suggest a             parameters) of the pointing gesture. We focus on the
relation between the form of a pointing gesture and the              planning duration of the gesture, the duration of the stroke
speaker’s communicative intent. Cleret de Langavant et al.           and the post-stroke hold-phase, as well as the point in time
(2011) had participants repeatedly point to objects on a table       at which the apex is reached after the visual presentation of
in front of them. Two addressees were always sitting next to         a referent (Levelt, Richardson, & La Heij, 1985), and the
the table. At the onset of a communicative block, the                amount of distance travelled by the pointing finger. Finally
participant was instructed to verbally address one of the            we also look at whether the synchronization of speech and
addressees before the block started and was instructed               gesture changes as a function of communicative intent.
before each trial of that block to point at a specific object for
that addressee, who named the object after observing the                                         Method
participant’s gesture. At the onset of a non-communicative
block, the participant addressed nobody and was instructed           Participants
before each trial to point at a specific object without having
                                                                     Twenty-four right-handed native speakers of Dutch (12
an addressee (and hence did not receive feedback from an
                                                                     female; mean age 20.6), studying at Radboud University
addressee). Compared to the latter, non-communicative
                                                                     Nijmegen, participated in the experiment. They were
condition, the former condition yielded pointing gestures
                                                                     compensated with 20€.
that had a trajectory and endpoint distribution that were
tilted away from the addressee, arguably because the
addressee's perspective on the target object was taken into
                                                                     Experimental Design and Set-up
account in the form of the gesture.                                  Participants were seated at a distance of 100 cm from a
   Everyday pointing gestures generally occur in a context in        computer screen that was placed back-to-back with another
which two interlocutors share a joint attentional frame in           computer screen (henceforth: the back screen). Stimuli were
which one person directs the attention of another person             four white circles in a horizontal line on the top of the
towards a location, event, or referent in the perceptual             screen, mirroring four circles on the back screen. The circles
environment (Tomasello et al., 2007). An important                   could light up either blue or yellow. A second participant (a
prerequisite for a successful referential pointing gesture is        confederate; henceforth: the addressee) looked at the back
that two interlocutors come to perceptually attend to the            screen and the participant’s pointing gesture via a camera.
same entity or location and are mutually aware of the fact           Figure 1 shows the view of the addressee via the camera
that they are both attending to the same thing (Clark, 1996).        (converted to a grayscale image). On all trials, participants
Therefore, instead of comparing a “communicative”                    referred to the circle that lit up. The addressee noted on a
situation (including addressing a listener and receiving             paper form to which of the four circles the participant
verbal feedback) to a “non-communicative” situation
(without addressing a listener and verbal feedback), as in
Cleret de Langavant et al. (2011), we here compare two
situations that are both communicative and differ only in the
communicative intent of the speaker-gesturer. As a proxy of
the communicative intent of the speaker-gesturer, we
manipulate the degree of informativeness of the pointing
gesture as a first factor in our design.
   A second factor manipulated here is the presence of
speech as a second modality. Pointing gestures often come
with concurrent deictic speech such as spatial
demonstratives (e.g., “this” and “that” in English). In the
production of referring expressions, speech and gesture are
tightly interconnected (Kendon, 2004; McNeill, 1992) and
can be used independently or simultaneously to single out a
referent (e.g., Bangerter, 2004), in contrast with iconic
gestures that canonically come with speech. In the current
study we manipulate the presence of such a second modality
(speech) and explore the yet unaddressed question of
whether the mere presence of speech as a second modality
influences the form parameters people exploit in producing           Figure 1: The addressee's view of the back screen and the
pointing gestures for their addressee, and whether the               pointing participant during a non-informative trial.
                                                                 1128

referred on each trial. In order to make the deictic act               equally distributed over the four circles and the four
informative in one case but non-informative in the other, the          conditions throughout the experiment, in a randomized way.
following set-up was used. In both conditions, via a camera,
the addressee observed the pointing gesture of the                     Procedure
participant, as well as the circles at the back screen                 At the arrival of the participant, the experimenter explained
providing the corresponding view of the four circles the               that a second participant (i.e., the confederate addressee)
participant was seeing. This way, the addressee saw which              would perform a behavioral task on the basis of the
of the four circles the participant pointed at, but without            participant’s gesture. The experimenter showed the
seeing which circle lit up on the participant’s side of the            participant the computer and form to be used by the
screen, a crucial aspect in our manipulation (see below).              addressee and demonstrated that the participant could be
   We manipulated the informativeness of the gesture                   seen on the computer screen via a camera. Also, it was
(informative versus non-informative) as well as the                    explained and shown to the participant that the addressee
modality of the deictic act (gesture-only versus gesture +             could only see the arm movement of the participant and the
speech) in a 2x2 within participants design. In the                    computer screen that was at the back of the computer screen
informative condition, a circle turned blue or yellow only on          that the participant saw. The addressee could not see the
the participants’ screen but not on the back screen.                   head of the participant, to avoid the participant from
Therefore the participant’s pointing gesture was the only              conveying information via the head and face. In order to
source of information on which the addressee had to base               keep participants motivated, it was emphasized that they
his decision in selecting the circle referred to by the                were in a joint activity with the addressee and that the
participant. In the non-informative condition, the                     success of this joint activity depended on how well they
corresponding circles would light up on both the                       worked together. The participant was then seated in a
participant’s and the addressee’s screen. Thus, the                    comfortable chair in the dimly-lit experiment room. The
participant’s pointing gesture was non-informative, because            height of the screen was adjusted to the height of the eyes of
the addressee saw one of the circles light up on the back              the participant. The button used by the participant was
screen at the same moment as the participant saw the                   placed at the height of the participant’s elbow, 23 cm in
corresponding circle light up (i.e., even before the onset of          front of the participant calculated from the vertical axis
the participant’s pointing gesture).                                   corresponding to the position of the participant’s eyes.
   The modality factor was manipulated by having                       Participants were instructed to always rest their finger on
participants use either one or two modalities in referring to          this button, except when making the pointing gesture, which
the circles. In gesture only blocks (G-only), participants             allowed calculating the duration and onset of the pointing
pointed to a circle when it turned blue or yellow without              gesture. A sensor was placed on the participant’s right index
producing speech. In gesture + speech blocks (G+S)                     finger nail to allow for motion tracking of the pointing
participants pointed to the circle and said either die blauwe          movements. Participants’ electroencephalogram (EEG) was
cirkel (“that blue circle”) or die gele cirkel (“that yellow           recorded continuously throughout the experiment. These
circle”), depending on the color of the circle. Note that,             results will be reported elsewhere.
because on every trial only one circle turned blue or yellow,             After montage of the motion tracking sensor the
the speech was never informative (neither in the informative           experimenter picked up the addressee. The addressee was
nor the non-informative blocks). The rationale for this was            shown the room in which the participant performed the task,
that we were interested in the possible effect of the mere             greeted the participant, and was seated in a chair in front of
presence of speech as a second modality, independently                 a computer in a room adjacent to the participant’s room. In
from the informativeness of the deictic act that was                   order to familiarize the participant with the different
manipulated separately in the gesture.                                 conditions and the task, thirty-two test-items (eight per
   Each trial started with a fixation cross, displayed for 500         condition) preceded the main experiment as a practice set.
ms, followed by the presentation of four white circles. After          Participants received specific instructions to point with or
a jittered period of 500-1000 ms, one of the circles turned            without speech before each block. In addition, before each
yellow or blue. At this point, the participant was allowed to          block, the participant was instructed whether the addressee
release her finger from a button, pointed to the blue or               could also see the same circles light up at the back screen or
yellow circle, and named the circle (in the G+S blocks). The           not during that block. Participants were asked to only move
experiment consisted of 16 blocks of 20 trials each. Every             their hand and arm when pointing. During the experiment,
condition in the experiment was represented by four blocks.            participants were allowed to have a short break after every
The order of presentation of blocks was counterbalanced                fourth block. Before and during the experiment, the
across participants. In half of the trials a circle lit up yellow,     communication between experimenter and addressee was
in the other half it lit up blue. The idea behind this was to          minimal and fully scripted, in order to be constant across
create a slightly more complex and varied utterances to                participants. After the experiment, the addressee was
enhance the ecological validity in this very strictly                  thanked for participation and left the room. Participants
controlled environment. Each block of 20 trials consisted of           were debriefed, financially compensated, and thanked for
ten circles lighting up yellow and ten lighting up blue,               participation.
                                                                   1129

Kinematic recording and analysis                                   dependent variable with Informativeness (Informative
Behavioral and kinematic data were acquired throughout the         versus Non-informative) and Modality (Gesture-only or
experiment using experimental software (Presentation,              Gesture+Speech) as within-subject factors.
Neurobehavioral Systems, Inc) and a 60 Hz motion tracking            A first analysis was performed on the Gesture Initiation
system and DTrack2 tracking software (both Advanced                Time. This analysis did not yield any significant main or
Realtime Tracking, Weilheim, Germany). For each trial, the         interaction effect. Next, we analyzed the Stroke Duration.
Gesture Initiation Time (i.e. the moment the participant’s         This analysis yielded a significant main effect of
finger left the button calculated from the moment a circle lit     Informativeness, F (1,23) = 10.97, p = .003, ηp2 = .32. This
up) was calculated. This measure thus reflected the time it        effect denoted that the duration of the stroke was
took to plan the pointing gesture. In addition, we collected       significantly longer in the Informative condition (M = 837
for each trial the Apex Time (i.e. the moment of the               ms) than in the Non-informative condition (M = 823 ms).
endpoint of the gesture calculated from the moment a circle        No significant main effect of Modality was found. There
lit up). The endpoint of the gesture was defined as the point      was no significant interaction between the two factors. Also
in time where the pointing index finger was at least 7 cm          an analysis on the Apex Time showed a significant main
from the button and only moved forward less than 2 mm for          effect of Informativeness, F (1,23) = 8.15, p = .009, ηp2 =
two consecutive samples. The Stroke Duration was defined           .26. This effect denoted that the apex was reached
as the interval between the onset of the gesture (i.e., The        significantly later in the Informative condition (M = 1379
Gesture Initiation Time) and the moment the apex was               ms) than in the Non-informative condition (M = 1359 ms).
reached (i.e., the Apex Time). The Incremental Distance            No significant main effect of Modality was found. There
travelled by the pointing index finger was calculated for the      was no significant interaction between the two factors.
complete stroke (similar to Levelt et al., 1985). Further, the       A further analysis was performed on the Incremental
Velocity of the hand movement was calculated for each trial        Distance. No significant main or interaction effect was
on the basis of the Apex Time and the Incremental Distance.        found. Because the same amount of distance was travelled
The Hold Duration of the pointing gesture was calculated by        across conditions, but the apex was reached later in the
subtracting the Apex Time from the Retraction Time (i.e.,          Informative condition than in the Non-informative
the moment the index finger moved back in the direction of         condition, the velocity of the pointing gesture must have
the button for at least 2 mm in two consecutive samples). In       been lower in the Informative condition compared to the
the G+S blocks, the Speech Onset Time was calculated from          Non-informative condition. Indeed, an analysis on the mean
the moment one of the circles lit up. The Synchronization          Velocity yielded a significant main effect of
Time was defined as the difference between Apex Time and           Informativeness, F (1,23) = 5.75, p = .025, ηp2 = .20. The
Speech Onset Time.                                                 velocity of the pointing gesture was significantly lower in
                                                                   the Informative condition (M = 38.2 cm/s) than in the Non-
                           Results                                 informative condition (M = 38.7 cm/s). Again, no
                                                                   significant main effect of Modality or interaction between
Trials on which the Gesture Initiation Time was below 100          the two factors was found. Another analysis, performed on
ms or above 2000 ms were considered errors and excluded            the Hold Duration, yielded a significant main effect of
from all analyses (0.7% of total dataset). In addition, trials
                                                                   Informativeness, F (1,23) = 10.17, p = .004, ηp2 = .31. The
containing hesitations or errors in the participant’s speech
                                                                   Hold Duration was significantly longer in the Informative
were removed from further analyses (0.2% of all data).
                                                                   condition (M = 1235 ms) compared to the Non-informative
Separate analyses of variance were performed for each
                                                                   condition (M = 1143 ms). No significant main effect of
Table 1: Overview of the results per condition in the experiment. Duration in ms is displayed for the Gesture Initiation Time
(GIT), Stroke Duration (Stroke), Apex Time (Apex), Hold Duration (Hold), Speech Onset Time (SOT), and Synchronization
Time (Sync). Further, the Incremental Distance in cm (Dist) and Velocity in cm/s (Velocity) are provided. The standard error
of the mean is indicated between parentheses.
   Condition                GIT        Stroke     Apex        Dist    Velocity     Hold          SOT        Sync
   Informative
   Gesture-only             534 (21)   834 (30)   1368 (42) 51 (1) 38.5 (1)        1252 (135)
   Gesture + Speech         550 (22)   840 (27)   1389 (39) 51 (1) 37.8 (1)        1219 (121)    1385 (65)   4 (54)
   Non-informative
   Gesture-only             532 (22)   819 (29)   1351 (41) 51 (1) 39.0 (1)        1138 (116)
   Gesture + Speech         541 (24)   826 (27)   1367 (40) 51 (1) 38.5 (1)        1149 (106)    1351 (66)   16 (54)
                                                               1130

Modality was found. There was no significant interaction           reached its apex, regardless of whether the gesture was
between the two factors.                                           informative or not. This finding is in line with previous
   In the G+S conditions, participants referred linguistically     studies showing such temporal alignment of pointing and
to the circle on the screen while pointing. An analysis on the     speech (e.g., Levelt et al., 1985; McNeill, 1992) and with
Speech Onset Time with Informativeness as the only within-         models of speech and gesture production that underline the
subject factor revealed a significant main effect, F (1,23) =      synchronization of speech and gesture (e.g., De Ruiter,
6.79, p = .016, ηp2 = .23. This effect reflected that the          2000; Krauss et al., 2000). Here we show that this temporal
speech onset on average took place significantly later in the      synchrony between deictic speech and gesture is maintained
Informative condition (M = 1385 ms) than in the Non-               irrespective of the speaker-gesturer’s communicative intent.
informative condition (M = 1351 ms). An analysis on the               We found a similar effect of communicative intent in
Synchronization Time did not show a significant main effect        situations where people only used gesture to communicate,
of Informativeness (p = .16), indicating that the onset of the     compared to situations where speech and gesture were
speech and the apex of the gesture were aligned similarly          concurrently produced (Clark, 1996; Kendon, 2004).
and independently from the informativeness of the gesture.         However, in our study, speech was purposefully never
Table 1 summarizes all results.                                    informative and very similar across trials, and there is
                                                                   indeed evidence that deictic speech can interact with the
                         Discussion                                form of a simultaneously produced gesture (e.g., Gonseth,
                                                                   Vilain, & Vilain, 2012). It is therefore possible that
Research investigating the production of iconic gestures has
                                                                   whenever speech itself is informative enough to single out a
found that the form of such gestures changes on the basis of
                                                                   referent, speaker-gesturers no longer design their concurrent
the communicative intent of the speaker-gesturer.
                                                                   gesture to be maximally informative. Future research needs
Importantly, here we show that also in the case of pointing
                                                                   to shed more light on the influence of speech-gesture
gestures speaker-gesturers exploit different form parameters
                                                                   interaction on the form of deictic gesture and speech while
as a function of their communicative intent. First, the
                                                                   manipulating the informativeness of the speech.
duration of the stroke of pointing gestures was longer in the
                                                                      In general, the results of our study fit well with models of
informative condition, which led to a gesture with a lower
                                                                   speech and gesture production that allow for a role of the
velocity and delayed the moment at which the apex was
                                                                   speaker-gesturer’s communicative intent in modulating the
reached. Presumably participants did this in order to be as
                                                                   exact form of a gesture, such as the Sketch model (De
precise as possible in pointing to a target, which could be
                                                                   Ruiter, 2000) and the Interface model (Kita & Özyürek,
achieved by pointing more slowly. An additional benefit
                                                                   2003). Conversely, our data would argue against models of
would then be that the addressee would have more time to
                                                                   speech and gesture production that question whether the
identify towards which referent the gesture was heading.
                                                                   speaker’s communicative intent plays a role in determining
Second, the post-stroke hold-phase of the gesture was
                                                                   the form of a gesture (e.g., Krauss et al., 2000). In our study,
maintained longer, presumably in order to assure that the
                                                                   participants had the communicative intention of producing a
addressee had enough time to identify which referent the
                                                                   pointing gesture towards a referent, either accompanied with
speaker pointed to. The form parameters under investigation
                                                                   referential speech or not. The Sketch model, which
here were not affected by the presence of deictic speech.
                                                                   explicitly describes the production of pointing (in addition
Nevertheless, the onset of speech was synchronized with the
                                                                   to other types of gesture), underlines that upon the intention
moment at which the pointing gesture reached its apex.
                                                                   to produce a pointing gesture, conventions such as which
   A previous study compared a communicative to a non-
                                                                   hand shape and finger to use can be retrieved from a
communicative situation and found that people may modify
                                                                   knowledge store (called a “gestuary” by De Ruiter, 2000) in
the trajectory and endpoint location of their pointing gesture
                                                                   memory. This representation of the pointing gesture in the
to single out a referent for their addressee (Cleret de
                                                                   gestuary is only a template or abstract motor program, and
Langavant et al., 2011). The current study takes this
                                                                   there are a number of degrees of freedom that can be varied
research a step further by comparing two situations that are
                                                                   depending on the context in which the pointing gesture is
both communicative and identical except for the
                                                                   performed. According to this model, in our study,
communicative intent of the gesturer. Cleret de Langavant
                                                                   participants retrieved a pointing gesture template from
et al. (2011) did not find a difference in the duration of the
                                                                   memory and subsequently exploited the duration of both the
pointing gesture when comparing their communicative to
                                                                   stroke (and as such the velocity and the moment the apex
their non-communicative condition. Here we did find an
                                                                   was reached) and the post-stroke hold-phase of the gesture
effect of communicative intent on the duration of the stroke
                                                                   as free parameters. Our study thus suggests that duration is a
and the post-stroke hold-phase. Thus, in addition to varying
                                                                   free parameter that people use to vary the execution of their
the endpoint location and trajectory of a pointing gesture (as
                                                                   pointing gesture, and further specifies in which specific
in Cleret de Langavant et al., 2011), people may also use the
                                                                   components of the gesture duration is indeed varied.
duration of different sub-components of the pointing gesture
                                                                      The form a pointing gesture takes not only depends on the
in order to communicate effectively.
                                                                   gesturer's communicative intent. Research has shown that it
   Participants temporally aligned the onset of the deictic
                                                                   also depends on physical factors such as the spatial location
linguistic expression with the moment the pointing gesture
                                                               1131

of a referent. For instance, people may raise their pointing           competence from 9 to 15 months of age. Monographs of
arm and hand higher when a referent is more distant                    the Society for Research in Child Development, 255, Vol.
(Wilkins, 2003). Furthermore, the form of a gesture depends            63, 1-174.
on cultural factors. In different cultures, different body parts     Clark, H. H. (1996). Using Language. Cambridge:
are used for pointing (Kita, 2003; Wilkins, 2003). Finally, it         Cambridge University Press.
may depend on socio-pragmatic factors. In a corpus study             Cleret de Langavant, L., Remy, P., Trinkler, I., McIntyre, J.,
on Lao speakers, Enfield, Kita, and De Ruiter (2007)                   Dupoux, E., Berthoz, A., & Bachoud-Lévi, A.-C. (2011).
observed a distinction between relatively big points in                Behavioral and neural correlates of communication via
which the whole arm is outstretched and relatively small               pointing. PLoS ONE, 6:3, e17719.
points in which the hand is the main articulator. They argue         De Ruiter, J. P. (2000). The production of gesture and
that this difference in form is related to the pragmatic               speech. In D. McNeill (Ed.), Language and gesture.
function of the utterance a gesture occurs in. Big points              Cambridge: Cambridge University Press.
would do the primary work of an utterance, such as pointing          Enfield, N. J., Kita, S., & De Ruiter, J. P. (2007). Primary
out the location of an object, whereas small points would              and secondary pragmatic functions of pointing gestures.
occur in utterances in which speech is central, adding a               Journal of Pragmatics, 39, 1722-1741.
background modifier on the basis of social factors such as           Gerwing, J. & Bavelas, J. (2004). Linguistic influences on
the common ground between interlocutors (p. 1738). Future              gesture’s form. Gesture, 4, 157-195.
studies could investigate interactions between such different        Gonseth, C., Vilain, A., & Vilain, C. (in press). An
physical, cultural, socio-pragmatic, and communicative                 experimental study of speech/gesture interactions and
factors.                                                               distance encoding. Speech communication.
  To conclude, our study showed that people exploit the              Holler, J., & Stevens, R. (2007). An experimental
duration of the stroke (and as such its velocity and the               investigation into the effect of common ground on how
moment the apex is reached) and the post-stroke hold-phase             speakers use gesture and speech to represent size
of their pointing gesture to communicate effectively. Thus,            information in referential communication. Journal of
the form of a pointing gesture varies as a function of the             Language and Social Psychology, 26, 4-27.
speaker-gesturer’s communicative intent. Similarly to iconic         Holler, J., & Wilkin, K. (2011). An experimental
gestures, the form of pointing gestures is dependent, among            investigation of how addressee feedback affects co-
other factors, on the context-bound communicative relation             speech gestures accompanying speakers’ responses.
between speaker-gesturer and addressee.                                Journal of Pragmatics, 43, 3522-3536.
                                                                     Kendon, A. (2004). Gesture: Visible action as utterance.
                    Acknowledgments                                    Cambridge: Cambridge University Press.
We thank Albert Russel for technical assistance. JH was              Kita, S. (2003). Pointing. Where language, culture, and
supported through Marie Curie Fellowship #255569 as well               cognition meet. Mahwah, NJ: Lawrence Erlbaum.
as through ERC Advanced Grant #269484 INTERACT.                      Kita, S., & Özyürek, A. (2003). What does cross-linguistic
                                                                       variation in semantic coordination of speech and gesture
                                                                       reveal?: Evidence for an interface representation of
                         References                                    spatial thinking and speaking. Journal of Memory and
Alibali, M. W., Heath, D. C., & Myers, H. J. (2001). Effects           Language, 48, 16-32.
   of visibility between speaker and listener on gesture             Krauss, R. M., Chen, Y., & Gottesman, R. F. (2000).
   production: Some gestures are meant to be seen. Journal             Lexical gestures and lexical access: A process model. In
   of Memory and Language, 44, 169-188.                                D. McNeill (Ed.), Language and gesture. Cambridge:
Bangerter, A. (2004). Using pointing and describing to                 Cambridge University Press.
   achieve joint focus of attention in dialogue.                     Levelt, W. J. M., Richardson, G., & La Heij, W. (1985).
   Psychological Science, 15, 415-419.                                 Pointing and voicing in deictic expressions. Journal of
Bavelas, J., Gerwing, J., Sutton, C., & Prevost, D. (2008).            Memory and Language, 24, 133-164.
   Gesturing on the telephone: Independent effects of                McNeill, D. (1985). So you think gestures are nonverbal?
   dialogue and visibility. Journal of Memory and                      Psychological Review, 92, 350-371.
   Language, 58, 495-520.                                            McNeill, D. (1992). Hand and Mind: What gestures reveal
Butterworth, G. (2003). Pointing is the royal road to                  about thought. Chicago: University of Chicago Press.
   language for babies. In S. Kita (Ed.), Pointing. Where            Tomasello, M., Carpenter, M., & Liszkowski, U. (2007). A
   language, culture, and cognition meet. Mahwah, NJ:                  new look at infant pointing. Child Development, 78, 705-
   Lawrence Erlbaum.                                                   722.
Call, J., & Tomasello, M. (1994). Production and                     Wilkins, D. (2003). Why pointing with the index finger is
   comprehension of referential pointing by orangutans                 not a universal (in sociocultural and semiotic terms). In S.
   (Pongo pygmaeus). Journal of Comparative Psychology,                Kita (Ed.), Pointing. Where language, culture, and
   108, 307-317.                                                       cognition meet. Mahwah, NJ: Lawrence Erlbaum.
Carpenter, M., Nagell, K., & Tomasello, M. (1998). Social
   cognition,    joint     attention,   and      communicative
                                                                 1132

