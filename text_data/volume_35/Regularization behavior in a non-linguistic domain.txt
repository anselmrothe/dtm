UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Regularization behavior in a non-linguistic domain
Permalink
https://escholarship.org/uc/item/8fx246sv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Ferdinand, Vanessa
Thompson, Bill
Kirby, Simon
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                             Regularization behavior in a non-linguistic domain
                Vanessa Ferdinand (v.a.ferdinand@sms.ed.ac.uk), Bill Thompson (bill@ling.ed.ac.uk),
                         Simon Kirby (simon@ling.ed.ac.uk), Kenny Smith (kenny@ling.ed.ac.uk)
                                            Language Evolution and Computation Research Unit
                           School of Philosophy, Psychology & Language Sciences, University of Edinburgh
                                  Dugald Stewart Building, 3 Charles Street, Edinburgh, EH8 9AD, UK
                               Abstract                                   variables. Participants with lower capacity overproduced the
   Language learners tend to regularize unpredictable variation           most common variant, whereas participants with higher ca-
   and some claim that is due to a language-specific regularization       pacity did not. Regularization is also modulated by the num-
   bias. We investigate the role of task difficulty on regularization     ber of variables in a task; adults regularized slightly more
   behavior in a non-linguistic frequency learning task and show
   that adults regularize variable input when tracking multiple fre-      when predicting which of three lights will flash next than
   quencies concurrently, but reliably reproduce the variation they       when predicting for two lights (Gardner, 1957).
   have observed when tracking one frequency. These results sug-             In this paper, we explore the effect of tracking single versus
   gest that regularization behavior may be due to domain-general
   factors, such as memory limitations.                                   multiple frequencies on the regularization behavior of adults
   Keywords: frequency learning; regularization; probability              in a non-linguistic task. We show that participants probabil-
   matching; Bayesian models;                                             ity match when tracking a single frequency, but regularize
                                                                          when tracking six frequencies concurrently. Because con-
                           Introduction                                   current frequency learning is a prominent aspect of language
Languages contain very little unpredictable variation (Cham-              learning (Saffran, Alin & Newport, 1996), and also elicits
bers et al., 2003) and language learners tend to regularize the           regularization in a non-linguistic task, this is consistent with
inconsistent input they encounter (Reali & Griffiths, 2009;               a domain-general account of the observed regularization bias
Hudson Kam & Newport, 2009, Smith & Wonnacott, 2010).                     in language, possibly attributable to limited working memory.
For example, English contains two forms of the indefinite ar-
ticle a and an, but a deterministic rule (based on the initial                        Frequency learning experiment
phoneme of the following noun) governs the use of these two               Participants 381 participants were recruited via Amazon’s
variants. Why are languages regular, and what drives learn-               Mechanical Turk crowdsourcing platform and completed our
ers to eliminate free variation in language? Some have sug-               experiment online. 37 participants were excluded on the ba-
gested that we come to the task of language learning with the             sis of the following criteria: failing a color vision test (2),
expectation that languages are regular and that this expecta-             self-reporting the use of a pen or pencil during the task (14),
tion takes the form of a language-specific innate bias (Bicker-           not reporting their sex or age (2), or having previously partic-
ton, 1984; DeGraaff, 1999; Lumsden, 1999; Becker & Veen-                  ipated in any of our experiments, as determined by their user
stra, 2003). Others claim that linguistic regularization can              ID with MTurk (19). More participants were recruited than
be explained by domain-general learning mechanisms, such                  necessary with the expectation that many would be excluded
as the effects of memory limitations on the type of variation             by these criteria. Once the predetermined number of partic-
that learners produce (Hudson Kam & Newport, 2005, 2009;                  ipants per condition was met, data from the last participants
Hudson Kam & Chang, 2009). Hudson Kam and Newport                         was excluded, totaling 24 participants across all conditions
(2005, 2009) have shown that children tend to regularize free             and tasks. All excluded participants received the full mone-
variation, whereas adults maintain it by probability matching,            tary reward for the task. The average monetary reward per
and attribute this difference to children having lower work-              participant, converted to an hourly rate, was $2.64. Of the
ing memory capacity than adults. Newport (1990) demon-                    final 320 participants, 184 are female, and the mean age is 36
strated that children have more of a limited ability to learn             (min = 18, max = 69), with a standard deviation of 12 years.
from inconsistent input and Hudson Kam and Chang (2009)
                                                                          Materials The experiment was coded up as a java applet
showed that adults probability matched more when word re-
                                                                          that ran in the participant’s web browser in a 600x800-pixel
trieval was made easier and regularized more when it was
                                                                          field. Photographs of 6 different containers (a box, pouch, jar,
difficult, further corroborating their claim that memory limi-
                                                                          bowl, bucket, and basket) and graphically generated images
tations can lead to regularization, although see Perfors (2012)
                                                                          of marbles in 12 different colors (blue, orange, brown, grey,
for an account of restricted memory encoding that does not
                                                                          black, yellow, red, teal, olive, pink, purple, and lime) served
lead to regularization.
                                                                          as stimuli.
   A similar effect of memory limitations can be found in a
non-linguistic tasks. In a study with adults, Kareev et al.               One-item task This experiment consisted of a training
(1997) reported an effect of individual differences in work-              phase in which participants observed a series of 10 marble
ing memory capacity (as determined by a digit-span test) on               draws from a bag, and a testing phase in which participants
participants’ perception of the correlation of two probabilistic          were asked to produce another several likely draws from the
                                                                      436

                             % participants
                                                 50
  One-item
    task                                         25
                                                    0
                             % participants
                                                 50
   Six-item
     task                                        25
                                                    0
                                                         0     2   4   6    8 10
                                                         output frequency
                                                                   0:10                          1:9                      2:8                 3:7               4:6               5:5
                                                                                                                          input frequency
Figure 1: Each pane displays the percentage of participants that responded with a given output frequency of the minority marble
(m) during testing. Columns are the input ratio of m:M during training. Dashed lines mark the input frequency of m. In the
one-item task, participants probability matched, reproducing the input ratio with high fidelity. This task was between-subjects;
each participant was trained on one input ratio only. In the six-item task, participants were more likely to regularize than to
reproduce the input ratio. This task was within-subjects; each participant was trained on all six input ratios concurrently.
  training                                                          testing                                                   tios of m:M were tested and will be referred to as the 0:10,
                                                             ...                                                ...           1:9, 2:8, 3:7, 4:6, and 5:5 conditions. 192 participants took
                                                                                                                              part in this task, with 32 in each condition.
                                                           60                                                    60           Six-item task This task is based on the word frequency
                                              trial 2    trials                                      trial 2   trials
                         trial 2              stimulus                                     trial 2   choice                   learning task from Reali and Griffiths (2009). Participants
                                               2 sec                                                 shown
              trial 1     blank
                          1 sec
                                                                                 trial 1   choose
                                                                                                      2 sec                   observed 10 marble draws each from six different containers,
    trial 1   stimulus                                                 trial 1   choice
               2 sec                                                             shown
     blank
     1 sec
                                                                       choose
                                                                                  2 sec                                       totaling 60 marble draws (see Figure 2). Each container was
                                                                                                                              associated with 2 unique marble colors (12 unique marble
                                                                                                                              colors were therefore used). Training and testing trials were
  Figure 2: Training and testing trials for the six-item task.                                                                identical to the one-item task. Each container was uniquely
                                                                                                                              associated with one of the possible ratios specified by condi-
                                                                                                                              tion 0:10, 1:9, 2:8, 3:7, 4:6, and 5:5 above. Thus, the six-item
same bag. In each training trial, a picture of the bag was
                                                                                                                              task is a within-subject version of the one-item task, with the
displayed for 1000 milliseconds and then a marble (blue or
                                                                                                                              addition that training and testing trials from all six conditions
orange) appeared over the bag for 2000 milliseconds. There
                                                                                                                              are interleaved. Assignments of a ratio and marble colors (in
were 10 training trials, with no break between trials. In each
                                                                                                                              predefined color pairs) to each container was randomized per
testing trial, the bag was displayed with the two marble colors
                                                                                                                              participant. 64 participants took part in this task. Two ad-
below. Participants mouse clicked on a marble to make their
                                                                                                                              ditional versions of this experiment were also run; one where
choice of one draw from the bag. Their choice was displayed
                                                                                                                              all 6 bags were in condition 0:10 (each container was mapped
above the bag for 2000 milliseconds and then the next testing
                                                                                                                              to one color only) and one where all 6 containers were in con-
trial began. There were 10 testing trials with no breaks be-
                                                                                                                              dition 5:5. Each of these versions was completed by 32 new
tween trials. Locations (left or right) of the blue and orange
                                                                                                                              participants.
marbles were held constant across test trials for each partici-
pant, but counterbalanced across participants.                                                                                Experiment results
   A fixed ratio of blue to orange marbles was shown in the
training phase. Each participant was randomly assigned to                                                                     Participants in the six-item task were more likely to regular-
one of 6 training conditions based on this ratio. The color of                                                                ize their responses per container than participants in the one-
the training ratio’s minority marble (m) and majority marble                                                                  item task. Here, we refer to regularization as the production
(M) was counterbalanced across participants. All possible ra-                                                                 of a more extreme ratio than that observed during training,
                                                                                                                        437

                                                                      Figure 4: Distribution of participant responses for two addi-
                                                                      tional versions of the six-item task, where all items contained
                                                                      the same input ratio of m:M. One group of participants was
Figure 3: Difference in mean entropy scores between tasks,            trained on all 0:10 ratios and another group was trained on all
for each input ratio. Each participant’s sequence of marble           5:5 ratios.
draws during testing was converted into an entropy score.
Lower scores denote greater regularity within a response.
Participant responses were significantly more regular in the          responses and that participants’ responses were modulated by
six-item task than in the one-item task for input ratios 3:7,         training frequencies; they noticed differences in the input fre-
4:6, and 5:5. Error bars show the standard error of the mean.         quencies and this affected their responses. A significant inter-
                                                                      action of task and input frequency on entropy scores was also
                                                                      obtained, t(34) = 4.570, p < .001; participants responded dif-
where 0:10 and 10:0 are the most extreme ratios and 5:5 is            ferently to different input frequencies, and this pattern of re-
the least extreme. The distributions of participant responses         sponses also differed by task.
are shown in Figure 1. Each pane displays the percentage of              There was a significant difference in mean entropy scores
participants that responded with a given output frequency of          between tasks for input frequencies 3:7, 4:6, and 5:5 (W =
m, per input frequency and per task. In the one-item task, par-       1427.5, p = .001;W = 1714, p < .001;W = 1585.5, p <
ticipants probability matched; the mode of the population is          .001), respectively.1 The difference in mean entropy be-
on the input frequency of m, meaning that the most common             tween tasks was not significant for input frequencies 0:10,
response was perfect reproduction of the ratio observed dur-          1:9, and 2:8 (W = 894, p = .228;W = 1184.5, p = .192;W =
ing training. In the six-item task, visual inspection suggests        1264, p = .0542 ), respectively.
that participants did not reproduce the training ratios with as          Two additional experiments were conducted to explore the
high fidelity. Most participants regularized by overproducing         possibility that regularization in the six-item task is due to
the majority marble (all mass in the bars to the left of the dot-     interference between containers, such that ratios learned for
ted line) and a large number of responses are fully regular,          one container get confused with ratios learned for another
meaning the output frequency of m is 0 or 10.                         container. We eliminated this type of interference by train-
                                                                      ing participants on 6 containers with identical ratios. Figure
   To better assess the different degrees of regularization be-       4 shows participant responses when trained on all 0:10 ratios
tween tasks, we calculated the entropy of each participant’s          (left) and all 5:5 ratios (right). The average entropy for the all
sequence of test choices. This quantifies the amount of vari-         0:10 task is significantly lower than that of the 0:10 condition
ation (in bits) with a value between 0 and 1; where 0 denotes         in the six-item task (W = 5061, p = .004), but not signifi-
a completely regular sequence (i.e. a series of all blue marble       cantly different than the 0:10 condition in the one-item task
draws) and 1 denotes a maximally variable sequence (i.e. a            (W = 2900.5, p = .466). Tracking multiple 0:10 ratios is no
series of 5 blue and 5 orange draws, in any order). This allows       different than tracking one 0:10 ratio, but it is different from
us to refine our definition of regularization as the overproduc-      tracking one 0:10 ratio concurrently with other ratios. This
tion of one marble, such that the entropy of the participant’s        means interference may account for the errors participants
testing choices is lower than that of their training observa-         make in the original six-item task when producing draws for
tions. The mean entropy scores of participant responses per           the container they observed as 0:10. However, for the all 5:5
input frequency are shown in Figure 3.                                task, the average entropy was not significantly different from
   A linear mixed effects regression analysis showed a signif-
                                                                          1 These were determined with a non-parametric t-test, the
icant effect of task on entropy scores, t(34) = −7.226, p <
                                                                      Whitney-Mann U-test, since the distributions of entropy scores are
.001, and a significant effect of input frequency on entropy          non-normal.
scores, t(34) = −10.832, p < .001. This means the two tasks               2 After correction for multiple comparisons, this is not approach-
elicited different amounts of regularity within participants’         ing significance.
                                                                  438

the 5:5 condition in the six-item task (W = 5892.5, p = .617).       we switch to visualizing our data in terms of marble 1 (m1 )
Participants still produced 0:10 and 10:0 responses in the ab-       and marble 2 (m2 )3 . Figure 5 (top row) shows the two empir-
sence of observing these ratios during training. Therefore, in-      ical transition matrices and three model matrices for different
terference may account for some of the differences between           values of the prior parameter α. Each value of α defines a
the one-item and six-item tasks, but this isn’t the sole cause       unique transition matrix, and thus a unique pattern of behav-
of the regularization behavior observed in the six-item task.        ior. For example, if a Bayesian learner observes 1 draw of
                                                                     m1 and 9 of m2 , and if their prior is α = 0.01, they are most
                Frequency learning models                            likely to produce 0 draws of m1 and 10 of m2 , regularizing
What cognitive processes cause regularization? So far our            their productions. If their prior is α = 2, they are most likely
analyses have quantified the difference in regularity between        to produce 1 draw of m1 and 9 of m2 , probability matching
participants’ training and testing responses. In this sec-           their productions. And if their prior is α = 10, they are most
tion, we turn our focus to an internal force that can affect         likely to produce 3 draws of m1 and 7 of m2 , increasing varia-
a learner’s behavior; an inductive bias favoring certain ratios      tion in their productions. Thus, the prior used here intuitively
of marbles.                                                          captures a range of human behaviors in frequency learning.
                                                                        The model fitting task at hand is to determine which model
Bayesian model
                                                                     transition matrix most resembles the empirical transition ma-
Bayesian models provide a way to quantify inductive bi-              trix, by assigning the most likelihood to the empirical data.
ases and understand their effect on behavior. We fit a beta-         The prior associated with the best-fit model is the one that
binomial Bayesian sampler model to participants’ responses,          best explains participant behavior and gives us an idea of what
following Reali and Griffiths (2009), and ask what prior ex-         biases our participants may have.
pectation for regularity a Bayesian rational learner would              The best-fit bias in the one-item task is α = 1.55 with a
need to have in order to produce the data that our participants      log likelihood of −413, which is equivalent to correctly pre-
produced.                                                            dicting 20% of participant responses in this task 4 . This prior
   A Bayesian rational learner uses Bayes’ rule, P(h|d) ∝            shows an expectation for a slight amount of regularity in the
P(d|h)P(h), to infer what proportion of marbles generated            data set. For the six-item task, the best-fit bias is α = 1.21
the draws that they observed. Here, each proportion is a hy-         with a log likelihood of −1186, equivalent to 9% response
pothesis and the observed draws are the data. Bayes rule             prediction. This prior shows a stronger bias toward regularity
combines the prior probability of a hypothesis, P(h), with           in the six-item task than in the one-item task.
the likelihood of the data under that hypothesis, P(d|h), to            Prediction percentages are lower for the six-item task be-
arrive at a posterior probability of that hypothesis given the       cause participant responses are more variable in the this task
data, P(h|d). The prior is a beta distribution over all hypothe-     than in the one-item task. Only deterministic processes (with
ses, Beta( α2 , α2 ), where the parameter α determines whether       one output per input) can be predicted with 100% accuracy.
the learner expects to see regular draws or variable draws. A        The ceiling on model prediction for each task was determined
learner with α < 2 will tend to regularize their productions,        by fitting each data set to itself, yielding a maximum of 32%
a learner with α = 2 is unbiased toward any particular pro-          accuracy for the one-item task and 16% accuracy for the six-
portion of draws, and a learner with α > 2 is biased towards         item task. Relative to these ceilings, the best-fit models ac-
variability in draws. The likelihood of drawing N marbles in         count for 61% and 56% of participant responses in the one-
ratio k : (N − k) from a container of marbles in proportions         item and six-item tasks, respectively.
p : (1 − p) follows a binomial distribution (Equation 1).
                                                                   Bootstrap model
                                 N k
                   P(k|p, N) =      p (1 − p)N−k             (1)     An input-based random sampling model was also fit to the
                                 k
                                                                     data. This model defines the transition matrix that would be
   Once the posterior probability over all hypotheses has been
                                                                     obtained if participants produced their testing responses by
determined, the learner must choose a hypothesis to generate
                                                                     randomly sampling 10 draws from their training observations,
testing responses from. We take the case where learners sam-
                                                                     with replacement. In this case, each row would be a binomial
ple a hypothesis from the posterior distribution, and then sam-
                                                                     where p equals the training proportion of m1 . It is important
ple data from this hypothesis according to its likelihood (as if
                                                                     to note that this transition matrix defines the dynamics of drift
the learner were randomly drawing marbles from the hypoth-
                                                                     in one generation and may be used as a baseline for the loss of
esized proportion, with replacement, as in Equation 1).
                                                                     variation that can occur in the absence of a regularization bias.
   This model defines the probability of generating all test-
ing proportions (output states) from all training proportions            3 marble 1 (m ) refers to the blue marble in the one-item task,
                                                                                        1
(input states) and can be visualized as a transition matrix be-      and to the blue, brown, black, red, olive, and purple marbles in the
tween all possible states in the system. Because our exper-          six-item task.
                                                                         4 The raw log likelihoods should not be compared between tasks,
iment covers all possible training proportions for 10 draws
                                                                     because there are a different number of observations per task. This
from a bag, we can also construct an empirical transition ma-        is corrected for in the prediction percentages, which are comparable
trix from participant responses in each task. From here on,          between tasks.
                                                                 439

Figure 5: Transition matrices (top row) and their associated stationary distribution (bottom row) for the experimental results of
the two frequency learning tasks, and for the Bayesian model showing three example bias strengths (α = 0.01, 2, 10). Transition
matrices give the probability of moving from each input frequency (the number of training trials showing marble 1) to each
output frequency (the number of testing trials in which participants produced marble 1)3 . The stationary distribution shows
how often the transition matrix will produce each output frequency of marble 1.
For this model, the log likelihood of the one-item task data is              The results of these model fits strongly suggest that partici-
−259, equivalent to 25% response prediction, and is a bet-               pants in the six-item condition are not just performing poorly
ter fit than the best-fit beta-binomial sampler model5 . Thus,           at reproducing their training proportion, but they are regular-
of the models explored in this paper, drift provides the best            izing their responses in a way that can not be accounted for
account of our participants’ probability matching behavior.              by random errors.
However, a repeated measures Monte Carlo test shows that
the standard deviation among participant output entropies in             Learning biases and long-term behavior
the one-item task data are significantly lower than that obtain-         In addition to comparing the transition matrices, which de-
able by drift: p = .04, p = .03, p = .01, p = .003, for conditions       scribe the behavior of one generation of learners, we can also
2:8, 3:7, 4:6, 5:5, respectively. Although these data are well-          look at the long-term behavior of the system, which is de-
accounted for by the drift model, they still show a quantitative         scribed by the stationary distribution of the transition matrix
difference in standard deviation, meaning that the forces be-            (Figure 5, bottom row). This distribution tells us what per-
hind probability matching are not truly isomorphic to drift.             cent of the population we would expect to see in each state,
As for the six-item task, the log likelihood is −1076, equiva-           after an arbitrarily large number of generations, if the output
lent to 6% response prediction. Here, the sampler model with             state of one learner served as the input state to another. Grif-
a bias toward regularization is still the better fit.                    fiths and Kalish (2007) have shown that the stationary distri-
                                                                         bution mirrors the prior distribution over hypotheses for the
Null model                                                               Bayesian sampler model utilized here. The stationary dis-
This model is the transition matrix that would be obtained               tributions of the empirical transition matrices are most in-
if participants were randomly sampling from the two testing              teresting because these would be an estimate of our partic-
choices each trial (i.e. not engaging in the task). Here,                ipants’ regularization bias (the prior) if they were Bayesian
every row would be a binomial distribution where p = 0.5.                sampler learners6 . In line with this interpretation, the sta-
For this model, the log likelihood of the one-item task data             tionary distribution of the six-item task closely resembles
is −604, equivalent to 4% response prediction. For the                   that of its best-fit Bayesian model, which has a beta distri-
six-item task, the log likelihood is −1630, equivalent to                bution Beta(0.605,0.605). However, the stationary distribu-
1% response prediction. Of all models considered, this is                tion of the one-item task does not resemble that of its best-
the worst fit for both tasks, meaning that participants are              fit Bayesian model, which has a u-shaped beta distribution
not likely to be randomly sampling from their testing choices.           Beta(0.775,0.775). In general, the Bayesian model is a good
                                                                         fit to participant behavior in the six-item task, but does not ac-
    5 This bootstrap model, which defines the dynamics of evolution-     count very well for participant behavior in the one-item task.
ary drift, is equivalent to a Bayesian MAP model with α = 0. See
Reali & Griffiths (2010) for the proof.                                       6 Both of the empirical transition matrices are ergodic.
                                                                     440

A close examination of the model’s transition matrices and                                       References
stationary distributions shows that probability matching be-           Becker, A., & Veenstra, T. (2003). The survival of inflec-
havior with a low standard deviation is not within this model’s          tional morphology in French-related creoles. Studies in
range of behavior.                                                       Second Language Acquisition, 25, 283-306.
                                                                       Bickerton, D. (1984). The language bioprogram hypothesis.
                          Discussion                                     Behavioral and Brain Sciences, 7, 173-221.
                                                                       Chambers, J., Trudgill, P., & Schilling-Estes, N. (2003). The
We have shown that learning a single versus multiple fre-                handbook of language variation and change. Blackwell,
quencies modulates participants’ regularization behavior in a            Malden, MA.
non-linguistic task. When participants tracked the frequency           DeGraaff, M. (1999). Creolization, language change, and
associated with a single item, they probability matched; re-             language acquisition: an epilogue. In M. DeGraaf (Ed.)
producing the variation they had observed with high fidelity.            Language creation and language change: creolization, di-
However, when tracking multiple frequencies concurrently,                achrony, and development. Cambridge, MA: MIT Press.
participants regularized their responses, usually by overpro-          Gardner, A. (1957). Probability-learning with two and
ducing the most common variant.                                          three choices. The American Journal of Psychology,
   A beta-binomial Bayesian sampler model was fit to the re-             70(2), 174-185.
sults of each task and showed a stronger prior bias toward             Hudson, C., & Newport, E. (2005). Regularizing unpre-
regularization in the six-item task than in the one-item task.           dictable variation: the roles of adult and child learners in
Strictly speaking, the prior represents the inductive bias of            language formation and change. Language Learning
the learner, and participants should come to a marble-drawing            and Development, 1(2), 151195.
task with a particular expectation about the ratios of marbles         Hudson Kam, C., & Newport, E. (2009). Getting it right by
in containers, regardless of the difficultly of the task. The            getting it wrong: when learners change languages. Cogni-
fact that we find different best-fit priors according to different       tive Psychology, 59, 30-66.
task demands means that we are not revealing the inductive             Hudson Kam, C., & Chang, A. (2009). Investigating the
bias of our participants, per se, but a composite picture that           cause of language regularization in adults: memory con-
characterizes more than one cognitive constraint. At least one           straints or learning effects? Journal of Experimental Psy-
constraint that is sensitive to task demands should be added             chology, 35(3), 815-821.
to the model, such as a memory constraint that disproportion-          Griffiths, T. L., & Kalish, M. L. (2007). Language evolution
ally forgets lower-frequency observations. Such an addition              by iterated learning with Bayesian agents. Cognitive Sci-
could free up the prior to more accurately reflect participants’         ence, 31, 441480.
inductive bias. This raises a point of caution in comparing            Kareev, Y., Lieberman, I., & Lev, M. (1997). Through a nar-
inductive biases across domains without controlling for task             row window: sample size and the perception of correlation.
demands, since task demands can modulate bias strengths.                 Journal of Experimental Psychology, 126(3), 278-287.
   Our modeling results also suggest that human probability            Lumsden, J. S. (1999). Language acquisition and creoliza-
matching and regularization behavior do not lie on a simple              tion. In M. Degraaf (Ed.)        Language creation and lan-
continuum that can be captured by the prior alone. Although              guage change: creolization, diachrony, and development.
the Bayesian model accounted well for our participants’ regu-            Cambridge, MA: MIT Press.
larization behavior, it failed to account for the restricted vari-     Newport, E. (1990). Maturational constraints on language
ance of probability matching. Participants may be trying to              learning. Cognitive Science, 14, 11-28.
produce a representative sample of draws, where the most               Perfors, A. (2012). When do memory limitations lead to regu-
likely response is the training ratio itself. Such a parameter           larization? An experimental and computational investiga-
might lead to high-fidelity reproduction of the training pro-            tion. Preprint submitted to Elsevier.
portion under low memory constraints only.                             Reali, F., & Griffiths, T. L. (2009). The evolution of fre-
                                                                         quency distributions: Relating regularization to inductive
   If memory constraints are the cause of the regularization
                                                                         biases through iterated learning. Cognition, 111, 317-328.
bias revealed when learning the frequencies of marbles in sev-
                                                                       Reali, F., & Griffiths, T. L. (2010). Words as alleles: connect-
eral containers, then this same domain-general factor may be
                                                                         ing language evolution with Bayesian learners to models of
the cause of regularization in tasks naturally characterized by
                                                                         genetic drift. Proc. R. Soc. B, 277, 429-436.
concurrent frequency learning, such as language learning.
                                                                       Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learn-
                                                                         ing by 8-month-old infants. Science, 274(5294), 1926-
                   Acknowledgements                                      1928.
                                                                       Smith, K., & Wonnacott, E. (2010). Eliminating unpre-
Special thanks to Tom Griffiths and Luke Maurits for feed-               dictable variation through iterated learning. Cognition 116,
back. This research was supported by the University of Ed-               444-449.
inburgh’s College Studentship, the SORSAS award, and the
Engineering and Physical Sciences Research Council.
                                                                   441

