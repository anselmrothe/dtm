UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Developmental See-Saws: Ordered visual input in the first two years of life
Permalink
https://escholarship.org/uc/item/37q6828v
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Jayaraman, Swapnaa
Fausey, Caitlin
Smith, Linda
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

         Developmental See-Saws: Ordered visual input in the first two years of life
                                   Swapnaa Jayaraman, Caitlin M. Fausey, & Linda B. Smith
                                             ({swapnaa, cfausey, smith4} @indiana.edu)
                           Department of Psychological and Brain Sciences, Indiana University
                                      1101 East Tenth Street, Bloomington, IN 47405 USA
                                Abstract                                  general issue of what constitutes a developmentally
   The first two years of life are characterized by considerable          appropriate conceptualization of statistical learning in the
change in all domains – perception, cognition, action, and social         General Discussion.
interactions. Here, we consider the statistical structure of visual
input during these two years. Infants spanning the ages from 1 to         Faces and Hands as Important Social Stimuli
24 months wore body-mounted video cameras for 6 hours at home             The first two years of life are characterized by considerable
as they engaged in their daily activities. Our data strongly suggest
that the statistical structure of the learning environment is dynamic
                                                                          change in all domains – perception, cognition, action, and
and ordered. The available visual statistics are not stationary, but      social interactions. Findings in all of these domains indicate
rather they are gated by young children's developmental level. We         the important role of other people, in scaffolding and
find a rolling wave of "See-Saw" patterns over developmental time         supporting developmental process (Tomasello, 1988).
in two classes of important social stimuli: First faces, then hands;      Research into the social behaviors of mature partners that
and within hands, first other-then-self-then-touching-then-holding.       support infant learning have centered on two body regions –
These ordered environments may help learning systems “start
small,” find the optimal path to the optimal solution, and determine
                                                                          face and hands. Research into the adult actions that infants
the architecture of the system that does the learning.                    attend to as guides to learning and understanding the world
                                                                          also focus on two body regions – faces and hands. And,
Keywords: natural statistics; first-person camera; faces; hands           indeed, a very large literature suggests that infants are
                                                                          highly sensitive to what are very small movements in these
                            Introduction                                  body regions – a shift in eye gaze (Butterworth & Jarrett,
Growing evidence across many domains indicates that                       1991), a mouth opening (Moll & Tomasello, 2012), a point
human learners, including infants, are highly sensitive to the            (Leung & Rheingold,1981), and a grasp (Woodward, 1998).
statistical regularities in the learning environment (Saffran,            It seems likely that faces and hands are everywhere in early
Aslin & Newport, 1996) and that in many domains the                       infant experience. From the statistical learning perspective,
regularities in the learning environment contain sufficient               this would mean that face and hand experiences present a
information to yield deep conceptual representations                      very large data set for mining the structure and meaning of
(Chater, Tenenbaum & Yuille, 2006) of the kind that appear                social gestures.
responsible for syntax (Griffiths, Steyvers & Tenenbaum,                     However, contemporary research is also consistent with
2007), semantics (Griffiths, et al., 2007), categories (Madole            the idea that this statistical learning might be modulated by
& Oakes, 1999), and human visual object recognition                       internal (and innate, Meltzoff & Moore, 1977; Slater, 1999)
(Logothetis & Sheinberg, 1996; Quinn, Eimas & Tarr,                       biases that privilege faces early in development. Research
2001). As methods for understanding structure in large data               on infant face perception begins from the perspective that
sets advance, it seems likely that we will discover rich                  faces are a special class of stimuli. A large set of findings
insights in even broader domains about how the statistical                using diverse tasks indicate that very young infants are
structure of learning environments shapes human learning                  differentially sensitive to face-like visual stimuli relative to
and knowledge. The research presented in this paper makes                 other stimulus categories (Goren, Sarty & Wu, 1975;
two contributions to this endeavor: by extending the study                Johnson, et al., 1991) and can discriminate familiar faces
of the statistical structure of the learning environment to               from unfamiliar ones (Field et al, 1984) shortly after birth.
social stimuli – faces and hands; and by showing that the                 Moreover, the earliest social interactions consist of face-to-
statistical structure of the learning environment is not                  face play (Stern, 1971) and these have been characterized as
stationary. Rumelhart and McClelland’s (1986) model of the                “proto-conversations” that teach critical components of
learning of the past tense was once famously criticized                   turn-taking and seem a likely context for learning about the
(Pinker & Prince, 1988) as a cheat because the network was                facial cues that modulate social interactions and infant
presented with learning examples in an ordered way rather                 learning. Other evidence suggests that this early sensitivity
than as batch statistics. However, the statistics of the                  to faces plays a critical role in tuning face perception
learning environment can change substantially with                        processes: By 6 months infants recognize faces that are
development itself. The present findings provide one clear                similar to those that have dominated their visual experiences
and dramatic example of this reality. We return to the more               (same race) better than faces that are dissimilar (different
                                                                      669

race) (Kelly et al., 2007). Early visual deprivation appears to     Because of this, they may encounter and experience selected
disrupt indices of face expertise such as configural                regularities in just one small region of the total batch-
processing of faces (Maurer, Le Grand & Mondloch, 2002),            statistics learning environment (Smith & Gasser, 2005).
and identification of faces with altered orientations and           Given the dramatic changes in the skills of human infants
expressions (Geldart et al, 2002).                                  over the first two years of life, this seems highly likely.
   Systematic attention to hand actions as social indicators –      Given the ordered nature of these changes – first rolling
as pointers to objects to which infants should attend -- has        over, then reaching, then sitting stably, then crawling, and
been shown in 4 month olds (Rohlfing, Longo & Bertenthal,           then walking -- these selected statistics will also be ordered.
2012) but as far as we know this is the youngest                    West and King (1987) proposed the concept of ontogenetic
demonstration of an understanding of a hand action. Most of         niche: the idea that developmental level orders experiences
the evidence indicating infant attention to and understanding       in ways that constrains and canalizes developmental
of the meaning of hand actions – both in the context of             process. For example, in humans (and most mammal and
language learning (Bates et al, 1989) and in the context of         some bird species) the young require constant caretaking
understanding the causal structure of events (Baldwin, 1991;        and this constant caretaking limits as well as structures the
Woodward, 1998) – focuses on older infants. For example,            input, and thus the regularities that can be learned one at a
10 and 12 months olds have been shown to use hand actions           time. Humans’ changing sensory motor abilities seem likely
to predict causal sequences (Sommerville & Woodward,                to constrain and expand visual experiences in different ways
2005), 11 month olds have been shown to use the structure           at different times. Human infants spend their first 6 months
of a hand action to predict where an event will occur (Canon        where others place them – on the floor, in infant seats, in a
& Woodward, 2012), in a large number of experiments 9 to            crib, in arms – and see what is in those places and what their
14 month olds have been shown to use points and other               mature caretakers care to show them. By 12 months, infants
hand gestures to determine the intended referent of a heard         are much more masters of their own visual environments –
word (Rader & Zukow-Goldring, 2012), and 18 month olds              placing themselves in different locations and actively
may even understand hand gestures that mimic actions as             selecting what they will show themselves (Adolph et al.,
pointers to objects and events more readily than words              2012).
(Namy & Waxman, 1998), as may 2-4 year olds (Hahn &                    These considerations raise an alternative hypothesis about
Gershkoff-Stowe, 2010). Several recent studies on 12 to 18          faces and hands: Although faces and hands are equally
month old infants’ attention in naturalistic contexts indicate      ubiquitous in human environments, they are not equally
that these older infants differentially – and perhaps               ubiquitous in the visual environments of infants of different
systematically – look to the hand actions of mature partners        ages; instead, experiences of faces and hands are ordered,
when engaged in joint play with the parent (de Barbaro,             with dense experiences of faces characterizing the early
Chiba & Deák, 2011; Franchak, et al., 2010; Yoshida &               ontogenetic niche and dense experiences of hands
Smith, 2008), a result that suggests that these older infants       characterizing the later ontogenetic niche.
know that hand actions contain important social
information.                                                        Rationale for the present approach
   These findings indicate that infants may know about faces        The findings reported here are part of a larger program of
as sources of social information before they know about             research examining the statistical structure of natural visual
hands and suggest the following hypothesis: Although faces          environments as it relates to social cues and language
and hands are equally ubiquitous in the learning                    learning. We build on the approach of a growing number of
environments of infants, learning about these two classes of        researchers using ego-centric cameras (Fathi, Hodgkins &
social cues is gated by infants’ early differential sensitivity     Rehg, 2012; Kanade, 2009) to capture first person visual
to faces.                                                           environments. Studies of infants’ first person perspectives
                                                                    (mostly small laboratory studies, Aslin, 2009; Franchak et
Ordered input                                                       al., 2011; Smith, Yu, & Pereira, 2011) have shown that
Traditional approaches to statistical learning have                 these first person environments are characterized by
concentrated on non-incremental learning tasks, tasks in            properties of early visual experience that are not evident
which the entire training set is fixed at the start of learning     from third-person observer perspectives (Yoshida & Smith,
and then is either presented in its entirety or randomly            2008) and have also documented the impact of infant body
sampled. From this perspective, if learning needs to be             movements on infant visual experience (Kretch et al., 2012).
constrained in some way or directed to some portion of the          Intriguingly, all the head-camera studies conducted with
input, it must be accomplished by internal constraints on the       toddlers to date have noted that faces are rarely in the head
learning system (Markman & Hutchinson, 1984; Pinker,                camera images whereas hands – the child’s and social
1989), such as an innate sensitivity or interest in faces. But      partner’s – are often in view (Franchak et al, 2011; Frank,
infants do not encounter the world as a single set of fixed         2012; Smith et al, 2011; Yoshida & Smith, 2008). These
statistics; they encounter it one learning instance at a time.      studies, however, did not broadly sample the natural or
                                                                670

representative experiences of participants. The present study      Faces and Hands
was designed to do just this. Infants spanning the ages from       The first broad passes coded for the presence of Faces and
1 to 24 months wore body-mounted video cameras for 6               Hands. The infant (1-3, 7-9 months) and toddler (18, 24
hours at home as they engaged in their daily activities. The       months) data were coded with slightly different protocols.
first questions we asked of these data, the results we report      For infants, each coder saw up to eight frames and answered
here, are these: How prevalent are faces and hands in the          several questions about each frame. The two relevant
visual environment? Do the frequencies of faces and hands          questions were: (1) Do you see a human face or face part?
change systematically with development?                            and (2) Do you see other body parts or skin? If yes, which
                                                                   do you see? (a) bare hands/fingers, (b) bare feet/toes, (c)
 Method: Capturing early visual environments                       other body parts (neck, shoulder, knee, etc.), (d) body parts
                                                                   covered in clothes, (e) two or more of the above. In these
Participants                                                       analyses, only responses that indicated the presence of bare
23 infants and toddlers provided up to 6 hours of video            hands were further analyzed. Four unique coders judged
each. This visual corpus consists of four subsets grouped by       each frame. For toddlers, each coder saw up to 100 frames
age. All videos within an age range are treated as a set.          and answered the same yes-or-no question for all frames. In
                                                                   separate passes, coders answered either (1) Do you see a
           Table 1: Infant and toddler visual corpus               human face in this picture? or (2) Do you see a human hand
   Age (months)       n    Hours of video     Frames coded         in this picture? Five unique coders judged each frame.
        1-3           7        19.26             13,865
        7-9           5        21.88             15,754            Free, touching and holding hands
        18            6        22.64             16,303
        24            5        14.59             10,505
                                                                   The next coding passes focused specifically on hands. First,
       Total         23        78.37             56,427            we identified whether hands in the visual input belonged to
                                                                   the child or to someone else. Then, we identified whether
                                                                   the child's own hand was free, touching something, or
Materials and Procedure                                            holding a small object. In four distinct passes, coders
                                                                   answered one of these questions: Does any hand you see
A small, lightweight camera was used to record the visual
                                                                   belong to the child wearing the camera?, Is the child's own
environments of infants and toddlers (Looxcie 2, Looxcie,
                                                                   hand touching something?, Is the child's own hand holding
Inc.). The diagonal FOV is 62 degrees with a 2":infinity
                                                                   onto something?, Is the child's own hand holding something
depth of focus. The camera was secured to a wearable hat or
                                                                   that can be carried?
harness. Parents were given a camera, hat and/or harness,
and instructions about camera operations. Parents recorded
up to 6 hours of video when their child was awake.                              Results: Ordered visual input
Video pre-processing                                               Body parts in the visual environment
Recorded videos were screened for private content and              How prevalent are faces and hands in the visual
blank screens (e.g., camera was left turned on while not on        environments of infants and toddlers? The relative
child). Remaining videos were converted to images sampled          frequency of these two key body parts depends on the
at one frame for every five seconds of video. This first-of-a-     developmental stage of the child (Figure 1). The visual
kind corpus has approximately 78 hours of video and 56,000         environments of the infants had more faces than hands (1-3
frames of the natural visual environments of infants and           months: .29 Faces, .01 Hands; 7-9 months: .15 Faces, .06
toddlers in the first two years of life.                           Hands). For toddlers, hands were more prevalent than faces
                                                                   (18 months: .11 Faces, .28 Hands; 24 months: .07 Faces, .32
                                                                   Hands); χ2(3, N = 17962) = 6936.84, p < .001.
      Video coding: A reliable crowd-sourced
                                                                        Faces and hands appear to trade-off, suggesting ordered
                          approach                                 visual input: Faces first, then hands. The developmental
Frames were presented to coders on Amazon's Mechanical             trend is not just increased variability of body parts in the
Turk (mturk.com) and analyses consider only those frames           visual input: The total proportion of faces and hands
for which at least 75% of coders agreed (across all coding         together is more stable across the first two years of life (.30,
passes, 93.7% reliable judgments). Coding proceeded in six         .21, .34, .34, for each age range respectively). The key
separate passes through the data. For each pass, coders            finding is a "See-Saw" pattern: What is first available to
viewed an instructions page with example images.                   infants (here, Faces; "See") fades to developmental history
                                                                   ("Saw") as infants creates new tasks for themselves with
                                                                   advancing motor, language and social skills.
                                                               671

   Figure 1: Faces and hands in early visual environments
                                                                                Figure 2: Ordered visual input of Hands
Hands in the visual environment                                     object? Over the first two years of life, an increasing
                                                                    proportion of visual instances of touching the world are
What kinds of hands are potentially in view for infants and
                                                                    instances of holding objects (Figure 2c). Before 18 months,
toddlers? The answer to this question changes over the first
                                                                    the visual environment includes few instances of hands
two years of life. Here, we focus on three kinds of
                                                                    together with objects (7-9 months: .19 of all touching
developmentally relevant input: hand identity, contact
                                                                    instances). Toddlers' visual input, however, includes many
between hands and the world, and holding small objects.
                                                                    of these instances (18 months: .54; 24 months: .61). That is,
For each, we find patterns of ordered visual input: What is
                                                                    infants and toddlers find themselves in very different visual
visually available early is replaced by something else later.
                                                                    circumstances with respect to hands-on-objects, χ2(2, N =
                                                                    2814) = 141.61, p < .001. The pattern is: First hands
Hands Identity: Other-to-Own Whose hands are available
                                                                    touching, then hands holding.
in the visual input to infants and toddlers? Over the first two
years of life, the child's own hands are increasingly
available (Figure 2a). Early, the kinds of hands in the visual                        General Discussion
environment are overwhelmingly other people's hands, but            Our corpus of visual environments is unprecedented in
by toddlerhood the child's own hands are nearly half the            scope: We are capturing visual regularities throughout the
available hand visual input (1-3 months: .05 Own; 7-9               first two years of human life. Importantly, we capture
months: .35 Own; 18 months: .44 Own; 24 months: .46                 environments throughout these two years, rather than
Own), χ2(3, N = 9096) = 152.64, p < .001. The pattern is:           zooming in to focus on one unique time, or zooming out to
First someone else's hands, then your own hands.                    collapse across many different times. Everyday acting and
                                                                    thinking happens within nested timescales and complete
Hands Contact: Free-to-Touch When your visual                       theories of how environmental regularities matter for human
environment includes your own hand, what else is                    cognition demand evidence from each scale: from realtime
potentially in view? Over the first two years of life, infants      measures of in-the-moment attention through summaries of
increasingly make manual contact with the world (Figure             long-term experience. Our project provides critical insight
2b). Early, hands are free -- flailing and reaching. The visual     into a scale currently missing from theories of statistical
environment of 1-3 month-old infants does not include their         learning: developmental time.
own hands contacting the world. But, by 24 months, over                Our data strongly suggest that input is dynamic and
two-thirds of the views of their own hands also include             ordered. Visual regularities in developmental time may be a
something they touch (1-3 months: 0 Touching; 7-9 months:           rolling wave of "See-Saw" patterns. Here, we see this across
.68 Touching; 18 months: .68 Touching; 24 months: .77               two classes of important social stimuli - faces, then hands.
Touching), χ2(3, N = 3936) = 61.76, p < .001. The pattern           We also see this within hands, going from Other-to-Self-to-
is: First hands free, then hands touching the world.                Touching-to-Holding. If our investigation into early visual
                                                                    statistics had zoomed into 3-month-old infants, we would
Hands on Objects: Touch-to-Hold How often do early                  have missed important regularities about hands; if we had
visual environments include one's own hand holding an               zoomed out to batch statistics over the first two years of life,
                                                                672

we would have concluded that the environments of infants                                    References
and toddlers include roughly one-third body parts. Instead,         Adolph, K. E., Cole, W. G., Komati, M., Garciaguirre, J. S.,
we find a key pattern in environmental regularities:                  Badaly, D., Lingeman, J. M., & Sotsky, R. B. (2012) How
Developmental statistics are dynamic and ordered.                     do you learn to walk? Thousands of steps and dozens of
   The available visual statistics are gated by young                 falls per day. Psychological Science.
children's developmental level. A 3-month-old infant who is         Aslin, R. N. (2009). How infants view natural scenes
placed and carried finds herself in different visual                  gathered from a head-mounted camera. Optometry and
environments than a walking, talking 24-month-old. Like               vision science: official publication of the American
other species, our data suggest that humans experience                Academy of Optometry, 86(6), 561.
distinct ontogenetic niches as they progress toward adult-          Baldwin, D. A. (1991). Infants' contribution to the
like motor, social, and language abilities. These visual              achievement of joint reference. Child development, 62(5),
niches may do a lot of important filtering for young                  874-890.
learners: rather than sophisticated internal attentional            Bates, E., Thal, D., Whitesell, K., Fenson, L., & Oakes, L.
control, "starting small" in structured input may be                  (1989). Integrating language and gesture in
accomplished by other developmental constraints. Of                   infancy. Developmental Psychology, 25(6), 1004.
course, the fact that developmental changes in many skills          Butterworth, G., & Jarrett, N. (1991). What minds have in
constrain the visual environment does not rule out the                common is space: Spatial mechanisms serving joint visual
possibility of additional attentional gating. It may, however,        attention in infancy. British journal of developmental
reduce the challenges that attentional gating must resolve.           psychology, 9(1), 55-72.
   Does this temporal ordering of statistical regularities          Cannon, E. N., & Woodward, A. L. (2012). Infants generate
                                                                      goal‐based action predictions. Developmental Science.
matter? It could be that outcomes at 2 years are best
                                                                    Chater, N., Tenenbaum, J. B., & Yuille, A. (2006).
predicted by the total set of regularities and not by the order
                                                                      Probabilistic models of cognition:              Conceptual
of those visual environments. Alternatively, some paths
                                                                      foundations. Trends in Cognitive Sciences, 10(7),287-291.
through the search space may be optimal, and mother-nature          de Barbaro, K., Chiba, A., & Deák, G. O. (2011).
may optimize social learning by guiding the learner along             Micro‐analysis of infant looking in a naturalistic social
optimal paths. More radically, the order of these experiences         setting: insights from biologically based models of
may not just enhance the optimal solution, but may                    attention. Developmental Science, 14(5), 1150-1160.
determine the class of outcomes. Developmental process              Dominguez, M., & Jacobs, R.A. (2003). Developmental
consists not just in the sampling of information but also in          constraints aid the acquisition of binocular disparity
the change in the very internal structure of the learner.             sensitivities. Neural Computation, 15(1), 161-182.
Considerable evidence from a psycho-biological perspective          Elman, J. L. (1993). Learning and development in neural
shows that the ordering and timing of sensory information             networks: The importance of starting small. Cognition,
play a critical role in brain development (Held & Hein,               48(1), 71-99.
1963; Lord, 2012; Turkewitz & Kenny, 2004). Reordering              Fathi, A., Hodgins, J. K., & Rehg, J. M. (2012, June). Social
the usual sensory experiences within a developmental                  interactions: A first-person perspective. In Computer
individual changes the architecture of the brain, not just            Vision and Pattern Recognition (CVPR), 2012 IEEE
what is known but what is knowable (Knudsen, 2006). A                 Conference on (pp. 1226-1233). IEEE.
related idea, from cognitive theorists is the “starting small”      Field, T. M., Cohen, D., Garcia, R., & Greenberg, R.
hypothesis: limits that arise from the immaturity of the              (1984). Mother-stranger face discrimination by the
neural system constrain the input and, rather than holding            newborn. Infant Behavior and Development, 7(1), 19-25.
back development, play a role in fostering development              Fox, S.E., Levitt, P., & Neslon III, C.A. (2010). How the
(Dominguez & Jacobs, 2003; Elman, 1993; Fox, Levitt &                 timing and quality of early experiences influence the
Nelson, 2010; Newport, 1990; Westermann, 2000). Between               development of brain architecture. Child development,
birth and 2 years, human infants travel through a set of              81(1), 28-40.
                                                                    Franchak, J. M., Kretch, K. S., Soska, K. C., Babcock, J. S.,
highly distinct developmental environments determined first
                                                                      & Adolph, K. E. (2010, March). Head-mounted eye-
by their early immaturity and then by their growing
                                                                      tracking of infants' natural interactions: a new method.
emotional, motor, and cognitive competence. These ordered
                                                                      In Proceedings of the 2010 Symposium on Eye-Tracking
environments may help learning systems “start small,” find            Research & Applications (pp. 21-27). ACM.
the optimal path to the optimal solution, and determine the         Frank, M. C. (2012). Measuring children's visual access to
architecture of the system that does the learning.                    social information using face detection. Proceedings of
                                                                      the 34th Annual Meeting of the Cognitive Science Society.
                    Acknowledgments                                 Geldart, S., Mondloch, C. J., Maurer, D., De Schonen, S., &
This work was supported by NICHHD 28675, NIH NRSA                     Brent, H. P. (2002). The effect of early visual deprivation
HD007475-18, and NIH R21HD068475. The authors wish                    on the development of face processing. Developmental
to thank Char Wozniak and Ariel La for data collection.               Science, 5(4), 490-501.
                                                                673

Goren, C. C., Sarty, M., & Wu, P. Y. (1975). Visual               Pinker, S. (1989). Learnability and cognition: The
  following and pattern discrimination of face-like stimuli         acquisition of argument structure. The MIT Press.
  by newborn infants. Pediatrics, 56(4), 544-549.                 Pinker, S., & Prince, A. (1988). On language and
Griffiths, T. L., Steyvers, M., & Tenenbaum, J. B. (2007).          connectionism: Analysis of a parallel distributed
  Topics in semantic representation. Psychological                  processing            model            of           language
  review, 114(2), 211.                                              acquisition. Cognition,28(1), 73-193.
Hahn, E. R., & Gershkoff-Stowe, L. (2010). Children and           Quinn, P. C., Eimas, P. D., & Tarr, M. J. (2001). Perceptual
  adults learn actions for objects more readily than                categorization of cat and dog silhouettes by 3-to 4-month-
  labels. Language Learning and Development, 6(4), 283-             old      infants. Journal      of     experimental      child
  308.                                                              psychology, 79(1), 78-94.
Held, R., & Hein, A. (1963). Movement-produced                    Rader, N. D. V., & Zukow-Goldring, P. (2012). Caregivers’
  stimulation in the development of visually guided                 gestures direct infant attention during early word learning:
  behavior. Journal of Comparative and Physiological                the importance of dynamic synchrony.Language Sciences.
  Psychology, 56(5), 872.                                         Rohlfing, K. J., Longo, M. R., & Bertenthal, B. I. (2012).
Johnson, M. H., Dziurawiec, S., Ellis, H., & Morton, J.             Dynamic pointing triggers shifts of visual attention in
  (1991). Newborns' preferential tracking of face-like              young infants. Developmental Science.
  stimuli and its subsequent decline. Cognition, 40(1), 1-19.     Rumelhart, D. E., McClelland, J. L., & CORPORATE PDP
Kanade, T. (2009). First-person, inside-out vision. In IEEE         Research Group. (1986). Parallel distributed processing:
  Workshop on Egocentric Vision, CVPR (Vol. 1).                     explorations in the microstructure of cognition, vol. 2:
Kelly, D. J., Quinn, P. C., Slater, A. M., Lee, K., Ge, L., &       psychological and biological models.
  Pascalis, O. (2007). The other-race effect develops during      Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
  infancy evidence of perceptual narrowing. Psychological           Statistical learning by 8-month-old infants.
  Science, 18(12), 1084-1089.                                     Slater, A. M. (1999). Perceptual development: Visual,
Knudsen, E. I. (2006). Neural Derivation of Sound Source            auditory and speech perception in infancy. Psychology
  Location in the Barn Owl. Annals of the New York                  Press.
  Academy of Sciences, 510(1), 33-38.                             Smith, L. B., Yu, C., & Pereira, A. F. (2010). Not your
Kretch, K., Franchak, J., Brothers, J., & Adolph, K. (2012).        mother’s view: The dynamics of toddler visual
  What infants see depends on locomotor posture. Journal            experience. Developmental science, 14(1), 9-17.
  of Vision, 12(9), 182-182.                                      Smith, L., & Gasser, M. (2005). The development of
Leung, E. H., & Rheingold, H. L. (1981). Development of             embodied cognition: Six lessons from babies. Artificial
  pointing     as     a     social    gesture. Developmental        Life, 11(1-2), 13-29.
  Psychology, 17(2), 215                                          Sommerville, J. A., & Woodward, A. L. (2005). Pulling out
Logothetis, N. K., & Sheinberg, D. L. (1996). Visual object         the intentional structure of action: the relation between
  recognition. Annual review of neuroscience, 19(1), 577-           action     processing     and     action    production     in
  621.                                                              infancy. Cognition, 95(1), 1-30.
Lord, K. (2012). A Comparison of the Sensory                      Stern, D. N. (1971). A Micro-Analysis of Mother-Infant
  Development of Wolves (Canis lupus lupus) and Dogs                Interaction. Behavior Regulating Social Contact Between
  (Canis lupus familiaris). Ethology.                               a Mother and her 3 1/2 Month-Old Twins. Journal of the
Madole, K. L., & Oakes, L. M. (1999). Making sense of               American Academy of Child Psychiatry, 10(3), 501-517.
  infant categorization: Stable processes and changing            Tomasello, M. (1988). The role of joint attentional
  representations. Developmental Review,19(2), 263-296.             processes in early language development. Language
Markman, E. M., & Hutchinson, J. E. (1984). Children's              Sciences, 10(1), 69-88.
  sensitivity to constraints on word meaning: Taxonomic           Turkewitz, G., & Kenny, P.A. (2004). Limitations on input
  versus thematic relations. Cognitive psychology, 16, 1-27.        as a basis for neural organization and perceptual
Maurer, D., Grand, R. L., & Mondloch, C. J. (2002). The             development: A preliminary theoretical statement.
  many faces of configural processing. Trends in cognitive          Developmental Psychobiology, 15(4), 357-368.
  sciences, 6(6), 255-260.                                        West, M. J., & King, A. P. (1987). Settling nature and
Meltzoff, A. N., & Moore, M. K. (1977). Imitation of facial         nurture into an ontogenetic niche. Developmental
  and         manual         gestures        by       human         psychobiology, 20(5), 549-562.
  neonates. Science, 198(4312), 75-78.                            Westermann, G. (2000). Constructivist neural network
Moll, H., & Tomasello, M. (2010). Infant cognition. Current         models of cognitive development (Doctoral dissertation,
  Biology, 20(20), R872-R875.                                       University of Edinburgh).
Namy, L. L., & Waxman, S. R. (1998). Words and gestures:          Woodward, A. L. (1998). Infants selectively encode the goal
  Infants' interpretations of different forms of symbolic           object of an actor's reach. Cognition, 69(1), 1-34.
  reference. Child development,69, 295-308.                       Yoshida, H., & Smith, L. B. (2008). What's in view for
Newport, E.L. (1990). Maturational constraints on language          toddlers? Using a head camera to study visual
  learning. Cognitive Science, 14(1), 11-28.                        experience. Infancy, 13(3), 229-248.
                                                              674

