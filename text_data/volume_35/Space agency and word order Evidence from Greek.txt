UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Space, agency and word order: Evidence from Greek

Permalink
https://escholarship.org/uc/item/5q9436pm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Cheimariou, Spyridoula
Loui, Sonia

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Space, agency and word order: Evidence from Greek
Spyridoula Cheimariou (spyridoula-cheimariou@uiowa.edu)
Department of Communication Sciences and Disorders, University of Iowa
250 Hawkins Drive, Iowa City, IA 52242 USA

Sonia Loui (sonialoui@gmail.com)
Department of Philosophy & History of Science (MITHE), Ano Ilissia University Campus
GR-15771 Zografos, Greece

Abstract
We examined the role of spatial representations and word
order on thematic role assignment in Greek. Previous studies
suggest that spatial representations influence thematic role
assignment; agent is typically depicted on the left, and patient
on the right. Here, we address this issue using a language with
flexible word order which allows us to manipulate sentence
structure (SVO–OVS) orthogonally to thematic role. Greek
speakers heard SVO/OVS sentences while viewing depictions
of actions involving two characters and they judged whether
sentence and picture matched in meaning. The agent’s
position in the picture was directly manipulated. The results
support the effect of left bias on language processing.
However, this bias may be better understood when its
interaction with other sources of information and languagespecific constraints are taken into account. Theories of
prediction may help us illuminate how spatial biases and
linguistic factors interactively affect the way we process our
world.
Keywords: spatial representation, language, thematic role
assignment, word order, sentence comprehension, prediction,
Greek.

Introduction
The combinatory study of language and space aims to shed
light on how an analog, geometric and continuous
representation is encoded into a propositional algebraic and
discrete representation (Jackendoff, 1992; Geminiani,
Bisiach, Berti & Rusconi, 1995; Hayward & Tarr, 1995;
Jackendoff, 1996; Chatterjee, Southwood & Basilico, 1999;
Levinson, 2003; Papafragou, Hulbert & Trueswell, 2008,
among others). Recent research has inaugurated a discussion
on how language structures are constrained by spatial biases
(Chatterjee, Maher, Gonzales-Rothi, & Heilman, 1995;
Chatterjee, Southwood, & Basilico, 1999). Researchers
(Chatterjee et., al, 1995; Chatterjee, Southwood, & Basilico,
1999; Chatterjee, 2001; 2008) have entertained the claim
that events are conceptualized spatially and prelinguistically
proceeding from left towards the right. They assume that
language development exploits systems meant for left-toright spatial attention in the left hemisphere. Therefore, the
left-to-right directional bias indicates primitive spatial
representations and reflects a prelinguistic neural encoding
of events and actions.
Evidence for this claim comes from case studies in
agrammatic speech (Caplan & Futter, 1986; Caramazza &
Miceli, 1991). In these studies, the person with

agrammatism systematically assigned agency to the first
noun heard or to the one located to the left of the verb.
Chatterjee and colleagues (Chatterjee, et al. 1995;
Chatterjee, Southwood, & Basilico, 1999), based on the
Jacksonian notion that primitive cognitive functions are
overlaid with more complex functions, hypothesized that
people with agrammatic aphasia tend to follow a temporal
or spatial strategy based on those primitive spatial
representations in order to interpret a sentence once their
more complex linguistic abilities fail. To test for their
assumption they conducted studies in typical population
(Chatterjee et al., 1995; Chatterjee, Southwood, & Basilico,
1999; Barrett & Craver-Lemley, 2008). In these studies,
participants were asked to depict sentences describing an
action with two persons involved or to match sentences to
pictures. Participants tended to draw the agent of an action
closer to the left side of the picture. For example, in the
sentence «The girl chased the boy», it was more probable
for the participants to depict the girl on the left side of the
picture and the boy on the right side. Also, participants
responded faster when the agent was located on the left side
in sentence-picture matching tasks.
According to an alternative explanation, the left-to-right
directional bias is culturally determined by the directionality
of the reading/writing system (Maass & Russo, 2003; Chan
& Bergen, 2005; Dobel, Diesendruck, & Bolte, 2007).
Specifically, Maass and Russo (2003) investigated spatial
biases in thematic role assignment in directionally opposite
writing system, such as Italian (left-to-right) and Arabic
(right-to-left). They found that Italian speakers tended to
assign the agent on the left, while Arabic speakers had the
reverse tendency. Furthermore, the more years Arabic
speakers had spent abroad exposed to the opposite writing
system, the more mitigated their right-to-left bias was.
Furthermore, Dobel, Diesendruck, and Bolte (2007)
strengthened this argument by showing that the left or right
bias in depicting agency is based not only on reading and
writing practices, but also on the degree of exposure on
those practices. Specifically, they tested spatial biases in
German- and Hebrew-speaking adults and preschool
children. They found that the writing system influenced
thematic role assignment in adults, that is, German-speaking
adults had a left-to-right spatial bias, while Hebrewspeaking adults had the opposite bias. However, this was
not observed for preschool children who had no exposure to
the reading and writing systems of their language.

2012

The previous studies suggest that thematic role
assignment is affected conceptually and spatially by the
reading and writing systems. The present study extends the
role of language on thematic role assignment bias by adding
word order, that is, the within-sentence structure, as a
possible variable. The methodological paradigm used in
previous research (Chatterjee et al., 1995; Chatterjee,
Southwood, & Basilico, 1999) was based on English, a
language with highly restrictive word order. To manipulate
temporally or spatially the agent or the patient of an action,
previous studies either used active and passive voice
(Chatterjee et al., 1995), or verbs with different trajectories
(e.g. “The circle pushes the square”, in which the circle is
the agent and the action moves away from the agent, “The
circle pulls the square” in which the circle is the agent and
the action goes forward to the agent) (Chatterjee,
Southwood, & Basilico, 1999).
A question arising from this manipulation is whether
agency will be affected by the within-sentence structure,
that is, the order that thematic roles are presented within the
sentence. In Greek, which has a left-to right reading and
writing system, grammatical information is conveyed
through inflection, thus multiple word orders are allowed
(SVO, OSV, VOS, VSO, OVS, OSV). The agent or the
patient of an action can appear in any order within the
sentence independently of whether the sentence is active or
passive. For example, in active voice, structures such as
“The cooknom kicks the pirateacc” (the cook=agent) and “The
pirateacc kicks the cooknom” are both grammatical. Therefore,
highly inflectional languages, such as Greek, allow us to
manipulate word order without necessarily using the passive
voice which is of less frequency. In our study, we assume
that spatial biases will be influenced by the within-structure
sentence. We predict that participants will be faster in
responding to sentences that not only match in terms of
agency, but also in terms of characters’ position in the
sentence independently of thematic role assignment, that is,
even in conditions that characters’ share the same location
spatially and temporally, independently of meaning.

Methods
A sentence-picture verification task was used. Pairs of
characters were presented in a 2x2x2 experimental design.
Each picture involved two characters (character1 –
character2; e.g. “cook”, “pirate”) and each sentence
contained two nouns corresponding to those characters
(noun1 – noun2), one in nominative (agent) and one in
accusative (patient). The experimental stimuli were
manipulated on three dimensions: 1. characters’ position in
the picture (left – right), by flipping the image, 2.
characters’ position in the sentence (e.g. SVO – OVS) and
3. characters’ thematic role (agent – patient) in the sentence
by interchanging nominative and accusative case. Therefore,
thematic role assignment was actually the variable that
produced either matched- or mismatched-in-meaning
sentence-picture pairs. Eight experimental conditions were

created (see Table 1). Every pair of characters was
presented in each of eight conditions.
Table 1: Experimental design for sentence-verification
task
Meaning
Match
Match
“The
cooknom
kicks the
pirateacc”
“The
pirateacc
kicks the
cooknom”

Mismatch
Position in sentence
Mismatch
Match
Mismatch
“The
“The
“The
pirateacc
cookacc
piratenom
kicks the
kicks the
kicks the
cooknom”
piratenom”
cookacc”
“The
“The
“The
cooknom
piratenom
cookacc
kicks the
kicks the
kicks the
pirateacc”
cookacc”
piratenom”

In half of the experimental conditions thematic role
assignment reflected the depicted action resulting in
matched-in-meaning pairs, whereas in the other half,
thematic roles mismatched the depicted action (mismatchedin-meaning pairs). Furthermore, in half of the matched-inmeaning pairs, nouns’ location in sentence matched
characters’ position in picture, whereas in the other half,
nouns’ location in sentence mismatched characters’ position
in picture. The same was true for the mismatched-inmeaning conditions. Our dependent variable was response
times and our independent variables were character’s
position in the picture (left, right), and word order (SVO –
OVS).

Participants
Thirty-three adults, 18-30 year olds, participated in the
present experiment. They were all Greek native speakers.
They did not receive any compensation for their
participation.

Materials
Pictures The test stimuli consisted of 9 colored pictures.
Each picture depicted two characters taking part in an
action, and additional objects and people. The action
presented in the picture was always the same, that is,
character1 was always doing the action and character 2 was
receiving the action. However, there were two conditions.
Half of the pictures depicted the agent on the left and half of
them depicted the agent on the right. For each target picture,
the agent of the action was either depicted on the left or on
the right side of the screen by flipping the image. The filler
items consisted of 60 colored pictures depicting objects and
people. The order of experimental and filler items was
pseudo-randomized, with the constraint that each
experimental item was separated by a minimum of one filler
item. All pictures were part of a larger set of pictures used in

2013

Gennari, Mirkovic, and MacDonald (2012) and were
appropriately adjusted for the purposes of this experiment.
Sentences For the test sentences, 9 verbs representing
actions were used to construct quadruplets of active
sentences, resulting in 36 Greek sentences as test items,
ranging in length from 5 to 6 (mean = 5.5) words. These
sentences had two possible word orders (SVO or OVS) and
half of them were matching in meaning with the
experimental pictures, whereas the other half were not.
Examples of sentences are presented in Table 1.
Additionally, 120 Greek sentences were used as filler items
ranging in length from 3 to 10 words (mean = 4.9). Half of
them matched in meaning the filler pictures and half of them
did not. All sentences were recorded by a female native
Greek speaker whose instructions were to read each
sentence aloud in a natural, clear manner, in normal
intonation.

times did not differ in the SVO condition (t = 0.65; p =
0.5306), that is, agent’s position did not affect reaction
times. However, in the OVS condition, participants were
significantly faster in responding to pictures presenting the
agent on the right compared to left (t = -5.56; p = 0.0001),
i.e. when within-sentence structure matched in characters’
position in the sentence (Figure 1).
2800
2700
2600

OVS

2500

SVO

2400

2300
left

right

Procedure
Each participant, after giving verbal consent to participate in
the study was seated in a quiet room and given instructions
about the experiment. DMDX (Forster & Forster, 2003) was
used for the presentation of the stimuli. Visual stimuli were
presented at the center of a laptop screen. Auditory stimuli
were delivered over high quality headphones. In each trial,
participants saw a picture and simultaneously heard a
sentence corresponding or not to the picture. Participants
had to perform a 2AFC task to indicate whether the sentence
they heard matched the picture by pressing one of two
buttons. Participants were given three practice trials at the
beginning of the experiment in order to make sure they had
understood the task. There was no feedback. The
experiment lasted approximately 30 minutes.

Results
Data were analyzed with generalized linear mixed-effects
modeling, with random effects for participants and items,
employing function lmer of package lme4 (Bates, Maechler,
& Bolker, 2012) in R (R Development Core Team, 2012).
Response times were log-transformed. Only accurate
responses were included in the analysis (2% excluded) and
only those participants that had lower than 8% error rate.
None of the participants was excluded from the analysis.
Outliers were removed, that is, items with response time
values below 500 msec or above two standard deviations
from the mean. This resulted in excluding 4% of the total
data.
We conducted separate analyses for matched- and
mismatched-in-meaning stimuli. For the matched-inmeaning condition, a main effect of agents’ position was
found (t value = -5.19, p = 0.0001) (i.e. participants’
responses were faster when the agent was depicted on the
right) and a main effect of word order (t value = -9.29, p =
0.0001). However, agents’ position interacted with word
order (t value = 4.13, p = 0.0004). Contrasts among SVO
and OVS conditions revealed that participants’ reaction

Figure 1: Agents’ position and word order interaction in
reaction times in matched-in-meaning pairs. In all figures,
untransformed RTs are presented for ease of interpretation.
Same effects were found for the mismatched-in-meaning
condition. A main effect of agents’ position, (-6.06, p =
0.0001), word order (t value = -10.12, p = 0.0001) and an
interaction between agents’ position and word order was
found (t value = 4.13, p = 0.0001). Contrasts among SVO
and OVS conditions revealed that participants were slower
in responding to pictures that depicted the agent on the right
compared to left in the SVO condition (6.07; p = 0.0001).
However, in the OVS condition, people were faster when
the agent was presented on the right compared to left (t = 6.24; p = 0.0001). That is, participants were faster in
rejecting a mismatched-in-meaning pair when characters’
position in the sentence and characters’ position in the
picture matched (Figure 2).
2900
2800
2700
2600
2500
2400
2300

OVS

SVO

left

right

Figure 2: Agents’ position and word order interaction in
reaction times in mismatched-in-meaning pairs.

Discussion
The interaction between spatial and linguistic
representations was investigated in a sentence-picture

2014

verification task. Stimuli were manipulated in order to
explore the role of word order in spatial representation of
agency in a language with flexibility in word order. Our
experimental manipulation allowed us to disentangle
sentence structure and thematic role, in that agents could
appear in one of two positions in the sentence. We found
that when word order matched agents’ position latencies
dropped. This effect was not only observed in matched-inmeaning pairs, i.e. pairs in which both structure and
thematic role represented the depicted action, but also, in
mismatched-in-meaning pairs, i.e. pairs that only matched in
sentence structure independently of thematic role.
However, a robust finding in literature, that processing of
spatial representations is influenced by the directionality of
the reading and writing system, was not obtained in this
study. Since Greek is a left-to-right language we expected
that participants would be faster in responding to pictures
representing the agent on the left. In our study, participants
were faster responding to pictures presenting the agent on
the left only when the paired sentence was presented in
SVO structure. In the other conditions, left agency did not
facilitate participants’ responses. We suggest that this
seemingly contradictory result could be explained by the
interaction between agents’ spatial position and word order.
Specifically, we suggest that when the agent was
presented on the left it was consistent with the left-to-right
bias. This led to the formation of a strong expectation about
the upcoming sentence structure (i.e. SVO). When this
expectation was violated (i.e. OVS), reaction times became
longer. In contrast, when the expectation was fulfilled,
processing was significantly faster and reaction times
dropped. However, when the agent was presented on the
right side, no strong expectations were formed because the
two effects (agent’s position and left-to-right bias) partly
canceled each other out. Therefore, the differences in
latency between SVO and OVS structures should be much
smaller in this case. Moreover, since SVOs are more
frequent (and therefore easier to process), the mismatching
between the agent’s position and the sentence structure,
should affect to a greater extent the processing of the less
frequent OVS structures. Indeed, our results are in
accordance with this prediction. In sum, the seeming
absence of a left-to-right effect may be due to the violation
of a strong left expectation.
Our explanation seems compatible with recent theories of
prediction in cognition (Clark, 2012) and in sentence
processing (Kamide, Altmann, & Haywood, 2003; Dikker &
Indefrey, 2007; Altman & Mirkovic, 2009; Farmer, Brown,
& Tanenhaus, in press). Specifically, a way of explaining
the rapid nature of language comprehension stems from the
idea of prediction. Comprehenders exploit all available
information, integrate contextual constraints rapidly and
generate predictions about upcoming stimuli. In our study,
stimuli pairs were presented simultaneously. However,
auditory stimuli are inherently more dynamic than visual
stimuli. Sentences take longer to be presented and thus are
processed later than a static picture. Therefore, we assume

that participants had the opportunity to process the picture
longer and faster than the sentence, arguably allowing them
to formulate predictions about the sentence structure. To test
for this hypothesis, a future experimental manipulation
could involve pictures and sentences presented not
simultaneously but in different time points so that
expectations about upcoming stimuli could be enhanced.
For example, a sentence presented first in SVO structure
may formulate the expectation of left agency, whereas an
OVS structure may formulate the reverse expectation. If this
turns out to be correct, then language may impose strong
constraints and guide the way we conceptualize spatially
thematic roles.
To conclude, we found that sentence processing not only
reflects generic language characteristics, such the
directionality of the writing system, but is also sensitive to
frequency-driven effects, such as the occurrence rate of
specific syntactic structures (i.e. SVO versus OVS). In
addition, online language processing seems to be affected by
non-linguistic information, which is in line with other
findings (Tanenhaus, Spivey-Knowlton, Eberhard, &
Sedivy, 1995). Crucially, our findings are consistent with
the left-bias account according to which language-specific
factors may constrain and affect our conceptual
representations. In sum, our findings suggest that different
sources of information (both linguistic and non-linguistic)
are interactively used in forming expectations about
upcoming material.

Acknowledgments
We would like to thank Silvia Gennari (University of York)
for providing the visual stimuli. We also thank Efthymia
Kapnoula for useful comments on earlier versions of the
manuscript.

References
Altmann, G.T.M. & Mirkovic, J. (2009). Incrementality and
prediction in human sentence processing. Cognitive
Science, 33(4), 583-609.
Barrett, A.M., & Craver-Lemley, C.E. (2008). Is it what you
see, or how you say it? Spatial bias in young and aged
subjects. Journal of the International Neuropsychological
Society, 14(4), 562–570.doi:10.1017/s1355617708080764
Bates, D., Maechler, M., & Bolker, B. (2012). lme4: Linear
mixed-effects models using S4 classes. Available from
http://CRAN.R-project.org/package=lme4 (R package
version 0.999999-0).
Caplan, D., & Futter, C. 1986. Assignment of thematic roles
to nouns in sentence comprehension by an agrammatic
aphasic patient. Brain and Language, 27(1), 117–134.
Caramazza, A., & Miceli, G. (1991). Selective impairment
of thematic role assignment in sentence processing. Brain
and Language, 41(3), 402–436.
Chatterjee, A. (2001). Language and space: some
interactions. Trends in Cognitive Science, 5, 55–61.

2015

Chatterjee, Α., (2008). The neural organization of spatial
thought and language. Seminars in Speech and Language,
29, 226–38 .
Chatterjee, A., Maher, L.M., Gonzales-Rothi, L.J., &
Heilman, K.M. (1995). Asyntactic thematic role
assignment: The use of a temporal-spatial strategy. Brain
and Language, 49, 125–139.
Chatterjee, A., Southwood, M.H., & Basilico, D. (1999).
Verbs,
events
and
spatial
representations.
Neuropsychologia, 37, 395–402.
Chan, T.T. & Bergen, B. (2005). Writing Direction
Influences Spatial Cognition. In Proceedings of the
Twenty-Seventh Annual Conference of the Cognitive
Science Society, 412–417 .
Clark, A. (2012). Whatever next? Predictive brains, situated
agents, and the future of cognitive science. Behavioral
and Brain Sciences (in press).
Dikker, S. & Indefrey, P. (2007). Fine-graining structure
prediction in sentence processing: How language mixing
reveals an economic parser. 20th Annual CUNY
Conference on Human Sentence Processing, La Jolla, CA.
Dobel, C., Diesendruck, G., & Bolte, J. (2007). How writing
system and age influence spatial representations of
actions: A developmental, cross-linguistic study.
Psychological Science, 18(6), 487–491.
Farmer, T.A., Brown, M., & Tanenhaus, M.K. (2012).
Prediction, explanation, and the role of generative models
in language processing. Behavioral and Brain Sciences
(Commentary Article) (in press).
Forster, K., & Forster, J. (2003). DMDX: A Windows
display program with millisecond accuracy. Behavior
Research Methods, 35(1), 116–124.
Geminiani, G., Bisiach, E., Berti, A., & Rusconi, M.L.
(1995). Analogical representation and language structure.
Neuropsychologia, 33, 1565–1574.
Gennari, S.P., Mirkovic, J., MacDonald, M.C. (2012)
Animacy and competition in relative clause production: a
cross-linguistic investigation, Cognitive Psychology, 65,
141-176.
Hayward, W.G., & Tarr, M.J. (1995). Spatial language and
spatial representation. Cognition, 55, 39–84 .
Jackendoff, R. (1996). The architecture of the linguisticspatial interface. In P. Bloom, M.A. Peterson, L. Nadel, &
M. F. Garrett (Eds.), Language and space, Cambridge,
MA: MIT Press.
Kamide, Y, Altmann, G.T.M, Haywood S. L. (2003). The
time-course of prediction in incremental sentence
processing: Evidence from anticipatory eye movements.
Journal of Memory and Language, 49, 133–159.
Levinson, S.C. (2003). Space in language and cognition:
Explorations in cognitive diversity. Cambridge:
Cambridge University Press.
Maas, A. & Russo, A. (2003). Directional bias in the mental
representation of spatial events: nature or culture?
Psychological Science, 14(4), 296–301.

Papafragou, A., Hulbert, J., & Trueswell, J. (2008). Does
language guide event perception? Evidence from eye
movements. Cognition, 108, 155–184.
R Core Team. (2012). R: A language and environment for
statistical computing. R Foundation for Statistical
Computing,
Vienna,
Austria.
Available
from
http://www.R-project.org/ (ISBN 3-900051-07-0).
Tanenhaus, M.K., Spivey-Knowlton, M.J., Eberhard, K.M.,
& Sedivy, J.E. (1995). Integration of visual and linguistic
information in spoken language comprehension. Science,
268, 632–634.

2016

