UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Importance of Nouns in Text Processing
Permalink
https://escholarship.org/uc/item/4sj6j35s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Stuart, Lauren M.
Taylor, Julia M.
Raskin, Victor
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                The Importance of Nouns in Text Processing
       Lauren M. Stuart, Julia M. Taylor, and Victor Raskin ({lstuart, jtaylor1, vraskin}@purdue.edu)
                                                  Purdue University, 656 Oval Drive
                                                West Lafayette, IN 47907-2086 USA
                            Abstract                                 of language processing. We wish to explore how a bias in
                                                                     one of these stages, and its correction, affects processing in
  In the area of computational processing of natural language
  texts, advances toward simpler yet more accurate models of         another.
  meaning are desirable. As syntax is a major component of
  semantic analysis, we explore how a long-term institutional                          Sentence Processing
  bias towards the verb as the main determiner of syntactic (and
                                                                     As a sentence is analyzed, much importance is given to the
  semantic) structure may underserve some kinds of
  information. We introduce an analysis paradigm that restores       verb(s): modal verbs modify the main verb; noun phrases
  the noun to some importance in syntactic analysis. A noun-         participate as subjects or objects; any noun phrase not
  driven syntax representation has been developed and                directly related to the verb may be a complement of a
  evaluated, and implications of its use in further processing       preposition, which is itself associated with the verb or a
  and in better modeling of natural language meaning are             noun phrase, or of some other clause or phrase whose
  investigated.                                                      meaning props up the meaning of the verb (the event said to
   Keywords: Linguistics, Language Understanding, Human-             be encoded in this particular sentence) and whose place or
   Computer Interaction, Representation, Syntax, Semantics           expression in the syntactic structure of the sentence is as
                                                                     much (or more) dictated by the verb as the head of the
                        Introduction                                 phrase. Nouns generally remain building blocks of
Text interpretation by computers is highly desirable and             arguments to be fed into a verb.
arguably necessary as we continue to produce and analyze
text. One major benefit to the improvement of natural
language understanding (NLU) for text is more intuitive
natural interaction with highly structured or, conversely,
loosely associated, large stores of information.
  Text processing may proceed sequentially, on the
assumption that only full (or major) analysis of the surface-
ward structure yields the next deepest structure, where
deepest structure is some formulation of the text’s meaning,
possibly applicable to other meanings of other texts, and the
surface structure is the written or spoken input for a
computer. This linear process encourages the development
of incremental processing modules; that is, given some
intermediate representation of something going on in the
text, the module will produce a further refined model                  Figure 1: Representation of a phrase structure parse from
according to its internal rules and heuristics. For an                                      Berkeley Parser
example, take a phonetic processor that processes speech
data and outputs a series of symbols for use in phonological
and morphological analysis.
  The process does not have to be linear; an alternative
approach may parallelize the different analyses to some
degree, even to the maximum possible (for instance, we
cannot process any syntactic data if it has not yet been
furnished). In this approach, iterations of processing may
“clear up” a map of the sentence’s interpretation (meaning)               Figure 2: Representation of a dependency parse from
incrementally. Easy or simple rule applications start the                             Stanford Typed Dependencies
process and such selections provide feedback for further
selections in those areas of the map that are not yet clear, for       In syntactic representations, this privileging of the verb is
some threshold of “clear” that is dependent upon the form            typically expressed as a shorter distance between the root of
and eventual use of the data.                                        the tree and the main verb; some representations go so far as
  Linear or not, any processing of a text from its surface           to shorten the paths to the other verbs in the sentence. See
form to some model of its meaning relies on various stages           Figure 1 for a constituency tree representation, and note the
                                                                     comparative height of the verb and its nouns. Then see
                                                                 1390

Figure 2 for a dependency tree, noting how the removal of              which the verb is no help, or possibly even absent. Take a
some phrase structure also removes some steps to access                copular sentence: The Curiosity is the Mars rover. While the
any particular word, but verbs are still comparatively close           existential senses of is are large and have many
to the root and can be accessed from one another. This                 implications, they are only manageable when knocked down
reveals an intuition that a sentence is primarily “about” its          to the scope of is the Mars rover. In practice, the verb in this
verb and that composition of multiple sentences is “about”             sentence is demoted to purely technical predicate status and
lining up the verbs together.                                          the predicative nominal elevated in its place. Now we are to
   In the process of computational understanding of natural            analyze a noun phrase as a predicate; there is plenty of
language, a computer may be given a syntax tree from                   precedent, as we can talk about noun-expressed events
which to construct a meaningful model of the events and                taking arguments structured similarly to those their verb-
objects that the sentence describes (with “meaningful”, here,          expressed counterparts accept. Compare We celebrated the
determined by the eventual use to which the model will be              launch today with The celebration of the launch was today.
put: are we looking for frequencies of events? a                          However, the question must be asked: why is our analysis
reconstruction of the actions of one particular object?                so verb-centered, and to such a degree that we must
similarities in locations, origins, or attributes of events or         postulate verbs, i.e., essentially to create dummy verbs,
objects?). Then, to maintain the appropriate interpretation of         where there are none?
meaningfulness, the distance of a particular word or word
category from the root of the sentence must correlate to its                    Towards a Noun-Driven Paradigm
need, or incorporation, in the construction of this model.             We propose an alternative, perhaps complementary analysis
Given syntax trees that are verb-centered, it is most efficient        paradigm: center the noun. Such a paradigm might include
to construct verb-centered semantic representations.                   analysis of concepts as informational objects – for events to
Processing may not need to be sequential (as in,                       be frames – and events as actions somehow intrinsic or
phonological then morphological then syntactic then                    controlled by the objects they involve. This paradigm may
semantic), but we will leave that possibility alone for right          open up a world of gains in processing different flavors of
now.                                                                   information sources, particularly those that have been
   A mapping may be observed between simple sentences                  traditionally managed by computers, with different degrees
and logical expressions in first-order predicate logic: The            of naturalness in the language used to interact with them. A
images show a landscape can be formulated as a function                noun-driven paradigm may then boost ease of interaction
show() with the arguments images and landscape. The                    with these sources via natural language understanding by
proposition show(images, landscape) is held to be                      simply not introducing an unneeded event structure for
equivalent to the sentence – that is, if it is tested for a binary     analysis.
truth value, it evaluates to “true” in all the situations in              To this effect, we have proposed a noun-driven syntax
which the sentence from which it comes would be                        representation (Stuart, 2012). It inherits from the class of
considered true. More complex statements can be generated              dependency grammars by formulating syntax rules as
using such rules as well, e.g., show(images, landscape) &              directed binary relationships between nodes. For instance, a
is_on(landscape, Mars). By mapping natural language                    preposition may be eliminated entirely and encoded in the
sentences to this restricted logical form, we arrive at a sort         syntactic tree as a directed relation, carrying the meaning of
of semantic notation that is easier, somehow, for a computer           the preposition, between the elements it used to connect. For
to use. Its close resemblance to the syntax of many                    an example, see Figure 3.
programming languages suggests that, if only we can
translate all sentences into such expressions, we can execute
the program obtained by concatenation (in accordance with
rules for coordination, negation, etc.) of these expressions
and thereby arrive at some truth value for the sentences
taken together. We may not just want an answer (true or
false) but a model of the meaning in the text; tweaking the
execution of these formulae may allow us to build that
model.
   However, first-order predicate logic is not entirely
adequate. Luuk (2009) extends the mapping to a less strict
system and theorizes about the possible evolution of
argument-like concepts (nouns) before predicate-like
concepts (verbs, among others).                                              Figure 3: Prepositional collapse in Stanford Typed
   Still, all of this analysis is predicated on the idea that the                           Dependencies Output
verb (or the event it describes) is the central element of
analysis, from which all other considerations flow.                       There may be tradeoffs between dependency grammars
However, there are some natural and regular instances in               and constituency grammars – Nivre (2006) considered the
                                                                       tradeoffs favorable – but some may be more important in
                                                                   1391

the noun-driven paradigm (for instance: should it perhaps be       the sentence which are simplest to compute or represent
the noun-phrase-driven paradigm?) and only further                 drive the interpretation of the rest of the sentence.
investigation will reveal these.                                      As in many syntactic analysis algorithms, “steps” of
   A noun-driven representation has been developed, starting       processing can be reverted (or previous states saved) to
in Stuart, et al. (2012a) and Stuart, et al. (2012b). The          enable backtracking or the output of multiple best
structure links all nouns from the root, so a parallelized         candidates if appropriate. The processing shown in Figures
meaning-scaffolding program may have several starting              4 and 5 presupposes object-oriented semantic-processing
points and begin to converge upon an intermediate structure        modeling. For those systems with event-oriented semantic
(towards a model of meaning) as it traverses the nodes held        processing, verb-driven syntactic approaches (linear or
in common between noun-rooted subsets. The                         parallel) are just as useful.
corresponding parallelization applied to verb-driven
dependency grammar representations does not result in the
same gains: there are typically two noun phrases to every
verb phrase in English (Baker, 2005). The number of nouns
relative to verbs only gets larger when we consider noun
chains (“crater rim”—see also Taylor et al 2010, 2012) and
prepositional phrases (the objects of which are always noun
phrases).
                                                                     Figure 4: Processing steps when “show” tagged as a verb
   The number of prepositional phrases also contributes to
the complexity of syntactic analysis. Some prepositional
phrases have ambiguity in attachment; some may attach
somewhere in syntactic analysis but be restricted from that
attachment during more meaning-directed evaluation.
Consider The images show a landscape on Mars vs. The
images show a landscape of Mars. In the first, on may
attach to both show (the event of showing could occur on
Mars) and to landscape (the landscape is specifically one on       Figure 5: Processing steps when “show” tagged as a noun
Mars). In the second, of may only attach to landscape, but
can sometimes attach to other verbs (as a particle, for               Regardless of whether the semantic modeling used in
instance, in to think of), so the evaluation of the attachment     process is object-oriented, event-oriented, or some hybrid,
as valid may take several steps of analysis. Multiple              we find it prudent to also consider the possible object- or
prepositions can also attach to the same elements; as they all     event-biased information sources. Suppose we have an
will have noun-phrase objects, the centering of the noun           encyclopedia article about the geographical features of
phrase in analysis hikes the prepositional phrase up in the        Mars. While many sentences will perhaps explain the dates
hierarchy of importance as well.                                   and methods of discovery of certain facts about Mars and its
                                                                   geography, we can expect a large amount of discussion on
Implications for Semantic Processing                               the features themselves, their attributes, positions, and the
   The “object-oriented” nature of noun-driven syntax may          larger classes to which they belong. In the example sentence
also align sufficiently well with object-oriented semantic         A peak sits to the south of the crater rim, we receive
languages to collaborate easily in parallelized processing,        information that there is some peak (perhaps in a larger
allowing groups of objects at certain “stages” to be swapped       range of mountains) somewhere south of a crater that has
out with “higher-stage” interpretations or representations of      been (we hope) previously introduced. This is position
them.                                                              information; the verb is sit but if it were for some reason left
   Take the sentence introduced before: “The images show a         out of the sentence or replaced with is, is located, or is
landscape” and its partial processing, as shown in Figures 2       situated, we would still get the gist.
and 3. In the latter, “show” has been tagged as a noun rather         Consider, then, a general article about geography, the
than a verb. Possibly these are candidates with the highest        content of which an NLU system will have to make use of
confidence due to internal simplicity, some rules about            in order to understand the instantiations (in the Mars
sentence formation, the topic of the information, or from          geography article) of types and classes described in the
previously-mentioned information: “the images” likely              general article. We can expect some events here: various
refers to some set of images that have already been                geographers may have contributed to the development of
introduced. In a pass that has produced some semantic or           some concepts. However, we argue that the most useful part
intermediate representations for parts of the map——the             of the article (again, for understanding something about the
intermediate conclusions made in the other parts of the            features of Mars) is that part which defines the types,
sentence contribute to analysis of the other parts.                attributes, and relative locations of geographical features.
Analogously, in a greedy meaning algorithm, the subsets of         This area of the article is likely to be strongly noun-
                                                                   centered: positions, lists of items, and weak verbs may
                                                               1392

dominate. (A volcanic crater is a circular depression in the        prepositional phrase. Verb-centered processing (purely
ground.) This is not to say that the verb-driven paradigm is        syntactic or as a step towards semantic processing)
useless in a very noun-dominated information space.                 prioritizes “show”; it stands in for a fuller explanation that
However, a verb-driven syntactic analysis may waste some            investigating scientists learned about the reversals by
resources by trying to identify and promote predicates. As          reviewing data from the surveys, and thus does have some
well, a verb-driven semantic analysis may find that most of         importance (for instance in auditing the assertion “Many
its “events” are existential and not temporally-bounded             magnetic reversals have occurred”, as one question could be
instances of some action.                                           “How do we know that?”). In an article about the scientific
   Now consider some more rigidly-defined information               process, its many forms, and its contribution to knowledge,
spaces. The most rigid might be the company relational              this is a salient detail. However, in reading an article about
database, which strictly encodes lists of relationships             the geomagnetic history of the earth, we may be much more
between objects – Li et al. (2008) developed an engineering         interested in the apparent occurrence of magnetic reversals,
ontology and lexicon for processing natural language search         and the source of the data analyzed in order to reach that
queries, in a supply chain application, to just such a              conclusion.
database, which also included information in unstructured
(that is, natural language) descriptive documents. The user         Experimental Evaluation
queries (and therefore the ontology) emphasize parts’                 Stuart et al. (2012b) began evaluating the performance of
shapes, materials, purposes, and origins. Such domains are          the noun-driven syntax in a small query context: assuming
fundamentally concerned with objects and how they are               that most queries to syntax trees take the form of traversing
related to each other. The “translation” from machine-              the tree to or from a certain node or a node of a certain
readable language to natural language must rely heavily on          category, the node’s depth is used as a rough measure of
nouns, adjectives, quantities, and the relationships and            accessibility for further analysis. The initial experiment was
attributes of semantic concepts representing “things” rather        carried out by hand and in comparison with outputs from
than “happenings”. The basic semantic structure of the              Stanford Dependencies, Stanford PCFG, and Berkeley
information is already there: the database schema gives us          parsers. The dataset consisted of only 30 sentences; the
relations by which to connect the objects (event instances,         noun-driven syntax representation performed at least as
object-parts, etc.) that are its subject.                           well, or better, than the dependency grammar trees, and both
   Take now, for example, a computer program written in             much better than the phrase-structure trees. As well, the
some programming language. Improvement of NLU also                  dependency and noun-driven trees were evaluated from a
underwrites the improvement of translation between natural          parallelized perspective.
language and programming languages (for instance, in                  A larger experiment used 600 sentences, chosen from six
specifying and evaluating privacy constraints, as in Brodie         different articles, each of which fell under one of three
et al. (2006)). The language itself does not need to be             categories. The categories – “noun-heavy”, “verb-heavy”,
conceived of as object-oriented (Java, C++) because a               and “neither” – attempted to capture a meaning-motivated
reductive view of a computer program is that of an                  difference in syntax between information sources, as well as
informational object which takes informational objects as           to test intra-category variance to a degree. The performance
inputs and gives more information objects as outputs. The           of the noun-driven syntax was compared to that of a
transformations that these input objects undergo are events,        developed hybrid phrase structure representation – the latter
the transformations may be affected partially or wholly by          considerably “flattened” phrase structures. Direct
some qualities of the objects to which they are applied. This       comparison with a dependency parser’s output could not be
is a strength of inheritance and polymorphism in those              obtained for this larger experiment due to technical
object-oriented languages: one prototypical “event” can be          difficulties, but it is planned for the future.
expressed in terms of the classes of objects to which it is           The noun-driven representation was generated by a
applied, and many events are specific, intrinsic, and unique        phrase-structure parser integrated with Ontological
to a (class of) informational object (data structure). Thus,        Semantics Technology (OST), a natural language
“translation” of the event relies ultimately upon the objects       understanding framework under current development
involved; that is, Object.do() is specified at least in part by     (Taylor et al., 2012). The parser used a partial lexicon – a
the implementation of the class Object. Even in a language          set of word entries with associated syntactic information,
that is not specifically object-oriented, the specific actions      intended eventually to include semantic, morphological, and
undertaken in the execution of the method process(thing)            phonological information useful for word sense
depend on the content or nature of the object thing.                disambiguation and construction of semantic meaning
   Finally, consider the sentence “Airborne geomagnetic             representations. The parser used a modified chart-parsing
surveys showed a strange pattern of symmetrical magnetic            algorithm, similar to that presented in Allen (1987) but
reversals on opposite sides.” Our main verb here is “show”,         organized around heads of phrases rather than building
but the important events (the act of surveying, and the             phrase structure from left to right. The parser generated
occurrence of magnetic reversal) appear in noun form, and           parses in phrase-structure representations then converted
some important attributes appear as adjectives and a                those to noun-driven trees. An example representation of the
                                                                1393

output appears below in Figure 6; compare with Figures 1           distinction arises from a difference between transforming a
and 2.                                                             string of grammar symbols into all possible syntactically
                                                                   correct parses of the symbols, regardless of their content,
                                                                   and obtaining the correct parse, as the syntax parser has no
                                                                   ability to determine which of the correct strings of symbols
                                                                   is actually completely grammatically correct. This is a result
                                                                   of an inexpressive tag set and a lack of semantic parsing
                                                                   integration. For the 64-set, in 6 cases were the correct parses
Figure 6: Representation of a noun-driven dependency parse         not included in the output; this was due to a lexicon gap,
                                                                   verb particles not correctly accounted for, or an oversight in
  A testing program counted the depths for each word in the        vetting the data set for conformance to the limited grammar
word categories of interest (determiner, noun, verb, adverb,       template that the parser was designed.
preposition, adjective). One metric for appropriateness of            For the 600 sentences, some measures were taken of
the categories is in measuring the ratio of nouns to verbs;        possible syntactic ambiguity: if for one sentence the parser
this data is shown in Table 1. A “fingerprint” for each of the     turned out more than one parse and could be counted on
subcategories (counts by word class) appears in Figure 4;          (according to an interpretation of the outcome of the 64-set
note some similarity within each of the categories.                results, which is not entirely dependable) to be correct, if
However, these findings are complicated by unknown                 enthusiastic, in its determination of good syntactic parses,
effects of style (the two “noun-heavy” articles were from          then the sentence was determined to carry syntactic
Wikipedia, the two “neither” articles from the New York            ambiguity. Of the 600, 241 sentences were given only 1
Times website, and the last two from Safety.gov and a              parse; an equal number had 2. 16 sentences had 10 or more
recipe book, respectively), though there may be an                 different parses turned out; some of these were due to
association between style and subject matter that does             prepositional phrase attachment ambiguity, and some to
uphold the categorization. As well, these results do not           possibilities that, for instance, the form of a verb in the 3rd
distinguish between parses with differing levels of                person-present-singular is identical to that of a plural noun,
correctness or acceptability; work in progress does mark           or vice versa.
parses on a spectrum from non-grammaticality to candidacy
as the parse most compatible (with some semantic                                  Table 2: Depth Counts for Nouns
processing) with the rest of the article.
                                                                                       Noun-Driven              Phrase-Structure
                                                                      Group         Average     Min    Max   Average    Min     Max
                                                                      All              1          1      1      3.38        2      9
                                                                   Neutral 1           1          1      1      3.29        2      9
                                                                   Neutral 2           1          1      1      3.34        2      8
                                                                   Noun-heavy 1        1          1      1      3.48        2      9
                                                                   Noun-heavy 2        1          1      1      3.66        2      9
                                                                   Verb-heavy 1        1          1      1      3.27        2      8
                                                                   Verb-heavy 2        1          1      1      2.98        2      7
                                                                                  Table 3: Depth Counts for Verbs
    Figure 7: Word class counts per parse, by subcategory                              Noun-Driven            Phrase-Structure
                                                                      Group         Average    Min    Max   Average    Min    Max
                  Table 1: Noun/Verb Ratios
                                                                      All              2         2      2     2           2      2
       Sentence subcategory(article subject)        N/V
       Neutral 1 (Mars Rover)                       3.82           Neutral 1           2         2      2     2           2      2
       Neutral 2 (2012 Election)                    3.65           Neutral 2           2         2      2     2           2      2
       Noun-heavy 1 (Plate Tectonics)               4.82           Noun-heavy 1        2         2      2     2           2      2
       Noun-heavy 2 (Mathematics professions)       5.23
       Verb-heavy 1 (Safety Tips)                   3.59           Noun-heavy 2        2         2      2     2           2      2
       Verb-heavy 2 (Recipes)                       4.56           Verb-heavy 1        2         2      2     2           2      2
                                                                   Verb-heavy 2        2         2      2     2           2      2
  A sample of 64 sentences, randomly selected from the
600, was tested for parser correctness and accuracy – the
                                                               1394

                                                                                          References
            Table 4: Depth Counts for Prepositions
                                                                   Allen, James. 1987. Natural language understanding (2nd
                   Noun-Driven            Phrase-Structure           edn).Addison-Wesley.
   Group        Average   Min    Max    Average   Min     Max      Baker, Mark. 2005. "Lexical Categories: Verbs, Nouns, and
                                                                     Adjectives." Cambridge: Cambridge University Press.
   All             2.38     2      3      3.60       2     8
                                                                   Brodie, C. A., Karat, C., & Karat, J. (2006). An empirical
Neutral 1          2.40     2      3      3.58       2     8         study of natural language parsing of privacy policy rules
Neutral 2          2.47     2      3      3.68       2     7         using the SPARCLE policy workbench. SOUPS '06
                                                                     Proceedings of the second symposium on Usable privacy
Noun-heavy 1       2.34     2      3      3.69       2     8
                                                                     and security, 1.
Noun-heavy 2       2.33     2      3      3.59       2     8       Klein, Dan and Christopher D. Manning. 2003. Accurate
Verb-heavy 1       2.56     2      3      3.64       2     7         Unlexicalized Parsing. Proceedings of the 41st Meeting of
Verb-heavy 2       2.32     2      3      3.26       2     6
                                                                     the Association for Computational Linguistics 423-430.
                                                                   Luuk, Erkki. 2009. The noun/verb and predicate/argument
   Tables 2 and 3 show results for depth counts between the          structures. Lingua 119 (2009): 1707–1727.
two syntax representations evaluated, over the 600-sentence        de Marneffe, Marie-Catherine and Christopher D. Manning.
set, for the two main categories, noun and verb. We include          2008. The Stanford typed dependencies representation. In
the depth counts for prepositions as well (Table 4) because          Proceedings of the workshop on Cross-Framework and
of the complexity that prepositional phrases add to syntactic        Cross-Domain Parser Evaluation 1-8. Manchester, UK.
structure.                                                         de Marneffe, Marie-Catherine, Bill MacCartney, and
   Examination of these tables reveals that, even when             Christopher D. Manning. 2006. Generating Typed
compared with a “flatter” (verb-driven) phrase structure           Dependency Parses from Phrase Structure Parses. 5th
syntax representation, the noun-driven representation does         International Conference on Language Resources and
at least as well, if not better. Notice as well that in the        Evaluation (LREC 2006) 449-454.
phrase-structure trees, nouns have a wider range of “float”        Li, Zhanjun, Victor Raskin, and Karthik Ramani. 2008.
because, while a single noun may be the subject and thus be          Developing Engineering Ontology for Information
found in a shallower position, prepositional phrases and             Retrieval. Journal of Computing and Information Science
noun-chaining bury nouns further.                                    in Engineering 8(1):011003-13.
   Preliminary results from further evaluation also reveal         Nivre, J. 2005. Dependency Grammar and Dependency
data that may be usable for characteristic profiles of               Parsing. MSI report 05133. Växjö University: School of
prepositional attachment. As well, we may investigate                Mathematics and Systems Engineering, Växjö, Sweden
whether the addition of some phrase structure features to the      Raskin, V. 1983. A Concise History of Linguistic Semantics
dependency-like representation would provide better                  Pt 1. Department of English and Program in Linguistics,
information for prepositional attachment and other local             Purdue University, West Lafayette, IN.
operations influenced by concepts or structure use.                Stuart, Lauren M. 2012. Computational Evaluation of a
                                                                     Noun-Driven Syntax Representation. Unpublished
                                                                     Master’s Thesis, Linguistics Program, Purdue University,
                        Conclusion
                                                                     West Lafayette, IN.
If computational processing of information is (even                Stuart, Lauren M., Julia M. Taylor, and Victor Raskin.
sometimes) object-centered, then an object-centered                  2012a. Towards Noun-Driven Parsing. In Proceedings of
approach aligns with it. Given that we have started at the           2012 IEEE International Conference on Systems, Man,
syntax level, and that most objects (as well as some events)         and Cybernetics (SMC) 1984-1989. Seoul, South Korea.
are typically expressed as nouns, the noun-driven syntax           Stuart, Lauren M., Julia Taylor, and Victor Raskin 2012b.
representation, and an eventual development of a parsing             “Noun-Driven Syntactic Parsing for Natural Language
approach, begins the building of a noun/object-centered              Interfaces to Object-Centered Information Stores.” In
paradigm for the analysis of natural language text.                  Proceedings of Society for Design and Process Science
   There are information spaces that are not so noun-biased,         Conference (SDPS). Berlin, Germany.
or even further verb-biased – with the full field of verb-         Taylor, Julia M., Victor Raskin, Christian F. Hempelmann,
driven syntactic and semantic analysis, these will not be left       and Max S. Petrenko 2010. “Multiple Noun Expression
behind. A dual analysis, using both perspectives, may                Analysis: An Implementation of Ontological Semantic
produce some gains in efficiency and effectiveness.                  Technology, Computational Linguistics – Applications
                                                                     Workshop, Wisla, Poland.
                    Acknowledgments                                Taylor, Julia M., Victor Raskin, and Lauren M. Stuart
This research has been supported in part by the National             (2012). Machine Human Understanding: Syntax and
Science Foundation CISE/TC Research Grant #1012208.                  Semantics Revisited. IEEE-SMC Conference Seoul, S.
                                                                     Korea.
                                                               1395

