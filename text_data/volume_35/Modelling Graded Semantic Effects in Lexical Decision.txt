UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modelling Graded Semantic Effects in Lexical Decision
Permalink
https://escholarship.org/uc/item/2rh366s1
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Chang, Ya-Ning
Ralph, Matthew Lambon
Furber, Steve
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Modelling Graded Semantic Effects in Lexical Decision
                                     Ya-Ning Chang (ya-ning.chang@manchester.ac.uk)
                           Neuroscience and Aphasia Research Unit (NARU), University of Manchester,
                                             Brunswick Street, Manchester, M13 9PL, UK
                            Matthew Lambon Ralph (matt.lambon-ralph@manchester.ac.uk)
                           Neuroscience and Aphasia Research Unit (NARU), University of Manchester,
                                             Brunswick Street, Manchester, M13 9PL, UK
                                        Steve Furber (steve.furber@manchester.ac.uk)
        Advanced Processor Technologies Group, University of Manchester, Oxford Road, Manchester, M13 9PL, UK
                                Stephen Welbourne (stephen.welbourne@manchester.ac.uk)
                           Neuroscience and Aphasia Research Unit (NARU), University of Manchester,
                                             Brunswick Street, Manchester, M13 9PL, UK
                              Abstract                                  be able to exploit semantic information to support efficient
                                                                        LD. Although some subsequent studies have found reliable
  Recent studies have shown that the involvement of semantic
  information in visual lexical decision depends on the nature of       semantic influences on lexical decision under different foil
  nonword foils with semantic effects increased as nonwords             conditions (Joordens & Becker, 1997), others have failed to
  become more word-like (Evans, Lambon Ralph &Woollams,                 find such effect (Lupker & Pexman, 2010). Evans, Lambon
  2012). Given that most models of lexical decision focus on            Ralph and Woollams (2012) demonstrated that semantic
  orthographic information (Coltheart, Rastle, Perry, Langdon           involvement in lexical decision was graded by the difficulty
  & Ziegler, 2001; Grainger & Jacobs, 1996; Seidenberg &                of the decision task as indexed by the word-likeness of the
  McClelland, 1989), the role of semantics and its interactions
  with vision, orthography, and phonology has been
                                                                        foil. There were stronger semantic effects with
  overlooked. We developed a recurrent connectionist model of           pseudohomophones than with pseudowords, and the effects
  single word reading including visual, orthographic,                   were stronger with pseudowords than with consonant
  phonological, and semantic processing. The model                      strings. Apart from the behavioural data, there is also
  differentiated words from nonwords by integrating measures            evidence of semantic involvement in lexical decision from
  of polarity across four key processing layers. The contribution       neuroimaging studies. Woollams, Silani, Okada, Patterson
  of semantics depended on the type of nonword foils. The               and Price (2011) revealed that left anterior temporal
  model was more reliant on semantic information when the
  nonword foils were pseudowords and pseudohomophones                   activation, increased for atypical relative to typical strings
  rather than consonant strings. The results support the view           when lexical decisions were made more difficult in the
  that semantic involvement in lexical decision is graded by the        context of pseudohomophone foils. The left anterior
  difficulty of the decision task.                                      temporal lobe has been considered as a region for
   Keywords: semantic effects; lexical decision; reading;               combining various types of sensory and motor information
   computational modelling; visual word recognition.                    to form amodal semantic representations (Patterson, Nestor,
                                                                        & Rogers, 2007). The orthographic typicality effect in the
                          Introduction                                  left anterior temporal lobe has also been found in a previous
                                                                        electrophysiological (EEG) study. In a speeded lexical
Lexical decision (LD) has been widely used to study the
                                                                        decision task, atypical words were found to elicit stronger
cognitive processes involved in visual word recognition.
                                                                        source currents than did typical words at around 160 msec
Subjects are asked to judge whether a letter string is a word
                                                                        in the left anterior temporal lobe (Hauk, Patterson,
or not. Measures of accuracy and response time are thought
                                                                        Woollams, et al., 2006). These effects are consistent with
to reflect the differences in lexical-semantic processing of
                                                                        what has been observed in the neuropsychological studies of
words and nonwords. There seems to be consistent evidence
                                                                        patients with semantic dementia (SD), who have
that vision, orthography and phonology play roles in visual
                                                                        asymmetrically bilateral atrophy degeneration of the
lexical decision (Coltheart, Davelaar, Jonasson, & Besner,
                                                                        anterior temporal lobes. These patients show a progressive
1977; Grainger & Jacobs, 1996; Meyer, Schvanev, &
                                                                        degeneration of semantic knowledge (Hodges, Patterson,
Ruddy, 1974), however the extent of the involvement of
                                                                        Oxbury, & Funnell, 1992). When patients are asked to
semantics in lexical decision remains debateable (James,
                                                                        perform two-alternative forced-choice visual lexical
1975; Joordens & Becker, 1997; Lupker & Pexman, 2010).
                                                                        decision, they can correctly choose orthographically typical
James (1975) showed a reliable concreteness effect during
                                                                        words from the relatively atypical nonwords but have
lexical     decision      when      using     pseudoword        and
                                                                        difficulty in the reverse condition (Rogers, Lambon Ralph,
pseudohomophone foils, while the effect disappeared when
                                                                        Hodges, & Patterson, 2004). Taken together, this evidence
testing with consonant strings. He suggested subjects might
                                                                        supports the view that semantic processing is involved in
                                                                    310

lexical decision in particular when the words are                    learned. Conversely, relatively weaker activations would be
orthographically        atypical    and     the    foils    are      expected for a nonword representation as it is a novel
pseudohomophones.                                                    stimulus. One important model of lexical decision was
                                                                     developed by Plaut in 1997, who proposed that the measure
Models Based on Localist Views                                       of how strongly units were activated, called stress or
In the literature, several theories of visual word recognition       polarity, could be used as a basis for making lexical
have been proposed to explain the underlying mechanisms              decisions. He built a feedforward model which consisted of
of lexical decision (Coltheart, et al., 1977; Coltheart, et al.,     orthographic, phonological and semantic components and
2001; Grainger & Jacobs, 1996; Plaut, 1997; Seidenberg &             demonstrated that words tended to produce higher stress
McClelland, 1989). Some researchers argue that lexical               than nonwords at the semantic layer. With the proper
decision relies upon the orthographic lexicon (Coltheart, et         decision criteria, over 95 percent of words in the training
al., 1977). If there is a match, subjects would give a positive      corpus could be discriminated from nonwords. In addition,
response, otherwise, the negative response is made. On this          the network tended to produce higher semantic stress for
view, the locus of lexical decision is based on activation           pseudohomophones than for pseudowords in line with the
within the orthographic lexicon. The involvement of                  behavioural data.
phonology is a relatively late process after the mental
lexicon search while the semantic system is generally not            Accumulated Information for Lexical Decision
involved in the recognition processes unless the                     There are also other models which have emphasised the use
discrimination becomes extremely difficult (Coltheart, et al.,       of accumulated information within the system for making
2001). This orthographically based approach is shared with           decisions. One of these is the diffusion model, developed by
Grainger and Jacobs (1996), who developed a                          Ratcliff, Gomez and Mckoon (2004). The central idea of the
computational model of lexical decision. In their multiple           diffusion model was that the speed (drift rate) at which
read-out model (MROM), a word response could be made                 information was accumulated over time was affected by the
either when the particular word unit activation reached a            lexical status of the stimuli. They hypothesized that the drift
local criterion, M, or the overall activity in the word layer        rate had a positive correlation with a measure of how word-
reached a global criterion, Σ, before the temporal deadline          like a stimulus was. In their model, the decision was then
as T. The RT was based on the earliest moment where either           made when a random walk process driven by the drift rate
of criteria was met. If neither of the activation criteria was       reached either a word criterion or nonword criterion.
met, a nonword response was given and the RT was the                 Another model is the Bayesian reader model developed by
value of the deadline criterion. Grainger and Jacobs (1996)          Norris (2009). The basic premise of this model was to
assumed that the M criterion should be fixed as a normal             assume subjects would consistently compute the probability
recognition level and was set corresponding to individual            of the stimulus being a word or a nonword on the basis of its
word units. While the global criterion Σ and the temporal            lexical status. In the simulations conducted in Norris (2009),
deadline T would vary according to the lexical frequency             the recognition of a letter string being a word was made on
status of the stimulus. The higher probability the stimulus          the basis of the sum of the probabilities of all possible letter
was a word, the lower global criterion and the longer                strings and this value was expected to be 1.0. Therefore, the
temporal deadline were used. By this, the MROM model                 nonword likelihood could be computed simply by using 1
was able to simulate several standard effects seen in lexical        minus summed probability of letter strings corresponding to
decision including the frequency effects, the orthographic           words.
neighbourhood size effects, and their interactions (Grainger            In summary, data from behavioural, neuroimaging and
and Jacobs, 1996). Other models of visual word recognition           patient studies, all point to the involvement of semantic
such as the dual-route cascaded (DRC) model (Coltheart, et           processing in lexical decision. Previous models either
al., 2001) and the connectionist dual process (CDP+) model           postulate an exclusive role for semantics (Dilkina,
(Perry, Ziegler, & Zorzi, 2007) share similar decision               McClelland, & Plaut, 2010; Plaut, 1997) or no role for
mechanisms to the MROM model.                                        semantics (Coltheart et al. 2001; Grainger & Jacobs, 1996;
                                                                     Norris, 2009). Importantly none of the previous models
Models Based on Distributed Views                                    would be able to account for the data from Evans et al.
An alternative theory of visual word recognition argues that         (2012), which indicates that the degree of semantic
there is no mental lexicon for the store of word knowledge           involvement is flexible and can be modulated by the nature
in the recognition system (Dilkina, McClelland, & Plaut,             of the nonwords foils. The goal of this paper was to use a
2010; Plaut, 1997; Seidenberg & McClelland, 1989). On                novel model of reading to explore to what extent semantics
this view, the decision can be made on the basis of the              is involved in lexical decision and how it interacts with
differential activations elicited by familiar words and              other processing layers. In addition we aimed to be able to
unfamiliar nonwords. When presenting a word, strong                  simulate the data from Evans et al. illustrating how changes
activations are expected because the mappings between the            to the nature of the nonwords foils can bias lexical decision
visual or orthographic representation of the word and its            tasks. Based on earlier work (Chang, Furber, & Welbourne,
phonological and semantic representations have been                  2012a), we developed a fully implemented recurrent model
                                                                 311

of visual word recognition. The model included a visual           was trainable and that the performance of the model was
processing stage along with the orthographic, phonological        good on the production, comprehension and reading tasks.
and semantic processing stages. Importantly, the                     There were also control units for each layer except input
orthographic representations were allowed to learn during         and output layers. These acted to flexibly inhibit the
the training.                                                     activation of the layer they were connected to. The control
                                                                  units were important because they allowed the model learn
                          Method                                  to manage its own temporal dynamics. In particular they
                                                                  allowed the units at the latter layers to be suppressed until
Network Architecture                                              the input to them had had time to ramp up to values that
The architecture of the model is shown in Figure 1. The           reflected the influence of the visual input to the model.
model had two separate pathways for recognising words                The training corpus consisted of 2,971 words. The visual
from visual input: a phonological pathway and a semantic          representations used here were adapted from those used in
pathway. The H0 layer was functionally responsible for            Chang et al.’s (2012a) study. The network was trained on
visual processing while the OH layer was equivalent to the        12-point lower case words in Arial font. Each word was
orthographic layer in the triangle model except that the          positioned with its vowel aligned on a fixed slot of the
orthographic representations were learned through the             image. Ten slots were used in all and the size of each slot
course of training rather than being supplied as inputs. This     was 16x16 pixels. The scheme of phonological
mimics the situation in human development where                   representations was the same as that used in the Plaut et al.’s
orthographic representations emerge to support reading            (1996) model. The context units were used to differentiate
acquisition in children. The word recognition process started     the meanings of homophones, which have same
from the visual input layer and moved progressively to the        pronunciations but different meanings. For those
orthographic layer, and then progressed in separate               pronunciations with only one possible word meaning, the
pathways to the phonological and semantic layers. The             context units were all set to zero. For other pronunciations
phonological component consisted of 61 phonological units         corresponding to more than one word meanings, the context
which were all connected to a set of 20 clean up units. These     units were all set to 0 for the first meaning; and one of the
clean up units projected back onto the phonological units,        context units from right to left was set to 1 to represent the
forming an attractor. Similarly, the semantic component           second, third and fourth meaning accordingly. The semantic
consisted of 200 semantic units. These units were all             representations were generated using the same scheme as in
connected to another set of 80 clean up units, which              Chang, Furber, and Welbourne (2012b). The meaning of
projected back onto the semantic units. The context               each word was represented by a 200-dimensional semantic
component consisted of 3 units, which were used to provide        vector. Each vector had 5 active units in the first half of the
additional contextual information for discriminating              vector converted from the top positive attributes and 15
between homophones. The numbers of hidden units for each          active units in the second half of the vector converted from
layer were determined by pilot trials to ensure the model         the top negative attributes.
                   Figure 1. The architecture of the model. The dashed lines indicate inhibitory connections.
                                                              312

                                                                     as follows:
Training Procedure                                                                       ( ) (         )        (     )
The training was separated into two phases. In phase 1 only         where is the unit activation ranging from 0 to 1;         ( ) is
the phonology-semantics mappings were trained while in              the logarithmic function with the base of 2; is the polarity
phase 2 the full reading model was trained starting from the        measure. When known words are presented, the units tend
trained weights obtained in phase 1. In phase 1, the                to become binary, leading to high polarity values. However,
phonology-semantics model was first subdivided into two             when nonwords are presented, the activities of the units tend
parts: the production model learning the mappings from              to be low and closer to 0.5, resulting in generally low
semantics to phonology and context, and the comprehension           polarities. Two criteria were used for the model to make
model learning the mappings from phonology and context to           word-nonword decisions: (1) word boundary: the 3 standard
semantics. The production and comprehension model were              deviation line above the average nonword polarity; (2)
trained separately. The presentation of each example lasted         nonword boundary: the 3 standard deviation line below the
for 6 intervals of time and each interval of time was divided       average word polarity. The polarity for an item was
into 3 ticks. In each presentation, the input pattern of a word     computed by combining the measures of polarity for that
was clamped onto the input units for the full 6 intervals of        item at the H0 (visual processing), OH (orthographic
time and the task was to produce the correct target                 processing), phonological, and semantic layers. If an item
representation. For the last 2 intervals, the activations of        polarity crossed over the word boundary the item was
output units were compared to their targets. Error score, the       classified as a word. By contrast, if the item polarity crossed
difference between the units’ outputs and their targets, was        over the nonword boundary, the item was determined as a
used to calculate weight changes. No error was recorded if          nonword. There were, however, a few item polarities that
the output unit’s activation and target were within 0.1 of          remained between the two boundaries. In this case,
each other. At the end of phase 1 the accuracy rates of the         responses were made based on which boundary the polarity
production and comprehension model were 99.97% and                  was closest to at the last time tick. The response time was
99.43% for the phonological level and semantic level                the time tick when an item polarity first crossed over either
respectively.                                                       word or nonword boundary. In the situation where neither
   In phase 2, the weights obtained from the end of training        boundary was crossed the response time was taken as 30
the phonology-semantics model were embedded and frozen              ticks.
into the full reading model. The weight connections from
the visual layer to both phonological and semantic layers           Inverse Efficiency
were updated through training. There were local control             To control for potential differences in speed-accuracy trade-
units for each layer except input and output layers. The            off caused by the arbitrary selection of standard deviation
initial output of each control unit was set to 1. The weight        lines, we adopted a measure of inverse efficiency, which is
connections from its previous layer to each control unit were       considered to be a corrected reaction time (Roder,
free to be updated. The weight connections from each                Kusmierek, Spence, & Schicke, 2007). Inverse efficiency is
control unit to those units that it was controlling were            a combination of both reaction and accuracy (i.e., dividing
trainable, but the values were limited to between -4 and 0.         reaction time by accuracy). The lower the score, the more
The negative boundaries used here were to ensure that the           efficiently the model performed the task.
control unit acted to inhibit activation. The model was
allowed to update for 30 ticks of time. The visual
                                                                                               Results
representation of a word was presented at the input units for
all 30 ticks. The task was to produce correct phonological
                                                                    Semantic influences on lexical decision
and semantic patterns. For the last 2 intervals, the output
units were compared with their corresponding phonological           Evans et al. (2012) suggested that the subjects needed to
or semantic targets and errors were computed. To encourage          access semantic information in the lexical decision task
more accurate learning, no error was computed when the              particularly when words were tested with more word-like
output unit’s activation and target were within 0.001.The           nonwords such as pseudowords and pseudohomophones.
model was trained to produce 99.3% correct phonological             They showed a graded imageability effect in lexical
and 97.4% correct semantic patterns in the word reading             decision depending on the difficulty of the task. The
task.                                                               imageability effect was larger when words were tested
                                                                    against with pseudohomophones than with pseudowords.
Polarity Measures and Decision Criteria                             The effect disappeared in the context of consonant strings.
                                                                    We tested the model to see whether it could produce the
Plaut (1997) proposed that parallel distributed models can
                                                                    similar pattern as seen in Evans et al.’s data. After removing
perform the lexical decision task based on the measure of
                                                                    those words which were not in the training exemplars and
polarity, which is whether the units in the model have
                                                                    their matched nonword items, there were 70 words,
learned to adopt a binary representation. To capture this
                                                                    consisting of 35 high- and 35 low-imageability words. Their
phenomenon, Plaut (1997) introduced a formula to compute
                                                                    matched nonword pairs for the three different foil
the index of unit binarization which was termed unit polarity
                                                                    conditions, consonant string (CS), pseudoword (PW), and
                                                                313

pseudohomophone (PH) were also used in the current test.          Importantly, there was a significant interaction between
To compare with Evans et al (2012)’s data, the scores of          imageability and foil condition, F(2, 38)=3.60, p<.05,
inverse efficiency were normalised by the value obtained          showing that the size of imageability effect increased along
from the low imageability pseudohomophone condition.              with the word-likeness of the foils. Note that we also ran the
The same procedure was applied to Evans et al.’s (2012)           statistical tests on the unnormalised scores with the same
data. The results are shown in Figure 2. It is clear that the     pattern of results. This is what would be expected based on
simulation results (Figure 2, left) follow the pattern of         Evans et al.’s (2012) data. The post-hoc analyses showed
Evans et al.’s data (Figure 2, right). A 2x3 repeated             that the imageability effect was not significant with
measures ANOVA was conducted with imageability                    consonant strings (p>.05) while there were significant
(High/Low) and foil condition (CS/PW/PH) as within                imageability effects in the contexts of pseudowords, F(1,
subject factors and the scores of inverse efficiency were         19)=6.76, p<.05, and pseudohomophones, F(1, 19)=15.06,
used as a dependent variable. There was a reliable main           p<.01. The results were consistent with the findings in
effect of imageability, F(1, 19)=9.88, p<.01. The main effect     Evans et al.’s (2012) study, suggesting semantic effects vary
of foil condition was also significant, F(1.31, 24.85)=59.75,     in lexical decision, depending on the foil type.
p<.001 (with a Greenhouse-Geisser adjustment).
  Figure 2. Data are from simulation (Left) and from Evans et al. (2012). Normalised scores were computed by equating two
                              results based on the low imageability pseudohomophone condition.
                                                                  difficulty of the tasks (Evans, et al., 2012). That is in
                  General Discussion                              contrast with the localist view arguing for no or little
The primary aim of this paper was to develop a large-scale        involvement of semantics in lexical decision (Coltheart, et
recurrent reading model containing visual, orthographic,          al., 2001).
phonological, and semantic processing to support lexical             There are some existing lexical decision models
decision tasks. The model was used to explore the                 developed on the basis of the localist view of lexical
involvement of semantics in lexical decision with other           decision including the MROM model (Grainger & Jacobs,
processing components implemented in the system. This             1996) and the DRC model (Coltheart, et al., 2001) and the
approach is different to most existing models of lexical          CDP+ model (Perry, et al., 2007). These models can
processing which have focused on activity within a single         simulate several effects in lexical decision and the strategic
processing layer. Based on the measure of polarities at four      influences on lexical decision by flexibly adjusting decision
core processing layers (H0, OH, phonology and semantics),         criteria. However, their results are almost all based on
the model was able to perform the lexical decision tasks and      orthographic processing with little attention to other
account for the graded semantic effects found by Evans et         processing components in particular the semantic system.
al. (2012), as shown in Figure 2. The magnitude of semantic       Thus the questions as to how these models implement the
effects increased as nonwords became more word-like,              involvement of semantics in lexical decision, which
where the semantic effect was stronger with                       presumably requires some feedback connections from
pseudohomophones than with pseudowords and then with              semantics to their orthographic lexicon (Coltheart, et al.,
consonant strings. This provides evidence supporting the          2001) remain unclear. In particular, these localist models
distributed view of lexical decision which proposes that          would find it difficult to account for the graded changes in
semantic access is important and automatic in lexical             the involvement of semantics depending on foil type. In the
decision (Plaut, 1997). The actual use of semantic                current model this graded effect emerges naturally as a
information is flexible and is largely dependent on the           consequence of increasing task difficulty.
                                                              314

   In this paper we have followed Evans et al. (2012) by          James, C. T. (1975). Role of Semantic Information in
talking the size of the imageability effect as an index of          Lexical Decisions. Journal of Experimental Psychology-
semantic involvement, but future work could extend this in          Human Perception and Performance, 104(2), 130-136.
the model by developing additional metrics to quantify the        Joordens, S., & Becker, S. (1997). The Long and Short of
involvement of semantics including a direct comparison of           Semantic Priming Effects in Lexical Decision. Journal of
performance with and without the contribution from the              Experimental      Psychology-Learning     Memory      and
semantic layer.                                                     Cognition, 23(5), 1083-1105.
   To summarise, this paper uses a model of human visual          Lupker, S. J., & Pexman, P. M. (2010). Making Things
word recognition to explore the role of semantics in lexical        Difficult in Lexical Decision: The Impact of
decision. Crucially, the model was able to account for the          Pseudohomophones and Transposed-Letter Nonwords on
graded semantic influences on lexical decision                      Frequency and Semantic Priming Effects. Journal of
corresponding to the various types of foils, providing              Experimental      Psychology-Learning     Memory      and
evidence for semantic influences on lexical decision.               Cognition, 36(5), 1267-1289.
                                                                  Meyer, D. E., Schvanev, R. W., & Ruddy, M. G. (1974).
                    Acknowledgments                                 Functions of Graphemic and Phonemic Codes in Visual
This research was supported by grants under the Cognitive           Word-Recognition. Memory & Cognition, 2(2), 309-321.
Foresight Initiative (jointly funded by EPSRC, MRC and            Norris, D. (2009). Putting It All Together: A Unified
BBSRC - EP/F03430X/1) and the Neuroscience Research                 Account of Word Recognition and Reaction-Time
Institute at the University of Manchester.                          Distributions. Psychological Review, 116(1), 207-219.
                                                                  Patterson, K., Nestor, P. J., & Rogers, T. T. (2007). Where
                                                                    Do You Know What You Know? The Representation of
                         References                                 Semantic Knowledge in the Human Brain. Nature Reviews
Chang, Y. N., Furber, S., & Welbourne, S. (2012a). "Serial"         Neuroscience, 8(12), 976-987.
   Effects in Parallel Models of Reading. Cognitive               Perry, C., Ziegler, J. C., & Zorzi, M. (2007). Nested
  Psychology, 64(4), 267-291.                                       Incremental Modeling in the Development of
Chang, Y. N., Furber, S., & Welbourne, S. (2012b).                  Computational Theories: The Cdp+ Model of Reading
  Generating Realistic Codes for Use in Neural Network              Aloud. Psychological Review, 114(2), 273-315.
  Models. In N. Miyake, D. Peebles, & R. P. Cooper (Eds.),        Plaut, D. C. (1997). Structure and Function in the Lexical
  Proceedings of the 34th Annual Confrerence of the                 System: Insights from Distributed Models of Word
  Cognitive Science Society (pp. 198-203). Austin, Tx:              Reading and Lexical Decision. Language and Cognitive
  Cognitive Science Society.                                        Processes, 12(5-6), 765-805.
Coltheart, M., Davelaar, E., Jonasson, J. T., & Besner, D.        Plaut, D. C., McClelland, J. L., Seidenberg, M. S., &
  (1977). Access to the Internal Lexicon. In S. Dornic (Ed.),       Patterson, K. (1996). Understanding Normal and Impaired
  Attention and Performance Vi. Hillsdale, NJ: Lawrence             Word Reading: Computational Principles in Quasi-
  Erlbaum Associates.                                               Regular Domains. Psychological Review, 103(1), 56-115.
Coltheart, M., Rastle, K., Perry, C., Langdon, R., & Ziegler,     Ratcliff, R., Gomez, P., & McKoon, G. (2004). A Diffusion
  J. (2001). Drc: A Dual Route Cascaded Model of Visual             Model Account of the Lexical Decision Task.
  Word Recognition and Reading Aloud. Psychological                 Psychological Review, 111(1), 159-182.
  Review, 108(1), 204-256.                                        Roder, B., Kusmierek, A., Spence, C., & Schicke, T. (2007).
Dilkina, K., McClelland, J. L., & Plaut, D. C. (2010). Are          Developmental Vision Determines the Reference Frame
  There Mental Lexicons? The Role of Semantics in Lexical           for the Multisensory Control of Action. Proceedings of the
  Decision. Brain Research, 1365, 66-81.                            National Academy of Sciences of the United States of
Evans, G. A. L., Lambon Ralph, M. A., &Woollams, A. M.              America, 104(11), 4753-4758.
  (2012). What's in a Word? A Parametric Study of                 Rogers, T. T., Lambon Ralph, M. A., Hodges, J. R., &
  Semantic Influences on Visual Word Recognition.                   Patterson, K. (2004). Natural Selection: The Impactof
  Psychonomic Bulletin & Review, 19(2), 325-331.                    Semantic Impairment on Lexical and Object Decision.
Grainger, J., & Jacobs, A. M. (1996). Orthographic                  Cognitive Neuropsychology, 21(2-4), 331-352.
  Processing in Visual Word Recognition: A Multiple Read-         Seidenberg, M. S., & McClelland, J. L. (1989). A
  out Model. Psychological Review, 103(3), 518-565.                 Distributed, Developmental Model of Word Recognition
Hauk, O., Patterson, K., Woollams, A., Watling, L.,                 and Naming. Psychological Review, 96(4), 523-568.
  Pulvermuller, F., & Rogers, T. T. (2006). Q: When Would         Woollams, A. M., Silani, G., Okada, K., Patterson, K., &
  You Prefer a Sossage to a Sausage? A: At About 100                Price, C. J. (2011). Word or Word-Like? Dissociating
  Msec. Erp Correlates of Orthographic Typicality and               Orthographic Typicality from Lexicality in the Left
  Lexicality in Written Word Recognition. Journal of                Occipito-Temporal Cortex. Journal of Cognitive
  Cognitive Neuroscience, 18(5), 818-832.                           Neuroscience, 23(4), 992-1002.
Hodges, J. R., Patterson, K., Oxbury, S., & Funnell, E.
  (1992). Semantic Dementia - Progressive Fluent Aphasia
  with Temporal-Lobe Atrophy. Brain, 115, 1783-1806.
                                                              315

