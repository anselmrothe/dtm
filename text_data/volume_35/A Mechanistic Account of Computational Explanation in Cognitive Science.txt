UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Mechanistic Account of Computational Explanation in Cognitive Science
Permalink
https://escholarship.org/uc/item/8mz0328s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Mi?kowski, Marcin
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

        A Mechanistic Account of Computational Explanation in Cognitive Science
                                         Marcin Miłkowski (mmilkows@ifispan.waw.pl)
                                  Institute of Philosophy and Sociology, Polish Academy of Sciences
                                               ul. Nowy Świat 72, 00-330 Warsaw, Poland
                             Abstract                                     The claim that computational explanation is best
                                                                       understood as mechanistic gains popularity (Piccinini,
  Explanations in cognitive science rely predominantly on
  computational modeling. Though the scientific practice is            2007), and I have defended it at length against skeptical
  systematic, and there is little doubt about the empirical value      doubt elsewhere (Miłkowski, 2013). Here, I wish to
  of numerous models, the methodological account of                    succinctly summarize the account and, more importantly,
  computational explanation is not up-to-date. The current             add some crucial detail to the overall mechanistic
  paper offers a systematic account of computational                   framework proposed earlier. I cannot discuss Marr’s theory
  explanation in cognitive science in a largely mechanistic            in detail here (but see (Miłkowski, 2013, pp. 114–121)) and
  framework. The account is illustrated with a short case study
  of modeling of the mirror neuron system in terms of
                                                                       it is used only for illustration purposes. My remarks below
  predictive coding.                                                   are not meant to imply a wholesale rejection of his largely
                                                                       successful methodology.
   Keywords:      computation;       computational     modeling;          Marr’s account did not involve any theory of how
   explanation; mechanism; levels; information-processing.
                                                                       computation is physically realized, and it is compatible with
                                                                       a number of different accounts. I will assume a structural
      Importance of Computational Modeling                             account of computational realization here, defended also by
Computational modeling plays a special role in                         Piccinini (2008) and Chalmers (2011). For an extended
contemporary cognitive science; over 80 percent of articles            argument, see also (Miłkowski, 2011, 2013).
in theoretical journals focus on computational 1 models                   One particular claim that is usually connected with the
(Busemeyer & Diederich, 2010). The now dominating                      computational theory of mind is that the psychologically
methodology forcefully defended by (Marr, 1982) has                    relevant computation is over mental representation, which
turned out to be fruitful. At the same time, the three-level           leads to the language of thought hypothesis (Fodor, 1975).
account of Marr is not without problems. In particular, the            Here, no theory of mental representation is presupposed in
relationship among the levels is interpreted in various ways,          the account of computation, one of the reasons being that
wherein the change of level is both the shift of grain and the         representation is one of the most contentious issues in
shift of the boundary of the system under explanation                  contemporary cognitive science. As the present account is
(McClamrock, 1991); it is not at all clear what is the proper          intended to be descriptively adequate, assuming one
relation between competence and its realization or whether             particular theory of representation as implied by
bottom-up modeling is entirely mistaken; and, last but least,          computation would make other accounts immediately non-
whether one model should answer how, what and why                      computational, which is absurd. Another reason is that
questions related to the explanandum.                                  mechanistic accounts of computation do not need to
  My goal in this paper is to offer a descriptive account,             presuppose representation (Fresco, 2010; Piccinini, 2006),
which is close in spirit to the recent developments in the             though they do not exclude the representational character of
theory of mechanistic explanation (Bechtel, 2008; Craver,              some of the information being processed. In other words, it
2007; Glennan, 2002; Machamer, Darden, & Craver, 2000).                is claimed that only the notion of information (in the
According to mechanism, to explain a phenomenon is to                  information-theoretic sense, not in the semantic sense,
explain the underlying mechanism. Mechanistic explanation              which is controversial) is implied by the notion of
is a species of causal explanation, and explaining a                   computation (or information-processing).
mechanism involves the discovery of its causal structure.
While mechanisms are defined variously, the core idea is                            Explanandum phenomenon
that they are organized systems, comprising causally
                                                                       Marr stressed the importance of specifying exactly what the
relevant component parts and operations (or activities)
                                                                       model was supposed to explain. Specifying the
thereof. Parts of the mechanism interact and their
                                                                       explanandum phenomenon is critical also for the
orchestrated operation contributes to the capacity of the
                                                                       mechanistic framework, as several general norms of
mechanism. Mechanistic explanations abound in special
                                                                       mechanistic explanation are related to the specification of
sciences and it is hoped that the adequate description of the
                                                                       the capacity of the mechanism. All mechanisms posited in
principles implied in explanations generally accepted as
                                                                       explanations have an explanatory purpose, and for this
sound will furnish researchers also with normative
                                                                       reason, their specification is related to our epistemic
guidance.
                                                                       interest. For the same reason, the boundaries of the
                                                                       mechanism, though not entirely arbitrary, can be carved in
  1
    I am not using the word ‘computational’ here in the sense used     different ways depending on what one wishes to explain.
by Marr to define one of the levels in his account.
                                                                   3050

   The explanandum phenomenon has to be described                   remains a mechanism sketch.2 Note that even a grounded,
precisely in a mechanistic model; otherwise, the model’s            embodied, robotic model of visual perception may still be a
use and value will be unclear. The specification of the             mechanism sketch with respect to human vision. Also, a
model is not to be confused with raw, unrefined observation         model in which the explanatory focus is just a minor part of
or common-sense intuition about the capacity under                  the mechanism, while the parts included in the target are
consideration. The specification of the capacity may be (and        predominant, violates the principle of parsimony.
usually is) improved during the modeling process, wherein
the model allows to understand the capacity better. What the              Three levels of constitutive explanation
mechanistic model explains is the real mechanism, but how           Constitutive mechanistic explanation is the dominant form
the explanandum phenomenon is delineated is decided in              of computational explanations in cognitive science, and I
what was called “the model of data” in philosophy of                will focus on it in what follows. This kind of explanation
science (Suppes, 1962). For example, models of language             includes at least three levels of the mechanism: a
production usually presuppose that user’s productivity is the       constitutive (-1) level, which is the lowest level in the given
phenomenon to be explained, even though it is impossible to         analysis; an isolated (0) level, at which the parts of the
empirically observe a language user producing an infinite           mechanism are specified along with their interactions
set of sentences. If there are theoretical reasons to believe       (activities or operations); and the contextual (+1) level, at
that language users have this capacity, it will be described in     which the function of the mechanism is seen in a broader
a model of data. In this respect, mechanistic explanation is        context (e.g., the context for cricket phonotaxis includes the
in accord with Marr’s plea for explicit specification of what       dispersion of sound in the air). In contrast to how Marr
is computed.                                                        (1982) or Dennett (1987) understand them, levels here are
   To some degree, the specification of the explanandum             not just levels of abstraction; they are levels of composition.
phenomenon corresponds to description of the cognitive              Hence, they are tightly integrated but not entirely reducible
competence (understood generically as the capacity of the           to the lowest level.
mechanism). However, in contrast to traditional competence             Computational models explain how the computational
accounts, descriptions of the explanandum need not be               capacity of a mechanism is generated by the orchestrated
idealized. Also, the competence is explained with                   operation of its component parts. To say that a mechanism
realization, and its realization by underlying levels of the        implements a computation is to claim that the causal
mechanism is explanatorily relevant. This stands in contrast        organization of the mechanism is such that the input and
to traditional symbolic cognitive science.                          output information streams are causally linked and that this
                                                                    link, along with the specific structure of information
Explanatory focus and target                                        processing, is completely described (for more on various
In the context of computational modeling, which nowadays            mathematical notions of information, see Miłkowski (2013,
uses different computer simulations and embodied robots, it         chap. 2); note that I do not presuppose Church/Turing
becomes clear that properties of a model are not limited to         thesis). Importantly, the link might be cyclical and as
the ones related directly to the explanandum phenomenon.            complex as one could wish.
For example, a robotic model of cricket phonotaxis (Webb,              There are two ways in which computational models may
1995) has to include, for technical reasons, a circuit board        correspond to mechanisms; first, they may be weakly
even if there is nothing that corresponds to the board in the       equivalent to the explanandum phenomenon, in that they
cricket. Such boards are ignored when evaluating the                only describe the input and output information; or strongly
adequacy of the robotic explanation. I propose to distinguish       equivalent, when they also correspond to the process that
the explanatory focus of the model from its target, which is        generates the output information. Note that these notions
the real robot. In particular, all embodied mechanistic             have been used in methodology of computer simulation
models are complete with respect to the capacities of the           since 1960s (Fodor, 1968, chap. 4). Only strongly
target, while their explanatory focus may still include gaps:       equivalent models are explanatory according to the
we may still not know how certain properties of the insect          mechanistic framework.
give rise to the explanandum phenomenon even if we have a
robotic replica. The same goes for purely computational             Mechanistically adequate model of computation
models that contain numerous ad hoc additions (Frijda,              The description of a mechanistically adequate model of
1967; Lewandowsky, 1993). These additions are not parts of          computation at the 0 level usually comprises two parts: (1)
the explanatory focus.                                              an abstract specification of a computation, which should
   Whenever the causal model of the explanatory focus of            include all the causally relevant variables; (2) a complete
the mechanism is complete with respect to the explanandum           blueprint of the mechanism at this level of its organization. I
phenomenon (note: not complete in an absolute sense), the           will call the first part formal model of the mechanism and
model is a mechanistic how-actual explanation; if the model
includes some black boxes, whose function is more or less
                                                                       2
well-defined, it is a mechanism schema; otherwise, it                    These distinctions were used by Craver (2007), but were
                                                                    unrelated to the distinction between the target and the explanatory
                                                                    focus.
                                                                3051

the second instantiation blueprint of the mechanism, for             observables are tested, the more robust the model. Note that
lack of a better term. While it should be clear that a formal        the phenomenological validation modeled after the Turing
model needs to be included, it is probably less evident why          test (Turing, 1950) is not taken to be evidence of the
the instantiation blueprint is also part of the mechanistically      model’s empirical adequacy.
adequate model. The causal model must include all causally
relevant parts and operations without gaps or placeholder            Marr’s cash register
terms (think of generic and unspecific terms such as                 The account may be illustrated with the example used by
“representation” or “activation”). Yet formal models cannot          Marr (1982, pp. 22–24): a cash register in a supermarket.
function as complete causal models of computers. For                 The explanandum phenomenon is the capacity to add prices
example, to repair a broken old laptop, it is not enough to          of individual items and determine the overall sum to be
know that it was (idealizing somewhat) formally equivalent           paid. At the contextual level, one describes the cash register
to a universal Turing machine. Similarly, how mental                 as playing a certain role in the supermarket, by allowing
deficits will manifest themselves is not obvious based on a          easy calculation of the sum to be paid, and making the work
description of ideal cognitive capacity. One needs to know           of the cashier clerk easier. This includes a bar-code scanner,
its implementation.                                                  a conveyor belt, etc. At the isolated level, a dedicated
   Hence, the mechanistic model of a computational                   computer using special software is described. The
phenomenon cannot be limited to its formal properties.               constraints mentioned by Marr, such as commutativity or
Accordingly, merely formal models of, say, linguistic                associativity of addition, are included in the description of
competence, which abstract away from its realization, are            the software. Yet without describing the machine that can
assessed as essentially incomplete. They are either mere             run the software, this level of description is incomplete.
specifications of the explanandum phenomenon, but not                Various failures of the cash register (e.g., dimming of the
explanatory in themselves, or, when accompanied with a               display), can be explained not only in terms of the software
rough theory of how they are related to experimental data,           bugs but also as hardware failures. Also, the particular
mechanism sketches (Piccinini & Craver, 2011). This means            display configuration, which can be related to user
that computational explanations of psychological capacities          preferences at the contextual level, is usually not described
need to be integrated, for completeness, with models of their        fully in the software specification. It is the isolated level
realization. Otherwise, they may posit epiphenomenal                 where one describes the physical machine that can display
entities without any causal relevance. Contrary to the               the product name for the cashier clerk and, more
functionalist theory of psychological computational                  fundamentally, can run code by reading it from external
explanation (Cummins, 1983), mechanism requires it to be             memory (not all computers do so; a mechanical cash
causal. It follows that some symbolic models in psychology,          register, even if it performs computations, cannot run
even if they are weakly equivalent to the model of                   different software). The formal description, usually in terms
input/output data, are not considered to be fully explanatory        of the programming language or diagrams, is put into
because of the inherent danger of positing entities that are         correspondence with the machine. At the constitutive level,
causally irrelevant.                                                 the operations of the electronic parts of the machine are
   Just because the usual description of the computational           explained by reference to their properties, relationships, and
mechanism usually involves two different models, the                 organization. Just because vast differences between different
formal one and the instantiation blueprint, and these may be         types of registers are possible (witness the differences
idealized, computational modeling requires complex                   between the self-checkout register and the ones used during
integration, similar to one described as multiple-models             the American Civil War), the exact explanations will differ.
idealization (Weisberg, 2007).                                       Also, self-checkout machines will have the capacity to
   Note that my mechanistic account of computation does              collect cash automatically, which needs to be explained as
not stipulate that there be a single formal model of                 well (the explanandum will be different), and so forth.
computation that would fit all purposes. Rather, it adheres to         The purpose of this toy example is to show that the
transparent computationalism (Chrisley, 2000): any formal            mechanistic explanation differs a bit from Marr’s account
model that can be specified in terms of information-                 by explicitly tightly integrating the levels. Also, at all levels
processing is fine here, be it digital, analog, or hybrid, as in     one can ask the why-question: why is the design appropriate
contemporary computational neuroscience (Piccinini &                 for the user? Why does the cash register appropriately
Bahar, 2012).                                                        display figures on the screen? Why does it save energy? The
   The empirical adequacy of the mechanistically adequate            how-answer is specified at a lower level, and the lowest
model of computation can be tested. As such models are               level depends on our epistemic interest. The what-question
strongly equivalent to processes being modeled, usual                also concerns operation of all levels.
process-testing methods apply, including chronometry
(Posner, 2005), various kinds of experimental and natural                 Case study: Predictive coding in mirror
interventions (Craver, 2007), brain imaging – though with
                                                                                                neurons
usual caveats (Trout, 2008), and task decomposition
(Newell & Simon, 1972). All in all, the more independent             To demonstrate what methodological guidance is offered by
                                                                     the mechanistic account of computational explanation, let
                                                                 3052

me briefly describe a recently proposed model of action-                 interactions among levels of a cortical hierarchy. This
understanding in terms of predictive coding (Kilner, Friston,            means that the mechanism posited by authors comprises
& Frith, 2007). Predictive coding is one of the Bayesian                 more than just three levels, which is the minimal number for
frameworks and is gaining now considerable recognition                   constitutive explanations. Here, the upper level mechanism
(Clark, 2013). In the model, it is presupposed that this                 employs a generative model to predict representations in the
capacity is realized by the mirror-neuron system (MNS                    level below. Backward connections are used by the upper
henceforth).3 The explanandum phenomenon, or action                      level to convey the prediction to the lower level, which is
understanding, is described at four levels of hierarchy: (1)             used to produce information about prediction error. The
the intention-level, which includes long-term goals of                   instantiation blueprint of the mechanism includes this
actions; (2) the goal-level, which includes short-term goals             hierarchy whose architecture allows adjusting the neural
necessary to realize (1); (3) the kinematic level, which is the          representations of actions in terms of sensory representation
shape of the movement of limbs in space and time; and (4)                of causes of action if prediction error is found. The
the muscle level, which is the pattern of muscle activity                architecture is self-organizing, and the reciprocal exchange
underlying the action (Hamilton & Grafton, 2006). People                 of signals continues until the error is finally minimized.
have visual access only to (3) of other agents. Moreover, the              The formal model of the neural architecture is described
same kinematic level information is correlated to different              here in terms of empirical Bayesian inference (Friston,
intentions: Mr. Hyde might hurt someone with a scalpel by                2002, 2003, 2005): the prior expectations are generated by
making the same movements as Dr. Jekyll (Jacob &                         the self-organizing information-processing architecture. In
Jeannerod, 2005). What needs to be explained, therefore, is              other words, this model includes, as usual, two
how one understands actions, given ambiguous visual                      complementary parts: the instantiation blueprint,
information; the constraint of the model is that such                    characterized in terms what is known about MNS, and its
understanding is to be realized by MNS. Naturally, given                 formal computational specification. Quite obviously,
relatively scarce evidence about the details of MNS, the                 contrary to the programmable cash register, no stored-
model might be currently only biologically plausible. In                 program computer is posited.
mechanistic terms, it cannot be a how-actually model, as we                The constitutive level is merely touched upon; there is no
lack observables that could confirm that causal factors in the           extensive discussion of the precise realization of predictive
model are actual. We may have only a how-plausible model                 coding by elementary entities of the neural system. Thus,
(for more on this distinction, see (Craver, 2007)), which                this model is, at best, a mechanism schema, because it does
should ascribe a precise computational role for MNS.                     not explain how MNS comes to operate as it does. The
   Kilner, Friston & Frith note that other similar                       authors stress that to test the model, one would need to
explanations of action in terms of MNS posit forward or                  characterize the nodes of the cortical hierarchy anatomically
generative models. Yet these explanations cannot deal with               and functionally, and such characterization is not available.
the fact that people easily distinguish between the action of              The neural plausibility of the predictive coding and its
Dr. Jekyll and Mr. Hyde. In other words, they do not                     relation to empirical Bayesian modeling is the focus of
explain one important part of the phenomenon.                            much current discussion (Blokpoel, Kwisthout, & Van
   The contextual level of the proposed predictive coding                Rooij, 2012). In particular, the question whether the
mechanism includes the context in which the action is                    biologically plausible implementation of the predictive
observed (e.g., the operation theatre vs. dark streets of                coding is equivalent to empirical Bayes or not (it may
London). The context of action, which is not coded by                    somewhat approximate it). The mechanistic explanation
MNS, is hypothesized to be represented by other parts of the             requires that the mechanisms be not idealized in such a way
larger hierarchy, where intentions are encoded (Kilner et al.,           that would require to ignore tractability questions (Van
2007, p. 164). Note that such hierarchy can be naturally                 Rooij, 2008). The data in the original paper makes it
accounted for in the mechanistic framework, while in the                 impossible to answer critical questions about the mechanism
Marrian methodology, nested hierarchies of mechanisms are                in this context, such as the number of inputs in the Bayesian
still analyzed merely on three levels, which are not levels of           network, which is essential in assessing the parametrized
composition, as in Kilner et al.’s paper (this makes the                 complexity of the algorithm.
analysis of the model in Marrian terms all the more                        Were the model implemented on the computer, the results
difficult).                                                              of the simulation could be compared to those observed in
   The 0 level of the mechanism is then described as                     humans or in macaque monkeys. Alas, no such results are
performing predictive coding of action, i.e., the mechanism              reported by Kilner et al., and since without implemented
predicts the sensory consequences of movements, and the                  models detailed testing of hypotheses is impossible, the
prediction error is minimized through recurrent or reciprocal            empirical adequacy of the explanation is not entirely clear.
                                                                         To assess the adequacy properly, one should rather
   3
     For my purposes, it is quite irrelevant whether this account of     implement several comparable models of the same
MNS is correct or not (but see (Lingnau, Gesierich, & Caramazza,         explanandum phenomenon, which can also help in avoiding
2009)). I am merely interested in how the model is vindicated by         the confirmation bias to which researchers are prone (Farrell
its authors and how it should be evaluated from the mechanistic          & Lewandowsky, 2010; Miłkowski, 2013, p. 86).
standpoint.
                                                                     3053

   Some Bayesian theories in psychology were recently                 The present theory is not intended to settle debates over
criticized as fundamentalist, i.e., dogmatically trying to         matters in which modelers explicitly disagree; the only goal
model behavior as rational and without mechanistic                 is to make as much sense of various modeling approaches as
constraints (Jones & Love, 2011). Note that this is not true       possible, and make cross-approach comparisons possible by
of the model under consideration; Bayesian modeling in             showing the common ground between them.
neuroscience is obviously related to functioning of the               It is also not presupposed that computational explanation
brain. Instead of stressing the contrast between the               is the only proper way to explain cognition (Miłkowski,
mechanistic account of computational explanation and               2012). On the contrary, only some part of the mechanism
Bayesian modeling, my intention is to show that the                model is strictly computational (i.e., uses vocabulary of the
mechanistic framework can be used to evaluate the                  theory of computation). The constitutive level of the
contribution of the given model to progress in understanding       mechanism has to be framed in non-computational terms;
of the explanandum phenomenon.                                     otherwise, the computational operations of the isolated
   Summing up this part of the discussion, the mechanistic         level are not explained, and may turn out to be spurious
framework makes it easy to assess the maturity of the model        (Miłkowski, 2013, pp. 82–3). At the same time, the present
in terms of its completeness and empirical adequacy.               account leads naturally to explanatory pluralism, as the only
Because the computer implementation is lacking, it is              requirement for the theoretical frameworks used to describe
impossible to say whether the model contains a lot of              various levels of composition of mechanisms is that they
empirically undecided decisions that are needed to make it         include causally relevant factors.
run (hence focus/target evaluation is impossible). At the
same time, there is no information about the constitutive                               Acknowledgments
level. On the contextual level, placeholder terms such as          The author gratefully acknowledges the support of the
“intention encoding” are used and they need further                Polish National Science Center Grant in the OPUS program
explanations in other models. Thus, the model does not             no. 2011/03/B/HS1/04563.
include a complete specification of the mechanism.
   Also, it is not at all clear how long-term goals might be
understood in terms of mere sensory input prediction. Dr.
                                                                                            References
Jekyll’s intention to heal a patient (long-term goal) does not     Bechtel, W. (2008). Mental Mechanisms. New York:
seem, prima facie, to be represented just in sensory terms. If       Routledge (Taylor & Francis Group).
it is actually so represented, the model does not explain          Blokpoel, M., Kwisthout, J., & Van Rooij, I. (2012). When
how. This makes it a mechanism sketch, so its explanatory            Can Predictive Brains be Truly Bayesian? Frontiers in
value is, qualitatively speaking, on the par with traditional        Psychology, 3(November), 1–3.
symbolic models of competence. (Quantitative evaluation is           doi:10.3389/fpsyg.2012.00406
impossible here, as no results of experiments on computer          Busemeyer, J. R., & Diederich, A. (2010). Cognitive
implementation were reported.)                                       modeling. Los Angeles: Sage.
                                                                   Chalmers, D. J. (2011). A Computational Foundation for the
                          Conclusion                                 Study of Cognition. Journal of Cognitive Science, (12),
                                                                     325–359.
The mechanistic account of computational explanation
                                                                   Chrisley, R. (2000). Transparent computationalism. In M.
preserves the insights of Marr but is more flexible when
                                                                     Scheutz (Ed.), New Computationalism: Conceptus-Studien
applied to complex hierarchical systems. It may help
                                                                     14 (pp. 105–121). Sankt Augustin: Academia Verlag.
integrate various different models in a single explanation.
                                                                   Clark, A. (2013). Whatever Next? Predictive Brains,
Mechanistic methodological principles are inferred from
                                                                     Situated Agents, and the Future of Cognitive Science.
research practice in life sciences, neurosciences, and
                                                                     Behavioral and Brain Sciences, (in print).
cognitive science. Also, by subsuming computational
                                                                   Craver, C. F. (2007). Explaining the Brain. Mechanisms and
explanation under causal explanation, the mechanistic
                                                                     the mosaic unity of neuroscience. Oxford: Oxford
account is naturally complemented by methodology of
                                                                     University Press.
causal explanation (Pearl, 2000; Spirtes, Glymour, &
                                                                   Cummins, R. (1983). The Nature of Psychological
Scheines, 2000; Woodward, 2003).
                                                                     Explanation. Cambridge, Mass.: MIT Press.
   By allowing multiple nested hierarchies, the standard
                                                                   Dennett, D. C. (1987). The Intentional Stance. Cambridge,
three-level constitutive explanation is naturally expanded
                                                                     Mass.: MIT Press.
when needed. There is also no danger in preferring only the
                                                                   Farrell, S., & Lewandowsky, S. (2010). Computational
contextual level in the explanation, as it does not furnish us
                                                                     Models as Aids to Better Reasoning in Psychology.
with the constitutive causal factors. The constitutive level
                                                                     Current Directions in Psychological Science, 19(5), 329–
will also not obviate the need for the contextual level as it
                                                                     335. doi:10.1177/0963721410386677
does not contain some of the entities which are found at the
                                                                   Fodor, J. A. (1968). Psychological explanation: an
contextual level. For example, the encoding of intention is
                                                                     introduction to the philosophy of psychology. New York:
not realized by MNS only, so its explanation cannot be
                                                                     Random House.
‘reduced’ to the description of the lower levels.
                                                               3054

Fodor, J. A. (1975). The Language of Thought (1st ed.).             Implementation. Journal of Cognitive Science, 12(4),
  New York: Thomas Y. Crowell Company.                              359–379.
Fresco, N. (2010). Explaining Computation Without                 Miłkowski, M. (2012). Limits of Computational
  Semantics: Keeping it Simple. Minds and Machines,                 Explanation of Cognition. In V. C. Müller (Ed.),
  20(2), 165–181. doi:10.1007/s11023-010-9199-6                     Philosophy and Theory of Artificial Intelligence (pp. 69–
Frijda, N. H. (1967). Problems of computer simulation.              84). Berlin - Heidelberg: Springer. doi:10.1007/978-3-
  Behavioral Science, 12(1), 59–67.                                 642-31674-6_6
  doi:10.1002/bs.3830120109                                       Miłkowski, M. (2013). Explaning the Computational Mind.
Friston, K. (2002). Functional integration and inference in         Cambridge, Mass.: MIT Press.
  the brain. Progress in neurobiology, 68(2), 113–43.             Newell, A., & Simon, H. A. (1972). Human problem
Friston, K. (2003). Learning and inference in the brain.            solving. Englewood Cliffs, NJ: Prentice-Hall.
  Neural networks : the official journal of the International     Pearl, J. (2000). Causality: models, reasoning, and
  Neural Network Society, 16(9), 1325–52.                           inference. Cambridge: Cambridge University Press.
  doi:10.1016/j.neunet.2003.06.005                                Piccinini, G. (2006). Computation without Representation.
Friston, K. (2005). A theory of cortical responses.                 Philosophical Studies, 137(2), 205–241.
  Philosophical transactions of the Royal Society of                doi:10.1007/s11098-005-5385-4
  London. Series B, Biological sciences, 360(1456), 815–36.       Piccinini, G. (2007). Computing Mechanisms. Philosophy of
  doi:10.1098/rstb.2005.1622                                        Science, 74(4), 501–526. doi:10.1086/522851
Glennan, S. (2002). Rethinking Mechanistic Explanation.           Piccinini, G. (2008). Computers. Pacific Philosophical
  Philosophy of Science, 69(S3), S342–S353.                         Quarterly, 89(1), 32–73. doi:10.1111/j.1468-
  doi:10.1086/341857                                                0114.2008.00309.x
Hamilton, A. F. de C., & Grafton, S. T. (2006). Goal              Piccinini, G., & Bahar, S. (2012). Neural Computation and
  representation in human anterior intraparietal sulcus. The        the Computational Theory of Cognition. Cognitive
  Journal of neuroscience : the official journal of the             Science, n/a–n/a. doi:10.1111/cogs.12012
  Society for Neuroscience, 26(4), 1133–7.                        Piccinini, G., & Craver, C. (2011). Integrating psychology
  doi:10.1523/JNEUROSCI.4551-05.2006                                and neuroscience: functional analyses as mechanism
Jacob, P., & Jeannerod, M. (2005). The motor theory of              sketches. Synthese, 183(3), 283–311. doi:10.1007/s11229-
  social cognition: a critique. Trends in Cognitive Sciences,       011-9898-4
  9(1).                                                           Posner, M. I. (2005). Timing the brain: mental chronometry
Jones, M., & Love, B. C. (2011). Bayesian Fundamentalism            as a tool in neuroscience. PLoS biology, 3(2), e51.
  or Enlightenment? On the explanatory status and                   doi:10.1371/journal.pbio.0030051
  theoretical contributions of Bayesian models of cognition.      Spirtes, P., Glymour, C. N., & Scheines, R. (2000).
  Behavioral and Brain Sciences, 34(04), 169–188.                   Causation, prediction, and search (2nd ed.). Cambridge,
  doi:10.1017/S0140525X10003134                                     Mass.: The MIT Press.
Kilner, J. M., Friston, K. J., & Frith, C. D. (2007).             Suppes, P. (1962). Models of Data. In E. Nagel, P. Suppes,
  Predictive coding: an account of the mirror neuron system.        & A. Tarski (Eds.), Logic, Methodology, and Philosophy
  Cognitive processing, 8(3), 159–66. doi:10.1007/s10339-           of Science: Proceedings of the 1960 International
  007-0170-2                                                        Congress (pp. 252–261). Stanford: Stanford University
Lewandowsky, S. (1993). THE REWARDS AND                             Press.
  HAZARDS OF COMPUTER SIMULATIONS.                                Trout, J. D. (2008). Seduction without cause: uncovering
  Psychological Science, 4(4), 236–243.                             explanatory neurophilia. Trends in cognitive sciences,
  doi:10.1111/j.1467-9280.1993.tb00267.x                            12(8), 281–2. doi:10.1016/j.tics.2008.05.004
Lingnau, A., Gesierich, B., & Caramazza, A. (2009).               Turing, A. (1950). Computing Machinery and Intelligence.
  Asymmetric fMRI adaptation reveals no evidence for                Mind, LIX(236), 433–460. doi:10.1093/mind/LIX.236.433
  mirror neurons in humans. Proceedings of the National           Van Rooij, I. (2008). The tractable cognition thesis.
  Academy of Sciences of the United States of America,              Cognitive science, 32(6), 939–84.
  106(24), 9925–30. doi:10.1073/pnas.0902262106                     doi:10.1080/03640210801897856
Machamer, P., Darden, L., & Craver, C. F. (2000). Thinking        Webb, B. (1995). Using robots to model animals: a cricket
  about Mechanisms. Philosophy of Science, 67(1), 1–25.             test. Robotics and Autonomous Systems, 16(2-4), 117–
Marr, D. (1982). Vision. A Computational Investigation into         134. doi:10.1016/0921-8890(95)00044-5
  the Human Representation and Processing of Visual               Weisberg, M. (2007). Three kinds of idealization. Journal of
  Information. New York: W. H. Freeman and Company.                 Philosophy, 104(12), 639–659.
McClamrock, R. (1991). Marr’s three levels: A re-                 Woodward, J. (2003). Making Things Happen. Oxford:
  evaluation. Minds and Machines, 1(2), 185–196.                    Oxford University Press.
  doi:10.1007/BF00361036
Miłkowski, M. (2011). Beyond Formal Structure: A
  Mechanistic Perspective on Computation and
                                                              3055

