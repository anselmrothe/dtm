UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The effects of dual verbal and visual tasks on featural vs. relational category learning

Permalink
https://escholarship.org/uc/item/1qp1v8g2

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Jung, Wookyoung
Hummel, John

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The effects of dual verbal and visual tasks on featural vs. relational
category learning
Wookyoung Jung (jung43@illinois.edu)
Department of Psychology, 603 E. Daniel Street
Champaign, IL 61820 USA

John E. Hummel (jehummel@illinois.edu)
Department of Psychology, 603 E. Daniel Street
Champaign, IL 61820 USA

Abstract
Many studies have examined the distinction between featureand relation-based categories (Gentner, 2005; Genter &
Kurtz, 2005; Jung & Hummel, 2009; Tomlinson & Love,
2011). Those findings suggest that featural and relationl
categories have fundamentally different learning algorithms,
where relational categories rely on explicit representations
and thus require working memory and attention, as opposed
to featural categories which may be learned more implicitly.
In this study, we investigated further the distinction between
feature-and relation-based category learning using a dual task
methodology. Our results revealed an interaction: featural
category learning was more impaired by a visuospatial dual
task than by a verbal dual task, whereas relational category
learning was more impaired by the verbal dual task. Our
results suggest that in contrast to featural category learning,
which may involve mainly non-verbal mechanisms, relational
category learning appears to place greater demands on more
explicit and attention-demanding verbal or verbally-related
learning mechanisms.

confidence that anything learned about category learning
using feature-based categories will generalize at all to the
case of relational categories. For example, the kinds of
learning algorithms that work well with feature-based
categories (i.e., various kinds of statistical learning) are
completely incapable of learning relational categories
(Doumas, Hummel & Sandhofer, 2008; Hummel &
Holyoak, 2003; Jung & Hummel, 2009; Kittur et al., 2004,
2006).
One of the clearest examples of this difference comes
in the form of peoples’ ability to learn probabilistic (aka
family resemblance) category structures. It has been known
since the 1970s that people have no difficulty learning
categories with probabilistic structures, in which any given
feature is likely to belong to a given category (e.g., “bugs”
in category A are likely to have one kind of head whereas
“bugs” in category B are likely to have another), but no
feature is deterministically associated with any given
category (e.g., sometimes, bugs from category B will have
heads typical of bugs from category A and vice-versa; see
Murphy, 2002, for a review). However, as noted by Kittur et
al. (2004), such prototype effects have always been
observed with feature-based categories. With categories
defined by the relations between their exemplars’ features,
such prototype effects have proven difficult or impossible to
observe (Jung & Hummel, 2009, 2011; Kittur et al., 2004,
2006).
These differences between peoples’ ability to learn
featural and relational categories are consistent with the
claim that fundamentally different learning algorithms may
be at work in the two cases. For example, whereas
associative learning may work in the case of featural
categories, relational category learning may require a more
sophisticated algorithm based, for example, on structured
intersection discovery, in which learners compare examples
to one another, retaining what the examples have in
common and discarding or discounting the details on which
they differ (Gick & Holyoak, 1983; Hummel & Holyoak,
2003; Jung & Hummel, 2009, 2011; Kittur et al, 2004,
2006).

Key words: featural category learning; relational category
learning; dual task; verbal dual task; visuospatial dual task;
category learning algorithms

The ability to categorize plays a central role in human
mental life. We use categories to makes sense of the world.
They allow us to generalize knowledge form one situation to
another, to decide which objects in the world are
fundamentally the same, and to infer the unseen properties
of novel category members. Research on categorization has
mainly focused on feature-based categories—that is,
categories defined by their exemplars’ features, as when
“bugs” in one category tend to have a particular kind of
head, body and tail and “bugs” in the opposite category tend
to have a different kind of head, body and tail (e.g., Taylor
and Ross, 2009)—and comparatively little on relationbased categories—i.e., categories by the relations between
exemplars’ parts, or by relations between category
exemplars and other objects in the world (for reviews, see
Gentner, 2005; Goldwater, Markman, & Stilwell, 2011;
Jung & Hummel, 2009; Kittur, Hummel & Holyoak, 2004).
The distinction between featural and relational
categories matters because features and relations are very
different things—so different that we can have little or no

698

A fundamental assumption underlying this intersection
discovery hypothesis is that people’s mental representations
of relational categories are explicitly relational (see Hummel
& Holyoak, 2003; Jung & Hummel, 2009, 2011). That is,
we assume that people notice and explicitly represent the
relations between objects (and object parts) and use these
relations as the basis for making their categorization
responses. This assumption also leads to another critical
contrast with feature-based approaches to mental
representation and categorization. In contrast to featurebased representations, which come to us effortlessly,
relational representations require attention and working
memory (see, e.g., Hummel & Holyoak, 1997, 2003; Logan,
1994; Maybery et al., 1986).
In this study, we examined what kinds of working
memory might be involved in feature- or relation-based
category learning. In particular, our interest was in how
featural and relational category learning tasks respond to
verbal and visuospatial dual tasks. If featural and relational
category learning are based on different learning algorithms,
then they might be differentially sensitive to different kinds
of dual tasks.
Other researchers have also argued for multiple
systems of category learning (Ashby et al., 1998). Miles and
Minda (2011) showed that verbal dual tasks, which impose
an executive functioning load, impaired rule-defined
category learning, whereas a visual dual task impaired nonrule-defined learning regardless of executive functioning
demand. Their findings provided evidence that verbal
working memory and executive functioning are engaged in
the rule-defined system, and visual processing is more
engaged in the non-rule-defined system.
Our experiment will test the prediction that relational
category learning will be more subject to verbal dual-task
interference than feature-based category learning. By
contrast, feature-based learning will be more subject to
visuospatial dual-task interference than relational learning.
We used deterministic category structures; i.e., there
was always one relation or feature that was deterministically
predictive of category membership. The reason for using
deterministic categories is that the categories must be
learnable, even in the relational case, so that we can observe
the effects of our manipulation on trials to criterion (i.e.,
how long it takes subjects to learn the categories).
We orthogonally crossed relational vs. feature-based
categories with verbal dual task vs. visual dual task vs. no
dual task. In the verbal dual task conditions, subjects had to
perform a task known to interfere with relational processing
(memorizing digits) while they simultaneously performed
the category learning task. In the visual dual task condition,
subjects had to memorize the locations of filled squares in 3
X 3 grids while simultaneously learning the categorization.
In the no dual task condition, subjects simply performed the
category learning task by itself.

Method
Participants. A total of 75 subjects participated in the study
for course credit. Each participant was randomly assigned to
one of the six conditions.
Materials. Each exemplar consisted of a grey ellipse and a
grey rectangle. Each exemplar had both relational properties
(e.g., ellipse bigger than rectangle) and featural properties
(e.g., ellipse of size 4). Each subject was tasked with
deciding whether the objects they saw belonged to one of
two featural or one of two relational categories.
Each exemplar was defined by three category-relevant
properties: size (absolute in the featural condition or relative
in the relational condition), darkness (absolute or relative)
and orientation (absolute or relative). In the featural
condition, the orientation of the ellipse was deterministically
associated with category membership (i.e., horizontal
orientation for category A, vertical for category L), whereas
in the relational category condition, the relative orientation
of the ellipse and rectangle (i.e., either same or different)
was deterministically associated with category membership
(with same for category A and different for category L).
The other properties were probabilistically associated with
category membership.

Rectangle
size 3

Rectangle
size 7

Rectangle
darkness 3

Rectangle
darkness 7

Ellipse
orientation
horizontal

Ellipse
orientation
vertical

Figure 1. Three relevant properties in the featural condition:
category A (above) and L (below)
For the featural category condition, the prototypes of
the categories were defined as [1,1,1] for category A and
[0,0,0] for L, where [1,1,1] represents an rectangle size 3
[out of 9] for category A, 7 for category L, the color 3 [out
of 9] for category A, 7 for category L, and horizontal
orientation for category A, vertical for category L (Figure
1). Similarly, for the relational category condition, the
prototypes were defined as [1,1,1] for category A and

699

[0,0,0] for L, where [1,1,1] represents an ellipse larger,
darker, and same orientation and [0,0,0] represents a
rectangle larger, darker, and different orientation (Figure
2). Exemplars of each category were made by switching the
value of one dimension in the prototype (e.g., relational
category A exemplar [1,0,1] would have the ellipse larger,
lighter, and same orientation as the rectangle). Four copies
of each exemplar type were presented on each block, two
paired with a “Yes” responses on the dual task and two with
a “No” responses, resulting in 32 trials per category per
block.

remained on the screen until the participant responded.
Responses were followed by accuracy feedback.
Participants then saw one random digit and were asked to
decide whether it was in the set they saw previously.
A.Control

B. Verbal

C. Visuosaptial

38952
A or L?

Please
keep
memorizing

Please
keep
memorizing

Correct

A or L?

A or L?

Correct

Ellipse
Larger

Ellipse
Darker

Same
orientation

Correct

6
Was the digit
shown?

Was the cell
shaded?

Figure 3. Experimental design by each condition

Rectangle
Larger

Rectangle
Darker

In the visuospatial dual-task condition, a 3 by 3 grid
was displayed in the middle of a screen for two seconds
with two randomly-chosen cells filled. Participants were
asked to memorize the locations of the filled cells until they
completed the categorization task. In the recall task, one
filled cell was displayed in the grid and participants were
asked whether the cell had been filled in the original display.
The experiment consisted of 30 blocks (960 trials) and
continued until the participant responded correctly on at
least twenty nine of thirty two trials (90.6% correct) for two
consecutive blocks or until all 30 blocks had transpired,
whichever came first.

Different
orientation

Figure 2. Three relevant properties in the relational
condition: category A (above) and L (below)
Design. The experiment used a 3 (dual task: none vs. verbal
vs. visuospatial) X 2 (relevant property: features vs.
relations) between-subjects design.

Results

Procedure. Participants were assigned randomly to one of
the six groups. For the dual task conditions, on each trial, a
memory task was provided first and followed by a
categorization task and by a recall task. For the control
conditions, only the categorization task was provided
(Figure 3). Both categorization and dual task responses were
followed by accuracy feedback.
Participants in the verbal dual-task condition were first
given a verbal working memory task, in which 5 random
digits were displayed for two seconds with spaces between
them (so that they appeared to be individual numbers rather
than digits of a single number). Participants were asked to
memorize the digits while they performed the categorization
task. In the categorization task, an exemplar consisting of a
rectangle and an ellipse was shown. Participants were
instructed to press the A key if the stimulus belonged to
category A and the L key if it belonged to L. Each exemplar

Dual task accuracy. We discarded the data from
participants whose accuracy was below 70% correct on the
dual task (2 subjects in the verbal/featural condition). Mean
accuracy on the verbal dual task was M = .94 (SD = .03) for
the featural category learning condition, and M = 0.91 (SD =
0.06) for the relational learning condition. Mean accuracy
on the visual dual task was M = 0.91 (SD = 0.06) for the
featural condition, and M = 0.89 (SD = 0.04) for the
relational condition. There was no reliable difference
between the verbal and visuospatial tasks [t(51) = 1.61, p
= .114], suggesting that these tasks occupied cognitive
resources to roughly the same extent.
Category learning task accuracy: trials to criterion.
Since our primary interest is the rate at which participants
learn the categories as a function of the dual tasks, we report

700

our data first in terms of trials to criterion. These analyses
are conservative in the sense that participants who never
learned to criterion were treated as though they reached
criterion on the last block. Figure 4 shows the mean trials to
criterion by condition. A 3 (dual task) × 2 (category learning
task) between-subjects ANOVA revealed a main effect of
dual task [F(2, 69) = 5.058, MSE = 579014.858, p < 0.01].
Since our main interest is in how different dual tasks affect
the different kinds of category learning, one-way ANOVAs
were conducted for the featural and relational learning
conditions. The results revealed reliable differences between
dual tasks in the featural category learning condition
[F(2,35) = 4.981, MSE = 617725.846, p < 0.05]. Planned
comparisons in the featural category learning showed that
there was a reliable difference between the verbal (M = 386,
SD = 387) and visuospatial dual task (M = 697, SD = 411)
[t(35) = -2.288, p < 0.05]. There was also a reliable
difference between the visuospatial and the control
condition (M = 262, SD = 191) [t(35) = 3.014, p < 0.01].
The difference between the verbal and the control condition
was not reliable [t(35) = 0.877, p < 0.386]. The ANOVA
results from the relational condition revealed reliable
differences between the dual tasks [F(2,34) = 7.641, MSE =
799483.887, p < 0.01]. Planned comparisons revealed that
there was a reliable difference between the verbal (M = 739,
SD = 352) and visuospatial dual task (M = 330, SD = 362)
[t(34) = 3.221, p < 0.01]. There was also a reliable
difference between the verbal and control conditions (M =
276, SD = 222) [t(34) = 3.014, p < 0.01]. The difference
between the visuospatial and control conditions was not
reliable [t(34) = 0.404, p < 0.689]. No other main effects
were statistically reliable. Most interestingly, there was a
reliable interaction between dual task and category learning,
indicating that relational category learning was disrupted
more by the verbal dual task, whereas featural category
learning was disrupted more by the visuospatial dual task
[F(2,69) = 2.475, MSE = 855659.946, p < 0.01].

[t(35) = -2.037, p < 0.05], indicating that response times in
visuospatial feature-learning condition were longer than
those in verbal feature-learning. No other differences were
statistically reliable. There were no reliable differences in
the relational learning condition. Also, ANOVA showed a
reliable main effect of category learning [F(1, 69) = 3.883,
MSE = 1.166, p = 0.053], indicating that feature learning
(M = 1.17, SD = 0.55) was marginally faster than relational
learning (M = 1.42, SD = 0.56) (Figure 5).

900

**

800

*

Control
Verbal
Visual

Trials to criterion

700
600

**

500

**
**

400
300
200
100
0
Feature

Relation

Figure 4. Accuracy by category learning condition

1.8

Feature

1.6

Relation

1.4

Response times. Since the category learning accuracy
results yielded a reliable interaction between the dual and
category learning tasks, we also analyzed these tasks in
terms of participants’ mean response times on individual
trials in order to gain insight about the strategies participants
in each condition may have adopted. A 3 (dual task) × 2
(category learning task) between-subjects ANOVA revealed
a main effect of dual task [F(2, 69) = 3.202, MSE = 0.961,
p< 0.05]. One-way ANOVAs were also conducted in each
category learning condition. The main effect of dual task
was not reliable [F(2, 35) = 2.137, MSE = 0.612, p = 0.133]
in the featual learning condition. But since the accuracy data
showed that participants in visuospatial feature-learning
required many more trials than to reach to the criterion than
participants in verbal featural learning, we expected a
reliable difference between two conditions in a planned
comparison analysis. Our prediction was confirmed. There
was a reliable difference between the verbal (M = 0.99, SD
= 0.31) and visuospatial dual task (M = 1.41, SD = 0.78)

RT(sec)

1.2
1
0.8
0.6
0.4
0.2
0
Verbal

Visual

Control

Figure 5. Response times by dual condition

701

Doumas. L. A. A., Hummel, J. E., & Sandhofer, C.
M.(2008).A theory of the discovery and predication of
relational concepts. Psychological Review, 115, 1 - 43.
Gentner, D. (2005). The development of relational category
knowledge. In L. Gershkoff-Stowe & D. H. Rakison,
(Eds.), Building object categories in developmental time.
(pp. 245-275). Hillsdale, NJ: Erlbaum
Gentner, D., & Kurtz, K. (2005). Relational categories. In
W. K. Ahn, R. L. Goldstone, B. C. Love, A. B. Markman
& P. W. Wolff (Eds.), Categorization inside and outside
the lab. (pp. 151-175). Washington, DC: APA.
Gick, M. L., & Holyoak, K. J. (1983). Schema induction
and analogical transfer. Cognitive Psychology, 15, 1-38.
Goldwater, M. B., Markman, A. B., & Stilwell, C. H.
(2011). The empirical case for role-governed categories.
Cognition, 118, 359-376.
Hummel, J. E. (2010). Symbolic vs. associative
learning. Cognitive Science, 34, 958-965.
Hummel, J. E., & Holyoak, K. J. (1997). Distributed
representations of structure: A theory of analogical access
and mapping. Psychological Review, 104, 427-466.
Hummel, J. E., & Holyoak, K. J. (2003). A symbolicconnectionist theory of relational inference and
generalization. Psychological Review, 110, 220-264.
Kittur, A., Holyoak, K. J., & Hummel, J. E. (2006). Using
ideal observers in higher-order human category learning.
Proceedings of the Twenty Eight Annual Conference of
the Cognitive Science Society (pp. 435-440). Hillsdale,
NJ: Lawrence Erlbaum Associates.
Kittur, A., Hummel, J. E., & Holyoak, K. J. (2004).
Feature- vs. relation-defined categories: Probab(alistic)ly
Not the Same. Proceedings of the Twenty Six Annual
Conference of the Cognitive Science Society (pp. 696701).Hillsdale, NJ: Lawrence Erlbaum Associates.
Jung, W., & Hummel, J. E. (2009) Probabilistic relational
categories are learnable as long as you don’t know you’re
learning probabilistic relational categories. Proceedings of
The 31st Annual Conference of the Cognitive Science
Society, Society (pp. 1042-1047). Hillsdale, NJ: Lawrence
Erlbaum Associates.
Jung, W., & Hummel, J. E. (2011). Progressive alignment
facilitates learning of deterministic but not probabilistic
relational categories. Proceedings of the 33rd Annual
Conference of the Cognitive Science Society.
Logan, G. D. (1992). Shapes of reaction time distributions
and shapes of learning curves: A test of the instance
theory of automaticity. Journal of Experimental
Psychology: Learning, Memory and Cognition, 18, 883914.
Maybery, M. T., Bain, J. D., & Halford, G. S. (1986).
Information processing demands of transitive inference.
Journal of Experimental Psychology: Learning, Memory,
and Cognition, 12, 600-613.
Miles, S. J. & Minda, J. P. (2011). The effects of concurrent
verbal and visual tasks on category learning. Journal of
Experimental Psychology: Learning Memory &
Cognition, 37, 588-607.

Discussion
To the extent that relational concepts are qualitatively
similar to feature-based concepts, our understanding of
concepts can be expected to generalize from the
(extensively investigated) case of feature-based categories
to the (largely neglected) case of relational categories.
However, there is reason to believe they are not, casting
doubt on our ability to generalize our conclusions from
studies using feature-based categories to the case of
relational concepts.
Most notably, people have no difficulty learning
feature-based categories in which no single feature remains
invariant across all members of a category (see Murphy,
2002). By contrast, Kittur and colleagues showed that
relational categories are extremely difficult to learn when
there is no such relational invariant (i.e., property that holds
over all members of a category; Kittur et al., 2004, 2006).
Jung and Hummel (2009, 2011) provided additional
evidence that relational learning requires some kind of
invariant in order to succeed. These findings suggest that
featural and relational learning rely not only on qualitatively
different forms of mental representation (namely, features
vs. relations; see, e.g., Hummel, 2010; Hummel & Holyoak,
1997, for a discussion of the difference) but also that they
rely on qualitatively different kinds of learning algorithms
(e.g., associative learning in the featural case and something
more akin to structured intersection discovery in the
relational case; Jung & Hummel, 2009, 2011).
The current experiment provides additional evidence
for this sharp distinction between featural and relational
category learning. In the current experiment, featural
learning was impeded by a visual dual task (i.e., one that
might be expected to interfere with visual feature processing
as required for featural learning) but not by a verbal dual
task. Relational category learning, in sharp contrast, was
interfered with by a verbal dual task (which has been shown
to interfere with relational processing; Waltz et al., 2000),
but not by a visual dual task. This double dissociation
between visual vs. verbal dual task interference on the one
hand and featural vs. relational category learning on the
other adds to the growing evidence that these two kinds of
category learning rely on qualitatively different and
dissociable learning systems.

Acknowledgements
This research was supported by a grant from the University
of Illinois Research Board.

References
Ashby, F. G., Alfonso-Reese, L. A., Turken, A. U., &
Waldron, E. M. (1998). A neuropsychological theory of
multiple systems in category learning. Psychological
Review, 105, 442– 481.

702

Murphy, G. L. (2002). The big book of concepts,
Cambridge, MA: MIT Press.
Taylor, E. G. & Ross, B. H. (2009). Classifying partial
exemplars: Seeing less and learning more. Journal of
Experimental Psychology: Learning, Memory, &
Cognition, 35(5), 1374-1380.
Tomlinson, M.T., & Love, B.C. (2010). When learning to
classify by relations is easier than by features. Thinking &
Reasoning,16, 372-401.
Waltz, J. A., Lau, A., Grewal, S. K., & Holyoak, K. J.
(2000). The role of working memory in analogical
mapping. Memory & Cognition, 28, 1205-1212.

703

