UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The effects of dual verbal and visual tasks on featural vs. relational category learning
Permalink
https://escholarship.org/uc/item/1qp1v8g2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Jung, Wookyoung
Hummel, John
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                  Powered by the California Digital Library
                                                                        University of California

               The effects of dual verbal and visual tasks on featural vs. relational
                                                        category learning
                                            Wookyoung Jung (jung43@illinois.edu)
                                           Department of Psychology, 603 E. Daniel Street
                                                       Champaign, IL 61820 USA
                                           John E. Hummel (jehummel@illinois.edu)
                                           Department of Psychology, 603 E. Daniel Street
                                                       Champaign, IL 61820 USA
                           Abstract
  Many studies have examined the distinction between feature-         confidence that anything learned about category learning
  and relation-based categories (Gentner, 2005; Genter &              using feature-based categories will generalize at all to the
  Kurtz, 2005; Jung & Hummel, 2009; Tomlinson & Love,                 case of relational categories. For example, the kinds of
  2011). Those findings suggest that featural and relationl
  categories have fundamentally different learning algorithms,        learning algorithms that work well with feature-based
  where relational categories rely on explicit representations        categories (i.e., various kinds of statistical learning) are
  and thus require working memory and attention, as opposed           completely incapable of learning relational categories
  to featural categories which may be learned more implicitly.        (Doumas, Hummel & Sandhofer, 2008; Hummel &
  In this study, we investigated further the distinction between      Holyoak, 2003; Jung & Hummel, 2009; Kittur et al., 2004,
  feature-and relation-based category learning using a dual task      2006).
  methodology. Our results revealed an interaction: featural
                                                                            One of the clearest examples of this difference comes
  category learning was more impaired by a visuospatial dual
  task than by a verbal dual task, whereas relational category        in the form of peoples’ ability to learn probabilistic (aka
  learning was more impaired by the verbal dual task. Our             family resemblance) category structures. It has been known
  results suggest that in contrast to featural category learning,     since the 1970s that people have no difficulty learning
  which may involve mainly non-verbal mechanisms, relational          categories with probabilistic structures, in which any given
  category learning appears to place greater demands on more          feature is likely to belong to a given category (e.g., “bugs”
  explicit and attention-demanding verbal or verbally-related         in category A are likely to have one kind of head whereas
  learning mechanisms.
                                                                      “bugs” in category B are likely to have another), but no
  Key words: featural category learning; relational category          feature is deterministically associated with any given
  learning; dual task; verbal dual task; visuospatial dual task;      category (e.g., sometimes, bugs from category B will have
  category learning algorithms                                        heads typical of bugs from category A and vice-versa; see
                                                                      Murphy, 2002, for a review). However, as noted by Kittur et
      The ability to categorize plays a central role in human         al. (2004), such prototype effects have always been
mental life. We use categories to makes sense of the world.           observed with feature-based categories. With categories
They allow us to generalize knowledge form one situation to           defined by the relations between their exemplars’ features,
another, to decide which objects in the world are                     such prototype effects have proven difficult or impossible to
fundamentally the same, and to infer the unseen properties            observe (Jung & Hummel, 2009, 2011; Kittur et al., 2004,
of novel category members. Research on categorization has             2006).
mainly focused on feature-based categories—that is,                         These differences between peoples’ ability to learn
categories defined by their exemplars’ features, as when              featural and relational categories are consistent with the
“bugs” in one category tend to have a particular kind of              claim that fundamentally different learning algorithms may
head, body and tail and “bugs” in the opposite category tend          be at work in the two cases. For example, whereas
to have a different kind of head, body and tail (e.g., Taylor         associative learning may work in the case of featural
and Ross, 2009)—and comparatively little on relation-                 categories, relational category learning may require a more
based categories—i.e., categories by the relations between            sophisticated algorithm based, for example, on structured
exemplars’ parts, or by relations between category                    intersection discovery, in which learners compare examples
exemplars and other objects in the world (for reviews, see            to one another, retaining what the examples have in
Gentner, 2005; Goldwater, Markman, & Stilwell, 2011;                  common and discarding or discounting the details on which
Jung & Hummel, 2009; Kittur, Hummel & Holyoak, 2004).                 they differ (Gick & Holyoak, 1983; Hummel & Holyoak,
      The distinction between featural and relational                 2003; Jung & Hummel, 2009, 2011; Kittur et al, 2004,
categories matters because features and relations are very            2006).
different things—so different that we can have little or no
                                                                  698

      A fundamental assumption underlying this intersection        Method
discovery hypothesis is that people’s mental representations       Participants. A total of 75 subjects participated in the study
of relational categories are explicitly relational (see Hummel     for course credit. Each participant was randomly assigned to
& Holyoak, 2003; Jung & Hummel, 2009, 2011). That is,              one of the six conditions.
we assume that people notice and explicitly represent the
relations between objects (and object parts) and use these         Materials. Each exemplar consisted of a grey ellipse and a
relations as the basis for making their categorization             grey rectangle. Each exemplar had both relational properties
responses. This assumption also leads to another critical          (e.g., ellipse bigger than rectangle) and featural properties
contrast with feature-based approaches to mental                   (e.g., ellipse of size 4). Each subject was tasked with
representation and categorization. In contrast to feature-         deciding whether the objects they saw belonged to one of
based representations, which come to us effortlessly,              two featural or one of two relational categories.
relational representations require attention and working                 Each exemplar was defined by three category-relevant
memory (see, e.g., Hummel & Holyoak, 1997, 2003; Logan,            properties: size (absolute in the featural condition or relative
1994; Maybery et al., 1986).                                       in the relational condition), darkness (absolute or relative)
      In this study, we examined what kinds of working             and orientation (absolute or relative). In the featural
memory might be involved in feature- or relation-based             condition, the orientation of the ellipse was deterministically
category learning. In particular, our interest was in how          associated with category membership (i.e., horizontal
featural and relational category learning tasks respond to         orientation for category A, vertical for category L), whereas
verbal and visuospatial dual tasks. If featural and relational     in the relational category condition, the relative orientation
category learning are based on different learning algorithms,      of the ellipse and rectangle (i.e., either same or different)
then they might be differentially sensitive to different kinds     was deterministically associated with category membership
of dual tasks.                                                     (with same for category A and different for category L).
      Other researchers have also argued for multiple              The other properties were probabilistically associated with
systems of category learning (Ashby et al., 1998). Miles and       category membership.
Minda (2011) showed that verbal dual tasks, which impose
an executive functioning load, impaired rule-defined
category learning, whereas a visual dual task impaired non-
rule-defined learning regardless of executive functioning
demand. Their findings provided evidence that verbal
working memory and executive functioning are engaged in
the rule-defined system, and visual processing is more
engaged in the non-rule-defined system.
      Our experiment will test the prediction that relational             Rectangle          Rectangle              Ellipse
category learning will be more subject to verbal dual-task                   size 3          darkness 3           orientation
                                                                                                                  horizontal
interference than feature-based category learning. By
contrast, feature-based learning will be more subject to
visuospatial dual-task interference than relational learning.
      We used deterministic category structures; i.e., there
was always one relation or feature that was deterministically
predictive of category membership. The reason for using
deterministic categories is that the categories must be
learnable, even in the relational case, so that we can observe
the effects of our manipulation on trials to criterion (i.e.,             Rectangle                                  Ellipse
                                                                                                 Rectangle
how long it takes subjects to learn the categories).                        size 7               darkness 7         orientation
      We orthogonally crossed relational vs. feature-based                                                            vertical
categories with verbal dual task vs. visual dual task vs. no
dual task. In the verbal dual task conditions, subjects had to      Figure 1. Three relevant properties in the featural condition:
perform a task known to interfere with relational processing                       category A (above) and L (below)
(memorizing digits) while they simultaneously performed
the category learning task. In the visual dual task condition,           For the featural category condition, the prototypes of
subjects had to memorize the locations of filled squares in 3      the categories were defined as [1,1,1] for category A and
X 3 grids while simultaneously learning the categorization.        [0,0,0] for L, where [1,1,1] represents an rectangle size 3
In the no dual task condition, subjects simply performed the       [out of 9] for category A, 7 for category L, the color 3 [out
category learning task by itself.                                  of 9] for category A, 7 for category L, and horizontal
                                                                   orientation for category A, vertical for category L (Figure
                                                                   1). Similarly, for the relational category condition, the
                                                                   prototypes were defined as [1,1,1] for category A and
                                                               699

[0,0,0] for L, where [1,1,1] represents an ellipse larger,          remained on the screen until the participant responded.
darker, and same orientation and [0,0,0] represents a               Responses were followed by accuracy feedback.
rectangle larger, darker, and different orientation (Figure         Participants then saw one random digit and were asked to
2). Exemplars of each category were made by switching the           decide whether it was in the set they saw previously.
value of one dimension in the prototype (e.g., relational
category A exemplar [1,0,1] would have the ellipse larger,                 A.Control        B. Verbal          C. Visuosaptial
lighter, and same orientation as the rectangle). Four copies
of each exemplar type were presented on each block, two
paired with a “Yes” responses on the dual task and two with                                  38952
a “No” responses, resulting in 32 trials per category per                    A or L?
                                                                                                Please                 Please
block.                                                                                           keep                   keep
                                                                                              memorizing             memorizing
                                                                                Correct
                                                                                                   A or L?                A or L?
                                                                                                     Correct                 Correct
       Ellipse               Ellipse              Same
       Larger                Darker             orientation                                                 6
                                                                                                      Was the digit
                                                                                                         shown?               Was the cell
                                                                                                                                shaded?
                                                                          Figure 3. Experimental design by each condition
                                                                          In the visuospatial dual-task condition, a 3 by 3 grid
                                                                    was displayed in the middle of a screen for two seconds
       Rectangle           Rectangle             Different          with two randomly-chosen cells filled. Participants were
        Larger               Darker             orientation         asked to memorize the locations of the filled cells until they
                                                                    completed the categorization task. In the recall task, one
                                                                    filled cell was displayed in the grid and participants were
     Figure 2. Three relevant properties in the relational          asked whether the cell had been filled in the original display.
         condition: category A (above) and L (below)                The experiment consisted of 30 blocks (960 trials) and
                                                                    continued until the participant responded correctly on at
Design. The experiment used a 3 (dual task: none vs. verbal         least twenty nine of thirty two trials (90.6% correct) for two
vs. visuospatial) X 2 (relevant property: features vs.              consecutive blocks or until all 30 blocks had transpired,
relations) between-subjects design.                                 whichever came first.
Procedure. Participants were assigned randomly to one of            Results
the six groups. For the dual task conditions, on each trial, a      Dual task accuracy. We discarded the data from
memory task was provided first and followed by a                    participants whose accuracy was below 70% correct on the
categorization task and by a recall task. For the control           dual task (2 subjects in the verbal/featural condition). Mean
conditions, only the categorization task was provided               accuracy on the verbal dual task was M = .94 (SD = .03) for
(Figure 3). Both categorization and dual task responses were        the featural category learning condition, and M = 0.91 (SD =
followed by accuracy feedback.                                      0.06) for the relational learning condition. Mean accuracy
      Participants in the verbal dual-task condition were first     on the visual dual task was M = 0.91 (SD = 0.06) for the
given a verbal working memory task, in which 5 random               featural condition, and M = 0.89 (SD = 0.04) for the
digits were displayed for two seconds with spaces between           relational condition. There was no reliable difference
them (so that they appeared to be individual numbers rather         between the verbal and visuospatial tasks [t(51) = 1.61, p
than digits of a single number). Participants were asked to         = .114], suggesting that these tasks occupied cognitive
memorize the digits while they performed the categorization         resources to roughly the same extent.
task. In the categorization task, an exemplar consisting of a
rectangle and an ellipse was shown. Participants were               Category learning task accuracy: trials to criterion.
instructed to press the A key if the stimulus belonged to           Since our primary interest is the rate at which participants
category A and the L key if it belonged to L. Each exemplar         learn the categories as a function of the dual tasks, we report
                                                                700

our data first in terms of trials to criterion. These analyses            [t(35) = -2.037, p < 0.05], indicating that response times in
are conservative in the sense that participants who never                 visuospatial feature-learning condition were longer than
learned to criterion were treated as though they reached                  those in verbal feature-learning. No other differences were
criterion on the last block. Figure 4 shows the mean trials to            statistically reliable. There were no reliable differences in
criterion by condition. A 3 (dual task) × 2 (category learning            the relational learning condition. Also, ANOVA showed a
task) between-subjects ANOVA revealed a main effect of                    reliable main effect of category learning [F(1, 69) = 3.883,
dual task [F(2, 69) = 5.058, MSE = 579014.858, p < 0.01].                 MSE = 1.166, p = 0.053], indicating that feature learning
Since our main interest is in how different dual tasks affect             (M = 1.17, SD = 0.55) was marginally faster than relational
the different kinds of category learning, one-way ANOVAs                  learning (M = 1.42, SD = 0.56) (Figure 5).
were conducted for the featural and relational learning
conditions. The results revealed reliable differences between
dual tasks in the featural category learning condition                                               900
                                                                                                                **           Control
[F(2,35) = 4.981, MSE = 617725.846, p < 0.05]. Planned                                                                       Verbal
                                                                                                     800
comparisons in the featural category learning showed that                                                              *     Visual
there was a reliable difference between the verbal (M = 386,                                         700
SD = 387) and visuospatial dual task (M = 697, SD = 411)
[t(35) = -2.288, p < 0.05]. There was also a reliable                                                600
                                                                               Trials to criterion
difference between the visuospatial and the control
condition (M = 262, SD = 191) [t(35) = 3.014, p < 0.01].                                             500                                             **
The difference between the verbal and the control condition                                          400
                                                                                                                                     **
was not reliable [t(35) = 0.877, p < 0.386]. The ANOVA                                                                               **
results from the relational condition revealed reliable                                              300
differences between the dual tasks [F(2,34) = 7.641, MSE =
799483.887, p < 0.01]. Planned comparisons revealed that                                             200
there was a reliable difference between the verbal (M = 739,                                         100
SD = 352) and visuospatial dual task (M = 330, SD = 362)
[t(34) = 3.221, p < 0.01]. There was also a reliable                                                  0
difference between the verbal and control conditions (M =                                                       Feature                   Relation
276, SD = 222) [t(34) = 3.014, p < 0.01]. The difference
between the visuospatial and control conditions was not
reliable [t(34) = 0.404, p < 0.689]. No other main effects                                     Figure 4. Accuracy by category learning condition
were statistically reliable. Most interestingly, there was a
reliable interaction between dual task and category learning,
indicating that relational category learning was disrupted
                                                                                                     1.8    Feature
more by the verbal dual task, whereas featural category
learning was disrupted more by the visuospatial dual task                                            1.6    Relation
[F(2,69) = 2.475, MSE = 855659.946, p < 0.01].
                                                                                                     1.4
Response times. Since the category learning accuracy
                                                                                                     1.2
results yielded a reliable interaction between the dual and
category learning tasks, we also analyzed these tasks in
                                                                             RT(sec)
                                                                                                      1
terms of participants’ mean response times on individual
trials in order to gain insight about the strategies participants                                    0.8
in each condition may have adopted. A 3 (dual task) × 2
(category learning task) between-subjects ANOVA revealed                                             0.6
a main effect of dual task [F(2, 69) = 3.202, MSE = 0.961,
                                                                                                     0.4
p< 0.05]. One-way ANOVAs were also conducted in each
category learning condition. The main effect of dual task                                            0.2
was not reliable [F(2, 35) = 2.137, MSE = 0.612, p = 0.133]
in the featual learning condition. But since the accuracy data                                        0
showed that participants in visuospatial feature-learning                                                    Verbal         Visual               Control
required many more trials than to reach to the criterion than
participants in verbal featural learning, we expected a
reliable difference between two conditions in a planned                                               Figure 5. Response times by dual condition
comparison analysis. Our prediction was confirmed. There
was a reliable difference between the verbal (M = 0.99, SD
= 0.31) and visuospatial dual task (M = 1.41, SD = 0.78)
                                                                    701

                          Discussion                                 Doumas. L. A. A., Hummel, J. E., & Sandhofer, C.
                                                                       M.(2008).A theory of the discovery and predication of
       To the extent that relational concepts are qualitatively
                                                                       relational concepts. Psychological Review, 115, 1 - 43.
similar to feature-based concepts, our understanding of
                                                                     Gentner, D. (2005). The development of relational category
concepts can be expected to generalize from the
                                                                       knowledge. In L. Gershkoff-Stowe & D. H. Rakison,
(extensively investigated) case of feature-based categories
                                                                       (Eds.), Building object categories in developmental time.
to the (largely neglected) case of relational categories.
                                                                       (pp. 245-275). Hillsdale, NJ: Erlbaum
However, there is reason to believe they are not, casting
                                                                     Gentner, D., & Kurtz, K. (2005). Relational categories. In
doubt on our ability to generalize our conclusions from
                                                                       W. K. Ahn, R. L. Goldstone, B. C. Love, A. B. Markman
studies using feature-based categories to the case of
                                                                       & P. W. Wolff (Eds.), Categorization inside and outside
relational concepts.
                                                                       the lab. (pp. 151-175). Washington, DC: APA.
       Most notably, people have no difficulty learning
                                                                     Gick, M. L., & Holyoak, K. J. (1983). Schema induction
feature-based categories in which no single feature remains
                                                                       and analogical transfer. Cognitive Psychology, 15, 1-38.
invariant across all members of a category (see Murphy,
                                                                     Goldwater, M. B., Markman, A. B., & Stilwell, C. H.
2002). By contrast, Kittur and colleagues showed that
                                                                       (2011). The empirical case for role-governed categories.
relational categories are extremely difficult to learn when
                                                                       Cognition, 118, 359-376.
there is no such relational invariant (i.e., property that holds
                                                                     Hummel, J. E. (2010). Symbolic vs. associative
over all members of a category; Kittur et al., 2004, 2006).
                                                                       learning. Cognitive Science, 34, 958-965.
Jung and Hummel (2009, 2011) provided additional
                                                                     Hummel, J. E., & Holyoak, K. J. (1997). Distributed
evidence that relational learning requires some kind of
                                                                       representations of structure: A theory of analogical access
invariant in order to succeed. These findings suggest that
                                                                       and mapping. Psychological Review, 104, 427-466.
featural and relational learning rely not only on qualitatively
                                                                     Hummel, J. E., & Holyoak, K. J. (2003). A symbolic-
different forms of mental representation (namely, features
                                                                       connectionist theory of relational inference and
vs. relations; see, e.g., Hummel, 2010; Hummel & Holyoak,
                                                                       generalization. Psychological Review, 110, 220-264.
1997, for a discussion of the difference) but also that they
                                                                     Kittur, A., Holyoak, K. J., & Hummel, J. E. (2006). Using
rely on qualitatively different kinds of learning algorithms
                                                                       ideal observers in higher-order human category learning.
(e.g., associative learning in the featural case and something
                                                                       Proceedings of the Twenty Eight Annual Conference of
more akin to structured intersection discovery in the
                                                                       the Cognitive Science Society (pp. 435-440). Hillsdale,
relational case; Jung & Hummel, 2009, 2011).
                                                                       NJ: Lawrence Erlbaum Associates.
       The current experiment provides additional evidence
                                                                     Kittur, A., Hummel, J. E., & Holyoak, K. J. (2004).
for this sharp distinction between featural and relational
                                                                       Feature- vs. relation-defined categories: Probab(alistic)ly
category learning. In the current experiment, featural
                                                                       Not the Same. Proceedings of the Twenty Six Annual
learning was impeded by a visual dual task (i.e., one that
                                                                       Conference of the Cognitive Science Society (pp. 696-
might be expected to interfere with visual feature processing
                                                                       701).Hillsdale, NJ: Lawrence Erlbaum Associates.
as required for featural learning) but not by a verbal dual
                                                                     Jung, W., & Hummel, J. E. (2009) Probabilistic relational
task. Relational category learning, in sharp contrast, was
                                                                       categories are learnable as long as you don’t know you’re
interfered with by a verbal dual task (which has been shown
                                                                       learning probabilistic relational categories. Proceedings of
to interfere with relational processing; Waltz et al., 2000),
                                                                       The 31st Annual Conference of the Cognitive Science
but not by a visual dual task. This double dissociation
                                                                       Society, Society (pp. 1042-1047). Hillsdale, NJ: Lawrence
between visual vs. verbal dual task interference on the one
                                                                       Erlbaum Associates.
hand and featural vs. relational category learning on the
                                                                     Jung, W., & Hummel, J. E. (2011). Progressive alignment
other adds to the growing evidence that these two kinds of
                                                                       facilitates learning of deterministic but not probabilistic
category learning rely on qualitatively different and
                                                                       relational categories. Proceedings of the 33rd Annual
dissociable learning systems.
                                                                       Conference of the Cognitive Science Society.
                                                                     Logan, G. D. (1992). Shapes of reaction time distributions
                                                                       and shapes of learning curves: A test of the instance
                    Acknowledgements                                   theory of automaticity. Journal of Experimental
This research was supported by a grant from the University             Psychology: Learning, Memory and Cognition, 18, 883-
of Illinois Research Board.                                            914.
                                                                     Maybery, M. T., Bain, J. D., & Halford, G. S. (1986).
                                                                       Information processing demands of transitive inference.
                          References                                   Journal of Experimental Psychology: Learning, Memory,
Ashby, F. G., Alfonso-Reese, L. A., Turken, A. U., &                   and Cognition, 12, 600-613.
  Waldron, E. M. (1998). A neuropsychological theory of              Miles, S. J. & Minda, J. P. (2011). The effects of concurrent
  multiple systems in category learning. Psychological                 verbal and visual tasks on category learning. Journal of
  Review, 105, 442– 481.                                               Experimental Psychology: Learning Memory &
                                                                       Cognition, 37, 588-607.
                                                                 702

Murphy, G. L. (2002). The big book of concepts,
  Cambridge, MA: MIT Press.
Taylor, E. G. & Ross, B. H. (2009). Classifying partial
  exemplars: Seeing less and learning more. Journal of
  Experimental Psychology: Learning, Memory, &
  Cognition, 35(5), 1374-1380.
Tomlinson, M.T., & Love, B.C. (2010). When learning to
  classify by relations is easier than by features. Thinking &
  Reasoning,16, 372-401.
Waltz, J. A., Lau, A., Grewal, S. K., & Holyoak, K. J.
  (2000). The role of working memory in analogical
  mapping. Memory & Cognition, 28, 1205-1212.
                                                               703

