UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using Causal Induction in Humans to Learn and Infer Causality from Video
Permalink
https://escholarship.org/uc/item/4ng247kx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Fire, Amy
Zhu, Song-Chun
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

      Using Causal Induction in Humans to Learn and Infer Causality from Video
                                                     Amy Fire (amy.fire@ucla.edu)
                                               Song-Chun Zhu (sczhu@stat.ucla.edu)
                                              Center for Vision, Cognition, Learning, and Art
                                                   University of California, Los Angeles
                                                        Los Angeles, CA 90095 USA
                                Abstract                                 & Tenenbaum, 2007). Grammar models allow for multiple
    For both human and machine learners, it is a challenge to make       configurations and high-level structures, making them more
    high-level sense of observations by identifying causes, effects,     suitable for applications grounded on visual cues; Bayesian
    and their connections. Once these connections are learned, the       networks lack the representative power needed for this.
    knowledge can be used to infer causes and effects where visual
    data might be partially hidden or ambiguous. In this paper,             Grammar models are represented graphically in the And-
    we present a Bayesian grammar model for human-perceived              Or Graph (AOG). In the AOG, Or-nodes represent the mul-
    causal relationships that is learnable from video. Two exper-        tiple alternatives, and And-nodes represent hierarchical de-
    iments investigate high-level causal induction from low-level
    visual cues. In the first experiment, we show that a computer        compositions. The AOG naturally lends itself to represent
    can apply known heuristics used for causal induction by hu-          causation where multiple alternative causes can lead to an ef-
    mans to learn perceptual causal relationships. In the second         fect, and each cause is composed of conditions necessary for
    experiment, we show that our learned model can represent hu-
    mans’ performance in reasoning about hidden effects in video,        the effect.
    even when the computer initially misdetects those effects.              In this paper, we introduce a grammar model for repre-
    Keywords: Perceptual causality; causal induction; statistical        senting causal relationships between actions and object-status
    models.                                                              changes, the Causal And-Or Graph (C-AOG). We describe
                                                                         methods for learning the model by using co-occurrence to
                           Introduction                                  identify potential causal relationships between events and ap-
A man approaches a closed door. He reaches out to grasp the              plying the heuristics listed above to those potential relation-
handle and then stands there. Is it locked? Does he not have             ships. In two experiments, we investigate how the model
the key? He knocks and waits, but the door remains closed.               matches human perceptions of causality. Experiment 1 uses
Is there no one on the other side to open it?                            input typical of computer vision detection systems to investi-
    Watching these events unfold, humans can readily answer              gate learning the C-AOG and human perceptions of causality.
these questions based on their causal knowledge. One way                 Experiment 2 demonstrates that the C-AOG models human
humans can learn causal relationships is through daily ob-               judgments on imputing hidden variables from video.
servation by internally measuring co-occurrence of events
(Griffiths & Tenenbaum, 2005). Research suggests that                               A Grammar Model for Causality
humans use a few heuristics to determine whether a co-
                                                                         In this section, we introduce the Causal And-Or Graph for
occurrence is causal, including:
                                                                         causal reasoning, which ties agent actions to fluents.
• whether the temporal lag between cause and effect is short,
    and the cause precedes the effect (Carey, 2009) and                  Fluents and Actions
                                                                         Specifically defining those object statuses that vary over time,
• whether agent actions are responsible for causes (Saxe,
                                                                         the term fluents comes from the commonsense-reasoning lit-
    Tenenbaum, & Carey, 2005).
                                                                         erature (Mueller, 2006). Relevant here are two kinds of flu-
    However, learning from daily observation is limited: many            ents that intentional agents can change: object fluents (e.g., a
actions and effects are hidden. Our prior knowledge about                light can be on or off) and fluents of the mind (e.g., an agent
causal relationships between actions and effects allows us to            can be thirsty or not thirsty).
fill in information about the events in the scene.                          The values of these fluents change as a result of agent ac-
    Some current models represent knowledge with Bayesian                tions and also trigger rational agents to take action. A lack
networks, e.g., (Griffiths & Tenenbaum, 2005). These mod-                of change-inducing action (also known as the inertial action)
els, however, are disjoint from the low-level visual data that           causes the fluent to maintain its value; for example, a door
people observe. Instead, models are built using high-level an-           that is closed will remain closed until some action changes it.
notations. In reality, agents build knowledge by observing               In this work, fluents are modeled discriminatively.
low-level visual data, and models need to be able to deal with              Actions (Ai ) are modeled using the Temporal And-Or
uncertainty in observation.                                              Graph (T-AOG), a grammar model for actions (Pei, Jia, &
    Although Bayesian networks are commonly used to repre-               Zhu, 2011). In the T-AOG, And-nodes group the necessary
sent causality (Pearl, 2009), grammar models have the ex-                ways for an action to be performed that allow detection of the
pressive power to represent a greater breadth of possibili-              action (e.g., object/agent spatial relations, agent poses, scene
ties than a single instance of a Bayesian network (Griffiths             contexts, and temporal relationships), and Or-nodes provide
                                                                     2297

                                 Door fluent                          Probability on the C-AOG
                                                                      The probability model over the parse graphs in the C-AOG
                   closed                        open                 incorporates the detection probabilities of actions and fluents
                                                                      in a Bayesian manner. In particular, given the video I,
                                                                       P(pgC |I) = P(A1 , . . . An |I)P(∆F1 , . . . , ∆Fm |I)  ∏     P(w(v)) .
                                                                                                                              v∈VCOr
                                                                       | {z } |                            {z               }        | {z }
                                                                         posterior                     likelihood                      prior
       a01     a21     a41       a01                                                                                                         (1)
                                                                      The likelihood term is the detection probability for the in-
                                                                      cluded actions/fluents, and considers actions and fluents in-
             push       pull              exit      unlock   pull     dependently. VCOr is the set of included Or-nodes in the causal
                                                                      explanation, and w(v) returns the selected Or-branch. The
            Fluent           Fluent Transit Action         Action
                                                                      prior term gives the switch probability on the Or-nodes for
                                                                      the alternative causes and is learned by maximum likelihood
                                                                      estimation.
Figure 1: A C-AOG for door status as learned in Experi-
ment 1. The value of the top-level fluent is a consequence            Learning the C-AOG
its children. The fluent transit action nodes indicate the kind       To learn the C-AOG, potential causal relationships are found
of change that occurs in the fluent: step functions for change,       by restricting the set of all possible fluent/action interactions
flat lines for non-change (or inertial action). Action a0 is the      with the set of heuristics listed at the beginning. Actions and
inertial action (a lack of state-changing action). Arcs connect       fluents from all levels of their respective hierarchies are con-
children of And-nodes. It should be noted that each photo             sidered.
represents a further set of child And-nodes from the Tem-                A joint model is iteratively built up from the initial prob-
poral And-Or Graph (not shown). Thickened lines indicate              ability distribution over actions and fluent changes, incorpo-
selections on the Or-nodes that provide a single parse graph.         rating a new causal relationship each iteration. In an iteration,
                                                                      the contingency table of each action-fluent pair (Ai , ∆Fj ), e.g.,
                                                                      Table 1, is examined. The best causal relationship is deter-
the alternative methods of performing the action. While hid-          mined by maximizing the information gain (IG), which is
den Markov models and dynamic Bayesian networks have                  the Kullback-Leibler divergence (KL) (Kullback & Leibler,
also been used for action detection from video, the grammar           1951) between the full contingency table of Table 1 and the
is necessary as it allows representation of high-level struc-         expected contingency table predicted by the model in the cur-
tures and multiple configurations.                                    rent iteration (similar to work on texture modeling (Zhu, Wu,
   Our experiments are conducted using a pre-selected set of          & Mumford, 1997)). In particular, in a single iteration, causal
actions and fluents common to office, hallway, and elevator           relation cr∗ is added to the model where
scenes. Such scenes (and events therein) might be of interest
for surveillance, for example.                                                        cr∗ = argmax IG = argmax KL(f||h),                     (2)
                                                                                                   cr             cr
The Causal And-Or Graph                                               f = ( f0 , f1 , f2 , f3 ), and h is the analogous quantity from the
The Causal And-Or Graph (C-AOG) is a graphical represen-              current iteration’s model. The causal relationships with high-
tation for the grammar of causality. The top levels of one            est information gains are deemed most significant and are col-
C-AOG learned in Experiment 1 are shown in Figure 1.                  lected into the C-AOG.
   In the C-AOG, Or-nodes represent the alternative means
of causation (e.g., a monitor, through the computer, can be                  Table 1: Contingency table of relative frequencies.
turned on by someone using a mouse or a keyboard). Arrows                                             ∆Fj Present     ∆Fj Absent
point from these causing actions to their fluent effects.
   Each And-node is formed from the set of multiple con-                             Ai Present       f0              f1
ditions for the action, including its sub-actions. The action                        Ai Absent        f2              f3
nodes in a C-AOG may be inertial actions (resulting in no
change); unexplained instances of the fluent are also pooled             Our learning method integrates with existing action and
under the inertial action.                                            fluent detection systems, creating a unified framework for the
   A selection on the Or-nodes is called a parse graph, de-           spatial, temporal, and causal domains. Further, our method is
noted pg (such as the paths shown by thicker lines in Fig-            more computationally feasible for large networks of causal
ure 1). It provides a causal interpretation of each fluent’s par-     connections than Bayesian learning frameworks are (with
ticular value at a given time, answering “why” the fluent has         their prior distributions over graph structures). Traditional
that particular value.                                                causal induction as done by constraint satisfaction (Pearl,
                                                                  2298

                           (a) Door                           (b) Light                         (c) Monitor
      Figure 2: Information gains for causal relations in the order pursued, separated by fluent. Green circles label causes.
2009) or Bayesian formulations (Heckerman, 1995) is in-
tractable to ground on vision sensors. Models such as causal
support (Griffiths & Tenenbaum, 2005) learn a new, larger
model each iteration, and the number of possible models
grows exponentially. In contrast, the number of computations
to learn our model is constant each iteration.
          Experiment 1: Learning Causality
In this experiment, we test the model’s ability to learn human-
perceived causal relationships. For testing the algorithm, the
                                                                     Figure 3: Information gains for causal relationships in the
ground truth is established by linking known causing actions
                                                                     order pursued for the light fluent.
to their fluent effects.
Video Data Used
To test learning the C-AOG, videos were collected with a Mi-         Hierarchical Action Selection and χ2 Where compound
crosoft Kinect, recording the color and depth images simulta-        actions (e.g., in the doorway scene, unlocking with a key or
neously. The scenes collected include multiple doorways, an          entering a code, followed by pushing/pulling the door) are
elevator, and an office. Figure 1 shows some screenshots of          required for the effect, the causing actions may be located
the videos. The entire video collection lasts about 120 min-         within varying levels of the action hierarchy.
utes, and contains 21 pre-specified action categories. There            For actions hierarchically related to each other in the Tem-
are 8 to 20 (sometimes simultaneous) instances of each ac-           poral AOG, our model incorporates their dependences, mini-
tion category.                                                       mizing the chance that related actions are selected as causes.
   In this experiment, we first use perfect action and fluent        Figure 4 shows that Hellinger’s χ2 measure (a χ2 that is
detections to demonstrate learning. We compare these results         less sensitive to low expected values in a contingency table
to those obtained with noisy detections (with varying levels         (Ferguson, 1996)) fails to identify the correct causes, unable
of accuracy), such as would be output from the action and            to account for dependence.
fluent detection system.
Results and Discussion
Multiple Fluents Figure 2 shows plots of information gains
for causal relations in the order pursued, separated by flu-
ent. Causes are added to the model before non-causes with
clear cutoffs for the door and light fluents. The cutoff be-
tween cause and non-cause is obscure for the computer mon-
itor fluent because the model only acquired partial causal in-                (a) Our Method                (b) Hellinger’s χ2
formation (the preconditions of power and computer status
are hidden).                                                                Figure 4: Pursuit order for hierarchical causes.
Noisy Data Randomly flipping action detections leads to
the curves shown in Figure 3. As more noise enters the sys-          Long Delay, Causal Power, and ∆P Under the power PC
tem, the information gained by considering causal relations          theory (Cheng, 1997), perceptual causality is calculated as:
decreases. While learning works amid noisy scenes (many
actions happening simultaneously), clean detections are im-                                                 ∆P
portant.                                                                          causal power =                                  (3)
                                                                                                    P(effect|not cause)
                                                                2299

                ···                                                                                                     ···
                          485                  800            2500            2575             5535           6915
                 Frame Number (not to scale)
                                              Figure 5: Sample of human judgment key frames.
where ∆P (Allan, 1980) is given by:                                       The Stimuli
                                                                          Approximately 20 minutes of video data was captured using
          ∆P = P(effect|cause) − P(effect|not cause).              (4)    a Kinect in two scenes: a hallway and an office. Table 2 con-
                                                                          tains a summary of the fluents contained in the video, as well
   For an elevator, the only detectable causing action for the            as the values each fluent can take. While many of these flu-
door opening is pushing the elevator call button. In this ex-             ents are ordinarily viewable, they are ambiguous in the video
ample, our model outperforms causal power as shown in Fig-                (e.g., light status (ambient light may be from a window or a
ure 6. ∆P performs similarly to causal power.                             light) or water stream (resolution is not high enough to see it)
                                                                          in Figure 5).
                                                                             Through a website, volunteer participants (N = 15) were
                                                                          shown the test video which paused at preset frames, e.g.,
                                                                          those shown in Figure 5. Query points surround either a
                                                                          change in a fluent or a causing action. At each key frame,
                                                                          the participant was asked to assign a total of 100 points to
                                                                          all possible values of each fluent, according to his/her own
                                                                          recognition and reasoning for the events. Assignment of the
          (a) Our Method                     (b) Causal Power
                                                                          points corresponded to the subjective probabilities of the flu-
                                                                          ent values. Each participant was allowed to revise previous
        Figure 6: Pursuit order for the elevator scene.                   judgments with information derived from subsequent frames.
   The failure of causal power and ∆P originates when an ob-              Reference Estimates
served event (e.g., walking away) coincidentally always oc-               We compare the human responses to predicted fluent values
curs with the true cause (e.g., pushing the elevator call button)         by a baseline random noise model and by the C-AOG.
and the true cause is not perfectly detected. Both measures
favor 100% correlation, despite how rarely it occurred in the             Baseline Estimate (Random Noise). For a baseline esti-
video. The learning method presented here incorporates the                mate, the hidden fluents were randomly assigned uniformly,
frequency that the relationship is observed by examining the              without using any detection or causal information (e.g., 50%
full contingency table.                                                   for LIGHT ON and 50% for OFF). The baseline estimate
                                                                          provides a discriminative reference against which we can see
Further Discussion                                                        how well our model approximates human judgments.
Results match exactly with human perceptions of the causal                Computer Estimate (The C-AOG). Detectable actions
connections between actions and fluent changes, showing that              and fluent changes are first extracted from the videos and used
the C-AOG is learnable from co-occurrence and the heuristics
listed in the beginning (short temporal lag and agent actions
cause fluent changes).                                                                   Table 2: List of fluents considered.
   Our results are limited to the action and fluent categories                            Computer: ASLEEP/AWAKE
that are pre-specified, despite the fact that many potentially                            Monitor Display: ON/OFF
confounding actions were included. Those quantities must                                  Monitor Power: ON/OFF
be specified in advance so that appropriate detectors can be                              Cup: MORE/LESS/SAME
trained. It is possible, however, that different people would                             Water Stream: ON/OFF
produce different bottom-level actions and fluents.                                       Light: ON/OFF
                                                                                          Phone: ACTIVE/STANDBY
        Experiment 2: Inference Experiment                                                Trash Can: MORE/LESS/SAME
                                                                                          Agent : THIRSTY/SATIATED
In this experiment, our model is validated against humans in
                                                                                          Agent: HAS TRASH/NOT
the long-term reasoning task of inferring hidden fluent values.
                                                                      2300

                                                                                                                                                                                Non-maximum
                                                                                                                                                                                suppression
                                            Figure 7: Sample screenshots for noisy data.
as inputs to the C-AOG model.                                                                                                   (a) Hallway Dataset                                                                       (b) Office Dataset
                                                                                                                                                                                                  40
   The action grammar is pre-specified. Actions are manu-
                                                                                                       40
ally segmented, and then poses captured by the Kinect cam-                                                                                                                               ●
                                                                                                                                                                                                  20                  ●
era are clustered. Temporal parsing transforms the clustered
poses into hierarchically-labeled instances from the T-AOG.                                            20    baseline
                                                                                                                                                                                                         ● ●
                                                                                                                                                                                                              ●
                                                                                                                                                                                                         ●                                     com
The maximum probability action detections are used as input.                                                            ●
                                                                                                                                                               ●
                                                                                                                                                                           ●    ●                 0      ●●● ●
                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                           ●
   Fluent changes are detected from the video with the Gen-                                            0
                                                                                                                                                                   ●
                                                                                                                                                                       ●
                                                                                                                                                                       ●
                                                                                                                                                                                                                              ●
                                                                                                                                                                       ●                 ●                        ●
tleBoost algorithm (Friedman, Hastie, & Tibshirani, 2000) on                                                                    ●
                                                                                                                                                                       computer
                                                                                                                                                                                                  −20
                                                                                                                                                                   ●
features extracted as shown in Figure 7. Non-maximum sup-                                              −20
                                                                                                                                              ●                                 ●
                                                                                                                                                                                                                                       ●
                                                                                                                                                                                                                                    human
                                                                                                                                                       ●
pression provides the final detections of fluent changes.                                                                                         human
                                                                                                                                                                                                  −40
   These action and fluent detections (and their probabilities)
are then processed with potential causal explanations under                                                         −40                 −20                    0                    20                  −20               0       20
the C-AOG (by maximizing the posterior probability of(a)Equa-
                                                          Hallway Dataset                                                           (b) Office Dataset
                                                                                                       40
tion 1). The best-performing consistent causal description
                                             40
over the course of the video is then returned through the                                          ●
Viterbi algorithm (Forney Jr, 1973). Hidden fluents are im-                                            20                   ●
puted from this result.                      20  baseline                                                           ●                                                               baseline
                                                                                                                ● ●
                                                                                                                ●
                                                                                                                                                               ●   computer
                                                                                      ●   ●            0        ●●● ●
Results and Discussion                                 ●
                                                                          ●                                             ●
                                                                                                                                         ●
                                             0                                    ●
                                                                              ●
                                                                                  ●
To visualize the results, human, computer, and baseline esti-                     ●
                                                                                  computer
                                                                                                   ●
                                                                                                       −20
                                                                                                                        ●
                                                           ●
mates are reduced to two dimensions using multi-dimensional      ●            ●           ●
                                                                                                                                                           ●
                                             −20                                                                                                   human
scaling (MDS) according to the total variation distance be-human      ●
                                                                                                       −40
tween estimates, and plotted in Figure 8.
   In the hallway dataset, both fluent and action−40detections
                                                          −20  0                              20              −20                   0             20                       40                60
contribute to the causal inference of hidden fluents. The com-
puter performance is very similar to human performance as                     Figure 8: MDS plots of fluent value estimates. Blue dots:
shown in Figure 8(a). The baseline is far from the cluster of                 human estimates. Red squares: estimates using the C-AOG.
computer and human estimates.                                                 Green triangles: baseline estimates. See Further Discussion
   The office dataset only contains detections of actions; all                for notes on the human variability.
fluents are hidden. The computer’s performance is still an
improvement over the baseline towards human-level perfor-
mance, as shown in Figure 8(b).                                               capable of maintaining multiple interpretations; the C-AOG
Misinformation: Correcting Spatio-Temporal Detections                         result included both solutions.
In the hallway dataset, multiple changes in the light fluent
                                                                              Further Discussion
were detected, yet no causing action was detected, present-
ing a common situation in vision—detections are usually im-                   Even though the set of possible fluent values was provided
perfect. The C-AOG corrects these errors by balancing the                     to participants (significantly narrowing their available judg-
maintenance of detections with the consistency of causal ex-                  ments), the MDS plots show wide variation in human re-
planations. Figure 9 shows typical candidates of the results                  sponses. This is due to many factors. First, some participants
sorted in order of probability.                                               initialized fluent values differently (e.g., light ON versus OFF
   The C-AOG result was consistent with human judgments.                      in Figure 5), resulting in a large total variation distance. Also,
Humans selected a single value for the light fluent for the du-               some participants were more cautious than others, recording
ration of the video, but some selected ON while others chose                  judgments close to 50/50 where others took an all-or-nothing
OFF. This reinforces the need to have a probabilistic model                   approach to assigning judgments.
                                                                     2301

                                  No Action Detected!
                        ST
              Detections
              1st Class of
         Interpretations
                                                                                                         * Touch Switch * Touch Switch
              2nd Class of
          Interpretations
                   Frame Number              1345     1347 1348 1352    10333     10335    11877   11881       11941     11949
                   (not drawn to scale)
Figure 9: Given action and fluent detections that move the light fluent between ON and OFF without a causing action, the
C-AOG prefers this to be explained by incorrect detections of the light fluent. The second most probable class of explanations
is that two of the changes had causing actions that were missed by the detection.
   As evidenced by the C-AOG’s weaker performance, the of-            Cheng, P. (1997). From covariation to causation: A causal
fice dataset was particularly challenging. Action detections            power theory. Psychological review, 104(2), 367.
were poor and no fluent detections were available to identify         Ferguson, T. (1996). A course in large sample theory: Texts
conflicts, leaving the system heavily dependent on those in-            in statistical science (Vol. 38). Chapman & Hall/CRC.
correct action detections. Despite this disadvantage, the C-          Forney Jr, G. (1973). The viterbi algorithm. Proceedings of
AOG still provided enough reasoning capability to outper-               the IEEE, 61(3), 268–278.
form the baseline. This example underscores the importance            Friedman, J., Hastie, T., & Tibshirani, R. (2000). Addi-
of good vision-detection systems.                                       tive logistic regression: a statistical view of boosting (with
                                                                        discussion and a rejoinder by the authors). The annals of
                   Conclusions and Next Steps                           statistics, 28(2), 337–407.
In this paper, we have presented a probabilistic graphical            Griffiths, T., & Tenenbaum, J. (2005). Structure and strength
grammar model to match human perception of causal re-                   in causal induction. Cognitive Psychology, 51(4), 334–
lationships between actions and fluent changes, the Causal              384.
And-Or Graph (C-AOG).                                                 Griffiths, T., & Tenenbaum, J. (2007). Two proposals for
   Experiment 1 showed that the C-AOG of everyday activ-                causal grammars. Causal learning: Psychology, philoso-
ities can be learned, matching human perceptions of causal              phy, and computation, 323–345.
relationships. These causal relationships are even learnable          Heckerman, D. (1995). A bayesian approach to learning
amid noise, such as would be present in detection systems.              causal networks. In Proceedings of the eleventh conference
Further, experiment 1 showed that our method models human               on uncertainty in artificial intelligence (pp. 285–295).
judgments better than causal power and ∆P.                            Kullback, S., & Leibler, R. (1951). On information and suf-
   Experiment 2 showed that the C-AOG can be used as a                  ficiency. The Annals of Mathematical Statistics, 22(1), 79–
model of human perception grounded on video to impute val-              86.
ues for hidden fluents. This experiment captures the inherent         Mueller, E. T. (2006). Commonsense reasoning. San Fran-
variability of human estimations when confronted with video,            cisco, CA, USA: Morgan Kaufmann Publishers Inc.
and highlights the need for a model that can probabilistically        Pearl, J. (2009). Causality: Models, reasoning and infer-
incorporate causality and vision.                                       ence (2nd ed.). New York, NY, USA: Cambridge Univer-
   One current limitation of the C-AOG is that, if a situation          sity Press.
is unexplained, all possible parse graphs are assigned a low          Pei, M., Jia, Y., & Zhu, S.-C. (2011). Parsing video events
probability. In future work, we plan to investigate how adap-           with goal inference and intent prediction. In Computer
tive learning can be used to incorporate new instances of flu-          vision (iccv), 2011 ieee international conference on (pp.
ents into the C-AOG.                                                    487–494).
                                                                      Saxe, R., Tenenbaum, J., & Carey, S. (2005). Secret agents
                           Acknowledgments                              inferences about hidden causes by 10-and 12-month-old in-
This work is supported by ONR MURI grant N00014-10-1-                   fants. Psychological Science, 16(12), 995–1001.
0933.                                                                 Zhu, S.-C., Wu, Y., & Mumford, D. (1997). Minimax entropy
                                                                        principle and its application to texture modeling. Neural
                                  References                            Computation, 9(8), 1627–1660.
Allan, L. (1980). A note on measurement of contingency
   between two binary variables in judgment tasks. Bulletin
   of the Psychonomic Society, 15(3), 147–149.
Carey, S. (2009). The origin of concepts. Oxford University
   Press.
                                                                  2302

