UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Frequent Frames, Flexible Frames and the Noun-Verb Asymmetry.
Permalink
https://escholarship.org/uc/item/62467501
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Freudenthal, Daniel
Pine, Julian
Jones, Gary
et al.
Publication Date
2013-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                Frequent Frames, Flexible Frames and the Noun-Verb Asymmetry
                                                 Daniel Freudenthal, Julian Pine
                                            School of Psychology, University of Liverpool
                                                                Gary Jones
                                         School of Psychology, Nottingham Trent University
                                                             Fernand Gobet
                                            School of Psychology, University of Liverpool
                              Abstract                                  terms of the grammatical category of the items that occur
   In this paper we compare several mechanisms for using
                                                                        in the central position. The notion of a frequent frame is
   distributional statistics to derive word class information.          therefore thought to provide a powerful cue that children
   We contrast three different ways of computing statistics for         might employ in the acquisition of syntactic categories.
   independent left and right neighbours with the notion of a           More recent work has confirmed the utility of frequent
   frequent frame. We also investigate the role of utterance            frames for French (Chemla et al. 2009), but results have
   boundaries as context items and weighting of frequency               been less promising for languages with relatively free
   information in terms of the successful simulation of the             word order such as Dutch (Erkelens, 2009) and German
   noun-verb asymmetry. It is argued that independent
   contexts can classify items with a higher degree of                  (Stumper et al. 2011).
   accuracy than frequent frames, a finding that is more                   A major difference between the approaches of
   pronounced for larger input sets. Frequent frames classify a         Redington et al. and Mintz is that the approach described
   larger number of items, but do so with lower accuracy.               by Redington is inherently graded and frequency sensitive
   Utterance boundaries are useful for the development of a             in nature. Thus, in this approach, co-occurrence statistics
   noun category, particularly at intermediate levels of                are collected across all uses of a particular word.
   frequency sensitivity.
                                                                        Depending on the exact implementation, the approach can
   Keywords: Word class derivation, independent contexts,               also show varying degrees of frequency sensitivity with
   frequent frames.                                                     context vectors containing (rank orders of) word counts.
                                                                        Similarity is then expressed as a correlation-like measure
                          Introduction                                  across context vectors, which can be interpreted as a
Several authors have shown that distributional statistics               probability of two items being of the same class. This
can provide powerful cues for acquiring syntactic                       graded context-sensitivity is absent from Mintz’s
categories; words that belong to the same syntactic                     approach. Thus, while Mintz’s analysis is restricted to the
category tend to be preceded and followed by the same                   45 most frequent frames, it clusters together all items that
words. Thus, nouns tend to be preceded by determiners                   co-occur in one of these frames. The approach therefore
and adjectives and followed by verbs. Redington, Chater                 ignores many contexts in which a word may occur, and
and Finch (1998), building on work by Chater and Finch                  instead clusters items on the basis of (potentially one)
(1992), investigate several variants of the same basic                  occurrence in specific high frequency contexts.
principle: for any of a set of target words, a context vector              Typically, mechanisms for extracting grammatical
was derived that contained (rank orders of) counts of the               categories are evaluated in terms of accuracy (the extent
150 most frequent words in the corpus, in positions                     to which items that are clustered together belong to the
preceding and following the target words. Redington et al.              same syntactic category) and completeness (the extent to
computed correlations between the context vectors of the                all items within one syntactic category are clustered
target words, which were then used as input to a                        together). St. Clair et al. (2010), as well as Monaghan
Hierarchical Cluster Analysis, and concluded that the                   (2004), compared frames and independent contexts as
resulting classes mapped closely onto broad syntactic                   used by Redington et al. in the context of connectionist
classes. Redington et al. explore a number of variants of               simulations, and found that frames were accurate but
the basic mechanism, but get their best results by using a              resulted in low completeness while independent contexts
context of one preceding and one following word, and                    performed similarly in terms of accuracy but
using a rank order correlation as their distance measure.               outperformed frames in terms of completeness.
   An alternative mechanism for acquiring syntactic                        However, while high accuracy is clearly a desirable
categories has been proposed by Mintz (2003). Mintz                     property of a mechanism that derives syntactic categories
introduces the notion of a frequent ‘frame’: two lexical                (children for instance make very few word class errors), it
items with one word intervening (e.g. He X to). Mintz                   is less clear if high completeness is desirable, particularly
argues that the (45) most frequent frames in the (English)              if one is interested in modeling children’s early linguistic
corpora he analyses show high internal consistency in                   abilities. Thus, while children ultimately develop
                                                                   2327

linguistic abilities that suggest the presence of relatively      and 3. Cosine similarity based on the square root of
abstract linguistic categories, their early multi-word            frequency counts. These three different measures differ
speech has been characterized as lexically specific.              with respect to the weighting of frequency information,
Moreover, completeness is often measured across word              which is highest for cosine similarity based on raw counts
classes, when there appear to be developmental                    and lowest for rank orders. Weighting of frequency
discontinuities in children’s productive use of                   information is even lower for frequent frames: this
grammatical categories. Thus, children appear to be more          measure only considers whether or not target words co-
prepared to produce novel nouns than novel verbs in               occur within a given frame, not how often they co-occur.
familiar contexts (Akhtar & Tomasello, 1997), a finding
which has led to the suggestion that children may develop                                  Corpora
a productive noun category earlier than a productive verb         The analyses were performed on the child-directed speech
category (Tomasello, 2000).                                       of the 12 children in the Manchester corpus (Theakston et
   On the basis of these considerations, it would seem that       al., 2001). The child-directed speech in the Manchester
a mechanism that is plausibly employed by language                corpus is typically in the range of 25,000 to 30,000
learning children is one that favours accuracy over               utterances per child. Corpora were cleaned up minimally,
completeness and favours the linking of high numbers of           and only multi-word utterances were analysed. For all
nouns over the linking of high numbers of verbs. One              corpora the following statistics were collected: for every
factor that might impact on the relative likelihood of            word in the corpus, counts were collected for the items
linking nouns and verbs is the weighting of frequency             that preceded and followed it, as well as the frames (A X
information. Nouns for instance have a relatively high            B) that surrounded them. Frame counts were then tallied
likelihood of being preceded by one of a small set of             across words to determine overall counts for (frequent)
determiners. A second factor that is likely to affect the         frames.
relative linking of nouns and verbs is the availability of           One additional manipulation involved the merging of
utterance boundaries as framing elements. Nouns have a            the corpora for the 12 individual children into one large
relatively high likelihood of occurring in utterance final        corpus. This manipulation was included to determine
position, and the utterance boundary is thus a potentially        whether the mechanisms under investigation are
powerful cue for a noun category. Freudenthal et al.              differentially affected by changes in corpus size.
(2008), in the context of connectionist simulations,                 For the purpose of determining accuracy of derived
provide some evidence in support of this suggestion.              word pairings, words were assigned their respective Part
   The main aims of this paper then are as follows: 1. To         of Speech (POS) tag as employed on the %mor coding
compare frequent frames and measures similar to those             tier of the corpus. POS tags in the Manchester corpus are
used by Redington et al. (1998) in terms of their ability to      relatively detailed and distinguish between main verbs
simulate the word classes apparent in children’s early            and auxiliaries, as well as nouns, pronouns and proper
speech, 2. To investigate how different levels of                 nouns. The categories employed here are therefore similar
frequency sensitivity as well as the availability of              to what Mintz terms ‘expanded’ labelling. Where multiple
utterance boundaries may impact on these mechanisms.              POS tags were used for one word form (e.g. forms that
                                                                  can be used as either noun or verb) the most frequently
              Similarity measures used                            used POS tag was assigned. That is: words forms were
In the current paper we compare 4 different measures of           assigned to the grammatical category in which they were
similarity. We consider the frequent frames approach              used most frequently.
described by Mintz (2003), as well as 3 different
implementations of the independent contexts approach                                        Results
described by Redington et al. (1998). In line with                   There are several ways in which one can evaluate the
Redington et al., we considered as target words (i.e.             success of different similarity measures. Redington et al.
words to be classified) the 1000 most frequent words in           (1998) performed a cluster analysis, and plotted accuracy
the corpus. The frequent frames approach closely                  and completeness as a function of the similarity level (or
followed the implementation by Mintz: we considered the           number of clusters extracted). While this is informative, it
target words that co-occurred in the 45 most frequent             does raise a number of problems in interpreting the
lexical frames within a corpus. The implementations of            outcome. First, it is not immediately obvious at what
independent contexts closely followed the implementation          similarity level one should compare different
of Redington et al. The context for a given word was              mechanisms, and second, the clustering process itself can
encoded as a vector of length 300 consisting of counts of         be performed in different ways which have the potential
the 150 most frequent words in the corpus in the position         to influence the results in terms of accuracy and
directly preceding and following the target word. The             completeness. For these reasons we opted to sidestep the
actual similarity measures based on these vectors were: 1.        clustering process, and perform a more direct evaluation
Spearman rank order correlation (as used by Redington et          of the similarity scores. This was done by extracting all
al); 2. Cosine similarity based on raw frequency counts;          possible word pairs, and computing the relevant similarity
                                                             2328

                    Table 1: Accuracy and number of classified words for the four different distance measures.
                       Cos-Sim, Raw Freq            Cos-Sim. Sqrt Freq       Spearman rank order          Frequent Frames
                        Acc.             N           Acc.            N         Acc.           N           Acc.           N
          Anne           .90           1555           .92          2367         .91          1314          .69         8688
          Aran           .95            596           .94          2046         .92          1772          .66        23612
          Becky          .83            565           .82          1718         .88          1746          .71         5423
           Carl          .88            576           .92          2113         .92          1894          .70         6191
        Dominic          .81            409           .84          1418         .84          1313          .62         7904
           Gail          .84            355           .89          1223         .91          1152          .59         8381
            Joel         .76            329           .86          1063         .90          1089          .60         7182
           John          .76            326           .83          1938         .85          2570          .73         9269
            Liz          .78            340           .83          1171         .85          1546          .66         5354
          Nicola         .78            356           .89          1115         .91          1272          .62         9949
          Ruth           .92            276           .91           910         .89          1024          .61         8089
         Warren          .79            403           .84          1199         .86          1222          .70        14405
         Average         .84            507           .87          1523         .89          1492          .66         9537
         Merged          .93           1559           .95          9561         .93          8636          .55        76676
metrics for every word pair. Where a similarity metric                   the relevant corpus. Word pairs that co-occurred in
exceeded a certain threshold the word pair was considered                multiple frames were counted only once.
to belong to the same category.                                             Looking at the individual children and their average in
   This procedure obviously raises the question of what                  Table 1, it is obvious that there are substantial differences
threshold should be chosen for the different similarity                  between the different metrics. Frequent frames classify a
metrics. Generally, higher values for the threshold will                 large number of pairs, but do so at relatively low
result in higher levels of accuracy and lower numbers of                 accuracy. Accuracy levels for frequent frames are lower
classified items, but these numbers may differ across                    than reported by Mintz (who reports a type accuracy of
metrics for a specific value of the threshold. For this                  .91). This lower accuracy is at least partly caused by the
reason, we decided to choose a different value for the                   fact that, for the current analyses, words were assigned to
threshold across metrics such that the resulting accuracy                their most common category. While such a procedure
was always relatively high (~ 90%) and comparable                        makes sense for graded measures that collate statistics
across the metrics1, thus allowing for a meaningful                      over different contexts, it may be less appropriate for the
interpretation of differences in completeness. Table 1                   frame style analysis. Thus several words can be used as
shows percentage accuracy as well as number of                           either a noun or a verb (e.g. pull, paint). In the corpora
classified items for the 12 individual children in the                   employed here, pull is overwhelmingly used as a verb,
Manchester corpus, the average for these children as well                while paint is used as a noun more often than a verb (and
as scores for the merged Manchester corpus.                              as a consequence, is considered to belong to the noun
   The concept of a threshold for classification is                      class for the current analyses). The frequent frames
irrelevant for frequent frames (thus making it impossible                analysis will classify these items together (resulting in a
to peg accuracy at 90%), as the notion of a frame entails                false alarm) because they co-occur in the frame you X
that two items that co-occur in one of the frequent frames               your.
are of the same word class. Table 1 therefore lists                         For this reason we performed a second, contextual
accuracy and number of classified items for all word pairs               accuracy analysis on the frames analysis: for every word
that co-occurred in one of the 45 most frequent frames in                pair that co-occurred in one of the frequent frames, we
                                                                         considered the actual category of the word within the
                                                                         (most frequent) frame. This analysis resulted in accuracy
   1
     The actual threshold levels were chosen to result in accuracy       scores (.76 on average) that were higher than in the
levels close to 90% on the basis of a pilot study and were set at        standard analysis, but still lower than those attained by the
.95 for raw cosine similarity, .70 for sqrt cosine similarity, and       probabilistic measures.
.50 for rank order correlation. The same thresholds were used
                                                                            A comparison of the probabilistic measures also reveals
throughout the analyses reported in this paper. Pilot work
furthermore suggested that the accuracy of the different                 differences. Spearman rank-order and square root cosine
measures was similarly affected by proportional threshold                similarity classify a similar number of items at similar
variations.                                                              levels of accuracy. Raw cosine similarity on the other
                                                                    2329

hand only classifies around a third of the number of items           Table 2: Proportion of noun-noun pairings relative to
that the other probabilistic measures classify.                          noun-noun plus verb-verb pairings (total N in
   Looking at the results for the merged corpus, it                     parentheses), excluding utterance boundaries.
becomes apparent that all four measures classify a larger        NV-ratio       Cos-       Cos-Sqrt Spearman        Frames
number of items. The three probabilistic measures                                Raw
however, do so with slightly higher accuracy than for the           Anne         .99          .93         .63          .34
individual children, while the frequent frames measure                         (1387)       (2084)      (1068)       (5836)
shows a decrease in accuracy (66% vs. 55%, and 76% vs.              Aran         .99          .84         .67          .55
69% for the contextual score). Thus, it appears that the                        (560)       (1784)      (1440)      (15222)
merged corpus contains additional information that can be          Becky         .99          .91         .66          .03
successfully employed by the probabilistic measures but                         (461)       (1349)      (1421)       (3685)
not the frequent frames measure. The increased                      Carl         .99          .89         .72          .01
information in the merged corpus is actually detrimental                        (507)       (1885)      (1652)       (3964)
to the accuracy score for frequent frames. This latter            Dominic        .97          .83         .48          .02
finding appears to be caused by the fact that the frequent                      (316)       (1040)       (937)       (4499)
frames approach is overly sensitive to the occurrence of            Gail         .96          .89         .67          .02
‘stray’ words within the frequent frames. The fact that a                       (284)        (975)       (888)       (4452)
word needs to occur only once within a specific frame to            Joel         .99          .85         .63          .02
be clustered with all other words within that frame means                       (237)        (831)       (853)       (3828)
that infrequent words that are atypical of a particular             John         .99          .90         .79          .40
frame can potentially exert undue influence on overall                          (246)       (1566)      (2104)       (6378)
accuracy scores. This problem becomes more pronounced
                                                                     Liz         .97          .91         .80          .10
in larger corpora. Such effects are less of a problem for
                                                                                (250)        (894)      (1169)       (3214)
the probabilistic measures.
                                                                   Nicola        .96          .74         .56          .16
                                                                                (275)        (907)      (1049)       (6056)
                The noun-verb asymmetry
                                                                    Ruth         .99          633         .85          .04
It was argued earlier that children are more willing to use                     (244)        (746)       (790)       (4645)
novel nouns in known contexts than they are to use verbs.         Warren         .98          .76         .47          .52
This finding has been taken as evidence that children                           (311)        (904)       (927)       (9565)
develop a productive noun category earlier than they
develop a verb category. In this section, we examine to
                                                                  Average        .98          .87         .66          .28
what extent the different metrics show a preference for
                                                                                (432)       (1247)      (1191)       (5945)
the clustering of nouns and verbs. This was done by
examining the ‘hits’ from the data in Table 1, and
                                                                  Merged         .99          .80         .67          .57
counting the number of noun-noun and verb-verb pairs.
                                                                               (1426)       (8577)      (7319)      (63747)
The resulting data (proportion of noun-noun pairs relative
to noun-noun + verb-verb pairs) are displayed in Table 2.
   It is clear from Table 2 that the measures that are most
                                                                            The role of utterance boundaries
frequency sensitive cluster the highest proportion of
nouns. Thus, cosine similarity based on raw frequencies          The analyses reported in Table 1 and 2 only considered
clusters a relatively low number of items but these items        ‘lexical contexts’. That is, only words were considered as
consist almost exclusively of nouns. Square Root Cosine          context items. The following set of analyses included the
similarity and rank order correlation are equally                beginnings and ends of utterances as context items.
productive in terms of the number of items they classify,        Redington et al. (1998) do consider utterance boundaries
with the more frequency sensitive Cosine Similarity              as context items in one of their analyses (and conclude
linking more nouns. Frequent frames on the other hand            that they are potentially useful), but the non-parametric
overwhelmingly link verbs. It is also apparent from Table        nature of their distance metric (rank order correlations)
2 that, for frames, there is considerable variation in the       may underestimate the potential utility of utterance
proportion of noun-noun pairings: Aran’s proportion is           boundaries.
highest at 55%, but half the children show a proportion of          Mintz (2003) does not consider utterance boundaries,
noun-noun pairings under 5%.                                     and it could be argued that there is little reason to
                                                                 consider them. Intuitively, the appealing feature of frames
                                                                 is that (because of their lexical nature) they are highly
                                                                 constraining and hence likely to result in relatively high
                                                                 accuracy. Allowing utterance boundaries in frames limits
                                                                 their constraining nature and may thus reduce accuracy
                                                                 levels. At the same time, however, frames including
                                                            2330

utterance boundaries have the potential to capture large             The analyses presented here suggest that independent
numbers of nouns (e.g. The X end$) and thus might serve           contexts result in better predictions than frequent frames.
to counteract the verb bias apparent in Table 2. Table 3          Frequent frames classify a larger number of words, but do
shows the accuracy scores and number of word pairings             so with lower overall accuracy.
for the analysis that include the utterance boundary as a            Apart from being more accurate, the mechanisms based
framing element. The proportion of noun-noun pairings             on independent contexts also cluster more nouns than
relative to noun-noun plus verb-verb pairings are shown           verbs. This appears to be consistent with the suggestion
in Table 4. For reasons of brevity, Tables 3 and 4 do not         that children form a productive noun category earlier than
present data for the individual children in the Manchester        they form a verb category. The reverse is true of frequent
corpus, but only the average and merged data across the           frames:      across    the    corpora     frequent    frames
12 children.                                                      overwhelmingly cluster verbs rather than nouns, with
                                                                  noun-noun pairings making up under 5% of pairings for
       Table 3: Proportion correct and number of word             half the corpora.
          pairings including utterance boundaries.                   When considering large input sets (i.e. the merged
             Cos-raw       Cos-Sqrt Spearman Frames               Manchester corpus), it becomes obvious that the
Average          .82          .90         .90         .49         mechanisms employing independent contexts are able to
               (862)        (5739)      (3163)     (81351)        utilize the additional information contained in larger data
                                                                  sets to classify a larger number of items with similar
 Merged          .85          .91         .92         .28         levels of accuracy. The frequent frames mechanism also
              (4098)       (23271)     (11271)    (316651)        classifies a larger number of items when employed on a
                                                                  larger data set, but does so with lower accuracy. This
It is evident from Table 3 that the probabilistic measures        result suggests that one of the strengths of frequent frames
deal well with the addition of the utterance boundary as a        — its ability to quickly categorize a relatively large
framing element. Accuracy levels are comparable to those          number of items on the basis of limited data — becomes a
shown in Table 1, while the number of word pairings has           weakness when faced with larger datasets. Thus, the fact
increased by a factor 2 to 3. Inspection of Table 4               that the approach does not consider the frequency with
furthermore indicates that the increase in completeness is        which items occur in the target frames, results in it being
largely the result of increased linking of noun pairs. This       relatively brittle and sensitive to noise and infrequent
is particularly noticeable in the square root cosine              items in the input.
similarity model, which links twice as many words as the             As an illustration, consider the frame You X to, which is
rank order model. Thus, the average square root cosine            the most frequent frame for the corpus of Carl as well as
similarity model links over 4700 noun-noun pairs,                 the merged Manchester corpus. Within Carl’s corpus this
compared to ~1900 for the rank order model. This                  frame contains 22 unique words, of which 20 (or 91%)
difference reflects the greater frequency sensitivity of the      are verbs. Across the Manchester corpus, the same frame
cosine model, and suggests that square root of raw                contains a total of 89 unique words of which 67 (or 75%)
frequency represents an optimum level of frequency                are verbs. This increase in non-verbs has a marked impact
sensitivity.                                                      on the accuracy for the frame which drops from .74 to .49.
                                                                  Many of the non-verbs occurring in the frame are
      Table 4: Number of noun-noun pairings relative to           legitimate (but infrequent) fillers for the frame (e.g. back,
             noun-noun plus verb-verb pairings,                   off, down, happy, ready, anything, something, just, how,
                 including utterance boundaries.                  over, not, one), while others are slightly more exotic: that
NV-ratio Cos-raw Cos-Sqrt Spearman                 Frames         (from we brought you that to help you), tomorrow (from
 Average          .99         .95         .77         .83         who’s taking you tomorrow to playgroup) to somewhat
                (677)       (4957)      (2501)     (38097)        bizarre: card (from a thank you card to give you).
                                                                     Since noisiness is an inherent property of the speech
 Merged           .99         .90         .67         .72         signal, which contains frequent repetitions, retracings and
               (3256)      (19924)      (9558)     (82924)        restarts, this finding suggests that frequent frames may
                                                                  not be a suitable source of information for category
                                                                  extraction unless combined with some sort of ‘clean-up
                                                                  mechanism’ or probabilistic element. Such an addition,
                        Conclusions
                                                                  however, would considerably weaken the great strength of
The main aim of this paper was to compare a mechanism             this approach: its ability to rapidly classify items on the
for extracting syntactic categories based on independent          basis of little information.
contexts with Mintz style frequent frames in terms of their          All three mechanisms that computed statistics over
accuracy and ability to cluster nouns and verbs. A                independent contexts were able to attain higher accuracy
secondary aim was to investigate the role of frequency            levels, though they classified fewer items. It was argued
sensitivity and availability of utterance boundaries as           that the probabilistic nature of these mechanisms allows
framing elements.
                                                             2331

them to utilize the additional information in larger corpora       similarity, suggesting that this represents an optimum
without suffering from the brittleness associated with             level of frequency sensitivity.
frequent frames.
   A similar pattern emerges when including utterance                               Acknowledgements
boundaries as context items. For independent contexts,             This research was supported by the Economic and Social
the inclusion of utterance boundaries results in                   Research Council under grant number ES/J011436/1.
comparable levels of accuracy, coupled with greater
levels of completeness. The inclusion of utterance
boundaries in frequent frames results in a drop in
                                                                                          References
performance, in particular when considering the merged             Akhtar, N., & Tomasello, M. (1997). Young children’s
corpus. Such a finding may not be surprising (and indeed             productivity with word order and verb morphology.
may not be in the ‘spirit’ of frequent frames), since the            Developmental Psychology, 33, 952-965.
inclusion of utterance boundaries leads to the measure             Chemla, E., Mintz, T. H., Bernal, S., & Christophe, A.
being less constrained than the lexical frequent frames              (2009). Categorizing words using ‘frequent frames’:
that were originally proposed by Mintz. It does, however,            What      cross-linguistic    analyses   reveal   about
provide an additional indication that independent contexts           distributional acquisition strategies. Developmental
are less brittle and better able to incorporate additional,          Science, 12, 396–406.
potentially noisy information.                                     Erkelens, M. A. (2009). Learning to categorize verbs and
   The increased flexibility of independent contexts is              nouns. Unpublished PhD Thesis, Universiteit van
further underscored by the analyses relating to the noun-            Amsterdam, Amsterdam.
verb asymmetry. Empirical work has suggested that                  Finch, S. P. & Chater, N. (1992). Bootstrapping syntactic
children are more likely to substitute novel nouns in                categories. Proceedings of the 14th Annual Conference
familiar contexts than they are to substitute novel verbs.           of the Cognitive Science Society (pp. 820-825).
(Akhtar & Tomasello, 1997; Tomasello, 2000). If the                Freudenthal, D., Pine, J. & Gobet, F. (2008). On the
number of classified nouns versus verbs is an indication             utility of conjoint and compositional frames and
of such a tendency, frequent frames would appear to                  utterance boundaries as predictors of word categories.
result in levels of verb-richness that are overly high. Thus,        In B. C. Love, K. McRae, & V. M. Sloutsky (Eds.),
when excluding utterance boundaries, noun pairs make up              Proceedings of the 30th Annual Conference of the
on average only 28% of noun and verb pairs for frequent              Cognitive Science Society (pp. 1947-1952). Austin, TX:
frames, compared to approximately 80% for independent                Cognitive Science Society.
contexts. While the inclusion of utterance boundaries              MacWhinney, B. (2000). The CHILDES project: Tools
leads to higher levels of noun pairs in the frequent frames          for analysing talk (3rd Edition). Mahwah, NJ: Erlbaum.
approach, the results from Table 2 suggest that this is            Monaghan, P. & Christiansen, M. (2004). What
achieved at the expense of accuracy. For independent                 information is useful and usable in language
contexts, accuracy and noun richness remain high, whilst             acquisition? Proceedings of the 26th Annual Conference
completeness is improved relative to the condition                   of the Cognitive Science Society. Mahwah, NJ:
without utterance boundaries.                                        Lawrence Erlbaum.
   Some differences were also apparent within the                  Mintz, T. (2003). Frequent frames as a cue for
different implementations of independent contexts. The               grammatical categories in child directed speech.
present paper compared three different measures that                 Cognition, 90, 91-117.
differed primarily in terms of the weighting of frequency          Redington, M., Chater, N. & Finch, S. (1998).
information. Within the constraints employed (which                  Distributional information: A powerful cue for
included a threshold value that results in an average                acquiring syntactic structures.
accuracy level of approximately 90%), it was apparent              St. Clair, M.C., Monaghan, P., & Christiansen, M.H.
that a similarity measure based on raw frequency counts              (2010). Learning grammatical categories from
results in relatively low completeness, while                        distributional cues: Flexible frames for language
completeness for square root cosine similarity and rank              acquisition. Cognition, 116, 341-360.
order correlations perform at similar levels of                    Stumper, B., Bannard, C., Lieven, E., & Tomasello, M.
completeness, with the square root cosine similarity                 (2011). Frequent frames in German child-directed
measure showing more of a noun advantage than the less               speech: A limited cue to grammatical categories.
frequency sensitive rank order correlation. Overall, the             Cognitive Science, 35, 1190-1205.
inclusion of utterance boundaries leads to higher levels of        Theakston, A.L., Lieven, E.V.M., Pine, J.M. & Rowland,
noun-richness, suggesting it is a useful source of                   C.F. (2001). The role of performance limitations in the
information. The size of this effect of noun-richness                acquisition of Verb-Argument structure: An alternative
however was dependent upon frequency sensitivity: while              account. Journal of Child Language, 28, 127-152.
noun-richness increased for all probabilistic measures,            Tomasello, M. (2000). Do young children have adult
this was most pronounced for the square root cosine                  syntactic competence? Cognition, 74, 209-253.
                                                              2332

