UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Theory of Subjective Probability [Featuring a Proof that the Conjunction
Effect is not a Fallacy]
Permalink
https://escholarship.org/uc/item/5n36v406
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Maguire, Phil
Moser, Philippe
Maguire, Rebecca
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

                             A Computational Theory of Subjective Probability
                   [Featuring a Proof that the Conjunction Effect is not a Fallacy]
                                                 Phil Maguire (pmaguire@cs.nuim.ie)
                                                       Department of Computer Science
                                                            NUI Maynooth, Ireland
                                                 Philippe Moser (pmoser@cs.nuim.ie)
                                                       Department of Computer Science
                                                            NUI Maynooth, Ireland
                                            Rebecca Maguire (rebecca.maguire@ncirl.ie)
                                               School of Business, National College of Ireland
                                                    Mayor Street, IFSC, Dublin 1, Ireland
                                                   Mark Keane (mark.keane@ucd.ie)
                                                School of Computer Science and Informatics
                                                            UCD, Dublin 4, Ireland
                               Abstract                                  For instance, Tverksy and Kahneman (1983) applied prob-
                                                                         ability theory to real-world situations involving personality
   In this article we demonstrate how algorithmic probability the-       decisions, medical judgments, criminal motives and political
   ory is applied to situations that involve uncertainty. When peo-
   ple are unsure of their model of reality, then the outcome they       forecasts. On observing consistent deviations from the math-
   observe will cause them to update their beliefs. We argue that        ematical theory, they interpreted their findings as evidence of
   classical probability cannot be applied in such cases, and that       a serious flaw in human reasoning (see Costello, 2009, for a
   subjective probability must instead be used. In Experiment 1
   we show that, when judging the probability of lottery number          review of the associated debate). In this article we adopt the
   sequences, people apply subjective rather than classical proba-       alternative stance that consistent deviations between human
   bility. In Experiment 2 we examine the conjunction fallacy and        reasoning and a simplified, artificial mathematical theory are
   demonstrate that the materials used by Tverksy and Kahne-
   man (1983) involve model uncertainty. We then provide a for-          far more likely to reflect deficiencies in the theory than they
   mal mathematical proof that, for every uncertain model, there         are to reflect sub-optimality in how people think about likeli-
   exists a conjunction of outcomes which is more subjectively           hood.
   probable than either of its constituents in isolation.
   Keywords: Conjunction fallacy; algorithmic statistics; likeli-                           Classical Probability
   hood judgments; surprise; subjective probability.
                                                                         Probability theory was formalised by Kolmogorov in the
                                                                         1930s through the notion of probability space, whereby a set
                           Introduction                                  of possible outcomes is mapped to a number that represents
Breaking news: Pandemonium erupted today at the National                 its likelihood by a probability measure function. For exam-
Lottery headquarters as the numbers 1, 2, 3, 4, 5 and 6 were             ple, a perfect dice outputs the numbers from 1 to 6 with equal
drawn for the third week in a row. Lottery officials, stunned            frequency. However, in the real world it is rarely feasible to
by a sense of déjà vu, scrambled to release a statement insist-        identify the theoretical probability measure function which
ing that the lottery drum selection mechanism meets the high-            underlies the events we observe. Because we have to work
est standards for randomness. Meanwhile thousands are cel-               backwards, using the events to deduce the original function,
ebrating after ignoring the opinions of mathematicians who               we can never be sure if the model we are using is correct.
had viewed the two previous draws as a statistical fluke. Com-              For example, according to classical probability theory, no
mentators in the media are demanding an immediate investi-               conceivable sequence of numbers produced by rolling a dice
gation, describing the incident as a fiasco.                             will ever lead us to revise our beliefs about the nature of the
   The mathematical concept of probability, originally formu-            dice. Even if we rolled 1, 1, 1, 1... the hypothesis of the
lated to describe the highly constrained environment of games            sequence being a statistical fluke would always remain in-
of chance, has now found its way into everyday parlance, with            finitely more likely than the possibility that the dice is biased.
people using it to quantify the likelihood of everything from               In reality, nobody has beliefs which are strong enough to
the possibility of economic recession to the risk of global              stand up to the requirements of classical probability theory.
warming. Such has been the unquestioned adoption of the                  We strongly believe that the numbers drawn from the lottery
probability concept into mainstream culture that it has be-              are random, yet there are certain sequences which, as in the
come the default assumption that probability theory provides             introductory lottery example, would cause us to question our
the only logical way for people to think about likelihood.               assumptions and consider other possibilities. If the sequence
                                                                     960

1, 2, 3, 4, 5, 6 was drawn three weeks in succession, it might        alarm bells to go off, because it indicates that one’s model is
suggest that the balls were not equally weighted, the drum            likely to be suboptimal. This is known as surprise.
mechanism was defective, or that one of the lottery officials            When surprise occurs there are two potential resolutions.
was playing a practical joke. The point where we start to             First, more observation data can be gathered, which might
ask questions reveals how strongly we hold our beliefs. But           mitigate the randomness deficiency by revealing it to be a
no matter how confident we are about a particular model of            statistical fluke. If this does not resolve the discrepancy then
reality, there will always be some sequence of events which           the remaining alternative is to update one’s model to fit the
will cause us to change our mind.                                     data. Either way, the resolution process necessitates urgent
   This poses a crucial problem for probability theory. Let’s         sampling of information from the environment. During the
consider the probability of 1, 2, 3, 4, 5, 6 being drawn in           surprise response, eye widening, opening of the mouth and
a lottery for three weeks in a row. If the draw is unbiased           enlargement of the nasal cavity serve to facilitate the intake
then this sequence of events is just as likely as any other. In       of sensory information (see Maguire et al., 2011).
a lottery with 45 numbers, the exact probability is C(45, 6)3 .          Consider for example looking at the floor and seeing
But if this sequence of events actually unfolded, it would lead       some crumbs which spell out the words “YOU ARE BEING
us to believe that the draw mechanism is biased. Given the            WATCHED”. When crumbs fall on the floor it is just as prob-
new updated belief, then the probability of getting 1, 2, 3, 4,       able that they will arrange themselves into this pattern as any
5, 6 is actually far higher. So what is the true probability of       other. If we were certain that the crumbs had fallen randomly
this sequence of events?                                              then it would not be interesting. However, where knowledge
   To apply classical probability theory a single model of re-        is uncertain then people respond to randomness deficiency.
ality must be selected. We must assume either that the lottery        The pattern of crumbs is randomness deficient because there
draw is biased or that it isn’t. But doing so would be a mis-         is another model which can explain it more concisely: Some-
take because we don’t actually know which world is the case.          body might have deliberately arranged the crumbs in this way.
The situation involves model-outcome dependence, insofar as           The first strategy is to look at the rest of the floor. If the rest
the outcome affects our beliefs about the system that gener-          of the floor is covered in many crumbs which have no other
ated it. Stating that the probability of drawing 1, 2, 3, 4, 5, 6     patterns then the overall randomness deficiency is mitigated.
is C(45, 6)3 is misleading because, if this sequence of events        If these are the only crumbs on the floor then finding a satis-
actually occurred, we would no longer trust the assumptions           factory explanation becomes critical.
involved in computing that probability.                                  People are motivated to seek out randomness deficiency
                                                                      in the world (Dessalles, 2006). The experience of random-
             Uncertainty in the Real World                            ness deficiency with subsequent resolution through represen-
                                                                      tational updating is what makes subjects interesting, films en-
The issue here is that classical probability theory only applies
                                                                      tertaining and jokes funny (Schmidhuber, 2009). Accord-
to cases involving a definitive probability measure function,
                                                                      ingly, when people speak intuitively about likelihood and
while models of reality always involve uncertainty. Though
                                                                      probability, it is the concept of representational updating
useful for reasoning about games deliberately engineered to
                                                                      which is relevant to them.
generate pseudo-randomness, classical probability has less
applicability to everyday life, where reducing uncertainty and
                                                                                         Subjective Probability
optimising models of reality are the principal goals. In our
previous work examining the difference between surprise and           Because it assumes a definitive probability measure function,
probability judgments (Maguire, Maguire, & Keane, 2011)               classical probability theory cannot be applied to the concept
we presented a cognitive theory of uncertainty modeling               of representational updating. This limitation means that the
which views the maintenance of an up-to-date representa-              theory is, for the large part, irrelevant to everyday life and thus
tion of reality as the principal motivation guiding informa-          inappropriate for evaluating the nature of human reasoning.
tion seeking behaviour. People rely on observational data to             Developments in algorithmic statistics have allowed prob-
continually refine their model of the environment, thus main-         ability theory to be extended to situations involving an uncer-
taining the optimality of their decision making. In particular,       tain probability measure function (see, e.g., Vityányi & Li,
the signal that they rely on to diagnose discrepancies between        2000; Gács et al., 2001). The optimal model which can be
their model and the real world is randomness deficiency.              derived from a set of observations is the one which maxi-
   The best model of a set of observational data is the one           mizes the compression of that dataset, yielding the Minimum
which describes it most concisely, so that the description of         Description Length (MDL), a concept which formalizes Oc-
the data relative to the model is ‘incompressible’ or random          cam’s razor.
(see Rissanen, 1978; Gács, Tromp, & Vityányi, 2001). In the            Whenever an observation is no longer typical with respect
case that one’s model of reality is optimal, then new sensory         to an MDL model it should be adjusted to lower the ran-
data should still be random with respect to it. The experi-           domness deficiency of the data (see Li & Vityányi, 2008,
ence of randomness deficiency (i.e. a pattern which could be          for details on how the updating process is carried out). We
described more concisely using an alternative model) causes           can quantify the extent of this representational adjustment in
                                                                  961

terms of the amount of information that, given the original              psource . The observer tries to learn the probability density
model, would be required to obtain the updated model. The                psource by finding the shortest optimal model based on the
more the information required, the more significant (and less            observations made so far. Formally, after having observed
likely) the update.                                                      strings d1 , d2 , . . . , dn , the observer seeks to construct a hypo-
   The model that people hold of reality represents the very             thetical model pn where
best that they can do in representing their environment and
provides the very best that they can achieve in terms of pre-
dictions. If we assume that our representation is a reliable                  pn = arg min{|p∗ | : p is optimal for d1 , d2 , . . . , dn and
predictor of events then the larger a potential update to that                  d1 , d2 , . . . , dn are (p, α)-typical}.
representation, the rarer it should be. Accordingly, we can
apply probability theory to speak about the likelihood of an                If the next observation dn+1 is surprising, action may be
outcome requiring an update of a particular size. The uncer-             required. Formally, observation dn+1 is α-surprising if the
tainty which precludes probability theory from being applied             length of its shortest description given p is less than the num-
to real-world scenarios is circumvented by shifting the focus            ber of bits a Shannon-Fano code based on p would require
from an underdetermined probability measure function to the              after subtracting the surprise level α, i.e.,
immutable mechanism of representational updating.
                                                                                           K(dn+1 |p∗n ) < − log pn (dn+1 ) − α.
Preliminaries
A computable probability density function p can be inter-                   If an update is performed, then the subjective information
preted as a model for a string generating device. Given such             of dn+1 (the “cost” of the update) is the amount of information
a device, described by p, there are some “type of strings”               needed to update the model to the latest, that is the length
we expect to be output, whereas some others are surprising.              of the shortest description of the new model, given the old
String x is said p-typical if it is a random string relative to the      model, i.e.,
model described by p, i.e. the model already describes all the                     subjective information(dn+1 ) = K(p∗n+1 |p∗n ).
regularities in x.
   Formally, let α > 0 be a constant, called the surprise thresh-           Subjective probability (the probability of the update) can
old, which represents the level of randomness deficiency that            then be quantified based on the amount of information it con-
necessitates representational updating. String x is p-typical            tains, i.e.,
with surprise threshold α (or (p, α)-typical) if the length of
                                                                                                                                ∗     ∗
its shortest description given p is at least the number of bits                    subjective probability(dn+1 ) = 2−K(pn+1 |pn ) .
a Shannon-Fano code based on p would require (an encoding
where the more p-likely a string is, the shorter its encoding                                           Experiment 1
will be) after subtracting the surprise level α, i.e.,                   In the following experiment we investigated the hypothesis
                                                                         that people use subjective probability rather than classical
                   K(x|p∗ ) ≥ − log p(x) − α.                            probability to judge the likelihood for real-world events. We
   The idea behind the minimal description length (MDL) of               used an example for which the use of classical probability the-
a string x (Gács et al., 2001) is to take the shortest (in descrip-     ory seems particularly compelling, namely lottery sequences
tion length) among all models for which x is typical. To avoid           (see Dessalles, 2006). A naive application of classical proba-
overfitting (i.e. the model is specifically built for x instead          bility suggests that all lottery sequences are just as likely.
of for all “strings of type x”) the description length of both
the model and the string given the model, should be equal to
                                                                         Method
the description of the string on its own. Formally, probabil-            In a lottery system where 6 numbers are drawn from 45, each
ity density function p is optimal for string x if the shortest           ordered sequence has a classical probability of C(45, 6). Ac-
description of x has the same length (up to an additive con-             cording to the theory outlined in the previous section, the
stant) as the shortest description of p plus the number of bits          subjective probability of an outcome is related to its ran-
required for a Shannon-Fano encoding of x based on p, i.e.,              domness deficiency. People expect the lottery numbers to
                                                                         be Kolmogorov-random. The more they deviate from a typ-
                 K(x) = K(p) − log p(x) ± O(1)                           ical random string, the lower the subjective probability that
where O(1) means the equality holds up to an additive con-               they reflect the output of a random source. The random-
stant. The MDL of string x is the shortest (description length)          ness deficiency of a string is quantified precisely by its MDL.
among all optimal probability density functions for x for                However, since this theoretical construct is not computable
which x is typical.                                                      in practice, we are obliged to create a heuristic compressor
                                                                         which approximates it.
Subjective information and probability                                      We considered the patterns to which people are sensitive
Suppose an observer experiences observations d1 , d2 , . . . gen-        in discriminating predictable sequences from random ones.
erated by some source with computable probability density                Overtly non-typical random patterns include ones in which
                                                                     962

the numbers are consecutive (e.g. 3, 4, 5, 6, 7, 8) or where             tively. As it happened, the first lottery ticket sequence had a
they increase in a constant step size. To compress these pat-            compressed description length of 31 bits, and the second had
terns we created a simple compressor which takes in an or-               a length of 30 bits. The ordering of the five sequences on the
dered sequence of six numbers, and computes the six step                 screen was randomized.
sizes between them (with the first number counting as the first             Participants ranked each set of five sequences in order of
step). A Huffman encoding scheme is then applied, which re-              likelihood of being the quickpick sequence, from highest
lates bit size to step size. A breakdown of the structure of the         probability to lowest probability. After the process was com-
associated Huffman tree is provided in Table 1.                          plete participants were shown the actual lottery tickets so that,
   Using this system the sequence 10, 32, 33, 35, 39, 45 is              as promised, they could see if they had made the correct judg-
transformed to step sizes of +10, +22, +1, +2, +4, +6 which is           ment or not.
then encoded using 8 + 8 + 2 + 3 + 4 + 6 = 31 bits. Analysing               Unfortunately for the experimenters, the lottery tickets did
six years of bi-weekly Irish National Lottery draws revealed a           not turn out to be winning ones.
mean compressed length of 30.9 bits, with a mode of 31 bits.
The most randomness deficient of the 624 sequences was 2,                Results and Discussion
4, 32, 34, 36, 37 (description length of 20 bits), while the             An individual applying classical probability would view all
most random was 9, 20, 26, 27, 34, 45 (description length of             sequences as equally likely and would thus only have a
39 bits). The theoretical minimum description length of our              20% chance of correctly identifying one quickpick sequence
system was 12 (e.g. 1, 2, 3, 4, 5, 6), while the theoretical             mixed with four others. However, 64% of participants cor-
maximum was 43 (e.g. 7, 13, 20, 29, 36, 45). The number of               rectly identified the numbers on the first ticket, and 66% on
bits needed to perfectly encode an ordered random sequence               the second ticket (i.e. ranked these sequences in first place).
of six numbers between 1 and 45 is 23.0 bits. Although our               When participants were shown the lottery tickets at the end
compressor cannot compute MDL, it delivers compression                   of the experiment they were surprised that their intuition had,
for randomness deficient outputs (i.e. it compresses below               in the majority of cases, led them to make the correct choice.
23.0 bits for certain non-typical random sequences) and can                 Figure 1 shows the mean compressed bit size for sequences
therefore be used to evaluate the hypothesis that people use             ranked from first to fifth place across the two presentations.
subjective rather than classical probability.                            The overall correlation between ranking and compressed de-
                                                                         scription length was 0.965, p < .001.
      Table 1: Structure of Huffman encoding scheme.
                                                                                                  30.0
        Level Depth     Leaves              #Branches
        1               -                   2                                                     28.0
        2               +1, repeat          2
                                                                                                  26.0
                                                                            Compressed
                                                                                     d Bit Size
        3               +2, +3              2
        4               +4                  3                                                     24.0
        5               +5                  5
                                                                                                  22.0
        6               +6                  9
        7               +7, +8              16                                                    20.0
        8               +9 up to +40        -
                                                                                                  18.0
                                                                                                  16.0
Participants 130 undergraduate students from NUI
                                                                                                         First   Second   Third   Fourth   Fifth
Maynooth participated voluntarily in this study.
Procedure As an initial step we purchased two quickpick
(i.e. randomly selected) lottery tickets for the next week’s             Figure 1: Mean compressed bit size according to rankings of
Irish National Lottery, with six ordered numbers ranging                 likelihood.
from 1 to 45. Participants were informed that we had pur-
chased these tickets and that, for each of the two quickpick                These results demonstrate that, not only do people use sub-
sequences, their goal was to identify it from among a group              jective probability, they also enhance the accuracy of their
of five candidate sequences. No mention was made of how                  judgments by using it. While the naive mathematician as-
the other four sequences had been generated.                             sumes all lottery sequences are equally likely, the savvy
   Each quickpick sequence was presented on a screen along               layperson realises there is an element of uncertainty involved
with four other sequences randomly generated using our com-              in how those sequences were generated. The greater the ran-
pressor algorithm. The four distractor sequences met the con-            domness deficiency of a sequence, the greater the subjective
straints of having compressed bit-sizes of between 15 and 18             probability that it was generated by a non-random generative
bits, 19 and 22 bits, 23 and 26 bits, and 27 and 29 bits respec-         mechanism.
                                                                   963

   Our central argument in this article is that, because models        she is still active in the feminist movement suggests that she
of reality always involve uncertainty, people apply subjective         has not changed much since her student days. Because these
probability rather than classical probability in everyday life.        two models of Linda are quite different, there is no defini-
In the following experiment we investigated whether the ap-            tive probability measure function relative to which classical
plication of subjective probability can explain experimental           probability can be expressed.
observations which have previously been interpreted as ex-
amples of fallacious reasoning.                                        Method
                                                                       In the following experiment we investigated whether the out-
                         Experiment 2                                  comes for the Linda scenario cause participants to adjust their
The conjunction effect is a situation in which people assert           model of Linda.
that a conjunction of two outcomes is more probable than ei-           Materials For this experiment we altered the Linda sce-
ther of those outcomes in isolation. According to classical            nario by including the outcomes as part of the description.
probability theory this is a fallacy because requiring two out-        We removed the information that she is single, outspoken
comes to be validated is always a stricter criterion than re-          and very bright and included at the end of the description
quiring a single one to be validated (i.e. P(x ∧ y) ≤ P(y)).           either that “Linda is a bank teller” (Version 1) or “Linda is
The most celebrated example of the fallacy involves one of             a bank teller and is active in the feminist movement” (Ver-
the materials used by Tverksy and Kahneman (1983), involv-             sion 2). Participants were then asked to rate the probability
ing an individual named Linda.                                         of Linda having the attributes of being single, outspoken and
   Linda is 31 years old, single, outspoken, and very bright.          very bright (from 0 to 100%). In order for classical prob-
She majored in philosophy. As a student, she was deeply con-           ability to be applicable, then the probabilities provided for
cerned with issues of discrimination and social justice, and           Versions 1 and 2 should not differ significantly. Linda should
also participated in anti-nuclear demonstrations.                      be just as independent, outspoken and bright regardless of
   Which is more probable?                                             whether she is active in the feminist movement or not.
   a) Linda is a bank teller
                                                                       Participants 106 undergraduate students from NUI
   b) Linda is a bank teller and is active in the feminist move-
                                                                       Maynooth participated voluntarily in this study.
ment.
   Tverksy and Kahneman (1983) report that, when the two               Procedure Participants were randomly assigned either Ver-
possible outcomes are listed together as above, 85% of people          sion 1 or Version 2 of Linda’s description and wrote down
violate the conjunction rule by identifying b) as more proba-          their probabilities for the three characteristics, which were
ble. Tverksy and Kahneman’s explanation is that people get             randomly ordered along with three other filler characteristics
confused by what they call ‘representativeness’. They found            (Linda plays golf, Linda is dyslexic, Linda suffers from anx-
that participants’ responses reflect the extent to which the de-       iety).
scriptions match a stereotype, with a correlation of 0.98 be-
tween mean ranks of probability and representativeness.                Results and Discussion
   It is interesting to note that this correlation closely matches     The mean probabilities for the three characteristics are shown
the observed correlation of 0.97 between mean ranks of prob-           in Table 2. When Linda was described as a bank teller and ac-
ability and compressed description length in Experiment 1.             tive in the feminist movement she was rated as significantly
This suggests the possibility that representativeness and ran-         more likely to be single, demonstrating that the outcomes
domness deficiency are closely related concepts.                       used in the Linda scenario cause participants to adjust their
   In Experiment 1 we found that, when there is uncertainty            model of Linda.
as to the generative mechanism which produced an outcome,
people rely on randomness deficiency to make judgments.
                                                                       Table 2: Mean probability ratings, t-test scores and signifi-
The uncertainty in Experiment 1 concerned the fact that par-
                                                                       cance for the two descriptions of Linda.
ticipants were given no information as to how four of the five
lottery sequences were generated. Rather than assuming that                               Ver. 1    Ver. 2  t-test
all the sequences were generated randomly, they correctly                 Single          47%       64%     t(104) = 4.11, p < .001
used randomness deficiency to make inferences that resolved               Outspoken       77%       80%     p > .05
the uncertainty.                                                          Very Bright     59%       63%     p > .05
   In the Linda example, some information about Linda is
provided, but there is much about her that remains unknown
(e.g. has she settled down since her student days?) In the case           The numbers generated by a perfect dice never lead us to
of uncertainty regarding the underlying probability measure            update our beliefs about the nature of the dice, yet finding out
function, then classical probability cannot be applied. For            about Linda’s current activities does lead people to update
example, if we find out that Linda is a bank teller, then we           their beliefs about her. Because the model of Linda is un-
might infer that she has settled down. In contrast, hearing that       certain, subjective probability must be applied. What people
                                                                   964

are quantifying when they identify the conjunction as more                                        Conclusion
probable is that the conjunction contains more subjective in-         Although Tverksy and Kahneman (1983) identified an associ-
formation, and that, relative to the process of representational      ation between representativeness and the conjunction effect,
updating, the likelihood of an outcome diminishes with the            they never provided an explanation for why such an associ-
amount of subjective information it carries. Basing decisions         ation might exist, instead being satisfied to pass it off as an
on subjective probability is mathematically the correct ap-           arbitrary reasoning fallacy. Had they questioned participants
proach when dealing with uncertainty regarding the under-             regarding their judgments, rather than dismissing them as fal-
lying probability measure function.                                   lacious, then the resultant findings may have facilitated the
   In the following section we build on this result by prov-          extension of classical probability theory. In sum, perhaps
ing that for every situation involving uncertainty (i.e. all real     the most salient fallacy on display in Tverksy and Kahne-
world scenarios) there is a conjunction of events which is            man’s (1983) study is the misplaced belief that mathematical
more subjectively probable than either of its constituents in         theories which have been developed for precision models in
isolation.                                                            the exact sciences retain their validity when used to describe
                                                                      complex cognition in the real world.
  Proof that Conjunction Effect is not a Fallacy                         Tverksy and Kahneman (1983) posed the following ques-
In this section we prove that given any hypothetical model            tion: “Why do intelligent and reasonably well-educated peo-
p, there are always two strings of events x, y such that x is         ple fail to recognize the applicability of the conjunction rule
a substring of y but y has higher subjective probability. The         in transparent problems?” Here, we have presented the an-
idea of the proof is that any long enough typical string of           swer: Because often it’s not applicable.
events can always be decomposed into a substring of events
that carries greater subjective information.                                                      References
Theorem 1. Let E1 , E2 , . . . Em be m independent events and         Costello, F. J. (2009). How probability theory explains the
let p be the associated computable probability measure func-             conjunction fallacy. Journal of Behavioral Decision Mak-
tion. Let α > 0 be a surprise threshold. There exists a con-             ing, 22, 213–234.
junction of events A = A1 ∧ A2 ∧ . . . ∧ An with a constituent B      Dessalles, J. L. (2006). A structural model of intuitive prob-
(i.e. p(A) < p(B)) such that B is (p, α)-surprising (i.e. car-           ability. In Proceedings of the seventh international confer-
ries subjective information) and A is (p, α)-typical (i.e. has a         ence on cognitive modeling (pp. 86–91). Trieste: Edizioni
subjective probability of 1).                                            Goliardiche.
                                                                      Gács, P., Tromp, J. T., & Vityányi, P. M. B. (2001). Algorith-
Proof. Let E1 , E2 , . . . Em , p and α > 0 be as above. Without
                                                                         mic statistics. IEEE Transactions in Information Theory,
loss of generality m = 2k and p can be seen as a probability on
                                                                         47, 2443–2463.
strings of length k (each coding one event Ei ) extended multi-
                                                                      Li, M., & Vityányi, P. M. B. (2008). An introduction to
plicatively i.e., p : 2k → [0, 1] is extended multiplicatively by
                                                                         Kolmogorov complexity and its applications. New York:
p(xy) := p(x)p(y).
                                                                         Springer Verlag.
   Let n be a large integer. Let y ∈ 2kn be a (p, α)-typical
                                                                      Maguire, R., Maguire, P., & Keane, M. T. (2011). Making
string. y can be viewed as the concatenation of n strings of
                                                                         sense of surprise: An investigation of the factors influenc-
length k (i.e. the conjunction of n events). By the pigeon
                                                                         ing surprise judgments. Journal of Experimental Psychol-
hole principle, there must be such a string that occurs at least
                                                                         ogy: Learning,Memory and Cognition, 37(1), 176–186.
n/2k times. Denote this string by s, and let l be the number of
                                                                      Rissanen, J. J. (1978). Modeling by the shortest data descrip-
occurences of s in y, i.e. l ≥ n/2k . Because y is (p, α)-typical
                                                                         tion. Automatica (Journal of IFAC), 14, 465–471.
we have p(s) > 0. Thus p(s) = 2−c for some c > 0. Let x be
                                                                      Schmidhuber, J. (2009). Simple algorithmic theory of subjec-
l concatenations of s. Because p is extended multiplicatively
                                                                         tive beauty, novelty, suprise, interestingness, attention, cu-
we have p(x) > p(y).
                                                                         riosity, creativity, art, science, music, jokes. Journal of the
   Let us show that x is (p, α)-surprising. To describe x it
                                                                         Society of Instrument and Control Engineers, 48(1), 21–
suffices to describe l plus a few extra bits that say “print s
                                                                         32.
l times”. Since l can be described in less than 2 log l bits
                                                                      Tverksy, A., & Kahneman, D. (1983). Extentional vs. in-
(by a prefix free program) we have K(x) < 3 log l for n large
                                                                         tuitive reasoning: The conjunction fallacy in probability
enough. We have
                                                                         judgment. Psychological Review, 90, 293–315.
                                                                      Vityányi, P. M. B., & Li, M. (2000). Minimum description
  − log p(x) − α = − log p(sl ) − α = − log p(s)l − α                    length induction, Bayesianism, and Kolmogorov complex-
                                                                         ity. IEEE Transactions on Information Theory, 46, 446–
                   = −l log 2−c − α = cl − α > 3 log l > K(x)            464.
                   ≥ K(x|p∗ )
   for n large enough. Thus x is (p, α)-surprising, but y is
not.
                                                                  965

