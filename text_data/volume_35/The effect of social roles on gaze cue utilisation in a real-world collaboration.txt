UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The effect of social roles on gaze cue utilisation in a real-world collaboration
Permalink
https://escholarship.org/uc/item/0nq111sn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
MacDonald, Ross
Tatler, Benjamin
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                     Powered by the California Digital Library
                                                                         University of California

        The effect of social roles on gaze cue utilisation in a real-world collaboration
                                       Ross G. Macdonald (rgmacdonald@dundee.ac.uk)
                                        School of Psychology, University of Dundee, Nethergate,
                                                           Dundee, DD1 4HN, UK
                                     Benjamin W. Tatler (b.w.tatler@activevisionlab.org)
                                        School of Psychology, University of Dundee, Nethergate,
                                                           Dundee, DD1 4HN, UK
                              Abstract                                  could slow down responses in a Posner (1980) task,
                                                                        suggesting that the artificial gaze cue stimuli automatically
   During collaboration, people communicate using verbal and
   non-verbal cues, including gaze cues. Social factors can affect      shifted attention away from the target. Variants of this study
   gaze allocation, however most research on gaze cueing has            looking at eye movements have found that participants will
   not considered these factors. The presence of social roles was       also look in the direction of the distracting gaze cue, even
   manipulated in a collaborative task whilst eye movements             though they know there is no reason to do so (Ricciardelli,
   were measured. In pairs, participants worked together to             Bricolo, Aglioti, & Chelazzi, 2002; Galfano et al, 2012).
   make a cake. Half of the pairs were given roles (“Chef” or           These findings have been used to suggest that humans are
   “Gatherer”) and the other half were not. Across all
   participants we found, contrary to the results of static image
                                                                        “hard-wired” to automatically follow the gaze cues of others
   experiments, that participants spent very little time looking at     (Emery, 2000).
   each other, challenging the generalisability of the conclusions         The above research shows that people look at eyes and
   from lab-based paradigms. When given spoken instructions,            follow gaze cues when viewing isolated static images of
   listeners in the roles condition looked at the speaker               others. However, in the real world, gaze cues usually occur
   significantly more than listeners in the no roles condition. We      alongside spoken language. There appears to be an intimate
   conclude that our tendency to seek the gaze cues of                  link between gaze allocation and spoken language, with
   collaborators is affected either by our social perceptions of
   the collaborator or their perceived reliability.                     people making anticipatory eye movements to objects that
                                                                        relate to what they hear (Altmann & Kamide, 1999). Gaze
   Keywords: eye movements; joint attention; real world; gaze           cue utilisation in particular has been shown to be affected by
   cues; social interaction.                                            spoken language; changing the syntactic structure of a
                                                                        sentence, whilst maintaining meaning changes the timing of
                          Introduction                                  gaze following (Knoeferle & Kreysa, 2012). Reciprocally,
  When collaborating with another on a task, we need to                 Stuadte and Crocker (2011) showed the gaze cues can affect
communicate. As well as using spoken language, there are a              the understanding of spoken language; participants were
number of non-verbal cues we can use, with the directional              shown videos of a robot describing the spatial and featural
gaze cues given by the eyes being the most well-researched              relations between a series of visible objects, whilst
of these. Gaze cues are first used very early in life and               providing gaze cues. The robot made mistakes in his
continue to be given and followed throughout adulthood.                 descriptions that could have been corrected in two different
People have a tendency to orient to and follow the gaze cues            ways. The experimenters found that participants would
of others and can to do this with ease. However, there is               correct in the way that was congruent with the gaze cue,
evidence that the language accompanying a gaze cue and the              suggesting that they were inferring meaning from the
social context of the cue can affect how people orient to and           robot’s gaze and assuming that the robot meant to refer to
follow gaze cues. In the real world, gaze cues will always              the object that it was gazing at. Given the effect gaze cues
occur within a social context, yet this context is removed in           and language have on each other, it is important to use
most studies. The aim of the present study is to measure eye            language in a paradigm investigating how gaze cues are
movements in a real-world setting to observe how the                    used naturally in collaboration.
utilisation of gaze cues can be affected by social context in a            As well as mostly occurring alongside language, all gaze
natural collaboration.                                                  cues in the real world are provided in a social context. When
  When viewing images of faces, people have a tendency to               interacting with another, where we look can be affected by
look at the eyes (Yarbus, 1967) and when viewing images of              our proximity to this other person (Argyle & Dean, 1965).
social scenes people will seek out faces and eyes                       Social effects specifically on gaze seeking were investigated
(Birmingham, Bischoff & Kingstone, 2007; 2009) even                     by Laidlaw, Foulsham, Kuhn and Kingstone (2011), who
when the person being fixated is not visually prominent and             found that participants sitting in a waiting room were
has no role for understanding the scene (Zwickel & Võ,                  significantly more likely to look at a person on a monitor
2010). As well as orienting to these cues, people show a                than the same person present in the room. Gallup et al
tendency to follow them. Friesen and Kingstone (1998)                   (2012) found similar results for gaze following rather than
showed that incongruent gaze cues presented at fixation                 seeking. They observed people walking past an attractive
                                                                    942

item in a hallway and found that people were more likely to        Participants, in pairs, were given a recipe to follow in order
look in the same direction as somebody walking in front of         to make the batter for a cake. During this collaboration their
them than somebody walking towards them. The results of            eye movements were recorded using portable eye-trackers.
these studies were explained by their respective authors as        When coding the data we were particularly interested in the
being due to participants trying to avoid potential                time participants spent looking at each other (interpersonal
interactions with strangers, which might be triggered by any       gaze) or at the same object simultaneously (mutual gaze).
gaze seeking or following behaviour detected by the                Half of the pairs were given roles (chef or gatherer) to fulfil
oncoming person. These findings indicate that social factors       and the other half were not. By manipulating this we are
can affect the way we utilise the gaze cues of strangers,          able to investigate whether the perception of another’s role
which suggests that social context may have an effect on           in collaboration has any significant effect on the extent to
gaze utilisation in one-to-one interactions and                    which we seek and follow their gaze cues in a real-world
collaborations.                                                    interaction.
   Macdonald and Tatler (2013) considered gaze seeking
and following behaviour in a real world communicative                                          Methods
task, involving one-to-one interaction between an instructor
(the experimenter) and a participant. The instructor
manipulated his use of gaze as well as the specificity of his      Participants
instructions in a simple block-building task. Participants
                                                                   Twenty-four students from the University of Dundee
were found to only seek and follow gaze cues when the
                                                                   participated in this experiment. They were split into twelve
language was ambiguous (it did not specify which single
                                                                   pairs to carry out the task. Six pairs were allocated to the
block the participant was meant to pick up), suggesting that
                                                                   roles condition and six were allocated to the no roles
gaze cues are used flexibly, depending on other information
                                                                   condition (see design).
that is available. It was also noted that even when gaze cues
supplied the only unambiguous information about which
block to pick up (because the spoken instructions were
                                                                   Materials
ambiguous) participants did not seek and follow these all of
the time. It was speculated (Macdonald & Tatler, 2013) that        The experiment took place in a kitchen area on the
social factors may have played a part in these results. More       University of Dundee campus. The kitchen was fully
specifically, the social cost of looking at the instructor         equipped with standard kitchen appliances, but only the
frequently in each trial may have deterred participants from       oven and microwave were used. All items and foodstuffs
seeking and following these gaze cues. Although this is            that could be removed were removed before testing and the
speculation, these results make a case for manipulating            experimental materials were arranged carefully around the
social factors in a real-world gaze-cueing experiment.             kitchen. This included the items and foodstuffs that were to
   One way to manipulate social factors in a gaze cueing           be used for the procedure as well as a selection of distractor
task is to manipulate what the participant knows about the         items. All of these items were placed in the same location
entity with which they are interacting. Participants carrying      for each pair of participants. A Recipe Procedure sheet was
out a Posner (1980) task in Italy were shown distracter gaze       provided for each pair. This sheet explained, step-by-step,
cueing stimuli made from the faces of Italian political            how to make the batter for a Victoria Sponge. There was
figures, including Silvio Berlusconi (Liuzza et al, 2011).         also a Chef Guidelines sheet and a Gatherer Guidelines
The gaze of Berlusconi was found to cause significantly            sheet for those in the roles condition. These sheets explained
more interference in the task for right-wing voters (in-           the responsibilities and duties for participants in the chef
group) than left wing voters (out-group). These results            and gatherer roles.
suggest that people may be more prone to following the
gaze cues of others with shared beliefs. Crosby, Monin and
Richardson (2008) showed that participants were more               Design
likely to look at an individual on a monitor if they thought       This experiment had a between subjects design. The two
the individual could hear comments that were potentially           independent variables for the analysis of mutual fixations
offensive to that individual. These results show that social       and time participants spent looking at each other
factors such as beliefs about another individual can affect        (interpersonal gaze) were the use of roles (roles or no roles)
how others look at them as well as how others look at              and the allocation of roles within the roles condition (chef or
external objects whilst communicating with them. Although,         gatherer). For the analysis of the instruction statements the
these results show effects of prior beliefs about others on        independent variables were the use of roles (roles or no
gaze behaviour, it is still unclear how beliefs about the role     roles) and the identity of participant (speaker or listener).
or knowledge of another affect the use of gaze cues in
natural collaboration.
   The present study manipulates participants’ perception of
their collaborator by assigning them roles in a task.
                                                               943

Procedure                                                              stored alongside a power supply, but were stored in a light
This experiment required two participants. The                         backpack worn by the participant. This eye tracker also has
experimenter began by fitting a portable eye tracker to the            a small microphone attached to the frame. This microphone
first participant. At this point in the roles condition the first      recorded sound throughout the experiment and was able to
participant was given the Chef Guidelines and the second               pick-up the voices of both participants. Gaze direction was
participant was given the Gatherer Guidelines. They were               estimated off-line using Yarbus software provided by
both instructed to read over their sheet and make sure they            Positive Science, LLC, which tracks the pupil and corneal
understood their roles. The Chef Guidelines informed the               reflection. Calibration was carried out in two stages, one
chef that they were in charge of preparing the recipe and              looking down at a counter and the other looking across the
that the gatherer was there to assist them. The sheet                  room. These two stages were used because by tracking one
explained that the chef was expected to mix and prepare                eye we are not able to directly measure the vergence of the
ingredients, following a recipe which they could not show to           eyes that occurs as participants focus on objects at different
the gatherer. The chef would not be expected to collect any            distances. Instead we fit the model to fixations on both
items or foodstuffs, but to delegate those duties to the               proximal and distal points. If the tracker estimates in the
gatherer. The chef would also be able to ask the gatherer to           scene video fell on the correct calibration positions the
assist them with any aspect of the preparation they wished.            calibration was deemed adequate. Eye movement data were
The Gatherer Guidelines explained that the gatherer would              recorded at 30Hz with a spatial accuracy of about 1 degree.
not be expected to make any decisions concerning the                   Once videos for both participants were rendered with the
preparation, but should instead do as instructed by the chef.          eye movement information, Quicktime Pro was used to
Once the participants declared they understood their roles             synchronise both videos in to one movie file, ready for
the gatherer was asked to remain outside whilst the                    analysis.
experimenter and the chef entered the kitchen. The
experimenter then gave the chef the Recipe Procedure sheet
and told the chef where all of the necessary items and                 Analysis
foodstuffs were located. The chef was then told they would             Eye tracking data were coded manually offline using
have approximately three minutes to familiarise themselves             Quicktime Media player and audio information was
with the kitchen and the locations of the items. During these          extracted using Audacity sound editing software. The first
three minutes the experimenter fitted another portable eye-            two dependent variables considered were (1) the proportion
tracker to the gatherer. In the no roles condition the second          of time both participants fixated the same object (mutual
eye-tracker was fitted straight after the first. At this point, in     fixations) and (2) the proportion of time a participant spent
both conditions, both participants were brought into the               looking at their partner (interpersonal gaze). For these
kitchen and the eye-trackers were switched on.                         analyses, in each pair, one participant was labelled person A
   The cameras were synchronised and the eye-trackers                  and the other was labelled person B. In the roles condition
calibrated. Once calibration was complete, those in the no             person A was the chef and B was the gatherer. Since there
roles condition were directed to the Recipe Procedure sheet            were not any defined roles in the no roles condition,
and informed that all of the items they would require were             participants in this condition were arbitrarily allocated as
located around the kitchen. All participants were informed             person A or B. The frame-by-frame coding of these data
that the experimenter would be standing outside the kitchen,           was split between the lead experimenter and three
out of sight and that the participants must make no attempt            undergraduate volunteers from the School of Psychology.
to interact with him. The experimenter then told the                   To begin, all four coders coded the same movie file and
participants that they may begin as soon as he was out of the          these were all compared by the lead experimenter to ensure
room. The experimenter left and the procedure began. The               a consistent and high quality of coding. Mutual fixations
procedure ended when the participants put the batter                   were compared across conditions by a t-test and the
mixture in the oven.                                                   proportion of time spent on interpersonal gaze was analysed
                                                                       using a 2 (roles or no roles) by 2 (person A or person B)
                                                                       independent measures ANOVA.
Eye movement and sound recording                                          The individual instructions were also coded and analysed.
Participants’ eye movements were tracked using two                     These were coded by the lead experimenter alone, using
Positive Science LLC mobile eye trackers, which allowed                audacity sound editing software and the Quicktime movie
free head movement. Each eye tracker has two cameras                   files. For each pair, each instruction statement was
mounted on the frame of a pair of spectacles: one records              numbered and transcribed, noting the speaker. The time that
the scene from the participant’s point of view and the other           the speaker first looked (if at all) at the listener and vice
records the right eye. Data from these cameras were                    versa was coded for each instruction statement. In the roles
captured on digital camcorders. For one of the eye-trackers            condition, the speaker was always the chef and the listener
these camcorders were stored, alongside a power supply for             always the gatherer. In the no roles condition the participant
the eye-tracker, in a lumbar pack worn by the participant.             who gave the instruction was considered to be the speaker.
The camcorders connected to the second tracker were again              Therefore the identity of the speaker and listener would
                                                                   944

switch throughout each movie in the no roles condition.
From coding these data we considered the percentage of
instructions in which the participant looked at the other
participant. This was analysed using a 2 (role or no role) by
2 (speaker or listener) ANOVA.
                            Results
Overview of eye movements in collaboration
The first set of results is focused on the general eye
movement behaviour of participants in the roles and no roles
conditions. To investigate this behaviour we measured the
proportion of time participants spent mutually fixating
objects and the proportion of time spent fixating on the co-          Figure 2: The mean percentage of time participants spent
participant (interpersonal gaze).                                   on interpersonal gaze for Person A, Person B and A and B
   The mean proportion of time in which both participants            simultaneously for both the roles and no roles conditions
fixated on the same item (mutual fixation) is shown in                               (with standard error bars)
Figure 1.
                                                                     It can be seen from Figure 2 that on average person B
                                                                  spent more time looking at person A (3.77%) than vice-
                                                                  versa (1.92%) in the roles condition, whilst participants
                                                                  spent only 0.43% of the total time on simultaneous
                                                                  interpersonal gaze. In the no roles condition, Person A was
                                                                  found to spend slightly more time looking at person B
                                                                  (2.62%) than vice versa (2.31%) and only 0.27% of the time
                                                                  was spent simultaneously looking at one another. A two
                                                                  (roles, no roles) by two (person A, person B) ANOVA was
                                                                  carried out on these results. No main effects of role
                                                                  condition (F(1,20) = 0.171, p = 0.683) or participant
                                                                  (F(1,20) = 0.701, p=0.412) were found, nor was there any
                                                                  significant interaction (F(1,20) = 1.381, p = 0.254).
    Figure 1: The mean percentage of time in which mutual
  fixation occurred for participant pairs in the roles and no     Analysis of eye movements during instructions
          roles condition (with standard error bars).             These results consider the eye movement behaviour during
                                                                  the periods when one of the participants was giving spoken
   A larger mean percentage of time was spent on mutual           instructions to the other. For the roles conditions the spoken
fixation in the roles condition (27.23%) than the no roles        instructions were always provided by the chef. For the no
condition (20.69%). However this difference was not found         roles conditions, any instructions could have been provided
to be significant (t(10) = 1.37, p = 0.200)                       by either participant. We investigated the mean percentage
   The mean percentage of time spent engaged in                   of (spoken) instructions in which interpersonal gaze
interpersonal gaze is shown in Figure 2. This plot shows the      occurred. For each of the roles and no roles conditions, we
percentage of time that A spends looking at B and vice versa      considered cases when the speaker looked at the listener, the
for the roles and no roles conditions. The amount of time         listener looked at the speaker or both speaker and listener
when participants A and B simultaneously looked at each           looked at each other at the same time (Figure 3).
other is also shown in Figure 2, for the roles and no roles
conditions.
                                                              945

                                                                    between the percentage of time that interpersonal gaze
                                                                    occurred across roles conditions. However, participants
                                                                    spent far less time (between 2-4%) looking at each other
                                                                    than they spent mutually fixating other objects. This is
                                                                    notable as it appears to be at odds with the results of some
                                                                    previous lab-based studies. People have been shown to have
                                                                    a preference for looking at eyes when viewing pictures of
                                                                    people (Yarbus, 1967) or social scenes (Birmingham et al,
                                                                    2009; Zwickel & Võ, 2010), however in this task
                                                                    participants spent very little time looking at their partners.
                                                                    Given the potential informativeness of the eyes (Tomasello
                                                                    et al, 2007) and the ease with which people can interpret
                                                                    gaze direction (Anderson, Risko & Kingstone 2011) this
     Figure 3. The mean percentage of instructions in which
                                                                    finding may seem surprising. However, studies using real
 interpersonal gaze occurred for speakers, listeners and both
                                                                    people as stimuli may offer an explanation. Laidlaw et al
  speakers and listeners in the roles and no roles conditions
                                                                    (2011) showed that people were less likely to look at a
                  (with standard error bars).
                                                                    present confederate than the same confederate on a video
                                                                    monitor and Gallup et al (2012) found that people were less
   A two (roles, no roles) by two (speaker, listener) ANOVA
                                                                    likely to follow the gaze of strangers that could see them
showed a main effect of identity of participant (speaker or
                                                                    than strangers who could not. They concluded that this was
listener) (F(1,20) = 12.00, p = 0.002). The main effect of
                                                                    due to there being potential consequences (social
role condition was not significant (F(1,20) = 3.21, p =
                                                                    interaction) to looking at the present confederate or the on-
0.089), however, there was a significant interaction (F(1,20)
                                                                    coming stranger. A collaborator in the present study could
= 4.92, p = 0.038). Post-hoc t-tests showed that listeners
                                                                    potentially react to the looks of a participant, whereas the
looked at speakers during significantly more instructions in
                                                                    static and video images in lab based paradigms could not.
the roles condition (50.20%) than the no roles condition
                                                                    Therefore, these lab-based studies may have over-estimated
(20.28%, p = 0.010), but there was no significant difference
                                                                    the tendency of people to look at eyes and faces in social
found between speakers’ looks to listeners across the roles
                                                                    settings.
(7.78%) and no roles (10.97%) conditions (p = 0.766).
                                                                       These results present an obvious question; if people rarely
                                                                    look at each other in an interaction, can they still utilise gaze
                                                                    cues? Although our results cannot lead us to a definite
                         Discussion                                 answer, there are three main arguments for the ability to
   The aim of this study was to investigate the effect of           utilise gaze cues in these circumstances. Firstly, it has been
manipulating social context on the utilisation of gaze cues in      shown that gaze cues can be followed and affect language
a real world collaborative social interaction. Using portable       comprehension, even when they are not directly fixated
eye trackers we were able to measure the eye movements of           (Knoeferle & Kreysa, 2012). Secondly, when gaze cues are
both collaborators for the duration of the task. The time           fixated, the fixations do not necessarily involve long periods
participants spent looking at each other in this real world         of time viewing the eyes. Looks to gaze cues may be very
paradigm was much less than expected, given the results of          brief, but very informative. Thirdly, it may be the case that
experiments using static social scenes (Birmingham et al,           eyes are generally not sought out during a task, but are used
2007; 2009). Social context was actively manipulated in this        effectively when required, for example, during instructions.
paradigm by the presence or absence of roles as there is               From our findings it is possible to speculate about the
evidence from lab based studies (Crosby et al, 2008; Liuzza         third possibility. Listeners were found to look at the speaker
et al, 2011) that beliefs about a collaborator can affect gaze      during significantly more instructions in the roles condition
behaviour. The amount that listeners looked at speakers             than the no roles condition. This finding shows that our
during instructions was affected by our manipulation of the         preference for looking at others can be affected by social
roles of the two participants, providing evidence that the          context. In the roles condition the listener was always the
tendency to look at another individual during a real world          gatherer, following instructions given by an informed chef,
interaction may be influenced by the social context provided        who was in charge. In the no roles condition the identity of
by the roles of the individuals. This result is consistent with     the listener would switch between the two equal partners,
previous suggestions that gaze seeking and following may            depending on who was giving the instruction. Macdonald
depend on the social context of the gaze cues (Gallup et al,        and Tatler (2013) found that the degree of informativeness
2012; Laidlaw et al, 2011; Macdonald & Tatler, 2013).               of gaze cues affected the extent to which the cues were
   There was no significant difference found between the            sought out, with highly informative cues being sought most
percentage of time in which mutual fixations occurred in the        often. One possible interpretation of the present findings
roles and no roles conditions, with collaborators spending          could be that our manipulation of the roles of the
approximately one-quarter of task time mutually fixating on         participants effectively manipulated the perceived
the same objects. There was also no significant difference
                                                                946

informativeness of the cues provided by the chef: listeners          Birmingham, E., Bischof, W. F., & Kingstone, A. (2007).
in the roles condition may consider the gaze cues of the chef          Why do we look at people’s eyes? Journal of Eye
to be highly informative, whereas the gaze cues of the                 Movement Research, 1(1), 1-6.
speaker in the no roles condition may be considered less             Birmingham, E., Bischof, W. F., & Kingstone, A. (2009).
informative.                                                           Get Real! Resolving the debate about equivalent social
   Alternatively, our pattern of results could arise from a            stimuli. Visual Cognition, 17 (6), 904-924.
social effect of authority. Liuzza et al (2011) found that           Crosby J. R., Ronin B., & Richardson D. R. (2008). Where
right-wing voters were more heavily influenced by the gaze             do we look during potentially offensive behaviour?
cues of their political leader than the gaze cues of the               Psychological Science. 19(3): 226-228.
opposition leader. In the roles condition, the chef is in            Emery, N. J. (2000). The eyes have it: the neuroethology,
charge of the procedure and is therefore the leader of the             function and evolution of social gaze. Neuroscience and
gatherer. It is possible that, as well as being more inclined to       Biobehavioural Reviews, 24, 581-604.
follow the gaze cues of a leader, people are also more               Friesen, C.K., & Kingstone, A. (1998). The eyes have it!
inclined to orient to the leader’s gaze cues. Although the             Reflexive orienting is triggered by nonpredictive gaze.
results do not allow us to favour one explanation over the             Psychonomic Bulletin and Review, 5, 490-495.
other, these findings provide good evidence that the social          Galfano, G., Dalmaso, M., Marzoli, D., Pavan, G., Coricelli,
context of collaboration can affect the extent to which                C., & Castelli, L. (2012). Eye gaze cannot be ignored (but
collaborators look at each other during communication. A               neither can arrows). Quarterly Journal of Experimental
more controlled future experiment may be able to                       Psychology, 65(10), 1895-1910.
distinguish between the effects of the perceived reliability of      Gallup, A. C., Chong, A., & Couzin, I. D. (2012). The
a person and the perceived social role of a person.                    directional flow of visual information transfer between
   This experiment investigated the effect of social roles on          pedestrians. Biology Letters, 8(4), 520-522.
eye movement behaviour in a natural collaboration by using           Knoeferle, P., & Kreysa, H. (2012). Can speaker gaze
dual portable eye-trackers. We manipulated the roles of the            modulate syntactic structuring and thematic role
participants to investigate the effect on gaze behaviour.              assignment during spoken sentence comprehension?
Listeners were found to look more at a speaker providing               Frontiers in Psychology, 3, 538.
verbal instructions if the speaker was playing the role of a         Laidlaw, K. E. W., Foulsham, T., Kuhn, G., & Kingstone,
chef. This suggests that our tendency to look at others is             A. (2011). Potential social interactions are important to
either affected by our social perceptions of a person or by            social attention. Proceedings of the National Academy of
our perception of their reliability. Additionally, we found            Sciences, 108, 5548-5553.
that in this real social collaborative setting, people spent         Liuzza, M.T., Cazzato, V., Vecchione, M., Crostella, F.,
very little time looking at each other, challenging the                Caprara, G. V., & Aglioti, S.M. (2011). Follow my eyes:
generalisability of the conclusions from lab-based                     The gaze of politicians reflexively captures the gaze of
paradigms (Birmingham et al, 2007; 2009; Zwickel and Võ,               ingroup voters. PloS ONE 6(9), e25117.
2010). Our results provide a strong case for investigating           Macdonald, R.G., & Tatler, B.W. (2013). Do as eye say:
gaze cueing behaviour in highly naturalistic environments as           Gaze-cueing and language in a real-world social
well as providing evidence for the effect of social context on         interaction. Journal of Vision, 13(4):6, 1-12.
the utilisation of gaze cues.                                        Posner, M.I. (1980). Orienting of attention. The Quarterly
                                                                       Journal of Experimental Psychology, 32, 3-25.
                     Acknowledgments                                 Ricciardelli, P., Bricolo, E., Aglioti, S. M., & Chelazzi, L.
This paper was supported by an EPSRC Studentship                       (2002). My eyes want to look where your eyes are
awarded to Ross Macdonald. The authors would like to                   looking: Exploring the tendency to imitate another
thank Anne-Joanna MacGregor, Julia McVean and Nicole                   individual’s gaze. Neuroreport, 13 (17), 2259-2264.
Spittle for assistance with video coding.                            Staudte, M., & Crocker, M. W. (2011). Investigating joint
                                                                       attention mechanisms through spoken human-robot
                                                                       interaction, Cognition, 120, 268-291.
                          References                                 Tomasello, M., Hare, B., Lehmann, H. & Call, J. (2007).
                                                                       Reliance on head versus eyes in the gaze following of
Altmann, G.T.M., & Kamide, Y. (1999). Incremental                      great apes and human infants: The cooperative eye
   interpretation at verbs: Restricting the domain of                  hypothesis. Journal of Human Evolution, 52, 314-320.
   subsequent reference. Cognition, 73, 247-264.                     Yarbus, A.L. (1967). Eye Movements and Vision. New
Anderson, N.C., Risko, E.F., & Kingstone, A. (2011).                   York: Plenum Press.
   Exploiting human sensitivity to gaze for tracking the eyes.       Zwickel, J., & Võ, M. L. H. (2010). How the presence of
   Behavioural Research,43(3), 843-52.                                 persons biases eye movements. Psychonomic Bulletin &
Argyle, M., & Dean, J. (1965). Eye-contact, distance and               Review, 17, 257-262.
   affiliation. Sociometry, 28(3), 289-304.
                                                                 947

