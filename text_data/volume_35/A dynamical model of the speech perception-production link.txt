UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A dynamical model of the speech perception-production link
Permalink
https://escholarship.org/uc/item/2540b6f8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Roon, Kevin D.
Gafos, Adamantios I.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    A Dynamical Model of the Speech Perception-Production Link
                                                Kevin D. Roon (kdroon@nyu.edu)
                                Department of Linguistics, New York University, 10 Washington Place
                                                        New York, NY 10003 USA
                                         Adamantios I. Gafos (gafos@uni-potsdam.de)
    Linguistics Department and Center of Cognitive Sciences, Universität Potsdam, Haus 14, Karl-Liebknecht-Straße 24-25
                                                      Potsdam 14476 Germany, and
                                                Haskins Laboratories, 300 George Street
                                                       New Haven, CT 06511 USA
                               Abstract                                area was being stimulated. Kerzel & Bekkering (2000) and
   How and to what extent the speech production and perception
                                                                       Galantucci, Fowler, & Goldstein (2009) found that subjects
   systems are linked is a question of longstanding debate (cf.        response times (RTs) can be modulated systematically and
   Diehl, Lotto, & Holt, 2004; Galantucci, Fowler, & Turvey,           involuntarily by various stimuli they perceive while speak-
   2006). Despite the long history of this debate and a vast num-      ing. We refer to these effects broadly as “perceptuo-motor
   ber of studies providing experimental evidence indicating an        effects” (Galantucci et al., 2009) because they are effects
   intimate link between perception and production, formal pro-        that indicate an influence of speech motor plans during the
   posals of this link have been conspicuously lacking in the lit-     process of speech perception.
   erature. In this paper, we provide a computationally explicit,
   dynamical model of the process of phonological planning. In            Much of the debate in the literature on the speech percep-
   this model, the properties of a perceived utterance automati-       tion-production link has centered on the claim of the Motor
   cally serve as input to the ongoing planning of an intended ut-     Theory of Speech Perception (Liberman & Mattingly, 1985)
   terance. Using tools from non-linear dynamics, we formalize         that motor codes are the sole object of speech perception.
   how incoming inputs from perception influence the ongoing           However, as Lotto, Hickok, & Holt (2009) point out, “there
   choice of phonological parameter values to be used in produc-       is no debate that speech production and perception interact
   tion. The use of a dynamical model enables establishing ex-
                                                                       in some manner [...] It is the ‘nature’ of the production-
   plicit bridges between phonological representations and re-
   sponse time data. Our model provides an account of response         perception link that has not been established.” The purpose
   time modulations reported in independent experimental work,         of this study is not to disprove either side of the debate
   and makes additional concrete predictions that can be tested        around that particular claim of the Motor Theory, but rather
   experimentally. In sum, our model provides a foundation for         to address this latter point and provide a specific computa-
   better understanding the cognition of speech perception,            tionally explicit proposal regarding the nature of the percep-
   speech production, and the interaction between the two.             tion-production link.
                                                                          In this paper, we propose a specific formalization of the
   Keywords: Speech production; speech perception; dynamical           perception-production link within a computational model of
   modeling; perceptuo-motor effects; phonological planning.           the dynamics of phonological planning. To illustrate our
                                                                       model, we focus on the response time data from the re-
                 Perceptuo-Motor Effects                               sponse-distractor experimental task used by Galantucci et al.
Many studies have provided evidence for the influence of               (2009). In this task, subjects learned visual stimulus-spoken
the speech production system during the process of speech              syllable pairings (e.g., if you see && say ba, if you see ##
perception. Yuen, Brysbaert, Davis, & Rastle (2010)                    say da). While subjects were preparing the required re-
showed that the articulations subjects produced could be               sponses (either ba or da), distractors were presented at vary-
modulated by stimuli they perceived immediately before                 ing delays (i.e., Stimulus Onset Asynchronies, “SOAs”)
producing a cued utterance. Specifically, subjects had in-             relative to the presentation of the visual cue indicating the
creased alveolar closure in producing s- or k-initial utteranc-        required response. The distractors were either a short tone,
es when they heard a t-initial distractor, compared to base-           the same syllable the subject was preparing to say (e.g., da-
line cases (t is a sound produced with the tongue-tip making           da), or another syllable that differed in place of articulation
full contact at the alveolar ridge, but for fricatives like s the      from the response (e.g., ba-ga). In the Kerzel & Bekkering
tongue-tip contact is not complete, and for k the contact is           (2000) study, video distractors were used instead of auditory
by a different articulator in a different location). D'Ausilio et      distractors, with similar results.
al. (2009) administered transcranial magnetic stimulation to              Figure 1 summarizes the experimental results from Galan-
the areas of subjects’ motor cortex that control lip or tongue         tucci et al. (2009). First, the presence of any distractor re-
movement and had subjects identify acoustic stimuli that               sulted in longer RTs. Second, there was a monotonic effect
were ambiguous as to place (labial vs. lingual). They found            of SOA on RTs. Both of these effects can be seen by look-
that subjects were more likely to mistakenly perceive stimu-           ing at the Tone condition. RTs in the Tone condition (at
li as having the place whose corresponding motor cortex                both SOAs) were slower than on trials when there was no
                                                                   1241

distractor, and RTs in the Tone condition were longer at
SOA 200 than at SOA 100. From these two effects, it is
evident that the mere presence of any distractor (linguistic
or not) results in a slow-down in RTs. The Identity and
Mismatch conditions introduce effects of linguistic
(in)congruency between the responses and distractors in
addition to whatever process generates the non-linguistic
effects seen in the slow down due to a distractor presence
and SOA. Crucially, RTs in the Mismatch condition were
longer than in the Identity condition.
                                                                                Figure 2: Components of the model.
                                                                  Planning Fields A key concept in the model is that of the
                                                                  planning field. Each phonological parameter of an intended
                                                                  utterance is assigned a planning field. Planning fields evolve
                                                                  over time and determine the specific parameter settings of
                                                                  the phonological parameters in an intended utterance. A
                                                                  planning field is defined by three axes: an axis representing
                                                                  the possible phonological parameter values, an axis repre-
                                                                  senting the activation level associated with each possible
     Figure 1: Result patterns from Galantucci et al. (2009).     phonological parameter value, and an axis representing time
                                                                  (see Figure 3).
   These results motivate two broad computational princi-
ples, which in turn will inform the design of our model.
These are the principles of excitation and inhibition. The
fact that RTs were shorter in the Identity condition than in
the Tone condition indicates the influence of excitation,
since linguistic congruency offsets the slow-down intro-
duced by the presence of a distractor. The longer RTs in the
Mismatch condition compared to the Tone condition show
the influence of inhibition due to linguistic incongruency,
increasing the RTs beyond the effects of the mere presence
of a distractor.
   Dynamical Model of Phonological Planning                             Figure 3: Tongue Tip (TT) articulator planning field.
We propose a formal, dynamical, computational model of
the perception-production link, situating it in the planning         The phonological parameter relevant to the TT field is
process by which phonological parameters are set in speech        that of the constriction location for the tongue-tip articula-
production. The components of the model are shown in Fig-         tor. Therefore, the phonological parameter axis in this field
ure 2. The model includes four dynamical planning fields          is represented by a continuum of constriction locations from
(shaded rectangles), Inputs to these planning fields (ovals)      dental (most anterior) to post-alveolar (most posterior). The
that determine the actual parameter values to be produced,        use of a discrete planning field for each parameter is moti-
and a Monitor function that decides when all of the required      vated by the desire to have our model be maximally compat-
values have been determined.                                      ible with extant models of phonological representation. The
   Figure 2 also shows an Implementation system that exe-         planning fields here correspond closely to the parameters
cutes the motor plans for the intended utterance based on the     used in Articulatory Phonology (Browman & Goldstein,
production parameter values determined by the model. This         1986, et seq.), with a field for each “tract variable”, though
Implementation system is not part of our model. The focus         our model could be applied to any appropriate system. As
in our modeling work is on planning, that is, on the process      with the tongue-tip articulator, there are also planning fields
of choosing values for phonological parameters. This pro-         for the other two primary oral articulators used in producing
cess unfolds in time and, in the schematic shown in Figure        the syllables relevant to the experimental setting at hand—
2, takes place before articulatory movement initiation and        the lower lip (LL) and tongue body (TB)—and one field for
control, which are the business of the Implementation sys-        voicing. The parameter axis for the Voicing planning field is
tem. The Implementation system could be, e.g., either the         represented by the well-known continuum of Voice Onset
Task Dynamics Model (Saltzman & Munhall, 1989) or the             Time (“VOT”).
DIVA model (Guenther, 1995).                                         The planning fields evolve based on inputs to these fields.
                                                                  As we make explicit below, the dynamics of that evolution
                                                              1242

are formalized within the computational framework of Dy-                  dA(x, t) is the change in activation level A of x at time step
namic Field Theory (“DFT”, e.g., Erlhagen & Schöner,                   t. The rate of evolution of the field is controlled by τ, with
2002). Each field evolves such that after sufficient input(s),         larger values of τ resulting in slower evolution of the field. h
a peak of activation builds up and eventually stabilizes, with         is the resting level of the field. The inputs are added to the
one parameter value having a maximum activation level. In              field, when appropriate, by the terms inputRESPONSE(x, t) and
Figure 3, following increasing values on the time axis, we             inputDISTRACTOR(x, t). r and d encode the relative strengths of
can see the gradual evolution of a localized peak in activa-           the inputs. The cross-field inhibition (indicated in Figure 2
tion at some value of constriction location intermediate be-           by the bidirectional arrows between the articulator planning
tween anterior and posterior.                                          fields) introduced by any other articulator field(s) is added
   Representing each articulator as its own field in the model         by the term inhibitionCROSS-FIELD(x, t) when the activation peak
with voicing as one separate field reflects the purpose of a           in another fields exceeds a threshold value (χ). The DFT
planning field, which is to compute a single production val-           dynamics (Erlhagen & Schöner, 2002) capture the case of
ue based on one or more potentially conflicting inputs. Our            parameter setting for one effector. In our case, we have sev-
model assumes that these planning fields are the mechanism             eral articulators, and a single one must be chosen for any
by which phonological planning of any utterance is                     given speech segment. This is the motivation for the cross-
achieved, that is, they are not specific to this experimental          field inhibition. In our model, cross-field inhibition follows
task. The design of the planning fields therefore reflects the         a basic property of DFT in which inhibition comes into play
general demands of speech production.                                  when some threshold is crossed (we illustrate this with sim-
                                                                       ulations below). Noise is added to introduce stochastic be-
Input There are two sources of input to the evolving plan-             havior into the model evolutions. The equation that defines
ning fields. One corresponds to the parameter values for the           the evolution of the Voicing field differs from the one that
required response, and the other corresponds to the parame-            defines the evolution of the articulator fields only in that it
ter values for the auditory distractor perceived during the            does not contain a term for cross-field inhibition, because
planning of the utterance. Inputs are represented as two-              the Voicing field neither inhibits nor is inhibited by any
dimensional distributions of activation levels across the              other planning field. This design reflects the fact that voic-
spectrum of possible values for a given parameter. Although            ing and articulator are cross-classifying parameters for Eng-
not required by the framework, each given input in the pre-            lish consonants (Chomsky & Halle, 1968).
sent model is a normal distribution defined by the equation:              The interaction term, interaction(x, t), the DFT “engine”
                                                                       that drives the evolution of the activation field through local
                                               2
             activationinput = e –(x−val+noise) / 2σ 2                 excitation and global inhibition, is defined by:
                                                                                                               2
                                                                                                                 /2 σ w2 )
   val indicates the mean of the distribution, and was varied                              w(x) = wexcitee−( x             − winhibit
from trial to trial by adding a small noise term. Since con-
striction location does not vary in the examples used in the              The interaction term induces changes in the field as some
model of this task, the input values for constriction location         value(s) of x approach a “soft” threshold (θ), which is de-
did not materially change in the simulations. The standard             termined by a sigmoid threshold function, defined by:
deviation of the distribution (σ) defines its width. Both re-
sponses and distractors in the task modeled here are voiced,                                                      1
                                                                                             f (u) =
so the input to the Voicing field was always the same.                                               1+ exp[−β (u − θ )]
Dynamics The purpose of the planning fields is to deter-                  The use of a soft threshold means that some x values be-
mine the phonological parameter values to be sent to im-               low θ do engage the interaction term, but the contribution to
plementation. Planning fields have two possible stable                 the interaction of activation values less than θ diminishes
states. They either stay flat at their resting value, or they can      with distance from θ. The system is non-linear due to this
have a single, sustained peak of activation. The value sent to         soft threshold, in that incremental changes in activation lev-
implementation for a given field is the parameter value that           els have a non-uniform effect on the field’s evolution.1
has the maximum amount of activation when the field stabi-
lizes in this second stable state. The fields in the model                1
                                                                            The variable values used were: τ = 150 and h = –3.25. The
evolve based on the mechanisms of DFT. The dynamics of                 noise term added/subtracted a random amount of activation averag-
each of the three articulator planning fields (LL, TT, and             ing approximately 1.25 activation units to every x value at each
TB) are controlled by the equation:                                    time step in the evolution. The resting level of an activation field
                                                                       was therefore about –2 activation units, equal to the resting level h
       τdA(x, t) = –A(x, t) + h + r(inputRESPONSE(x, t))               plus noise. The response input weight (r) was 2.7, and was the
          + d(inputDISTRACTOR(x, t)) – inhibitionCROSS-FIELD(x, t)     same for inputs to both the articulator and Voicing field of the
                                                                       required response. d was 4.5. The cross-field inhibition threshold
          + interaction(x, t) + noise
                                                                       (χ) was 0. The amount of cross-field inhibition subtracted on each
                                                                       step from other fields when an articulator field was above (χ) was
                                                                       0.75. The values for the interaction term were the same in all four
                                                                   1243

   Since the required response and the perceived distractor                   in those fields by the interaction term. The TB and LL fields
both serve as input to the model, the evolution of the fields                 receive no input, and there is no change in their activation
is driven by a combination of excitation and inhibition, de-                  levels until around time step 200. At that point their activa-
pending on whether the two inputs have congruent parame-                      tion levels start to drop due to the TT field reaching the
ter values. Congruent inputs to the model introduce excita-                   cross-field inhibition threshold (χ), indicated by the horizon-
tion, while incongruent inputs inhibit each other.                            tal dot-dashed teal line drawn at activation level 0. The TT
                                                                              and Voicing activation levels continue to rise until they both
Monitor The Monitor determines when activation has built                      have passed the criterion value (κ), indicated by the solid
up in required fields to a level that is sufficient to send to                line drawn at activation level 5. The time step at which the
Implementation, based on a criterion value (κ), which is the                  second field passes κ (minus 100, since that is the time step
same across all four planning fields. The decision criteria                   at which the cue is presented) is marked as the RT on that
for the Monitor are straightforward. The Monitor waits until                  trial (the solid vertical line at about time step 425). The
the activation level for some x value in both the Voicing                     Monitor takes the maximum parameter values from the
field and one articulator field reach criterion. At that point it             Voicing and TT fields and passes them to Implementation.
chooses the parameter values from those two fields with the
highest activation level to be sent to Implementation. This
has the effect that sometimes it is the Voicing field and
sometimes an articulator field—whichever field evolves
more slowly—that determines the RT on the trial.
Simulations                                                                     A)
Figure 4 illustrates the model dynamics by showing how the
planning fields evolve during a single trial in three different
conditions of the experimental study from Galantucci et al.
(2009). The figures show the maximum activation level over
time for each of the four planning fields. The dot-dashed red
line shows the TT field evolution, the dashed blue line
shows the LL field, the solid pink line shows the TB field,
and the solid black line shows the Voicing field. Differences
in the rate of rise of the maximum activation level of the
fields predict differences in experimental RTs.
   Figure 4A shows the evolution of the fields in the Tone                      B)
condition. Since the tone distractor has no linguistic content,
it serves as a baseline reference of how the planning fields
evolve in the unperturbed case. The vertical dotted lines at
time steps 100 and 500 indicate the duration of the required
response input to the fields. Thus, the activation levels of
the TT and Voicing fields start to rise at time step 100, the
point at which the subject begins planning the required ut-
terance based on the visual cue on that trial (here
# # instructing the subject to say da). The horizontal dot-
dashed black line drawn at activation level 0.7 indicates the
soft threshold (θ) that determines the engagement of the                        C)
within-field interaction term. The effects of the interaction
term can be seen in that the rate of increase in the activation
level of the TT and Voicing fields is not linear: as the acti-
vation level of each field approaches θ, the steepness of the
curve increases due to the local excitation being generated
                                                                                    Figure 4: Evolution of planning fields in (A) the Tone,
activation fields: θ = 0.7, wexcite = 0.45, winhibit = 0.1, σ = 1. For the        (B) Identity, and (C) Mismatch conditions. Dashed blue
sigmoid function, β was always 1.5. The constriction location input
distribution for all articulator fields had a mean (val) of 0 and SD =
                                                                                 lines show the maximum activation level of the LL field,
2, defined on an arbitrary scale of constriction locations that                 dot-dashed red of the TT field, solid pink of the TB field,
ranged from –10 to 10. For the Voicing parameter, distributions for            solid black of the Voicing field. The horizontal black line at
all voiced stimuli input had a mean of 5 ms VOT and SD = 45 ms.                 activation = 5 shows the threshold κ at which the Monitor
The criterion value (κ) was 5. The specific values of the variables             chooses values for production, and the vertical black line
in the above equations are not meaningful in and of themselves.                   perpendicular to it shows the simulated RT on the trial.
Their values relative to each other are more informative.
                                                                          1244

   Figure 4B shows the evolution of the fields in the Identity      response differed in articulator. As explained above, in this
case on a trial with a da response and da distractor. From          case cross-field inhibition slows down the evolution of the
time step 0 to 200, all fields evolve in the same way as in         articulator field for the required response.
the Tone condition. The vertical dashed lines at time steps
200 and 325 indicate the duration of the input from the dis-                                  Discussion
tractor. Since the distractor inputs are qualitatively the same     Our model fills a gap in the speech planning literature.
as those for the response, the activation level for the TT and      Models of speech motor implementation (Saltzman & Mun-
Voicing fields rises at a much greater rate than in the Tone        hall, 1989; Guenther, 1995) explicitly capture how articula-
condition because both inputs add activation to the same            tors move through space and over time to achieve their lin-
range of parameter values, in addition to the local excitation      guistic targets, but existing models of the sources of those
being generated by the interaction term. The fields therefore       target values either do not address the timecourse of the
cross κ earlier than in the Tone condition, and the simulated       planning process (Chomsky & Halle, 1968; Browman &
RT is shorter.
                                                                    Goldstein, 1986), or assign little to no role to representa-
   Figure 4C shows the evolution of the fields in the Mis-
                                                                    tions at the level of phonological features (Dell, 1986; Roe-
match case on a trial with a da response and ba distractor.
                                                                    lofs, 2000). Our results show the benefit of a model that
Since the response and distractor share the same value of
                                                                    addresses timecourse and phonological features explicitly.
voicing, the evolution of the Voicing field in this condition          Our model makes additional predictions for the cue-
is qualitatively the same as in the Identity case. The evolu-       distractor task that can be tested experimentally. The model
tion of the TT field, however, is different. When the distrac-      predicts that similar RT effects should be obtained when the
tor input starts at time step 200, the activation level of the      Mismatch condition is such that the distractor and response
LL field begins to rise, and eventually crosses χ, introducing
                                                                    differ in voicing rather than in articulator. The model pre-
cross-field inhibition to the TT field. The distractor input
                                                                    dicts longer RTs in this Mismatch condition (e.g., da-ta)
ends at time step 325, but by that time the LL field maxi-
                                                                    than in the Tone or Identity condition (e.g., da-da). In our
mum is well above θ, so it maintains a peak of activation for
                                                                    model, the source of this difference in RTs is the within-
some time due to the interaction term, and the cross-field          field inhibition that arises from the introduction of two in-
inhibition of the TT field by the LL field therefore persists.      compatible inputs to the same field. This within-field inhibi-
As a result, the rate of rise of the TT field activation level      tion is an inherent property of the DFT computational
slows down compared to its rise in the Tone condition. The          framework. Galantucci et al. (2009) did not test this condi-
Monitor has to wait longer for the TT field to cross κ, and
                                                                    tion, but results reported by Roon (2013) show perceptuo-
thus the RT on this trial is longer than in the Tone condition.
                                                                    motor effects of voicing in the response-distractor task that
                                                                    are independent of articulator. This prediction is thus borne
                                                                    out. Figure 5B shows the model predictions for an experi-
                                                                    ment where the Identity condition is the same as the one
                                                                    reported in Figure 5A (da-da), but where the Mismatch
                                                                    condition is da-ta. The model predicts slower RTs in the
                                                                    Mismatch condition than in the Tone condition. Future work
                                                                    will involve expanding the model to accommodate these
                                                                    new experimental results.
                                                                       A second set of predictions concerns variation and pho-
                                                                    netic detail in representations and processes. Since catego-
    Figure 5: (A) Model simulations of the Galantucci et al.        ries like voicing are defined as distributions on a phonetic
 experiment. (B) Predictions for a scenario where distractor        continuum like VOT, compatible inputs need not be exactly
    and response differ in Voicing rather than articulator.         the same in order to mutually excite each other: it is suffi-
                                                                    cient for the maximum activation peaks of two inputs to be
   Using our model, we simulated 150 trials for each of the         near enough to each other. This excitation happens automat-
three conditions (Identity, Tone, and Mismatch) at an SOA           ically, without any need to classify inputs categorically by
of 100 time steps for a total of 450 trials. On each trial, the     defining category ranges. We plan to pursue this set of pre-
time step at which the Monitor determined the RT was rec-           dictions in future work as well.
orded. The activation level of each planning field was reset           Most speech consists of utterances that are longer than
to its trial-initial state at the beginning of each trial. The      monosyllables. Our present model does not address the
simulated results are shown in Figure 5A. The model quali-          planning field dynamics beyond CV syllables, which is
tatively replicates the experimental results from Galantucci        what is required to account for reported perceptuo-motor
et al. (2009). RTs in the Identity condition were shorter than      effects. Future expansion of the model will address the dy-
the Tone condition, due to the reinforcing inputs and lack of       namics involved in the planning of larger utterances.
any inhibition. On the other hand, RTs were longer in the              Our model of the observed experimental effects bears di-
Mismatch condition than in the Tone condition (and than             rectly on establishing the nature of the perception-
the Identity condition). This is because the distractor and         production link. In our model, speech perception is linked to
                                                                1245

speech production as part of the process by which parameter        recommendations expressed in this material are those of the
values are set. The link between perception and production         authors and do not necessarily reflect the views of the Na-
is the obligatory input of the perceived distractor to the mo-     tional Science Foundation. AIG gratefully acknowledges
tor planning field shown in Figure 2. Given the facilitation       support from ERC AdG Grant 249440.
and inhibition based on (in)congruency between distractors
and responses, there must be some intersection between the                                  References
motor codes activated during motor planning of the required        Browman, C. P., & Goldstein, L. M. (1986). Towards an
response and the codes activated during the perception of             articulatory phonology. Phonology Yearbook, 3, 219–252.
the distractor. The term “codes” refers to parameters such as      Chomsky, N., & Halle, M. (1968). The Sound Pattern of
voicing and articulator, and more precisely to the parameter          English. New York: Harper & Row.
values represented in our model. Our claim is not that the         D'Ausilio, A., Pulvermüller, F., Salmas, P., Bufalari, I.,
codes activated by perceiving the distractor must exclusive-          Begliomini, C., & Fadiga, L. (2009). The motor
ly be motor codes. Rather, it is that the codes activated in
                                                                      somatotopy of speech perception. Current Biology, 19,
the perception of the distractor must minimally be motor
                                                                      381–385.
codes. Our study was not designed to address whether non-
                                                                   Dell, G. S. (1986). A spreading-activation theory of retrieval
motor codes are also activated. Our results are fully compat-
                                                                      in sentence production. Psych. Review, 93, 283–321.
ible with the Motor Theory (Liberman & Mattingly, 1985).
                                                                   Diehl, R. L., Lotto, A. J., & Holt, L. L. (2004). Speech
Our results are also consistent with theories that do or could
                                                                      perception. Annual Review of Psychology, 55, 149–179.
propose a link between auditory-acoustic (or other) codes          Erlhagen, W., & Schöner, G. (2002). Dynamic field theory
that are activated during the perception of the distractor, and       of movement preparation. Psych. Review, 109, 545–572.
motor codes corresponding to these auditory-acoustic codes
                                                                   Galantucci, B., Fowler, C. A., & Goldstein, L. M. (2009).
(cf. Viviani, 2002: Figure 21.12), as long as a link between
                                                                      Perceptuomotor compatibility effects in speech. Attention,
these other codes and the motor codes is assumed.
                                                                      Perception, & Psychophysics, 71(5), 1138–1149.
   In sum, the perception-production link must be specified
                                                                   Galantucci, B., Fowler, C. A., & Turvey, M. T. (2006). The
at the level of setting motor parameter values, including
                                                                      motor theory of speech perception reviewed.
articulator and voicing, that need to be activated either di-
                                                                      Psychonomic Bulletin & Review, 13(3), 361–377.
rectly or via associated codes. The effects of the perception-
                                                                   Guenther, F. H. (1995). Speech sound acquisition,
production link are seen as the influence of a perceived dis-
                                                                      coarticulation, and rate effects in a neural network model
tractor on the process of setting those parameters, i.e., on a
                                                                      of speech production. Psych. Review, 102, 594–621.
production process, as seen in the reported RT modulations
                                                                   Kerzel, D., & Bekkering, H. (2000). Motor activation from
and their simulation by our model.
                                                                      visible speech: Evidence from stimulus response
                                                                      compatibility. Journal of Experimental Psychology:
                        Conclusions                                   Human Perception and Performance, 26(2), 634–647.
During speech production, a speaker must retrieve the pho-         Liberman, A. M., & Mattingly, I. G. (1985). The motor
nological representations of the required utterances by as-           theory of speech perception revised. Cognition, 21, 1–36.
sembling a set of parameter values that specify the vocal          Lotto, A. J., Hickok, G. S., & Holt, L. L. (2009). Reflections
tract actions corresponding to these utterances. We have              on mirror neurons and speech perception. TRENDS in
presented a formal, dynamical, computational model of this            Cognitive Science, 13, 110–114.
process. In the model, assigning values to these parameters        Roelofs, A. (2000). WEAVER++ and other computational
is a time-dependent process, captured as the evolution of a           models of lemma retrievala and word-form encoding. In
dynamical system over time. The model accounts for exper-             L. R. Wheeldon (Ed.), Aspects of Language Production
imental results that have been proposed as evidence for an            (pp. 71–114). Philadelphia: Psychology Press.
intimate link between perception and production. In our            Roon, K. D. (2013). The dynamics of phonological
model, the perception-production link consists of the phono-          planning. Doctoral dissertation, Department of
logical parameter values of a perceived stimulus obligatorily         Linguistics, New York University, New York, NY.
contributing to the evolution of the activation levels of the      Saltzman, E. L., & Munhall, K. G. (1989). A dynamical
fields engaged with the ongoing phonological planning of a            approach to gestural patterning in speech production.
required response. The present model can explain reported             Ecological Psychology, 1(4), 333–382.
effects on response times, and makes new, experimentally           Viviani, P. (2002). Motor competence in the perception of
testable predictions about similar response time modula-              dynamic events: a tutorial. In W. Prinz & B. Hommel
tions. The model therefore provides a foundation for a better         (Eds.), Common mechanisms in perception and action:
understanding of speech production, perception, and the link          Attention and performance XIX (pp. 406–442).
between the two.                                                      Oxford/New York: Oxford University Press.
                                                                   Yuen, I., Brysbaert, M., Davis, M. H., & Rastle, K. (2010).
                    Acknowledgments                                   Activation of articulatory information in speech
KDR gratefully acknowledge research supported by NSF                  perception. Proceedings of the National Academy of
Grant 0951831. Any opinions, findings, and conclusions or             Sciences (Social Sciences), 107(2), 592–597.
                                                               1246

