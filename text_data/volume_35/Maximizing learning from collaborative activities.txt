UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Maximizing learning from collaborative activities
Permalink
https://escholarship.org/uc/item/04q05458
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Lam, Rachel
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Maximizing learning from collaborative activities
                                                 Rachel J. Lam (rachel.lam@asu.edu)
                                                          Arizona State University
                                                     Teachers College, 300 E. Lemon St.
                                                             Tempe, AZ 85281
                               Abstract                                    One limitation to training students in specific skills before
                                                                        collaborating is that they often fail to retain those skills after
   Utilizing a Preparation for Future Learning paradigm and the         time (Webb, Nemer, & Ing, 2006). The challenge of
   Interactive-Constructive-Active-Passive framework, this study
   examined how two different kinds of cognitively engaging             structured guidance during collaboration is that too much
   activities prepared students to learn from collaborating.            can constrain creativity and flexible discussion, which can
   Findings show that preparing prior to collaborating improved         hinder learning (Cohen, 1994). Therefore, one question that
   learning, but a difference was not detected in the type of           remains is, does the effort and time that it takes to train or
   preparation. In addition, differences in learning outcomes were      guide students in collaborative behaviors really pay off?
   only present in measures of deep knowledge. Analyses used a          Work that has investigated the design of collaborative
   multilevel method targeted to dyadic data. Discussion addresses
                                                                        activities to naturally elicit effective dialoguing addresses
   designing collaborative classroom activities that are effective
   and efficient for deep learning, as well as the importance of        this challenge, showing that open-ended and flexible tasks
   aligning assessments to depth of learning.                           can enrich discussion (Janssen, Erkens, Kirshner, &
                                                                        Kanselaar, 2010; Van Boxtel, Van der Linden, & Kanselaar,
   Keywords: collaborative learning; preparation for future             2000). However, this only occurs when students have
   learning; cognitive engagement; classroom learning.                  sufficient prior knowledge (Nokes-Malach, Meade, &
                                                                        Morrow, 2012). Thus, a collaborative learning method that
                          Introduction                                  avoids the time and effort needed to train students in
Collaborative learning has become a common instructional                particular skills or structure their instance-by-instance
strategy in a variety of educational settings because of its            dialogic behaviors, while providing the opportunities for
potential to boost student learning. Through peer discussion,           students to acquire adequate prior knowledge is investigated
students can receive immediate feedback, ask questions,                 in the current study.
generate explanations, challenge each other, jointly
construct understanding, and elaborate on each other’s                               Cognitive theoretical models
ideas, which are all behaviors that have been shown to                     Two cognitive theoretical models supported the design of
improve learning outcomes in both the classroom and                     the collaborative activities in this study. The Interactive-
laboratory. However, despite the extensive research that has            Constructive-Active-Passive (ICAP) framework and the
been conducted on collaborative learning, the literature is             Preparation for Future Learning (PFL) paradigm are
still unclear as to what factors lead to the best learning              described below.
outcomes, in particular, for deep understanding of concepts.
Thus, this work aimed to investigate two factors that may
                                                                        The ICAP framework
improve deep knowledge, in particular, in a conceptual (as
opposed to a problem-solving) domain: (a) individually                     The ICAP framework differentiates student engagement
engaging in the learning material prior to collaborating and            in learning tasks by categorizing students’ overt behaviors
(b) “constructively” engaging, where students are generating            as Interactive, Constructive, Active, or Passive, and is
(constructing) new knowledge beyond the learning material.              founded on theoretical assumptions about how those
   There are mixed results as to how collaboration affects              behaviors link to different cognitive processes (Chi, 2009;
student learning (Barron, 2003; Craig, Chi, & VanLehn,                  Menekse, Stump, Krause, & Chi, 2012). An Interactive
2009). In general, students do not always take advantage of             behavior might be debating or extending a partner’s idea
the benefits collaboration affords, thus, researchers have              and the cognitive process underlying Interactive
searched for ways to help students collaborate more                     engagement would be co-creating knowledge. Inventing a
effectively. Methods such as training students in                       rule, self-explaining, or creating a concept map would be
collaboration skills (Hausmann, 2006; Uesaka & Manalo,                  Constructive, the underlying cognitive process being
2011), providing structured guidance to students while                  creating new knowledge. Active behaviors include
interacting (Coleman, 1998; Walker, Rummel, &                           highlighting a textbook chapter or copying solutions steps
Koedinger, 2011), and designing collaborative learning                  from the board, and correspond to assimilating knowledge.
environments that elicit meaningful discussion (Engle &                 Listening or watching would be considered Passive,
Conant, 2002; Kapur & Bielaczyc, 2012) have been found                  corresponding to the process of storing knowledge. The
to improve learning from collaborating. However, there are              ICAP hypothesis makes the prediction that Interactive
also challenges and limitations to these methods.                       activities will produce better learning outcomes than
                                                                        Constructive activities, which are better than Active
                                                                    2814

activities, which are all better than Passive activities:         lies in the “structure” of the model (Chi & VanLehn, 2012).
I>C>A>P. There is empirical support for the ICAP                  Surface features can be facets such as labels and definitions,
hypothesis, although the Interactive category carries several     physical characteristics, or other plain facts. Structural
caveats (Menekse et al., 2012). One is that engagement            knowledge is much more complex, representing the
should only be considered Interactive when both individuals       relationships between the features of a concept and/or the
in a dialogue are engaging constructively. This does not          process by which a concept occurs or functions. Thus, the
always occur (literature on the process of collaboration in       current work used student-generated written responses to
learning settings attests to this claim). Thus, this current      assess deep, structural-based learning, while T/F pre- and
study will address the question of how learning is affected       posttests were used to assess shallow, surface-feature
by interacting on a Constructively designed task or an            learning.
Actively designed task.
                                                                                             Method
The PFL paradigm                                                     The study used a 2x2 experimental design examining
   This paradigm takes into account how earlier learning          Preparation (No Prep and Prep) and Type of Task (Active
experiences can shape future learning, under the perspective      and Constructive). The two dependent variables were
that prior learning can activate a mental model to either         shallow learning and deep learning. In order to preserve
facilitate or hinder the learning of a new concept (Schwartz,     both internal validity and ecological validity, the study was
Sears, & Chang, 2007). Although the PFL paradigm was              conducted as a classroom study across four introductory
introduced in the literature over two decades ago (Schwartz       psychology classes with equal representation of the four
& Bransford, 1998), more recent work has used this model          conditions in each classroom. The students participated in
to investigate learning outcomes in a variety of domains          the study as a part of their “regular” classroom activity for
(Chin et al., 2010, in elementary school science; Gadgil &        the weekly topic of “concepts of memory.”
Nokes-Malach, 2012, in cognitive psychology; Schwartz,
Chase, Oppezzo, & Chin, in press, in physics). This work          Participants
has shown that invention-type tasks better prepare students
                                                                     Ninety students from four Psych 101 courses at a large
to learn from a lecture (Schwartz & Martin, 2004). In other
                                                                  community college in a Southwestern city in the United
words, tasks that are set up to cognitively engage students in
                                                                  States participated in this study. The mean age of students
a “constructive” way, by causing students to generate new
                                                                  was 21 years and the sample represented an ethnically
knowledge (Chi, 2009), are those that best prepare students
                                                                  diverse population (46% Hispanic, 37% Caucasian, 10%
to learn in a future task. The majority of the work that has
                                                                  African American, and 7% Asian, Native American, or
investigated the PFL paradigm uses some form of didactic
                                                                  Middle Eastern). Fifty six percent of the students were
instruction (i.e. lecture) as the future task, thus, little is
                                                                  female, 44% were male.
known about the effects other forms of instruction as future
tasks, such as collaboration. The current study utilizes the
PFL model to structure collaborative learning activities for      Materials
students, however, the future activity is peer discussion            Regarding the topic of interest, prior research attests to
(instead of a lecture) and students individually (rather than     the difficulty that students have in deeply understanding the
collaboratively) engage in the preparation task.                  differences between a variety of concepts of memory, in
                                                                  particular, for encoding- and schema-based concepts
Measures of learning and mental models                            (Schwartz & Bransford, 1998). Thus, all learning activity
   In light of using the two aforementioned cognitive             materials and assessments were based on Schwartz and
perspectives as the basis for this study, the measures of         Bransford’s (1998) materials. These materials were the only
learning outcomes should be viewed as representing student        form of instruction to students for the topic. Students
mental models of the concepts being tested. Mental models         received no other instructional material (lecture, textbook
can be assessed through externalizations such as self-            readings, etc.) prior to the study and, therefore, were
generated concept maps, matrices, drawings, and free-             assumed to have limited prior knowledge of the concepts.
writing (Janssen et al., 2010; Schwartz, 1995; Van                   The study used the following materials: (1) pretest and
Amelsvoort, Andriessen, & Kanselaar, 2007). Multiple-             demographic survey, (2) four versions of learning materials
choice or T/F tests are often used to measure student             based on condition, (3) posttest, and (4) scoring rubrics.
learning with regard to accuracy or correctness of                   (1) The pretest consisted of T/F questions that were very
knowledge, however, these are not necessarily appropriate         slightly modified from Schwartz and Bransford’s (1998)
to fully assess a mental model (Bransford & Schwartz,             verification measure, which was used in several studies on
1999; Schwartz et al., 2007). A more complete picture of          concepts of memory.
student knowledge can be captured by combining these                 (2) The materials used during the learning phase were
types of assessments. With respect to measuring depth of          equivalent in domain content, however, the specific task
knowledge, shallow knowledge can be equated to the                instructions varied according to the ICAP cognitive
“surface features” of a mental model, while deep knowledge        engagement definitions and whether or not the condition
                                                              2815

included a preparation period. In Prep conditions, students        prior deep knowledge of memory concepts. As already
were given a portion of the class time to individually work        mentioned, they not did have previous instruction on the
on the task prior to engaging with a partner, while students       topic in their classes and in addition, they produced low
in the No Prep conditions worked with a partner for the            shallow knowledge scores at pretest (M=50.8%, SD=21.6).
entirety of the learning phase. Active tasks asked students to     Thus, rather than a gain score, the deep learning measure
work within the existing learning materials (i.e. they did not     used only the posttest prediction task scores.
have to generate inferences beyond the materials to                   (4) Scoring rubrics were developed in order to quantify
complete the tasks), while the Constructive tasks required         students’ responses to these prediction tasks. Responses
students to invent concepts. To provide an example, the            were coded by how well they represented any of the
Constructive task required students to answer questions            following eight concepts: elaboration, schema, gist, serial
such as, “Why do people remember certain kinds of                  position effect, generation effect, obstacle recall,
information, but not other kinds?” after studying a memory         interference, and encoding failure. These concepts may have
experiment and its results. They had to generate ideas about       been explicitly learned in the Active conditions, through the
the process of memory. The Active version of the task, on          “search and select” tasks, or may have been implicitly
the other hand, instructed students to study a list of memory      learned in the Constructive conditions, through the
terms and their descriptions. They then applied the terms to       “invention of concepts” tasks. A code of “other” was used
the same memory experiment included in the Constructive            for responses that represented novel ideas about memory
version by writing the term next to the appropriate result of      (i.e. ideas that were not taught through the activities). This
the experiment. These students had to “search and select,”         coding translated to a score ranging from 0-3 points, based
but did not necessarily have to generate any new                   on a holistic-style rubric. A higher score indicated
knowledge. Since the Active tasks took much less time to           knowledge of a broader range of concepts, representing a
complete (as shown in a prior pilot study of this work), they      more complete mental model of memory. A score was also
included a secondary memory experiment task that was               given for the quality of students’ reasoning supporting the
identical in structure to the first, but with a different cover    relationship between their predictions and the concepts, also
story. This was to control for time-on-task, which was             ranging from 0-3 points. This score indicated knowledge of
equalized across the four conditions.                              the relationships between the concepts and their applications
   (3) The posttest included the same T/F questions that           to novel settings, thus, representing a better structured
were used in the pretest. To avoid a “testing effect” (i.e.        mental model. A total score of 0-6 was possible. Two raters
learning solely attributed to the recognition of identical test    scored a randomly selected 20% of the data and intraclass
questions at a later testing phase), the ordering of the           correlation was used to assess inter-rater reliability,
questions was changed and there were four to five days in-         ICC(2,1)=.76, p<.001. One rater scored the remaining tests.
between the tests. (See work by Bjork and Storm, 2011, for
details regarding the conditions under which testing               Procedure
influences learning.) Student gain scores from pre- to                The study took place over the course of a week. On the
posttest served as the measure of shallow learning.                first day, students took the pretest and filled out the
   Two additional tasks were included on the posttest to           demographic survey. Students were given 15 minutes to
obtain a measure of deep learning. These were “prediction”         complete the pretest.
tasks, where students had to study novel experiments on               Students completed the learning activity phase during the
memory (i.e. they did not appear in the learning materials)        next class. They were randomly assigned to one of the four
and synthesize their recently learned knowledge in order to        conditions: (a) No Prep-Active, (b) No Prep-Constructive,
apply it to new experimental conditions, generate new              (c) Prep-Active, and (d) Prep-Constructive. For No Prep
inferences about how memory works, predict the results of          conditions, students were randomly assigned to a partner
the experiments, and provide evidence of their reasoning for       and told to follow the instructions on their packets. They
predictions. Students freely wrote their responses to a set of     were encouraged to share ideas, try come to agreement
sub-questions that all corresponded to a basic question of,        before writing down an answer, and not to worry about
“Based on what you now know about memory, how do you               writing right or wrong answers. Instructions varied
think the results of these experiments will turn out?”             depending on whether students were completing the Active
   Because these types of prediction tasks are likely deeply       or Constructive version (described in the Materials section),
cognitively engaging, there was concern that including any         but all students were told to try to contribute equally to the
on the pretest might influence students to engage differently      discussion. For Prep conditions, students first completed an
in the learning activity tasks. In particular, the Active          individual packet. They were told not to worry about right
conditions may have become contaminated if students were           or wrong answers and to do their best. They were informed
primed in a pretest task to think more deeply about the            that they would use this packet to work with a partner. After
concepts. Thus, the pretest only included the shallow T/F          the individual work (ranging from 15-20 minutes), students
questions. Although this prevented obtaining any measure           were randomly paired and spent the remaining class period
of deep knowledge prior to the learning phase, this was of         doing their collaborative packet (10-15 minutes). They were
less concern since it was highly unlikely that students had        told to share their ideas, try to contribute equally to
                                                               2816

discussion, and come to agreement before writing down                     These results are not surprising because even the “lowest”
their answers. At the end of class, all materials were                 condition (No Prep-Active) constitutes an effective teaching
collected (each pair turned in a jointly completed                     strategy in a number of ways. Students were provided terms
collaborative packet). Students spent 30-35 minutes on the             and definitions, the opportunity to apply those to real-world
learning task in all conditions.                                       examples, and the benefit of engaging in discussion.
   The posttest was given in the following class and was               Because these pre- and posttests were used to assess the
completed individually. Students spent 35-50 minutes on the            knowledge of the surface features of memory concepts,
posttest. Any students who finished before 30 minutes                  students were expected to gain in all conditions. The
passed were asked to go over their answers one more time.              differences between conditions were only hypothesized for
                                                                       deep learning, attesting to the sensitivity of the manipulation
                              Results                                  of the conditions. The deep learning results are below.
   To avoid violation of the assumption of independence of
subjects (which traditional ANOVA assumes) (Kenny,                     Deep learning
Kashy, & Cook, 2006), a dyadic multilevel model was used                  Ninety students completed the prediction task portion of
for all analyses. Figure 1 illustrates the model. The analytic         the posttest. The prediction task posttest scores were reliably
technique was a linear mixed model with the Restricted                 different across conditions. There was a main effect of
Maximum Likelihood (REML) method, appropriate to cope                  Preparation F(1,41.1)=5.79, p<.03, but no effect of Type of
with dependency between partners within dyads.                         Task, nor an interaction effect. Students who prepared in the
                                                                       task individually in either type of task before collaborating
                                                                       showed evidence of deeper learning. See Figure 2.
                  Figure 1: Multilevel dyadic design.
Shallow learning
   Analysis of the pre- and posttests compared learning gains
across conditions. “Normalized change” calculations were
used to adjust learning gains by accounting for influences of                         Figure 2: Prediction task results.
pretest scores, yielding a more sensitive measure of gains
(Marx & Cummings, 2007). When post>pre, the following                     This result was not expected since prior work supports the
formula was used: post-pre/1-pre. When post<pre, a                     notion that “constructively” engaging activities should
different formula was used: post-pre/pre. Although students            produce improved learning above “actively” engaging
gained in all conditions, there was no reliable difference             activities. As shown in Figure 2, there is virtually no
between conditions. Table 1 summarizes these results.                  difference between the Active and Constructive conditions
                                                                       when students individually prepared prior to collaborating.
              Table 1: Shallow learning mean scores                    One interpretation of these results is that the inclusion of
  Condition              n      Pretest% Posttest%          Adj.       preparation prior to discussion in a collaborative activity
                                                            Gain       boosts learning such that it overrides any effects of type of
  No Prep-Active         14     53.6         72.6           .43        task. It is possible that the inclusion of an individual
  No Prep-               18     49.1         61.1           .21        preparation period increases the likelihood that students will
    Constructive                                                       engage constructively in a dialogue, regardless of whether
  Prep-Active            15     46.7         63.3           .28        the task itself requires generation of new knowledge. In
  Prep-                  19     53.5         71.9           .40        other words, the preparation may have spontaneously
    Constructive                                                       impelled students to engage constructively even in Active
  Total                  66     50.8         67.2           .33        tasks, thus, further exploratory analyses were conducted to
  Note: Due to incompletion of the T/F questions at either pre- or     check this.
  posttest, the total sample was reduced from 90 to 66 students.
                                                                   2817

Preparation facilitates constructive engagement                    opportunities that peer discussion offers as compared to
   To assess differences between how the No Prep-Active            didactic forms of instruction, this is an important finding
and Prep-Active students engaged in the tasks, the                 towards design of classroom activities, especially with
collaborative activity worksheets were examined. They              regard to deep learning. Although this study cannot inform
were scored by student effort, rather than in correctness of       on the comparison between collaborative learning and
responses, since these were never intended to measure              didactic instruction as future learning tasks of a PFL model,
learning. Support for such a strategy can be found in work         it supports the need for more work in this area.
on dynamic assessments (Bransford & Schwartz, 1999;                   The ICAP framework was not necessarily supported as an
Schwartz et al., 2007), which measure readiness to learn,          effective tool for designing learning activities since, overall,
rather than learning outcomes. Thus, as related to the PFL         there were no differences in type of task on learning.
paradigm, these learning tasks can be viewed as readiness          However, the ICAP hypothesis predicts outcomes based on
tasks that prepared students to engage in collaboration, with      student engagement, not on task instructions. Thus, the
the posttest prediction task measuring learning. It is possible    exploratory analysis showed that students in the Prep-Active
that students from the Prep-Active condition developed an          condition might have engaged constructively, justifying a
enhanced readiness for learning in discussion, accounting          null effect. Additionally, one might argue that because all
for the improved performance on the prediction tasks.              four conditions included collaborative activities, the level of
   Each dyad that completed at least 94% (15 of 16 items) of       engagement for all conditions was actually Interactive.
the activity worksheet received an effort score of two; those      What is of interest here is that there then should have been
that completed at least 75% received an effort score of one;       an overall null result, however, that did not occur in the
zero points were given to any dyads that completed under           deep learning outcomes. Chi (2009) discusses the idea that
69% of the activity (only four dyads). Since amount of work        working in pairs does not automatically make engagement
completed is not a thorough indication of how deeply               Interactive, and that to be truly Interactive, both students
engaged students were in the activities, the number of times       must at minimum be engaging constructively. Thus, with
students within a pair disagreed was also taken into account.      regard to design of learning tasks, one way to better ensure
The worksheets included a line for each item that asked            that students engage Interactively in collaborative tasks is to
students if they agreed on the answer, and if not, they were       include an individual preparation task prior to discussion.
instructed to explain their disagreements. (Work on                Future work is examining discourse data from a sampling of
argumentation shows that students benefit from talking             pairs from this study to further inform on how discourse
through disagreements, Asterhan & Schwarz, 2009.)                  processes related to learning, within in the contexts of the
Analysis of discourse could have provided a better measure         ICAP framework and PFL paradigm.
of engagement, however, that was beyond the scope of this             This study draws concern toward prior work that has not
paper. Thus, activity effort and average number of                 used analytic techniques that account for dependency
disagreements per pair were used to measure engagement.            between partners within dyads. Future work in areas of
   Results showed that dyads in the Prep-Active condition          collaborative learning should utilize dyadic or multilevel
produced a higher activity score (M = 1.71) compared to            models to analyze data that includes individual student
those in the No Prep-Active condition (M = 1.43), and had a        outcomes (such as individually completed posttests).
slightly higher average number of disagreements (.55                  Regarding the learning assessments, this study shows the
compared to .45, respectively). Although none of these             usefulness of distinguishing between deep and shallow
differences were significant, put together they provide some       learning, and that different kinds of measures are needed to
support that preparation may influence students to engage          evaluate learning of varying depths. By using a mental
constructively in an activity, even when the activity in and       model perspective to understand outcomes, one can see that
of itself does not require such engagement.                        a measure of “surface feature” knowledge would have
                                                                   shown no effects across conditions. An appropriate measure
                                                                   of deep “structural” knowledge was needed to tease apart
              Discussion and future work                           how learning was affected by the collaborative tasks.
   This study tested the effects of preparation and type of           To conclude, it appears that one way to maximize the
task on shallow and deep learning in a collaborative activity.     benefits of collaboration on deep learning is to include a
Students engaged in either an Actively or Constructively           preparation task, which allows students to develop a
designed task, and either worked individually during part of       readiness for learning in future discussion. Preparation also
the learning phase, then collaborated (Prep), or worked            may elicit spontaneous constructive engagement in future
jointly the entire time (No Prep). (Recall that time-on-task       discussion, and it may not be necessary to otherwise design
and domain content of the learning materials were the same         collaborative activities to specifically engage constructive
across all conditions.) Results showed that preparation            behaviors. In addition, students who prepared only spent
improved deep learning outcomes, but no difference was             half the amount of the time collaborating. Thus, using a PFL
detected for type of task. The main effect of preparation on       paradigm to structure collaborative activity is also efficient,
outcomes extends the PFL paradigm, showing that peer               in that students can make the most effective use of their time
discussion can serve as a beneficial future learning task (i.e.    engaging in discussion.
the future task need not be lecture). Considering the learning
                                                               2818

                   Acknowledgments                              Janssen, J., Erkens, G., Kirschner, P.A., & Kanselaar, G.
                                                                  (2010). Effects of representational guidance during
This work was partly funded by a GRSP grant from the
                                                                  computer-supported collaborative learning. Instructional
Graduate & Professional Student Association at Arizona
                                                                  Science, 38(1), 59-88.
State University. Thanks to Julie Morrison for feedback on
                                                                Kapur, M. & Bielaczyc, K. (2012). Designing for productive
materials, Ruth Wylie and Kasia Muldner for their
                                                                  failure. Journal of the Learning Sciences, 21(1), 45-83.
mentorship, Micki Chi for her early influence on this work,
                                                                Kenny, D.A., Kashy, D.A, & Cook, W.L. (2006). Analysis
and Kathy Nakagawa for her support and encouragement.
                                                                  of Dyadic Data. New York: Guilford.
                                                                Marx, J.D. & Cummings, K. (2007). Normalized change.
                         References                               American Journal of Physics, 75(1), 87-91.
Asterhan, C.S.C. & Schwarz, B.B. (2009). Argumentation          Menekse, M., Stump, G.S., Krause, S., & Chi, M.T.H. (in
  and explanation in conceptual change: Indications from          press). Differentiated overt learning activities for effective
  protocol analyses of peer-to-peer dialog. Cognitive             instruction in an engineering classroom. Journal of
  Science, 33, 374-400.                                           Engineering Education.
Barron, B. (2003). When smart groups fail. Journal of the       Nokes-Malach, T.J., Meade, M.L., & Morrow, D.G. (2012).
  Learning Sciences, 12(3), 307-359.                              The effect of expertise on collaborative problem solving.
Bjork, E.L. & Storm, B.C. (2011). Retrieval experience as a       Thinking & Reasoning, 18(1), 32-58.
  modifier of future encoding: Another test effect. Journal     Schwartz, D.L. (1995). The emergence of abstract
  of Experimental Psychology: Learning, Memory, and               representations in dyad problem solving. The Journal of
  Cognition, 37(5), 1113-1124.                                    the Learning Sciences, 4(3), 321- 354.
Bransford, J.D. & Schwartz, D.L. (1999). Rethinking             Schwartz, D.L. & Bransford, J.D. (1998). A time for telling.
  transfer: A simple proposal with multiple implications.         Cognition and Instruction, 16(4), 475-522.
  Review of Research in Education, 24, 61-100.                  Schwartz, D.L., Chase, C.C., Oppezzo, M.A., & Chin, D.B.
Chi, M.T.H. (2009). Active-Constructive-Interactive: A            (in press). Practicing versus inventing with contrasting
  conceptual framework of differentiating learning                cases: The effects of telling first on learning and transfer.
  activities. Topics in Cognitive Science, 1(1), 73-105.          Journal of Educational Psychology.
Chi, M.T.H. & VanLehn, K. (2012). Seeing deep structure         Schwartz, D.L. & Martin, T. (2004). Inventing to prepare
  from the interactions of surface features. Educational          for future learning: The hidden efficiency of encouraging
  Psychologist, 47(3), 177-188.                                   original student production in statistics instruction.
Chin, D.B., Dohmen, I.M., Cheng, B.H., Oppezzo, M.A.,             Cognition and Instruction, 22(2), 129-184.
  Chase, C.C., & Schwartz, D.L. (2010). Preparing students      Schwartz, D.L., Sears, D., & Chang, J. (2007).
  for future learning with Teachable Agents. Educational          Reconsidering prior knowledge. Carnegie Symposium on
  Technology Research and Development, 58, 649-669.               Cognition, 319-344. Mahwah, NJ: Lawrence Erlbaum.
Cohen, E.G. (1994). Restructuring the classroom:                Uesaka, Y. & Manalo, E. (2011). The effects of peer
  Conditions for productive small groups. Review of               communication with diagrams on students’ math word
  Educational Research, 64(1), 1-35.                              problem solving processes and outcomes. Proceedings of
Coleman, E.B. (1998). Using explanatory knowledge during          the 33rd Annual Meeting of the Cognitive Science Society
  collaborative problem solving in science. Journal of the        (pp. 312-317). Austin, TX: Cognitive Science Society.
  Learning Sciences, 7(3&4), 387-427.                           Van Amelsvoort, M., Andriessen, J., & Kanselaar, G.
Craig, S.D., Chi, M.T.H. and VanLehn, K. (2009).                  (2007). Representational tools in computer-supported
  Improving classroom learning by collaboratively                 collaborative argumentation-based learning: How dyads
  observing human tutoring videos while problem solving.          work with constructed and inspected argumentative
  Journal of Educational Psychology, 101(4), 779-789.             diagrams. Journal of the Learning Sciences, 16(4), 485-
Engle, R.A. & Conant, F.R. (2002). Guiding principles for         521.
  fostering productive disciplinary engagement: Explaining      Van Boxtel, C., Van der Linden, J., & Kanselaar, G. (2000).
  an emergent argument in a community of learners                 Collaborative learning tasks and the elaboration of
  classroom. Cognition and Instruction, 20(4), 399-483.           conceptual knowledge. Learning and Instruction, 10, 311-
Gadgil, S. & Nokes-Malach, T.J. (2012). Overcoming                330.
  collaborative inhibition through error correction: A          Walker, E., Rummel, N., & Koedinger, K.R., (2011).
  classroom experiment. Applied Cognitive Psychology,             Designing automated adaptive support to improve student
  DOI: 10.1002/acp.1843                                           helping behaviors in a peer tutoring activity. Computer-
 Hausmann, R.G.M. (2006). Why do elaborative dialogs              Supported Collaborative Learning, 6, 279-306.
  lead to effective problem solving and deep learning?          Webb, N.M., Nemer, K.M., & Ing, M. (2006). Small-group
  Proceedings of the 28th Annual Meeting of the Cognitive         reflections: Parallels between teacher discourse and
  Science Society (pp. 1465-1469). Vancouver, B.C.:               student behavior in peer-directed groups. Journal of the
  Sheridan Printing.                                              Learning Sciences, 15(1), 63-119.
                                                            2819

