UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Assessing the effectiveness of older adults’ spatial descriptions in a fetch task
Permalink
https://escholarship.org/uc/item/9kw3d69s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Carslon, Laura
Skubic, Marjorie
Miller, Jared
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                        University of California

        Assessing the effectiveness of older adults’ spatial descriptions in a fetch task
                                               Laura A. Carlson1 (lcarlson@nd.edu)
                                            Marjorie Skubic2 (skubicm@missouri.edu)
                                                 Jared Miller1 (jmille39@nd.edu)
                                            Zhiyu Huo2 (zhiyuhuo@mail.missouri.edu)
                                          Tatiana Alexenko3 (ta7cf@mail.missouri.edu)
             1
               Department of Psychology, 119-D Haggar Hall, University of Notre Dame, Notre Dame, IN 46556 USA
                     2
                       Electrical and Computer Engineering Department, University of Missouri, Columbia, MO
                                3
                                  Computer Science Department, University of Missouri, Columbia, MO
                               Abstract                               older adults (Alexenko et al., 2013), parsing the natural
   The current paper examines spatial descriptions provided by
                                                                      language descriptions and coding them into chunks that can
   older adults in the context of a fetch task in a virtual house     be converted into robot commands, recognizing key
   environment that mimics an eldercare setting. Sixty-four           furniture items within a cluttered environment that are
   older adults provided directions for how to find a target or       included in the descriptions, and identifying spatial relations
   where to find a target to a robot or human (named Brian)           within the horizontal plane (e.g., behind the couch) and the
   avatar. There were systematic differences in the form and          vertical plane (e.g., on top of the table) (Skubic et al, 2012).
   structure of the descriptions based on the communicative task.        Given that the robot algorithms are driven by the
   Specifically, how descriptions were longer, contained more
   detail, and were dynamically structured as compared to where       properties of the spatial descriptions, in the current paper we
   descriptions. However, where descriptions were found to be         examine how the communicative task of the speaker
   more effective in conveying the target location, as assessed       impacts the features of the descriptions, and present data
   with a subsequent target selection task. Implications for the      that reflect the effectiveness of the descriptions.
   development of robot algorithms for the comprehension of
   naturalistic spatial language across these two communicative           Spatial Directions and Spatial Descriptions
   tasks are discussed.
                                                                         A fetch task is one in which a speaker specifies the
   Keywords: Human-robot interaction (HRI); spatial language;         location of a desired target for an addressee whose goal is to
   dynamic and static; how and where; effectiveness; fetch task;
   assistive robotics; eldercare.
                                                                      retrieve the target. There are two ways in which the
                                                                      location can be indicated by the speaker. The speaker could
                           Introduction                               provide directions that tell how to get to the target location
                                                                      or the speaker could provide descriptions that specify
   An emerging line of research in human-robot interaction            information about where a given target location is. Research
involves the development of assistive devices for use in              has shown systematic differences in the type and structure
eldercare settings, either as social companions (e.g., Heerink        of the language that is used for each of these communicative
et al., 2008; Kidd, Taggart, & Turkle, 2006; Libin & Cohen-           tasks. For example, Plumert et al. (1995) found that written
Mansfield, 2004; Shibata, Kawaguchi, & Wada, 2011;                    directions on how to find a target in a hierarchically
Wada et al., 2003) or as task-oriented robots assisting with          organized doll-house environment were more likely to
navigation (Montemerlo et al., 2002), managing medication             provide more detailed messages and contain more spatial
(Tiwari et al., 2011)], and providing reminders (Pollack et           units that tended to be organized in a descending sequence
al., 2002). Older adults also report wanting help with tasks          (floor à room à reference object. e.g., The keys are on the
such as cleaning, heavy lifting, and fetching objects (Beers          first floor in the living room on the table.) as compared to
et al., 2012). They also prefer to speak naturally to these           written descriptions of where to find a target that were less
assistive devices, rather than use a more constrained                 detailed and organized in an ascending sequence (reference
interface (Scopelliti, Guiliani, & Fornara, 2005).                    object à room à floor, e.g., The keys are on the table in
   To accommodate these preferences, recently we gathered             the living room on the first floor).
a corpus of spatial descriptions from older adults who                   This distinction between how and where has also been
interacted with an avatar within a virtual house setting in the       characterized as dynamic and static (Wahlster. 1995, Fasola
context of a fetch task. Our primary goal in this project is to       and Mataric 2012) spatial language, respectively, with
develop robot algorithms for the online comprehension of              dynamic stepping the addressee through the environment in
these natural language spatial descriptions and to test these         a point by point fashion and static offering spatial
algorithms in an analogous physical environment with a                information that does not embed the addressee in the
physical robot. In working toward this goal, on the basis of          environment. Dynamic spatial directions are also inherently
the corpus, we have identified key components that need to            sequential, while static descriptions are not. Nevertheless,
be developed for the robot including speech recognition for           static descriptions are often overlooked or treated the same
                                                                  281

as dynamic directions by other researchers (Tellex et al,         of the target location to either a robot or human avatar
2011), perhaps due to the focus on two-dimensional route          (named Brian) who faced them (as indicated by the arrow in
instructions or the assumption that dynamic descriptions are      Figure 1), such that their perspectives were misaligned by
better or more prevalent (Kollar et al., 2010, MacMahon et        180 degrees. Previous research has shown a preference for
al., 2006, Vogel and Jurafsky 2010, Shimizu and Haas              speakers to use an addressee perspective when perspectives
2009).                                                            between speaker and addressee are misaligned (Mainwaring
   In the current work, we assess two questions related to        et al., 2003; Schober, 1993), with such preference also
this how/where distinction: First, we ask whether there are       observed for robot addressees (Tenbrink et al., 2002).
consistent differences in the type and form of the spoken         However, given that older adults have shown negative
spatial language that is produced by older adults in response     emotional responses to robots (Scopelliti et al, 2005), we
to how and where instructions that might echo Plumert et          included the addressee manipulation to assess whether older
al’s (1995) findings with written spatial language. We focus      adults in particular would be more likely to adopt their own
on the type of language included in the descriptions, and the     perspective rather than the perspective of the robot. These
amount of detail, and ignore the hierarchical sequencing that     perspective results are presented in Carlson et al. (2013). A
Plumert et al. (1995) measured, because our environment           second manipulation was related to the task instructions.
consists of a single floor, as intended for mimicking an          Specifically, older adults were instructed to either provide
eldercare setting. Second, we ask whether these differences       directions for how to find the target or to provide
are associated with differences in the relative effectiveness     descriptions of where the target was located. Both the
of the descriptions.                                              addressee manipulation (robot or Brian) and the task
                                                                  instruction manipulation (how or where) were between
Corpus of descriptions from older adults in a                     subject manipulations, with the consequence that 16 older
virtual fetch task                                                adults each provided 8 descriptions (128) for each of the 4
Our corpus consists of 512 spatial descriptions collected         addressee X instruction combination (128 X 4 = 512
from 64 older adults (mean age = 76 years) who specified          descriptions in total).
the location of 8 targets embedded in the virtual house               A full report of the older adult corpus can be found in
environment shown in Figure 1. Targets were placed in the         Carlson et al. (2013). We focus here on the how versus
living room (on the left in Figure 1) and bedroom (on the         where differences. Figure 2 provides the task instructions
right in Figure 1) on tables that also contained two other        (adapted from Plumert et al., 1995), and examples from the
objects that could potentially serve as reference objects. On     corpus.
each trial, older adults explored the virtual house with the                                                     !"#$                                   %&'('$
assistance of an experimenter and found a designated target.             )*+,(-./"*+$,"$       !"#$%#&'#""&'(#&!"#$%&'()*"+,+'*()*&')&        !"#$%#&'#""&!"#$%&'()*"+,+'*
                                                                           01(/.201*,+$                     +,-&'(#&'$./#'0&                     *(#.#&'(#&'$./#'&1%0&
They were then positioned in the central hallway (marked                                                           $                                        $
by “Start” in Figure 1), and provided a description                 2--.#%%##3&4.1$,&        4.1$,&'<.,&')&=)<.&.1/('0&>)&')&'(#&.))?&   4.1$,&'(#&@))8&1%&1,&'(#&.))?&')&
                                                                    5$./#'&6&7&4))8&         ),&=)<.&.1/('&$,-&/)&%'.$1/('&$(#$-&$,-&    =)<.&.1/('&$,-&1'%&),&$&'$@"#&$'&
                                                                    &                        '(#&@))8&1%&.1/('&'(#.#&@#A).#&=)<0&        '(#&A$.&%1-#&)A&'(#&.))?0&
                                                                    &                        &                                           &
                                                                    &                        4.1$,&;"#$%#&'$8#&6&).&9&%'#;%&A).*$.-&     &
                            Robot                                   5$./#'&9&7&:#""&;(),#&   $,-&#,'#.&'(#&.))?&),&=)<.&"#B0&C;),&       5(#&F#""&;(),#&1%&1,&'(#&@#-.))?&
                                                                    $                        #,'#.1,/&'(#&.))?&'$8#&$@)<'&D&%'#;%&       ),&'(#&@#-%1-#&'$@"#0&&
                             Or                                                              A).*$.-&$,-&=)<E""&%##&$&%?$""&@.)*,&                          $
                            Brian                                                            '$@"#&*1'(&$&@"$F8&');0&5(#&F#""&;(),#&
                                                                                             '($'&=)<&$.#&"))81,/&A).&1%&),&'($'&'$@"#0&
                                                                                                                   $
                                                                      2--.#%%##3&G)@)'&      H,'#.&'(#&.))?&),&=)<.&.1/('&$,-&             5(#&@))8&1%&1,&'(#&"1J1,/N-1,1,/&
                                                                      5$./#'&6&7&4))8&       F),I,<#&%'.$1/('&<,I"&=)<&(1'&$&@.)*,&        .))?&),&'(#&-1,1,/&.))?&'$@"#0&
                                                                      &                      F)J#.#-&'$@"#&$,-&),&'$@"#&)A&'(#&'$@"#&1%&   &
                                                                      &                      '(#&@))80&                                    &
                                                                      &                      &                                             5(#&F#""&;(),#&*$%&),&'(#&"#B&
                                                                      5$./#'&9&7&:#""&;(),#& H,'#.&'(#&.))?&),&=)<.&1??#-1$'#&"#B&         %1-#&),&$&.)<,-&'$@"#&,#$.&'(#&
                                                                      &                      $,-&@=&'(#&"1K"#&,1/('%'$,-&,#L'&')&'(#&      @#-0&
                                                                                             @#-&'(#.#&1'&1%&),&');&)A&1'0&M'E%&$&.)<,-&
                                                                                             ,1/('&'$@"#&$,-&'(#&F#""&;(),#&1%&1,&'(#&
                                                                                             F#,'#.0&
                           START
                                                                             Figure 2: Instructions and sample descriptions by
                                                                                               how/where and addressee
                                                                      As shown in Table 1, how descriptions contained more
                                                                  words overall per description, and included more spatial
                                                                  terms (such as “on”, “to” and “right”) and more hedges
                                                                  (such as “immediately” and “slightly”). In contrast, where
                                                                  descriptions contained more house units (such “room”,
                                                                  “door” and “wall”). Descriptions often contained large
    Figure 1: Overview and screen shots of the virtual house      furniture items in the rooms (such as “bed” and “couch”),
                                                                  and rarely contained reference objects that were collocated
                                                              282

on the tables (such as “lamp”), with the incidence of these                  they found the target, and then named it. The key dependent
categories not varying across how and where descriptions.                    measure was their accuracy in selecting the target.
Finally, how descriptions were more likely to have a                            As shown in Figure 3, we examined two indicators of this
dynamic form than the where descriptions.                                    accuracy: selection of the correct target, and selection of the
                                                                             correct table on which the target appeared. This latter
                                                                             measure is important because two potential reference
                                       !"#$               %&'('$
                                                                             objects appeared on the tables next to the targets, and often
    !"#$%&'(#&$(%)#*'+",&        -&.&/0123&45&.&617& -&.&68193&45&.&61:&
                                                                             the descriptions did not provide enough information to
    4';+;<&=(#>%&'(#&$(%)#*'+",& -&.&9163&45&.&1/?&  -&.&/1@3&45&.&1/8&      identify which object on the table was the target (see
    A"B%(&B,*=%&'(#&$(%)#*'+",&  -&.&6163&45&.&162&  -&.&6193&45&.&16/&      example descriptions in Figure 2). The infrequent use of the
    A($C(%&'(#&$(%)#*'+",&       -&.&1//3&45&.&12:&  -&.&1283&45&.&12/&      reference objects that appeared next to the target is
    D&$E,;>*)&$(%)#*'+",%&&      -&.&8:1@3&45&.&@1@& -&.&@:173&45&.&018&     consistent with Plumert et al. (1995) who found that such
                                                                             reference objects were only consistently used when the
    Table 1: Significant differences between how and where                   target was located on the reference object as opposed to
                      older adult descriptions                               beside it.
   These results are consistent with Plumert et al. (1995)                             !""#$%"&'()'*%+,-'.-,-"/(0'%.'%')#0"/(0'()'%11$-..--'
who also found that how descriptions contained more spatial                                               %01'20.*$#"/(0'
units and were more detailed than where descriptions. What                      #!!"
remains unclear is whether these differences are associated                      +!"
with any differences in effectiveness. That is, these                            *!"
descriptions were all collected by older adult speakers in the                   )!"
context of a fetch task in which accurately specifying the                       (!"
                                                                                 '!"                                                       3/456"
location of the target is critical for the success of the task.
                                                                                 &!"                                                       71819"
We ask next whether how or where descriptions are more
                                                                                 %!"
effective in identifying the location of the target.                             $!"
                                                                                 #!"
Differences in how vs. where effectiveness                                        !"
   To assess effectiveness, we randomly selected from the                                    ,-./."                      012"
corpus of older adult descriptions two from each speaker’s
set of 8 descriptions (with half of the speakers addressing
Brian and half the robot), with the constraint that the                               !""#$%"&'()'(+3-"*'.-,-"/(0'%.'%')#0"/(0'()'%11$-..--'
location of each target was specified an equal number of                                                  %01'20.*$#"/(0'
times across the set of descriptions that we were                               #!!"
assessing. These descriptions were then provided to sixty-                       +!"
four younger adults to assess effectiveness. Their task was                      *!"
to listen to a description without the target, navigate through                  )!"
the house in accordance with the description, and then guess                     (!"
                                                                                 '!"                                                       3/456"
the identity of the target. 4 targets were placed on tables in
                                                                                 &!"                                                       71819"
the living room and 4 targets were placed on tables in the
                                                                                 %!"
bedroom. Each table contained a target and two distractor
                                                                                 $!"
objects. Each participant performed two trials (one in the
                                                                                 #!"
living room and one in the bedroom). Before the trials                            !"
began, the younger adults were shown a video tour of the                                     ,-./."                      012"
house that did not include the targets. This was to
                                                                                 Figure 3: Selection accuracy for correct table (top) and
familiarize them with the house environment and the
                                                                                 correct target (bottom) as a function of how/where and
relative locations of the rooms and their contents. On each
                                                                                    addressee. Dotted line indicates chance selection.
trial, participants started in the hallway of the house,
standing in the location and at the orientation of the avatar,
                                                                                With respect to selection of the correct table, performance
as specified by the label “robot or avatar” shown in Figure
                                                                             in all conditions was significantly above chance
1, and facing the original speaker’s location (which is
                                                                             performance of 12.5, based on 8 possible tables in the
marked in Figure 1 with the label “Start” and with an
                                                                             environment. In addition, significantly better performance
orientation specified by the arrow). They were therefore
                                                                             was observed for “where” descriptions (M = 61%) than for
facing the position of the participants from which the
                                                                             “how” descriptions (M = 42%), F(1,60) = 4.51, p < .05. In
descriptions were gathered. A participant was given a
                                                                             addition, there was a significant effect of addressee, with
description from the corpus with the target item removed,
                                                                             more accurate performance for descriptions provided to
and they navigated through the house until they thought
                                                                             Brian (M = 67%) than to the robot (M = 36%), F(1,60) =
                                                                         283

12.55, p < .01. The interaction between instruction and                                  !""#$%"&'()'*%+,-'%./'*%$0-*'1-,-"2(.'%1'%')#."2(.'()'*%$0-*'
addressee was marginal, F(1,60) = 3.13, p = .08.                                 #!!"
   With respect to the selection of the correct object,
                                                                                  +!"
performance in all conditions was significantly above
                                                                                  *!"
chance performance of 4.2 (based on 24 possible targets in
the environment (3 on each of 8 tables)). For this analysis,                      )!"
there was only a main effect of addressee: F(1,60) = 7.10, p                      (!"
< .05; the effect of instruction and the interaction were not                     '!"
significant (Fs < 1.6, ps < .21).                                                 &!"
                                                                                                                                               ,-../,0"0123/"
   For the object selection measure, we also assessed how                                                                                      ,-../,0"01.4/0"
                                                                                  %!"
likely it was that participants selected the correct object,
given that they selected the correct table.                        Chance         $!"
performance in this case is 33%, given that there are three                       #!"
objects (target and two reference objects on each table).                          !"
   Figure 4 shows that in all conditions, accuracy was
significantly above chance. We expect that this is because
the target objects were generally smaller than the reference
objects on the tables. Clark, Schreuder and Buttrick (1983)
argue that when a reference is under-determined by a                              Figure 5: Selection accuracy for table and target selection
speaker, the addressee will select an object from a group of                         as a function of target. Dotted lines indicate chance
               !""#$%"&'()''"(*+,-(*%.'(/01"2'31.1"-(*'4,51*'"($$1"2'                                           selection.
                  2%/.1'31.1"-(*'%3'%')#*"-(*'()'%++$13311'%*+'
                                   ,*32$#"-(*'
                                                                                  Chi-square analyses revealed no significant differences
         #!!"
          +!"
                                                                               among targets, for either the correct table accuracy or the
          *!"                                                                  correct target accuracy. This indicates that there were not
          )!"                                                                  any targets or locations that were particularly difficult to
          (!"
          '!"                                                       3/456"     describe and/or find. This is likely due to the simple layout
          &!"
                                                                    71819"
                                                                               and relatively impoverished contents of the rooms in the
          %!"                                                                  virtual house.
          $!"
          #!"
                                                                                  Overall, the results for the assessment of the older adults
           !"                                                                  spatial descriptions indicate that the where descriptions
                     ,-./."                     012"                           allowed participants to more easily select the target and its
                                                                               table than the how descriptions. We suspect that the
        Figure 4: Selection accuracy for the correct object,
                                                                               differences in accuracy for table selection as a function of
 conditional on correct table selection. Dotted line indicates
                                                                               addressee that were observed are likely due to other
                          chance selection.
                                                                               properties of the descriptions, such as the perspective
                                                                               adopted by the speaker. For a full report of the older adult
objects that offers the most contrast from the others along a
                                                                               corpus, see Carlson et al. (2013).
given dimension. For example, imagine a speaker tells an
addressee to pick up a ball and refers to a collection of three
balls (a golf ball, a squash ball and a basketball) that are                                                Conclusions
placed on a table in front of them. Clark et al. argue that it                    Together, the detailed analysis of the corpus and the
is likely that the addressee will select the basketball because                results of the experiment assessing the effectiveness of the
it is the most unique item in the set, standing out in terms of                descriptions point to an interesting contrast. On the one
size.                                                                          hand, the corpus analysis reveals that how descriptions are
   Finally, we also examined whether there were differences                    longer, offer more detail, include more spatial terms, and are
in accuracy for the individual targets. Given that each of the                 dynamic, as compared to the where descriptions that are
targets appeared in a given location (and location was not                     shorter, include more references to house structures, and are
counterbalanced across targets), this serves an indicator as                   often static. On the other hand, these same how descriptions
to whether any of the target locations were particularly                       are not as effective in communicating the location of the
difficult to describe and find. Figure 5 shows accuracy as a                   target, as assessed by the accuracy for selecting the target
function of the targets, both as indicated by the correct                      and its table. We are currently comparing the effectiveness
selection of the table and correct selection of the object.                    of these older descriptions with the effectiveness of a corpus
                                                                               of descriptions collected from younger adults within the
                                                                               same virtual environment. Moreover, we are also recording
                                                                               the paths that participants take to the target in response to
                                                                               these descriptions, with the idea that the paths may offer an
                                                                               additional online measure of effectiveness. Metrics we are
                                                                           284

examining include path length, navigation speed, number of         Clark, H. H., Schreuder, R., & Buttrick, S. (1983). Common
pauses, and changes in heading.                                      ground and the understanding of demonstrative reference.
   These results also have several interesting implications          Journal of Verbal Learning and Verbal Behavior, 22,
for the development of robot algorithms in this task. For            245-58.
example, it may be beneficial for the robot algorithm to           Fasola, Juan, and Maja J. Matarić. "Using Spatial Language
initially classify a description as one that is conveying            to Guide and Instruct Robots in Household
directions or one that is conveying location, given that the         Environments." (2012), AAAI Technical Report, FS-12-
form and content of the descriptions vary as a function of           07.
communicative task. In a natural setting, of course, the           Heerink, M., Kröse, B., Wielinga, B., and Evers, V. (2008).
speaker may not be explicit about whether he or she is               “Enjoyment, Intention to Use and Actual Use of a
providing directions or specifying location (that is, the            Conversational Robot by Elderly People,” Proc., Intl.
speaker is not assigned a how or where task per se, as in our        Conf. on Human-Robot Interaction, pp. 113-119.
current work). This classification would need to be based on       Kidd, C., Taggart, C.W., and Turkle, S. (2006). “A Sociable
the properties of the descriptions themselves.                       Robot to Encourage Social Interaction among the
   In addition, the robot algorithms will need to take into          Elderly,” Proc., IEEE Intl Conf on Robotics and
account the differential effectiveness of the two types of           Automation, pp. 3972-3976.
descriptions. The “how” descriptions may provide a more            Kollar, T., Tellex, S., Roy, D., and Roy, N. (2010). “Toward
explicit approach to allow direct translation into robot             Understanding Natural Language Directions,” Proc., 5th
commands; however, varying viewing perspectives will                 ACM/IEEE International Conference on Human-Robot
complicate the interpretation. To follow the directions of the       Interaction, pp. 259.
“how” descriptions, a robot does not rely as much on               Libin, A. and Cohen-Mansfield, J. (2004). “Therapeutic
perception, which may improve the efficiency of the fetch            Robocat for Nursing Home Residents with Dementia:
navigation in some static environments but not necessarily           Preliminary Inquiry,” American Journal of Alzheimer’s
the effectiveness. In contrast, the “where” descriptions             Disease and Other Dementias, 19(2):111-116.
provide more hints using reference structures and objects so       MacMahon, M., Stankiewicz, B., and Kuipers, B. (2006).
that the robot can navigate to the target using perception.          “Walk the Talk: Connecting Language, Knowledge, and
The “how” descriptions may be easier to interpret but have a         Action,” Route Instructions, pp 1475-1482.
lower probability to navigate the robot to the specified           Mainwaring, S., Tversky, B., Ohgishi, M. & Schiano, D.
target, especially given a dynamic environment in which              (2003). Descriptions of simple spatial scenes in English
reference furniture items have been moved. The “where”               and Japenese. Spatial Cognition and Computation, 3, 3-42
descriptions require the challenge of translating them into        Montemerlo, M., Pineau, J., Roy, N., Thrun S., and Verma,
navigation commands but may provide more reliable fetch              V. (2002). “Experiences with a Mobile Robotic Guide for
results, even in the case of moved reference items.                  the Elderly,” Proc., AAAI-02, pp. 587-592.
                                                                   Plumert, J. M., Carswell, C., DeVet, K., and Ihrig, D.
                                                                     (1995).        “The Content and Organization of
                    Acknowledgments                                  Communication about Object Locations,” Journal of
This research was supported with funding by the National             Memory & Language, 34:477-498.
Science Foundation Grant IIS-1017097. We thank Xiao Ou             Pollack, M.E., Brown, L., Colbry, D., Orosz, C., Peintner,
Li for constructing the virtual house environment and Erin           B., Ramakrishnan, S., Engberg, S., Matthews, J.T.,
Gibson, Oscar Gonzalez, Diane Garritson, Ashley                      Dunbar-Jacob, J., and McCarthy, C.E. (2002) “Pearl: A
Herrmann, Mary Johnson, Kevin Kimberly, Kathleen                     Mobile Robotic Assistant for the Elderly,” Proc., AAAI
Loftus, Angelique Laboy-Capparopa, Elliott Mitchem, and              Workshop on Automation as Eldercare.
Joe Wernke for help collecting and coding the data.                Schober, M. F. (1993). Spatial perspective-taking in
                                                                     conversation. Cognition, 47(1), 1-24.
                                                                   Scopelliti, M., Giuliani, V., and Fornara, F. (2005). “Robots
                         References                                  in a Domestic Setting: A Psychological Approach,”
Beer, J., Smarr, C.A., Chen, T.L., Prakash, A., Mitzner,             Universal Access in the Information Society, 4, 146-155.
   T.L., Kemp, C.C., and Rogers, W.A. (2012). “The                   Scopellite, Guiliani, & Fornara, 2005
   Domesticated Robot: Design Guidelines for Assisting             Shibata, T., Kawaguchi, Y., and Wada, K. (2011).
   Older Adults to Age in Place,” Proc., IEEE Conference             “Investigation on People Living with Seal Robot at Home
   on Human Robot Interaction - Session: Living and                  - Analysis of Owners’ Gender Differences and Pet
   Working with Service Robots, Boston, MA, pp. 335-342.             Ownership Experience,” International Journal of Social
Carlson, L. A., Skubic, M., Miller, J., Huo, Z., & Alexenko,         Robotics, 4(1):53-63.
   T. (2013).         Strategies for human-driven robot            Shimizu, N. and Haas, A. (2009). “Learning to Follow
   comprehension of spatial descriptions by older adults in a        Navigational Route Instructions,” Proc., Intl. Joint Conf.
   robot fetch task. Revised manuscript submitted for                on Artificial Intelligence, pp.1488-1493.
   publication in special issue of Topics.
                                                               285

Skubic, M., Alexenko, T., Huo, Z., Carlson, L., and Miller,
  J. (2012). “Investigating Spatial Language for Robot
  Fetch Commands,” Grounding Language for Physical
  Systems, AAAI Technical Report, WS-12-07, pp. 39-45.
Tellex, S., Kollar, T., Dickerson, S., Walter, M.,
  Banerjee, A., Teller, S. and Roy, N. (2011).
  “Understanding Natural Language Commands for
  Robotic Navigation and Mobile Manipulation,”
  Proc., Conf. on Artificial Intelligence (AAAI).
Tenbrink, T., Fischer, K., & Moratz, R. (2002). Spatial
  strategies of human-robot communication.” KI #4
  [Online]. Available: http://citeseerx.ist.psu.edu/
  viewdoc /summary?doi=10.1.1.58.2151
Tiwari, P., Warren, J., Day, K.J., and Datta, C. (2011).
  “Comprehensive Support for Self-Management of
  Medications by a Networked Robot for the Elderly”
  Proc., Health Informatics New Zealand 10th Annual
  Conference and Exhibition, Aukland.
Vogel, A. and Jurafsky, D. (2010). “Learning to Follow
  Navigational Directions,” Proc., 48th Annual Meeting of
  the Association for Computational Linguistics, pp. 806-
  814.
Wada, K., Shibata, T., Saito, T. and Tanie, K. (2003).
  “Psychological and social effects of robot assisted activity
  to elderly people who stay at a health service facility for
  the aged,” in Proc., Intl. Conf. on Robotics and
  Automation, pp. 3996–4001.
Wahlster, W., Statiques Et Dynamiques, and Gerd Herzog.
  "Coping with Static and Dynamic Spatial Relations."
  (1995).
                                                               286

