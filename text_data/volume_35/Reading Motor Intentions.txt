UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reading Motor Intentions
Permalink
https://escholarship.org/uc/item/6h45q9d9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Lewkowwicz, Daniel
Delevoye-Turrell, Yvonne
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                                  Reading Motor Intentions
                                    Lewkowicz Daniel (daniel.lewkowicz@etu.univ-lille3.fr)
                                 URECA laboratory, Univ Lille Nord de France, F-59000 Lille, France
                                  Delevoye-Turrell Yvonne (yvonne.delevoye@univ-lille3.fr)
                                 URECA laboratory, Univ Lille Nord de France, F-59000 Lille, France
                                                MESHS, USR 3185, F-59000 Lille, France
                               Abstract                                 contexts affect movement kinematics, but that these
                                                                        deviants may be used to read motor intention. For example,
  Some evidence in very recent psychological studies have               when observing actions performed under social context or
  demonstrated that motor simulation ability is crucial for the         not, Castiello and collaborators demonstrated that humans
  correct understanding of social intentions. The present study         can successfully use kinematic cues of reach-to-grasp
  was conducted first to confirm that the nature of the motor           movements to predict the final goal of the action (Sartori,
  intention leads to early modulations of movement kinematics.          Becchio, & Castiello, 2011). Similar results were also found
  Then, we tested whether humans could read an agent’s                  using point-light displays of simple reach to grasp
  intention when observing the very first element of a complex
  action sequence. Results revealed early variations in
                                                                        movements (Manera, Becchio, Cavallo, Sartori, & Castiello,
  movement kinematics and further showed that human agents              2011). However, in these studies, the classification rates
  can use these deviants to distinguish above chance level              were obtained under a forced two-choice paradigm, and for
  between three different social actions. Similar performance           the most subtle differences (cooperative vs individual
  levels were found using an artificial classifier (Neural              preferred speed or competitive vs fast speed) the
  Network) and this procedure demonstrated furthermore that             classification rates were very small (near 50%).
  decisions could be taken on the basis of information contained           In the present work, we wanted to study the capacity of
  in the first 500ms of movement kinematics. Taken together
  these results confirm the importance of motor simulation for          humans to read motor intention in a sequence of 2 motor
  adapted social interaction, and suggest how robotic adaptive          elements. One novelty of this study is that the sequences
  controllers may use as input low-level motor information (e.g.        were performed entirely during an interactive situation with
  kinematics) to afford biologically inspired social behaviors.         a con-specific, without any interruption or verbal instruction
   Keywords: Classifier; kinematics; sequences; motor control;          between the sequences. As such, we recorded sequential
   intentionality: social interaction; internal models; prediction;     actions during an ecologically inspired task (Jungle Speed),
   motor planning; biological movement.                                 a simple face-to-face game using a unique manipulated
                                                                        object. Our main focus was to compare human and artificial
                           Introduction                                 categorization performances for three different sequential
                                                                        actions that took part during the game. To test the
  In everyday activities, the grasping of an object might be            hypothesis that kinematics alone is sufficient to read social
performed with different prior intentions: e.g. touch, move,            intention, we fed the artificial classifier with movement
throw or pass. Ansuini et al. (2008) have measured the                  kinematics only.
prior-to-contact grasping kinematics for reach-to-grasp                    Confronting Jacob & Jeannerod’s (2005) reading motor
movements performed toward a bottle filled with water. By               intention hypothesis, we hypothesized that human agents are
comparing hand shaping across tasks involving different                 able to read motor intention through the simple observation
subsequent actions - pour the water into a container; throw             of arm kinematics of the first element of a 2-sequence
the bottle; move the bottle from one spatial location to                action. This is possible due to the fact that arm kinematics
another - the authors demonstrated how the prior intention              of the reach to grasp movements reveal specific deviants in
in grasping the object strongly affected the positioning of             function of goal intention from an ideal optimized
the fingers during the reaching and the contact phase of the            trajectory. Finally, if motor simulation is sufficient, then an
action (Ansuini, Giosa, Turella, Altoè, & Castiello, 2008).             artificial neural network should be able to learn from the
In another series of studies, Becchio and collaborators                 deviants and predict as well as humans, the motor intention
investigated the effects of social context on reach-to-grasp            of an observed agent. In the following section, we first
actions. They found initial adjustments reflecting specific             describe the methods we used to make the observation
planning strategies (Becchio, Sartori, Bulgheroni, &                    videos (Part A), which were then played to human agents
Castiello, 2008a) as well as online adjustments (Sartori,               (Part B) and used as input parameters to an artificial neural
Becchio, Bulgheroni, & Castiello, 2009) when performing                 network (Part C).
under social context (see : Becchio et al., 2010 for a
review).                                                                                     Creating Stimuli
  More recently, researchers have gone one step further to                 Two adults participated in the study, one experimenter
suggest that not only end-point constraints and social                  and the other as subject. Both participants were right handed
                                                                    2872

as verified with the Handedness questionnaire (Oldfield,            set up the game rules, no other verbal instructions were
1971). They had no prior knowledge of the experiment and            given during the blocks. The three different positions
provided informed consent before participating in the               (‘Play’; ‘Me’; ‘You’) where the dowel had to be placed
experimental session that lasted approximately 90 minutes.          were delimited by visual marks directly placed on the
The subjects’ movements were recorded using a (1) a video           tabletop.
camera (Sony Handycam) and (2) 4 Oqus infrared cameras                 The recordings.           The best 16 recordings of each
(Qualysis).5 infrared reflective markers were placed on the         category (‘Play’, ‘Me’ and ‘You’) were extracted using
thumb (tip), index (base and tip) and the wrist (scaphoïd and       VirtualDub and kept for future use as stimuli. Each
pisiform). Cameras were calibrated before each session,             sequence was delimited with a 1-second pre-trial, i.e.,
allowing the system to reach a standard deviation smaller           before the initial movement onset, and was cut exactly one
than 0.2 mm, with a 200 Hz sampling rate                            frame before the index finger contacted the object. Movies
                                                                    were compressed with FFdshow codec (MJPEG) at 50
                                                                    frames per seconds with a screen resolution of 720x576.
                                                                    Video clips were coupled with the recordings of the arm
                                                                    kinematics using 4 Oqus infrared Cameras (Qualisys).
                                                                    Infrared reflective markers were placed on the index (base
                                                                    and tip), the thumb (tip), the wrist (scaphoïd and pisiform)
                                                                    of each participant, as well as on the object. Cameras were
                                                                    calibrated before each recording session, allowing the
                                                                    system to reach a standard deviation smaller than 0.2 mm
                                                                    for all three absolute positions at a 200 Hz sampling
                                                                    frequency. Care was taken as to provide no contextual
                                                                    information within the video clips (torso, gaze, face
                                                                    expression), i.e., only the hand and the target object were
                                                                    fully in view. Velocity profiles are presented in Figure 2 and
           Figure 1. Schematic representation of the                show that play, me or you sequences show deviations during
                     experimental setup.                            both first and second motor element (amplitude and the
                                                                    width of the bell-shaped curves, first and second peaks of
   The game.      The object that was to be manipulated by          velocity, time position for local minima).
the subject was a wooden dowel of width 2 cm and height of
4 cm that was placed precisely 20 cm in front of the starting
position (‘pick’ position). The subject started each trial by
pinching index and thumb together at the starting position
(see Figure 1). Each trial, the subject's task was to reach and
grasp the dowel between thumb and index finger in order to
move it from the initial position to one of the three ‘place’
positions during an adapted version of the jungle-speed
game. The game consisted in 4 blocks of approximately 40
rounds. First, the subject’s task was to pick and place the
dowel at the ‘Play’ position in order to set the initial
condition of the game. Then, at the ‘go’ signal (high pitch)
both participants reached for the dowel as quickly as
possible. The competitive move was not recorded and is not
part of this study, although, this was indeed intentionally
omitted during instructions given to the subject. During
competitive move, the first who have grasped the dowel,
won the round and scored a point. The second phase
consisted in a rewarding phase. The dowel was first always               Figure 2. Mean velocity profiles for the three
repositioned at pick position and the subject wait at starting        categories of sequences. Each bell-shape curve
position for the next audio tone (low pitch). During the              corresponds to a motor element. The first is the reach to
rewarding phase just after the competitive move, the subject          grasp element, and the second bell-shape curve is placing
has to reach to grasp the dowel and place it either at the            element. The local minima are used to segment the two
‘You’ position if the experimenter scored during                      motor elements and compute movement times.
competitive move, or at the ‘Me’ Position if the participant
scored during competitive move. The game went on until
one of the two players reached 20 points. Thus, we recorded
                                                                            Human Categorization Performance
twice as much ‘Play’ moves than ‘You’ or ‘Me’ moves                    The short video clips were presented to a panel of human
during the game. Nonetheless, after 5 rounds of training to         subjects to test whether human agents were able to predict
                                                                2873

the goal of a sequential action when shown only the first             Number of correct responses. There was an absence of
sub-element of a sequence, i.e., the reach movement.               Block effect on classification performances, F(2,50) =
                                                                   0.102, p = .903. However, a main effect of Category was
   Participants, Apparatus and Software. Twenty-six                obtained, F(2,50) = 16.022, p < .001, η² p=.39. Post-hoc
young adults (mean age: 21.82 ± 2.76 years, range = 18 - 29        Scheffé analyses further showed that participants were more
years) participated in the study. All subjects were right          accurate for trials in the ‘Me’ category (M = 57.53, SD =
handed (Oldfield, 1971) and had no prior knowledge of the          13.02 %) than in the ‘You’ (M = 40.87, SD = 12.12 %) and
experiment. Subjects provided informed consent before              in the ‘Play’ category (M = 47.27, SD = 13.04 %). More
participating in the experimental session that lasted              importantly, Chi-squared tests showed highly significant
approximately 45 minutes. Participants were seated                 difference between observed frequencies and random
comfortably facing a table in a dark and silent room. For          guessing baselines for the ‘Me’ (guess rate = 36.98,
each trial, participants started by placing their hand on          p<.001), ‘Play’ (guess rate = 36.12, p<.001) or ‘You’ (guess
response keys that were delimited by tape placed directly on       rate = 26.90, p<.001). These results confirmed that
the keyboard keys. Stimuli were presented on a laptop              performance was significantly greater than chance level.
computer with MATLAB software (Mathworks) with the
PsychToolbox environment.                                          Categorization with Artificial Neural Networks
                                                                      In the following section, we present the simple
   Experimental Procedure.           The participants' task        feedforward neural network that was developed to
was to answer on the keypad after each video clip                  demonstrate the possibility to categorize on the only basis of
presentation whether the social intention of the sequence          motor kinematics.
was ‘let’s Play’ (5 key), ‘for Me’ (2 key) or ‘for You’ (8
key). A 1-second blank screen was displayed in between                Architecture and Learning procedure. A simple
two trials. Participants were instructed to give their answers     classification Neural Network was constructed with N
as fast and as accurately as possible. They were obliged to        neurons (1-23 neurons) as inputs, 3 hidden layers and 3
provide an answer within a 4-second time window                    output neurons (one for each category). The N size is the
otherwise the trial was cancelled and presented at the end of      sub-selection of the total movement duration. Activation
the block. A feedback message was given to tell participants       functions for the output layers were symmetrical and
if their response was too slow. Each block consisted in the        sigmoid, between -1 and 1.
random presentation of a series of 48 stimuli, i.e., 16               With this NN, the instantaneous velocity in 3D was
different video clips for each of the three categories (Play;      calculated between the recorded positions of the wrist for
Me; You). After a 5-minute pause, the next block of 48             two subsequent frames. A threshold of 20 mm.s-1 was then
video clips was presented.                                         determined to compute the reaction time (RT) delay
                                                                   between the start of the recording and the actual beginning
   Dependent variables and statistical analyses.        The        of the movement. Second, a sampling parameter was used to
number of correct responses (correct prediction of the             compute the average velocity across 10 frames. Third, the
ongoing action) and the response times were calculated for         mean velocity values were converted from mm.s-1 to m.s-1 in
each category. The dependent measures were submitted to a          order to get data within an overall range of 0 to 1. Finally, a
repeated-measure ANOVA with Block and Category (Play;              training set (25%) and a test set (75%) were randomly
Me; You) as within factors. The participants’ scores for           picked from the 144 different kinematic recordings. 20
each category were compared using a Chi-square between             different networks were trained to obtain the classification
the observed scores and the random distribution between            performance for every specific target time widow (i.e. time
categories corrected by total the number of answer of that         window for kinematic recognition). The mean response and
category. In other term, because the total amount of answer        variance across the 20 networks are described in the result
is not exactly the same between categories, we consider the        section as the NN success rate (this value is always lower
guessing base-rate of each category separately. The alpha          than the best performing network). By varying the amount
level of significance was set to 0.05.                             of data fed as input, we computed the classification
                                                                   performance from multiple time windows. The learning
   Response times.          Results showed no effect of            procedure was a back-propagation algorithm using the
Block on response time, F(2,50) = 1.401, p = .256,                 FANN library (Nissen, 2003). Target error (to stop the
indicating that participants answered with a similar response      learning) was set to MeanStandardError < 0.001 with a
time in the first (M = 878, SD = 382 ms), the second (M =          maximum number of epochs set to 10 000, and 300
848, SD = 315 ms), and in the third block (M = 944, SD =           iterations between each test (evaluation of target global
316 ms). No effects of Category were found on response             error.
time, F(2,50) = 2.621, p=.083, indicating that participants
answered within the same delay both for ‘Play’ (M = 900,              Classification results in function of time. Results
SD = 294 ms), ‘Me’ (M = 866, SD = 294 ms), and ‘You’               revealed that the simple artificial classifier was able to
categories (M = 905, SD = 300 ms).                                 converge in most cases. The classifier succeeded in
                                                               2874

discriminating between categories for input sizes above 9,          advance the development of future cybernetic systems that
i.e. with a time window of 450 ms. For the input size of 9,         will afford true human-robot interactivity.
single sample t-tests confirmed that all categories were
above chance level, p < .001: ‘Play’ (M = 55.70 SD = 8.08              Kinematics reflecting motor intention. In the abundant
%); ‘Me’ category (M = 56.70 SD =4.16 %), and ‘You’                 literature of manipulating actions, the effects of end-point
category (M = 50.33 SD = 5.63 %). Figure 3 presents the             constraints on the early parts of movement kinematics have
detailed results for 12 different input sizes, between 50ms to      been investigated extensively in experimental psychology.
1150ms with a step of 100ms. From the input size of 5               In individualistic situations, multiple sources have been
(250ms) to 9 (450ms), only 2 categories were successfully           reported to modify and shape hand trajectory in two-element
recognized while the other remained below chance level;             sequences such as second-target distance (Gentilucci,
Below 250ms, only one category was correctly classified.            Negrotti, & Gangitano, 1997), end-target orientation
The crucial point to note here is nevertheless the fact that by     (Haggard, 1998; Hesse & Deubel, 2010) or second-action
450ms all categories are classified above chance level; a           type (Armbrüster & Spijkers, 2006; Marteniuk, MacKenzie,
point in time that occurs before the end of the first sub-          Jeannerod, Athenes, & Dugas, 1987). In social interactive
element of movement sequence confirming the capacity of a           manipulative tasks, final-goals have also been reported as
simple network to predict motor intention by the use of low-        having an effect on reach-to-grasp kinematics such as giving
level kinematics early on during motor execution.                   vs. placing an object (Becchio et al., 2008a), cooperative vs.
                                                                    competitive actions (Becchio, Sartori, Bulgheroni, &
                                                                    Castiello, 2008b; Georgiou, Becchio, Glover, & Castiello,
                                                                    2007), absence vs. presence of social request (Ferri,
                                                                    Campione, Dalla Volta, Gianelli, & Gentilucci, 2011),
                                                                    verbal communicative vs. non-communicative intentions
                                                                    (Sartori, Becchio, Bara, & Castiello, 2009). The kinematic
                                                                    effects reported here are consistent with this literature and
                                                                    suggest that when planning a sequential action with multiple
                                                                    sub-elements, the requirements of the endpoint element are
                                                                    back-propagated to constrain the way the very first element
                                                                    of the sequence will be planned and performed. Thus, it is
                                                                    possible to suggest that low-level motor components may
                                                                    contain early indices that reflect the end-point motor
                                                                    intention of an agent.
                                                                       Reading intentions.      In the present study, the first part
                                                                    of each movement was identical, i.e., the agents initiated
                                                                    their move with their hand placed on the starting pad of the
   Figure 3. Results obtained with the ANN. Note that with          playing area, and reached for and grasped the wooden-peg
an input size of 450ms, most of the networks classify the           that was always at the same position on the table. However,
movements with a higher rate than chance level and before           the second part of the move was specific and directly related
the end of the first motor element (vertical grey bar).             to the game intention: lift the wooden peg to take it (‘Me’
                                                                    category), to give it (‘You’ category) or to place it on the
                                                                    table (‘Play’ category). Thus, any kinematic deviants
                         Discussion                                 observed on the first part of the sequence may be related to
   In the present contribution, we report experimental data         the social intention of the second part. By measuring two
confirming that motor intention can be read through the             basic motor parameters (peak velocity and movement
simple observation of movement kinematics. More                     duration), we showed that it was possible to dissociate the
specifically, we first showed that the three different motor        three types of social interaction categories (Figure 2). We
intentions that were used in a simplified version of the            then tested the fact that human observers could use these
Jungle Speed game (Asmodee eds.) modified the kinematics            deviants to classify observed actions above chance level.
of the first (reach) sub-element of the sequential action.          The video clips were created in order to show the first sub-
Second, human agents were able to classify rapidly (<1s)            element only, without any contextual cues; care was also
and above chance level (>40%), the trial category when              taken to cut the end of the reaching action, one frame before
observing a video-clip of the reaching movement only of the         object contact, in order to avoid providing any cues on
sequence. Third, a classic feedforward neural network was           movement direction of the second part of the sequence. Our
also able to categorize motor intention through the use of          findings demonstrate that classification is possible and that
low-level kinematic information of, once again, the reaching        in certain cases, the participants’ performance can be
sub-element only. In the following section, we discuss these        extremely precise (up to 67% of correct classification for the
findings in more detail and describe how this work can help         best of participants). But how is this possible?
                                                                2875

                                                                     robots that afford true interaction, i.e., being able (1) to read
   An alternative low-level hypothesis. It is nevertheless           motor intention in human kinematics in order to adapt but
possible that the understanding of motor intention is based          also (2) to move with biological realistic kinematics, in
on more low-level cue readings. As suggested by the work             order allow others to understand the intention of the robot.
of Perrett and al. (Perrett et al., 1989), the visual system         Following the data presented here, we hypothesize that a
definitely contribute to action recognition and the                  humanoid robot could become interactive if it moved
performance showed by humans could be interpreted as the             following the laws of biological movement with action
resolution of an “inverse” problem (goal attribution) with a         sequences that integrate back propagation of terminal
simple bayesian inference about which goal explain the best          intention. Such a phenomenon would provide the means for
which action (Csibra, 2008). Indeed, despite a total absence         human agents to read intentionality and thus, gain in
of contextual cues within the video clips (body, head, eyes),        understanding the goal of the robot’s movements.
we demonstrated in the present study that participants were          Furthermore, including social deviants in the motor
able to read motor intention significantly above chance              kinematics within early steps of motor sequences would also
level. Hence, the subjects’ responses could be guided by the         allow safe interaction with large industrial robots by
slight deviances from the optimal strategy (i.e. to grasp            affording humans the possibility of anticipating false moves
without any subsequent action) in the low-level motor                in joint actions that share similar work spaces.
kinematics. This confirms recent results presented by Stapel            Implementing robots with the architecture necessary to
et al. (2012) who showed that in absence of contextual cues,         “afford intentionality” would need to integrate the different
kinematics could be a key source of information to predict           brain regions that are known to play a role in motor
intentions of ongoing actions. To go further in this low-level       planning and motor-sensory predictive mapping. De
hypothesis, we conducted a second work for which we used             Rengervé et collaborators (de Rengervé, Hirel, Andry,
a very simple artificial neural network classifier and we            Quoy, & Gaussier, 2011) have recently reported on such an
showed that this simple classifier performed as well as our          architecture, which included amongst other areas, the
human subjects in categorizing the three different social-           cerebellum and the basal ganglia. Tested on both software
intended video-clips. Further studies, namely brain imaging,         and hardware, this neural architecture has demonstrated its
are needed in order to determine whether the good                    efficiency on data collected in a hydraulic robotic arm. With
performance reached in our human individuals was due to              a series of imitation trials, this system demonstrated the
direct coding of the low-level kinematic parameters or               capacity to learn how to perform sequential actions that
whether the kinematics deviants are simple by products and           respected biological laws, i.e., to perform movements with
that even for simple actions, human performances engage in           kinematics that mirror those performed by human agents. As
a cognitive motor simulation to read motor intention (see            such, this robot arm has demonstrated increased interactivity
e.g. Kilner, Friston, & Frith, 2007; Kilner & Frith, 2008).          with human agents affording augmented interaction both in
   It is to note that correct classification of the three social     time and in space (none published results). Ongoing studies
categories was far from being perfect, reaching in the best of       are now being conducted to assess whether this interactivity
cases 60% of correct identification. Hence, kinematics can           is associated to an increase in the capacity of human
be used for predicting ongoing actions but cannot be the             collaborators to read the robot’s intention.
only source, used by human agents to judge motor intention.
It has been shown that during natural sequential task (i.e.                                   Conclusion
preparing a sandwich), eye movements are stereotyped and                We have here described experimental findings in humans
predictive (Hayhoe, Shrivastava, Mruczek, & Pelz, 2003).             demonstrating that it is possible to read motor intention
During the task, the eye precedes the hand movements in              through the simple observation of kinematic deviants.
systematic way ensuring a good coding of object position             Classification capacities were significantly above chance
for accurate planning of arm (Johansson, Westling,                   level and provided human subjects the means to dissociate
Bäckström, & Flanagan, 2001). This coordination between              between three different socially oriented actions. We argue
eye and hand movements during manipulative tasks have                in the present study that reading intentionality may not
extensively been tested in experimental psychology and               depend on a high-level cognitive function as suggested in
have demonstrated that e.g., eye movement onset is always            the psychological literature. Internal simulations may not be
faster than hand movement onset, and the peak velocity of            systematically required and understanding other intentions
both eye and hand movements are strongly correlated,                 may in certain cases relate to a direct coding of those
suggesting that they possess a coupled function. It is thus          kinematic deviants that back propagate from end-point to
possible that using both gaze position and the hand                  early on during sequence execution; this direct coding
movements kinematics, an observer would be able to                   would emerge through years of joint-action experiences,
increase the efficiency of intention reading (see also :             during interactions with adult con-specifics. As a first step
(Bekkering & Neggers, 2002).                                         to support this hypothesis, we report in the present study
                                                                     simple neural networks that were able, after learning the
Perspectives for interactive and social robotics.                    meaning of kinematic deviants, to classify the three
           The application of our work would be to develop           categories of actions to the same degree of accuracy than
                                                                 2876

our human participants. These preliminary results stresses                    and competitive behaviour. Cognition, 102(3), 415
the importance of further developing the optimal theories of                  ‑433.
motor control in order to include the effects on sequential         Haggard, P. (1998). Planning of action sequences. Acta
actions such as, back propagation phenomena of social                         Psychologica, 99(2), 201‑215.
context.                                                            Hayhoe, M., Shrivastava, A., Mruczek, R., & Pelz, J.
                                                                              (2003). Visual memory and motor planning in a
                     Acknowledgments                                          natural task. Journal of Vision, 3(1).
The work reported here was financially supported by a grant         Hesse, C., & Deubel, H. (2010). Advance Planning in
from the French Research Agency ANR-2009-CORD-014-                            Sequential Pick–and–Place Tasks. Journal of
INTERACT. The work provided by DL was also financed                           Neurophysiology, 104(1), 508‑516.
by the region Nord-Pas-de-Calais (France).                          Johansson, R. S., Westling, G., Bäckström, A., & Flanagan,
                                                                              J. R. (2001). Eye–hand coordination in object
                         References                                           manipulation. the Journal of Neuroscience, 21(17),
Ansuini, C., Giosa, L., Turella, L., Altoè, G., & Castiello, U.               6917–6932.
          (2008). An object for an action, the same object for      Kilner, J. M., Friston, K. J., & Frith, C. D. (2007).
          other actions: effects on hand shaping.                             Predictive coding: an account of the mirror neuron
          Experimental Brain Research, 185(1), 111‑119.                       system. Cognitive Processing, 8(3), 159‑166.
Armbrüster, C., & Spijkers, W. (2006). Movement planning            Kilner, J. M., & Frith, C. D. (2008). Action observation:
          in prehension: do intended actions influence the                    inferring intentions without mirror neurons.
          initial reach and grasp movement? Motor control,                    Current Biology, 18(1), R32–R33.
                                                                    Manera, V., Becchio, C., Cavallo, A., Sartori, L., &
          10(4), 311‑329.
                                                                              Castiello, U. (2011). Cooperation or competition?
Becchio, C., Sartori, L., Bulgheroni, M., & Castiello, U.
                                                                              Discriminating between social intentions by
          (2008a). The case of Dr. Jekyll and Mr. Hyde: A
                                                                              observing prehensile movements. Experimental
          kinematic study on social intention. Consciousness
                                                                              Brain Research, 211(3-4), 547‑556.
          and Cognition, 17(3), 557‑564.
                                                                    Marteniuk, R. G., MacKenzie, C. L., Jeannerod, M.,
Becchio, C., Sartori, L., Bulgheroni, M., & Castiello, U.
                                                                              Athenes, S., & Dugas, C. (1987). Constraints on
          (2008b). Both your intention and mine are reflected
                                                                              human arm movement trajectories. Canadian
          in the kinematics of my reach-to-grasp movement.
                                                                              Journal of Psychology, 41(3), 365‑378.
          Cognition, 106(2), 894‑912.
                                                                    Nissen, S. (2003). Implementation of a fast artificial neural
Becchio, C., Sartori, L., & Castiello, U. (2010). Toward
                                                                              network library (fann). Report, Department of
          You The Social Side of Actions. Current
                                                                              Computer Science University of Copenhagen
          Directions in Psychological Science, 19(3), 183‑                    (DIKU), 31.
          188.                                                      Oldfield, R. C. (1971). The assessment and analysis of
Bekkering, H., & Neggers, S. F. W. (2002). Visual search is                   handedness:       the      Edinburgh      inventory.
          modulated by action intentions. Psychological                       Neuropsychologia, 9(1), 97–113.
          Science, 13(4), 370–374.                                  Perrett, D. I., Harries, M. H., Bevan, R., Thomas, S.,
Csibra, G. (2008). Action mirroring and action                                Benson, P. J., Mistlin, A. J., … Ortega, J. E.
          understanding:      An      alternative     account.                (1989). Frameworks of analysis for the neural
          Sensorymotor Foundations of Higher Cognition.                       representation of animate objects and actions.
          Attention and Performance XXII, 435–459.                            Journal of Experimental Biology, 146(1), 87–113.
De Rengervé, A., Hirel, J., Andry, P., Quoy, M., &                  Sartori, L., Becchio, C., Bara, B. G., & Castiello, U. (2009).
          Gaussier, P. (2011). On-line learning and planning                  Does the intention to communicate affect action
          in a pick-and-place task demonstrated through                       kinematics? Consciousness and Cognition, 18(3),
          body manipulation. In 2011 IEEE International
                                                                              766‑772.
          Conference on Development and Learning (ICDL)
                                                                    Sartori, L., Becchio, C., Bulgheroni, M., & Castiello, U.
          (Vol. 2, p. 1‑6).                                                   (2009). Modulation of the action control system by
Ferri, F., Campione, G. C., Dalla Volta, R., Gianelli, C., &                  social intention: unexpected social requests
          Gentilucci, M. (2011). Social Requests and Social                   override     preplanned     action.    Journal    of
          Affordances: How They Affect the Kinematics of                      Experimental Psychology. Human Perception and
          Motor Sequences during Interactions between
                                                                              Performance,             35(5),          1490‑1500.
          Conspecifics. PLoS ONE, 6(1), e15855.
                                                                              doi:10.1037/a0015777
Gentilucci, M., Negrotti, A., & Gangitano, M. (1997).
                                                                    Sartori, L., Becchio, C., & Castiello, U. (2011). Cues to
          Planning an action. Experimental Brain Research,
                                                                              intention: The role of movement information.
          115(1), 116‑128.
                                                                              Cognition, 119(2), 242‑252.
Georgiou, I., Becchio, C., Glover, S., & Castiello, U.
          (2007). Different action patterns for cooperative
                                                                2877

