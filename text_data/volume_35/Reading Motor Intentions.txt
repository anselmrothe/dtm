UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reading Motor Intentions

Permalink
https://escholarship.org/uc/item/6h45q9d9

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Lewkowwicz, Daniel
Delevoye-Turrell, Yvonne

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Reading Motor Intentions
Lewkowicz Daniel (daniel.lewkowicz@etu.univ-lille3.fr)
URECA laboratory, Univ Lille Nord de France, F-59000 Lille, France

Delevoye-Turrell Yvonne (yvonne.delevoye@univ-lille3.fr)
URECA laboratory, Univ Lille Nord de France, F-59000 Lille, France
MESHS, USR 3185, F-59000 Lille, France
Abstract
Some evidence in very recent psychological studies have
demonstrated that motor simulation ability is crucial for the
correct understanding of social intentions. The present study
was conducted first to confirm that the nature of the motor
intention leads to early modulations of movement kinematics.
Then, we tested whether humans could read an agent’s
intention when observing the very first element of a complex
action sequence. Results revealed early variations in
movement kinematics and further showed that human agents
can use these deviants to distinguish above chance level
between three different social actions. Similar performance
levels were found using an artificial classifier (Neural
Network) and this procedure demonstrated furthermore that
decisions could be taken on the basis of information contained
in the first 500ms of movement kinematics. Taken together
these results confirm the importance of motor simulation for
adapted social interaction, and suggest how robotic adaptive
controllers may use as input low-level motor information (e.g.
kinematics) to afford biologically inspired social behaviors.
Keywords: Classifier; kinematics; sequences; motor control;
intentionality: social interaction; internal models; prediction;
motor planning; biological movement.

Introduction
In everyday activities, the grasping of an object might be
performed with different prior intentions: e.g. touch, move,
throw or pass. Ansuini et al. (2008) have measured the
prior-to-contact grasping kinematics for reach-to-grasp
movements performed toward a bottle filled with water. By
comparing hand shaping across tasks involving different
subsequent actions - pour the water into a container; throw
the bottle; move the bottle from one spatial location to
another - the authors demonstrated how the prior intention
in grasping the object strongly affected the positioning of
the fingers during the reaching and the contact phase of the
action (Ansuini, Giosa, Turella, Altoè, & Castiello, 2008).
In another series of studies, Becchio and collaborators
investigated the effects of social context on reach-to-grasp
actions. They found initial adjustments reflecting specific
planning strategies (Becchio, Sartori, Bulgheroni, &
Castiello, 2008a) as well as online adjustments (Sartori,
Becchio, Bulgheroni, & Castiello, 2009) when performing
under social context (see : Becchio et al., 2010 for a
review).
More recently, researchers have gone one step further to
suggest that not only end-point constraints and social

contexts affect movement kinematics, but that these
deviants may be used to read motor intention. For example,
when observing actions performed under social context or
not, Castiello and collaborators demonstrated that humans
can successfully use kinematic cues of reach-to-grasp
movements to predict the final goal of the action (Sartori,
Becchio, & Castiello, 2011). Similar results were also found
using point-light displays of simple reach to grasp
movements (Manera, Becchio, Cavallo, Sartori, & Castiello,
2011). However, in these studies, the classification rates
were obtained under a forced two-choice paradigm, and for
the most subtle differences (cooperative vs individual
preferred speed or competitive vs fast speed) the
classification rates were very small (near 50%).
In the present work, we wanted to study the capacity of
humans to read motor intention in a sequence of 2 motor
elements. One novelty of this study is that the sequences
were performed entirely during an interactive situation with
a con-specific, without any interruption or verbal instruction
between the sequences. As such, we recorded sequential
actions during an ecologically inspired task (Jungle Speed),
a simple face-to-face game using a unique manipulated
object. Our main focus was to compare human and artificial
categorization performances for three different sequential
actions that took part during the game. To test the
hypothesis that kinematics alone is sufficient to read social
intention, we fed the artificial classifier with movement
kinematics only.
Confronting Jacob & Jeannerod’s (2005) reading motor
intention hypothesis, we hypothesized that human agents are
able to read motor intention through the simple observation
of arm kinematics of the first element of a 2-sequence
action. This is possible due to the fact that arm kinematics
of the reach to grasp movements reveal specific deviants in
function of goal intention from an ideal optimized
trajectory. Finally, if motor simulation is sufficient, then an
artificial neural network should be able to learn from the
deviants and predict as well as humans, the motor intention
of an observed agent. In the following section, we first
describe the methods we used to make the observation
videos (Part A), which were then played to human agents
(Part B) and used as input parameters to an artificial neural
network (Part C).

Creating Stimuli
Two adults participated in the study, one experimenter
and the other as subject. Both participants were right handed

2872

as verified with the Handedness questionnaire (Oldfield,
1971). They had no prior knowledge of the experiment and
provided informed consent before participating in the
experimental session that lasted approximately 90 minutes.
The subjects’ movements were recorded using a (1) a video
camera (Sony Handycam) and (2) 4 Oqus infrared cameras
(Qualysis).5 infrared reflective markers were placed on the
thumb (tip), index (base and tip) and the wrist (scaphoïd and
pisiform). Cameras were calibrated before each session,
allowing the system to reach a standard deviation smaller
than 0.2 mm, with a 200 Hz sampling rate

Figure 1. Schematic representation of the
experimental setup.
The game.
The object that was to be manipulated by
the subject was a wooden dowel of width 2 cm and height of
4 cm that was placed precisely 20 cm in front of the starting
position (‘pick’ position). The subject started each trial by
pinching index and thumb together at the starting position
(see Figure 1). Each trial, the subject's task was to reach and
grasp the dowel between thumb and index finger in order to
move it from the initial position to one of the three ‘place’
positions during an adapted version of the jungle-speed
game. The game consisted in 4 blocks of approximately 40
rounds. First, the subject’s task was to pick and place the
dowel at the ‘Play’ position in order to set the initial
condition of the game. Then, at the ‘go’ signal (high pitch)
both participants reached for the dowel as quickly as
possible. The competitive move was not recorded and is not
part of this study, although, this was indeed intentionally
omitted during instructions given to the subject. During
competitive move, the first who have grasped the dowel,
won the round and scored a point. The second phase
consisted in a rewarding phase. The dowel was first always
repositioned at pick position and the subject wait at starting
position for the next audio tone (low pitch). During the
rewarding phase just after the competitive move, the subject
has to reach to grasp the dowel and place it either at the
‘You’ position if the experimenter scored during
competitive move, or at the ‘Me’ Position if the participant
scored during competitive move. The game went on until
one of the two players reached 20 points. Thus, we recorded
twice as much ‘Play’ moves than ‘You’ or ‘Me’ moves
during the game. Nonetheless, after 5 rounds of training to

set up the game rules, no other verbal instructions were
given during the blocks. The three different positions
(‘Play’; ‘Me’; ‘You’) where the dowel had to be placed
were delimited by visual marks directly placed on the
tabletop.
The recordings.
The best 16 recordings of each
category (‘Play’, ‘Me’ and ‘You’) were extracted using
VirtualDub and kept for future use as stimuli. Each
sequence was delimited with a 1-second pre-trial, i.e.,
before the initial movement onset, and was cut exactly one
frame before the index finger contacted the object. Movies
were compressed with FFdshow codec (MJPEG) at 50
frames per seconds with a screen resolution of 720x576.
Video clips were coupled with the recordings of the arm
kinematics using 4 Oqus infrared Cameras (Qualisys).
Infrared reflective markers were placed on the index (base
and tip), the thumb (tip), the wrist (scaphoïd and pisiform)
of each participant, as well as on the object. Cameras were
calibrated before each recording session, allowing the
system to reach a standard deviation smaller than 0.2 mm
for all three absolute positions at a 200 Hz sampling
frequency. Care was taken as to provide no contextual
information within the video clips (torso, gaze, face
expression), i.e., only the hand and the target object were
fully in view. Velocity profiles are presented in Figure 2 and
show that play, me or you sequences show deviations during
both first and second motor element (amplitude and the
width of the bell-shaped curves, first and second peaks of
velocity, time position for local minima).

Figure 2. Mean velocity profiles for the three
categories of sequences. Each bell-shape curve
corresponds to a motor element. The first is the reach to
grasp element, and the second bell-shape curve is placing
element. The local minima are used to segment the two
motor elements and compute movement times.

Human Categorization Performance
The short video clips were presented to a panel of human
subjects to test whether human agents were able to predict

2873

the goal of a sequential action when shown only the first
sub-element of a sequence, i.e., the reach movement.
Participants, Apparatus and Software. Twenty-six
young adults (mean age: 21.82 ± 2.76 years, range = 18 - 29
years) participated in the study. All subjects were right
handed (Oldfield, 1971) and had no prior knowledge of the
experiment. Subjects provided informed consent before
participating in the experimental session that lasted
approximately 45 minutes. Participants were seated
comfortably facing a table in a dark and silent room. For
each trial, participants started by placing their hand on
response keys that were delimited by tape placed directly on
the keyboard keys. Stimuli were presented on a laptop
computer with MATLAB software (Mathworks) with the
PsychToolbox environment.

Categorization with Artificial Neural Networks
In the following section, we present the simple
feedforward neural network that was developed to
demonstrate the possibility to categorize on the only basis of
motor kinematics.

Experimental Procedure.
The participants' task
was to answer on the keypad after each video clip
presentation whether the social intention of the sequence
was ‘let’s Play’ (5 key), ‘for Me’ (2 key) or ‘for You’ (8
key). A 1-second blank screen was displayed in between
two trials. Participants were instructed to give their answers
as fast and as accurately as possible. They were obliged to
provide an answer within a 4-second time window
otherwise the trial was cancelled and presented at the end of
the block. A feedback message was given to tell participants
if their response was too slow. Each block consisted in the
random presentation of a series of 48 stimuli, i.e., 16
different video clips for each of the three categories (Play;
Me; You). After a 5-minute pause, the next block of 48
video clips was presented.
Dependent variables and statistical analyses.
The
number of correct responses (correct prediction of the
ongoing action) and the response times were calculated for
each category. The dependent measures were submitted to a
repeated-measure ANOVA with Block and Category (Play;
Me; You) as within factors. The participants’ scores for
each category were compared using a Chi-square between
the observed scores and the random distribution between
categories corrected by total the number of answer of that
category. In other term, because the total amount of answer
is not exactly the same between categories, we consider the
guessing base-rate of each category separately. The alpha
level of significance was set to 0.05.
Response times.
Results showed no effect of
Block on response time, F(2,50) = 1.401, p = .256,
indicating that participants answered with a similar response
time in the first (M = 878, SD = 382 ms), the second (M =
848, SD = 315 ms), and in the third block (M = 944, SD =
316 ms). No effects of Category were found on response
time, F(2,50) = 2.621, p=.083, indicating that participants
answered within the same delay both for ‘Play’ (M = 900,
SD = 294 ms), ‘Me’ (M = 866, SD = 294 ms), and ‘You’
categories (M = 905, SD = 300 ms).

Number of correct responses. There was an absence of
Block effect on classification performances, F(2,50) =
0.102, p = .903. However, a main effect of Category was
obtained, F(2,50) = 16.022, p < .001, η² p=.39. Post-hoc
Scheffé analyses further showed that participants were more
accurate for trials in the ‘Me’ category (M = 57.53, SD =
13.02 %) than in the ‘You’ (M = 40.87, SD = 12.12 %) and
in the ‘Play’ category (M = 47.27, SD = 13.04 %). More
importantly, Chi-squared tests showed highly significant
difference between observed frequencies and random
guessing baselines for the ‘Me’ (guess rate = 36.98,
p<.001), ‘Play’ (guess rate = 36.12, p<.001) or ‘You’ (guess
rate = 26.90, p<.001). These results confirmed that
performance was significantly greater than chance level.

Architecture and Learning procedure. A simple
classification Neural Network was constructed with N
neurons (1-23 neurons) as inputs, 3 hidden layers and 3
output neurons (one for each category). The N size is the
sub-selection of the total movement duration. Activation
functions for the output layers were symmetrical and
sigmoid, between -1 and 1.
With this NN, the instantaneous velocity in 3D was
calculated between the recorded positions of the wrist for
two subsequent frames. A threshold of 20 mm.s-1 was then
determined to compute the reaction time (RT) delay
between the start of the recording and the actual beginning
of the movement. Second, a sampling parameter was used to
compute the average velocity across 10 frames. Third, the
mean velocity values were converted from mm.s-1 to m.s-1 in
order to get data within an overall range of 0 to 1. Finally, a
training set (25%) and a test set (75%) were randomly
picked from the 144 different kinematic recordings. 20
different networks were trained to obtain the classification
performance for every specific target time widow (i.e. time
window for kinematic recognition). The mean response and
variance across the 20 networks are described in the result
section as the NN success rate (this value is always lower
than the best performing network). By varying the amount
of data fed as input, we computed the classification
performance from multiple time windows. The learning
procedure was a back-propagation algorithm using the
FANN library (Nissen, 2003). Target error (to stop the
learning) was set to MeanStandardError < 0.001 with a
maximum number of epochs set to 10 000, and 300
iterations between each test (evaluation of target global
error.
Classification results in function of time. Results
revealed that the simple artificial classifier was able to
converge in most cases. The classifier succeeded in

2874

discriminating between categories for input sizes above 9,
i.e. with a time window of 450 ms. For the input size of 9,
single sample t-tests confirmed that all categories were
above chance level, p < .001: ‘Play’ (M = 55.70 SD = 8.08
%); ‘Me’ category (M = 56.70 SD =4.16 %), and ‘You’
category (M = 50.33 SD = 5.63 %). Figure 3 presents the
detailed results for 12 different input sizes, between 50ms to
1150ms with a step of 100ms. From the input size of 5
(250ms) to 9 (450ms), only 2 categories were successfully
recognized while the other remained below chance level;
Below 250ms, only one category was correctly classified.
The crucial point to note here is nevertheless the fact that by
450ms all categories are classified above chance level; a
point in time that occurs before the end of the first subelement of movement sequence confirming the capacity of a
simple network to predict motor intention by the use of lowlevel kinematics early on during motor execution.

Figure 3. Results obtained with the ANN. Note that with
an input size of 450ms, most of the networks classify the
movements with a higher rate than chance level and before
the end of the first motor element (vertical grey bar).

Discussion
In the present contribution, we report experimental data
confirming that motor intention can be read through the
simple observation of movement kinematics. More
specifically, we first showed that the three different motor
intentions that were used in a simplified version of the
Jungle Speed game (Asmodee eds.) modified the kinematics
of the first (reach) sub-element of the sequential action.
Second, human agents were able to classify rapidly (<1s)
and above chance level (>40%), the trial category when
observing a video-clip of the reaching movement only of the
sequence. Third, a classic feedforward neural network was
also able to categorize motor intention through the use of
low-level kinematic information of, once again, the reaching
sub-element only. In the following section, we discuss these
findings in more detail and describe how this work can help

advance the development of future cybernetic systems that
will afford true human-robot interactivity.
Kinematics reflecting motor intention. In the abundant
literature of manipulating actions, the effects of end-point
constraints on the early parts of movement kinematics have
been investigated extensively in experimental psychology.
In individualistic situations, multiple sources have been
reported to modify and shape hand trajectory in two-element
sequences such as second-target distance (Gentilucci,
Negrotti, & Gangitano, 1997), end-target orientation
(Haggard, 1998; Hesse & Deubel, 2010) or second-action
type (Armbrüster & Spijkers, 2006; Marteniuk, MacKenzie,
Jeannerod, Athenes, & Dugas, 1987). In social interactive
manipulative tasks, final-goals have also been reported as
having an effect on reach-to-grasp kinematics such as giving
vs. placing an object (Becchio et al., 2008a), cooperative vs.
competitive actions (Becchio, Sartori, Bulgheroni, &
Castiello, 2008b; Georgiou, Becchio, Glover, & Castiello,
2007), absence vs. presence of social request (Ferri,
Campione, Dalla Volta, Gianelli, & Gentilucci, 2011),
verbal communicative vs. non-communicative intentions
(Sartori, Becchio, Bara, & Castiello, 2009). The kinematic
effects reported here are consistent with this literature and
suggest that when planning a sequential action with multiple
sub-elements, the requirements of the endpoint element are
back-propagated to constrain the way the very first element
of the sequence will be planned and performed. Thus, it is
possible to suggest that low-level motor components may
contain early indices that reflect the end-point motor
intention of an agent.
Reading intentions.
In the present study, the first part
of each movement was identical, i.e., the agents initiated
their move with their hand placed on the starting pad of the
playing area, and reached for and grasped the wooden-peg
that was always at the same position on the table. However,
the second part of the move was specific and directly related
to the game intention: lift the wooden peg to take it (‘Me’
category), to give it (‘You’ category) or to place it on the
table (‘Play’ category). Thus, any kinematic deviants
observed on the first part of the sequence may be related to
the social intention of the second part. By measuring two
basic motor parameters (peak velocity and movement
duration), we showed that it was possible to dissociate the
three types of social interaction categories (Figure 2). We
then tested the fact that human observers could use these
deviants to classify observed actions above chance level.
The video clips were created in order to show the first subelement only, without any contextual cues; care was also
taken to cut the end of the reaching action, one frame before
object contact, in order to avoid providing any cues on
movement direction of the second part of the sequence. Our
findings demonstrate that classification is possible and that
in certain cases, the participants’ performance can be
extremely precise (up to 67% of correct classification for the
best of participants). But how is this possible?

2875

An alternative low-level hypothesis. It is nevertheless
possible that the understanding of motor intention is based
on more low-level cue readings. As suggested by the work
of Perrett and al. (Perrett et al., 1989), the visual system
definitely contribute to action recognition and the
performance showed by humans could be interpreted as the
resolution of an “inverse” problem (goal attribution) with a
simple bayesian inference about which goal explain the best
which action (Csibra, 2008). Indeed, despite a total absence
of contextual cues within the video clips (body, head, eyes),
we demonstrated in the present study that participants were
able to read motor intention significantly above chance
level. Hence, the subjects’ responses could be guided by the
slight deviances from the optimal strategy (i.e. to grasp
without any subsequent action) in the low-level motor
kinematics. This confirms recent results presented by Stapel
et al. (2012) who showed that in absence of contextual cues,
kinematics could be a key source of information to predict
intentions of ongoing actions. To go further in this low-level
hypothesis, we conducted a second work for which we used
a very simple artificial neural network classifier and we
showed that this simple classifier performed as well as our
human subjects in categorizing the three different socialintended video-clips. Further studies, namely brain imaging,
are needed in order to determine whether the good
performance reached in our human individuals was due to
direct coding of the low-level kinematic parameters or
whether the kinematics deviants are simple by products and
that even for simple actions, human performances engage in
a cognitive motor simulation to read motor intention (see
e.g. Kilner, Friston, & Frith, 2007; Kilner & Frith, 2008).
It is to note that correct classification of the three social
categories was far from being perfect, reaching in the best of
cases 60% of correct identification. Hence, kinematics can
be used for predicting ongoing actions but cannot be the
only source, used by human agents to judge motor intention.
It has been shown that during natural sequential task (i.e.
preparing a sandwich), eye movements are stereotyped and
predictive (Hayhoe, Shrivastava, Mruczek, & Pelz, 2003).
During the task, the eye precedes the hand movements in
systematic way ensuring a good coding of object position
for accurate planning of arm (Johansson, Westling,
Bäckström, & Flanagan, 2001). This coordination between
eye and hand movements during manipulative tasks have
extensively been tested in experimental psychology and
have demonstrated that e.g., eye movement onset is always
faster than hand movement onset, and the peak velocity of
both eye and hand movements are strongly correlated,
suggesting that they possess a coupled function. It is thus
possible that using both gaze position and the hand
movements kinematics, an observer would be able to
increase the efficiency of intention reading (see also :
(Bekkering & Neggers, 2002).
Perspectives for interactive and social robotics.
The application of our work would be to develop

robots that afford true interaction, i.e., being able (1) to read
motor intention in human kinematics in order to adapt but
also (2) to move with biological realistic kinematics, in
order allow others to understand the intention of the robot.
Following the data presented here, we hypothesize that a
humanoid robot could become interactive if it moved
following the laws of biological movement with action
sequences that integrate back propagation of terminal
intention. Such a phenomenon would provide the means for
human agents to read intentionality and thus, gain in
understanding the goal of the robot’s movements.
Furthermore, including social deviants in the motor
kinematics within early steps of motor sequences would also
allow safe interaction with large industrial robots by
affording humans the possibility of anticipating false moves
in joint actions that share similar work spaces.
Implementing robots with the architecture necessary to
“afford intentionality” would need to integrate the different
brain regions that are known to play a role in motor
planning and motor-sensory predictive mapping. De
Rengervé et collaborators (de Rengervé, Hirel, Andry,
Quoy, & Gaussier, 2011) have recently reported on such an
architecture, which included amongst other areas, the
cerebellum and the basal ganglia. Tested on both software
and hardware, this neural architecture has demonstrated its
efficiency on data collected in a hydraulic robotic arm. With
a series of imitation trials, this system demonstrated the
capacity to learn how to perform sequential actions that
respected biological laws, i.e., to perform movements with
kinematics that mirror those performed by human agents. As
such, this robot arm has demonstrated increased interactivity
with human agents affording augmented interaction both in
time and in space (none published results). Ongoing studies
are now being conducted to assess whether this interactivity
is associated to an increase in the capacity of human
collaborators to read the robot’s intention.

Conclusion
We have here described experimental findings in humans
demonstrating that it is possible to read motor intention
through the simple observation of kinematic deviants.
Classification capacities were significantly above chance
level and provided human subjects the means to dissociate
between three different socially oriented actions. We argue
in the present study that reading intentionality may not
depend on a high-level cognitive function as suggested in
the psychological literature. Internal simulations may not be
systematically required and understanding other intentions
may in certain cases relate to a direct coding of those
kinematic deviants that back propagate from end-point to
early on during sequence execution; this direct coding
would emerge through years of joint-action experiences,
during interactions with adult con-specifics. As a first step
to support this hypothesis, we report in the present study
simple neural networks that were able, after learning the
meaning of kinematic deviants, to classify the three
categories of actions to the same degree of accuracy than

2876

our human participants. These preliminary results stresses
the importance of further developing the optimal theories of
motor control in order to include the effects on sequential
actions such as, back propagation phenomena of social
context.

Acknowledgments
The work reported here was financially supported by a grant
from the French Research Agency ANR-2009-CORD-014INTERACT. The work provided by DL was also financed
by the region Nord-Pas-de-Calais (France).

References
Ansuini, C., Giosa, L., Turella, L., Altoè, G., & Castiello, U.
(2008). An object for an action, the same object for
other actions: effects on hand shaping.
Experimental Brain Research, 185(1), 111‑119.
Armbrüster, C., & Spijkers, W. (2006). Movement planning
in prehension: do intended actions influence the
initial reach and grasp movement? Motor control,
10(4), 311‑329.
Becchio, C., Sartori, L., Bulgheroni, M., & Castiello, U.
(2008a). The case of Dr. Jekyll and Mr. Hyde: A
kinematic study on social intention. Consciousness
and Cognition, 17(3), 557‑564.
Becchio, C., Sartori, L., Bulgheroni, M., & Castiello, U.
(2008b). Both your intention and mine are reflected
in the kinematics of my reach-to-grasp movement.
Cognition, 106(2), 894‑912.
Becchio, C., Sartori, L., & Castiello, U. (2010). Toward
You The Social Side of Actions. Current
Directions in Psychological Science, 19(3), 183‑
188.
Bekkering, H., & Neggers, S. F. W. (2002). Visual search is
modulated by action intentions. Psychological
Science, 13(4), 370–374.
Csibra, G. (2008). Action mirroring and action
understanding:
An
alternative
account.
Sensorymotor Foundations of Higher Cognition.
Attention and Performance XXII, 435–459.
De Rengervé, A., Hirel, J., Andry, P., Quoy, M., &
Gaussier, P. (2011). On-line learning and planning
in a pick-and-place task demonstrated through
body manipulation. In 2011 IEEE International
Conference on Development and Learning (ICDL)
(Vol. 2, p. 1‑6).
Ferri, F., Campione, G. C., Dalla Volta, R., Gianelli, C., &
Gentilucci, M. (2011). Social Requests and Social
Affordances: How They Affect the Kinematics of
Motor Sequences during Interactions between
Conspecifics. PLoS ONE, 6(1), e15855.
Gentilucci, M., Negrotti, A., & Gangitano, M. (1997).
Planning an action. Experimental Brain Research,
115(1), 116‑128.
Georgiou, I., Becchio, C., Glover, S., & Castiello, U.
(2007). Different action patterns for cooperative

and competitive behaviour. Cognition, 102(3), 415
‑433.
Haggard, P. (1998). Planning of action sequences. Acta
Psychologica, 99(2), 201‑215.
Hayhoe, M., Shrivastava, A., Mruczek, R., & Pelz, J.
(2003). Visual memory and motor planning in a
natural task. Journal of Vision, 3(1).
Hesse, C., & Deubel, H. (2010). Advance Planning in
Sequential Pick–and–Place Tasks. Journal of
Neurophysiology, 104(1), 508‑516.
Johansson, R. S., Westling, G., Bäckström, A., & Flanagan,
J. R. (2001). Eye–hand coordination in object
manipulation. the Journal of Neuroscience, 21(17),
6917–6932.
Kilner, J. M., Friston, K. J., & Frith, C. D. (2007).
Predictive coding: an account of the mirror neuron
system. Cognitive Processing, 8(3), 159‑166.
Kilner, J. M., & Frith, C. D. (2008). Action observation:
inferring intentions without mirror neurons.
Current Biology, 18(1), R32–R33.
Manera, V., Becchio, C., Cavallo, A., Sartori, L., &
Castiello, U. (2011). Cooperation or competition?
Discriminating between social intentions by
observing prehensile movements. Experimental
Brain Research, 211(3-4), 547‑556.
Marteniuk, R. G., MacKenzie, C. L., Jeannerod, M.,
Athenes, S., & Dugas, C. (1987). Constraints on
human arm movement trajectories. Canadian
Journal of Psychology, 41(3), 365‑378.
Nissen, S. (2003). Implementation of a fast artificial neural
network library (fann). Report, Department of
Computer Science University of Copenhagen
(DIKU), 31.
Oldfield, R. C. (1971). The assessment and analysis of
handedness:
the
Edinburgh
inventory.
Neuropsychologia, 9(1), 97–113.
Perrett, D. I., Harries, M. H., Bevan, R., Thomas, S.,
Benson, P. J., Mistlin, A. J., … Ortega, J. E.
(1989). Frameworks of analysis for the neural
representation of animate objects and actions.
Journal of Experimental Biology, 146(1), 87–113.
Sartori, L., Becchio, C., Bara, B. G., & Castiello, U. (2009).
Does the intention to communicate affect action
kinematics? Consciousness and Cognition, 18(3),
766‑772.
Sartori, L., Becchio, C., Bulgheroni, M., & Castiello, U.
(2009). Modulation of the action control system by
social intention: unexpected social requests
override
preplanned
action.
Journal
of
Experimental Psychology. Human Perception and
Performance,
35(5),
1490‑1500.
doi:10.1037/a0015777
Sartori, L., Becchio, C., & Castiello, U. (2011). Cues to
intention: The role of movement information.
Cognition, 119(2), 242‑252.

2877

