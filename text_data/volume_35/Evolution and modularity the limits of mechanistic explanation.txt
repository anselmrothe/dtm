UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Evolution and modularity: the limits of mechanistic explanation
Permalink
https://escholarship.org/uc/item/8cn1b6ks
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Kuorikoski, Jaakko
Pöyhönen, Samuli
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                   Evolution and Modularity: The limits of mechanistic explanation
                                      Jaakko Kuorikoski (jaakko.kuorikoski@helsinki.fi)
                                                Social and Moral Philosophy, P.O. Box 24
                                                   University of Helsinki, 00014 Finland
                                        Samuli Pöyhönen (samuli.poyhonen@helsinki.fi)
                                                Social and Moral Philosophy, P.O. Box 24
                                                   University of Helsinki, 00014 Finland
                              Abstract1                                    evolutionary design: problem-solutions generated by genetic
   Accounts of mechanistic explanation require that complex
                                                                           algorithms. By analyzing the nature of solutions that genetic
   cognitive phenomena can be decomposed into simpler                      algorithms offer to computational problems, we suggest that
   subtasks. We provide a theory of explanation that rationalizes          evolutionary designs are often hard to understand because
   this requirement, and then we use a simple genetic algorithm            they can exhibit non-modular functionality, and that this
   exercise to demonstrate that evolution can produce designs              creates problems for strategies of mechanistic explanation.
   that violate this functional modularity requirement.
   Keywords: mechanism; explanation; evolution; modularity;                     Mechanistic Explanation in the Cognitive
   genetic algorithm                                                                                  Sciences
                                                                           According to the proponents of the mechanistic approach to
                           Introduction                                    explanation (Bechtel 2008; Craver 2007; Piccinini & Craver
Connectionism, dynamical systems theory, and new robotics                  2011), a central goal of the cognitive sciences is to provide
have questioned whether the search for information-                        understanding of system-level properties of the cognitive
processing mechanisms provides a feasible approach to the                  system in terms of the properties of its physical component
study of biologically evolved cognitive systems such as the                parts and their organization. The most developed
human mind. Whereas approaches that have their origins in                  philosophical account of strategies for reaching such
classical AI tend to conceive of cognition as a set of                     mechanistic understanding is Bechtel and Richardson’s
computational operations to be mapped onto physiological                   (2010) study of the heuristics of decomposition and
parts according to functional decompositions inspired                      localization (DL). The DL procedure goes roughly as
directly by the programmer’s intuitions about possible                     follows. First, the different phenomena that the system of
efficient subroutines, the alternative research programs                   interest exhibits are differentiated. Then the phenomenon of
emphasize that biological evolution is likely to produce                   interest is functionally decomposed, i.e., analyzed into a set
unintuitive designs of such complexity that renders                        of possible component operations that would be sufficient to
heuristics based on decomposability and programming                        produce it. One can think of this step as the formulation of a
intuitions unusable.                                                       preliminary set of simpler functions that, taken together,
  In this paper we analyze the problems that evolved                       would constitute the more complex input-output relation
solutions raise to the mechanistic understanding of cognitive              (the system-level phenomenon). The system is also
phenomena. The problem of understanding non-intuitive                      structurally decomposed into a set of component parts. The
designs produced by natural selection is well-known in                     final step is to try to localize the component operations by
philosophy of psychology (e.g., Clark 1997, Ch. 5),                        mapping them onto appropriate structural component parts.
philosophy of biology (Wimsatt 2007), and now even in                      If this cannot be done, the fault may lie with the functional
popular psychology (Marcus 2008), but it has proved to be                  and structural decompositions or with the very identification
difficult to articulate without a clear idea of what exactly it            of the phenomenon, and these may then have to be
is that evolutionary tinkering is supposed to hinder. The                  rethought. The identification and decomposition procedures
main challenge for scientific understanding is often framed                will in the beginning be guided by earlier theories and
and explained by pointing to the path-dependent nature and                 common sense, but empirical evidence can always suggest
the resulting unfamiliarity of the evolved design (Jacob                   that a thorough reworking of the basic ontology and the
1977). We argue that this is not the whole story. The aim of               form of the possible explananda may be in order.
this paper is to provide an explicit theory of mechanistic                    What the schema of Bechtel and Richardson lacks is an
explanation and understanding that will move us beyond                     explicit theory of explanation providing an account of what
intuitions towards a more systematic analysis of the nature                makes such decomposition and localization exercises
of these challenges. We also combine our theory of                         explanatory. Whereas cognitive theories of explanation
explanation with a computational application of                            (Churchland 1989; Thagard 2012; Waskan 2006) focus on
                                                                           the internal models and processes of the individuals engaged
   1
                                                                           in explanation-related tasks, such conceptualization is
     The authors are listed in alphabetical order. This paper is based
                                                                       840

misleading when thinking about the goal of research:                understandable for finite cognitive agents. Near-
understanding. We use the term ‘understanding’ in order to          decomposability means that the system can be decomposed
shift our focus from single explanations to a broader               into parts in such a way that the intrinsic causal properties of
collective epistemic goal. Scientific understanding proper is       the parts are more important for the behavior of the system
not what happens inside individual heads, but is constituted        than their relational causal properties, which are constituted
by the collective abilities of the scientific community to          also by their environment and interaction. Near-
reason about and to manipulate the objects of investigation.        decomposable systems are thus hierarchical in the sense that
To conceptualize scientific understanding directly based on         the complex whole can be seen as made from a limited set
models of individual explanatory cognition is to commit a           of simpler parts and interactions. Hierarchical systems are
fallacy of composition.                                             more manageable for cognitively limited beings because
  We therefore approach understanding as a public,                  their ‘complete description’ includes recurring or irrelevant
behavioral concept. Understanding is a regulative label,            elements describing similar recurring parts and non-
which is attributed with regard to manifest abilities in action     important interactions. The removal of such descriptions
and correctness of reasoning. Suitable cognitive processes          does not hamper our understanding of the system and thus
(comprehension), and possibly the possession of right               eases cognitive load.
mental models, taking place in the privacy of individual               Although there are a number of arguments that
minds, are a causal prerequisite for possible fulfillment of        conclusively show that such informational economy by
these criteria, but these processes themselves are not the          itself is not constitutive of understanding,2 we agree with
facts in virtue of which something is understood or not.            Simon (and Bechtel and Richardson) in that a property
They are not the criteria of understanding in the sense that        closely related to near-decomposability, namely modularity,
we would have to know them in order to say whether                  is a necessary condition for mechanistic explanations. In the
somebody really understands something. The correctness of           case of causal-mechanistic explanations, the explanatory
internal mental models is judged according to manifest              dependencies track the consequences of interventions
cognitive performance, not the other way round (Ylikoski &          (Woodward 2003; see fig. 1) and causal knowledge thus
Kuorikoski 2010).                                                   enables the goal-directed manipulation of the object of
  We take the principal criterion of understanding to be            explanation. These answers are the basis of the inferential
inferential performance: whether someone understands a              performance constitutive of causal understanding.
phenomenon is assessed based on whether he or she can
make correct inferences related to it. Thus our view of
understanding can be linked to Woodward’s (2003) widely
accepted account of scientific explanation, which tells us
more specifically what kinds of inferences are constitutive
of specifically explanatory understanding (see also Craver
2007). Explanation consists in exhibiting functional
dependency relations between variables. This is the
connection between explanation and understanding:
knowledge       of   explanatory     relationships     grounds
understanding by implying answers to what-if-things-had-
been-different questions concerning the consequences of
                                                                          Figure 1. Invariance under exogenous interventions
counterfactual or hypothetical changes in the values of the
                                                                         distinguishes “deep”, causal, dependencies from mere
explanans variable. This is the important difference between
                                                                      correlations. P(Y|Z = z) is not the same as P(Y|set(Z = z)).
explanatory information and purely descriptive information.
Whether someone understands a phenomenon is evaluated
                                                                    Such answers to what-if questions are derived from internal
according to whether he or she can make inferences not only
                                                                    or external representations of the object of understanding. In
about its actual state, but also about possible states of the
                                                                    order for these answers to be well defined, the dependencies
phenomenon or system in question.
                                                                    grounding the answers have to possess some degree of
                                                                    independence such that a local change in an aspect of the
           Modularity and Understanding                             phenomenon under study cannot ramify uncontrollably or
According to Bechtel and Richardson, decomposability is a           intractably. If local modifications in a part of a system
regulative ideal in mechanistic model construction because          disrupt other parts (dependencies) in a way that is not
complex systems are psychologically unmanageable for                explicitly specified (endogenized) in the (internal or
humans. Decomposition allows the explanatory task to be             external) representation of the system according to which
divided into parts that are manageable for cognitively              the what-if inferences are made, the consequences of these
limited beings, thereby rendering the system intelligible           changes are impossible to predict and counterfactual
(Bechtel & Richardson 2010). The idea comes originally              assertions impossible to evaluate (Woodward 2003, 333).
from Simon (1962), who claimed that complex systems
have to be nearly-decomposable in order to be                          2
                                                                         See, e.g.,Woodward 2003, 362–364.
                                                                841

Therefore, a necessary condition for a representation to           design-by-selection can lead to such non-modular complex
provide explanations, and thus understanding, of a                 behavior.
phenomenon is that the modularity in the representation
matches the modularity in the phenomenon.                                             Genetic Algorithms
   If we intervene on a causal input corresponding to
                                                                   From the point of view of AI, genetic algorithms
variable Xi in a model of the studied system, and the
                                                                   (henceforth GAs) are a form of non-exhaustive but
intervention, no matter how surgical, also changes the
                                                                   massively parallel search in the search space of a problem
dependencies within the system, or values of other variables
                                                                   (Holland 1975; Mitchell 1996). Although GAs are not the
themselves affecting variables causally downstream of Xi,
                                                                   only strand of evolutionary programming, they serve our
the model does not give correct predictions about the
                                                                   purpose well because their basic principles are easy to
consequences of the intervention. Hence, the model does not
                                                                   understand and they are the most well-known kind of
provide correct causal understanding of the system and the
                                                                   evolutionary programming outside computer science (Clark
causal role of the variable in it. If the system cannot be
                                                                   1997, 2001; Mitchell 2009). GAs are useful for a number of
correctly modeled on any level of description or
                                                                   different purposes, but here we use a simple example
decomposition so that it is modular in the way described
                                                                   originally from Mitchell (2009, Ch. 9), where a GA is used
above – if the system itself is not causally modular – no
                                                                   to evolve a behavioral strategy for a simulated agent.
what-if-things-had-been-different questions concerning
                                                                      Mitchell’s model shows how an algorithm mimicking
interventions in the system can be answered. This would
                                                                   biological evolution can be used to develop a controlling
mean that every local change brings about intractable
                                                                   program for a robot picking up soda cans on a 10x10 grid.
changes elsewhere in the system to such an extent that there
                                                                   Robby the robot can only see the squares adjacent to its
can be no representation that would enable a cognitively
                                                                   location (center, North, South, East, West), and each turn it
finite being to track these changes and make correct
                                                                   can either move one step to a particular direction, move at
inferences about their consequences.
                                                                   random, try to pick up a can, or do nothing. Each simulation
   The problem of understanding causally non-modular
                                                                   run lasts for a predetermined amount of time steps
systems has received some attention in the philosophy of
                                                                   (originally 200), and Robby's task is to pick up as many
science literature (e.g., Bechtel and Richardson 2010, Ch.
                                                                   randomly situated cans as possible.
9). However, according to the DL schema, before we can
even start thinking about searching for the causal-
mechanistic implementation of the complex system
behavior, we need to formulate hypotheses about the
possible functional decompositions of the behavior (see also
Cummins 1983). For example, what kind of simpler
subtasks could possibly produce complex cognitive
capacities such as language production and comprehension,
long-term memory, and visual object-recognition?                    Figure 2. Each “locus” in the genome G corresponds to one
Importantly, this task is separate, though not independent,          of the possible immediate environmental states of Robby,
from hypotheses concerning the implementation of the                 and each digit (the allele) to a move in that situation (e.g.,
capacity. Although the understanding offered by the                  ‘0’  ‘move north’, ‘5’  ‘pick up’) (see Mitchell 2009,
functional decomposition is not, strictly speaking, causal –                                     137).
component operations do not cause the whole behavior
because they are constitutive parts of it – the modularity         Initially a random population of software individuals is
constraint on understandability still applies in the following     generated, each with a “genome” consisting of 243 random
way. We can only understand the complex behavior by                numbers. Each locus in the genome guides Robby’s
having knowledge of its component operations, if we can            behavior in a particular situation (Fig 2). The fitness score
make reliable what-if inferences concerning the possible           of each candidate in the population is calculated by running
consequences of changes in the component operations for            several simulation trials: crudely, the more cans the robot is
the properties of the more complex explanandum capacity.           able to pick up on average, the higher its fitness. Programs
For example, we provisionally understand working memory            with the highest fitness are then used to form the next
if we can infer from possible changes in its hypothesized          generation: they are paired randomly, and the genomes of
component operations (such as differences in the properties        the two parents are crossed over at a randomly chosen point
of the postulated phonological loop or episodic buffer) to         to create the genomes of new individuals. Finally, for each
changes in the properties of the capacity. These inferences        locus of a descendant’s genome, there is a small probability
are only possible if the functional decomposition itself is        (.005) that a mutation occurs in it. As a result, the new
suitably modular, i.e., the consequences of “local“ changes        generation is based on the most successful variants among
in component operations do not ramify in an intractable            the previous generation, and the process loops back to the
way, making the behavior of the whole completely holistic.         fitness-calculation phase. Thus the GA continues searching
We now argue that genetic algorithms demonstrate that
                                                               842

for efficient solutions by charting new regions of the search          We suggest that these difficulties in understanding are
space.                                                              often created by the lack of modularity in the functional
   After a few hundred generations, the evolved strategies          decomposition of the behavior. The high-fitness Robby
start to achieve impressive results. As we replicated               (genome G in Fig. 1) mentioned in the paragraph above only
Mitchell’s simulation, we observed that after the 800th             leaves cans as markers in some specific situations, and only
generation, the best strategies among evolved Robbys                the totality of this selective marking strategy – together with
started to have higher fitness scores than a Robby                  navigational strategies utilizing cans and walls – constitutes
programmed by a human designer (ultimately 480 vs. 440              the effectiveness of the can-search procedure. Looking at
points).3 However, although solutions found with GAs are            isolated genes in Robby’s genome only reveals trivially
efficient, their behavior is often hard to understand. The          modular elements corresponding to elementary subtasks in
ingenious behavioral strategies that the programs employ            its behavior: one gene corresponds to an elementary move in
cannot be deciphered by simply looking at individual genes          a specific environmental situation. But we cannot make
or sets of genes. Instead, it is necessary to look holistically     inferences from local hypothetical changes in these
at the broad phenotypic behavior of the robot. A nice               elemental behaviors to consequent effects on fitness. The
illustration of this impenetrability of such evolved solutions      connection between any single elementary behavioral rule
is the fact that in some cases when a high-fitness Robby is         and the strategy is simply too complex and context
in the same square with a can, it decides not to pick it up,        dependent. A change in a single rule (in situation B; a can
but rather moves away from the square. While this behavior          present; whether to pick up or not to pick up the can) has
seems prima facie irrational, looking at the total behavioral       consequences for the effectiveness of the other elementary
profile of the robot uncovers a clever strategy: Robby uses         behavioral rules. Explanatorily relevant inferences would
cans as markers to remember that there are other cans on its        require an extra “level” of modular sub-operations between
side, and it explores the adjacent squares for extra cans           the individual movements and the strategy as a whole.
before picking up the marker can. Thus by not treating cans            The marker and vacuum-cleaner strategies mentioned
only as targets but also as navigational tools, Robby uses its      above appear to be examples of such middle-level sub-
environment to extend its severely limited visual capacities        operations, but by themselves they are insufficient to yield
and to compensate for its total lack of memory.                     understanding of the whole behavior of our most successful
   Moreover, by examining the behavior of a highly efficient        Robby. This is because the effectiveness of leaving a can is
1500th generation Robby, it can be seen that this marker            a result of the evolved coupling between the specific
strategy manifests in slightly different ways in different          situations in which Robby leaves a can and the rest of the
environmental situations. It is not a discrete adaptation, but      navigation behavior. Therefore, there is no way of
rather a collection of independently evolved sub-strategies.        independently altering these middle-level strategies. Also
Furthermore, the marker strategy is tightly intertwined with        “the bounce” is intertwined with the rest of the vacuuming
another      environment-employing        “hack”    that    the     navigation and cannot be independently altered. In general,
sophisticated Robby uses: when there is already a lot of            genetic algorithms do not often produce easily discernible
empty space on the grid, Robby employs a “vacuum-                   designs. Rather, the interesting heuristics in the system’s
cleaner” movement strategy. It follows the walls of the             behavior can only be revealed by simultaneously looking at
board, departing toward the center when it detects a can,           constellations of different genes, and eventually, the whole
employs the marker strategy if possible, and immediately            genome.
after cleaning up its local environment, returns directly to           To recapitulate, our example exhibits several distinct (yet
the south wall to continue its round around the board. This         related) challenges to understanding:
strategy also includes an ingenious “bounce” feature: when             (1) The discernible middle-level strategies (marker,
Robby arrives to the corner preceding the wall that is              vacuum-cleaner) do not have dedicated structural bases.
parallel to its default navigation direction in an empty field,     Instead, the nature of the design process leaves all atomic
it bounces off the wall to increase the range of this search        structural elements (the 243 DNA elements) open for
pattern.                                                            exploitation by all capacities serving the main goal.
   Such “kluges” are common to designs created by GAs.              Consequentially, the system is neither structurally nor
Like biological evolution, GAs can come up with solutions           behaviorally nearly-decomposable, but instead has a “flat
that a human designer would not think of. These solutions           hierarchy,” and strategies are implemented in highly
often offload parts of problem solving to the environment,          distributed structures.
and thus rely on a tight coupling between the system and its           (2) Challenge 1 above means that the interactions between
environment. And, as pointed out by Clark (1997, 2001),             subtasks tend to be strong: a change in one subtask
recurrent circuitry and complex feedback loops between              constituting a part of the marker-behavior also affects the
different levels of processing often feature in systems             functioning of the vacuum-cleaner navigation. In general,
designed by GAs. Such designs are often difficult to                the middle-level strategies can only be discerned and
understand.                                                         defined in a very abstract way, and the interaction-effect on
                                                                    their contribution to the overall fitness is so large as to make
   3
     Code obtainable on request.
                                                                843

any inferences about the consequences of partial changes in        employing a limited set of instrumentally interpreted macro-
one strategy next to impossible.                                   variables?
   (3) The way in which the strategies contribute to the              There are important disanalogies between GAs and
fitness of the individual is highly context-dependent and          biological evolution. As is the case with Robby, there is
depends on the properties of the environment as well as the        often no genotype–phenotype distinction. In biological
DNA of the agent. Even small modifications to the                  evolution, however, genes do not directly cause properties
environment can lead to drastic changes in the performance         of the phenotype, but rather participate in guiding
of a strategy. For instance, we observed that adding only a        ontogenesis. It has been suggested that ontogenesis itself
few randomly placed extra walls on the grid radically              favors modular design. GAs may also seem a problematic
collapses the average score of the successful Robby                platform for exploring the possibilities of DL heuristics,
described above.                                                   since the lowest level of functional organization and the
                                                                   level of implementation are identical (i.e., the genome).
Extrapolating from this very simple case, we contend that          However, we see no reasons why this would affect our
GAs may design behavior that cannot be tidily decomposed           argument. Moreover, the argument developed here is not
into hierarchical and modular subtasks, whose individual           only about genetic selection, but about selection in general,
contributions would be easy to understand (i.e., we could          and failures of functional modularity may in principle also
infer how a change in a sub-routine would affect the               arise in the course of development – at least if the idea of
behavior of the mother-task). Instead, feedback, many tasks        neuronal group selection or “neural Darwinism” is taken
using the same subtasks as resources, and tight system-            seriously.
environment coupling lead to holistic design where almost             The recent research on biological control networks
“everything is relevant for everything.” The evolved               (metabolic and gene regulatory networks) suggests that
functional architecture is flat in that there are few              evolved modular organization is in fact the rule rather than
discernible levels of order between the elementary                 the exception: control networks exhibit network modularity
operations and the complex behavior. The counter-                  and the recurring modules (motifs) have easily discernible
intuitiveness of such flat architectures is apparent in the        modular functions. Therefore, the question in the recent
deep mistrust faced by connectionist suggestions for non-          years has rather been to formulate an evolutionary
hierarchical design of cognitive capacities (see e.g.,             explanation for this modular design. Genetic algorithms
Rumelhart and McClelland 1986 vs. Pinker and Prince                have been used to argue that modularity is not selected for,
1988).                                                             but that it is instead a byproduct of specialization of gene
   Furthermore, GAs underscore the path dependence of              activity (Espinasa-Soto & Wagner 2010) or of selection
evolutionary problem solving. For sufficiently complex             against densely connected networks and long connections
computational problems there are often several local               (Clune, Mouret & Lipson 2013).
maxima in the fitness landscape of the problem, and the               Most interesting for our case, Kashtan and Alon (2005;
population can converge to different maxima in different           see also Kashtan et al. 2007) have demonstrated that when
runs of the simulation. The functional decomposition that a        the goals themselves are composed of modularly varying
human designer comes up with is just one possible solution         sub-goals, evolution tends to produce modular functionality.
among several others. Perhaps our biological evolution             It seems easy to see why this is the case. If the tasks to
actually ended up with a radically different one.                  which the system has to adapt remain the same, the selection
                                                                   environment does not change, and the peaks in the fitness
            Lessons for the Study of Mind                          landscape are stable, then selection favors strategies that
                                                                   offload problem solving to that particular environment as
Genetic algorithms demonstrate that evolution can, in
                                                                   much as possible. But if the task itself is composed of
principle, lead to non-modular functionality. This imposes a
                                                                   changing subtasks, it makes sense to design the adaptive
limit on our ability to understand such behavior: if we
                                                                   response in such a way that a particular sub-operation can
cannot trace the consequences of changes in the sub-
                                                                   locally adapt to a local change in a subtask without altering
operations, we cannot answer what-if questions concerning
                                                                   the totality of the otherwise well-functioning behavior.
the complex behavior. Such behavior constitutes a thorny
                                                                      In their research, Kashtan and Alon evolved several
problem for mechanistic understanding of the
                                                                   network models to compute complex Boolean functions,
implementation of the said behavioral capacities, since the
                                                                   with fitness calculated according to how close the network
DL heuristic cannot get off the ground: we do not even
                                                                   output was to the target. They found that by modularly
know what we are supposed to localize. We can now ask
                                                                   varying goals, it is often possible to considerably speed up
two questions: should we expect to find such non-modular
                                                                   the evolution. In our Robby simulation, we studied the
functionality in nature, especially in human cognition, and if
                                                                   effects of changing environment for the evolution of
so, what attitude should we adopt with respect to this
                                                                   modularity by allowing the environment to change
problem. Should the aim of causal-mechanistic
                                                                   discretely from an initial no-walls (torus) condition to one
understanding of the brain be given up, and be replaced, for
                                                                   with walls, and eventually to one with also random
example, with non-mechanistic dynamical models often
                                                                   obstacles. Our results suggest that although “modularity in
                                                               844

tasks” does speed up learning, it can often prematurely weed         Clune, J., Mouret, J-B., & Lipson, H. (2013). The
out diversity in the population in such a way that, in the end,        evolutionary origins of modularity. Proceedings of the
the global maximum for the main target task cannot be                  Royal Society B, 280.
reached.                                                             Clark, A. (1997). Being There: Putting Brain, Body and
   It seems likely that our cognition has evolved in at least          World Together Again. Cambridge MA: The MIT Press.
partly modularly changing selection environment, but the             Clark, A. (2001). Mindware: An Introduction to the
extent to which we should expect to find modular                       Philosophy of Cognitive Science. Oxford: Oxford UP.
functionality in human cognition is hard to estimate. We             Cummins, R. (1983). The Nature of Psychological
suspect that the usefulness of many of the existing                    Explanation. Cambridge MA: MIT Press.
computational models investigating the evolution of                  Espinosa-Soto C, Wagner A. (2010). Specialization Can
biological modularity is constrained by the fact that the              Drive the Evolution of Modularity. PLoS Computational
tasks (e.g. simple categorization, logic circuits) solved by           Biology, 6(3).
the algorithms are straightforwardly computational and do            Holland, J. (1975). Adaptation in Natural and Artificial
not really involve any interesting behavioral aspects. This is         Systems. Ann Arbor: University of Michigan Press.
why the Robby platform has certain advantages for                    Jacob, F. (1977). Evolution and Tinkering. Science 196
exploring evolved functionality: The dynamic nature of the             (4295): 1161–1166.
simulation allows the “emergence” of novel and irreducibly           Kashtan, N., & Alon, U. (2005). Spontaneous evolution of
top-level strategies in a way that is lacking in the more static       modularity and network motifs. PNAS 102 (39): 13773–
contexts.                                                              13778.
                                                                     Kashtan, N., Noor, E. & Alon, U. (2007). Varying
Because of the uncertainty related to the actual extent of             environments can speed up evolution. PNAS 104 (34):
non-modularity in human cognition, we stress the                       13711–13716.
conditional nature of our argument. Our study of genetic             Levins, R. (1973). The Limits of Complexity. in Pattee, H.
algorithms and our analysis of the properties of the resulting         (Ed.), Hierarchy Theory: The Challenge of Complex
designs only demonstrates that evolution can create designs,           Systems. London: Braziller.
which are in principle beyond the understanding of unaided           Marcus, G. (2008). Kluge: The Haphazard Construction of
cognitive beings such as us.                                           the Human Mind. Boston and New York: Houghton
   Yet there is nothing mysterious in such designs. Simon              Mifflin.
pondered whether the apparent abundance of hierarchical,             Mitchell, M. (1996). An Introduction to Genetic Algorithms.
nearly decomposable complexity was due to our selective                Cambridge MA: MIT Press.
attention to precisely such systems, but we believe this to be       Mitchell, M. (2009). Complexity. A guided tour. Oxford:
a somewhat hasty conjecture. We have no trouble finding                Oxford University Press.
and delineating systems, such as Robby, or possibly                  Piccinini, G., & Craver, C. (2011). Integrating Psychology
ourselves, that manifest functionally non-decomposable                 and Neuroscience: Functional Analyses as Mechanism
behaviors sustained by a flat architecture. However, there             Sketches. Synthese 183 (3): 283–311.
certainly might be a psychological bias that makes us see            Pinker, S., & Prince, A. (1988). On Language and
hierarchical design also where there is none. One way of               Connectionism: Analysis of a Parallel Distributed
coping with this obstacle to understanding is to realize that          Processing Model of Language Acquisition. Cognition
there are no fundamental reasons to limit the relevant                 23: 73–193.
epistemic agent to be an unaided human. Although only a              Rumelhart, D., & McClelland, J. (1986). On Learning the
human agent can experience a sense of understanding, this              Past Tenses of English Verbs. In McClelland &
feeling should not be confused with understanding itself.              Rumelhart et al. (Eds.), Parallel Distributed Processing
Therefore brute computational approaches can produce                   vol. I. Cambridge MA: MIT Press.
understanding as long as the epistemic subject, the cognitive        Simon, H. (1962). The Architecture of Complexity.
unit whose inferential abilities are to be evaluated, is               Proceedings of the American Philosophical Society 106:
conceived as the human-computer pair.                                  476–482.
                                                                     Thagard, P. (2012). The Cognitive Science of Science.
                         References                                    Cambridge MA: MIT Press.
                                                                     Waskan, J. (2006). Models and cognition: Prediction and
Bechtel, W., & Richardson, R. (2010). Discovering
                                                                       explanation in everyday life and in science. Cambridge,
   Complexity: Decomposition and Localization as
                                                                       MA: The MIT Press.
   Strategies in Scientific Research. Cambridge MA: The
                                                                     Wimsatt, W. (2007). Re-Engineering Philosophy for
   MIT Press.
                                                                       Limited Beings. Cambridge MA: Harvard UP.
Churchland, P. M. (1989). A Neurocomputational
                                                                     Woodward, J. 2003. Making Things Happen. Oxford UP.
   Perspective: The Nature of Mind and the Structure of
   Science. Cambridge, MA: MIT Press.                                Ylikoski, P., & Kuorikoski, J. (2010). Dissecting
                                                                       Explanatory Power. Philosophical Studies 148, 201–219.
                                                                 845

