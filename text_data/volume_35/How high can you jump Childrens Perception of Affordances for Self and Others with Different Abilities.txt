UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How high can you jump? Children's Perception of Affordances for Self and Others with
Different Abilities

Permalink
https://escholarship.org/uc/item/8x1107n8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Fine, Justin
Kloos, Heidi
Jenkins, Mona

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

How high can you jump?
Children’s Perception of Affordances for Self and Others with Different Abilities
Justin M. Fine (jmfine@asu.edu)
Department of Psychology, Arizona State University
Tempe, AZ 85287 USA

Heidi Kloos (heidi.kloos@uc.edu)
Department of Psychology, University of Cincinnati
Cincinnati, OH 45221 USA

Mona M. Jenkins (jenkinmo@mail.uc.edu)
Department of Psychology, University of Cincinnati
Cincinnati, OH 45221 USA

environment. The embodied approach claims that individuals
neurally simulate (Grush, 2004) how they or another might
accomplish an action. Both theories’ ability to explain social
perception in a jumping estimation task was tested in the
current study.

Abstract
The current study investigated whether children and adults can
distinguish between actions they are afforded and those
afforded to an actor. Participants judged the maximum height
they could reach while jumping and they judged the maximum
height that the actor could reach while jumping. They did so
with and without a weighted backpack, and they did so with
and without walking several laps. Results show that before the
addition of the weighted backpack, participants rated the
actor’s abilities as much closer to their own. While wearing
the weighted backpack and then walking with it, participants’
estimates decreased for themselves, but remained mostly
unchanged for the adult.
Keywords: social perception; affordances;
embodiment; ecological psychology; development

Affordances as the Object of Perception

agency;

Introduction
For individuals to successfully navigate their environment,
they must be able to perceive when different actions are
possible. How does an individual know whether they can
reach a jar from a shelf, step over a barrier, or navigate
through traffic without incident? The ability to perceive
potential actions is not limited to the individual’s actions.
Daily activities are filled with social interactions, such as
conversational turn-taking (Shockley, Santana, & Fowler,
2003), helping someone lift an object (Richardson, Marsh, &
Baron, 2007), or detecting whether two people can fit through
a doorway (Davis, Riley, Shockley, Cummins-Sebree, 2010).
Because people can readily interact and coordinate with other
individuals, this suggests that individuals can perceive the
actions afforded others and groups of people working
together.
In the case of social interaction however, the perceiver
doesn’t necessarily have a priori information about another
person’s action capabilities. Two approaches to this
problem—the ecological and embodiment perspective—
contend that minimally, perception serves the purpose of
guiding action. The ecological approach focuses on the
physical and spatial relationship of an observer to the

Several researchers studying how individuals perceive
possibilities for action in their environment have narrowed in
on Gibson’s (1979) concept of affordances. An affordance is
meant to capture the relationship of an individual’s
morphology and action capabilities to the spatial layout of the
environment and objects. For an individual to detect an
affordance is to perceive an opportunity for action.
Affordance detection is seen in behaviors such as stair
climbing (Warren, 1984) or chair sitting (Mark, 1987).
Warren (1984) found that individuals selection of the tallest
climbable stair is best described by a nearly, invariant ratio of
leg-length to stair-riser height. Rather than focusing solely
on riser height information, estimates are predicted by a ratio
that exists only as a function of perceiver and stair.
Individual’s daily routine rarely consist of just solo actions.
For example, soccer players must decide whether their
teammates are in the correct position to receive a pass. The
natural tendency towards such social coordination suggests
individuals readily detect what actions other people are
afforded; people can accurately report what objects others
can reach (Rochat, 1995), lift and move together (Richardson,
Marsh, & Baron, 2007), what chairs another person can sit on
(Stoffregen, Gorday, Sheng, & Flynn, 1999), and how high
another person can jump and reach (Ramenzoni, Riley,
Shockley, & Davis, 2008a). This detection ability suggests
information is readily available regarding the perceived
person and their environment. Stoffregen et al. (1999) found
that observers use affordance based information to detect the
possible sitting height for other individuals. They asked
individuals to watch a video of an actor standing next to a
chair and estimate the maximal and preferred sitting height
for the actor. As long as the spatial relationship between the

2285

actor and apparatus was preserved, participants could
accurately estimate the heights. Estimates were also accurate
when participants only saw a kinematic display. The
estimates were found to be most accurate when they were
scaled by the leg length of the actor in the video, not the
participant.
In this case, the estimates are based on scaling the physical
morphology of the person to the spatial layout. Studies have
also shown that people can perceive the capabilities for others
to produce actions that are scaled by biomechanical
properties such as jumping to reach an object (Ramenzoni et
al., 2008a). In this case, it is less clear what information an
observer might use to form a perception about another
person’s ability.

Simulations and the Embodied Perceiver
An alternative perspective on social perception and action
rests on neurologically driven mechanisms as a basis for
behavior. This approach has been brought under the banner
of the Common Coding (Prinz, 1997) or Embodied
Simulation (Grush, 2004) approach. This approach suggests
that social behaviors are explainable by a proposed overlap
in how individuals represent perceived and performed
actions. In other words, if a person watches an action being
performed or plans to produce an action, they simulate the
motor program and sensory consequences underlying that
action. Simulation behavior is akin to covert imitation
behavior (Wilson & Knoblich, 2005).
The mirror neuron system is thought to underlie such
perception and action overlap (Rizzolatti & Craighero, 2004).
The finding that mirror neurons, found in the F5 area of a
Macaque monkey’s premotor cortex, activate similarly to the
viewing and production of an action (e.g., reaching for a
glass), provide a mechanism for simulations. The perception
of action possibilities in the embodied stance, thus, relies on
neural based representations of the observer in the
environment.
Behavioral support is found in stimulus-response
incompatibility studies and action perception studies. For
example, Brass, Bekkering, Wohlschlager, & Prinz (2000)
showed that finger movement reaction times are slower after
watching a video of a hand performing the opposite of the
instructed movement. They propose this is due to neural
interference. Upon seeing the stimulus cue to respond,
participants automatically simulate the action they saw; this
creates a delayed response due to the overlap between the
intended and observed action.
Researchers have suggested that such overlap between
perception and action may provide a basis for understanding
many social behaviors (Gallese, Keysers, & Rizzolatti, 2004;
Sebanz & Knoblich, 2009). Knoblich and Jordan (2002)
postulate that the mirror neuron system and embodied
simulations support the ability to predict potential actions and
their outcomes for perceivers and other people. Simulations
are derived through a perceiver detecting or representing the
actions they are afforded. These simulations are also used to
judge the action capabilities of other individuals.

Results supporting a simulation theory of social perception
have drawn on behavioral and physiological data. CalvoMerino, Glaser, Grezes, Passingham, and Haggard (2005)
found greater activity in cortical regions containing mirror
neurons when participants watched videos containing dance
movements they were trained to perform. Individuals
watching point-light displays are also more sensitive to
movements produced by themselves than the movements of
other people (Loula, Prasad, Harber, & Shiffrar, 2005). These
findings suggest that an observer’s perception of another
person’s ability is derived from the observer’s own capacity
for action.
The proposal by Knoblich and Jordan (2002), regarding
social action perception, suggests that the perceiver’s
estimation of other person’s capacity to produce actions
should be scaled to the perceiver’s ability. Interestingly,
Ramenzoni et al (2008a) found that putting weights on a
participant reduced jump and reach estimates for themselves
and an actor even though the actor was not wearing weights.
This finding suggests that people may use simulations to
estimate others, but use themselves as a frame of reference.
It is not clear however, whether such estimates are really
based on one’s own ability to act per se, or are scaled by
another relationship. Ramenzoni, Riley, Shockley, & Davis
(2008b) manipulated observer eye-height in another study as
well. They found significant changes in the participants’
estimates for themselves and the actor. These findings
suggest that eye-height scaled information and embodied
simulations both contribute to determining the ability to
judge actions for others. Simulation behavior may provide a
template for judgments while detection of eye-height or other
optically specified information is used to tune those
judgments.

Study Overview
The current study examined whether a person’s inherent and
manipulated jumping ability affect their judgments of their
own and another person’s ability equivalently. Specifically,
we tested whether individuals’ judgments are based solely on
their own ability to jump and reach an object or whether
estimates are underpinned by simulations tuned by detecting
optically specified information. In this case, the detectable
information is the eye-height difference between the
participant and another person. Thus, we predicted that an
observer’s estimation accuracy for another person should be
related to the difference in eye-height of the perceiver and
actor and the similarity of their inherent jumping abilities. If
individuals only use simulations to make judgments,
reducing observer’s abilities should significantly reduce
estimates for themselves and the actor. If estimates for the
actor remain mostly unchanged, we predict that participants
are using simulations tuned by differences in the eye-height
between participant and actor.
To test the current predictions, we asked children and
adults to estimate the maximum jumping abilities for
themselves and an actor. Past studies (Ramenzoni et al.,
2008a) have only used adult participants. This population

2286

doesn’t discriminate between groups who possess naturally
different abilities and potentially different simulation
capabilities. Both groups were used under the assumption
that children naturally have lower jumping abilities then
adults. Thus, they should have inherently different action
capabilities to simulate. Participants had never seen the actor
walk, jump, or reach for anything, removing any cues
regarding the actor’s biomechanical abilities, which has been
shown to improve individual’s judgments of other’s
(Ramenzoni, Riley, Davis, Shockley, & Armstrong, 2008c).
We manipulated participant’s perception of their own
jumping abilities and potentially the actors jumping abilities
(Ramenzoni et al., 2008a) by increasing their weight. This
was accomplished by having participants wear a backpack
containing weights. Weighted estimates were provided
before and after walking with the backpack.

were allowed to have the experimenter adjust the apparatus,
if the figurine was lowered too much. Estimates were coded
using a tape measure drawn onto the wall. The figurine was
then lifted to the top of the wall and a new trial started.
Participants closed their eyes between each trial, preventing
the usage of any spatial cues provided by resetting the
apparatus. When estimates were made for the participant’s
own abilities, the actor was not in the room. When estimates
were made for the actor, the actor stood next to the apparatus.
A trial started by giving a verbal “go” signal, upon which the
participant opened her/his eyes and the figurine was lowered.

Methods
Participants
Participants were 15 children between 4.5 and 5 years old (M
=4.9, SD = 0.32) and 15 adults between 18 and 24 years old
(M =21, SD = 2.5). Children ranged in weight from 30 to 55
lbs (M =48.6, SD = 7.3), in height from 94 to 130 cm (M
=112, SD =9.3), and in eye-height from 85 to 123 cm (M
=104, SD = 9.6). Adults ranged in weight from 141 to 210 lbs
(M =159, SD =30.2), in height from 162 to 195 cm (M = 171,
SD = 7.7), and in eye-height from 152 to 185 cm (M =162,
SD = 8.6). The actor had a weight of 140 lbs, height of 166
cm, and eye-height of 152 cm. All participants were either
undergraduate students at the University of Cincinnati or
children of undergraduates.

Materials
To estimate jumpability, a figurine was suspended by a pulley
and rope from the ceiling (see Figure 1). It could be lowered
down a wall. Participants stood on a flat surface (100 cm x
100 cm), 7 feet from the suspended object. The actor was
positioned one foot to the left of the apparatus, facing the
participant. The room was covered in black felt, including the
background of where the figurine was suspended. Two
adjustable backpacks, one adult-sized and one child-sized,
were used to add weight to the participants. The weights used
in the bag weighed 15 g each. The amount of weight used per
person was approximately 5% of their body weight (±15g).
Participants were given help to put on the bags during the
experiment.

Procedure and Design
Participants were asked to play a guessing game. They were
instructed to accurately estimate their own and another
person’s maximum ability to jump for the figurine. Prior to a
trial, the figurine was lifted to the ceiling and then lowered
down slowly. This was accomplished by an experimenter
standing behind the wall and using the pulley system. The
instruction was to tell the experimenter to stop lowering the
figurine when it was at the reachable height. Participants

Figure 1: Experimental setup. The girl represents the
participant making a judgment about herself as well as the
actor (the boy in front of the wall). The person behind the
wall represents the experimenter lowering the figurine.
The experiment consisted of six types of trials, dependent
on whether the participant was making estimates for
themselves or the actor, and whether the participant had no
weights (no-weights trial), had weights (weights-beforewalking trial), or had walked with weights (weights-afterwalking trial). In the no-weights condition, individuals made
estimates from the designated spot. Participants were then
given a backpack to wear (pre-weighed to approximately 5%
body weight), but were not allowed to move from the spot.
After making their judgments, they were asked to walk 10
circular laps around the room. They then made the two
remaining estimates. Two estimates were made for each trial
type. The average of the two was used for the dependent
variables. After all of the judgments, participants were asked
to perform two jumps with the backpack on and two jumps
without the backpack. The average across the two jumps of
each kind was used to measure actual jumping abilities.
Because we wanted to examine the effects of going from a
non-manipulated (no-weights) to a manipulated, but
unadjusted (weights before walking), and adjusted (weights
after walking) scenario, we did not counterbalance the order
of trial type. We did however, counterbalance the order of
the Person factor (self vs. other). Combining all of the
factors, we utilized a mixed-design of Age Group (Child vs.
Adult) x Person (Self vs. Actor) x Trial Type (no-weights,
weights-before-walking, and weights-after-walking).

2287

Results
The following analyses present variables, described below, to
analyze the actual jumping abilities, the mean estimated
jumping height for the participant and actor (per trial type),
and the estimation error (calculated as actualjump-height –
estimatedjump-height). To examine whether optical information
is related to jumpability estimates, the relationship of eyeheight difference to estimation error is also considered.

actor, across each level of Condition, yielded a significant
effect for the weights before walking, F(1,28) = 5.63, p < .05,
2𝑝 = .17, and after walking condition, F(1,28) = 9.70, p < .05,
2𝑝 = .26. The mean estimates provided by both age groups
for the participant and actor are displayed in Figure 2.
Table 1. Mean jumping estimates and estimation error in cm.
All values are rounded to whole integers. Standard deviations
are in parentheses.

Actual Jumping Abilities
First, we analyzed the actual jump height for the child and
adult participants in a normal and weighted scenario. This
measure was used to determine whether the weight
manipulation actually affected jumping ability. Mean
jumping height was analyzed with a 2 (Age Group: child,
adult) x 2 (Condition: non-weighted, weighted) mixed-design
ANOVA. As expected, there was a main effect of the
between-group variable of Age Group, F(1,28) = 80.30, p <
.05, 2𝑝 = .74. Overall, there were differences in the jumping
abilities of the children (M = 160.96, SD = 23.66 cm) and
adult (M = 227.80, SD = 17.98 cm) group. The main withingroup effect of Conditions was also significant, F(1,28) =
33.10, p < .05, 2𝑝 = .54. In general, both groups exhibited
similar changes in jumping without weights (M = 195.70, SD
= 40.88 cm) and with weights (M = 191.96, SD = 39.42 cm).
The two-way interaction was not significant, suggesting both
groups were similar in changes between non-weighted and
weighted jumping ability (M = 7.2, SD = 2.34 cm). The effect
of Condition and lack of interaction reveals that the weights
reduced participant’s abilities similarly, regardless of Age
Group.

Estimated Jumping Abilities
To determine whether participants jumpability estimates for
themselves and the actor were equivalently affected by the
weight manipulation, we analyzed the participants’ mean
jumpability estimates using a 2 (Age Group: child, adult) x 2
(Estimated Person: participant, actor) x 3 (Condition: noweights, weights before walking, and weights after walking)
mixed-design ANOVA.
The analysis revealed a significant three-way interaction of
Age Group x Estimated Person x Condition, F(1.69,47.57) =
4.94, p < .05, 2𝑝 = .74. Follow-up analyses were performed
by splitting the Age Group (child and adult) factor into two
separate 2 (Estimated Person: participant, actor) x 3
(Condition: no-weights, weights before walking, and weights
after walking) repeated-measures ANOVAS. The results for
the adult group yielded a significant interaction between
Estimated Person and Condition, F(1.62,22.71) = 27.64, p <
.05, 2𝑝 = .66. Simple effects compare estimates for the
participant versus the actor at each level of Condition
revealed no significant effects. The analysis for child
participants yielded a two-way interaction between Estimated
Person and Condition, F(1.69,23.76) = 32.78, p < .05, 2𝑝 =
.70. Simple effects analyses comparing the participant and

Group
Adult

Condition
No-weights
Before walking
After walking

Child

No-weights
Before walking
After walking

Person
Self
Actor
Self
Actor
Self
Actor
Self
Actor
Self
Actor
Self
Actor

Estimate
222 (7)
219 (9)
218 (8)
218 (9)
210 (11)
216 (8)
179 (13)
185 (11)
170 (12)
187 (10)
157 (12)
188 (11)

Error
8 (13)
16 (10)
7 (14)
17 (10)
-7 (2)
19 (10)
-14 (17)
45 (11)
-11 (16)
47 (10)
-12 (7)
47 (12)

Estimation Accuracy
The accuracy of estimates were analyzed by examining the
mean estimation error (actualjump-height – estimatedjump-height)
using a 2 (Age Group: child, adult) x 2 (Estimated Person:
participant, actor) x 3 (Condition: no-weights, weights before
walking, and weights after walking) mixed-design ANOVA.
Analyses revealed a significant three-way interaction of Age
Group x Estimated Person x Condition, F(1.42,39.77) =
11.86, p < .05, 2𝑝 = .29.
Follow-up analyses were performed by splitting the age
groups into two separate 2 (Estimated Person: participant,
actor) x 3 (Condition: no-weights, weights before walking,
and weights after walking) repeated-measures ANOVAs.
The two-way interaction was significant in the adult group,
F(1.28,18.03) = 23.25, p < .05, 2𝑝 = .62. Simple effects were
used to compare estimation error for the participant versus
the actor at each level of Condition. Results yielded a
significant difference in the weights before walking
condition, F(1,28) = 4.60, p < .05, 2𝑝 = .31, and in the weights
after walking condition, F(1.28,18.03) = 108.79, p < .05, 2𝑝 =
.62. Analyses for the child age group were analyzed similarly.
In this case, only the main effect of Estimated Person was
significant, F(1,14) = 150.77, p < .05, 2𝑝 = .92.

Accuracy and Eye-Height Scaling
Lastly, we examined whether a relationship between the
perceiver’s and actor’s eye-height explains the accuracy of
estimates made for the actor. The focus on actor estimates
was chosen because participants provided a consistent level

2288

of accuracy for themselves, but varied in their accuracy for
the actor.

80
No Weights
Weights Before Walking
Weights After Walking

Estimation Accuracy (cm)

60

40

20

0

-20

-40

-60
-40

-20

0

20

40

60

80

Eye-Height Difference (cm)

Figure 3: Scatterplot showing the relationship of the
participant’s estimation accuracy for the actor with the
difference in eye-height.

Figure 2: Mean jumping estimates by condition, for the
participant and the actor. Estimates for the adult (panel A)
and child participants (panel B) are shown separately.
Analyses were accomplished using a linear regression to
predict the mean estimation error for the actor from the
difference in eye-height between participant and actor (eyeheightparticipant - eye-heightactor). Separate regressions were
used for each condition (no-weights, weights before walking,
and weights after walking). For simplicity, analyses were not
split between age group.
The results showed that eye-height difference accounted
for a substantial amount of the variance in the no-weights (R2
=.70, F(1,28) = 63.83, p < .05), weights before walking, (R2
=.73, F(1,28) = 76.75, p < .05), and in the weights after
walking condition (R2 =.65, F(1,28)= 52.72, p < .05). The
results for the three separate analyses are displayed in Table
2, and the data is in Figure 3.
Table 2: Results of regression analyses of estimation error for
the actor predicted by the eye-height difference between actor
and participant.
Variable
No-weights
Before walking
After walking

β
.834
.856
.808

SE(β)
.104
.098
.111

t
7.98
8.76
7.26

Sig. (p)
P < .01
P < .01
P < .01

Discussion
The present study examined what information observer’s use
when estimating another person’s ability to jump for an
object.

Like previous findings (Ramenzoni et al., 2008a and 2008b),
we anticipated individuals could detect the actor’s ability
with some accuracy. Some studies (Ramenzoni et al., 2008a)
have shown that changing the participant’s ability to jump by
adding weights alters a perceiver’s estimate of their own and
an actor’s ability, despite not changing the actor’s abilities.
This has been taken as support that an observer’s perceptual
judgment is driven by a simulation mechanism. Other studies
have shown that estimates of another person’s abilities are
better described by some physical relationship of the actor
(e.g., leg-length) to the environment (Rochat, 1995;
Stoffregen et al., 1999) or the physical relationship between
two people (Richardson et al., 2007).
Based on the current line of theorizing, we predicted that
participant estimates for themselves should decrease when
weights were initially added and more so after walking with
them on. Additionally, if participants were utilizing eyeheight information, then the estimates for the actor should not
decrease significantly. Examining the mean jumpability
estimates (Figure 2. and Table 1.), it is clear that participant’s
estimates for themselves decreased significantly in both age
groups, but didn’t decrease similarly for the actor. Only with
child participants, however, were there significant
differences between estimates for themselves and the actor
across conditions. The lack of an effect in the adult group is
similar findings of Ramenzoni et al. (2008a). The non-effect
in the adult group, though, might be due to the eye-height
similarity between the adult participants and actor. The
children, on average, had a greater eye-height difference to
the actor than the adult group.
If perceivers used eye-height information to tune
affordance judgments of jumping for the actor, then estimate
accuracy should scale with eye-height (Ramenzoni et al.,
2008b). Specifically, perceivers with the closest similarity in
eye-height to the actor should exhibit the greatest accuracy,
assuming they have similar jumping abilities. The regression

2289

analyses of eye-height difference across conditions support
this proposal. The R2 values demonstrate that a high, and
similar, amount of variance is captured by the model across
all conditions and age groups. Furthermore, the standardized
coefficients are significant and similar across all conditions
(Table 2.). Examination of Figure 3 reveals increased
accuracy for participants closest in eye-height to the actor.
The mean estimation errors (Table 1.) also show that adults
were more accurate than children. Interestingly, the scaling
relationship shows that as the participant’s eye-height
decreased away from the actor, there was an increasing
tendency to overestimate the actor; as participant eye-height
increased away, there was a tendency to underestimate.
Together, these findings suggest a potential two part process
to perceiving action capabilities for others. Observers can
estimate boundaries for another person’s abilities by
simulating a potential action. Detection of optical
information — such as eye-height difference can fine tune
these estimates.

Acknowledgments
The authors thank Anna Silverman for help with data
collection.

References
Brass, M., Bekkering, H., Wohlschläger, A., & Prinz, W.
(2000). Compatibility between observed and executed
finger movements: comparing symbolic, spatial, and
imitative cues. Brain and cognition, 44(2), 124-143.
Calvo-Merino, B., Glaser, D. E., Grèzes, J., Passingham, R.
E., & Haggard, P. (2005). Action observation and acquired
motor skills: an FMRI study with expert dancers. Cerebral
cortex, 15(8), 1243-1249.
Davis, T.J., Riley, M.A., Shockley, K., & Cummins-Sebree,
S. (2010). Perceiving affordance for joint actions.
Perception, 39(12), 1624-1644.
Gallese, V., Keysers, C., & Rizzolatti, G. (2004). A unifying
view of the basis of social cognition. Trends in Cognitive
Sciences, 8 (9), 396-403.
Gibson, J. J. (1979). The ecological approach to visual
perception. Lawrence Erlbaum.
Grush, R. (2004). The emulation theory of representation:
motor control, imagery, and perception. Behavioral and
Brain Sciences, 27, 377-442.
Knoblich, G., & Jordan, S. (2002). The mirror system and
joint action. In M. I. Stamenov & V. Gallese (Eds.), Mirror
neurons and the evolution of brain and language.
Amsterdam: John Benjamins.
Loula, F., Prasad, S., Harber, K., & Shiffrar, M. (2005).
Recognizing people from their movement. Journal of
Experimental Psychology: Human Perception and
Performance, 31 (1), 210.
Mark, L. S. (1987). Eye height-scaled information about
affordances: A study of sitting and stair climbing. Journal
of Experimental Psychology: Human Perception and
Performance, 13(3), 361.

Prinz, W. (1997). Perception and action planning. European
journal of cognitive psychology, 9(2), 129-154.
Ramenzoni, V. C., Riley, M. A., Shockley, K., & Davis, T.
(2008a). Carrying the height of the world on your ankles:
Encumbering observers reduces estimates of how high an
actor can jump. The Quarterly Journal of Experimental
Psychology, 61 (10), 1487-1495.
Ramenzoni, V. C., Riley, M. A., Shockley, K., & Davis, T.
(2008b). An information-based approach to action
understanding. Cognition, 106 (2), 1059–1070.
Ramenzoni V.C., Riley M.A., Davis T., Shockley, K., &
Armstrong, R. (2008c). Tuning in to another person’s
action capabilities: perceiving maximal jumping-reach
height from walking kinematics. Journal of Experimental
Psychology: Human Perception and Performance, 34 (4),
919-928.
Richardson, M. J., Marsh, K. L., & Baron, R. M. (2007).
Judging and actualizing intrapersonal and interpersonal
affordances. Journal of Experimental Psychology: Human
Perception and Performance, 33 (4), 845-859.
Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron
system. Annu. Rev. Neurosci., 27, 169-192.
Rochat, P. (1995). Perceived reachability for self and for
others by 3-to 5-year-old children and adults. Journal of
Experimental Child Psychology, 59 (2), 317-333.
Sebanz, N. & Knoblich, G. (2009). Prediction in joint action:
What, when, and where. Topics in Cognitive Science, 1 (2),
353-367.
Shockley, K., Santana, M. V., & Fowler, C. A. (2003).
Mutual interpersonal postural constraints are involved in
cooperative conversation. Journal of Experimental
Psychology: Human Perception and Performance, 29 (2),
326–332
Stoffregen, T. A., Gorday, K. M., Sheng, Y.-Y., & Flynn, S.
B. (1999). Perceiving affordances for another person’s
actions. Journal of Experimental Psychology: Human
Perception and Performances, 25 (1), 120-136.
Warren, W. H. (1984). Perceiving affordances: Visual
guidance of stair climbing. Journal of Experimental
Psychology: Human Perception and Performance, 10 (5),
683-703.
Wilson, M., & Knoblich, G. (2005). The case for motor
involvement in perceiving conspecifics. Psychological
bulletin, 131(3), 460.

2290

