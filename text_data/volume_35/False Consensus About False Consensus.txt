UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
False Consensus About False Consensus

Permalink
https://escholarship.org/uc/item/2t1036d4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Galesci, Mirta
Olsson, Henrik
Rieskamp, Jorg

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

False Consensus About False Consensus
Mirta Galesic (galesic@mpib-berlin.mpg.de)
Center for Adaptive Behavior and Cognition, Max Planck Institute for Human Development
Lentzeallee 94, 14195 Berlin, Germany

Henrik Olsson (olsson@mpib-berlin.mpg.de)
Center for Adaptive Behavior and Cognition, Max Planck Institute for Human Development
Lentzeallee 94, 14195 Berlin, Germany

Jörg Rieskamp (joerg.rieskamp@unibas.ch)
Department of Psychology, University of Basel
Missionsstrasse 62a, 4055 Basel, Switzerland

social support. Third, people may believe that situational
factors that led them to hold a particular view will affect
others in a similar way, leading them to adopt the same view
as well. Note that this view contrasts with another popular
bias, namely the fundamental attribution error, whereby
people believe that their behavior is caused by situation but
others’ behavior is caused by dispositional factors. Fourth,
believing that others share one’s view may have a
motivational cause, such as fulfilling the need to validate
own belief and maintain self-esteem. Fifth, false consensus
is in line with a Bayesian analysis that assumes a uniform
prior distribution and one’s own view as the only evidence
(Dawes & Mulford, 1996).
It is more difficult to explain false uniqueness. Suls and
Wan (1987) extend the motivational account and propose
that false uniqueness can contribute to one’s self esteem
when the behavior or view in question is desirable, but find
inconsistent support for this view (Suls, Wan, & Sanders,
1988). Moore and Kim (2003) show that because people
rely more on information about themselves than about
others when forming judgment of prevalence of their views,
effects similar to both false consensus and false uniqueness
can occur. However, their measure of these effects is
different than that used in most other studies: they use the
difference between people’s judgments and true population
values rather than the difference between judgments of
groups of people holding different views.
Here we investigate a so far neglected possible factor that
may lead to both effects: the format of the questions used to
measure these effects. Most studies investigating false
consensus use one of two response formats. Either they ask
about both the percentages of performers and nonperformers, for example, “What % of your peers do you
estimate would carry the sandwich board around
campus?__% What % would refuse to carry it?__% (Total
should be 100%)” (Ross, Greene, & House, 1977), or they
ask only about the percentages of performers, e.g., “What
percentage of students do you think agreed to wear the
sign?” (Krueger & Clement, 1994). There are no studies,
however, that compare how different response formats
affect estimates of the false consensus effect. For example,

Abstract
Research on human reasoning is dominated by
demonstrations of the errors people make in various judgment
and decision-making tasks. The area of social cognition is not
an exception: the list of apparent errors is long and includes a
number of contradictory phenomena. Here we explore a
prominent example of the contradictory pairs of biases: false
consensus and false uniqueness. We show in an empirical
study and with simulations that the consensus in the literature
about the stability of these effects may be premature, as their
occurrence depends on the format of questions used to
measure them.
Keywords: False consensus; false uniqueness; social circle;
response formats.

Introduction
The false consensus effect (Ross, Greene, & House 1977) or
"looking glass perception" (Fields & Schuman 1976)
describes a phenomenon that people who exhibit a certain
behavior or endorse a particular view (“performers”) believe
that this behavior or view is more common overall than do
people with different behaviors or views (“nonperformers”).
For example, Democrats would judge that democratic views
are more spread in the general public than Republicans
would. This kind of result has been documented so often
that the false consensus bias has been considered an
automatic response that may be “developmental vestiges of
the infantile belief that all others are like us” (Krueger &
Clement, 1994, p.609). However, an opposite bias called
false uniqueness has also been documented (Frable, 1993;
Mullen, Dovidio, et al., 1992). People holding a particular
view sometimes tend to think that their view is less popular
than do people holding a different view.
At least five different explanations have been proposed to
explain false consensus effects (Marks & Miller, 1987).
First, people are likely to have selective exposure to similar
others, so their estimates of larger social environments are
based on biased samples. Second, their preferred view may
be more salient to them than a different view, which may
make them think that their preferred view has a stronger

472

Table 1: Characteristics used in the study, along with
percentage of people answering “yes” (performers) in
national surveys, and percentage of such people in the
present sample.

it is not known whether the effect would remain the same if
participants were asked about nonperformers rather than
performers. It is well known from survey methodology
literature that response formats can have strong effects on
answers independently of people’s true beliefs (Tourangeau,
Rips, & Rasinski, 2000). Similarly, research on subjective
probability calibration shows that people can appear
overconfident, well calibrated, or underconfident depending
on the response format used (Juslin, Wennerholm, &
Olsson, 1999). This motivates us to explore these effects in
the case of false consensus and false uniqueness effects.

Characteristic
1
2

Method

3

We asked 104 participants recruited from Mechanical Turk
(43% female, mean age 34, 44% with bachelor or higher
degree) three groups of questions about 10 characteristics,
listed in Table 1. The questions were taken from publicly
available results of large national surveys (Gallup World
Poll 2011 for characteristics 1-5, Pew Center 2011 for 610); full texts are available on request. In the present study,
participants first gave their personal answer to each of the
10 questions. In this way we classified them as either
performers or nonperformers on a particular characteristic.
Thereafter they estimated the percentage of performers
and/or nonperformers in their social circle (defined as adults
you were in personal, face-to-face contact with at least twice
this year), and in the general population of the United
States. One random half of the participants answered the
questions about their social circle first, and another half
about the population.
For each characteristic, a random third of performers and
a random third of nonperformers gave estimates of social
circle and population percentages in one of the following
response formats: 1) estimating only the percentage of
performers, 2) estimating only the percentage of
nonperformers, and 3) estimating both percentage of
performers and nonperformers. Figure 1 provides an
example of the three response formats for one of the
characteristics, and Table 2 lists all formats. Note that in
format 3 the estimates for performers and nonperformers
have to sum to 100, but there is no such check in formats 1
and 2. Estimates for social circle and for the population
were given always in the same format. The same individual
could have answered questions for different characteristics
in different formats, depending on whether he was a
performer or nonperformer himself, and to which response
format group he was randomized to.

4
5
6
7
8
9
10

No money for
food in past 12
months
Donated to
charity last
month
Experienced
theft in past 12
months
Religion is
important part
of daily life
Attended
worship in past
7 days
Belief in God
necessary to be
moral
Believes in God
Smokes tobacco
at least once/day
Military force
sometimes
necessary
Homosexuality
should not be
accepted

Population % of
performers

Sample % of
performers

19

18

57

41

12

21

64

28

47

14

53

13

70

54

15

24

77

84

36

18

Figure 1. Example of the three response formats used to
elicit estimates of performers and nonperformers in general
population.

473

Table 2: Different ways in which prevalence of performers
can be inferred, depending on the response format.
Response
format
1
2

Estimates about
prevalence of
Performers only
Nonperformers only

Estimates given
by
Performers
Performers

Abbreviation
P.P
NP.P

3

Performers and
Nonperformers

Performers

Pnp.P
NPp.P

1
2
3

Performers only
Nonperformers only
Performers and
Nonperformers

Nonperformers P.NP
Nonperformers NP.NP
Nonperformers Pnp.NP
NPp.NP

Results
How stable are false consensus effects across different
response formats? If response format does not play a role,
estimates of prevalence of performers should be the same
for all formats, consequently resulting in same direction and
size of false consensus effects. However, Figure 2 shows
that the effects vary depending on response formats used to
estimate prevalence of performers. The most extreme
example is characteristic number 1 (no money for food),
where estimates exhibit false uniqueness when performers
estimate prevalence of performers (types 11-13), but false
consensus when performers estimate prevalence of
nonperformers (types 21-23) or when they estimate
prevalence of both performers and nonperformers (types 3133). Several other characteristics show similar patterns of
both false consensus and false uniqueness effects.

False consensus and false uniqueness can be measured in
different ways. The most prevalent approach in the literature
is to calculate the difference between the prevalence of
performers as estimated by performers (P.P) and the
prevalence of performers as estimated by nonperformers
(P.NP). A positive difference P.P - P.NP is interpreted as
false consensus, and a negative difference as false
uniqueness. In our study, separate groups of both performers
and nonperformers gave estimates in 3 different formats.
This enables calculating the size of false consensus in 9
different ways, listed in Table 3.

50
40

3

Size of False Consensus

30
10

20

9
10

10
0

2
4
7
8
3
6
5
1

2
9
10
7
4
5
8
6

-10

6
9
2
10
8
7
6
9
3
4
5
1

7
2
8
4
5

6
9

1
10
3

6
10

10
1
7

6
2
9

8

2
3
4
8

2
7
7
8
5
4

6
6
9

1

2
10
7

10
7
9
2
8

1

5

9
5
4

8
5
4

3
4
5

3

3

-20

Table 3: Different ways in which false consensus effects can
be calculated, depending on the response format.
Type of false
consensus
11
12
13
21
22
23
31
32
33

1

1
3

1

-30
-40

Calculation
P.P - P.NP
P.P - (100 - NP.NP)
P.P - Pnp.NP
(100 - NP.P) - P.NP
(100 - NP.P) - (100 - NP.NP)
(100 - NP.P) - Pnp.NP
Pnp.P - P.NP
Pnp.P - (100 - NP.NP)
Pnp.P - Pnp.NP

11

12

13 21 22 23 31
Type of False Consensus

32

33

Figure 2: False consensus effects for nine different ways of
calculating false consensus (see Table 3 for details). Small
numbers denote effects for different characteristics. Full line
denotes mean of the effects. Dotted lines denotes difference
between performers and nonperformers in participants
social circles (see text).
How can these different false consensus and false
uniqueness effects for the same characteristics be explained?
We propose a simple model of how estimates of prevalence
of performers in the population are derived. The model has
two plausible assumptions. First, people derive estimates
about the general population based on the samples they have
in their immediate social environment, that is their social
circles (see Galesic, Olsson, & Rieskamp, 2012, for a social
circle model that accounts for people's estimates of
population distributions). Support for this assumption is
shown in Figure 2, where dotted line represents differences

474

of each group in the sum of both groups. If their recall of
performers and nonperformers is unaffected by other factors
(see Discussion for more comments on this possibility), then
their population estimate of performers equals the
percentage of performers in their social circle (SCP).
Note that for simplicity we do not model the fact that
reports of social circles are similarly affected by response
formats as the population estimates. However we believe
that modeling this would only make estimated parameters
larger, but would not change relative differences between
estimates in different formats.
To check whether this simple model could reproduce the
pattern of results in Figure 2, we simulated estimates of
prevalence of performers for 10 different fictitious
characteristics with social circle prevalence ranging from
1% to 91% in steps of 10 percentage points. We modeled
population estimates using the formulas above and different
values of α. For all values of α lower than 1 the pattern of
false consensus effects is very similar to the empirical
results in Figure 2. Figure 3 shows an example for α=.8.

in percentages of performers and nonperformers, calculated
by different methods, in participants’ social circles. They
parallel the population estimates (r=.89).
Second, we assume that to derive these estimates, people
attempt to recall as many individuals in their social circle
belonging to the required category (e.g. performers) as they
can. Because of time and effort limits, they are often not
able to recall all such individuals. Consequently they may
underestimate the percentage of those individuals in the
population relative to what they would report had they
recalled all such individuals in their social circle.
The model can be formalized for each response format
separately, as follows. Recall that to estimate false
consensus effects, a researcher needs estimates of
prevalence of performers. When a person is asked only
about performers in the general population (response format
1, see Table 2), his estimate of population prevalence of
performers can be modeled as:

P1  SC P   ,
where P1 is the performers’ population prevalence
estimated in response format 1, SCP is the percentage of that
person’s social circle that are performers, and α is a memory
activation level parameter ranging from 0 to 1. Note that
according to this model people are assumed to always
estimate population prevalence of performers as lower or
equal than in their social circle. When a person is asked only
about nonperformers in the general population (response
format 2), his estimate of population prevalence of
performers can be inferred from his estimate of population
prevalence of nonperformers. This can be modeled as:

40
Size of False Consensus

30

P2  100  SCNP   ,
where SCNP is the percentage of that person’s social circle
that are nonperformers, and the meanings of other symbols
are the same as above. Note that if prevalence of
nonperformers is underestimated (α<1), then the inferred
prevalence of performers in this response format will be
overestimated relative to the true percentage in the social
circle.
Finally, when a person is asked to estimate the percentage
of both performers and nonperformers (response format 3),
his estimate of population prevalence of performers can be
modeled as:

20
10
0
-10
-20
-30

11

12

13 21 22 23 31 32
Type of False Consensus

33

Figure 3: Simulated patterns of false consensus and false
uniqueness effects, for α=.8. Full line denotes results
assuming the same social circles for performers and
nonperformers. Dotted line denotes results assuming that
performers know relatively more performers than do
nonperformers.
As visible in Figure 3, the pattern of false consensus and
false uniqueness effects in this fictitious data set is very
similar to the empirical pattern shown in Figure 2. The full
line represents false consensus estimates assuming that
performers and nonperformers have the same percent of
performers in their social circles. However, in reality each
group typically knows more individuals similar to
themselves. Therefore we observe stronger false uniqueness
effects in the simulation than in the empirical data.
However, if we assume a small difference in social circles
so that nonperformers have 20 percentage points fewer
performers in their social circles than do performers, all



SCP  
  SCP ,
P3  100  





SC
SC
NP
 P

where meanings of symbols are the same as above. Because
in this response format percentages of performers and
nonperformers have to sum to 100, the denominator serves
to normalize the sum of prevalence estimates of performers
and nonperformers, which would be lower than 100 if α<1.
That is, it is assumed that people recall a subset of
performers and nonperformers from all performers and
nonperformers in memory, and then estimate the percentage

475

normative rules of reasoning. Here we show that properties
of social environments as well as of memory processes, and
their interplay with the way questions are asked, can
produce apparent false consensus and false uniqueness
effects on its own. This work does not diminish the potential
importance of other explanations of origins of these effects,
but provides a baseline for the part of these effects that are
artifacts rather than a cognitive bias.

effects shift towards stronger false consensus. This is shown
as a dotted line in Figure 3.

Discussion
The pattern of false consensus and false uniqueness
effects seems to be a product, to a large extent, of the way
questions are asked and the samples people take from their
social environments.
If both performers and nonperformers are asked about
their own groups (false consensus type 12), then false
uniqueness effects are likely to occur. This is so because
imperfect recall of nonperformers about the members of
their own group leads to inflated estimates of the prevalence
of performers. More generally, when nonperformers are
asked about their own group rather than about performers
(types 12, 22, and 32), we see a reduction of false consensus
that in some cases turns into false uniqueness.
In contrast, when nonperformers are asked about
performers (types 11, 21, and 31), the imperfect recall alone
will lead to underestimation of performers’ prevalence. If
there is no difference between social circles of performers
and nonperformers, then the false consensus effect for type
11 will be zero (see the point 11 of the full line in Figure 3).
If there is a difference, then the false consensus effect will
occur, as in the point 11 of the dotted line in Figure 3 and in
empirical results in Figure 2). In all other conditions where
nonperformers answer about performers, false consensus
effects are most likely.
The two response formats that are most often used in the
literature, where performers and nonperformers answer
about performers only (type 11) or about both performers
and nonperformers (type 33), produce very similar false
consensus effects. This may contribute to the wide-spread
consensus in the literature about the robustness of the false
consensus effect. However as our findings show, false
uniqueness and false consensus can occur for the same
characteristics, depending on how the question is asked.
Therefore false consensus may not be such a robust bias as
previously assumed.
Note that the simple model described here neglects effects
of frequency of contact on recall, and does not specify how
the percentage estimates are formed in the first place. This
model cannot explain the empirical fact that population
estimates often resemble smoothed versions of one’s social
circle (Galesic et al, 2012), that is performers report smaller
proportion of performers and larger proportion of
nonperformers in population than in their social circle. A
more elaborate model would describe how people sample
from their social circle, for example based on frequency of
contact, and how they estimate the percentage of performers
based on that sample. The final estimates are likely to be
shaped by both, effects of question format, and other
sampling and estimation processes.
A common approach to explaining apparent errors in
social judgments is to look at the human mind and search
for motivational and cognitive processes that deviate from

Acknowledgments
We thank Max Planck Institute for Human Development for
financial support for this study.

References
Dawes, R. M., & Mulford, M. (1996). The false consensus
effect and overconfidence: Flaws in judgment or flaws in
how we study judgment? Organizational Behavior and
Human Decision Processes, 65, 201–211.
Frable, D. E. S. (1993). Being and feeling unique: Statistical
deviance and psychological marginality. Journal of
Personality, 61, 85–110.
Galesic, M., Olsson, H., & Rieskamp, J. (2012). Social
sampling explains apparent biases in judgments of social
environments. Psychological Science, 23, 1515–1523.
Juslin, P., Wennerholm, P., & Olsson, H. (1999). Format
dependence in subjective probability calibration. Journal
of Experimental Psychology: Learning, Memory, and
Cognition, 25, 1038–1052.
Krueger, J., & Clement, R. W. (1994). The truly false
consensus effect: An ineradicable and egocentric bias in
social perception. Journal of Personality and Social
Psychology, 67, 596–610.
Moore, D. A., & Kim, T. G. (2003). Myopic social
prediction and the solo comparison effect. Journal of
Personality and Social Psychology, 85, 1121–1135.
Mullen, B., Dovidio, J. F., Johnson, C., & Copper, C.
(1992). In-group-out-group differences in social
projection. Journal of Experimental Social Psychology,
28, 422–440.
Ross, L., Greene, D., & House, P. (1977). The “false
consensus effect”: An egocentric bias in social perception
and attribution processes. Journal of Experimental Social
Psychology, 13, 279–301.
Suls, J., & Wan, C. K. (1987). In search of the falseuniqueness phenomenon: Fear and estimates of social
consensus. Journal of Personality and Social Psychology,
52, 211–217.
Suls, J., Wan, C. K., & Sanders, G. S. (1988). False
consensus and false uniqueness in estimating the
prevalence of health-protective behaviors. Journal of
Applied Social Psychology, 18, 66–79.
Tourangeau, R., Rips, L. J., & Rasinski, K. (2000). The
psychology of survey response. New York: Cambridge
University Press.

476

