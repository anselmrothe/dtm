UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The visual motion aftereffect from mental imagery depends on speed

Permalink
https://escholarship.org/uc/item/9dh4p8nq

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Toskos Dils, Alexia
Boroditsky, Lera

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The visual motion aftereffect from mental imagery depends on speed
Alexia Toskos Dils (atoskos@stanford.edu)
Lera Boroditsky (lera@stanford.edu)
Stanford University, Department of Psychology
Jordan Hall, 450 Serra Mall, Building 420, Stanford, CA 94305 USA
Abstract
When we imagine a train snaking through a desert, does
information about the train’s speed make it into our visual
mental image? In this paper, we make use of the motion
aftereffect illusion (MAE) to test whether the speed of
imagined visual motion modulates transfer of adaptation to
a subsequent visual motion discrimination task.
We
compared the effects of viewing slow, medium, and fast
motion on the magnitude of the MAE (Experiment 1) with
the effects of simply imagining the same motion stimuli
(Experiment 2). In Experiment 1 we found that increasing
the speed of real visual motion from slow to medium
produced a corresponding increase in the magnitude of the
MAE, but increasing speed from medium to fast did not.
Likewise, imagining slow motion produced a smaller MAE
than did imagining medium motion, but the effect leveled of
between medium and fast motion. These findings suggest
that our mental imagery of motion is specific to the speed of
the moving objects, and highlight areas of overlap between
mental imagery and visual perception.
Keywords: Mental imagery; Motion aftereffect; Embodiment

Background
When we imagine a car racing by, how visual is the process
of creating the mental image? Do the representations we
generate include information about how fast the car appears
to be going? Or are they invariant to this property of visual
motion perception? In this paper, we make use of the
motion aftereffect illusion (MAE) to test whether the speed
of imagined visual motion modulates transfer of adaptation
to a subsequent visual motion discrimination task.
Researchers have long debated just how similar imagining
a visual scene is to actually witnessing it (Kosslyn, 1981;
Pylyshyn, 1973). Previous work examining the metric
properties of imagined static scenes has found that
information about size (Kosslyn, 1975), distance (Kosslyn,
Ball, & Reiser, 1978), and structure (Kosslyn, 1973) is
indeed persevered in mental imagery.
For example,
Kosslyn et al (1978) found that the distance between objects
in a mental image is proportional to the physical distance
between their real-world counterparts. Participants in their
study memorized a fictional map containing several
landmarks, and were later asked to “scan” between pairs of
landmarks in their mental image of the map. Results
showed that the greater the distance between two landmarks
on the physical map, the longer it took people to mentally
scan between them.

Other work has shown that people are capable of mentally
performing metric transformations on images of static
objects (Finke, Pinker, & Farah, 1989; Shepard & Metzler,
1971). In a study by Shepard and Metzler (1971),
participants judged whether pairs of geometric objects were
identical to one another or mirror reversed. The authors
reasoned that if people solved this task by mentally rotating
one object until it aligned with the other, their reaction time
should depend on the physical angular disparity between
objects. Indeed, participants took longer to mentally rotate
objects that would take longer to physically rotate, and vice
versa.
The metric properties of mental imagery for dynamic
scenes have not been studied as widely as for static scenes.
One feature of visual motion that has been found to make it
into mental imagery is motion direction. Winawer, Huk, &
Boroditsky (2008) demonstrated that imagining visual
motion in a particular direction is sufficient to produce
direction-selective adaptation in the visual system (i.e.,
produce a visual motion aftereffect illusion).
After
imagining upward motion, participants were more likely to
see a subsequent dynamic stimulus as moving downward,
and vice versa. Transfer of adaptation from mental imagery
to perception suggests that a common neural mechanism
underlies both processes.
However, the degree of
adaptation from mental imagery was considerably weaker
compared to that from real visual motion perception, which
sets a limit on the overlap between these two processes.
The adaptation paradigm used by Winawer and
colleagues provides a unique testing ground for discovering
other motion properties preserved in dynamic mental
images. In this paper, we ask whether the magnitude of the
visual motion aftereffect from mental imagery depends on
the speed of imagined motion. If so, does motion speed
modulate the MAE from imagery in the same way as speed
modulates the MAE from real visual motion perception?
That is, is speed yet another feature common to both mental
imagery and perception, or is it an area in which internallygenerated motion representations abstract away from their
externally-generated counterparts?
To test these questions, we first measured the effect of
speed on the MAE from real visual motion (Experiment 1),
and compared that with the MAE from imagining the very
same motion stimuli (Experiment 2). In Experiment 1,
subjects viewed videos of moving stripes (upward or
downward) in three within-subject conditions: slow,
medium, and fast. Following each video, participants
indicated the direction in which a set of dynamic dots
appeared to move. We found that increasing the speed of

3575

visual motion from slow to medium produced a
corresponding increase in the magnitude of the MAE, but
increasing speed from medium to fast did not.
In Experiment 2, participants simply imagined the videos
from Experiment 1 prior to completing the dot
discrimination task. We found that imagining motion
produced a reliable MAE (albeit weaker than from viewing
real visual motion). We also found that viewing and
imagining motion produced the same relative pattern of
results across conditions. As in Experiment 1, imagining
slow motion produced a smaller MAE than did medium or
fast motion, but there was no difference between the
medium and fast conditions.

Experiment 1
How does motion speed modulate the magnitude of the
MAE from real visual motion?

Methods
Participants 30 Stanford undergraduate students
participated in this study in exchange for payment.
Stimuli & Procedure The task design, procedure, and
visual stimuli used were modeled on those used by Winawer
and colleagues (2008) and Dils and Boroditsky (2010). On
each trial participants judged the direction of dot motion
after viewing real visual motion. Trials were presented in 6
blocks: 3(speed: fast, medium, or slow) by 2(adaptation
direction: upward or downward).
The upward and
downward versions of each speed were presented in
succession. Block order was otherwise randomized across
participants. Participants adapted to 60 seconds of motion
in the first trial of each block. The adaptation phase of each
subsequent trial lasted 6 seconds. There were 24 total trials
per block.
Adapting stimuli. Participants watched videos of drifting
black-and-white horizontal stripes. The videos showed a
sine grating with a spatial frequency of 3.44 cycles per
degree of visual angle drifting either upward or downward.
In the medium condition, the grating drifted at 4.77 degrees
per second. The slow grating drifted at half the speed of the
medium grating (2.39 degrees per second), while the fast
grating drifted at twice the speed of the medium grating
(9.54 degrees per second). A flickering fixation cross was
superimposed at the center of each video. The cross
flickered at the same rate that the grating drifted. This
feature was included to equate stimuli between Experiments
1 and 2, and it was task-irrelevant in the current study.
Test stimuli. Following the adaptation portion of each
trial, participants judged the direction of motion coherence
in a field of moving dots, without feedback. One hundred
round dots were placed within a round aperture 10 degrees
in diameter. The dots were light gray on a dark gray
background, and each dot was 0.10 degrees in diameter.
The dots moved at 12 degrees per second within the
aperture, and any dots whose x-y coordinates exceeded the
boundary of the aperture were randomly placed within the

aperture on each frame. A light gray static fixation dot 0.15
degrees in diameter was placed at the center of each dot
display. Dot motion was always presented for 1 second, at
which point the dot display disappeared from the screen.
Participants pressed “f” if the dots appeared to move
upward, and “j” if the dots appeared to move downward.
Each dot display had net motion coherence either up or
down. For each subject, three coherence values were
sampled 24 times in each direction. The values were
tailored to each participant’s dot motion sensitivity
threshold (as assessed in a baseline task described below).
They were selected to be 12.5%, 25%, and 50% of the
coherence necessary for each individual to detect the
direction of motion in a dot display with 99% accuracy.
Coherence and direction of motion were fully crossed and
balanced across trials and participants.
Baseline Motion Sensitivity Task. During the baseline
motion sensitivity measurement, participants viewed 192
dynamic dot displays in succession and on each trial had to
indicate the direction of motion coherence, upward or
downward. Participants pressed the ‘F’ key on a keyboard
to indicate upward motion and the ‘J’ key to indicate
downward motion. The percentage of dots that moved
coherently varied from trial to trial. In the baseline task, 12
coherence values were tested (99%, 66%, 44%, 29%, 20%,
13%, 9%, 6%, 4%, 3%, 2%, 1%), and each coherence level
was sampled 8 times in each direction (upward /
downward).
A logistic function was fitted to each
participant’s data at the end of the baseline task, and the fit
was used to compute the participant’s threshold (the
percentage of dot coherence required for 75% accuracy).
The threshold was then used to compute the coherence
values to be used in the main experimental task, namely,
values corresponding to 50%, 25%, and 12.5% of the
coherence necessary for asymptotic performance. These
values were selected to be sufficiently difficult yet
discriminable for participants.
We refer to these
‘normalized coherence’ values rather than the actual
subject-specific values in all references of motion coherence
in reporting results.
Analysis. Participants who did not reach asymptotic
performance on the baseline motion sensitivity test were
excluded from all analyses (5 people). A logistic model was
fitted to each participant’s data from the main adaptation
task. The regression models used a maximum likelihood
algorithm to generate the fits and included a bias term, a
term for motion coherence of the test stimulus, and three
terms for the direction of the adapting stimulus (slow,
medium, and fast motion). We computed the shift in the
motion response functions as a function of adaptation
direction for each level of motion speed. We used this
analysis (1) to ensure that there was a reliable MAE in the
full sample, and (2) to subsequently exclude participants
who did not show an overall trend in the direction of an
MAE after viewing real visual motion (4 participants).
Since the aftereffect from real visual motion is typically
large and robust, we reasoned that participants who did not

3576

at least numerically respond in the direction of adaptation
were likely not following task instructions. Even if they
were engaged in the task, the absence of an aftereffect
would prevent us from being able to assess its dependence
on speed in those individuals.
Data from the remaining 21 participants was submitted to
a mixed-models logistic regression. The model included
fixed-effect parameters for coherence of the test stimulus,
direction of adaptation, speed of the adapting stimulus
(Helmert coded), and trial number. The model also included
terms for the interaction between adaptation direction and
motion speed, as well as adaptation direction and trial
number. This last interaction term was included to account
for longitudinal shifts in the aftereffect due to accumulation
of adaptation and fatigue. Finally, the model included
random slopes by participant for the full fixed-effects
structure.

trajectory, but the fast condition falls early in the falling
phase for most individuals.
In Experiment 2, we ask whether speed of imagined
motion modulates the MAE in the same way as does speed
of real visual motion.

Results
Figure 1 shows the raw, unfitted means across participants
for upward and downward adaptation separately (including
participants whose data was not in the direction of an
MAE). In this inclusive sample, participants showed a
164.5% shift between the motion response functions in the
direction of adaptation.
This difference was highly
significant, β=-4.63, Z=-7.37, p<0.00001.
Next we tested whether speed modulated the magnitude
of the aftereffect in people who responded in the direction
of adaptation overall.
Indeed, viewing slow motion
produced a smaller MAE than did viewing medium or fast
motion (β=-2.31, Z=-4.68, p<0.00001). This corresponded
with a 12% per deg/s increase in the probability of
experiencing an MAE on a given trial. However, the
increase in the MAE from viewing fast motion compared to
medium motion was much smaller (0.65% per deg/s), and
this shift did not reach significance (β=-0.17, Z=-0.38,
p>0.5). The predicted means from this analysis are plotted
in Figure 2.

Discussion
We asked whether the MAE from real visual motion
perception depends on motion speed. We tested for MAEs
following slow, medium, and fast visual motion, and we
found that increasing speed from slow to medium or fast
resulted in a corresponding increase in the magnitude of the
MAE. However, we found no additional boost from
increasing adaptation speed from medium to fast.
This pattern of results is consistent with previous findings
on the relationship between speed of an adapting stimulus
and the MAE (Ashida & Osaka, 1995; see Mather,
Verstraten, & Anstis, 1998 for a review). For example,
Ashida and Osaka found that the magnitude of the MAE for
a given subject increases with speed until it peaks between
5-10 degrees per second. It then begins to decrease as speed
continues to increase. The slow and medium conditions in
the present study fall squarely within the rising phase of this

Figure 1. Mean proportion UP responses after viewing real visual
motion (upper panel) and after imagining visual motion (lower
panel). Upward adaptation is plotted in red, and downward
adaptation is plotted in blue. Error bars denote ±1 s.e.m.

Experiment 2
Does speed modulate the magnitude of the MAE from
imagined motion? If so, is the pattern of results similar to
what we observed from viewing real motion?

Methods
Participants 30 Stanford undergraduate students
participated in this study in exchange for payment.
Stimuli & Procedure The stimuli and procedure for this
experiment were identical to Experiment 1, except that
participants imagined the drifting gratings during the
adaptation portion of each trial rather than viewing them.
Before each block, participants were shown upward and
downward examples of the grating videos that they would
need to imagine during the block. Participants viewed each

3577

video twice for 30 seconds before each block in which a
new motion speed was being introduced. They viewed each
video twice for 6 seconds before all other blocks. We made
sure the visual motion presented during this familiarization
phase did not interfere with our results during the main
experimental task in three ways. 1. Participants were
familiarized with both upward and downward motion,
creating no net bias in either direction. 2. The
familiarization was followed by at least 30 seconds of verbal
instructions, a longer delay than necessary for an MAE from
this duration of exposure to real visual motion stimuli to
dissipate (Hershenson, 1989). 3. The direction of motion
adaptation in the first experimental block following
familiarization was chosen randomly.
At the beginning of each trial, an upward or downward
facing arrow superimposed on a static image of the grating
indicated the direction in which participants were to imagine
the stripes moving. This cue faded over the course of a
second. Once the cue disappeared completely, a flickering
fixation cross appeared at the center of the screen.
Participants were instructed to fixate on the cross while
imagining the stripes and to use the rate of the flicker to
help them remember how fast the stripes should move.
Participants were also instructed to use the fixation cross as
a cue for when to start and stop imagining motion.
Analysis. All analyses described in Experiment 1 were
applied in the same way to the data from Experiment 2,
including limiting our main analysis to participants who
showed a motion aftereffect illusion. We know from
previous work that there is considerable variation across
individuals in the magnitude and direction of the aftereffect
from internally-generated visual motion (Dils & Boroditsky,
2010). Some individuals show a large MAE from mental
imagery, others show a small MAE, and a small number
shows priming and not adaptation. While the causes of
these individual differences are not yet known, the variation
itself is systematic. People who show an aftereffect from
mental imagery also show an aftereffect from other forms of
internally-generated visual motion such as linguistic
descriptions of motion. The predictions we drew from
Experiment 1 about how participants in Experiment 2
should behave only apply to people who showed an MAE
overall, as we did not have enough participants who showed
priming from real visual motion to create a set of
predictions for this subgroup. Further, we did not have
enough individuals who showed priming in Experiment 2 to
measure the effect of speed on priming from imagined
visual motion. Therefore, after first confirming that there
was a reliable aftereffect from visual motion imagery in the
entire sample, we limited the primary speed analysis of this
paper to those participants whose responses at least
numerically trended in the direction of a motion aftereffect.
We excluded 1 participant from all analyses for failing to
reach asymptotic performance in the baseline sensitivity
task. We excluded 5 participants from the main analysis
whose results did not trend in the direction of adaptation.
Additionally, we conducted a mixed-models analysis testing

for the presence of an interaction between experiments
(Nieuwenhuis, Birte, & Wagenmakers, 2011). This analysis
included all previously described predictors plus a term for
the concreteness of the adapting stimulus (real versus
imagined visual motion), as well as the full factorial 3-way
interaction between concreteness, adaptation direction, and
motion speed.

Results
Figure 1 shows the raw, unfitted means across participants
for upward and downward adaptation separately (including
participants whose data was not in the direction of an
MAE). In this inclusive sample, participants showed a
9.89% shift between the motion response functions in the
direction of adaptation. This difference was reliable, β=0.42, Z=-2.13, p<0.05.
Next we tested whether speed modulated the magnitude
of the aftereffect from imagined motion in people who
responded in the direction of adaptation overall. Indeed,
viewing slow motion produced a smaller MAE than did
viewing medium or fast motion (β=-0.59, Z=-2.08, p<0.05).
This corresponded with a 4.97% per deg/s increase in the
probability of experiencing an MAE on a given trial.
However, the increase in the MAE from viewing fast
motion compared to medium motion was much smaller
(0.60% per deg/s), and this shift did not reach significance
(β=-0.04, Z=-0.13, p>0.5). The predicted means from this
analysis are plotted in Figure 2.
Finally, we asked whether the magnitude of these effects
differed between real and imagined visual motion. The
overall magnitude of the motion aftereffect illusion was
greater for real visual motion than it was for imagined visual
motion (β=-3.30, Z=-8.11, p<0.00001). Also, the increase
in the MAE from slow to medium and fast motion
adaptation was significantly steeper for real visual motion
than it was for imagined motion (β=-1.74, Z=-3.46,
p<0.001).

3578

Figure 2. Model estimates of the effect of speed on the degree of
adaptation for real and imagined visual motion for average (zero)

coherence and average trial. Positive values are consistent with a
motion aftereffect illusion.

Discussion
In this study, we asked whether speed of visual motion is
preserved in mental imagery. Specifically, we tested
whether imagining slow, medium, and fast motion would
differentially affect the magnitude of the motion aftereffect
from mental imagery. We found that imagining motion
indeed made people more likely to perceive a subsequent
dynamic test stimulus as moving in the direction opposite
the adapting motion. However, this effect was not constant
across all speeds we tested. Increasing the speed of visual
motion from slow to either medium or fast produced a
corresponding increase in the magnitude of the MAE from
imagery. However, increasing the speed of visual motion
from medium to fast did not result in any additional increase
in the MAE.
We also asked whether the relative effects of speed on the
MAE from imagery would pattern like those from
perception. Indeed both viewing and imagining motion
produced a similar rise and then leveling off of the MAE as
a function of speed. However, the initial rise was reliably
steeper for real visual motion perception than for mental
imagery.

General Discussion
We started this paper by asking just how similar the
representations generated in the service of mental imagery
are to those generated during actual visual perception. We
indeed found evidence of considerable overlap. First we
replicated previous work showing that simply imagining
motion is sufficient to produce a motion aftereffect illusion.
This suggests that perception and mental imagery recruit, at
least in part, the same direction-selective neural mechanisms
in the visual system (Dils & Boroditksy, 2010; Winawer,
Huk, & Boroditsky, 2008). Further, we found that visual
motion speed modulates the MAE from both perception and
imagery. The relative shape of the effect of speed is similar
for internally- and externally-generated visual motion. This
pattern suggests that the mechanisms recruited by both
perception and mental imagery are in fact speed-specific.
However, we have also identified some key differences
between visual motion processing and mental imagery. The
effects of imagining motion on subsequent visual perception
are considerably smaller overall than those from viewing
real motion. Moreover, increasing visual motion speed
produces a disproportionately smaller increase in the MAE
from imagery relative to perception before it levels off.
These findings call for a more nuanced view of how and
when the processes that underlie mental imagery and
perception interact, and when they diverge.
This work replicates and extends previous findings on the
motion aftereffect from mental imagery (Dils & Boroditsky,
2010; Winawer et al., 2008). The present findings help to
rule out concerns that the MAE from internally-generated

motion results from a high-level cognitive bias and not from
direction-selective adaptation of visual mechanisms.
Cognitive bias should not depend on metric visual
properties such as speed. Even if there were reason to
predict such a relationship, it seems unlikely that it would
lead to the specific pattern of results we observed. After all,
we found that the very fastest imagined motion condition
did not produce the largest MAE. Conversely, the real
visual motion study provided a useful set of predictions
about how speed should modulate the MAE from imagery.
While our findings suggest that speed is a feature of realworld visual motion that is preserved in mental imagery, it
may be the case that our participants were particularly likely
to create speed-specific mental images simply because it
was one of the few differentiating features of our motion
stimuli. Had our speed manipulation been subtler, perhaps
we would not have seen it modulate the MAE from mental
imagery. Future work aims to address whether features of
visual motion such as speed, contrast, and spatial frequency
creep into mental images automatically and irrespective of
context, or whether they are represented in a more contextspecific way.
A further set of questions concerns speed represented in
linguistic descriptions of motion. If we hear about a train
racing versus crawling through the desert, do the resulting
mental images contain some of the implied speed
information? In previous work, it has been shown that
speed implied in linguistic passages can have consequences
for cognitive processing. For example, Matlock (2004)
demonstrated that people are faster to process sentences
describing fictive motion (e.g., The highway runs through
the valley) after reading a story that describes fast motion
compared to a story that describes slow motion. Future
work can examine whether differences in the speed of
implied motion described in language can also have visual
consequences (e.g., in the size of the MAE) in addition to
the speed of processing effects discovered by Matlock
(2004).

Acknowledgments
The authors would like to thank Megan D’Aguiar for
assisting with data collection for these studies. We would
also like to thank all members of the Cognation Lab. This
research was supported by an NSF BCS #1058119 to LB.

References
Ashida, H., & Osaka, N. (1995). Motion aftereffect with
flickering test stimuli depends on adapting velocity.
Vision Research, 13, 1825-1833.
Blake, R., & Hiris, E. (1993). Another means for measuring
the motion aftereffect. Vision Research, 33, 1589-1592.
Brainard, D. H. (1997) The Psychophysics Toolbox, Spatial
Vision, 10, 433-436.
Dils, A. T., & Boroditsky, L. (2010). Visual motion
aftereffect from understanding motion language.
Proceedings of the National Academy of Sciences, 107,
16396-16400.

3579

Finke, R. A., Pinker, S. & Farah, M. J. (1989).
Reinterpreting visual patterns in mental imagery.
Cognitive Science, 13, 51-78.
Hershenson, M. (1989). Duration, time constant, and decay
of the linear motion aftereffect as a function of the
inspection duration. Perception & Psychophysics, 45,
251-257.
Kosslyn S. M. (1973). Scanning visual images: Some
structural implications. Perception and Psychophysics,
14, 90-94. Kosslyn, S. M. (1981). The medium and the
message in mental imagery: A theory. Psychological
Review, 88, 46-66.
Kosslyn S. M. (1975). Information representation in visual
images. Cognitive Psychology, 7, 341-370.
Kosslyn S. M., Ball, T., & Reiser, B. (1978). Visual Images
Preserve Metric Spatial Information: Evidence from
Studies of Image Scanning. Journal of Experimental
Psychology: Human Perception and Peformance, 4(1),
47-60.
Mather, G., Verstraten, F., & Anstis, S. M. (1998). The
motion aftereffect: a modern perspective. Cambridge,
Mass.: MIT Press.
Matlock, T. (2004). Fictive motion as cognitive simulation.
Memory and Cognition, 32 (8), 1389-1400.
Nieuwenhuis, S., Birte, F. U., & Wagenmakers, E.-J.
(2011).
Erroneous analysis of interactions in
neuroscience: a problem of significance.
Nature
Neuroscience, 14, 1105-1107.
Pylyshyn, Z. W. (1973). What the mind's eye tells the
mind's brain: A critique of mental imagery. Psychological
Bulletin, 80, 1-25.
Shepard, R. N., & Metzler, J. (1971). Mental rotation of
three-dimensional objects. Science, 171, 701-703.
Winawer J, Huk A, Boroditsky L. (2008) A motion
aftereffect from viewing still photographs depicting
motion. Psychological Science, 19, 276-283.

3580

