UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Understanding eye movements in face recognition with hidden Markov model
Permalink
https://escholarship.org/uc/item/1197p8wz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Chuk, Tim
Ng, Alvin C.W.
Coviello, Emanuele
et al.
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       Understanding eye movements in face recognition with hidden Markov model
                                             Tim Chuk (u3002534@connect.hku.hk)1
                                                Alvin C. W. Ng (asangfai@gmail.com)2
                                             Emanuele Coviello (ecoviell@ucsd.edu)3
                                               Antoni B. Chan (abchan@cityu.edu.hk)2
                                                   Janet H. Hsiao (jhsiao@hku.hk)1
   1                                                                     3
     Department of Psychology, The University of Hong Kong,                Department of Electrical and Computer Engineering, Uni-
Pokfulam Road, Hong Kong                                              versity of California San Diego, La Jolla, CA, USA
   2
     Department of Computer Science, City University of Hong
Kong, Tat Chee Avenue, Kowloon, Hong Kong
                           Abstract                                   ROIs, while Henderson et al. (2005) defined the two eyes
                                                                      as one ROI. Another problem is that the predefined ROIs
   In this paper we propose a hidden Markov model (HMM)-
   based method to analyze eye movement data. We conduct-
                                                                      may not really represent the data because different indi-
   ed a simple face recognition task and recorded eye move-           viduals have different saccade patterns. More recent stud-
   ments and performance of the participants. We used a vari-         ies attempted to discover ROIs directly from data. A
   ational Bayesian framework for Gaussian mixture models             commonly adopted way was to generate statistical fixa-
   to estimate the distribution of fixation locations and mod-        tion maps. A fixation map can be created by identifying
   eled the fixation and transition data using HMMs. We               the location of fixations and convolving a Gaussian kernel
   showed that using HMMs, we can describe individuals’ eye           on each fixation. Two fixation maps can be compared by
   movement strategies with both fixation locations and tran-
   sition probabilities. By clustering these HMMs, we found           Pixel test, which discovers statistically significant differ-
   that the strategies can be categorized into two subgroups;         ences in pixels (Caldara & Miellet, 2011). Using fixation
   one was more holistic and the other was more analytical.           maps, it was found that the upper center (i.e. the nose) and
   Furthermore, we found that correct and wrong recognitions          the upper left (i.e. the left half of the nose and the left eye)
   were associated with distinctive eye movement strategies.          parts of a face were the two most frequently viewed areas
   The difference between these strategies lied in their transi-      (Hsiao & Cottrell, 2008). This result was consistent with
   tion probabilities.
                                                                      an earlier study which used the Bubbles technique in dis-
   Keywords: Hidden Markov Model (HMM); eye move-
   ment; scan path; holistic processing; face recognition.            covering regions with diagnostic features in face recogni-
                                                                      tion (Gosselin & Schyns, 2001). Fixation maps also
                         Introduction                                 showed that children from different cultural backgrounds
                                                                      demonstrated different eye fixation patterns (Kelly et al,
   In the late 19th century, soon after Edmund Huey’s in-             2011).
vention of the world’s first eye tracker, researchers dis-               The use of fixation maps in face recognition studies
covered that in many daily life activities, eye movements             had been fruitful. However, as discussed earlier, eye
were rapid, discontinuous, and interrupted by temporary               movements combine saccades and fixations. The fixations
fixations (Wade & Tatler, 2011). Nowadays, this finding               recorded in eye movement studies should be considered
has been widely accepted and described as the ‘saccade                as time-series data that are collected over time. The eyes
and fixate’ strategy (Land, 2011). Eye movements were                 fixate at a location shortly, before a saccade brings them
found to facilitate face learning and recognition. For in-            to the next location. Many studies showed that saccades
stance, Henderson et al. (2005) showed that when partici-             can be influenced by top-down expectations as well as
pants were restricted to view face images only at the cen-            bottom-up inputs. Yarbus’s (1965) well-known eye
ter of the images, their recognition performances were                movement studies showed that depending on what people
significantly lowered than when they were allowed to                  expect to see, they exhibited different saccade patterns
view the images freely. Autistic patients, who could not              when looking at the same target image. Mannan et al.
judge facial expressions correctly, were found to have                (1997) discovered that saccades were more likely to be
abnormal eye fixations patterns (Pelphrey et al, 2002).               driven to the more ‘informative’ areas of an image, such
    Empirical studies on the relationship between eye                 as the edges and the high-spatial-frequency areas. These
movement and face recognition have primarily been fo-                 findings imply that the target location of a saccade could
cusing on identifying the regions of interest (ROIs). A               be a variable that has a set of possible values; different
ROI is a region on the face which people frequently fixate            values could be associated with different probabilities. In
in, such as the two eyes. Early studies often divided a face          this sense, eye movements may be considered as a sto-
into several regions and then identified the ROI through              chastic process, which could be better understood using
comparing the frequencies of each region being fixated in.            time-series probabilistic models. The fixation maps, how-
However, this approach suffered from the lack of an obje-             ever, do not contain temporal information.
ctive manner to divide faces. For instance, Barton et al.               Currently, there are two methods for describing the tem-
(2006) defined the two eyes as two irregularly shaped                 poral information in eye movement data. One is the
                                                                      string-editing method. It requires an image to be divided
                                                                 328

into several ROIs, each labeled with a letter, so that a se-         the assumed state from the previous state. The association
quence of eye fixations can be described by a string. Two            among the observable data and the hidden states are summa-
strings are then compared by measuring their Levenshtein             rized using probability distributions; each distribution repre-
distance (Goldberg & Helfman, 2010). This method does                sents the likelihood of a hidden state generating the data.
not capture the temporal information very precisely because          The probabilities of transiting from one state to other states
the measure of Levenshtein distance does not precisely rep-          are summarized in a transition matrix; each element repre-
resent the sequential differences between two strings. For           sents the probability of that transition. An HMM also has a
instance, the strings CAT and BAT differ in their first ele-         vector of prior values; each value indicates the probability
ment, while the strings CAB and CAT differ in their last             of the HMM starting from the corresponding state.
element. In both cases, however, the Levenshtein distance is            For instance, natural language processing is one area in
one. The other method is to generate fixation maps by fixa-          which HMM has been widely applied. The observable data
tion and compare between conditions (Caldara & Miellet,              are the words in a corpus, and the hidden states are the
2011). For instance, if an experiment has two conditions, all        word-class tags, such as nouns, verbs, and adjectives. An
the first fixations in each condition can be used to generate a      HMM cannot directly observe the word-class tags of the
fixation map. A comparison between the two fixation maps             words, but can infer them from the observed words and the
will show whether the two groups differ significantly in             likelihood of transiting from one word-class to another.
their first fixations. However, the problem associated with             In the context of face recognition, the HMM contains a
this method is that the significant areas are likely to be scat-     number of hidden states, which each represents a different
tered so that the pattern could be hard to interpret. In this        ROI of the face. The directly observable data is the fixation
paper, we propose to use a time-series statistical model, the        location, which belongs to a particular hidden state (ROI).
hidden Markov model (HMM) with Gaussian emission den-                The distribution of fixations in each ROI is modeled as a
sities, to analyze eye movement data. We show that HMMs              two-dimensional Gaussian distribution in a Cartesian space.
can 1) summarize a person’s general eye movement strate-             Over time, the transition from the current hidden state to the
gy, including person-specific ROIs and saccade patterns, 2)          next state represents the saccade pattern, i.e., movement
reveal between-subject similarities and differences of eye           between ROIs, which is modeled by the transition matrix of
movement patterns, and 3) discover the association between           the HMM. In summary, the hidden states of the HMM cor-
recognition performance and eye movement strategies. In              respond to the ROIs of the face, where each is observable
the next section, we will 1) briefly describe the experiment         through a two-dimensional Gaussian emission density of
in which we collected the data, and 2) explain the HMM-              fixations, and the transitions between hidden states represent
based method in more length.                                         the saccade patterns.
                                                                        Given a set of chains of fixations, we estimated the pa-
                            Method                                   rameters of the HMM using a two-stage procedure. We first
                                                                     learned the ROIs on the face from the fixation data. Ignor-
Experiment                                                           ing the temporal information, the ROIs can be seen as a
                                                                     mixture of two-dimensional Gaussian distributions, i.e., a
   A total of 32 Chinese participants were recruited at the          Gaussian mixture model (GMM). In this study, we used the
University of Hong Kong. The experiment was divided into             variational Bayesian framework for Gaussian mixture mod-
a training phase and a testing phase. In the training phase,         els (VBGMM) to estimate the Gaussian parameters, as well
participants were shown a total of 20 frontal face images. In        as the number of GMM components (Bishop, 2006). This
the testing phase, participants were shown 40 frontal face           Bayesian hierarchical method puts prior distributions on the
images; 20 were new images and 20 were the ones appear-              GMM parameters, and uses approximation methods to find
ing in the training phase. They were asked to judge whether          the maximum a posteriori (MAP) estimate. One important
they had seen the faces before. Their responses in the testing       feature of VBGMM is that it can automatically estimate the
phase were recorded together with the fixations they made            optimal number of ROIs and ‘deactivate’ the redundant
before the response. Eye movements were tracked and rec-             ones. After discovering the GMM components, or the ROIs,
orded using the Eyelink II eye-tracking system. On average,          we next estimated the transition probabilities and prior
participants made 2.5 fixations per trial, ranged from one to        probabilities of the hidden states, using the forward-
three (this average was 1.8 fixations in Hsiao & Cottrell,           backward algorithm (Bishop, 2006).
2008).                                                                  In this study, we aim to use HMMs to address two ques-
                                                                     tions. Firstly, we wanted to discover the eye movement
Model                                                                strategy of each individual in order to reveal the common
   HMMs are widely used to model data generated from                 strategies shared by a subgroup of the participants. Second-
Markov processes (Barber, 2012). A Markov process is a               ly, we wanted to explore whether accuracy at face recogni-
process whose present state is determined only by its previ-         tion was related to eye movements. To address the first
ous state. The states in an HMM are not directly observable,         question, we trained one HMM per subject, using fixations
so that the current state of the process can only be inferred        collected from all the trials of the subject, in order to repre-
from 1) the association between the assumed hidden state             sent the general eye movement pattern of that subject. To
and the observed data, and 2) the likelihood of transiting to
                                                                 329

cluster the subjects' HMMs, we used the variational hierar-
chical EM algorithm (VHEM) for HMMs (Coviello et al,
2012). The VHEM algorithm takes HMMs as inputs, sepa-
rates the inputs into subgroups, and estimates a representa-
tion HMM for each subgroup.
   To address the second question, we trained two HMMs
per subject, using fixation sequences collected from all the
correct trials (i.e., correct HMM) and all the wrong trials
(i.e., wrong HMM), respectively, to represent two eye
movement strategies that led to different performances. We
                                                                                               to red        to green         to blue
compared the correct HMMs to the wrong HMMs using
                                                                          prior values          0.39            0.16           0.45
subject analysis, based on the differences in log-likelihoods
                                                                            from red            0.69            0.07           0.24
of the observed data, in order to examine whether eye
                                                                          from green            0.17            0.68           0.15
movement strategies that lead to correct or wrong responses
                                                                           from blue            0.21            0.06           0.73
have significantly different patterns. Specifically, for the
fixation sequences of a participant leading to correct re-
                                                                           Figure 1: The image on the left shows the three GMM
sponses, we calculated the log-likelihoods of observing the
                                                                      components of the HMM. Each colored region represents a
sequences from the correct HMM, and then computed the
                                                                        ROI (red, green, or blue). The transition probabilities and
mean. We also calculated the mean log-likelihood from the
                                                                        the prior values are summarized in the table beneath. The
wrong HMM using the same sequences. Doing this on all
                                                                        image on the right shows the fixation map of all the fixa-
the 32 participants yielded two vectors of mean log-
                                                                                                    tions.
likelihoods, one represented the mean log-likelihoods of the
correct HMMs generating the correct eye movements, and
one represented the mean log-likelihoods of the wrong
HMMs generating the correct eye movements. The differ-
ences between the mean log-likelihoods for each subject is
an approximation to the Kullback-Leibler (KL) divergence
between the correct HMM and the wrong HMM, which is a
measure of difference between two distributions (Bishop,
2006). Similarly, we also calculate the mean log-likelihoods
of the fixation sequences leading to incorrect responses un-             Figure 2: From the left to the right, the three images show
der the wrong and correct HMMs.                                        the first, second, and third fixations that all subjects made.
                             Results                                     From the comparison between the VHEM output and the
                                                                     fixation map of all the fixations combined, it can be seen
Section 1.1- Summary of all eye movement patterns                    that the VHEM output was spatially similar to the fixation
   In order to model a participant’s eye movement patterns,          map. The fixation map showed that most fixations landed in
we pooled all the fixations that a participant made, regard-         the middle of the face, with some slightly to the right. The
less of their sequential order, and applied the VBGMM to             three Gaussian components found using the VHEM demon-
discover a mixture of Gaussian distributions. We then used           strated a similar tendency. One advantage that the VHEM
the found Gaussian components and the fixations in the               output has over the fixation map is that on top of the spatial
forward-backward algorithm to estimate the transition prob-          distributions, it provides the temporal information of the eye
abilities and the prior values of the Gaussian components.           movement data in the forms of the prior values and the tran-
The fixations put into the forward-backward algorithm were           sition probabilities.
in their sequential orders. Each participant’s eye movements             The transition probabilities and the prior values suggested
were modeled by an HMM. Using the VHEM to group all                  that in general, fixations were more likely to start from the
HMMs into one cluster, the VHEM generated a representa-              red and the blue regions and to remain in or shift between
tion of the cluster which summarized the eye movement                the two regions. The chance of beginning from the green
patterns of all the participants in one HMM. Figure 1 below          region was lower. However, these fixations were more like-
shows the representation HMM and the fixation map of all             ly to stay in the same region than moving to the other re-
the fixations combined. Figure 2 below shows the fixation            gions. The fixation maps are shown in Figure 2. While there
maps per each fixation.                                              appears to be some movement between fixations, the fixa-
   The left image in figure 1 shows the HMM model. For in-           tion maps carry no information about the actual saccade
stance, the prior value of the red region suggests the proba-        pattern. However, using the results from the HMM analy-
bility of a first fixation belonging to that region. The proba-      sis, we can better interpret the fixation maps. The higher
bility of the next fixation transits from the red into the green     probabilities of remaining in the same regions and the lower
region is 0.07.                                                      probability of starting from the green region may have re-
                                                                 330

sulted in the fixations forming three separate clusters at the        The table below shows the probabilities of the 32 HMMs
third fixation; the cluster corresponded to the green region       belonging to the two subgroups. Each HMM was a model of
was less compacted.                                                a participant’s eye movement patterns, so that the two num-
                                                                   bers of each participant can be conceptualized as the degree
Section 1.2 - Two general strategies                               to which the participant was biased to holistic or analytic
  Another advantage of using the HMM-based method is               eye movement strategies. Overall, 10 participants used ho-
that the VHEM can group the input HMMs into several                listic pattern, while 22 used the analytic strategy.
subgroups and generate a representation HMM for each
subgroup. These would reveal the eye movement patterns                  Table 1: Summary of the normalized log-likelihoods of
shared by the participants in the same subgroup. The VHEM                   the subjects belonging to the two subgroups.
adopts a bottom-up, data-driven approach. It estimates the
distance between an input HMM and a representation                  ID      Holistic     Analytic      ID     Holistic  Analytic
HMM. The distance between an input HMM and all the                  01          0            1         17         0        1
representation HMMs are then normalized, which gives a              02          0            1         18        .04      .96
probability-based measure of how likely the input HMM               03          1            0         19         0        1
belongs to a subgroup.                                              04          1            0         20         1        0
  Using the VHEM, we discovered two subgroups, as                   05          0            1         21         1        0
shown in Figure 3 below.                                            06          0            1         22         0        1
                                                                    07          1            0         23         0        1
             Holistic strategy     Analytic strategy
                                                                    08          0            1         24         0        1
                                                                    09          0            1         25         0        1
                                                                    10          1            0         26         1        0
                                                                    11          0            1         27         0        1
                                                                    12          0            1         28         1        0
                                                                    13          1            0         29         1        0
                                                                    14          0            1         30        .02      .98
                                                                    15          0            1         31         0        1
                                                                    16          0            1         32         0        1
                                                                      The log-likelihoods suggested that the two subgroups
Holistic                to red      to green       to blue         were very distinctive from each other. To confirm whether
   prior values          0.33         0.39           0.28          they really represented two distinctive eye movement pat-
      from red           0.65         0.24           0.11          terns, we randomly created 50 pseudo-data chains; each was
    from green           0.22         0.61           0.17          a sequence of three pseudo fixations. We measured the log-
     from blue           0.12         0.25           0.63          likelihoods of the two HMMs generating the pseudo-data.
                                                                   Paired t-test showed that the log-likelihoods generated by
Analytic                to red      to green       to blue
                                                                   the two HMMs were significantly different, t (49) = -12.81,
   prior values          0.06         0.47           0.47
                                                                   p < .001; mean log-likelihood difference was 13.84. The
      from red           0.39         0.22           0.39
                                                                   finding further confirmed that the two eye movement pat-
    from green           0.03         0.75           0.22
                                                                   terns were distinctive from each other.
     from blue           0.05         0.25           0.70
                                                                   Section 2 – Association between performance and eye
    Figure 3: The two representation HMMs of the two sub-
                                                                   movement patterns
groups are shown in the left and the right images respective-
                               ly.                                    To investigate whether the differences in recognition per-
  It can be seen that the representation HMM on the left           formance are associated with different eye movement pat-
was more ‘condensed’. The three Gaussian components                terns, we trained per participant an HMM on all the fixa-
were relatively small in size and were squeezed toward the         tions collected from the correctly responded trials (correct
center of the face. This pattern was similar to the “Eastern       HMM), and an HMM on all the fixations collected from the
pattern” found in a previous study (Kelly et al., 2011) that       incorrectly responded trials (wrong HMM). We compared
was argued to represent a more holistic strategy. The HMM          the mean log-likelihoods of the data being generated by the
representation on the right, on the other hand, was more           two HMMs.
‘spread’. The three Gaussian components were large and                Paired t-test showed that the mean log-likelihoods of cor-
more separated from one another. This pattern could be             rect data being generated by the correct HMMs (M = -
loosely associated with the “Western pattern” (Kelly et al.,       18.13) were significantly higher than the mean log-
2011) that represented a more analytic way of perceiving a         likelihoods of correct data being generated by the wrong
face.                                                              HMMs (M = -18.42), t (31) = -2.58, p = .01. The mean log-
                                                                   likelihoods of the wrong data being generated by the wrong
                                                               331

HMMs (M = -17.9) was also significantly higher than the
mean log-likelihoods of correct data being generated by the
wrong HMMs (M = -18.53), t (31) = -4.58, p < .001. The
results suggested that the two sets of HMMs were signifi-
cantly different from each other. Figure 4 – 7 below illus-
trate the HMMs and the fixation maps of a few subjects.
          correct HMM                  wrong HMM
                                                                correct HMM                       to red      to green
                                                                prior values                      0.63        0.37
                                                                from red                          0.68        0.32
                                                                from green                        0.63        0.37
                                                                wrong HMM                         to red      to green
                                                                prior values                      0.39        0.61
correct HMM                    to red     to green              from red                          0.89        0.11
prior values                   0.81       0.19                  from green                        0.83        0.17
from red                       0.19       0.81
from green                     0.81       0.19                        Figure 6: The correct and wrong HMMs of subject 3.
wrong HMM                      to red     to green
prior values                   0.50       0.50
from red                       0.60       0.40
from green                     0.87       0.13
      Figure 4: The correct and wrong HMMs of subject 1.
           correct HMM                wrong HMM
                                                                   Figure 7: From the left to the right, the three images show
                                                                 the difference between the fixation maps of correct and the
                                                                 wrong responses of the three subjects shown in Figure 4-6.
                                                                   From the figures above, we see that in some cases, the
                                                                key difference between the wrong and correct HMMs can be
                                                                discovered from the temporal rather than the spatial domain
                                                                of the data. For instance, for subject 1, the correct and the
                                                                wrong HMMs were spatially similar, but the wrong HMM
                                                                had a different set of prior values and transition probabili-
                                                                ties. If the subject started looking at the image from the right
                                                                eye, the response is more likely to be incorrect. 1
correct HMM                     to red    to green                 One disadvantage of comparing fixation maps between
prior values                    0.61      0.39                  correct and wrong responses can be seen from figure 7
from red                        0.36      0.64                  above. The pixel test in each case discovered many signifi-
from green                      0.66      0.34                  cantly different regions. These regions are all over the face,
wrong HMM                       to red    to green              which make them very hard to be qualitatively explained.
prior values                    0.51      0.49
from red                        0.54      0.46                                             Discussion
from green                      0.47      0.53
     Figure 5: The correct and wrong HMMs for subject 2.           1
                                                                     We decided to restrict the correct and wrong HMMs to two
                                                                hidden states because there was not enough data to train three hid-
          correct HMM                  wrong HMM                den states in the wrong HMMs.
                                                            332

   In this paper, we have proposed an HMM-based method              110610). We thank Tina Liu for collecting the data for the
to analyze eye movement data and demonstrated several               study. We are also grateful to the Research Grant Council of
advantages.                                                         Hong Kong (project code HKU 745210H to J.H. Hsiao) and
   Firstly, our method can learn the ROIs for each person           the HKU Seed Funding Program for Basic Research (project
from the data together with their temporal information. This        code 201011159124 to J.H. Hsiao).
provides the information for describing and inferring the
scan paths. Although fixation maps can be generated by                                       References
fixations, such that the maps could be used to show the dis-        Baber, D. (2012). Bayesian reasoning and machine learn-
tributional difference of fixations over time, they do not            ing. Cambridge: Cambridge University Press.
contain transition information so that describing and infer-        Barton, J. J. S., Radcliffe, N., Cherkasova, M. V., Edelman,
ring scan paths are impossible.                                       J., & Intriligator, J. M. (2006). Information processing
    Secondly, using VHEM, the HMMs can be grouped into                during face recognition: the effects of familiarity, inver-
clusters based on their similarities. Our finding of this clus-       sion, and morphing on scanning fixations. Perception 35,
tering showed that participants demonstrated either a holis-          1089-1105.
tic strategy or an analytic strategy. The two strategies were       Bishop, C. M. (2006). Pattern recognition and machine
significantly different from each other.                              learning. New York: Springer.
   Lastly, by comparing the correct and the wrong HMMs,             Caldara, R. & Miellet, S. (2011). iMap: a novel method for
we showed that the ‘correct’ eye movements were signifi-              statistical fixation mapping of eye movement data. Behav-
cantly different from the ‘wrong’ eye movements, and that             ior research methods 43, 864-878.
the difference to a considerable extent can be attributed to        Coviello, E., Chan, A. B., & Lanckriet, G. R. G. (2012). The
the transition differences instead of spatial distribution dif-       variational hierarchical EM algorithm for clustering hid-
ferences. Comparison of the fixation maps of correct and              den Markov models. In Neural Information Processing
wrong responses also showed the differences between the
                                                                      Systems (NIPS).
‘correct’ and ‘wrong’ eye movements, but the differences
                                                                    Goldberg, J. H. & Helfman, J. I. (2010). Scanpath clustering
were too spread so that the results lacked identifiable pat-          and aggregation. Proceedings of the 2010 Symposium on
terns. Also, the fixation map method was not able to show             Eye-Tracking Research & Applications, 227-234.
the difference in transition probability between eye move-
                                                                    Gosselin, F. & Schyns, P. G. (2001). Bubbles: a technique
ments in correct and wrong trials.
                                                                      to reveal the use of information in recognition tasks. Vi-
   The lack of empirical findings to support the scan path
                                                                      sion Research 41, 2261-2271.
theory caused eye movement researchers’ lack of interest in
                                                                    Henderson, J. M. (2003). Human gaze control during real-
sequential information (Henderson, 2003). Our findings,
                                                                      world scene perception. TRENDS in Cognitive Sciences 7,
however, suggest that sequential information could be asso-
                                                                      498-504.
ciated with performance. Theoretically, given a chain of
                                                                    Henderson, J. M., Williams, C. C., & Falk, R. J. (2005). Eye
fixations, using the two HMMs, the accuracy of the re-
                                                                      movements are functional during face learning. Memory
sponse can be predicted. This further justifies using HMMs
                                                                      & Cognition 33, 98-106.
to describe and analyze eye movement patterns. Future work
                                                                    Hsiao, J. & Cottrell, G. (2008). Two fixations suffice in face
will test this hypothesis.
                                                                      recognition. Psychological Science 19, 998-1006.
   In the current study, we pooled all the fixations together
                                                                    Kelly, D. J., Jack, R. E., Miellet, S., De Luca, E., Foreman,
to find the ROIs because we assumed that the ROIs are the
                                                                      K., & Caldara, R. (2011). Social experience does not
same across fixations. An alternative approach that does not
                                                                      abolish cultural diversity in eye movements. Frontiers in
rely on this assumption is to train the GMMs by fixation, so
                                                                      Psychology 2, 1-11.
that at each fixation, there are a unique set of ROIs. An
                                                                    Land, M. F. (2011). Oculomotor behavior in vertebrates and
HMM in this case will have time-dependent states. For fu-
                                                                      invertebrates. In S. Liversedge, I. Gilchrist, & S. Everling
ture research, we attempt to investigate this further.
                                                                      (Eds.), Oxford handbook of eye movements. Oxford: Ox-
   In summary, here we show that eye movements can be
                                                                      ford University Press.
better studied and understood using HMMs. With HMMs,
                                                                    Mannan, S. K., Ruddock, K. H., & Wooding, D. S. (1997).
we can describe both the spatial and the sequential aspects
                                                                      Fixation patterns made during brief examination of two
of eye movements. We also show that clustering the HMMs
                                                                      dimensional images. Perception, 26, 1059-1072.
can yield interesting between-group differences. The two
                                                                    Pelphrey, K. A., Sasson, N. J., Reznick, S., Paul, G., Gold-
subgroups roughly correspond to more holistic and more
                                                                      man, B. D., & Piven, J. (2002). Visual scanning of faces
analytic strategies. We further show that correct and wrong
                                                                      in autism. Journal of Autism and Developmental Disor-
recognitions have different eye movement patterns and that
                                                                      ders 32, 249-261.
the differences can be found in the transition probabilities.
                                                                    Wade, N. J., & Tatler, B. W. (2011). Origins and applica-
                                                                      tions of the eye movement research. In S. Liversedge, I.
                    Acknowledgements                                  Gilchrist, & S. Everling (Eds.), Oxford handbook of eye
   A.B. Chan acknowledges support from the Research                   movements. Oxford: Oxford University Press.
Grants Council of the Hong Kong SAR, China (CityU
                                                                333

