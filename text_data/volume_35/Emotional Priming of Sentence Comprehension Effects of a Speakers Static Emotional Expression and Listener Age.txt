UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Emotional Priming of Sentence Comprehension: Effects of a Speaker’s Static Emotional
Expression and Listener Age
Permalink
https://escholarship.org/uc/item/4783t5jd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Authors
Carminati, Maria Nella
Knoeferle, Pia
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       Emotional Priming of Sentence Comprehension: Effects of a Speaker’s Static
                                      Emotional Expression and Listener Age
                              Maria Nella Carminati (mcarmina@techfak.uni-bielefeld.de)1,3
                                      Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)1,2,3
                                              1 SFB 673 “Alignment in Communication”
                                        2 Cognitive Interaction Technology Excellence Center
                                                        3 Department of Linguistics
                                                Universitätsstr. 25, Bielefeld University,
                                                         33615 Bielefeld, Germany
                              Abstract                                  while processing sentences (for a recent review, see Huettig,
   We report two visual-world eye-tracking experiments that             Rommers, & Meyer, 2011).
   investigated how and with which time course emotional                  In recent years the scope of research on the language-
   information from a speaker’s face affects younger (N = 32,           vision interaction has been extended to more complex and
   Mean age = 23) and older (N = 32, Mean age = 64) listeners’          subtle aspects of naturalistic, visually-situated language
   visual attention and language comprehension as they                  events, such as dialogue interactions. One topic has been
   processed emotional sentences in a visual context. The age           how visually-perceivable speaker-based cues, for example,
   manipulation was aimed at testing predictions by socio-
   emotional selectivity theory of a positivity effect in older
                                                                        speaker gaze and gestures, affect language processing.
   adults. After viewing the emotional face of a speaker (happy         Results suggest that a speaker’s gaze is incrementally
   or sad) on a computer display, participants were presented           integrated into language processing by listeners (e.g., Hanna
   simultaneously with two pictures depicting opposite-valence          & Brennan, 2007).
   events (positive and negative; IAPS database) while they               Another potentially powerful cue that could be used by a
   listened to a sentence referring to one of the events.               listener is a speaker’s emotional facial expression. The
   Participants’ eye fixations on the pictures while processing         question of how such a cue is used in language processing is
   the sentence were enhanced when the speaker’s face was
   emotionally congruent with the sentence/picture compared to          particularly relevant to current psychological research,
   when it was not. The enhancement occurred from the early             especially in light of the recent surge in interest in embodied
   stages of sentence-reference disambiguation; importantly, it         and situated cognition, and the increasingly available
   was modulated by age, in that for the older adults it was more       evidence supporting a close interaction between emotions
   pronounced with positive faces, and for the younger ones with        and language (e.g., Havas, Glenberg, & Rinck, 2007).
   negative faces. These findings demonstrate for the first time        However, to the best of our knowledge there is todate no
   that emotional facial expressions, similarly to previously           study that has examined effects of a speaker’s facial
   studied speaker cues such as eye gaze and gestures, are
   rapidly integrated into sentence processing. They also provide       expression      on     spoken      sentence     comprehension.
   new evidence for positivity effects in older adults in online        Additionally, evidence for visual context effects in sentence
   incremental situated sentence processing.                            processing comes almost exclusively from studies with
                                                                        young adults (ca. 19-31 years). By contrast, the extent to
   Keywords: sentence processing; visual-world paradigm;                which visual context affects sentence comprehension in
   emotional processing; speaker cues; positivity effect;               older adults is less clear. The present research addresses
   facial expressions                                                   these two open issues in two eye-tracking experiments that
                                                                        examined (a) the time course with which a speaker’s
Visual Context Effects on Language Processing                           emotional      facial    expressions     can     influence    a
The study of context effects on language processing has                 comprehender’s visual attention to target pictures during
been a major topic of investigation in psycholinguistic                 spoken sentence comprehension; and (b) the nature of this
research, and since the development of the visual world                 influence in young versus older adults.
paradigm in the mid-nineties, psycholinguists have had at
their disposal a powerful tool to investigate a potentially             Emotion Processing and Emotional Priming
rich source of context effects on language processing, that                Ekman’s (1972) proposal of a set of six basic universal
of the visual context. Among other things, findings from                emotions associated with distinct facial emotional
this research have demonstrated how information such as an              expression configurations (happiness, sadness, fear, anger,
object’s size, color, or shape, depicted clipart events, real-          disgust, and surprise) has been widely tested over the years
world action events, action affordances, and the spatial                and assumed by many scholars in the field of emotion
location of objects are all rapidly integrated during sentence          research (e.g., Lundqvist, Flykt, & Öhman, 1998). Within
comprehension and can affect a listener’s visual attention              this view, the basic facial expressions are associated with a
                                                                   1976

distinctive meaning, so they could, in principle, be used by a      while they listened to the sentence were recorded. In line
speaker to strengthen the meaning of her utterances. There          with the usual findings from the visual world paradigm,
is evidence that emotional faces such as happy or angry             when participants begin processing the sentence, we expect
ones, are attended to faster and are processed more deeply          them to look at the target (the IAPS picture described in the
than neutral ones (Palermo & Rhodes, 2007). Generally, the          sentence) from the time it becomes clear which picture the
same attention advantage enjoyed by emotional faces                 sentence is about (i.e., a sentence effect).
(compared to nonemotional, neutral ones) is found for
emotional stimuli in different modalities, for example,
emotional words, pictures and sounds (e.g., Hermans, De
Houwer, & Eelen, 2001).
   Not only do emotional stimuli attract more attention and
are remembered better than corresponding neutral ones, they
can also influence how other stimuli (e.g., words, pictures)
are processed. This influence has been demonstrated in
emotional priming studies (Fazio, 2001), where responses to
a target stimulus are facilitated (i.e., faster) when prime and
target have the same emotional valence (e.g., positive-
positive, negative-negative), compared to when they have
opposite valence. Interestingly, priming occurs not only
when prime and target belong to same modality and
category (e.g., when they are both faces, pictures or words)
but also across modalities. e.g., from a picture to a face
(Carroll & Young, 2005, Expt 2), or from a picture or facial
expression to a word (Carroll & Young 2005, Expt 1 and 4).
                                                                          Figure 1: Sequence of events in an experimental trial
Emotional Priming of Sentences: Current Study
With regard to the issue of whether a speaker’s emotional             However, for us the more interesting question is whether
facial expression can influence not just lexical but also           and how the facial prime affects (i.e., primes) the processing
sentence processing, the just-mentioned findings on                 of the sentence, in other words, the face x sentence
emotional priming from faces to words suggest that it               interaction. In line with findings from emotional priming
should: Just as the perception of a happy face (the prime)          research, we expect facilitation when the prime (i.e., the
produces a faster response to a positive (vs. negative) target      face) is emotionally congruent with the target (i.e., the
word, so a smile on a speaker’s face might facilitate a             sentence/picture) compared to when prime and target are
listener’s processing of a positive (vs. negative) sentence.        incongruent. In our experiment the dependent variable is
To our knowledge, no research has so far investigated the           fixations on the pictures while incrementally processing the
emotional priming of whole sentences (as opposed to                 sentence; so we expect that looks to the target picture
isolated words) using emotional facial expressions. In the          should be facilitated when the emotional face is valence-
current study, we used the visual world paradigm to                 congruent (vs. incongruent) with the sentence. This
examine the time course of emotional priming in sentence            facilitation should be reflected in more and longer fixations
processing. We employed a design typical of many visual-            to the target picture in congruent than in incongruent
world experiments on sentence comprehension: Participants           conditions (cf. Arai, Van Gompel, & Scheepers, 2007).
listened to sentences relating to visual material displayed on         Furthermore, the timing of this facilitation is of particular
a computer screen (see Fig.1, for the sequence of events in         interest to us, as it would reveal details about the time
an experimental trial). Before hearing the sentences, our           course of integrating emotion information into language
participants saw either a smiling or a sad face (see Fig. 1,        processing. Earlier findings (see above) suggest that
Display 1). They were told that this was the face of the            emotional information enjoys privileged attention, so this
speaker of the ensuing sentence (thus simulating a speaker-         would predict that facilitation effects should occur from the
hearer scenario). Then two emotional pictures from the              early stages of processing the sentence. Alternatively,
International Affective Picture System database (IAPS,              considering the specifics of our experimental task,
Lang, Bradley, & Cuthbert, 1999), one positive and one              facilitatory effects may not surface until later or not occur at
negative, were displayed side by side on the screen. After          all during the processing of the sentence. This is because for
1500 ms the sentence was played and referenced either one           facilitation to take place perceivers need to integrate cues
or the other picture; accordingly, the sentence also had a          from the visual, linguistic and emotional modalities and this
positive or negative emotional content (see Fig. 1, Display         may be a complex task to perform on the fly. In addition to
2). Thus, the speaker’s facial expression could be                  facilitating the processing of the sentence itself (face x
emotionally congruent or incongruent with the sentence.             sentence interaction), the face may affect the fixations that
Participants’ eye movements to the display on the monitor           listeners make on the pictures independently of the sentence
                                                                1977

valence. This would be reflected in a preference to look at         Methods
the picture which is emotionally congruent with the face,
i.e., a face-picture congruence effect. To be triggered, this       Participants
face-picture congruence effect does not require linguistic          Thirty-two older (60-72 years, M = 64.37, SD = 3.57) and
input from the sentence (but only information from the face         32 younger (19-29 years, M = 22.90, SD = 2.73) adults took
and the pictures), so it could occur earlier, before sentence       part in the experiment in return for a monetary reward; all
disambiguation, as well as later, after disambiguation. Note        gave informed consent.
that a face x sentence interaction, which is the effect of
primary interest to us, cannot be reduced to a face-picture         Materials
congruence effect, as it requires the additional input from
the sentence to occur.                                              Materials consisted of photographs of emotional facial
                                                                    expressions, emotional pictures and auditorily presented
Emotion Processing in Younger and Older Adults                      sentences. There were 28 experimental and 56 filler items.
                                                                    Each experimental item consisted of a facial expression
The age group manipulation in our study was inspired by             (happy/sad), a display showing a positive and a negative
research showing that emotion processing changes across             picture taken from the IAPS database (Lang et al., 1999)
the life span (for a review, see Ruffman et al., 2008).             and a sentence describing either the positive or negative
According to socio-emotional selectivity theory (Mather &           picture. The emotional faces were selected from 15 sets of
Carstensen, 2003), as people grow older, they realize that          Bielefeld-University student portraits, each set depicting a
their time is limited and focus more on emotionally-                neutral, a sad and a happy expression. From these sets we
satisfying experiences in the present moment. This change           selected the 4 best sets (2 male, 2 female) based on the
arguably leads to the so-called ‘positivity effect’, observed       results of a valence-rating study (N=18).
in studies where young and older adults were compared on               The positive and negative images were selected on the
emotional processing. For example, when presented with              basis of the valence ratings in Lang et al., 2008, (negative
pairs of pictures (a neutral face, and a positive or negative       images: range 2.42 - 5.07, M = 3.46, SD = 1.69; positive
face), older people spent less time inspecting the negative         images: range 5.51 - 8.22, M = 7.19, SD = 1.55). Arousal
than positive face; i.e., they displayed an attentional bias        scores of negative and positive images were similar (paired
away from the negative and towards the happy expression.            t-test t(27) = -.84, p = .41).
Younger people, by contrast, showed no preference (Mather              The sentences for each of the two images of the 28
& Carstensen, 2003), or preferred negative faces (Isaacowitz        experimental item-picture pairs fulfilled constraints specific
et al., 2006). Positivity effects have also been found in the       to length, structure and content. All started with an
recall of pictures and facial expressions (e.g., Mather &
                                                                    introductory main clause containing a verb of opinion in the
Carstensen, 2003), or of long-term life events (Kennedy,
                                                                    first person singular (e.g., I think/believe/am of the opinion
Mather, & Carstensen, 2004). In recent years, researchers
                                                                    that…). This was followed by a subordinate clause about the
have discussed the proper characterization of the positivity
                                                                    event depicted in one of the two IAPS images of an item.
effect and the experimental conditions under which it can be
                                                                    The subordinate clause contained a subject noun phrase
observed. This has led to a broadening of the definition of
                                                                    (N1), followed by an object noun phrase (N2), an adverb
the effect, which now includes, not only an increased focus
                                                                    (Adv) and a final finite verb (Verb). Examples of the
on positive compared to negative information in older
                                                                    positive and negative sentence for an item are given in
versus younger adults, but also a reduced focus on negative
                                                                    Figure 1. Care was also taken to match the sentences, so far
information in older adults (see especially Langeslad & van
                                                                    as possible, by lemma frequency of nouns and adverbs,
Strien, 2009; Scheibe & Carstensen, 2010).
                                                                    using frequency counts from the CELEX database (Baayen,
   In light of this, given that our study involves the
                                                                    Piepenbrock, & Gulikers, 1995).
processing of emotional faces and emotional pictures and
                                                                       The sentences were recorded by 4 native speakers of
sentences, we should see differences in the way younger and
                                                                    German, two female and two male, and the speakers
older adults integrate the information from a negative or
                                                                    assigned to the faces, with 1 male being used for half of the
positive face with the processing of a negative or positive
                                                                    experimental items (14) and 1 female for the other half (14).
target sentence and corresponding picture (i.e., a face x
                                                                    The sound files of the two experimental sentences
sentence x age interaction). A prediction is that older people
                                                                    associated with an experimental picture pair were edited
should find it easier to integrate a positive face with a
                                                                    using professional sound editing software, to ensure that the
positive sentence than a negative face with a negative
                                                                    onsets of the critical words (N1, N2, Adverb) occurred
sentence (i.e., facilitation only for positive sentences, or
                                                                    exactly at the same point in time from sentence start in the
greater facilitation for positive than negative sentences). For
                                                                    positive and corresponding negative sentence (to achieve
younger people, on the other hand, one may expect equal
                                                                    this, pauses were shortened or between-word breaks were
facilitation for positive and negative sentences, only
                                                                    lengthened slightly as necessary). The combination of the
facilitation for negative, or greater facilitation for negative
                                                                    experimental faces, pictures and sentences yielded a 2
than positive sentences. Similar modulations by age are
                                                                    (Face: positive vs. negative) x 2 (Picture: positive vs.
predicted for the face-picture congruence effect.
                                                                    negative) x 2 (Sentence: positive vs. negative) design.
                                                                1978

   For the 56 distractor item picture-pairs, we constructed a       divided by the probability of looking at the positive picture
sentence that matched one of the two IAPS pictures. The             (ln(p(neg picture)/p(pos picture)). This measure expresses
content of half of the distractor sentences (28) was neutral,       the strength of the visual bias towards the negative versus
while 14 contained at least one positive word (e.g., The            positive picture. It is particularly suited for eye tracking data
talented artist is drawing the nice portrait) and the remaining     analyses with parametric tests (such as ANOVAs) because it
half one negative word (e.g., It is obvious that today the          violates neither independence nor homogeneity of variance
weather will be unbearable). The 56 filler items further            assumptions (cf. Arai et al., 2007). The log ratio is
differed from the experimental items as follows: the facial         symmetrical around zero: A positive log ratio indicates
expression was either neutral (28 items), positive (14 items)       more looks to the negative than the positive picture; a
or negative (14 items); both IAPS images had mid-range              negative log ratio indicates more looks to the positive than
valence (3.5 - 6.5); there was only 1 sentence per filler item.     the negative picture; and a value of zero means the two
                                                                    pictures get an equal number of looks.
Procedure                                                              Fig. 2 (a)-(b) plots the time course of fixations for the
The experimental session started with the collection of             Post-N1 onset region for the two age groups. These graphs
demographic details from the participants, and with the             are based on log gaze probability ratios (henceforth ‘log
administration of some cognitive tests and of a mood                ratios’) computed on successive 20-ms time slices.
questionnaire. Eye movements were recorded using an SR
Research Eyelink 1000 Desktop head-stabilised eye tracker
(SR Research, Mississauga, Ontario, Canada). Participants
were told that the study investigated language
comprehension in relation to a visual display: They would
first see the face of a person who was thinking about
something and was about to speak, and after that they would
hear him/her utter a sentence which described one of the
two pictures shown on the screen. The task was to look,
listen and understand the sentence, and decide whether the
valence of the face matched the valence of the sentence
(“Does the face match the sentence?”) by pressing one of
two buttons. The sequence of events in an experimental trial
is illustrated in Fig. 1.
                   Analyses and Results
   The data of interest were the participants’ fixations on the
pictures during sentence processing, i.e., during the time
listeners inspect Display 2 (see Fig. 1). Because the initial
part of the sentence (cf. Fig. 1, “Ich meine dass”) was
neutral between the negative and positive sentence,
disambiguation towards the positive or negative picture
occurred from the initial NP (N1) of the embedded sentence
onwards (cf. Fig. 1, “die Mechaniker/die Vorstadtkinder”).
Therefore any possible facilitation in the processing of the
sentence (face x sentence interaction) due to having seen a
congruent face can only be expected to occur after N1 onset.
   By contrast, a face-picture congruence effect (i.e., looks
to the pictures as a function of prime face) can occur both
before and after sentence disambiguation. We thus defined               Figure 2: Mean log gaze probability ratios for young and
two time periods: the Post-N1 (onset) region (from the onset            older participants in the Post-N1 onset region, from the
of N1 until sentence end (average duration 4016 ms, SD =                                       onset of N1.
456) and the Pre-N1 (onset) region (including, in addition to
the initial, neutral part of the sentence, the last 1200 ms of         In Fig. 2 the sentence effect can clearly be seen in the two
the 1500-ms picture preview period, for a total duration of         sets of lines moving apart from about 500 ms after the onset
3000 ms). Because our main focus is the face x sentence             of N1: The red lines (for the two negative sentence
interaction (and its possible modulation by age), we will           conditions) rise steadily above zero, indicating an increasing
first present the findings for the post-N1 onset region.            preference for the negative picture, while the black lines (for
   The measure we used to analyze fixations on the pictures         the positive sentence conditions) go in the opposite
is the mean log gaze probability ratio, i.e., the log of the        direction, indicating an increasing preference for the
ratio of the probability of looking at the negative picture         positive picture in these conditions.
                                                                1979

   A face-priming effect on the processing of the sentence          reported above for the whole Post-N1 region) on mean log
(i.e., the facilitatory effect occurring from having seen a         ratios for the individual word regions, i.e., N1, N2, Adverb
sentence-congruent emotional face) emerges in the relative          and Verb (see Fig. 2). For the N1 region, these comparisons
distance between the solid and the dotted line of each              yielded a similar pattern of results as in the previous
sentence condition: If having seen a face of the same               analyses, i.e., older participants showed a facilitation from
valence as the sentence facilitates sentence processing, the        the positive prime face in the positive sentence conditions
congruent condition (solid line) should be associated with a        (ps < .01), but not in the negative sentence conditions. By
greater absolute value than the incongruent condition               contrast, young participants showed significant facilitation
(dotted line).                                                      in the negative sentence condition (ps < .002), while in the
   The log-ratio means for the post-N1 region were                  positive sentence condition facilitation was fully significant
submitted to 2 x 2 x 2 (Face x Sentence x Age) repeated-            only in the item analysis (p1 = .06; p2 = .02). The only other
measures ANOVAs with participants and items as random               (nearly) significant comparison occurred for the positive
effects. The ANOVAs revealed a significant effect of face-          sentences in the adverb region (ps < .05): For older adults a
picture congruence (ps < .001), with a negative picture             positive (vs. negative) face, facilitated the processing of a
preference when the face was negative (M= .15) and a                positive sentence, but a negative face was of no advantage
positive picture preference when the face was positive (M =         in processing a negative sentence. The fact that results were
-.11). This effect was not modulated by age (both F’s < 1).         significant in the early, N1 region for both age groups
   As expected, there was a highly significant sentence             suggests that the integration of the visual context with facial
effect (ps < .001): When the sentence was negative, there           and linguistic information occurs early and that the time
was a preference for looking at the negative picture and the        course of this integration does not substantially differ
opposite was true when the sentence was positive (Ms =              between the two age groups.
1.65 vs. - 1.61). Importantly, the sentence effect was                In the pre-N1 onset region, the ANOVA analyses on the
significantly modulated by age (ps < .002). This Sentence x         log ratios revealed a face-picture congruence effect (ps >
Age interaction is due to the fact that older adults, when          .02), not modulated by age: The negative picture was fixated
hearing a negative sentence, look less at the negative picture      longer when the face was negative and the positive picture,
(vs. the positive one) than the younger adults; in other            when the face was positive. There was also a significant
words, they are less “responsive” to the negative sentence          picture effect, with the negative picture attracting overall
than the younger group.                                             more looks than the positive one (ps < .02). However, this
   Crucially for our experimental hypotheses, the 3-way             general bias for the negative picture was weaker for the
Face x Sentence x Age interaction was fully significant by          older participants (the interaction with age was marginally
participants (p1 = .025, p2 = .13). For our hypotheses, this        significant in the participants’ analysis (p1= .069; p2= .18).
interaction reflects the facilitating effect of the face on the
processing of the sentence and the modulation of this effect                      Discussion and Conclusion
by age. Post-hoc pairwise comparisons on participants and             These eye-tracking results are important for the following
items means of the individual groups (i.e., for each age            reasons. First, they demonstrate for the first time that
group) compared the two negative sentence conditions and            priming from an emotional face occurs during sentence
the two positive sentence conditions (Bonferroni correction         comprehension in a visually-situated task (i.e., when
for 4 comparisons, p = 05/4 = .0125). These comparisons             language is about objects and actions in the visual context).
can tell us if younger and older participants show different        Moreover, priming effects were found from the early stages
sensitivities to the negative or positive prime face during the     of sentence-reference and valence disambiguation (i.e., N1),
processing of the sentence. In the comparisons for the              showing that the seemingly complex integration of visual
younger participants, only the difference between the two           information from an emotional face, a picture and a
negative sentence conditions was significant (ps < .02),            sentence happens rapidly and without particular effort.
while the corresponding comparisons for the older adults            Previous research in visually-situated comprehension tasks
yielded only a significant difference between the two               has demonstrated that speaker-based information such as
positive sentence conditions (ps < .02).                            gaze is rapidly integrated into sentence processing (e.g.,
   Thus, for younger participants a negative prime face (vs. a      Hanna & Brennan, 2007; Knoeferle & Kreysa, 2012).
positive one) significantly enhanced looks to the negative          Importantly, our results provide evidence that a speaker’s
picture during the processing of a negative sentence. By            emotional facial expression also has a rapid influence on
contrast, a positive face had no enhancing effect on younger        sentence interpretation.
adults’ processing of a positive sentence. For the older              Crucially also, our results provide new evidence for age
group however, the opposite pattern emerged: A negative             differences in the processing of emotional information. All
face had no effect on the processing of a negative sentence,        of the age-based modulations that we observed are
but a positive (vs. negative) face elicited more looks to the       compatible with a positivity effect, i.e., either an increased
positive picture when the positive sentence was processed.          focus on positive compared to negative information by older
   To assess the time course of this facilitation, we               versus younger adults, or a reduced focus on negative
performed pairwise comparisons (similar to the ones                 information by older adults (Langeslad & van Strien, 2009;
                                                                1980

Scheibe & Carstensen, 2010). The fact that positivity effects         face conversation. Journal of Memory and Language, 57,
were found in the early stages of sentence processing using           596-615.
a highly time-sensitive methodology such as eye tracking            Havas, D.A., Glenberg, A.M., & Rinck, M. (2007). Emotion
has also implications for the question of the mechanisms              simulation during language comprehension. Psychonomic
underlying the positivity effect, and the level(s) of                 Bulletin and Review, 14, 436-441.
processing at which these mechanisms operate.                       Hermans, D., De Houwer, J., & Eelen P. (2001). A time
   A central tenet of socioemotional selectivity theory is that       course analysis of the affective priming effect. Cognition
emotion regulation improves with age and that the positivity          and Emotion, 15, 143–165.
effect occurs because older people are capable (consciously         Huettig, F., Rommers, J., & Meyer, A.S. (2011). Using the
or unconsciously) to selectively regulate their emotions in           visual world paradigm to study language processing: A
order to enhance positivity and well-being. According to              review and critical evaluation. Acta Psychologica, 137,
this view, the positivity effect should be strongest in tasks         151- 171.
and situations that require controlled processing with              Kennedy Q., Mather M., & Carstensen L.L. (2004). The role
associated exertion of cognitive effort, and less so in tasks         of motivation in the age-related positivity effect in
that measure automatic or initial processing (Scheibe &               autobiographical memory. Psychological Science, 15,
Carstensen 2010). Although evidence from several studies              208–214.
suggests that positivity effects require deliberate use of          Knoeferle, P. & Kreysa, H. (2012). Can speaker gaze
mood regulation strategies to occur (e.g., Isaacowitz, Toner,         modulate syntactic structuring and thematic role
& Neupert, 2009), recent evidence has shown that                      assignment during spoken sentence comprehension?
controlled processing and cognitive effort are not necessary          Frontiers in Psychology, 3:538.
to trigger positivity effects in older adults (e.g., Allard,        Isaacowitz, D.M., Wadlinger, H.A., Goren, D., & Wilson,
Wadlinger & Isaacowitz, 2010). We suggest that the                    H.R. (2006). Selective preference in visual fixation away
positivity effects found in early processing in the eye               from negative images in old age? An eye tracking study.
tracking measures of our experiment are also more likely to           Psychology and Aging, 21, 40– 48.
be a result of an early and non-strategic emotion processing        Isaacowitz, D.M., Toner, K., & Neupert, S.D. (2009). Use
mechanism.                                                            of gaze for real-time mood regulation: Effects of age and
                                                                      attentional functioning. Psychology and Aging, 24, 989–
                    Acknowledgments                                   994.
                                                                    Langeslag, S.J., & van Strien, J.W. (2009). Aging and
This research was funded by the German Research
                                                                      emotional      memory:       The     co-occurrence      of
Foundation (DFG) within the SFB-673 Project. We thank
                                                                      neurophysiological and behavioral positivity effects.
Katja Glados and Katja Münster for their help.
                                                                      Emotion, 9, 369–377.
                                                                    Lundqvist, D., Flykt, A., & Öhman, A. (1998). Karolinska
                         References                                   directed emotional faces. Stockholm: Karolinska Institute
Allard E.S., Wadlinger H.A. & Isaacowitz, D.M. (2010).                and Hospital, Section of Psychology.
   Positive gaze preferences in older odults: Assessing the         Mather, M., & Carstensen, L.L. (2003). Aging and
   role of cognitive effort with pupil dilation. Aging,               attentional biases for emotional faces. Psychological
   Neuropsychology, and Cognition, 17.3, 296-311.                     Science, 14, 409-415.
Arai, M., Van Gompel, R.P.G., & Scheepers, C. (2007).               Palermo R., & Rhodes G. (2007). Are you always on my
   Priming ditransitive structures in comprehension.                  mind? A review of how face perception and attention
   Cognitive Psychology, 54, 218-250.                                 interact. Neuropsychologia, 45, 75–92.
Baayen, R.H., Piepenbrock, R., & Gulikers, L. (1995). The           Ruffman, T., Henry, J.D., Livingstone, V., & Phillips, L.H.
   CELEX lexical database [CD-ROM]. Philadelphia:                     (2008). A meta-analytic review of emotion recognition
   University of Pennsylvania, Linguistic Data Consortium.            and aging: Implications for neuropsychological models of
Carroll, N.C., & Young, A.W. (2005). Priming of emotion               aging. Neuroscience & Bio-behavioral Reviews, 32, 863-
   recognition. Quarterly Journal of Experimental                     881.
   Psychology, 58A, 1173-1197.                                      Scheibe S., & Carstensen L.L. (2010). Emotional aging:
Ekman, P. (1972). Universals and cultural differences in              Recent findings and future trends. Journals of
   facial expressions of emotion. In J. Cole (Ed.), Nebraska          Gerontology Series B: Psychological Sciences and Social
   Symposium on Motivation, 1971 (Vol. 19). Lincoln:                  Sciences, 65B.2, 135-44.
   University of Nebraska Press.                                    Trueswell, J.C., Sekerina, I., Hill, N., & Logrip, M.L.
Fazio, R.H. (2001). On the automatic activation of                    (1999). The kindergarten-path effect: studying online
   associated evaluations: An overview. Cognition and                 sentence processing in young children. Cognition, 73, 89-
   Emotion, 15, 115–141.                                              134.
Hanna, J., & Brennan, S. (2007). Speakers’ eye gaze
   disambiguates referring expressions early during face-to-
                                                                1981

