UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Model of General Rule Learning with Unnatural Classes
Permalink
https://escholarship.org/uc/item/41m3q1c5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)
Author
Calamaro, Shira
Publication Date
2013-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         A Computational Model of General Rule Learning with Unnatural Classes
                                          Shira Calamaro (shira.calamaro@yale.edu)
                                             Department of Linguistics, 370 Temple Street
                                                       New Haven, CT 06511 USA
                              Abstract                                classes over unnatural classes may be explained by the
                                                                      inability to generalize over certain classes of segments. This
   This paper presents the results of a computational model of
   generalized phonological rule learning (Calamaro and Jarosz,       preference is realized in the model through a generalization
   2012), which is used to model experimental studies on the          bias, or preference for general rules. The learnability of
   learning of phonotactic patterns governed by natural and           some types of unnatural rules is also explained by the
   unnatural classes. I focus on two papers with conflicting          model, which can identify the robust patterns present in the
   results on the learnability of natural and unnatural rules.        data and distinguish between them through the interaction of
   Saffran and Thiessen (2003) find that a phonotactic pattern of     complexity and competition.
   positional voicing restrictions governed by a natural class of
   segments is learned by infants, but a similar pattern governed
   by an unnatural class is not learned. In contrast, Chambers,
                                                                                              Background
   Onishi, and Fisher (2003) find that infants can learn a            In their artificial-language experiments on phonological
   phonotactic pattern governed by an unnatural class of              acquisition, Saffran and Thiessen (2003) attempt to find the
   segments. The computational model presented in this paper is       types of patterns that are learnable by infants and identify
   able to account for these seemingly conflicting results,           the types of pattern that are more difficult to learn. 9-month-
   explaining both the learnability and unlearnability of rules       old infants were trained on a set of language data exhibiting
   governed by unnatural classes.
                                                                      the specified pattern. They were then tested using the head-
   Keywords: Linguistics; Phonology; Language Acquisition;            turn preference procedure, in which listening times for
   Computational Model; Statistical Learning                          familiar and novel words were measured. A significant
                                                                      difference in listening times would indicate which patterns
                         Introduction                                 had been learned by the infants after a brief training period.
Many artificial-language experiments have explored the                  In one experiment, they looked at the learning of voicing
learnability of sound patterns in acquisition and how these           restrictions in different positions of a syllable. Using two
may reflect biases in the phonology. The interpretation of            conditions, they restricted the types of consonants that could
experimental results can often be attributed to a number of           appear in the onset, the position preceding the vowel, and
different theoretical models. In this paper, I explore the            the coda, the position following the vowel. In one condition,
results of experimental studies on the learnability of                the onset position was restricted to the set of voiceless stops
unnatural rules and provide an analysis in a computational            [p,t,k], while the coda was restricted to voiced stops [b,d,g].
model.                                                                For example, words of the form pibtad were permitted, but
   Experiments in language acquisition have found                     not *bipdat. In the second condition, the restrictions were
conflicting results in the learnability of unnatural sound            reversed, with voiced stops in the onset and voiceless stops
patterns. In one study, Saffran and Thiessen (2003) found             in the coda. The sets [p,t,k] and [b,d,g] each form a natural
that infants were able to learn phonotactic voicing                   class of stop consonants because they can be distinguished
restrictions governed by a natural class of segments, but             using a single feature, [voice]. The results showed that
were unable to learn the same pattern when governed by an             infants were indeed capable of learning this distinction, with
unnatural class. In contrast, Chambers, Onishi, and Fisher            a significant difference in looking times between familiar
(2003) have shown that phonotactic patterns governed by               and novel words. In this experiment, the infants were able to
unnatural classes may be learnable.                                   learn a phonotactic pattern governed by a natural class of
   In this paper, I present a computational model of                  segments.
generalized rule learning (Calamaro and Jarosz, 2012),                  The next experiment investigated the learning of voicing
which offers an account of the results found by Saffran and           restrictions of unnatural classes in different prosodic
Thiessen (2003) and Chambers et al. (2003). This model                positions. Unlike the previous experiment, in which the sets
uses statistical regularities in the input, as well as linguistic     [p,t,k] and [b,d,g] could be distinguished by the [voice]
filters, to learn phonological alternations. It encodes these         feature, the sets used in the second experiment cannot be
patterns as generalized rules over natural classes of                 distinguished by any feature, making them unnatural. In one
segments, which can explain the inability to generalize               condition, [p,d,k] appeared in the onset while [b,t,g]
certain patterns that do not fall into a natural class.               appeared in the coda. The reverse was true in the second
   The results of these computational experiments will help           condition, with [b,t,g] appearing in the onset and [p,d,k]
to further clarify the nature of the results of the acquisition       occurring in the coda. The experimental results differed,
studies. The preference for patterns governed by natural              with no significant difference in looking times between the
                                                                      familiar and novel words. In the experiment, the infants
                                                                  269

failed to learn a phonotactic pattern governed by an                 an intervening segment in the phonetic space based on their
unnatural class of segments.                                         features, which are represented by a vector with values for
   Overall, the Saffran and Thiessen (2003) results show that        place, sonority, voicing, nasality, rounding, and vocalic. 2
infants are capable of learning patterns over a set of               The second filter removes pairs in which the allophone is
segments that form a natural class and can be described by a         not more similar to its context than the default segment.
minimal number of features, and it is more difficult to learn        Overall, these filters are able to introduce phonological
a pattern over an unnatural class of segments which cannot           knowledge not available to a purely statistical model.
be described by any set of features.                                    The GRL model also maintains use of KL-divergence,
   In contrast, Chambers et al. (2003) have shown that               though the formulation is somewhat changed, with the new
infants are capable of learning phonotactic patterns                 calculation shown in (1) :
governed by an unnatural class of segments. In this                     (1)
experiment, 16.5-month-old infants were tested using a
head-turn preference test. The training data consisted of                      Where:
artificial CVC words in which the set of segments [b, k, m,
t, f] and [p, g, n, Ê§, s] were restricted by position, appearing
in either the onset or coda. There is no combination of                        and
features that can be used to define these segments, so these
sets of segments constitute an unnatural class. In the testing       The equation in (1) is used to calculate scores for pairs of
phase of the experiment, infants were able to distinguish            alternating pairs of segments at a context c, defined as the
between legal and illegal words, meaning they had learned            following segment. The use of KL-divergence to find
the phonotactic pattern they had been trained on.                    alternating pairs captures the intuition that segments which
   The results found by Chambers et al. (2003) seem to be in         have highly distinct distributions in the data are likely to
conflict with the results found by Saffran and Thiessen              governed by some phonological or phonotactic rule.
(2003) on the learnability on rules governed by unnatural               The model creates general rules by merging alternating
classes. In addition to the distinction between natural and          pairs which undergo an identical structural change, as
unnatural classes, a learning model should also be able to           represented by a feature vector. For example, the alternating
account for these different results on the learnability of           pair (d,t) has a structural change of [0,-1,-1,0,0,0],
unnatural classes. In the next section, I present such a model       calculated as the difference between the feature vector of
to account for these results.                                        segments t: [4,1,0,0,0,0] and d: [4,2,1,0,0,0]. This difference
                                                                     vector represents the devoicing pattern of the (d,t) pair.
          Generalized Rule Learning Model                               The scores of alternating pairs as calculated in (1) are
The Generalized Rule Learning model (GRL: Calamaro and               summed for all pairs whose change in features is the same,
Jarosz 2012) presented here is used to test the learning of          giving a contextualized rule score. Each contextualized rule
the acquisition data in a computational setting. The GRL is a        is represented by a structural change vector, the context in
statistical model with linguistic constraints and generalized        which it occurs, and a rule measuring its strength. The
rule learning. The generalization component of the model is          calculation of contextualized rule scores is shown in (2):
motivated by experimental evidence showing that infants              (2)
are able to generalize rules using features (Maye, Weiss, and
Aslin 2008; CristiÃ¡ and Seidl 2008). Given a set of
segmented data, the model learns general rules for
alternations in the data at the contexts in which they occur,           The output of the formula in (2) is a set of rules which
as well as a score reflecting the strength of the rule. The          each apply at a single context. Many phonological rules
original goal of the GRL model was the learning of                   apply at multiple, related contexts, such as a vowel
alternations, such as word-final devoicing in Dutch, but in          nasalization rule that applies in the context of all nasal
this paper it is applied to static phonotactic patterns. The         segments. The contextualized rule scores can be further
GRL model is based on an earlier model (PLND:                        generalized, by merging rules whose contexts are
Peperkamp, Le Calvez, Nadal, and Dupoux, 2006) for                   phonologically related to each other and the change
learning pairs of alternating segments by calculating their          undergone by the rule. The formal calculation of the rule
statistical distribution in the data with an application of KL-      merging is defined in (3):
divergence (Kullback and Leibler, 1951) and linguistic                  (3)
filters.
   The GRL model maintains the use of the two linguistic
filters1 from PLND, which remove spurious pairs that
should not be considered as alternating segments for
linguistic reasons. The first filter removes pairs which have
   1                                                                    2
     See Appendix for formal definitions of the two filters.              See Appendix for the set of phonetic features.
                                                                 270

  Shared Change Condition (SCC): To merge, contexts                 alphabet with four vowels [a, i, o, u], three voiceless stops
must share feature values for any non-zero values in .              [p, t, k], and three voiced stops [b, d, g]. In condition a,
  Shared Values Condition (SVC): To merge, contexts must            voiced stops were restricted to coda position and voiceless
not differ along more than one feature.                             stops were restricted to onset position. The opposite was
                                                                    true for condition b, with voiceless stops occurring in coda
The formula in (3) is used to calculate the score of a              position and voiceless stops occurring in onset position.
generalized rule as the sum of all rules whose contexts meet           While the model does not specifically reference syllable
two conditions: the Shared Change Condition (SCC) and the           structure, successful learning of this data would find a rule
Shared Values Condition (SVC). Like the linguistic filters          of voicing/devoicing in the word-final context and before
from Peperkamp et al (2006), the merging conditions                 voiceless/voiced consonants.
provide linguistic information in assigning classes of sounds
that pattern together. The SCC requires that contexts must          Results
be related to the rule change in the same way by restricting        The results from experiment 1 are shown in Figure 1,
merging to contexts which share non-zero values of the rule         reflecting the highest scoring rules found by the model.
vector. The SVC requires that contexts be related to each
other by restricting merging to contexts which only differ                    Condition a                          Condition b
along a single feature dimension, thus approximating a                     35                                 35
natural class. The merging of contextualized rules into                    30                                 30
generalized rules can capture generalizations about the data               25                                 25
as well as assign increased scores to more robust rules                    20                                 20
                                                                           15                                 15
occurring in a set of related contexts.                                                                       10
                                                                           10
  This model learns generalized rules as a difference vector                5                                   5
of features, a set of contexts of application, and a score                  0                                   0
indicating the goodness of the rule. The rules learned by the
model will need to be interpreted somewhat differently from
the results of the Saffran and Thiessen (2003) and Chambers
et al. (2003) experiments, which measured successful
learning by significant differences in looking times in a
head-turn test. Instead, this model will need to look for rules
which reflect the regularities found in the training data.
Additionally, the model looks at alternations conditioned by                              Figure 1: Exp. 1 results
contexts defined as following segments and does not have
access to syllabic structure. Due to these limitations of the          Each bar in Figure 1 shows the score of a generalized
model, this discussion will focus on the results as they relate     rule. In Condition a, the highest scoring rule is the word-
to the learning of the pattern in coda position, which is           final voicing rule, (# [0,1,1,0,0,0]), where # represents the
defined by the following segment. With these restrictions in        word-final context and [0,1,1,0,0,0] represents the structural
mind, successful replication of results in the model will           change vector. The two non-zero values in the vector
mean the learning of a word-medial and word-final                   indicate a change in the sonority and voicing features in
voicing/devoicing rule in Experiment 1, no successful               pairs such as (t,d).3 The reverse rule is found in Condition b,
learning of any such a rule in Experiment 2, and the learning       with a structural change vector [0,-1,-1,0,0,0] indicating
of meaningful rules in Experiment 3.                                devoicing in pairs such as (d,t).
                                                                       In each of the two conditions, the highest scoring rule is
   Experiment 1: Learning rules governed by                         the desired voicing or devoicing rule. This rule reflects the
                                                                    change in voicing of the stops in coda position in the
                       natural classes
                                                                    training data. The voicing/devoicing rule is quite robust in
In Experiment 1, I replicate the results of an experiment by        each of the two conditions, scoring much higher than the
Saffran and Thiessen (2003), in which infants were able to          next highest scoring rule. A similar rule for word-medial
learn voicing restrictions by position.                             codas is also found, which is the voicing/devoicing rule
                                                                    occurring in {p,t,k} or {b,d,g} contexts.
Method                                                                 A number of spurious rules were also found by the model.
The Generalized Rule Learning Model, as described in the            These rules reflect a change in place of articulation, shown
previous section, was used.                                         as fronting and backing rules. While these rules are not
                                                                    desired, they do reflect a generalization in the data, namely,
Data                                                                a possible alternation between pairs like [p,t] or [t,k], in
The same training data from Saffran and Thiessen (2003)             which the segments differ only in place of articulation.
was used. Each condition in the training data consisted of 30       These spurious rules are likely an artifact of the small
unique CVCCVC words for each condition, made from an                   3
                                                                         See Appendix for the full set of feature values.
                                                                271

segment inventory, making a minor statistical regularity             place of articulation. This rule would account for a possible
appear to reflect a possible alternation. In artificial language     alternation between pairs such as (p,t) or (d,g), which can be
learning, these types of spurious statistical regularities have      generalized from statistical regularities in the data.
the potential to affect the results to a greater extent than in         The desired rules of voice alternations receive lower
natural language learning, as will be seen in Experiment 3.          scores than some of the spurious rules. The overall strength
  Overall, the results in Experiment 1 show learning of the          of these desired rules has decreased, with the weight of each
phonotactic pattern, aligning with the results found by              voicing/devoicing rule being split into two lower weighted
Saffran and Thiessen (2003). The model successfully                  rules. The reason for this decrease in the score is that the
learned the voicing restrictions when they were governed by          patterns cannot be fully generalized because they belong to
a natural class of segments.                                         an unnatural class. In experiment 1, the desired voicing rules
                                                                     were supported by three pairs of segments, one for each
 Experiment 2: Failure to learn rules governed                       place of articulation. In this experiment, the scores were
                   by unnatural classes                              split between two separate rules, each supported by one or
                                                                     two pairs of segments, (t,d) or (b,p) and (g,k).
In experiment 2, I replicate the results of a second
                                                                        Both factors of decrease in rule rank and loss of rule
experiment from Saffran and Thiessen (2003), in which
                                                                     strength contribute to the increased difficulty of learning the
infants were not able to learn phonotactic restrictions of
                                                                     phonotactic pattern in experiment 2. This difficulty in
unnatural classes of segments which are specified by voice
                                                                     learning is a desired result because infants failed to learn
and place of articulation.
                                                                     this same pattern in an experimental setting (Saffran and
                                                                     Thiessen 2003).
Method
                                                                        In this case, the unnatural voicing pattern was not the
The Generalized Rule Learning Model, as used in the                  most robust pattern in the data. The model found other
previous experiment.                                                 patterns which were generalizable from the given data,
                                                                     obscuring the desired patterns. From this result, a prediction
Data                                                                 of the model is that it would be able to learn a rule governed
The same training data from the Saffran and Thiessen                 by unnatural classes, if the data did not contain any other
(2003) experiment was used. The training data consisted of           patterns which could be inferred. Such a case is used by
30 CVCCVC words in each condition with the same                      Chambers et al. (2003), which will be shown in the
alphabet as experiment 1. In condition a, the set of coda            following experiment.
consonants was [b, t, g] and the set of onset consonants were
[p, d, k]. In condition b the voicing specifications were                Experiment 3: Learning rules governed by
reversed, with codas [p, d, k] and onsets [b, t, k].                                       unnatural classes
                                                                     In a final experiment, I run the GRL model on the data from
Results
                                                                     Chambers et al. (2003), in which infants were able to learn
In Exp. 2, the model failed to learn voicing restrictions            phonotactic patterns governed by an unnatural class of
governed by unnatural classes. These results are shown in            segments.
Figure 2, with the highest scoring rules represented.
                                                                     Method
      35 Condition a                   35    Condition b             The Generalized Rule Learning Model, as used in the
      30                               30                            previous experiments.
      25                               25
      20                               20                            Data
      15                               15
                                       10                            The data used in this experiment were replicated from
      10
       5                                 5                           Chambers et al. (2003). A set of CVC words were creating
       0                                 0                           using two groups of consonants belonging to an unnatural
                                                                     class: [b, k, m, t, f] and [p, g, n, Ê§, s]. The onsets were
                                                                     drawn from one group and codas from another, creating a
                                                                     phonotactic pattern governed by an unnatural class of
                                                                     segments.
                                                                     Results
                     Figure 2: Exp. 2 results                        While the data could not be generalized, the patterns were
                                                                     learnable as separate rules, as shown in Figure 3:
  The voicing and devoicing rules are no longer learned as
the highest scoring rules, as seen in Figure 2. The highest
scoring rule is now a spurious rule reflecting a change in the
                                                                 272

                         Experiment 3                                    governed by an unnatural class is not. Specifically, infants
 25                                                                      can learn patterns which occur over a set of segments that
                                                                         all agree in voicing and differ in place, they cannot learn
 20                                                                      patterns which occur over a set of segments that differ in
 15                                                                      both place and voicing.
 10                                                                         The GRL finds an asymmetry in the learning of natural
                                                                         and unnatural classes due to an inherent bias in the
   5                                                                     generalization mechanism. Generalized rules receive higher
   0                                                                     scores from the model because they have support from more
           Backing: # [1,0,0,0,0,0]
         Fronting: # [-2,0,0,0,0,0]                                      pairs of segments. The strength of general rules is computed
           Voicing: # [0,1,1,0,0,0]
       Devoicing: # [0,-1,-1,0,0,0]                                      by summing the scores of rules governing alternations
        Fortition: # [-1,-2,0,0,0,0]                                     between a single pair. Therefore, the more pairs of segments
           Backing: # [3,0,0,0,0,0]
          Lenition: # [0,2,0,0,0,0]
         Fronting: # [-3,0,0,0,0,0]                                      contributing to a general rule, the higher its score will be. In
           Backing: a [1,0,0,0,0,0]
         Fronting: a [-2,0,0,0,0,0]                                      the case of the Saffran and Thiessen (2003) data, the rules
           Voicing: a [0,1,1,0,0,0]
       Devoicing: i [0,-1,-1,0,0,0]
                                                                         governed by natural classes are supported by more segments
         Fortition: i [-1,-2,0,0,0,0]                                    than the unnatural ones. This inherent generalization bias
            Backing: i [3,0,0,0,0,0]
          Lenition: a [0,2,0,0,0,0]                                      assigns higher scores to the natural rules in Exp.1 than the
         Fronting: a [-3,0,0,0,0,0]
                                                                         unnatural rules in Exp. 2.
                                                                            The asymmetry in the learning of natural and unnatural
                    Figure 3: Exp. 3 results                             rules has previously been explained by a Complexity Bias
                                                                         (Moreton and Pater, 2011). Under this account, the more
The rules shown in Figure 3 are striking due to the                      complex set of features needed to describe unnatural classes
uniformity of the data. While the segments could not be                  makes the learning of unnatural patterns more difficult.
generalized by position, the model was able to find                      Natural classes, which can be described with fewer features,
relationships among between-group segments. For example,                 can be learned more easily.
the (b, p) pair is reflected by the word-final devoicing rule               The generalization mechanism in the GRL accounts for
(# [0,-1,-1,0,0,0]), while the (k, g) pair is reflected by the           the same patterns as the Complexity Bias, but for a different
word-final voicing rule (# [0,1,1,0,0,0]).                               reason. While the Complexity Bias asserts that unnatural
  With a one-to-one mapping of segments to learned rules,                rules are more difficult to learn because they require the
we would expect five rules, but instead find eight. While                encoding of additional feature values, the GRL attributes
each segment belongs to at least one rule, some segments                 this asymmetry to weaker statistical regularities due to the
are learned as multiple rules. For example, âpâ is found in              more complex data. This prediction of the GRL can be seen
both the devoicing rule (# [0,-1,-1,0,0,0]) with the pair (b,p),         by the difference in rules scores in Exp. 1 versus Exp. 2.
but also in the fortition rule (# [-1,-2,0,0,0,0]) with (f,p).              The GRL model has an additional property that interacts
  While some of these are the same rules which were                      with complexity: competition. In the results from Exp.1, the
unlearnable in Experiment 2, namely voicing and devoicing,               desired pattern was learned because of the high score
a potential difference here is the lack of interference from             relative to other rules. In Exp. 2, the lower scoring unnatural
spurious rules. While in the case demonstrating                          rules were dominated by competing spurious rules,
unlearnability, the desired rules were dominated by spurious             interfering with their learnability. This interaction between
rules. In this experiment, the desired rules were the highest            complexity and competition allows the GRL to make
scoring rules.                                                           additional predictions beyond complexity alone, which will
                                                                         play a role in the learning of different types of unnatural
                        Discussion                                       classes.
The computational experiments presented in this paper seek               Unnatural vs. Unnatural Classes
to address two fundamental questions about the learnability
of phonotactic patterns: Why are patterns governed by                    In Experiments 2 and 3, the learning data contained
natural classes easier to learn than those governed by                   phonotactic patterns governed by unnatural classes. In the
unnatural ones? How can we explain results in which                      original experimental setting, infants did not learn the
unnatural patterns are learnable? The first question is                  unnatural pattern in Experiment 2 (Saffran and Thiessen
addressed by comparing the results of Experiments 1 and 2,               2003), but did learn the pattern in Experiment 3 (Chambers,
and the second by comparing the results of Experiments 2                 et al. 2003). Likewise, the GRL found a similar difference in
and 3.                                                                   the learnability of the two unnatural patterns, as shown in
                                                                         this paper. The distinction to be made between these two
Natural vs. Unnatural Classes                                            unnatural patterns lies in the nature of the data.
                                                                            Both experiments presented artificial data in which
In Experiments 1 and 2, the GRL replicated the results
                                                                         syllable positions were restricted to a specific set of
found by Saffran and Thiessen (2003), that a phonotactic
                                                                         consonants. In Saffran and Thiessen (2003) the sets were [p,
pattern governed by a natural class is learned, while one
                                                                   273

d, k] and [b, t, g]; in Chambers et al. (2003) they were [b, k,     Future work will explore other predictions made by the
m, t, f] and [p, g, n, Ê§, s]. While both sets of data are           model and extensions needed to account for additional data.
unnatural to some extent, there is a striking difference in the
segment inventories of the two experiments.                                                   Appendix
   While the pattern presented in Saffran and Thiessen
(2003) is unnatural, the segment inventory is well-balanced         Linguistic filters (Peperkamp et al. 2006)
among the feature set it uses, with a voicing distinction           Allophonic distributions of sa and sd are spurious if:
present for each place of articulation. In contrast, the
segment inventory of Chambers et al. (2003) is not as
balanced, with a mix of voicing, place and sonority
                                                                    With vi(s) the ith component of the vector representation of
distinctions that do not apply across all pairs of segments.
                                                                    s.
For example, there is a voicing distinction for the pairs (p,b)
                                                                    Allophonic distributions of sa and sd are spurious if:
and (k,g), but there exists no pair (t,d).
   The effects of the overall naturalness of the data are seen
directly in the computational results of Experiments 2 and 3.
In Experiment 2, the more balanced data allowed the GRL
to make a number of spurious generalizations, obscuring the         Feature values
robustness of the desired unnatural rules. In Experiment 3,         Segments are represented as feature vectors with the
the less balanced data could not be generalized by the              following values:
model, leaving the set of desired unnatural rules as the most          Place: bilabial 1, labio-dental 2, dental 3, alveolar 4, post-
robust in the data.                                                 alveolar 5, palatal 6, velar 7, uvular 8, glottal 9
   In the distinction between these two sets of unnatural              Sonority: voiceless stop 1, voiced stop 2, voiceless
patterns, the GRL is better able to predict these results than      fricative 3, voiced fricative 4, nasal 5, lateral 6, rhotic 7,
a model using complexity alone. The Complexity Bias                 glide 8, high vowel 9, mid vowel 10, low vowel 11
(Moreton and Pater 2011) predicts difficulty in the learning           Voicing: voiceless 0, voiced 1
of both types of unnatural patterns, but would predict even            Nasality: oral 0, nasal 1
greater difficulty in Exp. 3 due to the greater number of              Rounding: unrounded 0, rounded 1
features needed to describe the unrelated set of segments.             Vocalic: non-vowel 0, vowel 1
However, the experimental evidence shows the opposite is
true, with the data in Exp. 3 being learned more easily. The                            Acknowledgments
predictions of the GRL align with the experimental evidence
due to the interaction of competition and complexity in the         Many thanks for feedback from Gaja Jarosz, CLAY Lab,
model. The unnatural pattern in Exp. 3 is learned more              audiences at LSA 2013, and an anonymous reviewer.
easily than that in Exp.2 because the desired rules are not in
competition with any high scoring spurious rules as is the                                   References
case in Exp. 2.                                                     Calamaro, S. and Jarosz, G. (2012). A computational model
                                                                       of general rule learning for phonological alternations. Ms.
                         Conclusion                                 Chambers, K.E., Onishi, K.H., and Fisher, C. (2003).
The GRL is able to model the results of experimental data              Infants learn phonotactic regularities from brief auditory
showing the learning of phonotactic patterns by infants. It            experience. Cognition 87 B69-B77.
can account for the preference for learning natural rules over      ChristiÃ¡, A. and Seidl, A. (2008). Is infantsâ learning of
unnatural ones, as well as the distinction between the                 sound patterns constrained by phonological features?
learnability of different patterns of unnatural classes. This          Language Learning and Development 4(3), 203-227.
preference for natural classes is an inherent property of the       Kullback, S. and Leibler, R. (1951). On information and
model, due to the rule generalization component. While the             sufficiency. Annals of Mathematical Statistics 22, 76-86.
generalization component of the model does facilitate the           Maye, J., Weiss, D.J., and Aslin, R.N. (2008) Statistical
learning of natural rules, it does not exclude the learning of         phonetic learning in infants: Facilitation and feature
rules governed by unnatural classes. Indeed, rules governed            generalization. Developmental Science(11)1, 122-134.
by unnatural classes were learned by the model, when there          Moreton, E. and Pater, J. (2011). Learning artificial
were no other more robust rules in the data.                           phonology: A review. Ms.
   These experiments provide some promising results for the         Peperkamp, S., Le Calvez, R., Nadal, J.P., and Dupoux, E.
GRL model, with its ability to account for attested cases of           (2006). The acquisition of allophonic rules: Statistical
phonological learning. While there remains a possibility that          learning with linguistic constraints. Cognition 101(3),
differences in infant learning can be attributed to differences        B31-B41.
in experimental methodologies, these results show                   Saffran, J. and Thiessen, E. (2003). Pattern Induction by
compelling evidence for further exploration of this topic.             Infant Language Learners. Developmental Psychology
                                                                       Vol. 39, No. 3, pp. 484-494.
                                                                274

