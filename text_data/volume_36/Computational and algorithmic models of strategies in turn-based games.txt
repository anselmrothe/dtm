UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Computational and algorithmic models of strategies in turn-based games
Permalink
https://escholarship.org/uc/item/6pd0k6bk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Bergwerff, Gerben
Meijering, Ben
Szymanik, Jakub
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Computational and algorithmic models of strategies in turn-based games
                                                            Gerben Bergwerff
                                       Institute of Artificial Intelligence, University of Groningen
                                                Ben Meijering (ben@meijering.com)
                                       Institute of Artificial Intelligence, University of Groningen
                                         Jakub Szymanik (jakub.szymanik@gmail.com)
                               Institute for Logic, Language and Computation, University of Amsterdam
                                           Rineke Verbrugge (L.C.Verbrugge@rug.nl)
                                       Institute of Artificial Intelligence, University of Groningen
                                          Stefan M. Wierda (wierda.stefan@gmail.com)
                                       Institute of Artificial Intelligence, University of Groningen
                              Abstract                                    can control the order of reasoning required to play the game
                                                                          successfully by selecting the instances of the game.
   We study two different models of a turn-based game called                It has turned out in recent years that logic and the
   the Marble Drop Game, which is an experimental paradigm                computational sciences can help to delineate the complexity
   designed to investigate higher-order social reasoning. Our             of cognitive tasks, which in turn helps to explain human
   first model is a computational-level description of the game,
   associating cognitive difficulty of a game trial with its
                                                                          cognition in general, and human cognitive strategies in
   structural properties. Our second model is an algorithmic-             particular. Predictions based on computational analyses can
   level model postulating a forward reasoning plus back-                 be fruitfully compared with empirical evidence. For an
   tracking strategy for solving the game, rather than backward           overview of this emerging field of research, including
   induction as prescribed by game theory. Our experiment                 several examples of research on theory of mind combining
   shows that the algorithmic-level model is more predictive for          computational and empirical methods, see (Isaac, Szymanik,
   the participants’ reaction times. This research illustrates how        & Verbrugge, 2014). It appears that turn-taking games form
   various methods of logic and computer science may be used
   for building computational cognitive models.                           an especially successful application area in which to bring
                                                                          logic and computation to the lab (Szymanik, 2013).
   Keywords: cognitive difficulty; strategic games; higher-order            When analyzing cognition from a computational point of
   social reasoning; theory of mind                                       view, it is useful to distinguish the levels of analysis of the
                                                                          cognitive task at hand, as proposed by Marr (1983). In this
                          Introduction                                    paper, we investigate the cognitive task of making a
Theory of mind (ToM; Premack & Woodruff, 1978) is the                     decision in a particular turn-taking game. We will propose
ability to attribute beliefs, desires, and intentions to others.          an analysis on Marr’s computational level, which concerns
It is a widely studied phenomenon in the fields of                        the problem solved or the function computed, as well as an
psychology, neurosciences, philosophy, and logics. Despite                analysis on the algorithmic level, which concerns the
the wide interest in ToM, relatively little research has                  particular way of achieving a solution to the problem.
concentrated on the complexity of the underlying cognitive                  In the current paper, we will focus on the marble drop
strategies (Apperly, 2011).                                               game—a two-player game in which the players have to take
   We speak of first-order reasoning in ToM when a person                 into account the actions, beliefs and goals of the other.
attributes a simple belief, desire, or intention to someone
else. For example, imagine Ingrid and Rob interacting. If                 The marble drop game
Rob thinks “Ingrid knows that it is snowing”, he makes a                  The marble drop game is a strategic two-player game that
first-order ToM attribution. However, if the situation                    has been used to study theory of mind (Meijering, Van Rijn,
becomes more complex, first-order ToM reasoning is not                    Taatgen, & Verbrugge, 2011; Meijering, van Rijn, Taatgen,
sufficient. When Ingrid thinks “Rob knows that I know that                & Verbrugge, 2012; Raijmakers, Mandell, van Es, &
it is snowing”, she makes a second-order attribution.                     Counihan, 2014). Just like well-known games such as poker
   One way of studying the cognitive basis of ToM in a                    and bridge, marble drop is turn-based. However, marble
controlled experimental setting is the use of competitive and             drop is a perfect information game, in contrast with poker
collaborative games. By investigating the underlying                      and bridge, in which players cannot see the others’ cards. In
strategies used during these games, one can shed light upon               the game, each player is assigned a color (orange or blue).
the underlying cognitive processes involved in this game—                 Then, a marble is dropped onto trapdoors that are controlled
including ToM reasoning. In these games, the experimenter                 by one of the players: If the trapdoor is blue, the blue player
                                                                      1778

controls the trapdoor; if the trapdoor is orange, the orange          steps, where each step consists of attending to one pay-off.
player controls the trapdoor. A trapdoor leads either to              In the example game of Figure 1, the orange player would
another trapdoor or to a bin containing marbles. Each bin             perform backward induction as follows: check and compare
contains a number of blue and orange marbles1. The number             the numbers of orange marbles in bins 3 and 4 (two steps);
of marbles of the player’s own color determines his pay-off.          the number in bin 4 is higher, so now check and compare
In the marble drop games discussed in this paper, there are           the numbers of blue marbles in bins 2 and 4 (two steps); the
always four bins and four possible pay-offs, i.e., {1, 2, 3, 4}.      number in bin 2 is higher, so now check and compare the
The goal of this game for a player is to obtain as many               numbers of orange marbles in bins 1 and 2 (two steps); the
points as possible, irrespective of the score of the other            number in bin 1 is higher, so open the left-hand side of
player.                                                               trapdoor A. The total number of steps is 2+2+2=6. It is not
  An example trial of the marble drop game is shown in                hard to see that this is irrespective of pay-off structure.
Figure 1. In this particular trial, the blue (dark grey) player’s
highest number of marbles is in bin 3; for the orange (light
grey) player, the highest number of marbles is in bin 4.
                                                                           Figure 2: Pay-off structures of two types used in the
                                                                           experiment. The left and right numbers in the leaves
                                                                          correspond to the pay-off of the player and opponent,
                                                                          respectively. The numbers after S, T, and U represent
                                                                         whether it is the player’s turn (1) or the opponent’s (2).
                                                                      However, backward induction is not the only possible
                                                                      reasoning strategy. Meijering et al. (2012) investigated
                                                                      whether participants used this backward induction strategy,
                                                                      which is indeed in general the most optimal way to play the
                                                                      marble drop game, or if participants rather used the so-
                                                                      dubbed forward reasoning plus backtracking strategy. See
                                                                      the next section for an explanation how that strategy works
    Figure 1: A trial of the marble drop game that requires           for the example games represented in Figure 2.
 second-order reasoning: The orange (light grey) player has              Forward reasoning plus backtracking appears at first sight
   to reason about which side of trapdoor C the blue (dark            to be a suitable candidate because of the prevalence of a
   grey) opponent believes that the orange player himself             forward causal or temporal direction in human reasoning.
                         intends to open.                             Moreover, for most pay-off structures that can occur in
                                                                      theory, the solution can be found with forward reasoning
Backward induction, the process of reasoning backwards                plus backtracking in a smaller number of steps than when
from the end to determine a sequence of optimal actions,              backward induction were used (see Szymanik, Meijering,
will yield the optimal solution for this game (Aumann,                and Verbrugge, 2013 for a simulation showing this). For
1995). Although there is a lively debate among game                   example, if bin 3 had contained 4 blue and 4 orange
theorists about the question whether common knowledge of              marbles, the forward reasoning plus backtracking algorithm
rationality in a game of perfect information entails the              would only have taken four steps: “attend the number of
backward induction solution (see Ghosh et al. 2014 for an             marbles in bin 1, 2, 3 consecutively (three steps) and
overview), game theory textbooks generally propose                    conclude that bin 3 contains the maximum possible number
backward induction as the standard solution (e.g., Osborne            of 4 blue marbles; then check that it also contains the
& Rubinstein, 1994). For marble drop trials with four bins            maximum number, 4, of orange marbles (fourth step), so
and three trapdoors that have been used in the experiment,            choose the right-hand side of trapdoor A”.
the backward induction solution will always be found in 6                In their study, Meijering et al. (2012) recorded eye-
                                                                      fixations while participants were playing the marble drop
  1                                                                   game. Next, they analyzed the fixation patterns and
     Note that in the original game, the hue of the color of the
marbles in the bin determined its payoff. However, for the            compared the found patterns to predicted patterns by either
convenience of the reader, we will use the number of marbles.         the backward induction strategy or the forward reasoning
                                                                  1779

                                                                                       i
plus backtracking strategy. The eye-fixation data suggested                  • In a Λ 1 tree, all nodes are controlled by Player i.
that participants were using the forward reasoning plus                             i
                                                                             • A Λk+1 tree, a tree of k-alternations for some k ≥ 0,
backtracking strategy more than backward induction.
                                                                                starts with a player I node.
Forward reasoning plus backtracking
As suggested by the name of the strategy, forward reasoning          Note that all 16 game trees corresponding to item types used
                                                                                                                            1
plus backtracking is a combination of forward reasoning and          in the experiments of Meijering et al. (2012) are Λ3 trees.
backward reasoning. In principle, forward reasoning alone
can yield a very fast solution if the highest value for the blue     Definition 2 A game T is generic, if for each player, distinct
player is in bin 1—there is no need for ToM reasoning in             end nodes have different pay-offs.
that case. However, all items used in the experiment of
Meijering et al. (2012) were carefully picked such that they         Note that all 16 item types in the experiments of Meijering
all required second-order ToM reasoning in order to obtain           et al. (2012) are generic games.
the highest possible pay-off. In these items, backtracking is
required to predict the succeeding action of the opponent in         Definition 3 Suppose i ∈ {1,2}. If T is a generic game tree
order to determine whether the highest possible pay-off (4)          with the root node controlled by Player 1 and n is the
is accessible. A player who employs this strategy starts at          highest possible pay-off for Player 1, then T −is the minimal
the top trapdoor and tries to find out which trapdoor to open        sub-tree of T containing the root node and the node with
to obtain the highest pay-off, and then uses backward                pay-off n for Player i.
reasoning to find out whether that bin is reachable.                                                    1
   Szymanik et al. (2013) investigated the use of the forward        For example, consider both Λ3 trees from Fig. 2. Taking the
reasoning plus backtracking strategy by looking at the               minimal sub-trees containing the root node and the node
                                                                                                               1
reaction times obtained by Meijering et al. (2012).                  with pay-off 4 for Player 1 yield a Λ3 sub-tree for the item 1
Szymanik et al. used an ad hoc forward reasoning plus                          1
                                                                     and a Λ 2 sub-tree for item 3 (also see Szymanik et al., 2013
backtracking algorithm that had been used by Meijering et            for more explanations).
al. to create fixation-patterns for their eye-tracking analyses         The levels of lambda-difficulty of reduced trees T − (later
of the 16 item types used in their experiments. The                  “lambda-difficulty”) was indirectly tested by comparing
algorithm was then used to predict the number of decision            trials in which the highest pay-off was accessible to trials in
steps necessary for each type of trial. Szymanik et al. found        which the highest pay-off was not accessible (Szymanik et
that the number of steps as calculated by the algorithm              al., 2013). The rationale behind this test was that non-
indeed predicted the reaction times. In the current paper, we        accessible trials would generally include more alternations
present a more general forward reasoning plus backtracking           and would therefore be more difficult. Indeed, it turned out
algorithm that can be applied to any binary turn-taking              that the non-accessible trials took more time to complete
(extensive form) game tree (see Algorithm 1).                        than the accessible trials. However, Szymanik et al. did not
Structural Complexity of Game Trees                                  investigate the direct relation between the structural
                                                                     difficulty of the reduced trees and the reaction times.
Inspired by the work of Szymanik (2013) on the
                                                                        The current study builds on the work of Szymanik et al.
computational complexity of solving finite extensive-form
                                                                     (2013). Now for the first time we directly explore the use of
turn-taking games, Szymanik et al. (2013) investigated
                                                                     the lambda-difficulty of the reduced trees. In addition, we
possible computational-level explanations of the marble
                                                                     introduce an algorithmic-level explanation, namely the
drop task. They introduced a method to quantify the
                                                                     forward reasoning plus backtracking algorithm. The
difficulty of a marble drop trial that was constructed such
                                                                     predictive power of both the structural lambda-difficulty
that it is independent from particular algorithmic-level
                                                                     and forward reasoning plus backtracking strategy are
implementations. In their study, they proposed to look at the
                                                                     investigated. Thus, two hypotheses can be formulated.
structure of marble drop game trials. The main idea is to
quantify the complexity of the corresponding game trees
                                                                        H1: Is lambda-difficulty of reduced game trees predictive
with respect to the number of alternations between two
                                                                     for the reaction time of the marble drop game?
players. The intuition is that every alternation potentially
corresponds to the next level of higher-order ToM
                                                                        H2: Is the forward reasoning plus backtracking strategy
reasoning. Therefore, the difficulty of the game should
                                                                     predictive for the reaction time of the marble drop game?
increase with the number of alternations. Additionally, the
pay-off distribution must be taken into account, because                                     Implementation
many alternations may be simply ignored by the players if
reasoning about them clearly does not lead to better pay-            Forward reasoning + backtracking algorithm
offs. Let us give a reminder of the definitions.
                                                                     Algorithm 1 shows the implementation of the forward
                                                                     reasoning plus backtracking strategy as used in the current
Definition 1 Let us assume that players {1,2} strictly
                                                                     study. The algorithm computes the number of attentional
alternate in the game; Let player i ∈ {1,2}. Then:
                                                                 1780

steps (henceforth referred to as steps). The steps are             As an example, we will walk through two items that were
computed by counting the number of times a value gets              actually presented in the game experiment (see Figure 2).
attended. For example, comparing two values in bins of the         Item 1 At first, the player attends all leaves until she finds
marble drop game would be counted as two steps, because            her highest pay-off. The highest pay-off is in the fourth leaf
both values need to be attended for the comparison.                (i.e., the right leaf of U), hence it takes 4 steps. Next, the
                                                                   player needs to compare the pay-off of the opponent in this
      Algorithm 1. The following algorithm computes the            leaf with the pay-off of the opponent in the left leaf of T.
number of forward reasoning plus backtracking steps, where         Since there are two nodes to compare, this will take 2 steps.
 m is the number of nodes, Pn is the pay-off for the player at     Because the highest pay-off for the opponent is in the left
   node n, and On is the pay-off for the opponent at node n.       leaf of node T, the opponent will never let the first player
                                                                   reach her highest pay-off. Therefore, the highest pay-off is
Require: Pn ϵ {1 : m} and On ϵ {1 : m}                             not accessible. Finally, the player has to compare her pay-
Ensure: all Pn are unique and all On are unique                    off in the left leaf of T with the pay-off of the left leaf of the
01: n ← 1 {start with forward reasoning at the first node}         first node (i.e., node S). This comparison also requires
02: Steps ← 1                                                      attending to two nodes and thus takes 2 steps. This left leaf
03: while not max Pn do                                            has the highest possible pay-off. In total, the algorithm finds
04: n ← n + 1 and Steps ← Steps + 1 {While the highest             the highest possible solution in 8 steps.
       pay-off is not found continue with the next node}           Item 3 Again, the player attends all leaves until she finds
05: if max Pn and max On then                                      her highest pay-off. In this case, the highest pay-off is in the
06:       Steps ← Steps + 1 {Do not backtrack if the highest       second leaf (the left leaf of node T), and thus it takes 2 steps
          pay-off of both players is in this node}                 to find her highest pay-off. Next, the algorithm computes
07:       return Steps                                             the number of steps needed to find out whether the pay-off
08: end if                                                         is accessible. To that end, the pay-off in both leaves of node
09: end while                                                      U are compared—this also takes 2 steps. Then, the
10: High ← n {Remember the node with the highest pay-              opponent’s pay-off in the left leaf of node T is compared to
     off}                                                          the opponent’s pay-off in the right leaf of node U. This
11: Back ← m                                                       comparison also takes 2 steps. A rational opponent would
12: n ← m - 1 {Start backtracking at the last two nodes}           choose the left leaf at node T, because that is the highest
13: while Back ≠ High and n > 0 do                                 possible pay-off for the opponent. Thus, for the player, the
14: if trapdoor(n) = player then                                   highest pay-off is accessible. For this item, the algorithm
15:       if PBack > Pn then                                       computes for a total of 6 steps.
16:          Back ← Back {Node Back has the highest pay-
             off for the player, therefore the nodes can be        Output
             substituted by node Back}                             The two different proposed methods were used to describe
17:       else if PBack < Pn then                                  the difficulty of the game items as used in the data obtained
18:          Back ← n {Node n has the highest pay-off for the      by Meijering et al. (2012). The descriptions of the 16 items
             player, therefore the nodes can be substituted by     that were used in the current dataset are shown in Table 1.
             node n}
19:       end if                                                                      Experimental results
20: else if trapdoor(n) = opponent then                            Similarly to Szymanik et al (2013), the experimental data of
21:       if OBack > On then                                       Meijering et al. (2012) was used2. To recall, 23 psychology
22:          Back ← Back {Node Back has the highest score          students participated in the experiment. They were asked to
             for the opponent, therefore the nodes can be          play a marble drop game, as depicted in Figure 1, in which
             substituted by node Back}                             they only had to make the first decision (either stop and take
23:       else if OBack < On then                                  the pay-off or continue to the next trapdoor).
24:          Back ← n {Node n has the highest pay-off for the         Both the lambda-difficulty (abbreviated as Lambda) and
             opponent, therefore the nodes can be substituted      the number of steps as calculated by the forward reasoning
             by node n}                                            plus backtracking algorithm (abbreviated as Steps) were
25:       end if                                                   calculated for each trial that the participants had received
26: end if                                                         during the experiment.
27: n ← n - 1                                                         Next, linear mixed-effects models were used to
28: Steps ← Steps + 2 {There are two pay-offs being                investigate the predictive power of both the lambda-
       compared, hence this takes 2 steps}                         difficulty and the forward reasoning plus backtracking
29: end while                                                      strategy.
30: return Steps {Return the number of Steps for forward
reasoning plus backtracking}
                                                                      2
                                                                        Following Meijering et al. (2012), only reaction times from the
                                                                   second block were analyzed.
                                                               1781

                                                                      entered. Rationale behind this interaction is that we cannot
     Table 1: Number of steps when using forward reasoning            know what happens when an incorrect response is given,
plus backtracking (Steps) and the levels of lambda-difficulty         thus one could expect that Steps is not predictive for
  (Lambda) for all 16 items of the marble drop game in the            incorrect responses. To account for speed-up effects due to
     analyzed dataset. “Attainable” represents whether the            learning, the sequence in which trials were presented to the
    player’s highest possible pay-off 4 is in fact attainable.        participant was coded as the factor Trial. Thus, the fixed
                                                                      factors of the full model were entered as follows: Steps +
        Item3        Steps     Lambda (Λi )
                                           1
                                                  Attainable          Accuracy + Steps × Accuracy + Trial. Participant was
        1            8         3                  No                  entered as random factor. Automatic model selection selects
        2            8         2                  No                  the full model as the best model with an AIC of 954. The
        3            6         2                  Yes                 AIC of this model is lower than the AIC of the null-model
        4            8         2                  No                  thus the full model is a better model.
        5            8         2                  No                     The fixed factors of the selected model are listed in Table
        6            8         3                  No                  2. First, a main effect of Accuracy is found. The negative
        7            5         3                  Yes                 estimate β suggests that individuals are faster at correct
        8            6         2                  Yes                 trials. Furthermore, the Trial factor reveals the presence of a
        9            6         2                  Yes                 learning effect. The more trials an individual does, the faster
        10           8         3                  No                  he/she responds. The interaction effect Steps x Accuracy
        11           6         3                  Yes                 shows that Steps predicts the reaction times of marble drop
        12           5         3                  Yes                 games that are correctly solved. The lack of a main effect
        13           8         3                  No                  for Steps suggests that for incorrect trials, the forward
        14           6         3                  Yes                 reasoning plus backtracking does not predict reaction times.
        15           6         2                  Yes                 This is due to the algorithm’s incapability to predict errors.
        16           8         2                  No
                                                                            Table 2. The factors of the forward reasoning plus
Mixed-effect models                                                      backtracking model and the corresponding estimate (β), t-
The data was analyzed with linear mixed-effect models                                      statistics, and p-values.
using the LME4 package (Bates, Maechler, Bolker, &
Walker, 2013) available in R Project (Team R Core, 2013).                     Factor                   β         t          p
To find the best model, we formulated a full model based on                   Intercept              9.512      20.67    >0.001
theoretical assumptions. We then dredged the model by                         Steps                 -0.060      -0.87      0.387
systematically leaving out different fixed factors and                        Accuracy              -1.531      -3.27      0.001
interactions (Bartón, 2013). This dredge process resulted in
a subset of all possible models that the full model allowed                   Steps×Accuracy         0.209       3.00      0.003
for. Next, the Akaike information criterion (AIC; Akaike,                     Trial                 -0.007      -4.02    >0.001
1974) was calculated for each model, and the model with
the lowest AIC (i.e., the best model) was selected for further        Lambda-difficulty Lambda, Accuracy, Trial, and the
analyses. The AIC is suitable for this particular procedure,          interaction between Lambda and Accuracy were entered in
because it takes into account the trade-off between the               the full model, following the same rationale as in the before-
complexity of a model and its fit. Thus, we were able to              mentioned analyses. Thus, the fixed factors of the model
select the best model out of our subset of models.                    were entered as follows: Lambda + Accuracy + Lambda ×
Null-model In order to get a reference for the calculated             Accuracy + Trial. Participant was entered as random factor.
AIC for both the forward reasoning plus backtracking model            Automatic model selection preferred the model with factors
and the lambda-difficulty model, we calculated a null-model           Lambda + Trial to the full model. The simpler model has an
in which we only put the random effect of participant. The            AIC of 992, which is higher than the AIC of the forward
AIC of this null-model is 1056.                                       reasoning plus backtracking model, but lower than the AIC
   The p-values of the factors in the selected models were            of the null-model.
calculated by estimating the degrees of freedom                          The effects of the fixed factors for the Lambda + Trial
(Kuznetsova, Brockhoff, & Christensen, 2013).                         model are shown in Table 3. Both the main effects of Trial
Forward reasoning + backtracking First, Steps was                     and Lambda significantly predict the reaction time on a
entered in the model, because we hypothesized that Steps is           marble drop game. As with the forward reasoning plus
predictive of the reaction times. Secondly, Accuracy was              backtracking model, Trial can be interpreted as a learning
entered in the model. Accuracy was 0 or 1, corresponding to           effect. The effect of Lambda is more difficult to explain. If
an incorrect or correct response, respectively. Furthermore,          lambda-difficulty positively predicts reaction times (i.e., the
an interaction effect between Accuracy and Steps was                  more difficult a trial, the slower the participant), one would
                                                                      expect a positive estimate. However, the estimate of lambda
   3
     The corresponding trees can be found on the website
http://www.ai.rug.nl/SocialCognition/wp-content/uploads/trees.pdf
                                                                  1782

is negative, meaning that participants are faster in solving                               References
trials that are defined as difficult by the lambda-difficulty.
   Finally, when we compare the AIC scores of the lambda-          Apperly, I. (2011). Mindreaders: The Cognitive Basis of
difficulty model to the forward reasoning plus backtracking          "Theory of Mind". Hove etc.: Psychology Press.
model, the latter has a lower AIC score and thus best              Aumann, R.J. (1995). Backward induction and common
explains the data.                                                   knowledge of rationality. Games and Economic Behavior,
                                                                     8(1), 6-19.
 Table 3. The factors of the lambda-difficulty model and the       Bartón, K. (2013). MuMIn: Multi-model inference.
      corresponding estimate (β), t-statistics, and p-values.      Bates, D., Maechler, M., Bolker, B., & Walker, S. (2013).
                                                                     lme4: Linear mixed-effects models using Eigen and S4
        Factor                   β           t        p            Ghosh, S., Meijering B., Verbrugge, R. (in press). Strategic
        Intercept              9.684       84.38    >0.001           reasoning: Building cognitive models from logical
        Lambda                -2.263       -7.51    >0.001           formulas. Journal of Logic, Language and Information
                                                                   Isaac, A., Szymanik, J., & Verbrugge, R. (2014). Logic and
        Trial                 -0.008       -3.89    >0.001
                                                                     complexity in cognitive science. In A. Baltag, & S. Smets
                                                                     (Eds.), Johan van Benthem on Logical and Informational
                          Discussion                                 Dynamics (forthcoming). Trends in Logic book series,
                                                                     Berlin: Springer.
Overview                                                           Kuznetsova, A., Brockhoff, P. B., & Christensen, R. H. B.
We have investigated two cognitive models of playing a               (2013). lmerTest: Tests for random and fixed effects for
turn-based game called the Marble Drop Game. Our                     linear mixed effect models (lmer objects of lme4 package).
computational-level model is based on the logical                  Marr, D. (1983). Vision: A Computational Investigation into
description of the game trees in terms of player alternations        the Human Representation and Processing Visual
and the distribution of highest pay-off. Our more specific           Information. San Francisco, CA: W.H. Freeman.
algorithmic-level model proposes a concrete strategy that          Meijering, B., Van Rijn, H., Taatgen, N., & Verbrugge, R.
can be used by subjects to solve the game trials. The                (2011). I do know what you think I think: Second-order
previous experiments (Szymanik et al., 2013) have not been           theory of mind in strategic games is not that difficult.
able to distinguish between the two modeling approaches, as          Proceedings of the 33rd Annual Conference of the
both models are consistent with the eye-tracking study of            Cognitive Sciene Society, Austin, TX. 2486-2491.
Meijering et al. (2012). In this paper, by generalizing the        Meijering, B., van Rijn, H., Taatgen, N. A., & Verbrugge,
forward reasoning with backtracking algorithm put forward            R. (2012). What eye movements can tell about theory of
by Meijering et al. (2012), we have managed to disentangle           mind in a strategic game. PloS One, 7(9), e45961.
the predictions of the two models. We have shown that for          Osborne, M. J., & Rubinstein, A. (1994). A Course in Game
the experimental items of Meijering et al. (2012) only the           Theory. Cambridge, MA: MIT Press.
forward reasoning plus backtracking model allows to predict        Premack, D., & Woodruff, G. (1978). Does the chimpanzee
subjects’ behavior: the number of steps that the algorithm           have a theory of mind? Behavioral and Brain Sciences,
must take for a given marble drop game item predicts the             1(4), 515-526.
reaction time subjects will need to correctly solve the trial.     Raijmakers, M., Mandell, D., van Es, S., & Counihan, M.
                                                                     (2014). Children’s strategy use when playing strategic
Outlook                                                              games. Synthese, 191(3), 355-370.
In the future we plan to continue the reported research in a       Szymanik, J. (2013). Backward Induction Is PTIME-
number of directions. First of all, we would like to better          complete. Proceedings of the Fourth International
understand why the computational model based on the                  Workshop on Logic, Rationality, and Interaction. D.
structural descriptions has failed. Is it because the lambda-        Grossi, O. Roy, H. Huang (Eds.), Lecture Notes in
hierarchy does not take into account the decision of the             Computer Science, Vol. 8196, (pp. 352-356). Berlin:
other player? And if that is the reason, how could we fix it?        Springer.
Or maybe, the lambda predictions would approximate the             Szymanik, J., Meijering, B., & Verbrugge, R. (2013). Using
cognitive difficulty better for a wider variety of game items?       intrinsic complexity of turn-taking games to predict
Finally, what is the precise relation between our two                participants’ reaction times. Proceedings of the 35th
models? To answer the last two questions it would be                 Annual Conference of the Cognitive Science Society,
necessary to generalize the forward reasoning plus                   Austin, TX.
backtracking algorithm even more, in such a way that it            Team R Core. (2013). R: A Language and Environment for
could be applied to any turn-based game.                             Statistical Computing. Vienna, Austria: R Foundation for
                                                                     Statistical Computing.
                     Acknowledgments
The authors are grateful for the support of Vici Grant NWO-
277-80-001 awarded to RV. JS acknowledges NWO Veni
Grant 639.021.232.
                                                               1783

