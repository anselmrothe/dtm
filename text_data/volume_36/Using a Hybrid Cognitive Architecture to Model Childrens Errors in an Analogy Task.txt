UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using a Hybrid Cognitive Architecture to Model Children’s Errors in an Analogy Task
Permalink
https://escholarship.org/uc/item/22b5d550
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Licato, John
Sun, Ron
Bringsjord, Selmer
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

                     Using a Hybrid Cognitive Architecture to Model Children’s
                                                 Errors in an Analogy Task
                                                     John Licato (licatj@rpi.edu)
                                                     Department of Computer Science
                                                      Rensselaer Polytechnic Institute
                                                        Ron Sun (rsun@rpi.edu)
                                                     Department of Computer Science
                                                     Department of Cognitive Science
                                                      Rensselaer Polytechnic Institute
                                                Selmer Bringsjord (selmer@rpi.edu)
                                                     Department of Computer Science
                                                     Department of Cognitive Science
                                                      Rensselaer Polytechnic Institute
                              Abstract                                     [W]e can say that the failure to construct relations be-
                                                                           tween relations, or forms of forms, at the more primitive
   We model the performance of children on the Goswami and                 stages comes about because there are as yet no stable
   Brown (1990) analogy task, paying close attention to the dis-           elementary relations (and we mean two-term relations
   tribution of errors children made on the task. This distribution
   follows a very particular pattern which, as we show, may be             here, not four-term relations). Consequently there are
   simulated by assuming a lack of development in the richness             no simple forms that can be expressed in terms of stable
   of children’s concepts of physical causation. This modeling is          classes (Piaget et al., 2001, p.143).
   done using the hybrid cognitive architecture CLARION, and
   a method of representing structured knowledge within CLAR-
   ION’s dual-process system.                                           Goswami and Brown’s Experiment
   Keywords: analogy; analogical reasoning; reasoning; Piaget;          Nevertheless, Goswami and Brown (1990) were not con-
   CLARION; cognitive modeling; cognitive architectures                 vinced that Sternberg and Nigro (1980) and Goldman et al.
                                                                        (1982) properly controlled for Piaget’s apparent belief that
                           Introduction                                 two-term stable elementary relations did not exist in young
                                                                        children. For example, one preoperational child brought the
Analogical reasoning is a core component of adult human                 pair cork:bottle together with lid:pot under the justification
thought; researchers in cognitive science and artificial intel-         “’cause there’s something that comes out of the pot” (Piaget
ligence are coming to realize this increasingly (Gentner &              et al., 2001, p.142). Piaget et al. call this a momentary ap-
Forbus, 2011; Licato, Bringsjord, & Govindarajulu, 2013).               proximation rather than a stable analogy, since the lid object
But the ability to reason analogically was once seen as a               could easily be replaced with an oven, with the justification
higher cognitive ability that did not emerge fully until Piaget’s       “sometimes you heat it with the oven.” The relation which
formal-operations stage of cognitive development. While ex-             links the two pairs, upon which the determination of an ana-
ploring his concept of reflective abstraction, Piaget performed         logical match should be made, is easily abandoned by the
a set of experiments with children that supported his suspi-            child.
cion that analogy was linked to higher-level cognitive pro-                Goswami and Brown (1990) suspected that the results
cesses (Piaget, Montangero, & Billeter, 2001). Subsequent               would be different if two changes were made: First, children
work by Sternberg and Nigro (1980) and Goldman et al.                   should instead be tested only with very basic two-term causal
(1982) added to Piaget’s suspicion, eventually transforming             relations; and second, the experiment should verify first that
it into the hypothesis that 9- and 12-year-olds solve analo-            children actually have a stable understanding of those rela-
gies not using analogical reasoning, but by simple low-level            tions. Simple objects with which children were likely to be
association (Goswami & Brown, 1990).                                    familiar were also introduced, such as playdoh:cut playdoh
   But Piaget himself was not necessarily convinced that ana-           and apple:cut apple. The relation used here, that of cutting an
logical reasoning was impossible with young children. He                object, is typical of the basic, physical transformations used
observed cases in which children in the sensorimotor and                in the experiment.
preoperational stages displayed basic analogical reasoning,                The experiment was designed to rule out the possibility of
even if he thought many of them only provided “approximate              mere association matches being made over the correct, ana-
analogies from moment to moment.” He offered an explana-                logical matches. For each analogy problem, an a, b, and
tion for the apparent lack of analogical ability in the children        c term were given as pictures, in the typical a : b :: c :?
he worked with:                                                         proportional-analogy style. Children were asked to choose
                                                                    857

between the following, where the examples we provide are            seen in Table 1? This question is the focus of our work in this
from the playdoh:cut playdoh::apple:? problem:                      paper.
                                                                       The remainder of this paper will first briefly describe
• d - Correct choice (cut apple).                                   CLARION, the cognitive architecture chosen for this mod-
                                                                    eling task. We then need to touch on CLARION’s NACS
• e - Correct transformation, wrong object (cut bread).
                                                                    subsystem, and the style of structured knowledge representa-
• f - Wrong transformation, correct object (bruised apple).         tion which gives CLARION a unique ability to model many
                                                                    of the phenomena that are important in this task. We describe
• g - Mere appearance match of the c term (ball, where the          the steps we took to model the error distribution seen in Table
   ball’s size and shape are similar to those of the apple).        1, and then close with a brief discussion.
• h - Semantic/category match of the c term (banana).                                        CLARION
                                                                    CLARION (Sun, 2002) is an integrative cognitive architec-
   The analogy experiment was divided into two phases. In
                                                                    ture that has a dual-process structure; that is, is consists of
the first phase (the induction phase), children were simply
                                                                    two levels: explicit (top level) and implicit (bottom level).
asked to choose the correct answer, and were told whether
                                                                    CLARION has been able to model a wide variety of cogni-
the choice they made was correct or not. If it was incorrect,
                                                                    tive phenomena while maintaining psychologically plausible
the experimenter would show the child which was the correct
                                                                    data structures and algorithms (Sun, 2001; Sun & Zhang,
answer, and not explain any further. In the second phase (the
                                                                    2004, 2006). The dual-process representational system of
explanation phase), after choosing, the child would be given
                                                                    CLARION allows for both localist concepts, such as those
an explanation of why the correct answer applies, whether or
                                                                    presented in the Goswami and Brown (1990) experiment, and
not the choice the child made was correct.
                                                                    distributed knowledge, which is a natural way of representing
   Their results were positive: A clear demonstration of ana-
                                                                    low-level associations between concepts (Sun, 2002). This
logical ability was shown in children as young as 3 or 4 years
                                                                    makes it an ideal choice for our purposes.
of age, with a significant difference between them, and the
                                                                       The architecture is further divided into four subsystems,
performance by 6-year-olds was nearly perfect. No other age
                                                                    each with explicit and implicit levels, which specialize in
groups were tested. Perhaps more relevant to our current
                                                                    different aspects of cognition: the Motivational Subsys-
work, however, is the distribution of errors made by the 3-
                                                                    tem (MS), the Metacognitive Subsystem (MCS), the Action-
and 4-year-olds, which can be seen in Table 1.
                                                                    Centered Subsystem (ACS), and the Non-Action-Centered
                                                                    Subsystem (NACS). Work described in this paper will only
Table 1: Percentage of children who passed criterion, and           be using the NACS.
errors made by children on the Goswami and Brown (1990)
                                                                    NACS — the Non-Action-Centered Subsystem
analogy task. Errors presented as a percentage of total errors.
Error data from the 6-year-old age group were not provided          The NACS contains general knowledge about the world that
in the original paper, as the number of errors was deemed too       is not contained in the ACS. Whereas the ACS is meant to
small to be significant. Reprinted with permission.                 capture the knowledge that directly control actions while in-
                                                                    teracting with the world, the knowledge in the NACS is of-
            Percentage Passing Criterion (Children)                 ten more deliberative and used for making inferences. The
                                                                    top level of the NACS is called the General Knowledge Store
             Age (years)    Induction    Explanation                (GKS), and it contains localist chunks that can be linked to
             3              28           52                         each other using Associative Rules (ARs).
             4              73           90                            The bottom level of the NACS is called the AMN, or the
             6              95           100                        Associative Memory Network, and it contains implicit as-
                    Errors Made (Children)                          sociative knowledge encoded as dimension-value pairs (DV
                                                                    pairs). Each GKS chunk is connected to a set of DV pairs
       Age (years)                    E     F     G    H            in the AMN with weights that can be adjusted over time.
       3              Induce          21    45    18   16           This unique structure gives CLARION the ability to define
                      Explanation     23    39    17   21           a directed similarity measure between two chunks c1 and c2
       4              Induce          11    66    10   13           which is derived from the amount of overlap between the DV
                      Explanation     30    63    3    3            pairs connected to the two chunks (Sun, 1995; Tversky, 1977;
                                                                    Sun & Zhang, 2004). However, in this paper we will be us-
                                                                    ing a simplified similarity function based on the number of dv
   This distribution of errors is interesting, because it might     pairs connected to c1 and c2 :
be able to provide us some insight into better modeling
of analogical reasoning in cognitive architectures. What                                              |c1 ∩ c2 |
simulation-level details can account for the error distribution                           Sc1 →c2 =                             (1)
                                                                                                     |c2 |1.0001
                                                                858

   Note that it is possible for the denominator in Equation 1 to
                                                                                         Chases
be zero, in which case the entire equation is given the default
                                                                            WHOLE
value of 1. It is the measure in Equation 1 which we will
use in this paper to determine low-level associative similarity                                                           Chases
between chunks.
   The Associative Rules (ARs) link groups of chunks to other           COMPO-
                                                                                                                       Dog      Cat
                                                                         NENT
chunks in the GKS, and consist of a set of condition chunks
                                                                                     1st            2nd
c1 , c2 , ... and a single conclusion chunk d. For any given AR,
each condition chunk i has a weight Wi such that ∑i Wi = 1.
   The chunks in the GKS and DV pairs in the AMN have ac-
tivation levels which can be set by CLARION’s other subsys-
                                                                                             Dog             Cat
tems. Activations can also spread through the NACS using
the chunk-DV pair connections and the top-level ARs. The
manner in which this activation spreads can be restricted, as
other subsystems can temporarily disable Rule-Based Rea-             Figure 1: A knowledge structure representing the proposition
soning (activation spreading through ARs) or Similarity-             CHASES(DOG,CAT ). On the right is the simplified version,
Based Reasoning (activation spreading through chunk simi-            which omits the CDCs and many of the ARs, though they
larity), or perform activation propagation as some weighted          are there (just not pictured). Note that in both versions, only
combination of both of these reasoning types. These abilities        chunks are pictured. The bottom-level DV pairs which each
are detailed further in Sun & Zhang (2004, 2006), in which           chunk is connected to are omitted for simplicity.
these mechanisms are shown to be psychologically plausible.
   Structural knowledge in CLARION is represented through
combining ARs with Cognitively Distinguished Chunks, or              that tries (in parallel) different transformations of the source
CDCs. CDCs are depicted as star-shaped in our diagrams               chunks into templates. For the purposes of this paper, a sim-
(Figure 1). Associative rules link the CDCs to the chunks in         ple version of this algorithm is used that simply transforms
the structure. For example, the WHOLE CDC links object               the object-level chunks (objects a and b) to blank chunks.
nodes to proposition nodes. In Figure 1, which depicts the              Actually determining whether the template applies to the
proposition CHASES(DOG CAT), the WHOLE CDC is part                   chunks is a nontrivial algorithmic problem. We solve this by
of two ARs (depicted in the Figure as an arrow with multiple         using an Ant Colony Optimization (ACO) algorithm based on
tails and one head).                                                 (Sammoud, Solnon, & Ghédira, 2005). The algorithm starts
   A COMPONENT CDC is also defined, such that for every              by collecting the template and target chunks, and drawing el-
rule involving a WHOLE CDC, a complementary rule going               igibility links between pairs of chunks that can potentially be
in the other direction is created with a COMPONENT CDC.              mapped to each other. It determines this by using the simi-
Whole chunks are always pictured above component chunks.             larity metric defined in Equation 1. If that similarity is above
Next, we introduce Ordinal CDCs, which are also pictured in          a certain minimum similarity level ε, then an eligibility link
Figure 1 as 1ST, 2ND, etc. Ordinal CDCs simply preserve the          is drawn. Varying ε allows us to approximate the rigidity of
roles objects play within propositions in a general way that         the matching requirements, so that a lower value encourages
does not name the roles specifically (contrast this with the         more creative matchings, while a higher value forces more
LISA model (Hummel & Holyoak, 2003), which has distinct              structural consistency between the structures being matched.
role units for every type of role.).                                 Eligibility links are automatically drawn from blank chunks
                                                                     to other chunks in the target.
     Analogical Reasoning in CLARION Using                              The eligibility links are then selected by the ants in a
                             Templates                               bottom-up fashion, starting with the object-level chunks. As
Analogical and deductive reasoning in CLARION can be                 each level is completed, the eligibility links remaining in the
done using the template form. Templates are groups of                upper levels are re-evaluated. This is because the choices
chunks that both specify what constitutes an acceptable form         made at the lower levels may not be consistent with choices
match and how to transform the input when such a match is            on the upper levels (lest structural consistency between the
found. Chunks can also exist in templates that have zero se-         template and target structures be violated).
mantic content. These are called “blank chunks,” and will be            The ACO algorithm which matches templates to targets
used when matching templates to other structures. In Figure          can then be used. Our ACO implementation is described in
2, blank chunks are pictured as chunks without any labels.           more detail, along with a more thorough explanation of tem-
   Given some template and a set of structured chunks, before        plates, in (Licato, Sun, & Bringsjord, 2014). The authors are
performing analogical reasoning using the template system, a         not unaware of the level of compressed descriptions in this
set of source chunks has to first be collected. These chunks         paper regarding the simulation, but due to space many tech-
can then be transformed into a template using an algorithm           nical details had to be omitted from this paper.
                                                                 859

                                                        Cut_before_after                                 Bruised_before_
                Template                                                             Target                       after
              Cut_before_after                                        uncut_cut_
                                                                            pair
                                                                                                  uncut_cut_
      same_type                uncut_cut_              same_type              same_type                pair
                                    pair
                                                                                                              unbruised_
                                                                                                             bruised_pair
                                                              c           d          e          f           g          h
Figure 2: The template and target representation used in our simulation. DV pairs are not pictured here. Units pictured with
dotted lines are only present for the simulation of 6-year-old reasoning, whereas the rest of the units were present for all
simulated age groups.
              Matching Children’s Errors                              new units as a normal part of the learning process, such as the
                                                                      neurologically plausible model DORA (Doumas, Hummel, &
The period between 3- and 4-years of age is one of rapid cog-         Sandhofer, 2008), and those built on cascade-correlation neu-
nitive development in many areas, among these the ability to          ral networks (Shultz, 2003; Shultz & Sirois, 2008). Such sys-
understand, and reason about, physical causality (Das Gupta           tems increase their representational power dynamically, lead-
& Bryant, 1989; Frye, Zelazo, & Palfai, 1995). The increase           ing to qualitative changes in the expressivity of the knowl-
in this particular ability is reflected in the data from Table 1      edge representation used by the system, and giving them clear
(Goswami & Brown, 1990). The question before us, then, is:            advantages over static models (Shultz, 2012). The cascade-
Exactly what changes occur at CLARION’s level of abstrac-             correlation model has also been used to effectively model Pi-
tion that plausibly explain increased understanding of phys-          agetian tasks (Shultz, Mareschal, & Schmidt, 1994; Shultz,
ical causality? The obvious first answer is quantitative: We          2003).
can either increase ε (recall, this is the minimum similarity
required for an eligibility link to be drawn in the matching al-         It makes sense, then, that a qualitative change in the rep-
gorithm), or we can increase the number of ants and iterations        resentations used might offer an explanation for the Table 1
used in the ACO algorithm. Initial testing, however, showed           data. Assuming a constructivist (as opposed to a Fodorian
that a tweaking of these parameters was not enough to explain         nativist (Fodor, 2008)) theory of cognitive development, con-
the distribution of errors seen in Table 1. In particular, it did     cepts such as those used in the Goswami and Brown (1990)
not replicate the fact that f and e errors are by far the most        experiments are built and enriched from more primitive con-
common, in that order. Something else had to be explored in           structs. It should not be too controversial to suggest, then,
addition to the quantitative features. As it turns out, there are     that perhaps part of what explains the rapid increase in under-
some clues in the psychological literature that hint of a qual-       standing of physical causation after age 4 is a development
itative change as well. That change is a development in the           in the relevant conceptual constructs themselves. In other
conceptual representations used by the children.                      words, perhaps the 3- and 4-year-olds are reasoning using a
   The idea of qualitative change over time is a fundamen-            primitive version of the concepts being tested, which are not
tal one in Piaget’s constructivist philosophy (Piaget, 1977).         fully chunked, not fully explicit, and still decomposable into
Several systems implement constructivist views by recruiting          their constituent concepts; whereas the 6-year-olds, who per-
                                                                  860

formed at or close to ceiling, have much richer conceptual                   tent or incomprehensible; this is meant to represent instances
representations.1                                                            where analogical reasoning fails and the subject must resort
   We will use the playdoh:cut playdoh::apple:? problem as                   to other reasoning methods.
an example. The relevant relationship being tested is Cut, a                 Simulation Recall now that there are four quantitative pa-
rich concept consisting of: before and after states, a division              rameters that were varied in this simulation: the number of
in the object in the after state characterized by a clean slice,             ants and rounds used by the ACO algorithm, the ε value repre-
which was likely done with a sharp blade, etc. If the Cut                    senting the minimum similarity required for an identity link,
concept is built from observations, it is possible that these                and the δ value which set the frequency of SBR.
primitive concepts are those from which the Cut concept is                      For the 3-year-old group, a simulation of 20,000 iterations
built. If so, does the representational network of concepts                  was done using one ant, one round, and ε was randomly cho-
used by children still make use of these primitive concepts?                 sen from the [0.15, 0.3] range (one selection was made for
   The abundance of e and f errors might be explained via                    each simulated subject) to introduce variation. The value of
the use of primitive conceptual structures. Instead of struc-                δ used was 0.15. Another simulation of 20,000 iterations was
turing our simulation such that items c and d are linked                     done to simulate the 4-year-old group, which used five ants,
by a single predicate Cut, we link them with two sepa-                       five rounds, ε ∈ [0.25, 0.4], and δ = 0.05. Finally, for the 6-
rate concepts: Same Type (since they are both apples), and                   year-old group, the parameters were almost exactly the same
Cut Uncut Pair, which simply links two objects such that                     as the 4-year-old group; the only changes were the addition
one is uncut and the other is. Now c (an uncut apple) and                    of relationship chunks as pictured in Figure 2, and the setting
e (cut bread) can be linked with the Cut Uncut Pair predi-                   of δ = 0. The results are presented in Table 2.
cate, and c can be linked with f (a bruised apple) by way of
the Same Type predicate. Furthermore, we can link c, f with
an Unbruised Bruised Pair predicate and have that predicate                  Table 2: Percentage of correct choices and errors made by
share DV pairs with Cut Uncut Pair to reflect the semantic                   the simulation. Errors are presented as a percentage of total
similarity between bruising and cutting.                                     errors.
   This representation is pictured in Figure 2. Note that the                           Percentage Passing Criterion (Simulation)
source analog (the a and b chunks and all relationships be-
                                                                                             Age (simulated years)       Passed
tween them) was transformed into a template such that the
                                                                                             3                           41
object-level chunks were blank. We were then able to ex-
                                                                                             4                           74
ecute the model by matching this template to the represen-
                                                                                             6                           98
tation consisting of objects c through h. Most of the time,
the chunks corresponding to c would be mapped to a, and                                         Errors Made (Simulation)
whichever object’s chunks mapped to b was taken to be the
answer selected by the system. Also note that there are addi-                          Age (simulated years)     E      F     G   H
tional chunks which were only present for the representations                          3                         23     45    16  16
used for the 6-year-old group’s simulation, which is meant to                          4                         24     56    10  10
reflect more highly developed Cut and Bruise concepts in the                           6                         0      99    1   0
6-year-olds.
   In order to reflect object-level similarities shared between
the c and g objects, we simply created a set of DV pairs that                                         Conclusion
were uniquely shared by the chunks corresponding to c and
                                                                             Significant features of the human data were preserved in the
g. A parallel move was made for c and h. A parameter
                                                                             simulation. For example, f errors were more frequent than e
δ was introduced, which represents how frequently the sys-
                                                                             errors, and the ratio of correct answers to incorrect answers
tem resorts to using the sort of low-level associative reason-
                                                                             lines up nicely with the human data. We feel that this imparts
ing children were thought to reason with in place of analogy
                                                                             a certain level of plausibility to our assumptions, but never-
(Sternberg & Nigro, 1980). In CLARION, this type of rea-
                                                                             theless, it would be interesting to see if the assumptions made
soning is called Similarity-Based Reasoning (SBR) (Sun &
                                                                             in this paper hold up in other situations. The hand-chosen
Zhang, 2004). Our simulation used SBR to select an answer
                                                                             values of the quantitative parameters aside, perhaps more in-
whenever either a randomized variable was greater than δ, or
                                                                             teresting is our simulation’s assumption that part of what ex-
analogical reasoning produced a mapping that was inconsis-
                                                                             plains the difference in performance between 3-, 4-, and 6-
    1 This idea was inspired by the quote reprinted in this paper’s in-      year-olds is a qualitative difference in the representational
troduction, in which Piaget suggests there are “no simple forms that         structures used. If toddlers really do use concepts that are
can be expressed in terms of stable classes” (Piaget et al., 2001). Per-     not as “well-chunked” as those of older children, and instead
haps the idea that in toddlers, concepts are still in a form which is        use concepts composed largely of separable, primitive com-
predominantly a loose tying-together of primitive conceptual struc-
tures, rather than a solid and robust collection of rich concepts, was       ponents, subsequent experimentation might be able to support
what Piaget had in mind.                                                     or refute this difference. We encourage researchers to exam-
                                                                         861

ine this possibility, by designing experiments to detect and       Shultz, T. R. (2012). A Constructive Neural-Network Ap-
understand the nature of these proto-concepts.                       proach to Modeling Psychological Development. Cognitive
   Regardless, the modeling of qualitative increases in repre-       Development, 27, 383-400.
sentational strength is a promising direction, which our work      Shultz, T. R., Mareschal, D., & Schmidt, W. C. (1994). Mod-
will continue to explore.                                            eling cognitive development on balance scale phenomena.
                                                                     Machine Learning, 16, 57-86.
                         References                                Shultz, T. R., & Sirois, S. (2008). Computational Models
                                                                     of Developmental Psychology. In R. Sun (Ed.), The cam-
Das Gupta, P., & Bryant, P. (1989, October). Young Chil-
                                                                     bridge handbook of computational psychology (pp. 451–
  dren’s Causal Inferences. Child Development, 60(5), 1138-
                                                                     476). New York, New York, USA: Cambridge Univ Press.
  1146.
                                                                   Sternberg, R. J., & Nigro, G. (1980). Developmental Patterns
Doumas, L. A., Hummel, J. E., & Sandhofer, C. (2008). A
                                                                     in the Solution of Verbal Analogies. Child Development,
  Theory of the Discovery and Predication of Relational Con-
                                                                     51(1).
  cepts. Psychological Review, 115, 1-43.
                                                                   Sun, R. (1995). Robust Reasoning: Integrating Rule-Based
Fodor, J. A. (2008). LOT 2: The Language of Thought Revis-
                                                                     and Similarity-Based Reasoning. Artificial Intelligence,
  ited. Oxford Univ. Press.
                                                                     75(2).
Frye, D., Zelazo, P. D., & Palfai, T. (1995). Theory of Mind       Sun, R. (2001). From Implicit Skills to Explicit Knowledge:
  and Rule-Based Reasoning. Cognitive Development, 10,               A Bottom-Up Model of Skill Learning. Cognitive Science,
  483-527.                                                           25(2), 203-244.
Gentner, D., & Forbus, K. (2011). Computational Models             Sun, R. (2002). Duality of the Mind: A Bottom Up Approach
  of Analogy. Wiley Interdisciplinary Reviews: Cognitive             Toward Cognition. Lawrence Erlbaum Associates, Mah-
  Science, 2(3), 266-276.                                            wah, NJ.
Goldman, S., Pellegrino, J., Parseghian, P., & Sallis, R.          Sun, R., & Zhang, X. (2004). Accounting for Similarity-
  (1982). Developmental and Individual Differences in Ver-           Based Reasoning within a Cognitive Architecture. In Pro-
  bal Analogical Reasoning. Child Development, 53, 550-              ceedings of the 26th annual conference of the cognitive sci-
  559.                                                               ence society. Lawrence Erlbaum Associates.
Goswami, U., & Brown, A. L. (1990). Melting Chocolate              Sun, R., & Zhang, X. (2006). Accounting for a Variety of
  and Melting Snowmen: Analogical Reasoning and Causal               Reasoning Data Within a Cognitive Architecture. Jour-
  Relations. Cognition, 35(1), 69-95.                                nal of Experimental and Theoretical Artificial Intelligence,
Hummel, J. E., & Holyoak, K. J. (2003). Relational Rea-              18(2).
  soning in a Neurally-plausible Cognitive Architecture: An        Tversky, A. (1977). Features of Similarity. Psychological
  Overview of the LISA Project. Cognitive Studies: Bulletin          Review, 84(4), 327-352.
  of the Japanese Cognitive Science Society, 10, 58-75.
Licato, J., Bringsjord, S., & Govindarajulu, N. S. (2013).
  How Models of Creativity and Analogy Need to An-
  swer the Tailorability Concern. In T. R. Besold, K.-
  u. Kühnberger, M. Schorlemmer, & A. Smaill (Eds.), Pro-
  ceedings of the ijcai 2013 workshop on computational cre-
  ativity, concept invention, and general intelligence. Bei-
  jing, China.
Licato, J., Sun, R., & Bringsjord, S. (2014). Structural Rep-
  resentation and Reasoning in a Hybrid Cognitive Architec-
  ture. In Proceedings of the 2014 international joint confer-
  ence on neural networks (ijcnn).
Piaget, J. (1977). The Essential Piaget (H. E. Gruber &
  J. J. Voneche, Eds.). New York, New York, USA: Basic
  Books, Inc.
Piaget, J., Montangero, J., & Billeter, J. (2001). The Forma-
  tion of Analogies. In R. Campbell (Ed.), Studies in reflect-
  ing abstraction. Psychology Press.
Sammoud, O., Solnon, C., & Ghédira, K. (2005). An Ant Al-
  gorithm for the Graph Matching Problem. In 5th european
  conference on evolutionary computation in combinatorial
  optimization (evocop 2005). Springer.
Shultz, T. R. (2003). Computational Developmental Psychol-
  ogy. Cambridge, Massachusetts: The MIT Press.
                                                               862

