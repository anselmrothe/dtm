UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Testing a rational account of pragmatic reasoning: The case of spatial language
Permalink
https://escholarship.org/uc/item/6hp4m6gq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Carstensen, Alexandra
Kon, Elizabeth
Regier, Terry
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

     Testing a rational account of pragmatic reasoning: The case of spatial language
                                           Alexandra Carstensen (abc@berkeley.edu)
                            Department of Psychology, University of California, Berkeley, CA 94720 USA
                                             Elizabeth Kon (ellie.kon@berkeley.edu)
                            Cognitive Science Program, University of California, Berkeley, CA 94720 USA
                                            Terry Regier (terry.regier@berkeley.edu)
           Department of Linguistics, Cognitive Science Program, University of California, Berkeley, CA 94720 USA
                              Abstract                                     We seek to answer that question here, by replicating
   How do people recover precise meanings from ambiguous
                                                                      their study in the context of communication about spatial
   utterances? Frank and Goodman (2012) proposed that                 relations. Languages differ substantially in the ways they
   listeners do this by rationally combining evidence about word      partition the spatial domain into semantic categories, and
   meaning and the salience of particular objects in context.         these categories sometimes involve relatively subtle features
   They found that a Bayesian model based on this idea provided       such as attachment by spiking, or being astraddle, in
   a near-perfect account of their empirical data. However, their     addition to (from a Western viewpoint) more obvious
   test of the model was based on communication about simple          features such as containment and support (Levinson et al.,
   geometrical objects that varied along only three dimensions.
   Here, we ask whether their proposal extends to the richer and      2003). Thus, the domain of spatial relations is rich enough
   more complex domain of spatial relations. We find that it          to allow a test of Frank and Goodman’s (2012) proposal in a
   does. While the results are not as strong as in their original     semantically complex domain.
   study, they nonetheless demonstrate that simple formal                  We first review Frank and Goodman’s study, on which
   accounts of communication may capture important aspects of         ours is based. We then present our study, which tests their
   pragmatic inference.                                               proposal in the spatial domain. To preview our results, we
   Keywords: Spatial cognition, spatial language, semantics,          find that their account does predict pragmatic reasoning in
   pragmatics, communication.                                         the spatial domain, but does not do so as cleanly as in their
                                                                      original study in a simpler domain. We conclude that
       Language, thought, and communication                           pragmatic reasoning in more complex domains is
                                                                      substantially but not fully accounted for by their proposal as
     A growing trend in cognitive science views language
                                                                      it stands, and consider possible interpretations of this
through the lens of its function: as a vehicle for informative,
                                                                      finding.
efficient communication (e.g. Piantadosi et al., 2011; 2012;
Fedzechkina et al., 2012). One such line of work has argued
that systems of word meanings in the world’s languages                                Frank & Goodman (2012)
tend to support highly informative communication (Regier                   How does a listener interpret a speaker’s utterance in
et al., 2007; Baddeley & Attewell, 2009; Kemp & Regier,               context? Imagine that a speaker wishes to refer to a specific
2012; Khetarpal et al., 2013). However, word meanings                 referent rs, which is one of several possible referents in a
necessarily leave much information unspecified—thus, the              physical context C, and that the speaker has produced a
use of words must be supplemented by pragmatic reasoning              word w to convey this to a listener. Frank and Goodman
to allow speaker and listener to communicate effectively.             (2012) proposed that in such situations, the listener
What principles govern this pragmatic reasoning?                      determines the speaker’s intended referent through Bayes’
     Frank and Goodman (2012) proposed an account of                  rule: 1
pragmatic reasoning in language use. They argued that in
conversation, listeners determine the object to which a                                                  P( w | rs , C ) P(rs | C )
speaker is referring by rationally combining two sorts of             (1)         P(rs | w, C ) =
evidence: one concerning how well the speaker’s utterance                                           Σ P(w | rʹ′, C ) P(r ʹ′ | C )
                                                                                                    r ʹ′∈C
fits each potential referent, and the other concerning how
salient each potential referent is in context. Their study
                                                                      Here, the posterior probability P(rs|w,C) represents the
presented evidence that listeners combine these two sources
                                                                      listener’s subjective degree of belief that the speaker’s
of evidence in accord with Bayes’ rule in interpreting the
                                                                      intended referent is rs, given word w and context C. This
speaker’s intention. However, one limitation of their study
                                                                      quantity is proportional to the product of two terms: (1) the
is that it was based on communication about a very simple
                                                                      likelihood P(w|rs,C) of the speaker using word w given that
and cleanly circumscribed semantic domain, and it is not yet
known whether similar results would be obtained in a more
                                                                         1
complex domain.                                                            Our notation differs slightly from that of Frank and Goodman
                                                                      (2012), but there is no difference in intended meaning.
                                                                  2009

the intended referent was rs in context C, and (2) the prior                                     Our study
probability P(rs|C) that a word in context C would refer to
                                                                            In our experiment, we replaced Frank and Goodman’s
rs, without any specification of what that word is. The
                                                                        simple geometric stimuli with line drawings that depict
denominator of Equation 1 is a normalizing constant.
                                                                        spatial relations. These were taken from the Topological
   Frank and Goodman (2012) assumed that speakers choose
                                                                        Relations Picture Series (TRPS; Bowerman & Pederson,
words to be maximally specific—that is, that speakers select
                                                                        1992), a set of 71 line drawings depicting a variety of spatial
the term that picks out the smallest set of possible referents
                                                                        relations. Each line drawing shows an orange figure object
in a given context (cf. Xu & Tenenbaum, 2007).
                                                                        located relative to a black background object. Figure 1
Accordingly, they modeled the likelihood P(w|rs,C) as:
                                                                        shows a sample of 10 scenes from the TRPS, categorized
                                                                        according to the spatial naming systems of two languages.
(2)
                                          | w | −1
                    P( w | rs , C ) =              −1
                                       Σ | wʹ′ |
                                      wʹ′∈W
where w is the selected word, |w| is the number of objects in
the extension of w, and W is the set of all labels that could
be validly applied to the intended referent rs.
     To test their model, Frank and Goodman conducted an
experiment with three conditions: one to assess each of the
model’s three components.2 In all three conditions,
participants viewed a communicative context C consisting
of three simple geometrical objects that could vary in shape,
color, and pattern. For example, a context might contain a
solid blue square, a solid blue circle, and a solid green
circle. In the speaker condition, one of the objects in the
context was highlighted as the intended referent (e.g. the
blue circle), and participants were asked to bet on which
word (e.g. “blue”, “circle”) they would use to describe that                     Figure 1: Ten spatial scenes from the TRPS, as
object in that context; this provides an empirical measure of                categorized in two languages: Tiriyó and Yélî-Dnye.
the likelihood P(w|rs,C). In the salience condition, no object                        Adapted from Levinson et al. (2003).
was highlighted—instead, participants were told that a
speaker had used an unknown word to refer to one of the                 The TRPS has been widely used in cross-linguistic studies
objects shown in the context, and they were asked to bet on             of spatial language (e.g. Bowerman & Pederson, 1992;
which object was intended; this provides an empirical                   Levinson et al., 2003; Khetarpal et al., 2013; Regier et al.,
measure of the prior P(rs|C). Finally, in the listener                  2013), and it represents a broad, rich, and finely-detailed
condition, participants again saw three objects in context              range of different spatial relations. We investigate pragmatic
without any object highlighted, but this time were told that a          reasoning about reference in the domain of such scenes,
speaker had used a single word (e.g. “blue”) to refer to one            using the spatial terms of English (e.g. “in,” “around,” etc.).
of the objects, and were asked to bet on which object the
speaker intended; this provides an empirical measure of the                                       Methods
posterior P(rs|w,C). Frank and Goodman found that mean
bets in the speaker condition were very highly correlated               Participants
with their model likelihood (Equation 2), and that mean bets            A total of 1,427 participants from the U.S. took part in our
in the listener condition were very highly correlated with              experiment online through Amazon Mechanical Turk. These
their model posterior probability (Equation 1). They                    participants completed a total of 1,605 trials across all
concluded that this simple model captures “some of the                  conditions (described below), 447 of which trials were
richness of human pragmatic inference in context.”                      excluded from our analysis because the participant either
     We wished to test whether Frank and Goodman’s results              failed to follow instructions or completed more than one
generalize to the more complex domain of spatial relations.             trial, in which case subsequent trials were discarded.
To that end, we followed their formalization, their                     Because a unique participant completed each trial in every
experimental design, and their analysis, changing only the              condition, the number of participants in each condition is
character of the stimuli and the words that refer to them, as           equal to the number of trials.
described below.
                                                                        Materials
   2
     We describe their conditions briefly here, and provide concrete    Communicative contexts were constructed as triads of
examples with spatial stimuli below, when we present our variant        TRPS scenes presented side by side; an example is shown in
of their experiment.                                                    Figure 2 below. We divided the 71 scenes of the TRPS into
                                                                    2010

23 unique triad sets, such that no scene appeared in more                         For each of the three conditions, we specify below any
than one triad, and we excluded the two remaining scenes                      elements of procedure not already specified.
(TRPS scenes 2 and 46). Because the goal of the study is to
investigate reasoning under ambiguous reference, each triad                   Speaker (likelihood). Participants viewed a triad of spatial
was formed with the requirement that English spatial terms                    scenes, one of which was selected as the intended referent.
should be ambiguous when used in the context of the triad.                    The selected scene (the intended referent) was always
Specifically, every member of the triad shared at least one                   indicated by a dotted black square around it. Participants
English spatial term (that could describe that scene) with                    were given a list of all valid spatial terms that could be
another member of the triad. Spatial terms for scenes were                    applied to the intended referent (valid terms were identified
determined independently of the primary experiment.3                          independently as described in footnote 3; all other terms
                                                                              were assumed to have 0 probability of applying), and were
Design and procedure                                                          instructed to estimate the probability that they would use
Our design matched that of Frank and Goodman (2012)                           each term in the set to refer to the selected scene, in the
with one major exception: instead of generating stimuli with                  context of that triad of scenes. The instructions specified
pre-determined amounts of referential ambiguity, as they                      that these probability estimates should add to 100, and this
did, we created triads by randomly sampling from our                          requirement also served as a comprehension check; trials in
stimulus set with only the above-specified minimal                            which participants’ estimates did not sum to 100 were
ambiguity requirement within each triad.                                      discarded and re-run on new participants. Any of the three
    There were three conditions, corresponding to the three                   scenes within a triad could be the selected referent, yielding
elements of their model. The speaker condition empirically                    3 (scenes per triad) × 23 (triads) = 69 unique trial types (a
measured the likelihood P(w|rs,C); the salience condition                     trial type is a triad with a particular scene selected, as in
empirically measured the prior P(rs|C); and the listener                      Figure 2). Scene order was fully counterbalanced within
condition empirically measured the posterior P(rs|w,C). In                    these trial types for a total of 6 orders × 69 trial types = 414
all conditions, participants viewed triads of spatial scenes                  trials in this condition.
(contexts) and answered questions about them. Figure 2
shows an example trial, with instructions from each of the                    Salience (prior). Each participant was shown a triad of
three conditions.                                                             spatial scenes without any scene selected, and instructed to
                                                                              imagine that someone had used a word that the participant
    Speaker (likelihood): Imagine you are talking to someone and you          did not know to refer to one of the scenes in the triad. They
    want to refer to the selected scene and distinguish it from the other     were told that this word referred to the scene based on the
    two scenes. Which word would you use, “in” or “inside”?
    Estimate the probability that you would use each word as a percent
                                                                              spatial relationship depicted in it, and were asked to
    (responses must add to 100).                                              estimate how likely it was that the speaker was referring to
                                                                              each scene, such that their estimates summed to 100. As in
                                                                              the speaker (likelihood) condition, trials in which the
                                                                              participant failed to follow this instruction were discarded
                                                                              and re-run with new participants. Scene order was fully
                                                                              counterbalanced within the triad sets for a total of 6 orders ×
                                                                              23 triads = 138 trials in this condition.
    Salience (prior) / Listener (posterior): [scene selection highlight
    not shown] Imagine someone is talking to you and uses [a word             Listener (posterior). Each participant was shown a triad of
    you don’t know/the word “inside”] to refer to one of these scenes.        spatial scenes without any scene selected, together with an
    Which scene are they talking about? Estimate the probability that
    they are talking about each of the scenes as a percent (responses
                                                                              English spatial term (e.g. “on”) that could be validly applied
    must add to 100).                                                         to at least one scene in the triad. They were asked which
                                                                              scenes in the triad a speaker might be talking about when
    Figure 2: An example trial, with instructions from the                    using that label. Specifically, participants judged how likely
            speaker, salience, and listener conditions.                       it was that each scene was the speaker’s intended referent
                                                                              given that spatial term, and entered their judgments as
                                                                              percentages summing to 100. As in the other two
3
  In a separate experiment, 45 UC Berkeley undergraduates, all                conditions, participants whose estimates did not sum to 100
native English speakers, viewed each TRPS scene and answered                  were excluded and the trials re-run. Each of the 23 triads
the question “Where is the [figure object]?” by completing a fill-            was paired with all possible labels for scenes in that triad,
in-the-blank sentence that specified figure and ground but not the            yielding 202 unique trial types. Order within these trial
spatial relationship between them, for instance: “The cup _____               types was pseudo-randomly counterbalanced such that each
the table.” Responses were trimmed to standardize tense and                   unique trial type was presented in three of the six possible
remove non-spatial words (e.g. “is”). To ensure that spatial terms
                                                                              scene orders, yielding 606 trials in total in this condition.
were all of similar complexity, we only included responses with
two or fewer spatial morphemes as valid spatial term options. This
procedure resulted in each TRPS scene receiving at least two
spatial term labels; many received more.
                                                                          2011

 Figure 3: Example model calculation for the triad shown in Figure 2 with the label “inside.” Blue dots indicate participants’
                                   average responses; black lines indicate model predictions.
                   Analysis and results                            Testing the Bayesian model
                                                                   Finally, we tested the central claim: that listeners infer
Our analyses followed those of Frank and Goodman (2012).           speakers’ intentions through Bayesian combination of
We first tested the model’s assumption of speaker                  evidence. We combined the empirical prior (from the
informativeness. We then tested whether salience (the prior)       salience condition) and model likelihood (from Equation 1),
predicts responses in the listener condition—to see whether        to obtain the model’s predicted posterior—and compared it
this one source of evidence by itself suffices to explain          to the empirical posterior (listener condition). We found a
listeners’ inferences. Finally, we assessed the combination        significant correlation (r = .70, p < .0001; see Figure 4).
of evidence through Bayes’ rule, by comparing the model
posterior to empirical responses in our listener condition (to
which this quantity is intended to correspond), together with
a follow-up analysis. Figure 3 illustrates model calculations
alongside empirical results for one sample triad of scenes.
Testing the assumption of speaker informativeness
The model likelihood (Equation 2) is based on the
assumption that speakers choose words to be maximally
informative in context—that is, so that the word chosen will
pick out the smallest set of referents possible in a given
context. We tested this assumption by comparing empirical
data in the speaker (likelihood) condition with the model
likelihood term obtained through Equation 2. We found a
significant correlation between average empirical
likelihoods and model predictions (r = .36, p < .0001; all
correlation p-values obtained by permutation test). This                Figure 4: Correlation between model prediction and
result suggests that the model likelihood reasonably                   participants’ judgments about which spatial scene the
approximates speakers’ word choice in context, and that               speaker intended, given a speaker’s spatial term used in
speakers do appear to choose their words informatively.                                        context.
Does salience alone predict listener’s inferences?                 This correlation remains significant when predicted
It is conceivable that listeners might base their judgments of     posterior values of one and zero are excluded (r = .36, p <
speakers’ intentions solely on the salience of particular          .0001). We also explored another way to obtain a predicted
objects, without reference to how well a given word fits           posterior via Bayes’ rule: using the empirically determined
each referent. To test this, we compared empirical data from       likelihood (speaker condition) rather than the model
the salience (prior) condition to empirical data from the          likelihood, such that Bayes’ rule is now used to combine
listener (posterior) condition. We found no significant            two empirically determined sources of evidence. In this
correlation (r = .06, p = .09). This means that if the             case, the correlation with the empirical posterior (listener
Bayesian model’s posterior successfully predicts data from         condition) was again significant (r = .70, p < .0001). Thus,
the listener (posterior) condition, that success cannot be due     Frank and Goodman’s (2012) Bayesian account does seem
only to the prior, independent of likelihood.                      to capture listeners’ inference about speakers’ intentions
                                                              2012

under conditions of referential uncertainty, in a complex and          for the difference in model fit between our study and theirs.
semantically rich domain.                                              Second, we have seen that the model’s success with our data
     Given these results, and given that we have also found            is attributable entirely to the likelihood, and not at all to the
that any success of the Bayesian model cannot be attributed            prior. It is possible that our empirical prior is, for whatever
solely to the prior, we sought to understand whether the               reason, a flawed measure of the contextual salience of
model’s success could be attributed solely to the likelihood           particular objects. This possibility cannot be assumed, but it
instead. To that end, we obtained predictions of listeners’            also cannot be ruled out. Future research can usefully focus
judgments using Equation 1 again, but this time assuming a             on other means of assessing contextual salience, to help
uniform prior (P(rs|C) = ⅓, ∀r∈C), and using the model                 resolve this issue.
likelihood of Equation 2. We found that the correlation                     These caveats notwithstanding, our results do extend
between this uniform-prior-based model prediction and                  Frank and Goodman’s (2012) account to a richer and more
listener judgments was high (r = .70, p < .0001)—in fact, it           complex semantic domain, and help to support their
was as high as the correlation we obtained when combining              conclusion that simple formal accounts of communication
the model likelihood with the empirical prior (salience                may capture important aspects of pragmatic inference.
condition).4 Thus, it appears that this empirically based prior
adds nothing to the predictive power of the model, and the                                   Acknowledgments
real predictive component is the likelihood. Table 1
                                                                       We thank Michael Frank, Noah Goodman, Yang Xu, and
summarizes the results of all our analyses, together with
                                                                       Joshua Abbott for helpful comments. This work was
analogous analyses by Frank and Goodman (2012).5
                                                                       supported by NSF under grant SBE-1041707, the Spatial
                                                                       Intelligence and Learning Center (SILC), and under NSF
        Table 1: Pearson correlations in the present study
                                                                       Graduate Research Fellowship grant DGE 1106400.
      compared with those of Frank & Goodman (2012).
   Correlation                               Present   F&G
                                                                                                  References
   Likelihood: model vs. empirical           0.36*     0.98*           Baddeley, R., & Attewell, D. (2009). The relationship between
                                                                          language and the environment: Information theory shows why
   Emp. prior vs. emp. posterior             0.06      0.19
                                                                          we have only three lightness terms. Psychological Science, 20,
   Model vs. empirical posterior             0.70*     0.99*              1100-1107.
   Bayes vs. empirical posterior             0.70*      —              Bowerman, M., & Pederson, E. (1992). Cross-linguistic studies of
   Model with uniform prior vs.              0.70*      —                 spatial semantic organization. In Annual Report of the Max
   empirical posterior                                                    Planck Institute for Psycholinguistics 1992, 53-56.
                                                                       Fedzechkina, M., Jaeger, T., & Newport, E. (2012). Language
                                                                          learners restructure their input to facilitate efﬁcient
               Discussion and conclusions                                 communication. PNAS, 109, 17897–17902.
We have shown that Frank and Goodman’s formalization of                Frank, M., & Goodman, N. (2012). Predicting pragmatic reasoning
pragmatic inference in conversation extends to the domain                 in language games. Science, 336, 998.
of spatial relations—a more diverse and naturalistic domain            Kemp, C., & Regier, T. (2012). Kinship categories across
than that of simple geometric objects, in which they                      languages reflect general communicative principles. Science,
originally assessed their proposal. This suggests that their              336, 1049-1054.
                                                                       Khetarpal, N., Neveu, G., Majid, A., Michael, L., & Regier, T.
ideas may extend to richer and more complex semantic
                                                                          (2013). Spatial terms across languages support near-optimal
domains.                                                                  communication: Evidence from Peruvian Amazonia and
     However, our results also suggest caution, in at least two           computational analyses. In M. Knauff et al., (Eds.), Proceedings
respects. First, the correlations between the model                       of the 35th Annual Meeting of the Cognitive Science Society.
prediction and our listener judgment data, while significant,          Levinson, S., Meira, S., & the Language and Cognition Group
are substantially weaker than those of Frank and Goodman                  (2003). ‘Natural concepts’ in the spatial topological domain—
(2012), which were remarkably strong. Frank and Goodman                   Adpositional meanings in crosslinguistic perspective: An
explicitly anticipated that other factors such as word length             exercise in semantic typology. Language, 79, 485–516.
and frequency—which they provisionally assumed would                   Piantadosi, S., Tily, H., & Gibson, E. (2011). Word lengths are
                                                                          optimized for efficient communication. PNAS, 108, 3526-3529.
not be relevant in their initial study—may be relevant more
                                                                       Piantadosi, S., Tily, H., & Gibson, E. (2012). The communicative
generally; a natural question is whether such factors account             function of ambiguity in language. Cognition, 122(3), 280-291.
                                                                       Regier, T., Kay, P., & Khetarpal, N. (2007). Color naming reflects
   4                                                                      optimal partitions of color space. PNAS, 104, 1436-1441.
     We also repeated this uniform-prior analysis, but using the
empirical (speaker condition) rather than model likelihood, and        Regier, T., Khetarpal, N., & Majid, A. (2013). Inferring semantic
obtained very similar results (r = .71, p < .0001).                       maps. Linguistic Typology, 17, (pp. 89-105).
   5                                                                   Xu, F., & Tenenbaum, J. (2007)Word learning as Bayesian
     A possible concern is that the weaker correlations observed in
our study are an artifact of the smaller number of observations for       inference. Psychological Review, 114(2), 245-272.
each trial (we had 3 or 6 observations whereas Frank & Goodman
had 50). However, when we repeated our experiment with 50
observations per trial, we did not see substantial improvements
across the reported correlations.
                                                                   2013

