UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Making Sense out of Food
Permalink
https://escholarship.org/uc/item/82x0w05t
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Kievit-Kylar, Brent
Todd, Peter
Ahn, Yong-Yeol
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                                  Making Sense out of Food
                                             Brent Kievit-Kylar (bkievitk@indiana.edu)
                                     Cognitive Science Program, IU Bloomington, IN 47405 USA
                                                 Yong-Yeol Ahn (yyahn@indiana.edu)
                              School of Informatics and Computing, IU Bloomington, IN 47405 USA
                                               Peter M. Todd (pmtodd@indiana.edu)
                                     Cognitive Science Program, IU Bloomington, IN 47405 USA
                             Abstract                                  information (e.g., so-called McRae features that people
                                                                       generate to describe objects—McRae 2005). Similarly,
  In this paper we explore the application of a novel data
  collection scheme for multi-sensory information to the               multi-modal information from objective measures of the
  question of whether different sensory domains tend to show           visual, gustatory, and olfactory modalities along with
  similar relations between objects (along with some unique            subjective semantic and featural representations has been
  variance). Our analyses—hierarchical clustering, MDS                 shown to have significant cross-modal predictive power
  mapping, and other comparisons between sensory domains—              (Kievit-Kylar & Jones 2012a,b): Information about an
  support the existence of common representational schemes for         object in one sensory modality can provide significant
  food items in the olfactory, taste, visual, and tactile domains.
  We further show that the similarity within different sensory
                                                                       information on what that object’s representation is in
  domains is a predictor for Rosch (1975) typicality measures.         another modality. By combining information about an
  We also use the relative importance of sensory domains to            object across multiple modalities, the prediction of the
  predict the overall similarity between pairs of words, and           unknown modality improves further.
  compare subjective similarities to objective similarities based        Unfortunately, collecting objective similarity measures
  on physical sensory properties of the foods, showing a               based on physical features in various sensory domains is a
  reasonable match.                                                    difficult and expensive task, requiring specialized equipment
   Keywords: Multi-sensory; data collection; typicality.               for smell, taste, and touch information. Also, the resulting
                                                                       measures computed by collecting this information do not
                         Introduction                                  necessarily reflect the same sort of information available to
  While humans are primarily visual creatures (Barton                  and used by humans when they make their own similarity
1998, 1995) we rely on all of our senses to function in the            judgments (e.g., due to nonlinearities of senses as well as
real world. If early humans judged whether food had gone               potential mismatch between the features that can be
bad only from sight without use of smell, they would have              detected by humans versus machines). Here we use a novel
had a lower survival rate. The use of multisensory                     technique based on a fluency and grouping task to collect
information is ingrained in our world representations so               subjective similarity information across multiple sensory
deeply that it is often encountered in pre-conscious tasks             domains. This data is used to test the hypothesis that,
such as priming (Pecher 1998). But how much distinctive                overall, different sensory modalities tend to conserve the
information do the different sensory domains provide about             same similarity relations among a set of objects, coding
objects? Are exceptional objects in one sensory domain                 overlapping information. At the same time, the unique
unexceptional in others, or do the different senses tend to            variance contained in the details of those sensory modalities
provide largely overlapping information about objects?                 is critical to understanding the relationships of these
Addressing these questions and understanding the structure             objects.
of multimodal sensory representations may provide critical               To show this, we use cross-modal data we collected about
insights for building better semantic space models,                    different types of food. The category of food is useful for this
understanding language acquisition, and modeling memory                exploration because foods are fundamental objects for
phenomena including priming. Here we take an initial step              humans, and people have rich multi-sensory conceptions of
by introducing a crowdsourcing framework for collecting                various foods in terms of modalities including visual,
multi-sensory object information, and ways of analyzing it.            olfactory, taste, and tactile (we did not include aural). We
  In previous work, Kievit-Kylar & Jones (2011) showed                 then compare the subjective representations obtained from
that carefully collected visual information could be used as           people between sensory domains as well as to existing
a successful predictor for people’s judgments of overall               objective data within domains (e.g., comparing how similar
similarity between objects, and that this predictor captured           people judge the smell between two objects with how much
variance different from that supplied by semantic models               their composition of volatile chemicals overlaps) to assess
based on text corpora analysis (e.g., Dumais et al, 1997,              the extent of shared information across sensory domains for
Jones et al 2006, Lund and Burgess 1996) and featural                  foods.
                                                                   743

                        Procedures                                 participants to judge the overall similarity between items).
                                                                   (We limited domains seen per participant to three to avoid
This experiment was performed using the crowdsourcing
                                                                   fatigue.) The current sensory modality was indicated above
platform Amazon Mechanical Turk. Turk users were led to a
                                                                   the layout tool as shown in Figure 2 using an icon (nose,
custom web page from which to perform the task:
                                                                   tongue, hand, eye, and blank), the relevant verb in large
   http://www.indiana.edu/~semantic/fluency/fluency.html
                                                                   bold text, and a brief sentence priming that sensory domain,
   After providing consent, participants were asked to
                                                                   as follows:
perform a traditional verbal fluency task (Henley 1969) in
which they were given two minutes to list as many foods as
                                                                     Smell: Think about what it would be like to drive along a
they could think of. Each word entered cleared from the
                                                                   highway and smell the incredible odor of a skunk.
screen to avoid cuing. Spelling was cleaned up in post-
                                                                     Taste: Think about what it would be like to lick a penny.
processing. In the next phase, participants were given a
                                                                     Feel: Think about what it would be like to rub sandpaper
trial practice run with the word layout tool shown in Figure
                                                                   on your cheek.
1. The layout tool was seeded with words chosen to
                                                                     Look: Think about what it would be like to view a
represent all of the sensory domains we used so as to not
                                                                   beautiful landscape.
bias any in particular. The words used were: fragrant,
                                                                     Overall: Think about all of the foods that you have eaten.
woody, sweet, salty, rough, smooth, red, green. The order of
these words was randomized for participants.
   In the word layout tool, participants were allowed to
move each word by clicking and dragging with the mouse.
Words that were dragged close to each other were then
considered grouped by the system and this was indicated by
showing a connecting line. If items a and b were considered
in the same group, they were connected with a line. Far a
and b to be in the same group there has to exist a set of             Figure 2: Example of sensory cue as seen by participants.
items c, containing at least a and b and such that every item
in c is within a Euclidean length l of at least one other item       At the beginning of each layout tool round, the words
in c (where l was given as a fraction of the screen width, or      given to the participants to sort were the foods that they
the square root of .03 times the width of the display area).       themselves had entered during the initial verbal fluency
Participants were asked to move the words around the               segment of the experiment. These words were given lined up
display of the layout tool to indicate which words were            on the left side of the screen in the order in which they had
similar to each other. Their goal was to place the words into      been entered (similar to Figure 1). The participant then
groups to represent this similarity in the same fashion as         sorted the items according to their similarity in the
multidimensional scaling (MDS—Kruskal & Wish, 1978).               indicated sensory modalities until each item had been
The practice phase lasted until all items had been moved,          moved at least once and the participant clicked the
and the participant selected the “finish” button.                  “finished” button. After the three sensory sorting rounds,
                                                                   the participant was given a completion code and reimbursed
                                                                   at standard MTurk payment rates. In total, 110 participants
                                                                   completed the task.
                                                                                            Hypothesis
                                                                     We hypothesize that the similarity spaces generated by the
                                                                   participants will show common structure across the sensory
                                                                   modalities. That is, if two items are close in one sensory
                                                                   modality, they will tend to be close in another sensory
                                                                   modality. At the same time, we also hypothesize that there
                                                                   are important outliers that will provide more insights on the
                                                                   multi-sensory information integration.
                                                                                              Results
    Figure 1: Example of clustering as seen by participants
               when using the word layout tool.                      The resulting data set contained 8,609 food instances. A
                                                                   total of 475 word substitutions were generated to correct
   After the practice round, each participant was entered          spelling and lemmatize the data. This left 736 unique words,
into three more sensory modality rounds. These rounds              294 words of which occurred more than 2 times
were selected by the program and assigned in a random
order from the five categories “smell”, “taste”, “feel”,
“look”, “overall” (where “overall” was intended to lead
                                                               744

Similarity                                                           Results
   One of the primary goals of this data collection is to               Overall, each dendrogram displays a similar, intuitive
measure similarities between pairs of food items within each         pattern of clusters, as hypothesized. In each of the sensory
sensory domain. Getting a consensus similarity metric from           modalities, fruits tend to be grouped, as do vegetables,
the individual participant results required a technique for          meats, dairy, and baked goods. It is mainly in the details of
combining their data. First, we pre-processed all word sets          the variations that the differences in the sensory modalities
to standardize case and remove words not used by at least            exert themselves, such as tomato moving in with the fruits in
three participants. The remaining words were then reviewed           the smell category, or onion and potato following the round
by hand to identify spelling mistakes and standardize                fruits in the visual sensory modality.
language (e.g. normalize pluralization, compound vs.                    One way to see these differences is to follow a single food
separate words, and overly specific identifiers).                    item through the different sensory modalities and compare
   We define the similarity of a given pair of food items as         its nearest neighbor in each—for instance, “french fry.” In
follows:                                                             the visual domain, the fry is one of the immediate neighbors
                                                                     of potato chip, as both of these food items have similar
                               ∑𝑠 𝑗𝑜𝑖𝑛𝑒𝑑( 𝑓1 , 𝑓2 , 𝑠)               colors and one dimension longer than the others. The smell
              𝑠𝑖𝑚(𝑓1 , 𝑓2 ) =                                        domain also places the potato chip closest to the french fry
                                ∑𝑠 𝑢𝑠𝑒𝑑( 𝑓1 , 𝑓2 , 𝑠)
                                                                     presumably owing to the potato and oil scents. In the tactile
where s is the set of all participants, joined(a,b,s) is 1 iff a     (feel) modality, the greasiness of the fry pulls pizza in as the
and b were in the same group as defined by the participant           nearest neighbor. Under taste, subjects used knowledge that
s, and used(a,b,s) is 1 iff a and b were both entered by s.          a fry is made out of potatoes to place the potato as the
   This simple similarity measure represents the fraction of         nearest neighbor. As an overall measure, the potato chip is
participants who had connected two words together over the           again the closest neighbor to the french fry which may
number of participants who had used both words. While a              partially be due to the proximity of these two items within
measure based on the actual on-screen distance between               more sensory modalities, or may be due to the relative
pairs of items may have provided finer detail, the lines             strengths of these modalities when defining this food pair.
shown to participants (Fig. 1) indicated binary thresholds           This is the first evidence for our main hypothesis.
for similarities that may have been what was most important
to them as they positioned items; the distances between              MDS Layout
groups or between individual items within a group may not               We use classical Multidimensional Scaling (MDS) to
have mattered much during their layout process. It is                visualize the relationships between food items in 2D space.
important to note that this is a similarity metric, with higher      This is a mathematical version of what each participant
values meaning the two words are considered more similar,            manually and intuitively did with the layout tool for three
as opposed to a distance metric where lower values (smaller          sensory modalities. Here we combined all of the similarity
distances) between words indicate they are more similar.             information from participants in all five modalities using the
Both metrics will be used in the following sections.                 similarity measure described above and performed MDS on
   One problem with this technique is that a single                  the resulting averaged similarity spaces within each sensory
participant could greatly influence a similarity measure             domain for all of the food items.
between uncommon words. To avoid this, a threshold of at                Visualizations of this form and others have been shown to
least three participants all having used the same pair of            be extremely useful for understanding large data sets, and
words (regardless of whether they grouped them together or           the Word2Word visualization engine (Kievit-Kylar & Jones
not) was required for the similarity measure, otherwise the          2012a) provides a comprehensive package for generating
measure was given a value of zero. Similarity between a              such visualizations over semantic or network types of data.
word and itself was assigned the value 1.                            Words or concepts are treated as nodes in this model, and
                                                                     similarities between words are represented as edges with
Hierarchical Clustering                                              thickness relative to the strength of the similarity. The
   Hierarchical clustering was performed using the                   resulting MDS layouts for each sensory domain are shown
MultiDendrgrams software (Fernández & Gómez 2008)                    in Figure 3, where the overall similarity in shape of each is
with unweighted average distance clustering. As tree graphs          what should be focused on at this level (see also
with hundreds of nodes are very difficult to read, only the          http://www.indiana.edu/~semantic/fluency/imgs/MDS.png).
most frequently used food items (by over 50 participants)
are shown for each separate sensory modality (see                    Results
http://www.indiana.edu/~semantic/fluency/imgs/dendrogra                 Similarly to the dendrograms from hierarchical
m.png for image).                                                    clustering, the results of MDS show that these sensory
                                                                     modalities contain highly overlapping information (along
                                                                     with unique variance). The overall shape of the space within
                                                                     each of the sensory categories divides into fruits,
                                                                     vegetables, meats, and other foods. The dispersion of the
                                                                 745

different domains is also an interesting phenomenon
observable in these plots. While some domains, such as                       Table 1: Similarity between sensory domains.
“overall,” tend to have similarity relations that are well
agreed upon across participants, and thus tighter clusters,                           Smell     Taste    Feel     Look
visual or tactile information has many different types of                    Smell       1       .66      .59      .58
features (within each sensory domain) that participants                       Taste     .66       1       .65      .64
could be using to determine similarity, and the resulting                     Feel      .59      .65       1       .63
MDS space is therefore more dispersed.                                        Look      .58      .64      .63       1
                                                                       Figure 4: Visualization of similarity of sensory domains.
                                                                   Results
                                                                      As before, this analysis showed that the different sensory
                                                                   domains were highly interrelated. Taste and smell were the
         Figure 3: MDS layout on each sensory domain               most strongly correlated sensory modalities, most likely due
                           separately.                             to the strong interconnection between these two senses when
                                                                   consuming food (Roach, 2013). The least related domains
Comparing Sensory Domains                                          were visual and olfactory, reflecting their disparate bases.
  To determine more quantitatively how representations in          Visual information is effective at a greater range (finding an
one sensory modality match those in other modalities, we           item) but is not necessarily linked directly to chemical
need a metric that can compute overall similarity between          composition (can consuming that item harm us), which can
two similarity matrices. There are many techniques to do           be much more easily detected through olfaction.
this (Procrustes analysis, sum-squared error of pairs,
Pearson or Spearman correlation of rows, etc.). For the            Rosch Typicality
purposes of this paper, a simple sum-squared error of pairs           Another use of the data described in this paper is to
will be used. This is justified insofar as the data generation     determine the relative importance of different sensory
techniques we use produce their own normalization (i.e.,           domains in human ratings of how typical different items are
data are in common ranges). The precise definition of this         for their respective categories. Rosch (1975) collected a set
similarity metric is as follows:                                   of human generated typicality ratings for a number of
                                                                   different categories, including fruits and vegetables. Of the
𝑠𝑖𝑚(𝑚1 , 𝑚2 ) = ∑ ∑(𝑠𝑖𝑚(𝑤1 , 𝑤2 , 𝑚1 ) − 𝑠𝑖𝑚(𝑤1 , 𝑤2 , 𝑚2 ))𝑐      rated vegetables, 27 were matched with items our
                 𝑤1 𝑤2                                             participants generated over 5 times, and 29 matches were
                                                                   found for the fruit category. To compare Rosch’s ratings to
where the two-argument sim function on the left is the             our data, we can approximate a measure of typicality within
similarity between two sensory modalities m1 and m2 and            each sensory modality by averaging the similarity of a
the three-argument sim function is the similarity between          particular item with all other items within that category.
the first and the second word w1 and w2 within a given             Thus the typicality of an apple as a fruit, within the taste
sensory modality m. The distances between the sensory              domain, is the mean of our participants’ taste-similarity
modalities using this measure are shown in Table 1 and             ratings of apple with every other fruit they generated. Each
displayed as an MDS space in Figure 4. To perform MDS              word can then be plotted in terms of its Rosch typicality
on this table, distance space must be converted into               versus our participants’ mean similarity for each sensory
similarity space, by a simple power inversion such that each       modality. This is shown for the smell modality in Figure 5.
distance d was transformed into (1-n)c with the constant c            This figure indicates that the olfactory domain is a
set to spread the values into a reasonable range (here             moderate predictor of typicality of fruit (r=-.36) but not of
c=40).
                                                               746

vegetables (r=-.19). For the latter, the tactile and visual        the MDS layout, while the same foods (in different sensory
sensory domains are better predictors (r=-.35 and -.33).           domains) that are inconsistent with the “overall” domain
                                                                   (lighter points) are scattered around the periphery.
Item Level Domain Importance
   The data set described in this paper gives a unique look at
the similarity between sensory domains for a set of varied
food items. We can also explore, on a per-item level, how
items relate between domains. How does the similarity of a
particular object to its neighbors in one sensory domain
compare to those relationships in another domain?
                                                                      Figure 6: Items shown with intensity relative to their
                                                                   similarity of use between the “overall” domain and each
                                                                   individual sensory domain.
                                                                   Comparison to Objective Feature Similarity
                                                                      How well do the subjective similarity spaces generated by
                                                                   our participants in each sensory domain match those
                                                                   constructed from objective sensory features of the food
                                                                   items? We were only able to collect objective data about a
                                                                   sufficient number of the food items in our participant data
                                                                   for the sensory modalities of olfaction (from flavor
                                                                   compound information in Ahn et al., 2011) and vision (color
                                                                   and texture information in Meule & Blechert, 2012).
       Figure 5: Rosch typicality versus mean similarity.          Overlaps of words were found between the data sets, and
                                                                   similarity measures were computed between the participant
   To plot relative similarity of a word in its use between        generated similarities and the objective feature similarities.
domains, the “overall” domain was used as a base. For                 Figure 7 shows the olfaction data with a visual
every word and every domain, we performed the following            representation of the Procrustes analysis between subjective
operation: The row representing the similarity of the object       and objective similarity spaces. Thus, MDS was used on
w to all other objects within the domain d was extracted.          both data sets independently and then optimal parameters
The row representing the similarity of the word w within the       were used to tune scale, rotation, and translation to align
“overall” domain was also extracted. A sum-squared                 the two layouts. The participant similarities are shown with
difference similarity metric was run to compare these two          red connections and the objective similarities in green. Both
vectors, resulting in a single value for each word/domain          sets of words are laid out independently with MDS and
pair, which we call the Domain Importance Value (DIV).             aligned optimally. Black lines connect the same word in one
Note that a high DIV means high sum-square error and thus          set with itself in another. Thus shorter lines mean better
indicates a large difference between the “overall” domain          matches between the sets.
and the sensory domain in question (or a low importance
for that sensory domain in the overall domain).
   To visualize this information, an intensity value was
chosen for each item such that lighter colors are used to
represent items that are more dissimilar between the target
domain and the “overall” domain. The points representing
items were then displayed in an MDS distribution (over the
“overall” similarity space) as shown in Figure 6 (see also
http://www.indiana.edu/~semantic/fluency/imgs/ILDI.png
for a larger version).
Results
   Once again, there is a consistency across the four sensory
domains, but this time in their inconsistencies with the
“overall” similarity space. Darker points (more similar to              Figure 7: Procrustes visualization of subjective versus
the “overall” domain) tend to occur toward the center of                   objective similarities for the olfactory domain.
                                                               747

                                                                  Barton, R. A. (1998). Visual specialization and brain
   While olfaction similarities had extremely high                  evolution in primates. Proceedings of the Royal Society of
correlations, visual similarities matched significantly less        London. Series B: Biological Sciences, 265(1409), 1933-
well when full space matches like Procrustes were used, and         1937.
the structure of the olfactory data caused the MDS process        Dumais S. & Landauer T. (1997). A solution to Plato’s
to break down (too sparse a similarity set).                        problem: The latent semantic analysis theory of
   On a per-item basis, the trend is far clearer. To compute        acquisition, induction and representation of knowledge.
this for a given item, the vector row of that item                  Psychological review, 104(2), 211-240
corresponding to the similarity of that item with every other     Fernández, A., & Gómez, S. (2008). Solving non-uniqueness
item according to the participant measure was compared to           in agglomerative hierarchical clustering using
the row of that item corresponding to the objective ground          multidendrograms. Journal of Classification, 25(1), 43-
truth for that item. Because the two vectors of similarity          65.
values were generated in different ways (the former by the        Henley, N. M. (1969). A psychological study of the
mean overlap similarity measure defined earlier, and the            semantics of animal terms. Journal of Verbal Learning
latter by cosine similarity), we used a Pearson similarity          and Verbal Behavior, 8(2), 176-184.
measure to compare them. The average Pearson similarity           Jones M. N., Kintsch W., and Mewhort D. J. (2006). High-
was then computed for each item within each sensory                 dimensional semantic space accounts of priming. Journal
domain. The mean similarity per item between the                    of memory and language, 55(4), 534-552
subjective and objective similarity spaces was .51 for the        Kievit-Kylar, B., & Jones, M. N. (2011). The semantic
olfactory domain and .5 for the visual domain, indicating a         Pictionary project. In L. Carlson, C. Holscher, & T.
good match between subjective and objective similarity              Shipley (Eds.), Proceedings of the 33rd Annual
spaces for foods for these two senses.                              Conference of the Cognitive Science Society (pp. 2229-
                                                                    2234). Austin, TX: Cognitive Science Society.
                        Conclusions                               Kievit-Kylar, B., & Jones, M. N. (2012a). Visualizing
   Overall, these results support the hypothesis that the           multiple word similarity measures. Behavior research
representation of a particular item in different sensory            methods, 44(3), 656-674.
modalities will typically have strong overlap in terms of the     Kievit-Kylar, B., & Jones, M. N. (2012b). Cross modal
similarities to other items. Moreover, subjective and               inference in distributional models of semantics. Paper
objective similarity structures match up reasonably well            presented at the 22nd Meeting of the Canadian Society
(which also helps to validate the introduced data collection        for Brain, Behavior, & Cognitive Science, Kingston, ON.
technique). Ongoing extensions include testing how well           Kruskal, J.B., & Wish, M. (1978). Multidimensional Scaling
the cross-modal representation consistency can predict age          (Quantitative Application in the Social Sciences, 07-011).
of acquisition of different words—will those items that have        Beverly Hills and London: Sage Publications.
consistent representations in different sensory domains be        Lund K. & Burgess C. (1996). Producing high-dimensional
easier to learn by children?                                        semantic spaces from lexical co-occurrence. Behavior
   Food items were used in this study because foods elicit          Research Methods, Instruments, & Computers, 28(2),
sensory responses in many different modalities. However,            203-208.
by selecting this category, some modalities are increased in      McRae K., Cree G. S., Seidenberg M. S., & McNorgan C.
importance and others neglected (in particular sound was            (2005). Semantic feature production norms for a large set
not considered a relevant sense to elicit in this domain).          of living and nonliving things. Behavior Research
Food was also chosen due to the availability of rich                Methods, 37(4), 547-559
objective information about items in various sensory              Meule, A., & Blechert, J. (2012). food.pics: A picture
domains (such as nutrition or olfactory information), which         database for the study of eating and appetite. Obesity
allows comparisons with base-line measures on the items.            Facts 5 (Suppl. 2), 20.
The experimental procedure we developed could however be          Pecher D., Zeelenberg R., & Raaijmakers J. G. (1998).
used for any item category for which researchers can obtain         Does pizza prime coin? perceptual priming in lexical
a relevant set of objective sensory features.                       decision and pronunciation. Journal of Memory and
                                                                    Language, 38(4), 401-418
                                                                  Roach, M. (2013). Gulp: Adventures on the alimentary
                         References
                                                                    canal. New York: W.W. Norton.
Ahn, Y.-Y., Ahnert, S.E., Bagrow, J.P. & Barabási, A.-L.          Rosch, E. (1975). Cognitive representations of semantic
   (2011). Flavor network and the principles of food pairing.       categories. Journal of experimental psychology: General,
   Scientific Reports 1, 196. DOI:10.1038/srep00196.                104(3), 192-233.
Barton, R., Purvis, A., & Harvey, P. (1995). Evolutionary
   radiation of visual and olfactory brain systems in
   primates, bats and insectivores. Philosophical
   Transactions of the Royal Society of London. Series B:
   Biological Sciences, 348(1326), 381-392.
                                                              748

