UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Learning via Progressive Alignment using Interim Generalizations

Permalink
https://escholarship.org/uc/item/2j39t8p2

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Kandaswamy, Subu
Forbus, Ken
Gentner, Dedre

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Modeling Learning via Progressive Alignment using Interim Generalizations
Subu Kandaswamy (subu@u.northwestern.edu)
Kenneth D. Forbus (forbus@ northwestern.edu)
Qualitative Reasoning Group, Northwestern University, 2133 Sheridan Road
Evanston, IL 60208 USA

Dedre Gentner (gentner@ northwestern.edu)
Department of Psychology, Northwestern University, 2029 Sheridan Road
Evanston, IL 60208 USA

Abstract
There is ample empirical evidence that children can
sometimes learn during the course of even a few experimental
trials. We propose that one mechanism for this is the use of
analogical generalizations constructed in working memory,
producing what we call interim generalizations. Prior
research suggests that such generalizations can be constructed
when there is high similarity between closely spaced items.
This paper describes how structure-mapping simulations can
be adapted to capture this phenomenon, using automatically
encoded stimuli. It is an advance over prior models in that it
automatically detects when rerepresentation should be tried
and carries it out to improve its performance.
Keywords: Analogy; Computational modeling; Symbolic
Modeling; Cognitive Development.

Introduction
People have relational comparison capacities that seem
to outstrip any other primate (Gentner, 2003; Penn, Holyoak
& Povinelli, 2008). Yet young children are prone to focus
on object matches rather than relational matches. The
Relational Shift hypothesis (Gentner & Rattermann, 1991)
suggests that this difference is due to a lack of knowledge
about relational structures in younger children, and that as
they learn more, they gain the ability to make more
relational matches. Indeed, there is evidence that, under the
right conditions, preschool children can learn to carry out
relational matches.
In one such study, modeled here, Kotovsky & Gentner
(1996) explored children’s performance on comparison
tasks involving simple higher-order patterns, such as
symmetry and monotonic increase (Figure 1). In each triad,
the top figure is the standard, and the bottom two figures are
the choices from which a participant must pick. One choice
always has the same higher-order relationship between its
entities as does the standard, while the other has the same
entities as the relational choice, but permuted so that the
relationship does not apply. The triads in Figure 1 illustrate
the 2x2 manipulation, namely the polarity (same or
opposite) of the higher-order relation and the dimension
(size or brightness) over which the relationship holds.
Children were asked to choose which one of bottom choices
was most like the top one. No feedback was given at any
time. However, some easy high-similar triads were provided
as check trials.

The Relational Shift hypothesis predicts that older
children will do better than younger children, and that all
children will do better when there are lower-order
commonalities supporting the higher-order commonalities.
The results were consistent with these predictions: 4 year
olds performed below chance on all but the same
dimension/same polarity stimuli, where they were above
chance. By contrast, 6 year old and 8 year old children were
able to see the relational pattern to some degree without the
support of first-order relational overlap, but better with it.
The cross dimension/opposite polarity case was the hardest
condition, even for eight year olds. Yet some children
discovered this match over the course of the study. As
Kotovsky & Gentner (1996) remark:
“The emerging appreciation of relational
commonality can be seen in this comment by an eight
year old, who after struggling with her first several
cross-dimension matches, then excitedly articulated
a startlingly apt description of relational similarity:
“It’s exactly the same, but different!” She proceeded
to choose relationally for all the remaining triads”

Figure1: An example of four types of triads for a size
symmetry standard

How can we explain such learning within less than 20 trials,
without feedback? It requires that a child be able to detect
that they do not know a good answer. There is informal
evidence for this in that children in the study often puzzled
over the cross-dimensional triads, saying things like “A dark
one and a big one make daddies. The other one has two
twins and a daddy on the side.” Children further need to
figure out ways to rerepresent the stimuli so that the choice

2471

becomes clear. This rerepresentation process is aided by the
experience of comparing and aligning relational structure
across trials, as Kotovsky and Gentner showed in a second
study. In that study, 4-year-olds were given a progressive
alignment sequence: first 8 same-dimension (and same
polarity) triads, which were relatively easy to align; and
then 8 cross-dimension triads (also same-polarity). A
control group received 8 initial size-change triads (so that
they did not experience easy alignments over the saturation
dimension. The progressive alignment group performed
better on the subsequent cross-dimensional triads than did
the control group). This suggests that successfully aligning
the same-dimension triads led children to see the higherorder patterns that they had formerly missed—that is, to
rerepresent the stimuli.
This paper describes a computational model of this
phenomenon. We begin by summarizing the models of
analogical processes that we are building on. Then we
describe the idea of interim generalizations, that is,
analogical generalizations constructed within working
memory. Prior research (Gentner, Loewenstein & Hung,
2007) has suggested that such generalizations can be formed
when very similar stimuli are shown in quick succession.
Here, interim generalization serves as a rapid
rerepresentation mechanism by focusing attention on
relations that have proven beneficial in prior comparisons.
Two simulation studies are described, showing how these
ideas can account for Experiments 1 and 2 of Kotovsky &
Gentner (1996). We close with related and future work.

Background
Our model is built on Gentner’s (1983) structure-mapping
theory. We build on existing models of matching and
generalization, so we describe each in turn.
The Structure-Mapping Engine (SME; Falkenhainer et al.
1989) models the structural alignment process of
comparison. It takes as input two structured descriptions,
the base and target, which can contain entities, their
attributes, relations, and higher-order relations. SME
produces one or more mappings as its output, via a greedy
merge process (Forbus et al., 1994). Each mapping consists
of three things: (1) A set of correspondences, which
describe what goes with what (i.e. what entities and
statements match) (2) A score that provides a numerical
estimate of similarity, and (3) a set of candidate inferences
which describe how connected but non-overlapping
structure can be projected from the base to the target (or in
reverse, from the target to the base), according to the
correspondences of that mapping.
The similarity score can be normalized to be in the range
[0, 1]. There are two distinct normalization strategies, each
measuring something different. The first is to normalize by
the self-matching score of the base (or target), i.e. what
SME would compute for matching that description with
itself. This value measures how close the target (or base) is
to the representation used for normalization. The second
strategy is to normalize by the average self-matching scores

of both the base and target. This value measures how close
the two representations are to each other. As explained
below, both types of scores are used in this model.
The Sequential Analogical Generalization Engine (SAGE;
McLure et al 2010) provides a model of analogical
generalization. For each concept being learned, SAGE
maintains a generalization context which represents its
current model of that concept. Each generalization context
contains a set of generalizations and unassimilated
exemplars. Generalizations are probabilistic structured
descriptions, where the probability for each statement is the
frequency with which assimilated exemplars contain a
matching statement. We propose that there are two kinds of
generalization contexts. Persistent generalization contexts
are stored in long-term memory, and are used to accumulate
models over substantial periods of time (e.g. learning words
(Lockwood et al 2008), grammar (Taylor et al, 2011) and
conceptual change (Friedman & Forbus, 2009)). Interim
generalization contexts are part of working memory, and are
used for short-term, within-task comparisons and learning
(Day & Gentner, 2007). In interim generalization contexts,
only a small number of descriptions are maintained and
retrieval of them is based on similarity, biased via recency.
Given a new example being processed, the most relevant
abstraction from the generalization context is chosen on the
basis of its similarity score normalized with respect to the
abstraction, and modulated by recency.

Modeling the Forced Choice Task
We assume that children have default encoding strategies,
and that given a forced-choice task, they compare the
standard to each of the choices, with the standard serving as
the base. The choice with the highest base-normalized
similarity score is then selected as their choice, since they
are seeking the closest to the standard.

2472

Figure 2: Graphical representation of the relational choice
of the Different Dimension/Same Polarity saturationchange triad

But what if the two scores are very close? That is the
criterion used to trigger rerepresentation efforts: An
encoding that does not provide a clear choice is not
adequate. Such encodings arise in part because the child’s
default encoding strategies may produce extra, irrelevant
information that makes it harder for any relational
comparison to emerge. We further assume that when a
choice is clear, a generalization based on that comparison is
added to the interim generalization context. Given a
subsequent new task, if a generalization is retrieved for a
portion of the stimulus, then only the overlap between the
stimulus and the retrieved generalization is kept. This
provides filtering, to make relevant structure more apparent
based on experience. To illustrate, Figure 2 illustrates the
(automatically produced) initial representation of one of the
choices in a triad, while Figure 3 shows what remains after
filtering via an interim generalization.

on, our model uses the average self-matching score, since
that measures which pair is more promising. Particular
rerepresentation opportunities are spotted and carried out via
techniques described in (Yan et al. 2003). The basenormalized score is then recomputed based on the new
representations, and if there is now a clear difference, the
most similar choice is selected. Otherwise, rerepresentation
continues until the model runs out of techniques to try or a
resource bound is hit.

Figure 4: Graphical representation of the relational
choice after rerepresentation based on candidate
inferences.

Experiments
Figure 3: Graphical representation of the relational
choice after rerepresentation based on reminding.
Filtering based on prior generalizations is one simple
form of rerepresentation. Another, as proposed by Gentner
et al. (1995), involves recognizing that dimension-specific
comparative relations can be recast as a combination of
functions that denote dimensions and a domain-independent
comparative relation. For instance,
(darkerThan A B)
(biggerThan C D)
might be rerepresented as
(greaterThan (Darkness A) (Darkness B))
(greaterThan (Area C) (Area D))
where Area refers to the 2D area of the depicted entity.
This greatly improves the match, because structure-mapping
permits non-identical functions to align (here, Darkness
and Area) when doing so would support a larger relational
structure matching. Figure 4 illustrates how this changes
the example of Figure 3.
What signal should be used to determine when—and
which—rerepresentations are performed? That there is a
problem making a decision is clear when the scores for the
two choices are very close, as noted above. But there are
many possible rerepresentations between any two
descriptions. To decide which pair within the triad to focus

We used the Companion cognitive architecture (Forbus et al
2009) to conduct two simulation experiments,
corresponding to the first two experiments in Kotovsky &
Gentner (1996). Our goal was to model the behavior of four
year olds in the studies. That is, in the first experiment, it
should do well only on same dimension/same polarity
triads, and in the second experiment, given progressive
alignment, it should learn to do well on different dimension,
different polarity triads.
In the original study, two shapes (circles and squares),
two higher order relations (symmetry and monotonicity) and
two dimensions for the standards (size and color) were used.
This provided the basis for 16 relational patterns, 8 for each
polarity. The opposite polarity cards were only used as
relational choices, thus providing 8 standards. A stimulus
that is a standard in one triad will appear as a relational
choice in another.
16 non-relational choices were
constructed by permuting the objects in the relational
choices. We constructed 32 cards as PowerPoint slides and
used CogSketch (Forbus et al 2011), an open-domain sketch
understanding system, to generate qualitative visual and
spatial representations. CogSketch is useful for this purpose
because it can provide automatic encoding for experiments
(e.g. Kandaswamy & Forbus 2012), with a representation
vocabulary that has proven useful in modeling human visual
problem solving (Lovett & Forbus, 2011). Figure 2

2473

illustrates a portion of the representation created for two
symmetry standards of different dimensions.

Simulation Experiment 1
Recall that the four types of triads (ordered in terms of
predicted difficulty) are:
1. Same dimension/same polarity (SDSP)
2. Same dimension/different polarity (SDDP)
3. Different dimension/same polarity (DDSP)
4. Different dimension/different polarity (DDDP)
We created two ordered sets of 16 triads grouped by
polarity, shuffled so that there would be no more than two
of the same triad types consecutively, as in Experiment 1 of
Kotovsky & Gentner (1996). In particular, as in that study,
same-dimension triads (like the top left triad in Fig. 1) and
cross-dimension triads (bottom left, Fig. 1) were mixed
semi-randomly across the study. We evaluated our model on
the two sets. The model performs the triads task sequentially
following the determined order. The model uses three
parameters. The assimilation threshold (0.95) is used by
SAGE to determine when to assimilate examples into
generalization. It is also applied during the reminding phase
to choose the most similar generalization. The
rerepresentation threshold (0.55) controls when a mapping
between a base and a target looks promising enough to
attempt rerepresentation. The size limit (5) determines the
maximum number of items in the interim generalization
context. These values were set based on pilot experiments.
When the model has no clear choice, it does not make a
decision, unlike the children, who always had to make a
choice. (Importantly, the children were not given feedback
as to whether their choices were correct or not.) The
Kotovsky & Gentner experiments measured the proportion
of relational responses. Table 1 shows the results for four
year olds along with the model’s responses. As noted
above, the correct choice is always the relational choice, so
the children were above chance only for the SDSP case.
Table1: Proportions of choice types for Experiment 1

SDSP
SDDP
DDSP
DDDP

Children
Reln %
68%
49%
49%
48%

Model
Reln %
100%
0%
37.5%
12.5%

Model
NonReln%
0%
87.5%
0%
12.5%

Model
No-choice
0%
12.5%
62.5%
75%

The results of the model are qualitatively consistent with the
children’s behavior. First, the SDSP cases are easiest. The
model gets 100% of these correct because the automatic
encoding process, using CogSketch, is deterministic and
uniform, whereas children (68% correct) are likely to vary
more in their encodings. Second, when the no-choice model
answers are randomly distributed between the two possible
choices, the model is at chance for DDDP, somewhat better
than chance for DDSP, and far worse than chance for
SDDP. In the SDDP stimuli, there is sufficient relational

overlap between even a non-relational standard to make the
base-normalized comparison scores different enough to
satisfy the system that it has a reasonable answer. We
suspect that increasing the required difference in similarity
between the two alternatives would eliminate this behavior.
In the DDSP case, while the same dimension triads were not
consecutive, they were sometimes close enough that
occasionally interim generalizations were getting created.
This suggests that our model can form interim
generalizations a bit more readily than children do.
Table 2: Order of triad pairs in progressive alignment
condition as in Kotovsky & Gentner 1996
Dimension
same

Dimension of
Standard
size

same
same
same

size
color
color

cross
cross
cross

size
color
size

cross

color

High Order
Relation
monotonicincrease
symmetry
symmetry
monotonicincrease
symmetry
symmetry
monotonicincrease
monotonicincrease

Simulation Experiment 2
Experiment 2 was designed to test the Progressive
Alignment hypothesis, i.e. that children who first received
highly similar (i.e., highly alignable) closely spaced trials
could then do tasks that were beyond them previously. The
stimuli consisted of only same polarity triads. There were
two conditions.
1. Experimental condition: Eight same dimension triads
followed by eight cross dimension triads. The same
dimension triads consisted of both saturation-change
and size-change triads. To encourage progressive
alignment the triads were ordered as shown in Table
2. The children received two of each type.
2. Control condition: Same as in the progressive
alignment condition, but (as in the Kotovsky &
Gentner 1996 study) the eight same dimension triads
are all size-change triads, with no saturation-change
triads.
The procedure is the same as in Simulation Experiment 1.
The proportions of relational choices are shown in Table 3
and Table 4 respectively. Consistent with the human pattern,
the model was extremely accurate on the same-dimension
triads in both conditions. Also consistent with the human
data, the model was far more accurate on the subsequent
cross-dimensional triads in the experimental (progressive
alignment) condition than in the control condition. In the
progressive alignment condition, the model formed interim

2474

generalizations for both size-change and saturation-change.
This drove rerepresentation, leading to relational choices
being preferred. By contrast, in the control condition, the
model did not form any interim generalizations involving
saturation-change.
These results are qualitatively consistent with the results
of Kotovsky & Gentner (1996). Like the children, the model
performed better on cross-dimensional triads after
progressive alignment on both dimensions than after
progressive alignment only on the size/area dimension.
However, there are some discrepancies. The simulation
performs too well, especially on the same-dimension triads.
The model’s high degree of uniform encoding, and
aggressive use of rerepresentation, appears to be going
beyond what the children are doing.
Table 3: Proportions of choice types for Experiment 2,
Experimental Condition
Dimension

same
different

Relational
choice
100%
100%

Nonrelational
choice
0%
0%

No choice

0%
0%

Table 4: Proportions of choice types for Experiment 2,
Control Condition
Dimension

same
different

Relational
choice
100%
50%

Nonrelational
choice
0%
0%

No choice

0%
50%

Related Work
The DORA model (Doumas & Hummel, 2010) has been
used to model learning of 3D geon representations, starting
with synthetic 3D stimuli. Like our model, they extract
patterns of overlapping relations and apply them to
subsequent stimuli, although these are more like SAGE’s
persistent generalizations, since subsequent trials are
intended to model the course of development over multiple
years, versus within a single experiment, as in our model.
The interaction of perception and cognition has been
heavily emphasized in the work of Hofstadter’s group, e.g.
(Mitchell, 1993; French, 1995). Their models have focused
on highly interleaving these processes, but building domainspecific models of them, whereas our model does less
interleaving, but its components are domain-general and our
representations are calibrated against human visual problem
solving in multiple tasks (Lovett & Forbus, 2011; Lovett et
al 2007).
There has been increasing interest in rerepresentation in
analogy research. Kokinov et al. (2009) examined it in the
context of rapid visual perception, arguing that it could

cause shifts to an alternate model retrieved from long-term
memory. Davies & Goel (2008) used rerepresentation in
visual problem-solving, focusing on the classic Duncker
radiation problem.
Both share our concern with
understanding how analogy interacts with perception, but
neither of their efforts have been concerned with modeling
rapid learning.

Discussion
This paper has shown that a model based on structure
mapping and interim generalizations can simulate the
progressive alignment effects on 4 year olds found in
(Kotovsky & Gentner 1996). We conjecture that the use of
non-discriminating similarity comparisons to drive
rerepresentation, and the use of interim generalizations to
focus on relevant relational structure, are commonly used in
learning and reasoning.
There are several avenues of future work to explore.
First, even though the model’s behavior is qualitatively
consistent with that of four year olds in the experiment,
there are differences. Our model currently does not do
several things that children probably do during the course of
development. For example, it does not change its encoding
strategy to shift to a more abstract comparative relation, nor
does it introduce a new higher-order relationship (symmetry
or monotonicity) to encode the newly-discovered pattern.
Since the model’s behavior is qualitatively consistent with 4
year olds without these operations, it may be that the
children are not doing this, but there is insufficient evidence
to tell one way or the other. Second, we note that the
simulation’s responses are uniform and performance
improves rapidly, whereas children exhibit a wider range of
behavior. For example, even the 8 year olds in the original
experiment were not at ceiling in this task. Adding the
operations suggested above, and expanding the range of
rerepresentation operations available, as well as looking for
rerepresentation opportunities in both pairs, would widen
the search space of the model and perhaps capture the more
gradual improvement trajectory of children. Finally, to
explore these questions we plan to test the model with a
wider range of forced-choice tasks, to better triangulate
what combinations of processes and representations can
better explain these aspects of cognitive development.

Acknowledgments
This research was sponsored by the Socio-Cognitive
Architectures for Adaptable Autonomous Systems Program
of the Office of Naval Research, N00014-13-1-0470.

References
Davies, J. & Goel, A. (2008) Visiospatial Re-Representation
in Analogical Reasoning. The Open Artificial Intelligence
Journal, 2:11-20.

2475

Day, S. B., & Gentner, D. (2007). Nonintentional analogical
inference in text comprehension. Memory & cognition,
35(1), 39-49.
Doumas, L. A. A. & Hummel, J. E. (2010). A computational
account of the development of the generalization of shape
information. Cognitive Science, 34, 698-712.
Falkenhainer, B., Forbus, K. and Gentner, D. (1989). The
Structure Mapping Engine: Algorithm and examples.
Artificial Intelligence, 41, 1-63
Forbus, K., Ferguson, R., & Gentner, D. (1994) Incremental
Structure Mapping. Proceedings of CogSci-94.
Forbus, K, Klenk, M. and Hinrichs, T. (2009). Companion
Cognitive Systems: Design Goals and Lessons Learned
So Far. IEEE Intelligent Systems, 24(4), 36-46.
Forbus, K. D., Usher, J., Lovett, A., Lockwood, K. and
Wetzel, J., 2011. CogSketch: Sketch understanding for
cognitive science research and for education. Topics in
Cognitive Science, 3, 648-666. 43.
French, R. (1995) The Subtlety of Sameness. Cambridge,
MA: The MIT Press.
Friedman, S. and Forbus, K. (2009). Learning Naïve
Physics Models & Misconceptions. Proceedings of the
31st Annual Conference of the Cognitive Science Society.
Amsterdam, Netherlands.
Gentner, D. (1983). Structure-mapping: A theoretical
framework for analogy. Cognitive science, 7(2), 155-170.
Gentner, D. (2003). Why we’re so smart. In D. Gentner and
S. Goldin-Meadow (Eds.), Language in mind: Advances
in the study of language and cognition (pp. 195-235).
Cambridge, MA: MIT Press.
Gentner, D. (2010). Bootstrapping the mind: Analogical
processes and symbol systems. Cognitive Science, 34 (5).
752-775.
Gentner, D., Loewenstein, J., & Hung, B. (2007).
Comparison facilitates children's learning of names for
parts. Journal of Cognition and Development, 8. 285-307.
Gentner, D., & Rattermann, M. J. (1991). Language and the
career of similarity. In S. A. Gelman & J. P. Brynes
(Eds.), Perspective on thought and language:
Interrelations in development (pp. 225–277). New York:
Cambridge University Press.
Gentner, D., Rattermann, M. J., Markman, A. B., &
Kotovsky, L. (1995). Two forces in the development of
relational similarity. In T. J. Simon & G. S. Halford
(Eds.), Developing cognitive competence: New
approaches to process modeling (pp. 263-313). Hillsdale,
NJ: LEA.
Kandaswamy, S. and Forbus, K. (2012). Modeling Learning
of Relational Abstractions via Structural Alignment.
Proceedings of the 34th Annual Conference of the
Cognitive Science Society (CogSci). Sapporo, Japan.
Kokinov, B., Vankov, I., Bliznashki, S. (2009).
How
Analogy Could Force Re-representation of the Target and
Inhibition of the Alternative Interpretation. In: Kokinov,
B., Holyoak, K., Gentner, D. (eds.). New Frontiers in
Analogy Research. Sofia: NBU Press.

Kotovsky, L., & Gentner, D. (1996). Comparison and
categorization in the development of relational similarity.
Child Development, 67(6), 2797-2822.
Lockwood, K., Lovett, A., and Forbus, K. (2008).
Automatic Classification of Containment and Support
Spatial Relations in English and Dutch. Proceedings of
Spatial Cognition.
Lovett, A., & Forbus, K. (2011) Cultural commonalities and
differences in spatial problem solving: A computational
analysis. Cognition 121, pp. 281-287.
Lovett, A. Forbus, K., and Usher, J. (2007). Analogy with
qualitative spatial representations can simulate solving
Raven's Progressive Matrices. Proceedings of the 29th
Annual Conference of the Cognitive Science Society.
Nashville, TN.
Matthew McLure, Scott E. Friedman, Kenneth D. Forbus
(2010). Combining progressive alignment and nearmisses to learn concepts from sketches. Proceedings of
the 24th International Workshop on Qualitative
Reasoning. Portland, OR.
Mitchell, M. (1993) Analogy-Making as Perception: A
Computer Model. Cambridge, MA: MIT Press.
Penn, D. C., Holyoak, K. J., & Povinelli, D. J. (2008).
Darwin’s mistake: Explaining the discontinuity between
human and nonhuman minds. Brain and Behavioral
Sciences, 31, 109-178.
Taylor, J. L. M., Friedman, S. E., Forbus, K. D., Goldwater,
M. and Gentner, D. (2011). Modeling structural priming
in sentence production via analogical processes.
Proceedings of the 33rd Annual Conference of the
Cognitive Science Society (CogSci). Boston, MA.
Yan, J., Forbus, K. and Gentner, D. 2003. A theory of
rerepresentation in analogical matching. Proceedings of
the 25th Annual Conference of the Cognitive Science
Society.

2476

