UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Transfer of object shape knowledge across visual and haptic modalities
Permalink
https://escholarship.org/uc/item/29b6w0hk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Erdogan, Goker
Yildrim, Ilker
Jacobs, Robert A.
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

           Transfer of object shape knowledge across visual and haptic modalities
                                            Goker Erdogan (gerdogan@bcs.rochester.edu)
                                             Ilker Yildirim (iyildirim@bcs.rochester.edu)
                                             Robert A. Jacobs (robbie@bcs.rochester.edu)
                  Department of Brain & Cognitive Sciences, University of Rochester, Rochester, NY 14627 USA
                               Abstract                                   the existence of multisensory object representations. More-
                                                                          over, our analyses suggest that our multisensory object repre-
   We investigate the hypothesis that multisensory representa-            sentations are part-based.
   tions mediate the crossmodal transfer of shape knowledge
   across visual and haptic modalities. In our experiment, par-
   ticipants rated the similarities of pairs of synthetic 3-D objects
   in visual, haptic, cross-modal, and multisensory settings. Our                              Related Research
   results offer two contributions. First, we provide evidence for
   a single multisensory shape representation common to both vi-
   sual and haptic modalities. Second, our analyses suggest that
   these representations are part-based, representing objects as          Previous studies provide behavioral and neurophysiological
   compositions of subparts.                                              evidence for the existence of multisensory representations.
   Keywords: multisensory perception, visual perception,                  Quiroga (2012), for example, reported the existence of “con-
   haptic perception, object perception, shape representation             cept cells” which are neurons that respond selectively to par-
                                                                          ticular persons or objects regardless of the modality used to
                          Introduction                                    sense those persons or objects. One neuron, for instance, re-
Imagine the following simple scenario. You see an object,                 sponded when a person viewed an image of the television host
and later you are asked to find that object among a set of                Oprah Winfrey, viewed her written name, or heard her spoken
objects by using only your sense of touch. How might the                  name (Quiroga, Kraskov, Koch, & Fried, 2009). Additionally,
visual information about the object be transferred to the hap-            brain imaging studies (Amedi, Jacobson, Hendler, Malach, &
tic modality to achieve object recognition in this task? One              Zohary, 2002) show that LOtv, a neural region within the hu-
hypothesis is that haptic input is mapped to a visual shape rep-          man lateral occipital complex, is activated both by viewing
resentation, maybe like a form of visual imagery, and object              and touching objects.
recognition is achieved in this visual shape space. It is also               Behavioral results are consistent with neurophysiological
plausible that an analogous haptic imagery process is at play,            findings. Konkle, Wang, Hayward, and Moore (2009) re-
and object perception takes place in a haptic shape space. The            ported that motion aftereffects transferred between vision and
third alternative and the hypothesis we are arguing for is the            touch—when adapted to visual motion in a certain direc-
Multisensory Hypothesis. This hypothesis states that peo-                 tion, people felt tactile motion aftereffects in the opposite
ple use sensory representations of objects to infer amodal or             direction, and vice versa. Such a finding provides strong
multisensory representations characterizing objects’ intrinsic            evidence for a shared representation underlying visual and
properties, and object perception is mediated by these multi-             tactile motion perception. In another study, Lacey, Pappas,
sensory representations.                                                  Kreps, Lee, and Sathian (2009) found that subjects initially
   The first question we address is exactly this question of              showed viewpoint-dependent object recognition in both vi-
whether people use modality-specific (vision-specific and                 sual and haptic modalities. However, following unimodal
haptic-specific) object representations or whether they use               training with either visual or haptic stimuli, people’s object
modality-independent (multisensory) representations. The                  recognition performances became viewpoint-independent in
second question concerns the fine-grained structure of object             both modalities. A set of studies by Wallraven, Bülthoff,
representations. If multisensory representations underlie our             and colleagues also provide evidence for common object rep-
object perception, what can we say about the nature of these              resentations underlying visual and haptic object perception.
representations? An influential hypothesis in the cognitive               In these studies (Cooke, Jäkel, Wallraven, & Bülthoff, 2007;
science literature is that object representations are part-based,         Gaissert, Wallraven, & Bülthoff, 2010; Gaissert, Bülthoff, &
meaning that objects are represented in terms of their parts              Wallraven, 2011; Gaissert & Wallraven, 2012), subjects pro-
and the spatial relations among these parts (Marr & Nishi-                vided similarity judgments for different sets of objects, both
hara, 1978; Biederman, 1987).                                             artificial and natural, in vision alone, haptic alone, and vision-
   To address these questions, we collected similarity judg-              haptic conditions. It was found that subjects’ similarity rat-
ments from people about pairs of novel objects when objects               ings were similar in all three sensory conditions, thereby sug-
are viewed, when objects are grasped, when one object is                  gesting that these ratings were based on shared, multisensory
viewed and the other is grasped, and when both objects are                representations. The experiment reported here uses a similar
viewed and grasped. We found that participants gave similar               procedure, but extends this earlier work by focusing on the
ratings in all experimental conditions, providing evidence for            part-based nature of these representations.
                                                                      2163

                        Experiment                                    view an object. Messages on the computer monitor and au-
                                                                      ditory signals indicated to a participant when she or he could
Stimuli                                                               pick up and drop objects. On each trial, an experimenter first
We designed 16 novel objects based on a previously existing           placed one object in the compartment. The participant then
set of objects known as “Fribbles”. Fribbles are complex, 3-D         haptically explored this object. The experimenter removed
objects with multiple parts and spatial relations among parts.        the first object and placed a second object in the compartment.
They have previously been used in studies of visual (Hayward          The participant explored this second object. Each object was
& Williams, 2000; Tarr, 2003) and visual-haptic (Yildirim &           available for haptic exploration for 7 seconds. As is common
Jacobs, 2013) object perception.                                      in the literature on visual-haptic perception, the haptic input
   Each object is comprised of four parts that are attached to a      in the haptic experimental condition was available for longer
cylindirical body that is common to all objects.The four parts        than the visual input in the visual condition (Freides, 1974;
vary from object to object, though they are always located            Gaissert et al., 2011; Lacey, Peters, & Sathian, 2007; Newell
at the same four locations in an object. A particular object          & Ernst, 2001).
is specified by selecting one of two interchangeable parts at            In the cross-modal condition, objects in a pair were pre-
each location (4 locations with 2 possible parts per location         sented in different sensory modalities. For three participants,
yields 16 objects).                                                   the first object was presented visually and the second object
   Visual stimuli consisted of images of objects rendered from        was presented haptically. For four participants, this order was
a canonical (three-quarter) viewpoint so that an object’s parts       reversed.
and spatial relations among parts are clearly visible (see Fig-          In the multisensory condition, both objects were presented
ure 1). Stimuli were presented on a 19-inch CRT computer              both visually and haptically. During the 7 seconds in which
monitor. Participants sat approximately 55 cm from the mon-           an object could be touched, the visual image of the object was
itor. When displayed on the monitor, visual stimuli spanned           displayed for the final 3.5 seconds.
about 20 degrees in the horizontal dimension and 15 degrees              Visual and cross-modal conditions were run over two one-
in the vertical dimension. Visual displays were controlled us-        hour sessions on two different days, each session compris-
ing the PsychoPy software package (Peirce, 2007).                     ing two blocks of trials. For haptic and multisensory condi-
   Participants received haptic inputs when they touched              tions, an individual block required about an hour to complete.
physical copies of the objects fabricated using a 3-D printing        These conditions were run over four one-hour sessions.
process. Physical objects were approximately 11.5 cm long,               Of the 30 participants in the experiment, 2 participants pro-
6.0 cm wide, and 7.5 cm high. Participants were instructed to         vided similarity ratings that were highly inconsistent across
freely and bimanually explore physical objects.                       experimental blocks (one participant in the visual condition
                                                                      and the other in the multisensory condition). A Grubbs test
Participants                                                          (Grubbs, 1950) using each participant’s correlations among
                                                                      ratings in different blocks revealed that these two partic-
Participants were 30 students at the University of Rochester
                                                                      ipants’ ratings are statistical outliers (subject 1: g=2.185,
who reported normal or corrected-to-normal visual and hap-
                                                                      p<0.05; subject 2: g=2.256, p<0.05). These ratings were
tic perception. They provided written informed consent, and
                                                                      discarded from further analyses. The remaining 28 partic-
were paid $10 per hour. The study was approved by the Uni-
                                                                      ipants are divided among the four experimental conditions,
versity of Rochester Research Subjects Review Board.
                                                                      seven participants per condition.
Procedure                                                                We checked for a difference in ratings between the two
                                                                      subgroups in the cross-modal condition (one subgroup re-
On each experimental trial, a participant observed two objects        ceived visual before haptic presentation on each trial, whereas
and judged their similarity on a scale of 1 (low similarity) to 7     the other subgroup received the reverse order). A two-tailed
(high similarity). Within a block of 136 trials, each object was      Welch’s t-test (used when two samples have possibly un-
paired both with itself and with the other objects. Pairs were        equal variances) did not find a significant effect of the order
presented in random order. Participants performed 4 blocks            of the modalities in which objects were presented (t=0.087,
of trials.                                                            p<0.935). We, therefore, grouped the data from these sub-
   The experiment included four conditions referred to as the         groups.
visual, haptic, cross-modal, and multisensory conditions. In             Although participants performed four blocks of trials, we
the visual condition, participants saw an image of one object         discarded data from the first block because participants were
followed by an image of a second object. Images were dis-             unfamiliar with the objects and with the experimental task
played for 3.5 seconds.                                               during this block. Results reported below are based on data
   In the haptic condition, physical objects were placed in a         from blocks 2-4.
compartment under the computer monitor. The end of the
compartment closest to a participant was covered with a black         Results
curtain. A participant could reach under the curtain to hap-          Are object similarity ratings modality-independent? We
tically explore an object. However, a participant could not           carried out several analyses to understand whether partici-
                                                                  2164

                                            Figure 1: Stimuli used in the experiment.
pant’s similarity ratings are modality independent. In the
first of these analyses, we looked at the correlations between
the similarity judgments of participants within and across
experimental conditions. First, we averaged each partici-
pant’s ratings for each pair of objects over blocks 2-4 to form
participant-level similarity matrices. Then, we calculated the
correlations of each participant’s matrix with the participants
in the same condition and other conditions. The average
within and across condition correlations are shown in Fig-
ure 2. It is important to note that all of these correlations
                                                                                       Multi   0.89     0.81        0.83      0.86
are fairly high and, more importantly, across condition corre-
lations are roughly as large as within condition correlations.
For each condition, we also formed a condition-level similar-
                                                                                      Cross    0.86     0.78            0.8   0.83
ity matrix by averaging the participant-level matrices for the
                                                                          Condition
participants belonging to that condition. Correlations among
these condition-level matrices were extremely high, with the
                                                                                  Haptic       0.83     0.76        0.78      0.81
smallest correlation equal to 0.97. Taken as a whole, our cor-
relational analysis suggest that participants had similar no-
tions of object similarity in all experimental conditions.
                                                                                      Visual   0.91     0.83        0.86      0.89
   In our second analysis, we sought to understand the de-
gree of similarity among participants’ “perceptual spaces” for                                 Visual   Haptic      Cross     Multi
different experimental conditions. Multidimensional scaling                                                 Condition
(MDS) is widely used to extract the structure of perceptual
spaces from similarity data. MDS maps each object to a point          Figure 2: Average correlations within and across conditions
in an abstract perceptual space such that objects that are simi-      among participants’ similarity matrices.
lar are close to each other (Cox & Cox, 2000; Kruskal, 1964;
Shepard, 1962). We ran non-metric MDS with the Man-
hattan distance metric (metric MDS and Euclidean distance
metric produced similar results) on condition-level similar-
ity matrices to find four-dimensional perceptual spaces for
each condition. We assumed that the perceptual space is four-
dimensional because each object is composed of four parts
(and the shared cylindirical body). To quantify how similar
                                                                   2165

                                                                                      acquired through visual and/or haptic modalities.
            Random       0.898    0.892      0.896     0.895    0.897                    To test whether participants in our experiment used part-
                                                                                      based multisensory object representations, we ran several
                 Multi   0.151    0.108      0.119      0       0.895
                                                                                      analyses. Recall that the objects in our experiment were com-
                                                                                      posed of four parts; in other words, one can specify each of
    Condition
                                                                        Distance
                                                                          1.00        the objects with a four-dimensional representation. Thus, if
                                                                          0.75
                Cross    0.117    0.0715       0       0.119    0.896     0.50        our participants used a part-based representation, we would
                                                                          0.25
                                                                          0.00        expect the perceptual spaces associated with these represen-
                Haptic   0.131      0        0.0715    0.108    0.892
                                                                                      tations to be four-dimensional. In the first of our analyses, we
                                                                                      used MDS to examine the number of dimensions of the per-
                                                                                      ceptual space that best explains the similarity ratings in each
                Visual     0      0.131      0.117     0.151    0.898
                                                                                      condition. When applying MDS to find the perceptual spaces,
                                                                                      we varied the number of dimensions from one to six, and
                         Visual   Haptic     Cross     Multi   Random
                                           Condition                                  looked at the “stress” values. Stress values provide a measure
                                                                                      of goodness-of-fit, and are widely used to choose a percep-
Figure 3: Procrustes distances between 4-D embeddings for                             tual space’s dimensionality. In Figure 4a, we plot the stress
each experimental condition and for the Random condition.                             values as a function of the number of dimensions for each ex-
                                                                                      perimental condition and the Random condition. The stress
                                                                                      values for the Random condition are higher than the stress
the perceptual spaces for different conditions are, we used                           values for other conditions. For the four experimental condi-
Procrustes analysis to compute distances between two em-                              tions, stress values are much lower and, more importantly, the
beddings, meaning two sets of assignments of objects to loca-                         “elbows” point to a dimensionality of four, as expected from
tions in the abstract space. Since two embeddings that differ                         a part-based representation.
by a translation, rotation, or scaling correspond to the same                            Ashby, Maddox, and Lee (1994) pointed out potential pit-
spatial configuration, Procrustes analysis first finds the opti-                      falls when using MDS on average similarity matrices. First,
mal alignment between embeddings and then calculates their                            averaging favors the dominant perceptual space and may lose
distance.                                                                             information about the different perceptual spaces that some
   We computed pairwise Procrustes distances between em-                              individual subjects may use. Second, averaging increases
beddings for the four experimental conditions. To provide                             symmetry which enables the similarity judgments to be fit
a baseline against which we can compare our results, we                               well by MDS regardless of the nature of individual subject’s
added a fifth case referred to as the Random condition. For                           ratings. To avoid these pitfalls, we used the Bayesian Infor-
the Random condition, we obtained 100 similarity matrices                             mation Criterion (BIC) for multidimensional scaling devel-
by permuting the average similarity ratings of all subjects,                          oped by Lee and Pope (2003) which does not suffer from
applied MDS, and calculated the Procrustes distances be-                              these pitfalls. We reanalyzed our experimental data using
tween these embeddings and the embeddings from other con-                             MDS and BIC scores instead of stress values. The results
ditions. Figure 3 shows pairwise Procrustes distances based                           are shown in Figure 4b. For the Random case, the BIC score
on these five conditions. The Procrustes distances between                            is lowest at a dimensionality of zero, indicating that there is
visual, haptic, cross-modal and multisensory embeddings are                           no structure in the permuted matrices that can be modeled by
extremely small, especially when compared to the distances                            MDS. For the experimental conditions, BIC scores are lowest
for the Random condition. This means that the MDS em-                                 (or nearly so) at a dimensionality of four. Again, this result is
beddings of objects for all experimental conditions are nearly                        consistent with the hypothesis of part-based representations.
identical, suggesting that participants perceived similarities in                        We now re-examine the objects used in our experiment so
a highly similar fashion in all conditions. Critically, the fact                      that we can hypothesize about a likely format for part-based
that the cross-modal similarity judgments are nearly indistin-                        object representations. Our objects are composed of four
guishable from the judgments in unimodal and multisensory                             parts (plus the shared cylindrical body) which are always at
conditions supports the existence of multisensory object rep-                         the same four locations, and there are two possible parts at
resentations that are shared by visual and haptic perceptual                          each location. Hence, one can represent each of our objects
systems.                                                                              with four binary digits, where each digit corresponds to one
Are multisensory representations of objects part-based?                               of the four locations and the value of a digit specifies which
Researchers have proposed that people’s object representa-                            of the two possible parts is present at that location. We refer
tions are part-based—objects are represented by their parts                           to these representations as list-of-parts representations since
and the spatial relations among these parts (Marr & Nishi-                            each representation is a list of the four parts that make up an
hara, 1978; Biederman, 1987). Later work by Yildirim and                              object.
Jacobs (2013) extended this idea to other modalities, propos-                            We want to know if list-of-parts representations can ex-
ing part-based multisensory representations of objects that are                       plain our experimental data. To evaluate this, we used a
                                                                                   2166

                                    (a)                                                                    (b)
                                                      Condition                                                             Condition
                                                        Visual                                                               Visual
                                                        Haptic                                                               Haptic
             40                                         Crossmodal                                                           Crossmodal
                                                        Multisensory                                                         Multisensory
                                                        Random                                                               Random
                                                                                      1e+05
             30
        Stress
             20                                                               BIC Score
                                                                                      5e+04
             10
                 0                                                                    0e+00
                           2                 4                    6                           0        2             4                  6
                               Number of Dimensions                                                  Number of Dimensions
                     Figure 4: MDS stress values (a) and BIC scores (b) as a function of the number of dimensions.
Bayesian nonparametric additive clustering technique due to               compelling evidence that participants’ similarity ratings were
Navarro and Griffiths (2008). This technique infers hidden                based on modality-independent, part-based object represen-
or latent binary representations of objects from similarity rat-          tations.
ings. The technique does not assume a fixed number of di-
mensions for the representations. Rather it infers a poste-                                   Discussion and Future Work
rior probability distribution over the number of dimensions,
                                                                          In summary, we investigated two questions concerning vi-
along with a distribution over binary representations of ob-
                                                                          sual and haptic object perception: First, are people’s judg-
jects. When applied to the condition-level similarity matri-
                                                                          ments of perceptual similarity based on modality-specific or
ces, the technique found that the most probable dimension-
                                                                          modality-independent (multisensory) object representations?
ality is eight. However, the technique inferred two copies
                                                                          Our results corroborate earlier findings on the existence of
of each dimension, a potential problem noted by Navarro
                                                                          abstract multisensory representations and provide strong evi-
and Griffiths (2008). Consequently, the technique actually
                                                                          dence for the Multisensory Hypothesis. Second, what is the
inferred four-dimensional object representations. Critically,
                                                                          fine-grained nature of these representations? Our analyses
the inferred representations were the same for all experimen-
                                                                          show that participants used a part-based representation that
tal conditions and, when we discard duplicate dimensions,
                                                                          is closely related to a list-of-parts representation. However,
the inferred binary representations are exactly the representa-
                                                                          we do not claim that such simple list-of-parts representations
tions we expected—a four digit binary number for each object
                                                                          characterize people’s object representations. First, such rep-
where the value of each digit indicates the part that is present
                                                                          resentations do not specify the spatial relations among parts.
at each of an object’s four locations. This analysis provides
                                                                          It is clear, however, that people are sensitive to these spatial
strong evidence that participants in our experiment employed
                                                                          relations (e.g., consider a normal face vs. a scrambled face in
representations that are closely related to list-of-parts repre-
                                                                          which the eyes, nose, and mouth are assigned random posi-
sentations.
                                                                          tions). We consider the work reported here as an early step in
   We also examined correlations of distances between list-               understanding the fine-grained structure of object representa-
of-parts representations for pairs of objects and participants’           tions underlying visual and haptic perception. To better un-
similarity ratings. Because list-of-parts representations are             derstand the nature of these representations, further research
binary, we used the Manhattan distance metric—also known                  in more realistic scenarios with more complex objects is nec-
as city-block distance or l1 norm—to calculate distances be-              essary. We are currently working on a study to understand
tween representations. The correlations of the distances com-             how spatial relations play a role in multisensory object repre-
puted from list-of-parts representations and the experimen-               sentations.
tal condition-level similarity matrices are extremely high, all              Any hypothesis about object representations is incomplete
of them being larger than 0.97. These high correlations,                  without an account of how these representations are ac-
again, strongly suggest that participants used list-of-parts ob-          quired. We are currently working on a computational model
ject representations (or a closely related representational for-          that extracts abstract multisensory representations from vi-
mat) when judging object similarities.                                    sual and/or haptic sensory inputs. Our model combines ab-
  In summary, our experimental data and analyses provide                  stract structural object representations with sensory forward
                                                                       2167

models, and employs Bayesian inference to infer optimal ob-         Lacey, S., Pappas, M., Kreps, A., Lee, K., & Sathian,
ject representations. Then, using structural similarity mea-          K. (2009, September). Perceptual learning of view-
sures, we intend to use these inferred representations to rate        independence in visuo-haptic object representations. Ex-
the similarity between pairs of objects, and see how well our         perimental brain research, 198(2-3), 329–37.
model accounts for participants’ ratings.                           Lacey, S., Peters, A., & Sathian, K. (2007, January). Cross-
                                                                      modal object recognition is viewpoint-independent. PloS
                    Acknowledgments                                   One, 2(9), e890.
This work was supported by research grants from the Na-             Lee, M. D., & Pope, K. J. (2003, February). Avoiding the
tional Science Foundation (DRL-0817250) and the Air Force             dangers of averaging across subjects when using multidi-
Office of Scientific Research (FA9550-12-1-0303).                     mensional scaling. Journal of Mathematical Psychology,
                                                                      47(1), 32–46.
                          References                                Marr, D., & Nishihara, H. K. (1978, February). Represen-
                                                                      tation and recognition of the spatial organization of three-
Amedi, A., Jacobson, G., Hendler, T., Malach, R., & Zohary,           dimensional shapes. Proceedings of the Royal Society of
   E. (2002, November). Convergence of visual and tactile             London. Series B, 200(1140), 269–94.
   shape processing in the human lateral occipital complex.         Navarro, D. J., & Griffiths, T. L. (2008, November). Latent
   Cerebral cortex (New York, N.Y. : 1991), 12(11), 1202–12.          features in similarity judgments: a nonparametric bayesian
Ashby, F. G., Maddox, W. T., & Lee, W. W. (1994, May).                approach. Neural computation, 20(11), 2597–628.
   On the Dangers of Averaging Across Subjects When Using           Newell, F., & Ernst, M. (2001). Viewpoint dependence in vi-
   Multidimensional Scaling or the Similarity-Choice Model.           sual and haptic object recognition. Psychological Science,
   Psychological Science, 5(3), 144–151.                              12(1), 37–42.
Biederman, I. (1987). Recognition-by-Components : A The-            Peirce, J. W. (2007, May). PsychoPy–Psychophysics soft-
   ory of Human Image Understanding. Psychological Re-                ware in Python. Journal of neuroscience methods, 162(1-
   view, 94(2), 115–147.                                              2), 8–13.
Cooke, T., Jäkel, F., Wallraven, C., & Bülthoff, H. H.            Quiroga, R. Q. (2012, August). Concept cells: the building
   (2007, February). Multimodal similarity and categoriza-            blocks of declarative memory functions. Nature reviews.
   tion of novel, three-dimensional objects. Neuropsycholo-           Neuroscience, 13(8), 587–97.
   gia, 45(3), 484–95.                                              Quiroga, R. Q., Kraskov, A., Koch, C., & Fried, I. (2009, Au-
Cox, T. F., & Cox, A. A. (2000). Multidimensional Scaling,            gust). Explicit encoding of multimodal percepts by single
   Second Edition. Taylor & Francis.                                  neurons in the human brain. Current biology: CB, 19(15),
Freides, D. (1974). Human information processing and sen-             1308–13.
   sory modality: Cross-modal functions, information com-           Shepard, R. (1962). The analysis of proximities: Multidi-
   plexity, memory, and deficit. (Vol. 81) (No. 5). US: Ameri-        mensional scaling with an unknown distance function. I.
   can Psychological Association.                                     Psychometrika, 27(2), 125–140.
Gaissert, N., Bülthoff, H. H., & Wallraven, C. (2011, Septem-      Tarr, M. J. (2003). Visual Object Recognition: Can a Single
   ber). Similarity and categorization: from vision to touch.         Mechanism Suffice? In Perception of faces, objects, and
   Acta psychologica, 138(1), 219–30.                                 scenes : Analytic and holistic processes (pp. 186–220).
Gaissert, N., & Wallraven, C. (2012, January). Categorizing         Yildirim, I., & Jacobs, R. (2013). Transfer of object category
   natural objects: a comparison of the visual and the hap-           knowledge across visual and haptic modalities: Experi-
   tic modalities. Experimental brain research, 216(1), 123–          mental and computational studies. Cognition, 126, 135–
   34.                                                                148.
Gaissert, N., Wallraven, C., & Bülthoff, H. (2010). Visual and
   haptic perceptual spaces show high similarity in humans.
   Journal of vision, 10(2), 1–20.
Grubbs, F. (1950). Sample Criteria for Testing Outlying Ob-
   servations. The Annals of Mathematical Statistics, 21(1),
   1–164.
Hayward, W. G., & Williams, P. (2000, January). Viewpoint
   Dependence and Object Discriminability. Psychological
   Science, 11(1), 7–12.
Konkle, T., Wang, Q., Hayward, V., & Moore, C. I. (2009,
   May). Motion aftereffects transfer between touch and vi-
   sion. Current biology: CB, 19(9), 745–50.
Kruskal, J. (1964). Multidimensional scaling by optimizing
   goodness of fit to a nonparametric hypothesis. Psychome-
   trika, 29(1), 1–27.
                                                                2168

