UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
GAMIT-Net: Retrospective and prospective interval timing in a single neural network.
Permalink
https://escholarship.org/uc/item/3fb5j4rm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Addyman, Caspar
Mareschal, Denis
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                     University of California

            GAMIT-Net: Retrospective and prospective interval timing in a single neural
                                                                network.
                                          Caspar Addyman (c.addyman@bbk.ac.uk),
                                           Denis Mareschal (d.mareschal@bbk.ac.uk)
                                       CBCD, Department of Psychological Sciences, Birkbeck,
                                    University of London, Malet Street, London, WC1E 7HX, UK
                              Abstract                                memory traces to decay faster leading to longer estimates.
   The neural network version of the Gaussian Activation Model
                                                                      This factor alone explains increases in retrospective timing
   of Interval Timing (GAMIT-Net) is a simple recurrent               paradigms where a time estimate must be made without
   network that unifies retrospective and prospective timing in a     prior warning (and hence without intermediate sampling).
   single framework. It has two parts. Firstly, a time-dependent      (2) In prospective timing where it is known in advance that
   signal is generated by a spreading Gaussian activation. Next,      a time estimate will be required, participants will be
   a simple recurrent network (SRN) combines information from         estimating time as the task progresses. Increased cognitive
   the Gaussian and its own internal state during a timing task to    load will lead to reduced number of these intermediate
   generate time estimates. This model captures the scalar
   property of interval timing (Gibbon, 1977). Furthermore,           estimates. This gives the sense that time is passing more
   under high cognitive load the Gaussian fades faster while the      quickly and results in shorter estimates. Finally, the
   internal state is updated less often. These factors interact to    connectionist nature of the model provides a framework for
   account for the surprising finding that retrospective estimates    explaining developmental effects.
   increase under cognitive load while prospective estimates             The paper is organized as follows. We begin by
   decrease (Block, Hancock & Zakay, 2010).                           describing existing models of interval timing and discuss
   Keywords: interval-timing, activation-based model, time-           two recent key findings that a good model must address. We
   perception, retrospective and prospective timing.                  then describe of our connectionist model of timing based on
                                                                      memory-trace decay and demonstrate mathematically why
                          Introduction                                our model is constrained to show linear growth in errors.
   Our sense of time is ubiquitous and yet enigmatic.                 Finally, we present the simulations of the model. In
Interval timing is central to cognition in humans (e.g.,              particular, we show how prospective and retrospective
Grondin, 2008; Zakay & Block, 1997) and animals (Gibbon               estimates can be made within a single framework and yet
and Allan, 1984). It may even underlie conditioned learning           have opposite effects of cognitive load. We also show how
in animals (Gallistel & Gibbon, 2000). Over intervals in the          this model could provide developmental predictions.
range from half a second to several minutes humans and
other animals show very similar abilities. Interval timing            Existing models of interval timing
judgments by humans, rats and pigeons obey a version of                  There are three major classes for interval-timing model.
Weber‚Äôs Law known as the scalar property (Gibbon, 1977).              (1) Pacemaker-accumulator models rely on an internal
Yet three mysteries exist. What explains the scalar property?         pacemaker that emits regular, short pulses that are counted
Why do retrospective and prospective timing show opposite             by an accumulator. The number of pulses stored in the
effects of cognitive load (Block, Hancock & Zakay, 2010)?             accumulator gives the measure of the time that has passed
What explains the long developmental trajectory for interval          (Church, 1984; Gibbon et al. 1984; Taatgen et al, 2007). (2)
timing abilities (e.g., Szelag et al, 2002; Droit-Volet,              Multiple oscillator-coincidence detector models (also
Tourret & Wearden, 2004)? The current paper builds on our             sometimes called timestamp models) rely on multiple
previous research (Addyman et al. 2011; French et al. 2014)           neuronal oscillators started simultaneously with coincidence
to provide a unified answer to all these questions.                   detectors associating particular patterns of firing with given
   Our Gaussian Activation Model of Interval Timing                   time intervals, effectively time-stamping when an event
(GAMIT-Net) is a stochastic learning model. GAMIT-Net                 occurs (Church & Broadbent, 1990; Matell & Meck, 2000)
has two parts a columnar memory trace that produces decay             (3) In memory or neural process models the passage of time
and a connectionist simple recurrent network (Elman, 1990)            is derived from the activation of a neural process that is
that samples the decaying trace to provide time estimates.            decaying (Staddon & Higa, 1999) or increasing (Reutimann
The traces decay in statistically predictable (Gaussian)              et al., 2004).
manner permitting timing estimates. Mathematical
constraints on the accuracy of these estimates leads to the           The Scalar Property
linear growth in errors characteristic of the scalar property.
The differences between retrospective and prospective                    The scalar property or time scale invariance (Gibbon,
timing with cognitive load are explained through the                  1977) is a very widely replicated effect with humans, rats
interaction of two factors. (1) High cognitive load causes            and pigeons (Gibbon & Allan, 1984; Gibbon et al, 1997;
                                                                   98

Matell & Meck, 2000). It states that participant responses in       the case of prospective timing. This interaction is a
an interval timing task will have an approximately normal           challenge to clock and timestamp models. They provide no
(right skewed) distribution peaked at the target time with the      a priori reason to expect a difference between these two
width of the distribution directly proportional to the length       conditions. Furthermore, this interaction suggests that
of the interval. In other words the growth of error is constant     cognitive load is not just an additive factor (e.g., damping
(scalar) such that if estimates for interval T have error ¬±E,       responses across the board). This is a challenge for all
an interval of 2T will have errors ¬±2E. This is an instance of      existing models of interval timing. The main aim of the
Weber‚Äôs Law, which states that the confusability of two             GAMIT-Net model is to explain the scalar property and
stimuli is proportional to their magnitude. It places several       seemingly disparate retrospective and prospective timing in
important restrictions on the nature of any interval timing         a single framework.
mechanism (Hass & Hermann, 2012).
   In particular, it implies that the neural process underlying                             GAMIT-NET
time perception must measure growing variance in the                   In this section we describe GAMIT-Net, our model of
system. Only variance-based processes will lead to the              interval timing. A MATLAB implementation of the model
scalar growth of error. Accumulator models base their               is available at http://github.com/YourBrain/GAMIT.
estimates on the mean number of accumulated ticks.                     GAMIT-Net is built on the intuition that our sense of time
According to the Central Limit Theorem, such estimates              arises from our fading memory for events. The longer ago
have errors that grow with the square root of the total.            an event happened the fuzzier the memory associated with it
Pacemaker-accumulator models must introduce assumptions             will be. We claim that this relationship is statistically
as to why the cognitive system cannot use these more                predictable and that our interval timing abilities are acquired
precise quantities (e.g. Gibbon, 1992). Other models                by process of learning from our experience of changes in the
introduce arbitrary Gaussian thresholds on otherwise linear         world around us. We use estimates of the variance of the
(Reutimann et al., 2004) or logarithmic processes (Staddon          spreading Gaussian activation trace as a measure of how
& Higa, 1999). Early multiple oscillator models required            much time has passed. Furthermore, inescapable errors in
perfectly correlated sets of oscillators (Matell & Meck,            the estimation process lead to the scalar property.
2004). Recent work addresses this using more realistic,                Two factors account for differences between retrospective
noisy neural oscillators and neural network architecture            and prospective timing. First, we assume that the memory
(Buhusi & Oprisan 2013). However, no model that we are              decay is affected by cognitive load. Decay occurs faster
aware of accounts for the scalar property as an unavoidable         under high cognitive load, perhaps due to global inhibition
consequence of the way the timing mechanism works (Hass             from competing processes. This factor alone accounts for
& Hermann, 2012; Hass et al. 2008).                                 longer estimates in retrospective timing. Secondly, in
                                                                    prospective timing, we must additionally take into account
Retrospective and prospective time estimation                       the fact that participants will be making intermediate
   One of the biggest distinctions within interval timing is        estimates as the task progresses. We assume that the
between retrospective and prospective paradigms.                    cognitive system makes a number of ‚Äòattentional saccades‚Äô
Retrospective time keeping concerns our estimates of time           to the activation trace during a given interval. The final
in the recent past, while prospective time keeping concerns         estimate will take account of both the final pattern of
our predictions about the near future. In the former                activation and these intermediate estimates. Under high
awareness that time must be judged comes without warning            cognitive load the trace is decay faster as before but in
at the end of the interval, while in the latter it is known from    addition there will be fewer attentional saccades that are
the beginning of the interval that a time judgment will be          more spread out in time, giving the sense of time that less
required. Zakay and Block (2004) refer to this as the               time has passed, leading to shorter estimates.
difference between remembered and experienced duration.
The majority of models of time perception are models of             Network architecture
prospective timekeeping only. They are concerned with
                                                                    GAMIT-Net has two distinct components; a fading
predictions about future events, such as rats and pigeons
                                                                    Gaussian memory and a connectionist learning network.
learning to respond maximally at the target time in a fixed
                                                                    The network is schematically represented in Figure 1. In this
interval paradigm. One reason is they are built around a
                                                                    section we first describe the Gaussian activation curve and
counter (e.g. an accumulator, a set of oscillators or a
                                                                    explain why it constrains our model to show at best linear
climbing neural process) that must be explicitly started for
                                                                    growth in errors. Next we explain how the model uses a
each trial, something that is (by definition) not possible in
                                                                    simple recurrent network (SRN) architecture to capture both
retrospective paradigms.
                                                                    retrospective and prospective timing within a single
   The other reason is that retrospective and prospective
                                                                    framework.
estimates show a striking interaction with cognitive load.
Block et al. (2010) analyzed the results from over one
hundred studies with human subjects. They found that high
cognitive load increases your estimates in the case of
retrospective timing, whereas it decreases your estimates in
                                                                 99

                                                                                                                                                              Curve
                            Time Estimates                                                              0.1
                         (Thermometer scale)            GAMIT                                                                                                 Iterations
                                                                                                                                                                 10
  OUTPUT                                                Simple                                         0.09
                                                                                                                                                                 110
  (20 Units)
                                                      Recurrent                                        0.08
                                                                                                                                                                 210
                                                       Network                                         0.07                                                      310
                                                                                                                                                                 410
                                                                                                       0.06
  HIDDEN
                                                                                          Activation
                                                                                                                                                                 510
 (20 Units)                                                 Recurrent                                  0.05                                                      610
                                                            Connections
                                                                                                       0.04                                                      710
                                                                                                                                                                 810
                                                                                                       0.03
                                                                                                                                                                 1010
   INPUTS
 (220 Units)                                                                                           0.02                                                      1210
                                                                                                                                                                 1410
                                                                                                       0.01
                Gaussian Activation (200 units)   Context (20 units)
                                                                                                                                                                 1610
                                                                                                         0
                                                                                                              70   80   90    100 110       120   130   140
     Figure 1: GAMIT consists of an Elman-style simple                                                                       Columns
   recurrent network that learns to convert time-decaying
    Gaussian activation curves into linear time estimates.                                 Figure 2: An initially localized activation fades and
                                                                                         spreads over time as equation 1 iterates through time.
                                                                                      Curves are color coded according to the number of iterations
Time as Gaussian Activation Decay                                                            indicated by the scale on the right hand side.
  To implement the GAMIT-Net model, we begin with a                                   measure of their confusability (Kullback & Leibler, 1951)
cluster of cortical columns. The activation in the central                            and is given by:
column corresponds to an event in the world that is
registered in memory. Activation then spreads across the                                                                     !! !!! !       ! !!!                     !!!
                                                                                                       ùê∑!" (ùëã! ùëã ! ) =                  +           ‚àí 1 ‚àí ùëôùëõ                 ¬†.
cortical columns as follows. If we designate the activation                                                                   !!!!          ! !!!                     !!!
of the ith column at time step t by Ai(t), its activation at time                       We wish to show that in general
t+1 is determined by the following equation:
                                                                                                          DKL(X(t) || X(t+Œî)) = DKL(X(2t) || X(2t+ 2Œî)).
 ùê¥! ùë° + 1 = ùõºùê¥! ùë° + ùõΩ ùê¥!!! ùë° + ùê¥!!! ùë°                  + ùúâ ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†(1)
                                                                                      This is easy to see since, in all cases, ¬µ is constant so the
 where Œ± is the fraction of activation that remains in column                         first term cancels to 0 and other term is in ratio of ùúé!! to ùúé!!
i on each time step; Œ≤ is the fraction of activation spread                           which is the same in both cases; on the left hand side the
from each immediate neighbor of i on each time step; Œæ is a                           ratio ùúé ‚à∂ (1 + Œî)ùúé while on the right it is 2ùúé ‚à∂ (2 + 2Œî)ùúé.
noise parameter. The values of Œ± and Œ≤ must be chosen so                                 In other words, the confusability of Gaussian-like curves
that the total activity over time of the system neither rapidly                       grows linearly with variance (when the means are the same).
decreases to zero nor increases exponentially. Unless                                 Hence any process based on the discriminating two such
otherwise stated, we used values of Œ± = 0.7, Œ≤ = 0.14952                              curves cannot do better than a scalar error. Unlike in other
and Œæ = 0.00025. The evolution of activation in this cluster                          models, in GAMIT-Net scalar errors are a lower bound on
of columns is illustrated by the series of graphs in Figure 2.                        accuracy. Furthermore, as we will see below, the
Note that the difference equation presented here is an                                implemented version of GAMIT-Net shows a broadly linear
approximation to an underlying stochastic process. There is                           growth in error.
ample neurobiological evidence for this type of spreading-
                                                                                      GAMIT-Net Simple Recurrent Network
activation mechanism (e.g., Amari, 1980; Grossberg, 1980;
Herman et al., 1993; Koch & Segev, 1998; Capaday et al.,                                 The current paper uses an SRN (Elman, 1990) to combine
2011).                                                                                two of our previous modelling efforts (Addyman et al.,
                                                                                      2011; French et al., 2014) in a single framework. Addyman
Mathematical contraints on temporal estimates.                                        et al. (2011) showed that a feedforward neural network built
  Time estimates in GAMIT-Net are based on the growing                                on top of the Gaussian spreading activation function could
variance in the system as an initially localised activation                           model how timing abilities are acquired in infancy. We used
spreads through the columns. Here we show, following Hass                             motor signals to calibrate an embodied timing mechanism
& Hermann (2012), that if the underlying process has a                                across multiple sensory modalities. This model showed
linear growth in variance (i.e. X(t) ~ N(¬µ, œÉ), X(2t) ~ N(¬µ,                          developmental effects (Szelag et al., 2003) and the scalar
2œÉ)), X(3t) ~ N(¬µ, 3œÉ), then the scalar property arises                               property but could not capture retrospective and prospective
because these estimates can only be made with limited                                 effects (Block et al 2010). In a separate cognitive model
accuracy. Namely that if the uncertainty at time t is Œî, then                         (GAMIT - French et al., 2014) we demonstrated how to
at time 2t it will be 2Œî.                                                             capture those effects. That paper introduced the idea that
  The Kullback‚ÄìLeibler divergence between two normal                                  prospective timing involves ‚Äòattentional saccades‚Äô during
                                                                                      the timing task which affect estimates by using
distributions X1 ‚àº N(¬µ1, œÉ21‚Äâ‚ÄØ) and X2 ‚àº N(¬µ2, œÉ22‚Äâ‚ÄØ) provides a
                                                                                100

compensatory parameter which reduced prospective                          	 ¬†
estimates when saccades were less frequent (i.e. when time
appeared to passing more quickly). However, that model                                                        	 ¬†                                             Retrospective SRN Learning                 Epochs
could not capture learning.                                                                                   	 ¬†                                                                                               20
  In GAMIT-Net each time related event corresponds to an                                                      	 ¬†                           1500                                                                18
updating of the network. In retrospective case, the SRN
                                                                                                                     Network Time Estimate
                                                                                                              	 ¬†                                                                                               16
receives just two updates; one for the initial event and one at
                                                                                                              	 ¬†
                                                                                                                                                                                                                 14
the test time. In the prospective case, the network is also                                                                                  1000                                                                12
updated at intermediate points when the cognitive system                                                      	 ¬†                                                                                               10
monitors the passage of time (attentional saccade to the                                                      	 ¬†                                                                                               8
timing task). Higher cognitive load increases the decay of                                                    	 ¬†                           500
                                                                                                                                                                                                                 6
the Gaussian but decreases the number of saccades. In all
cases, we coded the initial event by a localised activation
                                                                                                              	 ¬†                                                                                               4
and empty context units and at each subsequent update the                                                     	 ¬†                                                                                               2
                                                                                                              	 ¬†
                                                                                                                                                0
inputs are the current Gaussian activations and a copy of the                                                                                       0   200     400   600     800   1000 1200 1400 1600 1800
                                                                                                                                                                            Target Time
previous hidden representation in the context units.                                                          	 ¬†
                                                                                                              	 ¬†
                        RESULTS                                                                               	 ¬†                                             Prospective SRN Learning                   Epochs
  We report three simulations results. First, we show that a                                                  	 ¬†
                                                                                                                                                                                                                 20
single network can learn to perform both retrospective and                                                                                                                                                       18
prospective timing and learning could be a rich source of                                                     	 ¬†                           1500
                                                                                                                     Network Time Estimate
                                                                                                                                                                                                                 16
developmental predictions. Second, we show that a trained                                                     	 ¬†                                                                                               14
network has scalar errors in both paradigms. Third, we show                                                   	 ¬†                           1000                                                                12
that increased cognitive load has a differential effect on                                                    	 ¬†                                                                                               10
retrospective and prospective time estimates in line with
empirical findings (Block et al. 2010).
                                                                                                              	 ¬†                                                                                               8
                                                                                                              	 ¬†                           500
                                                                                                                                                                                                                 6
Simulation 1 ‚Äì Retrospective and prospective                                                                                                                                                                     4
estimates in a single network.                                                                                                                                                                                   2
                                                                                                                                                0
  Ten SRNs with 220 inputs (200 curve + 20 context), 20                                                                                             0   200     400   600     800   1000 1200 1400 1600 1800
                                                                                                                                                                            Target Time
hidden and 20 output units were initialized with small
                                                                                 Figure 3: 10 na√Øve networks were trained for 20 epochs.
random weights and were trained for 20 epochs each. For
                                                                                    Each epoch contained 2500 randomly determined
each epoch of training we generated 50 fading Gaussian
                                                                                       retrospective and prospective timing events
curves by iterating an initially localized input using
Equation 1 with the parameters given above. For a given
curve we randomly picked 50 target times and presented the                                                                                                     Retrospective Relative Error
                                                                                 Error / Interval Length
network a random mixture of retrospective (p=0.5) and
prospective (p=0.5) timing events. Hence each epoch
consisted of 2500 training events. In a retrospective timing                                                0.1
event, the network received an input at the start of the trial
and second input and hidden layer context at the end. In a                                                 0.05
prospective timing event the network also received inputs of
the curve shape and context at several random attentional                                                    0
                                                                                                                  0                            200       400      600        800    1000   1200   1400   1600   1800
saccades. Saccades were generated by a Poisson process                                                                                                                Target Time
with parameter Œª	 ¬† =	 ¬† 100.	 ¬† Target times were coded on a                                                                                                Prospective Relative Error
                                                                                 Error / Interval Length
thermometer scale and learning was via backpropagation of
errors. The learning rate was 0.05 and the momentum was
                                                                                                            0.1
0.005. At each epoch of training we tested the networks
across the full range of possible time intervals on each of the
two timing tasks. Figure 3 shows the average output of the                                                 0.05
20 networks. As can be seen the network learns both tasks
well, approaching the idealised performance (dotted line) as                                                 0
                                                                                                                  0                            200       400      600        800    1000   1200   1400   1600   1800
they mature. Immature networks overestimate short                                                                                                                       Target Time
intervals and underestimate long ones in line with                                                                                                                                                                     	 ¬†
                                                                         Figure 4: The relative error on time estimate tasks. Average
experimental results with children (Szelag et al. 2003).
                                                                         of 20 fully trained networks. Dotted line show best linear fit.
                                                                   101

Simulation 2 ‚Äì The Scalar Property
                                                                                                              1.2
  Ten SRNs were fully trained as in Simulation 1 with 20
                                                                                                                      Retrospective
epochs of 2500 training events. Figure 4 shows the average
                                                                             Mean Duration Judgement Ratio
                                                                                                                      Prospective
relative error for 20 networks across the full range of                                                      1.15
possible time intervals on each of the two timing tasks,
calculated by dividing the absolute error by the target time.
These plots show that relative error was broadly constant                                                     1.1
proportion at all time intervals in line with the scalar
property.	 ¬†
                                                                                                             1.05
Simulation 3 ‚Äì The effects of cognitive load
  A single SRN was fully trained as in Simulation 1 with 20
epochs of 2500 training events with normal cognitive load                                                      1
                                                                                                                     0.95               1               1.05
parameters. . To simulate high cognitive load conditions we                                                                                             High
                                                                                                                     Low
decreased the value of decay parameter Œ≤ to 0.14946 and
                                                                                                                    Relative Cognitve Load (Normal load = 1.0)
increased the sampling parameter Œª to 110. For lower-than-
typical cognitive load, Œ≤ was increased to 0.14955 and Œª                Figure 6: Performance of GAMIT under cognitive load,
decreased to 90. We then tested the networks performance                    Results averaged over 20 runs of the program.
on 20 estimates of with target time t = 600. The results are
shown in Figure 6. The pattern of performance matched that            Finally, the neural network architecture of makes GAMIT-
found in Block et al. (2010), as shown in Figure 5. It is             Net unique as a developmental model of time perception
important to note that prospective underestimates are an              that allows for research and predictions about infant timing
emergent property of the network. They are a result of the            abilities.
weighting that the network learns to give these two                      GAMIT-Net addresses all these issues and, we believe, it
competing pieces of information under normal cognitive                has other features to recommend it. The model has good
load.                                                                 explanatory power. It is important to note that the network
                                                                      was not specifically designed to show the cognitive load
                                                                      interaction (Block et al. 2010). Philosophically, we believe
                                                                      our model is an advance over clock-based models in that
                                                                      gets more directly at the experience of time passing. Longer
                                                                      intervals correspond to greater memory decay. While
                                                                      greater cognitive load has two complementary effects of
                                                                      making memories fade faster and making time seem to pass
                                                                      more quickly.
                                                                         Moreover, activation decay and growth processes are
                                                                      ubiquitous and well understood and can account for
                                                                      evidence that timing and memory use the same cognitive
                                                                      resources (Fortin and Rousseau, 1997; Fortin, 1999) and
                                                                      both recruit the dorso-lateral prefrontal cortex (Wager and
                                                                      Smith, 2003, Genovesio et al., 2006). Related to this, the
                                                    	 ¬†              neural network architecture GAMIT-Net provides an
                                                                      approach to timing in which is based on a lifetime of past
 Figure 5: The effects of cognitive load on interval timing           experiences of observing change in the world. As a result
    based on a meta-analysis of 82 prospective and 31                 information about the passage of time is embedded in the
          retrospective tasks (Block et al., 2010).                   world rather than constructed in an abstract cognitive
                                                                      module.
                        Conclusion                                       There remain many issues to address. In Simulation 2, the
We have developed GAMIT-Net to address three goals.                   fit to linear growth in error is not perfect and future work
First, we sought to build a model of interval timing based on         should investigate it. Some studies report a greater than
measured variance that would give rise to the scalar                  linear increase of the timing errors (reviewed in Gibbon et
property as direct consequence of the way the timing                  al., 1997; Grondin, 2001; Hass et al., 2008). At present
mechanism works without ad-hoc assumptions or                         model fits data from a meta-analysis. Future work must
modifications (Hass & Herrmann, 2012). Second, we                     simulate results from individual experiments. Likewise, the
wished to unify prospective and retrospective interval                current work is restricted to recognition tasks where an
timing within a single model while still being able to                estimate is given at the end of an interval. The model should
account for the differential effects of cognitive load (Block         also be used to production tasks where participants generate
et al, 2010).                                                         time. We believe that the attentional saccade mechanism
                                                                102

built into GAMIT-Net provides a natural means of                 Gibbon, J. (1992). Ubiquity of Scalar Timing with a Poisson
simulating production tasks. Much further work is needed           Clock. Journal of Mathematical Psychology, 36, 283‚Äì
but we believe GAMIT-Net represents a powerful new                 293.
paradigm in interval timing research.                            Gibbon, J. & Allan, L. (Eds.) (1984) Timing and time
                                                                   perception. (Vol. 423) New York, NY: New York
                    Acknowledgments                                Academy of Sciences.
This work was supported by UK ESRC grant (RES-062-23-            Gibbon, J., Church, R., and Meck, W. (1984). Scalar timing
0819).                                                             in memory. New York Academy of Sciences., 423, 52‚Äì77.
                                                                 Gibbon, J., Malapani, C., Dale, C.L., & Gallistel, C. (1997).
                                                                   Toward a neurobiology of temporal cognition: advances
                        References                                 and challenges. Current Opinion in Neurobiology, 7(2),
Addyman, C., French, R.M., Mareschal, D. & Thomas, E.              170‚Äì184.
  (2011) Learning to perceive time: A connectionist,             Grossberg, S. (1980) How does the brain build a cognitive
  memory-decay model of the development of interval                code? Psychological Review, 87, 1‚Äì51.
  timing in infants. In, Proc. of the 33rd Annual Conference     Grondin, S. (2001). From physical time to the first and
  of the Cognitive Science Society, 354-359.                       second moments of psychological time. Psycholigcal
Amari, S. I. (1980) Topographic organization of nerve              Bulletin, 127(1), 22‚Äì44.
  fields. Bulletin of Mathematical Biology, 42, 339‚Äì364.         Hass, J., & Herrmann, J. M. (2012). The neural
Block, R. A., Hancock, P. A., & Zakay, D. (2010) How               representation of time: an information-theoretic
  cognitive load affects duration judgments: A meta-               perspective. Neural Comp., 24, 1519‚Äì1552.
  analytic review. Acta Psychologica, 134, 330‚Äì343.              Hass, J., Blaschke, S., Rammsayer, T., & Herrmann, J. M.
Buhusi, C. V., & Oprisan, S. A. (2013). Time-scale                 (2008). A neurocomputational model for optimal
  invariance as an emergent property in a perceptron with          temporal processing. Journal of Computational
  realistic, noisy neurons. Behavioural Processes, 95, 1‚Äì11.       Neuroscience, 25, 449‚Äì464.
  doi:10.1016/j.beproc.2013.02.015                               Herman, M., Ruppin, E. & Usher, M. (1993) A neural
Capaday C, van Vreeswijk C, Ethier C, Ferkinghoff-Borg J           model of the dynamic activation of memory. Bio. Cyber.,
  and Weber D (2011) Neural mechanism of activity spread           68, 455-463.
  in the cat motor cortex and its relation to the intrinsic      Koch, E. & Segev, I. (1998). Methods in Neuronal
  connectivity. Journal of Physiology, 589, 2515-2528.             Modeling : From Ions to Networks. Cambridge, MA: The
Church, R. (1984). Properties of the internal clock. Annual        MIT Press.
  Proceedings of the New York Academy of Science, 423,           Matell, M. S. & Meck, W. H. (2000) Neuropsychological
  566‚Äì582.                                                         mechanisms of interval time behavior Bioessays, 22, 94-
Church, R., & Broadbent, H.(1990) Alternative                      103.
  representations of time, number and rate. Cognition, 37,       Reutimann, J., Yakovlev, V., Fusi, S., & Senn, W. (2004).
  55‚Äì81.                                                           Climbing neuronal activity as an event-based cortical
Droit-Volet, S. (2003). Alerting attention and time                representation of time. Journal of Neuroscience, 24,
  perception in children. Journal of Experimental Child            3295‚Äì3303.
  Psychology, 85(4), 372‚Äì384.                                    Staddon, J.E.R. & Higa, J.J. (1999) Multiple time scales in
Elman, J. L. (1990). Finding structure in time. Cognitive          simple habituation. Psychological Review, 103, 720-733.
  Science, 14, 179‚Äì221.                                          Szelag, E., Kowalska, J., Rymarczyk, K., & P√∂ppel, E.
Fortin, C. (1999) Short-term Memory in Time Interval               (2002). Duration processing in children as determined by
  Production. International Journal of Psychology 34, 308-         time reproduction: implications for a few seconds
  316.                                                             temporal window. Acta Psychologica, 110(1), 1‚Äì19.
Fortin, C., & Rousseau, R. (1998). Interference from short-      Taatgen, N. A., van Rijn, H., & Anderson, J. (2007). An
  term memory processing on encoding and reproducing               integrated theory of prospective time interval estimation:
  brief durations. Psychological Research, 61, 269‚àí276.            The role of cognition, attention, and learning.
French, R. M., Addyman, C., Mareschal, D., & Thomas, E.            Psychological Review, 114, 577‚Äì598.
  (2014). Unifying prospective and retrospective interval-       Wager, T.D. and Smith, E.E. (2003) Neuroimaging studies
  time estimation: A new fading-Gaussian activation-based          of working memory: a meta-analysis. Cognitive, Affective,
  model of interval-timing, Procedia - Social and                  & Behavioral Neuroscience, 3, 255‚Äì274.
  Behavioral Sciences, 126, 141‚Äì150.                             Zakay , D. & Block, R. A. (1997) Temporal cognition.
Gallistel, C. R., & Gibbon, J. (2000). Time, rate, and             Current Directions in Psycholgical Science, 6, 12-16.
  conditioning. Psychological Review, 107(2), 289‚Äì344.           Zakay, D., & Block, R. A. (2004). Prospective and
Genovesio, A., Tsujimoto, S., & Wise, S. P. (2006).                retrospective duration judgments: an executive-control
  Neuronal activity related to elapsed time in prefrontal          perspective. Acta neurobiologiae experimentalis, 64, 319‚Äì
  cortex. Journal of Neurophysiology, 95(5), 3281‚Äì3285.            328.
Gibbon, J. (1977). Scalar expectancy theory and Weber‚Äôs
  law in animal timing. Psychological Review, 84(3), 279-
  325.
                                                             103

