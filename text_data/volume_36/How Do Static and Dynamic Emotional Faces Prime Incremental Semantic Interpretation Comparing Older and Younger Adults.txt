UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How Do Static and Dynamic Emotional Faces Prime Incremental Semantic
Interpretation?: Comparing Older and Younger Adults
Permalink
https://escholarship.org/uc/item/48c312j3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Munster, Katja
Carminati, Maria Nella
Knoeferle, Pia
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                             Powered by the California Digital Library
                                                                University of California

        How Do Static and Dynamic Emotional Faces Prime Incremental Semantic
                                                          Interpretation?:
                                      Comparing Older and Younger Adults
                                    Katja Münster (Katja.Muenster@uni-bielefeld.de)2,3
                             Maria Nella Carminati (mcarmina@techfak.uni-bielefeld.de)1,3
                                     Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)1,2,3
                                               1 SFB 673 “Alignment in Communication”
                                         2 Cognitive Interaction Technology Excellence Center
                                                        3 Department of Linguistics
                                               CITEC, Inspiration 1, Bielefeld University
                                                         33615 Bielefeld, Germany
                             Abstract                                   on assessing how object- and action-related information in
                                                                        the visual context influences spoken language
  Using eye-tracking, two studies investigated whether a
  dynamic vs. static emotional facial expression can influence          comprehension.
  how a listener interprets a subsequent emotionally-valenced              By contrast, we know little about how social and visual
  utterance in relation to a visual context. Crucially, we              cues of a speaker in the visual context (e.g., through his/her
  assessed whether such facial priming changes with the                 dynamic emotional facial expression) can affect a listener’s
  comprehender’s age (younger vs. older adults). Participants           utterance comprehension1. In principle, a speaker’s facial
  inspected a static (Experiment 1, Carminati & Knoeferle,              expression of emotion could help a listener to rapidly
  2013) or a dynamic (Experiment 2) facial expression that was          interpret his/her utterances. With a view to investigating
  either happy or sad. After inspecting the face, participants saw      sentence processing across the lifespan and in relation to
  two pictures of opposite valence (positive and negative;
                                                                        emotional visual cues, we assessed whether older adults
  presented at the same time) and heard an either positively or
  negatively valenced sentence describing one of these two              exploit static and dynamic emotional facial cues with a
  pictures. Participants’ task was to look at the display,              similar time course and in a similar fashion as younger
  understand the sentence, and to decide whether the facial             adults. The rapid integration of multiple emotional cues
  expression matched the sentence. The emotional face                   (facial, pictorial and sentential) during incremental sentence
  influenced visual attention on the pictures and during the            processing seems particularly challenging, yet such
  processing of the sentence, and these influences were                 integration appears to occur effortlessly in natural language
  modulated by age. Older adults were more strongly                     interaction. Here we examine how this integration is
  influenced by the positive prime face whereas younger adults          achieved using a properly controlled experimental setting.
  were more strongly influenced by the negative facial
  expression. These results suggest that the negativity and the
                                                                           To motivate our studies in more detail, we first review
  positivity bias observed in visual attention in young and older       relevant literature on emotion processing, on the recognition
  adults respectively extend to face-sentence priming. However,         of dynamic facial emotion expressions, and on emotion
  static and dynamic emotional faces had similar priming                processing in young relative to older adults.
  effects on sentence processing.
                                                                        Affective Words and Face-Word Emotion Priming
  Keywords: Eye-tracking; sentence processing; emotional
  priming; dynamic vs. static facial expressions                        Humans seem to attend more readily to emotional compared
                                                                        with neutral stimuli. For instance, participants in a study by
                         Introduction                                   Kissler, Herbert, Pyke, and Junghofer (2007) read words
                                                                        while their event-related brain potentials were measured.
Monitoring people’s gaze in a visual context provides a
                                                                        Positive and negative compared with neutral words elicited
unique opportunity for examining the incremental
                                                                        enhanced negative mean amplitude ERPs, peaking at around
integration of visual and linguistic information (Tanenhaus
                                                                        250 ms after word onset. On the assumption that enhanced
et al., 1995). Non-linguistic visual information can rapidly
                                                                        cortical potentials index increased attention, valenced
guide visual attention during incremental language
                                                                        relative to neutral information seems to immediately catch
processing in young adults (e.g., Chambers, Tanenhaus, &
                                                                        our attention (see e.g., Kissler & Keil, 2008 for evidence on
Magnuson, 2004; Knoeferle et al., 2005; Sedivy et al., 1999;
                                                                        endogenous saccades to emotional vs. neutral pictures;
Spivey et al., 2002). Similar incremental effects of visual
                                                                        Nummenmaa, Hyönä, & Calvo, 2006 for eye-tracking
context information emerged in event-related brain
potentials (ERPs) for older adults (e.g., Wassenaar &                      1
                                                                              (but see the rather substantial literature on gesture
Hagoort, 2007). However, the bulk of research has focused               interpretation)
                                                                     2675

evidence on exogenous attentional capture by emotional vs.       dynamic compared with static faces (see also Trautmann,
neutral pictures; Lamy, Amunts, & Bar-Haim, 2008 for             Fehra, & Hermann, 2009 for related fMRI evidence).
evidence on emotional vs. neutral facial expressions).           Against this background, we predict higher accuracy and
   A further paradigm for examining emotion processing is        faster response times with dynamic than static faces for the
emotional priming2. In emotional priming, emotionally            present studies.
congruent (vs. incongruent prime-target pairs) elicited faster
response times when participants had to detect an odd face       The Nature of Emotion Processing Across the Ages
among other faces (e.g., a picture of an emotional face in an    Evidence shows that the recognition of emotional stimuli is
array of neutral faces, Lamy et al., 2008). Reaction times       not invariant across the lifespan. Several ERP studies have
were shorter when an emotional facial expression was             found that the late positivity mean amplitude ERPs were
followed by a similar emotional expression (compared with        more positive-going for negatively- than for positively-
a neutral one) on the next trial. Thus, “implicit memory for     valenced words in young adults (e.g., Bernat, Bunce, &
a recently attended [static] facial expression of emotion        Shevrin, 2001; see Kanske & Kotz, 2007, Experiment 2).
speeds the search for a target displaying the same facial        This ‘negativity bias’ found in young people generalizes to
emotion” (Lamy et al., 2008, p. 152). Such priming did not       faces. For example, young adults preferentially attend to
occur when the target was a neutral face.                        negative (afraid) faces (Isaacowitz et al., 2006).
   In sum, emotional stimuli receive more attention than            By contrast, there is evidence showing that older people
neutral stimuli; however psycho- and neurolinguistic             focus more on positive and less on negative information
research on emotional priming has focused on words. By           (‘positivity effect’, socio-emotional selectivity theory,
contrast, we know little about how a smiling or a sad            Mather & Carstensen, 2005). In Mather and Carstensen’s
speaker face primes (visual attention during) spoken             (2003) study, older adults responded faster to a visually-
comprehension. Facial emotional expressions are part of          presented dot probe when it appeared where a neutral face
communication and could thus play an important (rapid)           had been than where a negative face had been (see also e.g.,
role even in incremental sentence processing (much like          Isaacowitz et al., 2007; Ruffman et al., 2008). Moreover,
extralinguistic cues from objects and events). If we observe     positive information (faces, pictures, life events) is
rapid and incremental face-priming effects on ensuing visual     memorized better than negative information in older age
attention to events during sentence comprehension, existing      (Isaacowitz et al., 2006; Kennedy, Mather, & Carstensen,
accounts of situated language processing will need to            2004; Mather & Carstensen, 2003). Thus, we can expect to
accommodate them (e.g., Knoeferle & Crocker, 2007).              see differences in how younger and older adults process
                                                                 emotional information. In particular, we expect the effects
Dynamic vs. Static Emotional Faces                               of negative and positive facial and sentence information to
Another novel aspect of our research is the direct               show opposite directionality.
comparison of dynamic and static prime faces. Research on
emotion recognition and emotional priming has used mostly        The Present Research
static pictures of emotional faces. By contrast, everyday
social signals are dynamic. Notwithstanding, it has been         We investigated how static (Experiment 1) versus dynamic
shown that people can quickly and correctly decode static        (Experiment 2) emotional facial expressions prime the
facial expressions (Kilts et al., 2003).                         interpretation of positively and negatively valenced
   However, higher recognition accuracy for dynamic than         sentences, which were about emotionally valenced pictures.
static stimuli has been reported in numerous studies (see        A further central aim was to assess potential differences in
Harwood, Hall, & Shrinkfield, 1999 for identification of         such priming effects for younger compared to older adults.
emotions from moving and static videotaped and                   Participants saw a picture of a person’s facial expression
photographic displays from written and pictorial labels of       (Experiment 1) or watched a video of a person’s facial
emotions; Kozel & Gitter, 1968 for identification of             expression changing naturally from neutral to either happy
different emotions from video vs. visual only vs. audio only     or sad (Experiment 2). They were told this was the face of
vs. still pictures). Recio, Sommer, and Schacht (2011)           the speaker. Following this prime, two event photographs
measured ERPs while participants performed a                     appeared on-screen, and shortly after, participants heard
categorization task for happy, angry and neutral faces (static   either a related positively- or negatively-valenced sentence
vs. dynamic). An early posterior negativity and a late           (Table 1). The sentence always referred to one of the two
positive complex were both enhanced and prolonged for            event photographs. Participants indicated as fast and as
dynamic compared to static facial expressions. At the same       accurately as possible whether the prime face matched the
time, response times were faster and accuracy higher for         sentence by pressing a “yes”- or “no”-button.
                                                                    During this task, we measured their eye movements to the
                                                                 event photographs, and response latencies in the face-
2
  Priming: what people perceive at one moment in time (dubbed    sentence verification task. A priming effect in this task
the ‘prime’) influences the perception and recognition of        could manifest itself in the eye movements or in the
subsequent information (often dubbed ‘target’).                  response latencies or in both measures. If the emotional face
                                                               2676

primes sentence processing and visual attention to the target      except that Experiment 1 used static emotional faces and
photographs, then we should find more/earlier looks to a           Experiment 2 dynamic facial expressions as primes. There
referenced photo when its valence matched (vs.                     were 28 experimental target items consisting of a picture
mismatched) the valence of the prime face. Response times          pair and corresponding sentence pair. Each picture pair had
should further be faster and accuracy higher for congruent         one positive and one negative picture, selected based on
trials (i.e., when both prime and target are either positive or    valence ratings (Lang, Bradley, & Cuthbert, 2008, the
negative in valence), irrespective of age.                         International Affective Picture System, IAPS). The
   We expect age effects in response times and accuracy            experimental pictures were balanced for screen position.
with slower and less accurate responses for older than             Within each item pair, they were controlled for arousal and
younger adults (see, e.g., Mather & Carstensen, 2003;              visual similarity.
Salthouse, 2010). As for eye movements, if the negativity             Each picture in a pair was associated with a
bias for younger adults generalizes to face-sentence               corresponding negative or positive sentence (Table 1). The
priming, we should observe an enhancement of looks to the          sentences were recorded in neutral intonation and at a
negative picture when prime and sentence are both negative.        relatively low pace, leaving a pause between phrases. The
We should not observe this enhancement, or this                    onsets of the critical word regions were aligned in each
enhancement should be smaller, when the sentence is                positive/negative sentence pair. Sentence pairs were
positive. Crucially, the opposite behavior (i.e., an               matched for syllable length. We crossed the picture-
enhancement for positive face-sentence pairs) is expected          sentence combinations with either a positive or negative
for the older adults.                                              static (Experiment1) or dynamic (Experiment 2) prime face,
   Considering the age biases, older adults should answer          in a 2 (prime face: negative vs. positive) x 2 (sentence:
positively congruent trials faster and more accurately than        negative vs. positive) x 2 (picture: negative vs. positive)
negatively congruent trials. By contrast, younger adults           design. The experimental faces consisted of photographs or
should demonstrate the opposite response time and accuracy         videos of sad and happy facial expressions. In Experiment
pattern or no bias. A negativity bias for younger adults           2, the face models first made a neutral face and then
should be evident in faster and more accurate responses to         naturally changed into either a happy or a sad expression. A
negatively than positively congruent trials.                       proportion of the filler items had neutral faces; for these,
   Additionally, we predicted faster response times and more       models were instructed to keep a constant neutral face.
accurate responses for Experiment 2 than for Experiment 1,         Experiment 1 and 2 used the same models, ensuring that the
if the dynamic facial expression results in a processing           emotional prime face only varied in its form of presentation.
advantage over the static facial expression.                          In addition to the 28 experimental items, we included 56
                                                                   filler items. Each filler item also consisted of a picture pair,
                                                                   a sentence about one of the pictures, and prime faces (28
                         Experiment                                neutral; 14 positive; and 14 negative).
Participants                                                       Procedure
32 older (60–72 years, M = 64) and 32 younger (19–29               An Eyelink 1000 Desktop Mounted System monitored
years, M = 23) adults participated in Experiment 1. 16             participants’ eye movements. Only the right eye was
younger (18-30 years, M = 24) and 16 older adults (60-80           tracked, but viewing was binocular. Prior to the experiment,
years, M = 68) participated in Experiment 2. All had               participants gave informed consent, read the instructions
German as their only mother tongue and normal or                   and completed eight practice trials. After this the eye tracker
corrected-to-normal vision. All were unaware of the                was re-calibrated and the experiment began. Each trial
experiment purpose and gave informed consent.                      started with a static facial expression (Experiment 1) or a
                                                                   video (Experiment 2). For Experiment 2, the facial
Materials and Design                                               expression stayed neutral (1.3 seconds) and then changed
Materials and design were identical for both experiments,          into the desired emotional expression (3.7 seconds). The
           Table 1: Sentence Structure and Example Sentences in German with a literal translation into English
   Positive Sentence
   IP                              NP1                        NP2                   ADJ              VERB
   Es ist offensichtlich, dass     die Kleine                 die Melone            heiter           verspeist.
   It is obvious that              the little (one)           the melon             cheerfully       eats.
   Negative Sentence
   IP                              NP1                        NP2                   ADJ              VERB
   Es ist offensichtlich, dass     die Blonde                 die Migräne           gereizt          verflucht.
   It is obvious that              the blonde (woman)         the migraine          fretfully        curses.
                                                                 2677

prime face was then disappeared and the valenced target           adults with negative faces (Carminati & Knoeferle, 2013).
photographs appeared; 1500 ms later, the sentence was             Here we report in detail the new data from Experiment 2, as
presented. Participants verified via a button press on a          well as the between-experiment comparison. Figure 1
Cedrus (RB 834) response box whether (“yes” or “no”) the          illustrates the results from Experiment 2 and specifically
face and sentence matched in valence. The timeout was             how the dynamic face affected looks to the pictures,
1500 ms after sentence end for young, and 3000 ms for             independent of sentence valence. For the long region
older adults. Participants were advised to answer as quickly      (Fig.1), older adults looked more at the positive picture after
and accurately as possible. The (left/right) position of the      seeing a positive (vs. negative) prime face, and inspected the
yes/no-answer button was counterbalanced across                   negative picture more after seeing a negative (vs. positive)
participants.                                                     face. By contrast, younger adults preferred to inspect the
                                                                  negative picture independent of face valence (face x group
Analysis                                                          interaction in the item analyses, p < .05). Older adults
                                                                  further had a numerically bigger preference for the positive
We divided the sentence into critical regions. The first
                                                                  picture after a positive face, than for the negative picture
region (the first noun phrase, NP1) extends from the onset
                                                                  after a negative face (Figure 1).
of NP1 until the onset of NP2 (Table 1). It represents the
first point in time at which the sentence disambiguates the
target picture. We also analyzed gaze over a longer time
period (‘long region’) to uncover effects during the
sentence. This period comprised the entire embedded
sentence starting from its first disambiguating word (NP1).
For each region, we computed the mean log gaze probability
ratio according to the formula: Ln (p(negative
picture)/p(positive picture)). Ln refers to the logarithm and p
refers to probability. This ratio expresses the bias of
inspecting the negative relative to the positive picture. The
ratio does not violate the independence and homogeneity of
variance assumptions, which makes it suitable for
comparing looks to two scene regions with parametric tests           More importantly, Figure 2 shows how looks to the
                                                                  sentence-matching picture were modulated by age in the
such as Analyses of Variance (ANOVAs, see, e.g., Arai,
                                                                  long region (face x sentence x age interaction): Younger
Van Gompel, & Scheepers, 2007). More looks to the
                                                                  participants were more likely to look at the negative picture
negative (vs. positive) picture are indexed by a positive log
ratio. More looks to the positive (vs. negative) picture are      after they had inspected a negative (vs. positive) prime face
                                                                  if the sentence was also negative (pairwise comparison: p <
indexed by a negative log ratio.
                                                                  .05), but the opposite pattern was absent (i.e., no difference)
   We computed mean log gaze probability ratios for each
                                                                  if the sentence was positive; by contrast, older adults were
region separately by participants and items. These means
                                                                  more likely to inspect the positive picture after a positive
were then subjected to ANOVAs with participants and items
                                                                  (vs. negative) facial expression but only if the sentence was
as random effects. We report ANOVAs on the combined
                                                                  positive (pairwise comparison, p < .05). This effect was also
eye-movement data for both groups. Unless otherwise
                                                                  reliable early, in the NP1 region (p < .05 by participants). In
stated, group was a between-participant factor in the
                                                                  short, as in Experiment 1 (static faces) we see face-sentence
analysis by participants and a within-item factor in the
                                                                  priming only for negative face-sentence pairs in young, and
analysis by items.
                                                                  only for positive face-sentence pairs in older adults.
   Reaction times were computed from NP1 onset. Accuracy
scores (excluding trials with timeouts and incorrect
responses) were computed for each group by condition. In
an additional analysis, we combined the data of the two
experiments and used Experiment (1 vs. 2) as a factor to                            *
detect a possible difference between the two experiments.
Results
Main results for the eye-movement analysis: The results
from Experiment 1 showed that fixations on the pictures
were increased when the speaker's (static) face was
emotionally congruent (vs. incongruent) with the sentence.
Crucially, this enhancement was modulated by age. The
effect for the older adults was more pronounced with
positive faces, whereas the effect was stronger for younger
                                                                2678

Finally, analyses on the combined data from Experiments 1          Somewhat unexpectedly, all participants responded
and 2 confirmed all the effects found in the analyses on the     significantly faster and more accurately to incongruent than
separate experiments; importantly no interactions with           congruent face-sentence valence items (Figure 3). This
experiment were observed.                                        “mismatch” effect was stronger in older than young adults.
  Response times: The results did not differ between             One, admittedly speculative, reason for this unexpected
experiments and we report the new results for Experiment 2.      pattern is that for some kinds of information in visual
Response times were slower for older than young adults (p        context, dissimilarities with language may be easier to
< .01); slower for negative than positive sentences (p < .05);   verify than similarities. Increased response latencies for
and slower for negative sentences in the older than the          matches compared with mismatches have also been reported
younger group (sentence x group interaction, p < .05).           by Vissers et al. (2008) when young adults verified a spatial
Participants’ verification times were also faster for            description against a line drawing. This mismatch effect
incongruous than congruous face-sentence pairs (p < .05).        does also not depend on the dynamics of the prime face, as
  Main results for the accuracy analysis: Accuracy results       both experiments yielded the same results. Contrary to our
did not differ between experiments and we report the new         initial predictions, dynamic (vs. static) emotional facial
results for Experiment 2. Figure 3 shows that younger            expressions did not enhance the post-comprehension
people were more accurate than older people (p < .05).           processing of the sentence, and they did not enhance eye
However, older adults’ accuracy was higher than younger          movement behavior either. Thus, although dynamic facial
adults’ for positive compared with negative sentences. Thus,     expressions are recognized faster and more accurately than
older adults seem to have benefitted more from positive          static facial expressions (Recio, Sommer, & Schacht, 2011),
sentences in answering the verification question.                this ‘recognition advantage’ for dynamic expressions does
Interestingly, responses were more accurate when face and        not seem to generalize to the specific context of our study.
sentence valence mismatched than when they matched                 However, age plays a crucial role in emotional priming.
(Figure 3), and this mismatch advantage was more                 One possible account for older adults’ focus shifts towards
pronounced in older adults. Young adults only displayed a        positive events is different fixation strategies for identifying
mismatch advantage for negative sentences.                       emotions. Perhaps older adults extract different information
                                                                 from faces than younger people (Mill et al., 2009). In
                                                                 addition, our results support existing findings that younger
                                                                 adults are more sensitive to negative than positive stimuli
                                                                 (e.g., Holt, Lynn, & Kuperberg, 2008; Taylor, 1991) in the
                                                                 sense that they are more facilitated by the negative face in
                                                                 processing the negative sentence. The decline in older
                                                                 adults’ emotion processing skills and general cognitive
                                                                 functions (Mill et al., 2009) could go hand in hand with a
                                                                 change in fixation strategies in causing the change from a
                                                                 negativity bias towards a focus on positive information
                                                                   Overall thus the observed face-sentence priming effects
                                                                 corroborate and extend existing findings about age
                                                                 differences in emotion recognition. Emotional primes,
                         Discussion                              regardless of whether they are static or dynamic, can
                                                                 facilitate the interpretation of an affective sentence.
An emotional speaker face primed both older and young
                                                                 Crucially, age modulated this facilitation, with older adults’
adults’ visual attention to valenced pictures as soon as it
                                                                 showing increased facilitation from positive and younger
became clear which picture the sentence referred to.
                                                                 adults from negative face primes.
However, crucially, this influence was modulated by age.
Priming occurred only with the negative face-sentence
combinations in young, and for positive face-sentence
                                                                                    Acknowledgements
combinations in older adults. This confirms our hypotheses       This research was funded by the SFB 673 “Alignment in
and suggests that visual attention, reflecting sentence          Communication” and by the Cognitive Interaction
interpretation, is guided by a negativity bias in young and      Technology Excellence Center (German Research
by a positivity bias in older adults (Figure 2).                 Foundation, DFG). We thank participants for their support.
  Moreover, younger participants showed an overall visual
preference for the negative picture, regardless of face                                   References
valence, but older adults, were clearly influenced by the        Arai, M., Van Gompel, R. P. G., & Scheepers, C. (2007).
prime face in the expected direction (Figure 1).                   Priming ditransitive structures in comprehension.
Furthermore, older people’s positive picture preference was        Cognitive Psychology, 54, 218-250.
numerically bigger than their negative picture preference,       Bernat, E., Bunce, S., & Shevrin, H. (2001). Event related
providing further evidence for a positivity bias (Figure 1).       potentials differentiate positive and negative mood
                                                                   adjectives during both supraliminal and subliminal visual
                                                               2679

  processing. International Journal of Psychophysiology,       Lang, P. J., Bradley, M. M., Cuthbert, B. N. (2008).
  42, 11-34.                                                     International Affective Picture System (IAPS): Affective
Carminati M. N, Knoeferle P. (2013). Effects of Speaker          ratings of pictures and instruction manual. Psychology (A-
  Emotional Facial Expression and Listener Age on                8), 61.
  Incremental Sentence Processing. PLoS ONE 8 (9), 1-16.       Mather, M., & Carstensen, L. L. (2003). Aging and
Chambers, C. G., Tanenhaus, M. K., & Magnuson, J. S.             attentional biases for emotional faces. Psychological
  (2004). Actions and affordances in syntactic ambiguity         Science, 14(5), 409-415.
  resolution. JEP: LMC, 30, 687-696.                           Mather, M., & Carstensen, L. L. (2005). Aging and
Harwood, N. K., Hall, L. J., Shinkfield, A. J. (1999).           motivated cognition: The positivity effect in attention and
  Recognition of facial Emotional expressions from moving        memory. Trends in Cognitive Sciences, 9, 496-502.
  and static displays by individuals with mental               Mill, A., Allik, J., Realo, A., Valk, R. (2009). Age-Related
  Retardation. American Journal on Mental Retardation,           differences in emotion recognition ability: A cross-
  104(3), 270-278.                                               sectional study. Emotion, 9(5), 619-630.
Holt, D. J., Lynn, S. P., Kuperberg, G. R. (2008).             Nummenmaa, L., Hyönä, J., & Calvo, M. (2006). Eye
  Neurophysiological      correlates   of    comprehending       movement assessment of selective attentional capture by
  emotional meaning in context. Journal of Cognitive             emotional pictures. Emotion, 6, 257-268.
  Neuroscience, 21(11), 2245-2262.                             Recio, G., Sommer, W., Schacht, A. (2011).
Isaacowitz, D. M., Wadlinger, H. A., Goren, D., & Wilson,        Electrophysiological correlates of perceiving and
  H. R. (2006). Selective preference in visual fixation away     evaluating static and dynamic facial emotional
  from negative images in old age? An eye-tracking study.        expressions. Brain Research, 1376, 66-75.
  Psychology and Aging, 21, 40-48.                             Ruffman, T., Henry, J. D., Livingstone, V., & Phillips, L. H.
Isaacowitz, D. M., Löckenhoff, C. E., Lane, R. D., Wright,       (2008). A Meta-Analytic review of emotion recognition
  R., Sechrest, L., Riedel, R., Costa, P. T. (2007). Age         and aging: Implications for neuropsychological models of
  differences in recognition of emotion in lexical stimuli       aging. Neuroscience and Biobehavioral Reviews, 32(4),
  and facial expressions. Psychology and Aging, 22(1), 147-      863-881.
  159.                                                         Salthouse, T. A. (2010). Selective review of cognitive
Kanske, P., & Kotz, S. A. (2007). Concreteness in                aging. Journal of the International Neuropsychological
  emotional words: ERP evidence from a hemifield study.          Society, 16, 754-760.
  Brain Research, 1148, 138-148.                               Sedivy, J. C., Tanenhaus, M. K., Chambers, C. G., &
Kennedy, Q., Mather, M., & Carstensen, L. L. (2004). The         Carlson, G. N. (1999). Achieving incremental semantic
  role of motivation in the age-related positivity effect in     interpretation through contextual representation.
  autobiographical memory. Psychological Science, 15,            Cognition, 71, 109 -147.
  208-214.                                                     Spivey, M. J., Tanenhaus, M. K., Eberhard, K. M., &
Kilts, C. D., Egan, G., Gideon, D. A., Ely, T. D., Hoffman,      Sedivy, J. C. (2002). Eye movements and spoken
  J. M. (2003). Dissociable neural pathways are involved in      language comprehension: Effects of visual context on
  the recognition of emotion in static and dynamic facial        syntactic ambiguity resolution. Cognitive Psychology, 45,
  expressions. NeuroImage, 18, 156-168.                          447-481.
Kissler, J. & Keil, A. (2008). Look – Don’t Look! How          Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K.
  emotional pictures affect pro- and anti-saccades.              M., Sedivy, J. C. (1995). Integration of visual and
  Experimental Brain Research, 188, 215-222.                     linguistic information in spoken language comprehension.
Kissler, J., Herbert, C., Peyk, P., Junghofer, M. (2007).        Science, 268(5217), 1632-1634.
  Buzzwords: early cortical responses to emotional words       Taylor, S. E. (1991). Asymmetrical effects of positive and
  during reading. Psychological Science, 18(6), 174-180.         negative      events:    The     mobilization-minimization
Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering,       hypothesis. Psychological Bulletin, 110, 67-85.
  M. J. (2005). The influence of the immediate visual con-     Trautmann, S. A., Fehra, T., Hermann, M. (2009). Emotions
  text on incremental thematic role-assignment: Evidence         in motion: dynamic compared to static facial expressions
  from eye-movements in depicted events. Cognition, 95,          of disgust and happines reveal more widespread emotion-
  95-127.                                                        specific activations. Brain Research, 1284, 100-115.
Knoeferle, P., & Crocker, M. W. (2007). The influence of       Vissers, C., Kolk, H., Van de Meerendonk, N., Chwilla, D.
  recent scene events on spoken comprehension: evidence          (2008). Monitoring in language perception: Evidence
  from eye movement. JML, 57, 519-543.                           from ERPs in a picture–sentence matching task.
Kozel, N. J., Gitter, A. G. (1968). Perception of emotion:       Neuropsychologia 46, 967-982.
  Differences in mode of presentation, sex of perceiver, and   Wassenaar, M., & Hagoort, P. (2007). Thematic role
  race of expressor. CRC Rep. 18, 36.                            assignment in patients with Broca’s aphasia: Sentence-
Lamy, D., Amunts, L., Bar-Haim, Y. (2008). Emotional             picture matching electrified. Neuropsychologia, 45, 716-
  priming of pop-out in visual search. Emotion, 8(2), 151-       740.
  161.
                                                             2680

