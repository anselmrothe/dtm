UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Parallel vs Serial Issues in Reading Aloud: Evidence for Parallel Processing from a
Computational Model of Japanese Kanji &amp; Kana Nonword Reading
Permalink
https://escholarship.org/uc/item/40f7h9x7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Ueno, Taiji
Ikeda, Kenji
Ito, Yuichi
et al.
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                  Powered by the California Digital Library
                                                                       University of California

  Parallel vs Serial Issues in Reading Aloud: Evidence for Parallel Processing from a
               Computational Model of Japanese Kanji & Kana Nonword Reading
                                                Taiji Ueno1,2 (taijiueno7@gmail.com)
                                       Kenji Ikeda2,3 (ikeda.kenji@f.mbox.nagoya-u.ac.jp)
                                                Yuichi Ito2,3 (ito.yuichi@nagoya-u.jp)
                                          Shinji Kitagami3 (kitagami@cc.nagoya-u.ac.jp)
                                          Jun Kawaguchi3 (kawaguchijun@nagoya-u.jp)
    1. Department of Psychology, University. of York, Heslington, York, YO10 5DD, UK. 2. Japan Society for the Promotion
            of Science; 3. Graduate School of Environmental Studies, Nagoya University, Nagoya, 4648601, JAPAN.
                              Abstract                                 However, this model (hereafter, SM89) was unable to read
                                                                       nonwords (i.e., untrained input pattern) as satisfactorily as
   Lower nonword reading performance in the old version of
   parallel-distributed processing models in English was taken as      humans (Glushko, 1979). Advocates of dual-route models
   evidence for the necessity of sequential components in              argued that SM89 was only an approximation of a lexical
   reading aloud, but the later updates have resolved this issue       look-up process, and this was taken as evidence for the
   without discarding the parallel processing principle. A             necessity of sequential components (Coltheart et al., 2001).
   model’s validity can be tested by cross-script extensions. On       Specifically, they expected that sequentially applying a
   this point, an extension to Japanese kanji reading has posed a      grapheme-phoneme correspondent rule per a grapheme
   question. Specifically, the latest Japanese connectionist model
   has incorporated a sequential component in order to improve         would allow a model to pronounce a nonword satisfactorily.
   kanji nonword reading performance. The present study,               In contrast, Plaut et al. (Plaut et al., 1996) explained it was
   however, proposed an alternative, fully parallel-distributed        only due to the size of the training set and/or to the input
   processing model to map distributed kanji and kana visual           coding schemes. After sorting these issues out, Plaut et al.
   representations to phonemic/moraic representations, with            (hereafter, PMSP96) successfully simulated nonword
   satisfactory nonword reading performance. First cross-              reading performance without a sequential component.
   linguistic evidence from Japanese is provided to support a
                                                                          Interestingly, the connectionist models for Japanese kanji
   single-mechanism theory that postulates parallel-processing
   for both words and nonwords reading.                                reading went part of the same way as English, but arrived at
                                                                       the opposite end. It is widely accepted that a cross-script
   Keywords: parallel-distributed processing model; sequential         extension is a useful paradigm to glean further evidence for
   processing; reading, Japanese kanji; nonword reading
                                                                       the validity of computational models (Perry et al., 2007).
                                                                       Given the success of PMSP96, it was natural that one of
                          Introduction                                 these authors, Patterson and her Japanese colleagues
The processes and mechanisms for reading aloud is one of               embarked on a Japanese PDP project. The outcome of their
the controversial issues in cognitive science. Implemented             initial attempt was successful and similar to the situation of
computational models have contributed to this issue by                 SM89, such that the model was able to read both Japanese
explicitly demonstrating the mechanisms and processes that             kanji consistent/regular words (later in details for the
can reproduce the behavioral data (Coltheart, Rastle, Perry,           operational definition) and irregular words within a single
Langdon, & Ziegler, 2001; Perry, Ziegler, & Zorzi, 2007;               mechanism (Ijuin, Fushimi, Patterson, & Tatsumi, 1999).
Plaut, McClelland, Seidenberg, & Patterson, 1996). These               However, this model was unable to read kanji nonwords (2-
models differ in whether a sequential component is                     kanji compounds, but the combination of these 2 kanji
permitted as well as parallel processing component, mainly             characters does not exist in real Japanese) as correctly as
in order to simulate nonword reading accuracy (Besner &                humans (Fushimi, Ijuin, Patterson, & Tatsumi, 1999). Given
Smith, 1992) and the word length effect (Weekes, 1997),                the history of English models, they naturally expected that
and so on. The present study contributes to this issue by              poor nonword reading would be attributed to extrinsic
providing the first example of a parallel-distributed                  factors such as training corpus and coding schemes, rather
processing (PDP, without a sequential component)                       than intrinsic factors such as its lack of indispensable
connectionist model which can read Japanese kanji and kana             mechanisms. However, the follow-up studies conducted by
words/nonwords.                                                        Japanese researchers in this group (Ijuin, Fushimi, &
   A historical overview of the parallel vs serial issues in           Tatsumi, 2001, 2002) have actually reached the different
English models should be helpful here. The PDP model by                conclusion. Specifically, Ijuin et al. (2001) explicitly
Seidenberg and McClelland (1989) incorporated only a                   mentioned as follows (translated into English by us):
single mechanism with parallel processing, and was able to
read both regular (e.g., mint) and irregular (i.e., pint) words.
                                                                   1634

      Our network was able to read only 7%~20% of                  (e.g., 和食 [wa-syo-ku], meaning Japanese food; 洋食 [yo-
      nonword sets. There are possible factors to affect           u-syo-ku], meaning Western food). However, there are a few
      network’s nonword reading, including (i) the size of
      the training corpus, (ii) input coding scheme, & (iii)
                                                                   words (thus atypical) whose pronunciation is [ji-ki] (e.g., 断
      the architecture of the network (‘architecture’ is the       食 [da-N-ji-ki], meaning fasting). In other words, reading
      direct translation of their Japanese, but as will be         these inconsistent-atypical words cannot rely on the
      shown later. what Ijuin et al. actually referred here        statistical bias (or rule), and instead should refer to the
      was ‘mechanism’, not ‘architecture’). We have                adjacent character to compute word-specific information,
      already tested the effects of (i) and (ii), but we know      such as lexical/semantic knowledge (Fushimi et al., 1999).
      that modifying these parameters do not improve the              Fushimi et al. (1999) also created a 2-kanji nonword by
      performance equivalent to humans
                (The note in the parenthesis is added by us)
                                                                   randomly combining 2 kanji characters. These combinations
                                                                   do not exist in real Japanese, such that there is no way to
   Thus, Ijuin et al. (2001) concluded that manipulating the       decide a single correct pronunciation for each character.
extrinsic factors was not enough to improve nonword                Therefore, a human output in nonword kanji reading is
reading accuracy, and instead dealt with the ‘architecture’.       scored as correct if any of the possible/legitimate
For this purpose, Ijuin et al. (2001, 2002) hardwired a            pronunciations is generated in each character (mean
position layer, which contained two task units, each of            accuracy = 89% in Fushimi et al., 1999). Because of this
which sent a time-/position-specific signal sequentially per       scoring method, letter-by-letter reading without a reference
a pronunciation of one character to the network (Figure 1),        to the adjacent characters always leads to correct nonword
and the network generated the correct pronunciation of each        reading. We will return to this issue later.
character sequentially. As a result, the network improved its         Finally, there is another script, kana in Japanese. Each
nonword reading equivalent to human adults (Fushimi et al.,        kana character has almost perfect transparency to its mora
1999). They concluded “this model is clearly different from        phonology (thus consistent). Because of this nature, every
dual-route models because the 2 kanji characters were              kanji word can be represented in kana form by translating a
presented in parallel (Ijuin et al., 2001, 2002)”, and assumed     kanji orthography into its pronunciation (morae), and then
it was a so-called triangle model.                                 converting that morae sequence to the one-to-one
    In this study, we report two simulations. In Simulation 1,     corresponding kana sequence (thus, kana-length of a kanji
we replicated Ijuin et al. (2001, 2002)’s sequential output        word = its mora-length). The reading models here were
model with a position layer, and our reanalysis of the model       trained for mapping from a kanji representation to its mora
showed that the model was actually hardwired dual                  representation as well as mapping from its kana form to the
mechanisms, one of which was specialized for a sequential          same mora representation for all the lexical items.
processing (parsing) mechanism. In Simulation 2, we
proposed a PDP model with fully-parallel outputs. This             Network: Sequential Outputs & Position Layer
model was able to read both kanji words and nonwords               Figure 1 shows the architecture of the network, adapted
satisfactorily without a sequential component.                     from Ijuin et al. (2002). There was a reason why we did not
                                                                   use exactly the same network in a strict sense reported in
                                                                   Ijuin et al. (2002). Specifically, their original model
                                                                   implemented the so-called semantic layer (Plaut et al., 1996),
     Simulation 1 (Replication and Reanalysis)
                                                                   whose input moved the activity of the output layer units
                                                                   towards the target value. When this technique was combined
Methods
                                                                   with the localist representations and with the max-criterion
Reading Japanese Kanji Words and Nonwords                          scoring method, then high kanji nonword reading accuracy
To facilitate understanding of the implementation details, an      could be an artefact (NB. Each of these techniques has no
explanation for the nature of mapping in Japanese kanji            issue when used in isolation, see Simulation 2). Specifically,
reading would be helpful. Correct reading of a Japanese 2-         during training of words, the direct orthography-phonology
kanji ideogram is an example of a quasiregular domain              route of such a model becomes a system which knows all the
(Seidenberg & McClelland, 1989). One-third of a single             legitimate pronunciations in each character (one may call
kanji character has only one possible pronunciation (thus          this as a rule system) rather than a phonological system,
consistent). In contrast, the remaining two-thirds have            such that it activates all the localist units for all the
several legitimate pronunciations (inconsistent). In addition,     legitimate pronunciations in each character. In contrast, the
the level of typicality in each correct pronunciation has been     semantic layer becomes a system which selects the correct
operationalized by Fushimi et al. (1999) as the type-              one of these localist units by boosting its activity towards 1
frequency of the phonemic-/moraic-friends among the                whereas inhibiting the other legitimate localist units. As a
orthographic-neighbors (i.e., the entire Japanese 2-kanji          result of this additional positive/negative inputs from the
ideogram cohort sharing the same kanji character in the            semantic layer, the output is scored as a correct word
same position). For example, when 食 (meaning eat)                  reading in the max-criterion. Then, shutting off the inputs
appears in the 2nd position of a 2-kanji ideogram, then in         from this selecting system (a procedure to test nonwords)
most cases (thus typical) the target pronunciation is [syo-ku]     leaves one of the legitimate localist units to be more active
                                                               1635

than the rest of non-legitimate localist units, resulting in       consisted of two task units, which alternated its ‘on/off’
correct nonword reading (as explained above, kanji                 status in time 1 and 2. The connections from these two units
nonword reading is scored correct if each character is             to the hidden layer were trainable. Therefore, it is crucial to
pronounced with any of the legitimate pronunciations).             analyse these connections in order to understand the nature
Taken together, when combining these techniques, a higher          of computations, which we did in the present study.
Japanese nonword reading would be an artifact, not due to            The 2-kanji ideograms for training were extracted from
the acquisition of the statistical structure underlining kanji     NTT database (Amano & Kondo, 2000). We first excluded
reading. So, we removed the semantic layer and focused on          both the archaic kanji characters and the daily characters yet
the demonstration of the sequential nature of that model.          with an archaic pronunciation. Jouyou-list by Ministry of
  When the network in Figure 1 was trained for reading a 2-        Education, Culture, Sports and Technology specifies the
kanji ideogram, then two units in the kanji input layer were       daily kanji characters and daily pronunciations for teaching
activated, each of which represented each of the two kanji         in school. The training words were made up of two kanji
characters, respectively. These two ‘on’ units were                characters with daily pronunciations in the Jouyou-list. The
maintained during the two time steps in a trial. In the first      words were selected only if the word frequency and
time step, the network activated the output localist unit for      familiarity were available. Words with a loan sound were
the correct pronunciation of the 1st kanji character (single/      removed. Also, mora-length in each kanji character was
double morae), and then in the 2nd time step, it activated         limited to one/two to minimize the dispersion problem. In
another localist unit for the 2nd kanji character pronunciation.   other words, the maximum mora-length (kana-length) of a
When the same word was trained in kana form, then the              word was 4, and kanji-length was always 2. The resultant
position-specific localist units for kana characters were          41,215 kanji 2-ideograms and their kana-forms (i.e., in total
activated during the two time steps, and the network was           82,430 input patterns) were used for training.
trained to produce the same output patterns as those of the           Lens (http://tedlab.mit.edu/~dr/Lens/) was used for
corresponding kanji word. When the kana-length (thus mora          training. Learning rate was set to 0.005. The root-squared
length) was 2 or 3, it was centred in the kana input layer in      word frequency count per million was used to scale the error
order to minimize the dispersion problem (Plaut et al., 1996).     derivatives. Weight decay was not used in Ijuin et al. (2002).
Thus, importantly, the model had to inhibit the mora(e)            Cross-entropy was used to estimate the error, and the
localist unit for the 2nd character during activating the unit     connection strength was adjusted through the back-
for the 1st character in time 1, and vice versa in time 2.         propagation algorithm after every trial. No adjustment was
  Given the input pattern was stable during the two time           made if the target-output difference was within 0.2.
steps in a trial, the only mechanism that allowed this             Momentum parameter was set to 0.9. An output was scored
sequential on/off shift in the output layer was the time-          as correct if the most active localist unit was that for the
specific signal from the position layer. The position layer        target pronunciation for real words (max-criterion). Kanji
                                                                   nonword reading was scored correct if the most active unit
                                                                   was one of the legitimate pronunciations in each kanji
                                                                   character. During testing, 120 kanji words and 120 kanji
                                                                   nonwords (Fushimi et al., 1999) were used. Their
                                                                   corresponding kana input patterns were used for assessing
                                                                   kana words and kana nonwords accuracies. The activity of
                                                                   each unit was a sigmoid function of the summed weighted
                                                                   input from other units.
                                                                   Results and Interim Discussions
                                                                   After 250 epochs of training (1 epoch = 82,430-word
                                                                   presentation), the network accuracy was equivalent to
                                                                   humans (Fushimi et al., 1999). Accuracies were 91.66% for
                                                                   120 kanji words (93.66% for humans), 93.33% for 120 kanji
                                                                   nonwords (88.79% for humans), 100% for 120 kana words,
                                                                   and 92.5% for kana nonwords (there is no human kana
                                                                   reading data, measured with the same item set).
                                                                      As explained above, the only mechanism that allowed
                                                                   sequential outputs from a stable 2-kanji input was the signal
                                                                   from the position layer (two task units). The amount of the
                                                                   inputs from these task units in each time step is
                                                                   mathematically equal to the connection strengths from each
Figure 1. Architecture of the sequential output model with a       of the task units to the 100 hidden units. Left half of Figure
position layer, adapted from Ijuin et al. (2002).                  2 visualizes these. We plotted the connection weights from
                                                               1636

the 2nd task unit (i.e., task unit input in time 2) to each of the       Simulation 2 (Fully Parallel Output Model)
100 hidden units against the weights from the 1st task unit
(i.e., task unit input in time 1). The resultant 100 plots in         Methods
Figure 2a are color-/shape-coded in terms of the spatial              Figure 4 shows the architecture of the network. The same
position they occupy in Figure2b (later in detail). In Figure         82,430 words as Simulation 1 were used for training. This
2a, there was a clear negative correlation between the task           time, the input/output patterns were distributed
unit inputs from the position layer in Time 1 and those in
                                                                      representations for kanji/kana characters and for phonetic
Time 2 [r(98) = -.74, p < .05, 95% CI = -82:-64]. In other            distinctive features of morae (Halle & Clements, 1983),
words, this hardwired position layer separated the hidden             respectively (Figure 5). The input patterns for kana words
units at least into two (/more) groups in terms of their              with 2 or 3 morae in length were centred to minimize the
‘on/off’ status in Time 1 and 2. The functions of these two           dispersion problem. Specifically, the kana character that
groups are more clearly visible if we add the bias input              corresponded to the first pronunciation of the 2nd kanji
values to these connection weights (Figure 2b) because the            character (when it is written in kanji) was always placed at
resultant scatterplot means the default activity of hidden            the 3rd character position of the kana layer (Figure 5). The
units without an orthographic input in Time 1 and 2,                  output patterns were also centred in the same way.
respectively. As a consequence, the hidden units were                    The output of the network was fully parallel, such that
clustered into five. Blue asterisk markers denoted the hidden         there was only one time step in a trial. The distributed
units that were “allowed” to be active in Time 1 upon
                                                                      inputs for 2 kanji characters (or corresponding kana inputs)
orthographic inputs but were “forced” to be inactive in Time          were presented simultaneously, and the correct distributed
2 by the negative input from the task unit (position unit 2).         representations for all the morae patterns were produced in
In contrast, red triangle makers denoted the opposite. It is          the output layer. The semantic system (Plaut et al., 1996)
natural to expect that the first group is specialized (i.e.,          sent an additional input (S, below) to move the output layer
modular) only for the pronunciation of a 1st kanji character          activations towards the correct target value (0 or 1).
(and corresponding kana characters) whereas the second
group is for a 2nd kanji character. This can be tested by                             (                           )
measuring character reading accuracy after ‘lesioning’ each                             (                           )
unit group selectively. As a result, Figure 3 shows double
dissociations of the 1st kanji character (and corresponding           S parameter was set to 0 when testing for nonword reading,
kana) specific deficit and the 2nd kanji character specific           following the past studies (Ijuin et al., 2002). One might say
deficit by lesioning each group selectively. The other hidden         this is not a validated procedure, but our pilot study
units seemed to be involved in both characters.                       confirmed this model was able to read nonwords
   In summary, this model separated two distinct                      satisfactorily even when trained without this semantic input.
mechanisms as DRC/CDP models (Coltheart et al., 2001;                 The 20-unit output pattern per mora (one row of the output
Perry et al., 2007). One (asterisks & triangle markers) was           layer in Figures 4-5) was compared to all the possible 104
specialized for a character-position-specific (thus script-           morae patterns, and the closest mora pattern was selected as
specific) sequential parsing mechanism, and the other                 its output in that mora position. Momentum was not used.
(remaining markers) involved for whole-word processing.               The error derivative was set to zero when the target-output
The second one should be helpful for the network to read              difference was below 0.1. Learning rate and weight decay
inconsistent-atypical words. In Simulation 2, we provide an           started from 0.5 & 5-E07, respectively, and were reduced by
alternative PDP model for kanji and kana reading without a            0.1 & 1-E01, per 5 epochs from the 31st epoch. After the
sequential component.                                                 50th epoch, each parameter was set to 0.01 & 0, respectively
    Figure 2. Input from the position units (left) plus bias unit (right)        Figure 3. Accuracy upon selective lesioning
                                                                  1637

                                                            for further 5 epochs training. The other parameters were the
                                                            same as Simulation 1.
                                                            Results and Interim Discussions
                                                               After 55 epochs of training, accuracies were 100% for
                                                            120 kana words, 98.33% for kana nonwords, 95% for 120
                                                            kanji words, and 81.65% for 120 kanji nonwords. Kanji
                                                            nonword accuracy was lower than humans (89%) in
                                                            Fushimi et al. (1999). However, as explained above, human
                                                            kanji nonword reading accuracy can be exaggerated if a
                                                            letter-by-letter reading strategy is taken. Importantly,
                                                            Fushimi et al. (1999) used a pure kanji nonword list. Testing
                                                            with a pure kanji nonword list allows participants to know
                                                            they do not need to refer to the adjacent character to
                                                            generate a legitimate pronunciation for each character,
                                                            leading to letter-by-letter reading. In fact, our replication of
                                                            Fushimi et al. (1999) showed that testing kanji nonword in a
                                                            pure list overestimated accuracy by 10% (Ikeda, Ueno, Ito,
                                                            Kitagami, & Kawaguchi, In preparation). Testing with a
                                                            mixed list of kanji words (necessary to refer to the adjacent
                                                            character for computing word-specific information) and
                                                            nonwords in a block yielded a more modest nonword
                                                            reading (81.57%, 95%CI = 77:86). Note that the network
                                                            also had no way to know if the next stimulus was a word or
                                                            nonword. Therefore, our network accuracy was equivalent
                                                            to humans if compared in a fair manner.
                                                               In summary, the current connectionist model had no
Figure 4. Architecture of a fully-parallel output model     sequential mechanisms yet acquired the statistical structure
                                                            underlying kanji/kana reading, and generalized it to
              Example 4-morae word                          nonwords. Thus, there is no necessity to incorporate dual
                                                            mechanisms for simulating kanji nonword accuracy. The
                             1st - 2nd morae (/ta-i/)       first attempt to generalize PMSP96 into Japanese was as
                             3rd- 4th morae (/hu-u/)
                                                            successful in simulating word reading (Ijuin et al., 1999) as
  Target sound (typhoon)
                                                            SM89. However, one could argue it only approximated
                                            1st kanji       lexical lookup process (Coltheart et al., 2001). The authors
                 1st & 2nd                                  naturally attributed it to the coding scheme and the corpus
              kana (/ta-i/)                  (/ta-i/)       size (Ijuin et al., 1999), but they later concluded these
                                                            factors did not improve performance, and attempted to
                  3rd & 4th                 2nd kanji       incorporate a sequential mechanism (Ijuin et al., 2001,
              kana (/fu-u/)                  (/fu-u/)       2002). In this study, however, we only improved some
                                                            parameters (weight decay, corpus size, and generalizable
 Kana input (typhoon)       Kanji input (typhoon)           input/output coding schemes) compared to Ijuin et al. (2001,
     Example 3-morae word (1 mora + 2-morae)                2002), and demonstrated successful kanji nonword reading
                                                            even without incorporating a sequential mechanism.
                             1st mora (/ke/)
                             2nd -3rd morae (/syo-u/)
  Target sound (make-up)
                                                                              General Discussion
                                             st             Nonword reading accuracy has been one of the test cases for
                                           1 kanji
               st                            (/ke/)         the necessity of a grapheme/character-based sequential
             1 kana (/ke/)                                  component (Coltheart et al., 2001; Perry et al., 2007; Plaut
                                                            et al., 1996). Plaut et al. (1996) has shown such a
                  2nd & 3rd                2nd kanji
                                                            component is not necessary to simulate English nonword
             kana (/syo-u/)                (/syo-u/)        reading. Further insights can be gleaned by cross-linguistic
 Kana input (make-up)       Kanji input (make-up)           extension (Perry et al., 2007). However, the Japanese
                                                            pioneering works were successful to simulate kanji nonword
     Example 3-morae word (2 morae + 1 mora)                reading by implementing a character-based sequential
   Figure 5. Examples of input-output     mapping           processing (parsing) mechanism (Ijuin et al., 2001, 2002),
                             1st & 2nd morae (/so -u/)
                               rd
                             3 mora (/ko/)
 Target sound (storehouse)
                                                        1638
                                           1st kanji
                  1st & 2nd

like the dual-mechanism models (Coltheart et al., 2001;                word recognition and reading aloud. Psychological
Perry et al., 2007). In contrast, our model did not implement          Review, 108(1), 204-256.
a sequential component, but nonetheless acquired the                Fushimi, T., Ijuin, M., Patterson, K., & Tatsumi, I. F. (1999).
statistical knowledge underlying Japanese kanji reading,               Consistency, frequency, and lexicality effects in naming
rather than approximating lexical lookup process, and                  Japanese Kanji. Journal of Experimental Psychology-
generalized this knowledge to nonword reading. Thus, we                Human Perception and Performance, 25(2), 382-407.
provide first cross-linguistic evidence from Japanese to            Glushko, R. J. (1979). Organization and activation of
support a single-mechanism theory that postulates parallel-            orthographic knowledge in reading aloud. Journal of
processing in converting kanji/kana orthography to morae               Experimental Psychology-Human Perception and
representations of words/nonwords.                                     Performance, 5(4), 674-691.
   Note that the position layer in Ijuin et al. (2001, 2002) is     Halle, M., & Clements, G. (1983). Problem book in
not the same as that in Plaut (1999). Plaut (1999) has                 phonology. Cambridgem, MA: MIT Press.
extended PMSP96 to sequential processing, but the signal            Ijuin, M., Fushimi, T., Patterson, K., & Tatsumi, I. (1999).
from his ‘position layer’ was an approximation of an                   A connectionist approach to Japanese kanji word naming.
attentional fixation mechanism (i.e., domain-general).                 Psychologia, 42(4), 267-280.
Specifically, that signal was not sequential from left to right     Ijuin, M., Fushimi, T., & Tatsumi, I. (2001). Kanji nonword
per a character/grapheme (i.e., reading-specific).                     reading by a connectionist model [written in Japanese].
   Finally, other behavioural phenomena, such as word-                 Paper presented at the The 4th Annual Meeting of
length effect (Weekes, 1997) have been taken as evidence               Japanese Cognitive Neuropsychology [dai 4 kai ninchi
for sequential mechanisms (Coltheart et al., 2001; Rastle,             shinkei shinrigaku kenkyuukai].
Havelka, Wydell, Coltheart, & Besner, 2009), and a similar          Ijuin, M., Fushimi, T., & Tatsumi, I. (2002). Surface
argument was made in Japanese literature (Tamaoka, 2005)               dyslexia in Japanese - A computational account from
to support the kanji-character based sequential processing             simulation study [written in Japanese]. Japanese Journal
(parsing) mechanism (Ijuin et al., 2002). However, Chang,              of Neuropsychology, 18, 101-110.
Furber, and Welbourne (2012) successfully simulated the             Ikeda, K., Ueno, T., Ito, Y., Kitagami, S., & Kawaguchi, J.
length effect by a PDP model, and attributed this effect to            (In preparation). Parallel vs serial issues in reading aloud:
the peripheral (visual/articulatory) processing, rather than to        Behavioral and computational approach to explain
the translation process itself from orthography to phonology.          nonword reading and lexicality by length interaction in
Our ongoing modelling project (Ikeda et al., In preparation)           Japanese.
has already simulated the length-by-lexicality interaction in       Perry, C., Ziegler, J. C., & Zorzi, M. (2007). Nested
Japanese kana reading, reported by Rastle et al. (2009), and           incremental modeling in the development of
other crucial phenomena, such as frequency-regularity                  computational theories: The CDP+ model of reading
interaction in kanji words/nonwords (Fushimi et al., 1999),            aloud. Psychological Review, 114(2), 273-315.
and surface dyslexic kanji reading upon damage in the               Plaut, D. C. (1999). A connectionist approach to word
semantic system (Plaut et al., 1996). Taken together, like             reading and acquired dyslexia: Extension to sequential
English (Plaut et al., 1996), evidence from Japanese reading           processing. Cognitive Science, 23(4), 543-568.
literatures supports parallel-distributed processing for            Plaut, D. C., McClelland, J. L., Seidenberg, M. S., &
reading aloud despite of the clear cross-linguistic                    Patterson, K. (1996). Understanding normal and impaired
differences in orthography and phonology.                              word reading: computational principles in quasi-regular
                                                                       domains. Psychol Rev, 103(1), 56-115.
                    Acknowledgments                                 Rastle, K., Havelka, J., Wydell, T. N., Coltheart, M., &
   This study was supported by Grant-in-Aid for JSPS (Japan            Besner, D. (2009). The Cross-Script Length Effect:
Society for the Promotion of Science) Fellows to T. Ueno.              Further Evidence Challenging PDP Models of Reading
                                                                       Aloud. Journal of Experimental Psychology-Learning
                                                                       Memory and Cognition, 35(1), 238-246.
                         References                                 Seidenberg, M. S., & McClelland, J. L. (1989). A
Amano, S., & Kondo, T. (2000). Japanese NTT database                   distributed, developmental model of word recognition and
   series: Lexical properties of Japanese, word-frequency:             naming. Psychological Review, 96(4), 523-568.
   Tokyo: Sanseido.                                                 Tamaoka, K. (2005). Is an orthographic unit of a single
Besner, D., & Smith, M. C. (1992). Models of visual                    Japanese kanji equivalent to a kanji phonological unit in
   recognition - When obscuring the stimulus yields a clearer          the naming task? [written in Japanese]. Cognitive Studies,
   view. Journal of Experimental Psychology-Learning                   12(2), 47-73.
   Memory and Cognition, 18(3), 468-482.                            Weekes, B. S. (1997). Differential effects of number of
Chang, Y.-N., Furber, S., & Welbourne, S. (2012). "Serial"             letters on word and nonword naming latency. Quarterly
   effects in parallel models of reading. Cognitive                    Journal of Experimental Psychology Section a-Human
   Psychology, 64(4), 267-291.                                         Experimental Psychology, 50(2), 439-456.
Coltheart, M., Rastle, K., Perry, C., Langdon, R., & Ziegler,
   J. (2001). DRC: A dual route cascaded model of visual
                                                                1639

