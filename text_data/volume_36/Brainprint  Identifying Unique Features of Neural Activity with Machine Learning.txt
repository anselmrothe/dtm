UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Brainprint: Identifying Unique Features of Neural Activity with Machine Learning
Permalink
https://escholarship.org/uc/item/8nk76909
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Ruiz-Blondet, Maria
Khlaifian, Negin
Armstrong, Blair
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

           Brainprint: Identifying Unique Features of Neural Activity with
                                                    Machine Learning
                                  Maria Ruiz-Blondet (mruizbl1@binghamton.edu)1
                                     Negin Khalifian (nkhalif1@binghamton.edu)2
                                     Blair C. Armstrong (b.armstrong@bcbl.edu)3
                                        Zhanpeng Jin (zjin@binghamton.edu)1, 4
                                     Kenneth J. Kurtz (kkurtz@binghamton.edu)2
                                        Sarah Laszlo (slaszlo@binghamton.edu)2
                1Department     of Bioengineering, 4400 Vestal Parkway East, Binghamton, NY 13902 USA
                  2Department     of Psychology, 4400 Vestal Parkway East, Binghamton, NY 13902 USA
   3Basque Center on Cognition, Brain, and Language, Paseo Mikeletegi 69, 2nd Floor, 20009 DONOSTIA SPAIN
    4Department of Electrical and Computer Engineering, 4400 Vestal Parkway East, Binghamton, NY 13902 USA
                           Abstract                                 for example, Jian-feng, 2010; Palaniappan & Mandic,
  Can a person be identified uniquely by some feature of            2007); however, the prior work has not substantially
  their neural activity, as they can be by fingerprints? If so,     interfaced with what is understood about the cognitive
  1) what would those features be like and 2) are existing
  computational methods sufficient to extract them? Here,           processes that impact an individual’s EEG or ERPs.
  we explore these questions by coordinating                        	
 One well-understood cognitive system that seems
  psychophysiological and machine learning approaches.              likely to differ uniquely between individuals is semantic
  We begin with the proposition that one unique feature of          memory, defined here as a memory network of concepts
  individual cognition is the detailed network of concepts,         and relationships between concepts. As an example of
  and relationships between concepts, that are present in
  each individual’s semantic memory.                We then         how individuals’ semantic networks differ, consider the
  demonstrate that we are able to accurately classify               concepts [bee] and [anaphalaxis]. Even with only these
  individual unlabeled brain activity—in the form of                two concepts, there are a number of plausible associated
  Event-Related Potentials (ERPs) elicited during a task            states in semantic memory that might be instantiated in
  that probes semantic memory—to the individual it                  individuals: an individual might not know what either
  belongs to with several pattern classifiers. These results
  demonstrate that it is possible to identify individuals on        of these things are, or might know both of them, or only
  the basis of unique features of their brain activity.             one or the other. A person with a bee allergy might
  Biometric applications are discussed.                             strongly associate the two concepts, while a person with
                                                                    no bee allergy might not associate them at all, or
  Keywords:           Machine Learning; Event-Related               associate them only weakly. Of course, there are many
  Potentials; Individual Differences; Biometrics
                                                                    more concepts and relationships that can be represented
Introduction                                                        than bees and anaphalaxis, and the more concepts and
Each of us has a sense that our individual cognitive                relationships that need to be represented, the less likely
worlds--our selves-- are unique. In a materialist                   any two people are to represent them in exactly the
epistemological framework, the self is instantiated by              same way (i.e., as the pool of possible concepts grows
the brain, and thus it is the brain and its workings that           beyond only [bee, anaphalaxis] to a larger pool like
make our selves unique. This sense is codified in                   [bee, anaphalaxis, snake, spider, chocolate, prawn,
modern cognitive science and cognitive neuroscience                 cilantro, clown], and then to larger pools and so on, it
by the idea of individual differences, which is the                 becomes less and less likely for all concepts and
acknowledgement that not all brains are identical, and              relationships to be represented the same way in multiple
not all individuals engage cognitive processes in an                individuals). Although it seems plausible that there are
identical manner (see, for example, Daneman &                       numerous neuro-cognitive systems that distinguish
Carpenter, 1980; Raz et al., 2005). The idea of                     between individuals, semantic memory, as we will see
individual differences is taken to its extreme in the field         below, produces a large, robustly studied
of biometrics, where it is assumed not only that                    electrophysiological response that has already been
individuals differ on some measure (e.g., fingerprint or            demonstrated to vary across individuals (although not
retinal topography), but that individuals are unique on             necessarily produce unique responses across
those measures. In this field, the EEG signal is starting           individuals).
to be considered as an identification characteristic (see
                                                                827

A Neural Measure of Semantic Memory                              of waveforms (i.e., labeling a test waveform as
Attempts to access semantic memory are known to                  belonging to an individual if that waveform had a
elicit a large, robust, electrophysiological response            higher cross-correlation with another waveform from
known as the N400. The N400 is a negative going                  the same individual than with waveforms from any
Event-Related Potential (ERP) component that peaks at            other individuals). This method is based on the intuitive
approximately 400 ms post stimulus onset, and is                 notion that, if brainprinting is possible, overall,
maximal over the back of the head. The N400 is                   waveforms elicited by the same person should be more
strongly sensitive to numerous manipulations of                  similar than waveforms elicited by different people, and
semantic memory including, but not limited to,                   also on past work suggesting that cross-correlation is an
violations of sentence context, semantic priming,                effective means of measuring EEG waveform similarity
imageability, concreteness, and number and strength of           (e.g., Chandaka & Chatterjee, 2009). However, this
lexical associations (see Kutas & Federmeier, 2011, for          method is not especially flexible; for example, it gives
review). Importantly, we have demonstrated in past               equal weight to similarities in all portions of the
work that the N400 is sensitive to whether or not a              waveform, even though the most important
particular visual word form has meaning to an                    similarities-- those reflecting similar semantic memory
individual participant. Specifically, when participants          networks-- should occur in temporally specific portions
are presented with a large variety of acronyms (e.g.,            of the waveform, and should therefore likely be
DVD, NPR), individuals present larger N400s to                   weighted more heavily by the pattern classifier.
acronyms they are familiar with than to acronyms they            	
 Pattern classifiers with increased flexibility, such as
are not familiar with (see Laszlo & Federmeier, 2007).           the ability to learn, are therefore appealing for the
This is taken to mean that when an unfamiliar item is            brainprint problem. It is advantageous for the classifier
presented, the system is less able to make contact with          to be able to learn what parts of the waveform are most
concepts in semantic memory than when a familiar item            important in telling people apart, and what parts are
is presented.                                                    either not informative or anti-informative. Here, we
	
 Participants are able to identify, on average, 83% of        considered two learning classifiers that seemed to us to
75 acronym items in our stimulus list-- 62 items. There          be particularly likely to be able to solve this problem.
are 1.2 x 1014 possible ways to randomly choose 62               These are Divergent Autoencoder (DIVA; Kurtz, 2007)
items from a set of 75, which quantifies the idea that it        and Naive Discriminant Learning (see Baayen, Milin,
is very unlikely for any 2 people to have an identical           Durdevic, Hendrix, & Marelli, 2011). The divergent
profile of familiar and unfamiliar items when the set of         autoencoder is a feed-forward neural network
items is of sufficient size (and, in fact, no two                architecture that provides an alternative to the
participants had exactly the same pattern of known and           multilayer perceptron (MLP) for applying the
unknown items in this dataset). In what follows, we              backpropagation algorithm to classification tasks. In
exploit the known variation in what acronyms are                 contrast to the MLP, which has a single output node for
familiar to individual participants as one possible              each possible classification, DIVA has a full copy of the
source of a signal that is unique to individuals. Other          input layer (a “channel”) corresponding to each possible
sources include individual variation in neural anatomy           classification. The key design principle is training the
that result in slightly different sizes and distributions of     autoencoder to reconstruct the members of each
ERPs across the scalp and slightly different timing of           category with the constraint that each autoassociative
the N400 and the ERP components that precede it --               channel shares a common hidden layer. Classification
each of these factors is represented in the data on which        outcomes are a function of reconstruction error: an item
we performed pattern classification.                             is a good member of a class to the extent it can be
                                                                 recoded and decoded along the appropriate channel
Machine Learning: Pattern Classification                         with minimal distortion. Kurtz (2007) originally
A wide variety of pattern classifying algorithms exist           developed DIVA as a cognitive model of human
that could, in principle, be applied to the problem under        category learning; research is currently in progress that
study (for extensive review, see Bishop, 1995). Here,            establishes the wider potential of DIVA networks as a
we focus on the performance of three methods that past           highly effective, general-purpose classifier for machine
work suggests should be well-suited for identifying              learning.
unique features in distributed, high-dimensional                    	
 NDL was selected as an alternate method as it has
representations of neural activity (such as the                  recently received considerable attention both because of
temporally extended ERP signal). The simplest method             its ability to account for classification phenomena
we considered was creating a simple linear discriminant          across domains and because its computational
based on the normalized cross-correlation between pairs          characteristics make it well-suited for modeling large
                                                             828

data sets that would typically be extremely                    	
 Note that this experiment was designed primarily as a
computationally expensive for related connectionist            study of written language comprehension, not as a study
models. This advantage is due in part to the derivation        of individual differences in psychophysiology. While
of equilibrium equations (Danks, 2003) that allow for          the dataset does include responses that are likely to be
the rapid calculation optimal weights, which enables the       non-identical across participants, as discussed, these
training of NDL models on extremely large data sets            differences were not maximized by design. For
(because the input to the models here is an entire ERP         example, while the items are not likely to be
waveform, for an input layer size of 550 units, the            represented identically by any two participants, they are
present problem is substantially larger in size than many      relatively benign (e.g., DVD, NFL) and therefore not
cognitive modeling problems). Similar to many other            likely to elicit individual reactions that are particularly
machine learning algorithms, however, it is capable of         strong or idiosyncratic. A more targeted design might
learning to weight the contributions of different input        feature items more likely to have stronger individual
dimensions based on their informativeness, allowing the        differences; for example, words with strong affective
algorithm to “focus in” on the most relevant dimensions        loadings (e.g., SPIDER, CLOWN), or low frequency
of inputs for discrimination.                                  words likely to be known by some but not all
	
 In what follows, we assess multiple metrics of             participants (see Ramscar et al., 2014).
accuracy for each of these classification methods in           	
 Similarly, because this experiment was not designed
identifying unlabeled exemplar ERPs, with the goal of          as a study of individual differences, relatively few trials
determining whether any of these techniques is able to         were acquired from each participant, in anticipation of
learn to extract unique features of individual brain           data analysis of group, as opposed to individual,
waves.                                                         averages, as is typical for ERP language experiments.
                                                               The high signal to noise ratio in ERPs could prohibit
Method: ERPs                                                   meaningful averages from being formed from
ERPs were drawn from an existing corpus of ERP                 individuals with so few trials available. The non-
visual word recognition data. These data were acquired         targeted design of the corpus from which data for
in an experiment following the methods of our past             classification were drawn, as well as the relatively low
studies demonstrating individual differences in N400s          signal to noise present in ERPs with so few trials, will
on the basis of individual acronym knowledge (Laszlo           both provide challenges to our classifiers. If we are
& Federmeier, 2007). In this study, EEG was recorded           able to achieve accurate classification in spite of these
from 32 adult participants (11 female, age range 18-25,        challenges, we will have reason to believe that our
mean age 19.12) who silently read an unconnected list          classification methods are robust.
of text. EEG was digitized at 6 midline electrodes sites.
Participants viewed 75 acronyms that each repeated             Method: Pattern Classifiers
once at a lag of 0, 2, or 3 intervening items, in addition     Training data for the classifiers was comprised of
to several other item types (words, pseudowords, and           responses to the first presentation of acronyms; test data
illegal consonsant strings) not analyzed in the present        was comprised of responses to the second presentation
work. Participants were instructed to press a button on a      of acronyms. The training and test data were thereby
gamepad when their name was presented on the screen.           completely non-overlapping.          After EEG artifact
This task was given in order to ensure that participants       rejection, each participant contributed 70 trials to both
were actively engaged in the experiment and attending          data sets (some participants had more than 70 trials left
to critical items (words, pseudowords, acronyms, and           after artifact rejection; from these 70 random trials were
illegal strings) without contaminating waveforms               selected).       One average per participant was not
elicited by critical items with response potentials.           considered to be sufficient training data for the neural
	
 That repetition was included in this design allows for     network classifiers. Therefore, 100 ERPs consisting of
homogenous but non-overlapping segmentation of the             random averages of 50 of the 70 trials were made for
data into train and test corpora for machine learning:         each participant, resulting in 3200 averages (100
first responses to acronyms were used for training, and        averages for each of the 32 participants) of 50 trials
second responses were used for testing. ERPs were              each to use as inputs for neural network training.
computed at each electrode time-locked to the onset of         Similarly, 100 random averages of 50 trials per
each of the four critical stimulus types, on each of the       participant were formed from the test data for network
two presentations (e.g., words, first presentation;            evaluation.
acronyms, second presentation). For a more detailed
description of the methods, see Khalifian (2013).
                                                           829

    - 8µV
        0                             1 sec.
          Subject 1: True ERP                 Subject 1: DIVA                             Subject 1: DIVA
                                              best reconstruction                         worst reconstruction
                                              [Rank 1]                                    [Rank 32]
 Figure 1. Sample Data and DIVA Reconstructions. On the left, a true ERP elicited by Subject 1. In the middle, the best
 DIVA reconstruction of that ERP after training. On the right, the worst DIVA reconstruction of that ERP after training.
 Notice that DIVA’s best reconstruction appears as a slightly filtered version of the true ERP, with activity in early
 temporal epochs emphasized.
Cross-Correlation                                              32-way classification; see Kurtz, 2007, for details). The
To classify by cross-correlation, we first computed the        200 unit hidden layer was shown to be the smallest size
maximum absolute value of the cross-correlation                that would enable near-perfect learning of the training
between pairs of waveforms (see Chandaka, Chatterjee,          set in pilot simulations. On each supervised training
& Munshi, 2009). These pairs could be self-self pairs          trial, hidden-to-output weights were adjusted only along
(i.e., one of the 100 averages from subject 1’s training       the correct category channel. The input-to-hidden
corpus and one of the 100 averages from subject 1’s test       connections followed a sigmoidal activation function;
corpus) or self-other pairs (i.e., one waveform elicited       the hidden-to-output connections followed a linear
by subject 1 and another elicited by subject 2, or subject     activation function. The network was trained for 1000
3, and so on, for a total of 31 self-other pairs). The         iterations; this was determined to be a level that allowed
cross-correlations between pairs were then divided by          satisfactory (>99%) train performance without
the norm (or vector length) of the pair, in order to           overfitting via prior validation simulations. After these
reduce variability caused by scalp thickness and other         1000 iterations, weights in the model were fixed.
cognitive-unrelated events, allowing consistency in            	
 At test, the model was presented with each of the
magnitude within cross-correlation results; data were          3200 test examples, and activation was allowed to
also high-pass filtered during recording to eliminate          propagate through the network. Reconstruction error
variability due to DC shifts.. The output of this              was measured on each output channel. The channel
operation was then ranked, with the highest ranked pair        with the least output error was assigned rank 1 for that
being this classifier’s guess as to which two waveforms        trial, the channel with the 2nd least output error was
were elicited by the same subject. This ranking method         assigned rank 2 for that trial, and so on. Again,
allows for the accuracy of the cross-correlation               assigning ranks to the model’s outputs allows for its
classifier to be analyzed identically to the accuracies of     accuracy to be analyzed in a manner identical to that
the other classifiers, as described below.                     used for the other classification methods. Figure 1
                                                               displays an example of an empirically derived ERP
Divergent Autoencoding (DIVA)                                  along with its best and worst DIVA reconstruction.
The DIVA network was a 550:200:550[32] feedforward             Note that, as was expected, the DIVA classifier learned
autoencoder. The 550 input nodes corresponded to the           to emphasize some parts of the input waveforms over
550 samples in the ERP waveforms; thus the entire              others.
waveform was veridically presented to the network.
The [32] signifies that, instead of having only one            Naive Discriminant Learning (NDL)
output layer representing the reconstruction of the input,     The NDL model was trained using a slight extension of
as in a standard autoencoder, there were 32 output             the NDL algorithm developed by Shaoul, Arppe,
layers, one for each possible “classification” by the          Hendrix, Milin, and Baayen (2013). Essentially, this
network of the input data (i.e., the model is making a
                                                           830

model can be considered as a two layer network with               identifying that subject, regardless of whether
550 inputs, corresponding to each sample of the full              ultimately the classifier actually “chose” the correct
ERP waveform, and 32 outputs, corresponding to each               classification (i.e., ranked it 1 most frequently). In what
of the participants who may have generated the                    follows, we will refer to this as the mean rank weight.
                                                                  The mean rank weight for the cross-correlation
waveform. This network was trained using the Danks
                                                                  classifier was .87. The mean rank weight for DIVA
(2003) equilibrium equations to identify threshold
                                                                  was .90. The mean rank weight for the NDL classifier
values and weights for above-and below-threshold                  was 0.88. We also calculated the absolute accuracy for
inputs that should be fed forward to each of the output           each time a trial was well classified (i.e. was correctly
units, to maximize the activation of the correct output           ranked 1) for all the 32000 trials. The results were 0.56
and minimize the activation of the incorrect outputs.             for cross-correlation, 0.54 for DIVA and 0.42 for NDL.
The use of these equilibrium equations effectively                	
 The null hypothesis for classification accuracy is that
allows for the weight matrix that would be discovered             the classifiers are assigning the first rank by chance;
by iterative discriminative learning across the training          meaning that the chance classification accuracy is 1 / 32
examples (e.g., as in back-propagation) to be derived in          = .03. Clearly, all classifiers performed substantially
a single sweep through the corpus. Following training,            better than chance. To quantify this statistically, we
the threshold values and weights were fixed and were              computed the distribution of decision accuracies across
                                                                  50 000 random permutations of the ranking matrix. We
used to generate the predicted outputs for the testing
                                                                  then assigned p-values to the null hypothesis by
data set. Activation of the output units was then ranked
                                                                  determining the proportion of random classification
to generate an analogous set of ranking data to that              accuracies that were higher than the observed
developed for the other machine learning algorithms               classification accuracy for each classifier (a type of
outlined above.                                                   approximate randomization test). Similarly, the null
                                                                  hypothesis for rank weight is that all 32 ranks are being
Results                                                           assigned by chance. We assigned p-values to the null
Identical analysis was performed on the rankings from             hypothesis by determining the proportion of mean rank
each classifier. A rank of 1 was considered a highly              weights in the random 50 000 permutations of the
confident “vote” for that classification, and was given a         ranking matrix that were higher than the observed mean
weight of 1, whereas a rank of 2 was given a weight of .          rank weight. The null hypothesis was rejected for all
97 and so on, such that a rank of 32 was given a weight           classifiers, on both measures of accuracy, at p < .0001
of 0. There are two, related, questions of interest when          (the same was true for absolute accuracy).
evaluating the accuracy of multi-way classifiers in this
manner. First, how often did the classifier make the              Discussion
“correct” classification (rank the correct classification         We set out to investigate whether we could accurately
highest)? Second, when the correct classification is not          identify individuals on the basis of unique features of
the first ranked classification, how highly is it ranked?         their neural activity. After advancing the proposition
This second question quantifies the idea that if, for             that one cognitive structure likely to be unique to
example, a classifier ranks the correct classification            individuals is the detailed organization of semantic
2nd, that should be considered a more favorable result            memory, we submitted ERP data acquired in a semantic
than if the classifier ranks the correct classification last.     memory task to multiple pattern classifiers: cross-
	
 To answer the first question, we asked how often the          correlation, DIVA, and NDL. All three classifiers were
correct classification was ranked 1 more frequently than          able to classify individual waveforms with a very high
any incorrect classification for each subject (e.g., if the       degree of accuracy robustly above chance---indeed,
correct classification was ranked 2 more often than it            performance was near ceiling in most of our analyses,
was ranked 1 within a particular subject’s 100 test               particularly for the training data. The fact that these
exemplars, that subject was considered incorrectly                results are very similar for the three different methods
classified); we will refer to this in what follows as the         used shows that the data includes robustly identifiable
classification accuracy. The classification accuracy for          differences across individuals, which can be detected by
the cross-correlation classifier was 0.90.                The     a variety of methods. It also demonstrates that our
classification accuracy for DIVA was 0.89. The                    cognitive linking premise-- that access to semantic
classification accuracy for NDL was 0.89. To answer               memory is a uniquely individual process-- is at least not
the second question, the mean of the weights assigned             entirely defunct as a rationale.
to the correct classification for each subject was taken          	
 There are numerous avenues of future research
as a measure of the success of the classifier in                  advancing our treatment here of the brainprint problem.
                                                              831

As a one example, it would be interesting to analyze the           Bishop, C. M. (1995). Neural networks for pattern
EEG data in single trials to see if the information of             	
 recognition. Oxford university press.
whether an acronym is recognized or not--without trial             Chandaka, S., Chatterjee, A., & Munshi, S. (2009).
averaging--can be detected by a classifier. Also,                  	
 Cross-correlation aided support vector machine
correlations between components (e.g., correlations                	
 classifier for classification of EEG signals. Expert
between the N400 and the P2) might provide another
                                                                   	
 Systems with Applications, 36(2), 1329-1336.
source of identifiable variation between individuals.. On
                                                                   Daneman, M., & Carpenter, P. A. (1980). Individual
the side of signal processing, using a voting scheme
between the algorithms, or even between different                  	
 differences in working memory and reading. Journal
electrode sites may improve over the accuracy of any               	
 of verbal learning and verbal behavior, 19(4),
single algorithm.. A point to highlight is that the data           	
 450-466.
processed in this work was collected for different                 Danks, D. (2003). Equilibria of the Rescorla-Wagner
purposes. It could be worthwhile to conduct an                     	
 model. Journal of Mathematical Psychology, 47,
experiment tailored specifically to generate a different           	
 109-121.
response by a range of users, in order to understand the           Jian-feng, H. U. (2010, March). Biometric System
upper limits of the brainprinting accuracy.                        	
 based on EEG Signals by feature combination. In
	
 Finally, our success here has implications for the             	
 Measuring Technology and Mechatronics Automation
applied use of brainprinting, as for secure and                    	
 (ICMTMA), 2010 International Conference on (Vol.
trustworthy authentication of access to sensitive
                                                                   	
 1, pp. 752-755). IEEE.
information.      There are multiple advantages of
                                                                   Khalifian, N. (2013) Life of ERPLE: Developing a
brainprinting over traditional biometrics (such as
fingerprints and retinal scans).         As opposed to             	
 silent reading task for use with children and adults.
traditional methods, brainprinting protects not only the           	
 SUNY Binghamton, Binghamton, New York.
system from unauthorized access, but also the subject              Kurtz, K. J. (2007). The divergent autoencoder (DIVA)
from being harmed in order to acquire its biometric                	
 model of category learning. Psychonomic Bulletin &
feature, as can happen with fingerprints, for example              	
 Review, 14(4), 560-576.
(BBC news: Malaysia car thieves steal finger). Our                 Kutas, M., & Federmeier, K.D. (2011). Thirty years
success here at uniquely identifying individuals even in           	
 and counting:       Finding meaning in the N400
a dataset not designed specifically for generating                 	
 component of the event-related brain potential (ERP).
maximally unique waveforms indicates that existing                 	
 Annual Review of Psychology.
computational methods are sufficiently sophisticated to            Laszlo, S., & Federmeier, K.D. (2007). Better the
make applied brainprinting feasible, in principle. In
                                                                   	
 DVL you know: Acronyms reveal the contribution of
future research, we aim to more rigorously explore the
                                                                   	
 familiarity to single word reading, Psychological
theoretical and practical considerations that will allow
this work to be of practical use to society.                       	
 Science, 18, 122-126.
                                                                   Palaniappan, R., & Mandic, D. P. (2007). Biometrics
Acknowledgments                                                    	
 from brain electrical activity: a machine learning
The authors acknowledge members of the Binghamton                  	
 approach. Pattern Analysis and Machine Intelligence,
University Modeling Meeting--especially S. Bhamdeo                 	
 IEEE Transactions on, 29(4), 738-742.
and T. Raway--for insightful discussion. This research             Ramscar, M., Hendrix, P., Shaoul, C., Milin, P., &
was supported by the Binghamton University Health                  	
 Baayen, H. (2014). The Myth of Cognitive Decline:
Sciences Transdiciplinary Area of Excellence (S.L &                	
 Non-Linear Dynamics of Lifelong Learning. Topics
Z.J), NSF CAREER BCS-1252975 (S.L.), and the                       	
 in cognitive science, 6, 5-42.
European Science Commission MC IIF-627784                          Raz, N., Lindenberger, U., Rodrigue, K. M., Kennedy,
(B.C.A.).
                                                                   	
 K. M., Head, D., et al. (2005). Regional brain
                                                                   	
 changes in aging healthy adults: general trends,
References
                                                                   	
 individual differences and modifiers. Cerebral cortex,
Baayen, R. H., Milin, P., Đurđević, D. F., Hendrix, P.,
                                                                   	
 15(11), 1676-1689.
	
 Marelli, M. (2011). An amorphous model for
                                                                   Shaoul, C., Arppe, A., Hendrix, P., Milin, P., & Baayen,
	
 morphological processing in visual comprehension
                                                                   	
 R. H. (2013). ndl: Naive Discriminative Learning. R
	
 based     on    naive      discriminative        learning.
                                                                   	
 package      version     0.2.14.      http://CRAN.R-
	
 Psychological Review, 118(3), 438-481.	
	
 	

                                                                   	
 project.org/package=ndl
                                                               832

