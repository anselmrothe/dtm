UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bayesian inference as a viable cross-linguistic word segmentation strategy: It’s all about
what’s useful
Permalink
https://escholarship.org/uc/item/48x18404
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Phillips, Lawrence
Pearl, Lisa
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

        Bayesian inference as a viable cross-linguistic word segmentation strategy:
                                                  It’s all about what’s useful
                                                   Lawrence Phillips and Lisa Pearl
                                                      Department of Cognitive Sciences
                                                       University of California, Irvine
                                                      {lawphill, lpearl}@uci.edu
                               Abstract                                     Proposals for early segmentation strategies have centered
   Identifying useful items from fluent speech is one of the             on language-independent cues that do not need to be derived
   first tasks children must accomplish during language acquisi-         from knowledge of existing words, such as transitional prob-
   tion. Typically, this task is described as word segmentation,         ability between syllables (Saffran, Aslin, & Newport, 1996).
   with the idea that words are the basic useful unit that scaf-
   folds future acquisition processes. However, it may be that           Experimental evidence also suggests that statistical cues like
   other useful items are available and easy to segment from             transitional probability are used earlier than language-specific
   fluent speech, such as sub-word morphology and meaning-               cues like metrical stress (Thiessan & Saffran, 2003).
   ful word combinations. A successful early learning strategy
   for identifying words in English is statistical learning, imple-         Bayesian inference for early statistical word segmentation
   mented via Bayesian inference (Goldwater, Griffiths, & John-          has been shown to be successful for identifying words in
   son, 2009; Pearl, Goldwater, & Steyvers, 2011; Phillips &
   Pearl, 2012). Here, we test this learning strategy on child-          English, whether the salient perceptual units are phonemes
   directed speech from seven languages, and discover it is ef-          (Goldwater et al., 2009; Pearl et al., 2011) or syllables
   fective cross-linguistically, especially when the segmentation        (Phillips & Pearl, 2012), and whether the inference process
   goal is expanded to include these other kinds of useful units.
   We also discuss which useful units are easy to segment from           is optimal (Goldwater et al., 2009; Pearl et al., 2011) or
   the different languages using this learning strategy, as the use-     constrained by cognitive limitations that children may share
   ful unit varies across languages.                                     (Pearl et al., 2011; Phillips & Pearl, 2012). Notably, however,
   Keywords: language acquisition; Bayesian learning; word               there is little evidence that current Bayesian word segmen-
   segmentation; cross-linguistic; segmentation metrics
                                                                         tation approaches succeed cross-linguistically (though see
                           Introduction                                  Johnson, 2008 and Fourtassi et al., 2013 for some examples).
Segmenting useful items, typically words, from fluent speech                If Bayesian segmentation is meant to be a universal early
is one of the first tasks children face in learning their native         strategy, cross-linguistic success is crucial. Interestingly,
language. The earliest evidence of infant word segmentation              there is some evidence that English may be inherently eas-
comes at six months (Bortfeld, Morgan, Golinkoff, & Rath-                ier to segment into words than other languages (Fourtassi,
bun, 2005) when familiar names are used to segment adjacent              Börschinger, Johnson, & Dupoux, 2013). We therefore evalu-
words. By seven and a half months, infants are beginning to              ate the Bayesian learners of Phillips & Pearl (2012) on seven
segment words using the most common stress pattern in their              languages with different linguistic profiles: English, German,
language (Jusczyk, Cutler, & Redanz, 1993; Jusczyk & Aslin,              Spanish, Italian, Farsi, Hungarian, and Japanese. Because ex-
1995; Echols, Crowhurst, & Childers, 1997), and by nine                  perimental evidence suggests that infants younger than seven
months infants also utilize phonotactics (Mattys, Jusczyk,               and a half months categorically represent syllable-like units,
& Luce, 1999), metrical stress patterns (Morgan & Saf-                   but not phonemes (Jusczyk & Derrah, 1987; Eimas, 1999)
fran, 1995), and coarticulation effects (Johnson & Jusczyk,              and that phonological representations are still developing at
2001) to identify words. Importantly, these later segmen-                this age (Werker & Tees, 1984), we follow previous model-
tation strategies use cues that vary cross-linguistically (e.g.,         ing studies (Swingley, 2005; Gambell & Yang, 2006; Lignos
metrical stress: English words tend to have word-initial stress          & Yang, 2010; Phillips & Pearl, 2012) and assume that the
while French words tend to have word-final stress). In order             relevant perceptual units for word segmentation are syllables.
to identify the relevant cues for these strategies, infants need a          We show that Bayesian segmentation is indeed a success-
pool of words from which to learn the language-specific cue.             ful cross-linguistic learning strategy, especially if we define
   While knowing some words is necessary to infer useful                 success in a more practical way than previous segmentation
language-specific cues to word segmentation, there are other             studies have done. In particular, we consider a segmenta-
units that may be useful to segment. For example, sub-                   tion strategy successful if it identifies units useful for subse-
word morphology can be useful for grammatical categoriza-                quent language acquisition processes (e.g., grammatical cat-
tion (e.g., -ing for identifying the word as a verb). Sim-               egorization, structure learning). Thus, not only are the or-
ilarly, meaningful word combinations could be useful for                 thographic words traditionally used as the “gold standard” in
early structure learning (e.g., could+I functioning as a kind            word segmentation tasks acceptable (e.g., in “I am eating in
of yes/no question marker). So, while it is important to know            the kitchen”: the orthographic words are I, am, eating, in, the,
how children could segment words, it is likely that segment-             and kitchen), but also productive morphology (e.g., -ing) and
ing other units is helpful for acquisition.                              coherent chunks made up of multiple function words (e.g.,
                                                                     2775

Iam, inthe) similar to some of the errors attested by Brown                In both the unigram and bigram case, this generative model
(1973; e.g., that’sa, what’sthat).                                      implicitly incorporates preferences for smaller lexicons by
                                                                        preferring words that appear frequently (due to (2), (4), and
            The Bayesian learning strategy                              (5)) and preferring shorter words in the lexicon (due to (3)),
Bayesian models are well suited to questions of language                both of which may be thought of as domain-general parsi-
acquisition because they naturally distinguish between the              mony biases.
learner’s pre-existing beliefs (prior) and how the learner eval-
uates incoming data (likelihood), using Bayes’ theorem:                    Learners: Implementing Bayesian inference
                                                                        The BatchOpt learner for this model is taken from Goldwater
                       P(h|d) ∝ P(d|h)P(h)                       (1)    et al. (2009) and utilizes Gibbs sampling (Geman & Geman,
   The Bayesian learners we evaluate are the optimal learn-             1984) to run over the entire input in a single batch, sampling
ers of Goldwater et al. (2009) and the constrained learn-               every potential word boundary 20,000 times to decide if a
ers of Pearl et al. (2011). All learners are based on the               word boundary is present. This represents the most ideal-
same underlying generative models developed by Goldwa-                  ized learner, since Gibbs sampling is guaranteed to converge
ter et al. (2009). The first of these models assumes words              on the segmentation which best fits the underlying model.
do not depend on previous words (a unigram assumption)                  Notably, this learner incorporates no cognitive processing or
while the second assumes that a word depends only on the                memory constraints. Because of this, we also evaluate the
word before it (a bigram assumption). While both are clearly            most successful constrained learner developed by Pearl et al.
overly-simplistic ideas about how language is generated, they           (2011) that incorporates processing and memory constraints,
may serve as a reasonable approximation of an infant’s first            providing a test of the utility of the model’s learning assump-
guesses about language structure. To encode these assump-               tions when inference is not guaranteed to be optimal.
tions into the model, Goldwater et al. (2009) use a Dirich-                The Online-Mem learner is taken from Pearl et al. (2011),
let process (Ferguson, 1973), assuming that the observed se-            and is similar to the BatchOpt learner in that it samples
quence of words w1 . . . wn is generated sequentially using a           boundaries during learning. However, the Online-Mem
probabilistic generative process. In the unigram case, the              learner operates utterance by utterance and does not sample
identity of the ith word is chosen according to:                        all potential boundaries equally. Instead, it implements a De-
                                                                        cayed Markov Chain Monte Carlo algorithm (Marthi, Pasula,
                                      ni−1 (w) + αP0 (w)                Russell, & Peres, 2002), sampling s previous boundaries us-
             P(wi |w1 . . . wi−1 ) =                             (2)    ing the decay function b−d to select the boundary to sample;
                                           i−1+α
   where ni−1 is the number of times w appears in the previous          b is the number of potential boundary locations between the
i–1 words, α is a free parameter of the model, and P0 is a base         boundary under consideration bc and the end of the current
distribution specifying the probability that a novel word will          utterance while d is the decay rate. So, the further bc is from
consist of the perceptual units x1 . . . xm :                           the end of the current utterance, the less likely it is to be sam-
                                                                        pled. Larger values of d indicate a stricter memory constraint.
                   P(w = x1 . . . xm ) = ∏ P(x j )               (3)    All results presented here use a set, non-optimized value for d
                                            j                           of 1.5, which was chosen to implement a heavy memory con-
                                                                        straint (e.g., 90% of samples come from the current utterance,
   In the bigram case, a hierarchical Dirichlet Process (Teh,
                                                                        while 96% are in the current or previous utterance). Having
Jordan, Beal, & Blei, 2006) is used. This model also tracks
                                                                        sampled a set of boundaries2 , the learner can then update its
the frequencies of two-word sequences and is defined as:
                                                                        beliefs about those boundaries and subsequently update its
                                         ni−1 (w0 , w) + βP1 (w)        lexicon before moving on to the next utterance.
   P(wi |wi−1 = w0 , w1 . . . wi−2 ) =                           (4)
                                              n(w0 ) − 1 + β
                                                                                              Perceptual units
                                   bi−1 (w) + γP0 (w)                   While the original model by Goldwater et al. (2009) used
                P1 (wi = w) =                                    (5)    phonemes as the basic perceptual unit for word segmentation,
                                        b−1+γ
                                                                        the learning model can operate on any unit. Based on exper-
where ni−1 (w0 , w) is the number of times the bigram (w0 , w)
                                                                        imental evidence, we chose syllables as a more realistic unit
has occurred in the first i–1 words, bi−1 (w) is the number
                                                                        of representation for six- and seven-month-old infants just be-
of times w has occurred as the second word of a bigram, b
                                                                        ginning segmentation. By three months, infants seem to pos-
is the total number of bigrams, and β and γ are free model
                                                                        sess categorical perception of syllable-like units, but not of
parameters.1
                                                                        phones (Jusczyk & Derrah, 1987; Eimas, 1999). Moreover,
    1 Parameters for the models utilized by all learners were cho-      infants continue to distinguish non-native consonant contrasts
sen to maximize the word token F-score of the unigram and bi-
gram BatchOpt learner. English: α = 1, β = 1, γ = 90; German:               2 All Online-Mem learners sample s = 20, 000 boundaries per
α = 1, β = 1, γ = 100; Spanish: α = 1, β = 200, γ = 50; Italian:        utterance. For a syllable-based learner, this works out to approxi-
α = 1, β = 20, γ = 200; Farsi: α = 1, β = 200, γ = 500; Hungarian:      mately 74% less processing than the BatchOpt learner (Phillips &
α = 1, β = 300, γ = 500; Japanese: α = 1, β = 300, γ = 100.             Pearl, 2012).
                                                                    2776

until ten to twelve months (Werker & Tees, 1984), which is                                   Corpora            (age range)     # Utt    # Syl
much later than when early segmentation begins (although                      English        Brent                (0;6-0;9)    28391     2330
vowels do begin this process around six months: Polka &                       German         Caroline            (0;10-4;3)     9378     1683
Werker 1994).3                                                                Spanish        JacksonThal         (0;10-1;8)    16924      524
   This means that syllables are viewed as atomic units, and                  Italian        Gervain              (1;0-3;4)    10473     1158
the learner loses access to all phonotactic information within                Farsi          Family, Samadi       (1;8-5;2)    31657     2008
a syllable. This assumption is supported by experimental evi-                 Hungarian      Gervain            (1;11-2;11)    15208     3029
dence showing that three-month-olds do not recognize sub-                                    Noji, Miyata,
syllabic similarities between syllables (Jusczyk & Derrah,                    Japanese                            (0;2-1;8)    12246      526
                                                                                             Ishii
1987). For instance, while three-month-olds distinguish /ba/
from /bu/ and /ba/ from /du/, they do not regard /ba/ as more               Table 1: Summary of cross-linguistic corpora from
similar to /bu/ than /du/, though /ba/ and /bu/ share an initial            CHILDES, including age range of children the speech was
phoneme while /ba/ and /du/ do not. This may suggest that                   directed at, the number of child-directed speech utterances,
infants disregard sub-syllabic information at this early age.               and the number of unique syllables.
   From a learning perspective, using syllables as the basic
perceptual input has both potential benefits and drawbacks.
The learning problem is somewhat easier because bound-                      German, Farsi). Likewise, the same amount of data is not eas-
aries cannot occur within syllables, which limits the number                ily available for each language. Our shortest corpus (German)
of possible boundary locations per utterance. However, the                  consists of 9,378 utterances, while the longest (Farsi) consists
model loses access to all phonotactic information in the lan-               of 31,657. Notably, corpus size does not seem to affect seg-
guage, which can provide useful statistical cues to boundary                mentation performance noticeably (see Table 3) which may
locations (Blanchard, Heinz, & Golinkoff, 2010).                            indicate that performance for this type of Bayesian segmen-
                                                                            tation strategy plateaus relatively quickly.
                   Cross-linguistic input                                      The languages themselves also contain many differences
We evaluate the Bayesian learner on corpora of child-directed               that potentially affect syllable-based word segmentation.
speech in seven languages: English, German, Spanish, Ital-                  While our English and Hungarian corpora contain 2,330 and
ian, Farsi, Hungarian and Japanese. All corpora were taken                  3,029 unique syllables, respectively, Japanese and Spanish
from the CHILDES database (MacWhinney, 2000) and are                        contain only 526 and 524. Because the generative model
briefly summarized in Table 1. When corpora were available                  prefers units to appear frequently, languages with fewer syl-
only in orthographic form, they were converted into an ap-                  lables will tend to have those syllables appear often, poten-
propriate phonemic form by native speakers. Afterwards, un-                 tially causing the learner to identify individual syllables as
syllabified corpora were syllabified. Where possible, we uti-               words. This can lead to oversegmentation errors, such as
lized adult syllabification judgments (Baayen, Piepenbrock,                 kissing segmented as kiss and -ing. In addition, these lan-
& Gulikers, 1996). All other words were syllabified using the               guages also differ in their syntax and morphology. For exam-
Maximum-Onset principle, which states that the beginning of                 ple, Hungarian and Japanese are both agglutinative languages
a syllable should be as large as possible, without violating a              that have more regular morphological systems, while English,
language’s phonotactic constraints. We note that this serves                German, Spanish, Italian and Farsi are all fusional languages
only as an approximation of the infant representation, given                to varying degrees. If a language has regular morphology,
the lack of clear data on infant syllabification at this age.               the learner might reasonably segment morphemes rather than
   Our corpora vary in a number of important ways. While                    words, and later language learning will depend on success-
most of our corpora are Indo-European languages (English,                   ful segmentation of morphemes. This highlights the need for
German, Spanish, Italian, Farsi), we also use data from two                 a more flexible metric of segmentation performance: A seg-
non-Indo-European languages (Hungarian, Japanese). Lan-                     mentation strategy that identifies useful morphology in ag-
guages were chosen such that available native speakers could                glutinative languages would be at a disadvantage if the “gold
give guidance regarding the phonemic encoding and segmen-                   standard” of orthographic words is used to evaluate it, even
tation results for each language. Though the learning task we               though useful units have been identified.
model is one which occurs in the first seven months, child-
                                                                                         Learning results & discussion
directed speech corpora are not always easily available in this
age range. So, while many of our corpora do consist entirely                We first analyze our results in terms of word token F-score,
of early child-directed speech (e.g., English, Japanese), some              the harmonic mean of token precision (P) and recall (R):
                                                                                      P∗R
corpora contain speech directed to older children as well (e.g.,            F = 2 ∗ P+R   . Precision measures the probability that a word
                                                                            segmented is a true word (# identified true / # identified) and
    3 We note that utilizing syllables does not address one potential
                                                                            recall measures the probability that any true word was cor-
concern: if at six to seven months, infants are still distinguishing
non-native contrasts, this may indicate that all representational units     rectly identified (# identified true / total # true). F-scores
at that age are phonetically narrower than adult representations. For       range from 0 to 100, with higher values indicating better
example, infants may categorically represent both /ta/ and /th a/.          performance. Performance on all languages is presented in
                                                                        2777

Table 3. The non-bolded F-scores represent performance                          Uni NSE      Uni F     Bi NSE      Bi F
against the “gold standard” of orthographic words typically            Ger      0.000257     60.33     0.000502    73.05
used in word segmentation modeling studies (Goldwater et                Ita     0.000348     61.85     0.000604    71.25
al., 2009; Pearl et al., 2011; Blanchard et al., 2010; Lignos &        Hun      0.000424     59.90     0.000694    66.20
Yang, 2010). This provides a simple, easy-to-implement met-            Eng      0.000424     53.12     0.000907    77.06
ric for comparison to previous segmentation models, though              Far     0.000602     66.63     0.00111     69.63
it has its conceptual shortcomings as the target state for early        Spa     0.00128      55.03     0.00103     66.53
segmentation, as discussed previously.                                  Jpn     0.00126      66.63     0.00239     69.63
   While English and German both perform very well against
the gold standard (Bigram BatchOpt: 77.06 and 73.05), all            Table 2: NSE scores compared against the BatchOpt token
other languages have somewhat lower performance (e.g.,               F-score for a language, when compared against the gold stan-
Spanish: 64.75 and Japanese: 66.53). Still, our results              dard word segmentation. Results are shown for both the Un-
far outperform a random-guess baseline segmenter (21.37–             igram and Bigram models. Lower NSE scores represent less
38.15). We also compare our results to the subtractive seg-          inherent segmentation ambiguity and higher token F-scores
menter with beam search from Lignos (2011), which provides           indicate a better word token identification.
a good baseline since it is also syllable-based and performs
extremely well on English. This learner goes through the in-
                                                                     dard that does not penalize certain “useful errors”. Table 4
put segmenting any word which it has previously recognized.
                                                                     presents common examples of each type of useful error.
When there are multiple possible words, the word previously
encountered most often is chosen. While this method works               First, we adjusted for mis-segmentations resulting in real
well for English (87.77) and German (82.37), it fairs much           words. For example, /alôajt/ (alright) might be overseg-
more poorly with the remaining languages (30.09 – 58.25).            mented as /al/ /ôajt/ (all right), resulting in two actual En-
                                                                     glish words. All languages show errors of this type, of-
   One important factor noticed by Fourtassi et al. (2013)
                                                                     ten occurring for the bigram model, with the fewest in En-
is that English is less ambiguous with respect to segmen-
                                                                     glish (BatchOpt: 4.52% of all errors) and the most in Span-
tation than other languages. Fourtassi et al. (2013) com-
                                                                     ish (BatchOpt: 23.97%). These errors are likely due to the
pare phonemically-encoded corpora of English and Japanese,
                                                                     model’s preference to segment frequently-occuring words it
demonstrating with an Adaptor Grammar (Johnson et al.,
                                                                     has already seen.
2007) that performance is much higher for English than
Japanese. They explain their results in terms of Normalized             Another reasonable error is productive morphology. Be-
Segmentation Entropy (NSE), defined for any utterance as:            cause the perceptual unit is the syllable, only syllabic mor-
                                                                     phology can be identified in this manner. This likely explains
                                                                     why languages like English, Spanish, and Italian have rel-
                 NSE = − ∑ Pi log2 (Pi )/(N − 1)              (6)    atively few errors that produce morphemes (e.g., BatchOpt:
                            i
                                                                     0.13%, 0.05%, and 1.13% of all errors respectively), while
   where Pi represents the probability of a particular segmen-       Japanese, with more syllabic morphology, has more such er-
tation i and N represents the length of the utterance in terms of    rors (e.g., BatchOpt: 4.69%). Prefixes and suffixes were only
perceptual units (e.g., phonemes in their analysis). In essence,     identified as useful morphological errors when they appeared
given knowledge of all the true words and their frequencies,         at the beginning or end of a segmented word, respectively.
NSE quantifies how ambiguous a particular utterance remains          For instance, the prefix /ôi/ as in redo, would not be counted
with respect to segmentation. For example, Fourtassi et al.          as a useful error if very were to be segmented as /vE ôi/.
(2013) note that the phrase /ajskôim/ has two possible seg-             A third reasonable error type was common sequences of
mentations that produce only English words: “I scream” (/aj          function words. For example, a learner might identify is that
skôim/) and “ice cream” (/ajs kôim/).                                a as a single word isthata, similar to the errors reported by
   Using our own unigram and bigram models to stand in for           Brown (1973). These errors tend to be more common for
the probability of any given segmentation, we replicate Four-        unigram than bigram learners. This is intuitive from a statis-
tassi et al.’s (2013) findings that English segmentation is less     tical standpoint because the unigram model is unable to ac-
ambiguous than Japanese (see Table 2). Notably however,              count for commonly occurring sequences of words (since it
we find that ambiguity does not correlate with our unigram           assumes all words are independent) and so accounts for these
results (r = -.0510) and correlates only moderately with our         frequently occurring sequences by combining them into a sin-
bigram results (r = -.3871).                                         gle word. Still, function word sequence errors are relatively
   Given that the differences in segmentation performance            uncommon in every language except German (e.g., BatchOpt:
could not be attributed solely to varying segmentation am-           21.73%; vs. English: 4.30%, Farsi: 2.12%).
biguity, we investigated the types of errors made across lan-           For all useful errors, F-scores were adjusted so that the
guages. It turned out that many errors fell into one of three        “correct” portions of the error were not penalized. For in-
categories of “useful errors”, described below. Table 3 shows        stance, if a learner mis-segmented oopsie as oop and see, see
token F-scores when compared against an adjusted gold stan-          would be counted as correct because it is a real English word
                                                                 2778

                                                         Eng      Ger      Spa      Ita     Far     Hun      Jpn
                                    Batch-Opt           53.12    60.33    55.03    61.85   66.63   59.90    63.19
                                                        55.70    73.43    64.28    70.48   72.48   64.01    69.11
                      Unigram
                                    Online-Mem          55.12    60.27    56.12    58.58   59.57   54.54    63.73
                                                        58.68    73.85    67.78    66.77   67.31   60.07    70.49
                                    Batch-Opt           77.06    73.05    64.75    71.25   69.63   66.20    66.53
                                                        80.19    84.15    80.34    79.36   76.01   70.87    73.11
                       Bigram
                                    Online-Mem          86.26    82.56    60.22    60.87   62.46   59.51    63.32
                                                        89.58    88.83    83.27    74.08   73.98   69.48    73.24
                                    Subtractive Seg.    87.77    82.37    58.25    39.95   35.14   49.83    30.09
                      Baselines
                                    Random              38.15    34.23    28.92    22.88   21.37   25.68    23.84
Table 3: Word token F-scores for each Bayesian learner across English, German, Spanish, Italian, Farsi, Hungarian, and
Japanese. Results are given both for Unigram and Bigram learners, and include both the BatchOpt and Online-Mem learners.
The F-score when compared against orthographic words is shown, with the adjusted F-score that includes “useful errors” in
bold. A random-guess baseline is given along with model results for the subtractive segmenter with beam search from Lignos
(2011). Higher token F-scores indicate better performance.
while oop would still be counted as incorrect since it is not.         acquisition. Pearl et al. (2011) and Phillips & Pearl (2012)
                                                                       found that the constrained Online-Mem learner outperformed
                             True             Model                    its ideal BatchOpt equivalent. Cross-linguistically, this pat-
                  Spa       porque           por que                   tern is less robust (unigram learners: only in English, Span-
   Real words             ‘because’            ‘why’                   ish, and Japanese (e.g. Spanish BatchOpt: 64.28 vs. Online-
                  Jap    moshimoshi        moshi moshi
                            ‘hello’           ‘if’ ‘if’                Mem 67.78); bigram learners: only in English, German, and
                  Ita         devi              dev i                  Spanish (e.g. German BatchOpt: 84.15 vs. Online-Mem
  Morphology             ‘you must’         ‘must’ P L                 88.83)). Thus, while there is some support for the idea that
                  Far       miduni           mi dun i
                         ‘you know’     P RES ‘know’ 2-S G             incorporating cognitive considerations into Bayesian learners
                  Ita         a me              ame                    might improve word segmentation results, it is not true for
  Func words                ‘to me’           ‘tome’                   every language. Still, for all languages it does appear that
                  Far     mæn hæm            mænhæm
                           ‘me too’          ‘metoo’                   adding psychological constraints does not significantly harm
                                                                       performance, especially once “useful errors” are taken into
Table 4: Examples of useful errors (with English glosses)              account. This suggests that Bayesian inference is a viable
made by learners in different languages. True words refer to           strategy for word segmentation cross-linguistically, even for
the segmentation in the original corpus, while Model output            learners who cannot perform optimal inference.
represents the segmentation leading to a useful error.                    Importantly, the goal of early segmentation is not for the in-
                                                                       fant to segment perfectly as an adult would, but to provide a
   Languages that fared more poorly when compared against              way to get the word segmentation process started. Given this
the original “gold standard” benefit the most from the use-            goal, Bayesian segmentation seems effective for all these lan-
ful error analysis, underscoring the utility of this more nu-          guages. Moreover, because our learners are looking for use-
anced metric. Focusing on the useful error results, we find            ful units, which can be realized in different ways across lan-
as previous studies did that the bigram learners outperform            guages, they can identify foundational aspects of a language
the unigram learners. This suggests that the knowledge that            that are both smaller and larger than orthographic words.
words depend on previous words continues to be a useful one
(as Goldwater et al. 2009, Pearl et al 2011, and Phillips &                                     Conclusion
Pearl 2012 found for English), though this difference may be           We have demonstrated that Bayesian segmentation performs
smaller for some languages (e.g., Farsi, Japanese). As with            quite well as an initial learning strategy for many different
the unadjusted results, performance for English and German             languages, especially if the learner is measured by whether it
is very high (best score: 89.58), while for other languages            identifies useful units. This not only supports Bayesian seg-
the learners tend to fare less well (best score: 70.87–83.27),         mentation as a viable cross-linguistic strategy, but also sug-
though still quite good if the goal is to generate a set of useful     gests that a useful methodological norm for word segmenta-
units from which to bootstrap further language acquisition.            tion research should be how well a learning strategy identi-
   Incorporating cognitive constraints into Bayesian learning          fies units that can scaffold future language acquisition. By
with the Online-Mem learner touches somewhat on the “Less              taking into account reasonable errors that identify such units,
is More” (LiM) hypothesis (Newport, 1990), which supposes              we bring our model evaluation into alignment with the actual
that cognitive limitations help – rather than hinder – language        goal of early word segmentation.
                                                                   2779

                   Acknowledgments                                 Jusczyk, P., Cutler, A., & Redanz, N. (1993). Infants’ pref-
We would like to thank Caroline Wagenaar, James White,               erence for the predominant stress pattern of english words.
Galia Barsever, Tiffany Ng, Alicia Yu, Nazanin Sheikhan,             Child Development, 64(3), 675–687.
and Sebastian Reyes for their help with corpus preparation. In     Jusczyk, P., & Derrah, C. (1987). Representation of speech
addition, we are very grateful to Robert Daland, Constantine         sounds by young infants. Developmental Psychology,
Lignos, Amy Perfors, Naomi Feldman, Jon Sprouse, Barbara             23(5), 648–654.
Sarnecka, Michael Lee, Alex Ihler, and UCLA’s phonology            Lignos, C. (2011). Modeling infant word segmentation. In
seminar for their helpful comments.                                  Proceedings of the Fifteenth Conference on Computational
                                                                     Natural Language Learning (pp. 29–38).
                        References                                 Lignos, C., & Yang, C. (2010). Recession segmentation:
                                                                     Simpler online word segmentation using limited resources.
Baayen, R., Piepenbrock, R., & Gulikers, L. (1996). Celex2.          In Proceedings of the fourteenth conference on computa-
  Linguistic Data Consortium.                                        tional natural language learning (pp. 88–97).
Blanchard, D., Heinz, J., & Golinkoff, R. (2010). Modeling         MacWhinney, B. (2000). The childes project: Tools for an-
  the contribution of phonotactic cues to the problem of word        alyzing talk (3rd ed.). Mahwah, NJ: Lawrence Erlbaum
  segmentation. Journal of child language, 37, 487–511.              Associates.
Bortfeld, H., Morgan, J., Golinkoff, R., & Rathbun, K.             Marthi, B., Pasula, H., Russell, S., & Peres, Y. (2002). De-
  (2005). Mommy and me: Familiar names help launch ba-               cayed mcmc filtering. In Proceedings of 18th uai (p. 319-
  bies into speech-stream segmentation. Psychological Sci-           326).
  ence, 16(4), 298–304.                                            Mattys, S., Jusczyk, P., & Luce, P. (1999). Phonotactic and
Brown, R. (1973). A first language: The early stages. Har-           prosodic effects on word segmentation in infants. Cognitive
  vard University Press.                                             Psychology, 38, 465–494.
Echols, C., Crowhurst, M., & Childers, J. (1997). The per-         Morgan, J., & Saffran, J. (1995). Emerging integration
  ception of rhythmic units in speech by infants and adults.         of sequential and suprasegmental information in preverbal
  Journal of Memory and Language, 36, 202–225.                       speech segmentation. Child Development, 66(4), 911–936.
Eimas, P. (1999). Segmental and syllabic representations in        Newport, E. (1990). Maturational constraints on language
  the perception of speech by young infants. Journal of the          learning. Cognitive Science, 14, 11–28.
  Acoustical Society of America, 105(3), 1901–1911.                Pearl, L., Goldwater, S., & Steyvers, M. (2011). Online learn-
Ferguson, T. (1973). A bayesian analysis of some nonpara-            ing mechanisms for bayesian models of word segmenta-
  metric problems. Annals of Statistics, 1(2), 209–230.              tion. Research on Language and Computation, 8(2), 107–
Fourtassi, A., Börschinger, B., Johnson, M., & Dupoux, E.           132. (special issue on computational models of language
  (2013). Whyisenglishsoeasytosegment. In Cognitive mod-             acquisition)
  eling and computational linguistics 2013 (pp. 1–10).             Phillips, L., & Pearl, L. (2012). ’less is more’ in bayesian
Gambell, T., & Yang, C. (2006). Word segmentation: Quick             word segmentation: When cognitively plausible leaners
  but not dirty.                                                     outperform the ideal. In Proceedings of the 34th annual
Geman, S., & Geman, D. (1984). Stochastic relaxation, gibbs          conference of the cognitive science society (pp. 863–868).
  distributions, and the bayesian restoration of images. Pat-      Polka, L., & Werker, J. (1994). Developmental changes in
  tern Analysis and Machine Intelligence, IEEE Transactions          perception of nonnative vowel contrasts. Journal of Exper-
  on, 6, 721–741.                                                    imental Psychology: Human Perception and Performance,
Goldwater, S., Griffiths, T., & Johnson, M. (2009). A                20(2), 421–435.
  bayesian framework for word segmentation. Cognition,             Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learn-
  112(1), 21–54.                                                     ing by 8-month-old infants. Science, 274, 1926–1928.
Johnson, E., & Jusczyk, P. (2001). Word segmentation by 8-         Swingley, D. (2005). Statistical clustering and the contents of
  month-olds: When speech cues count more than statistics.           the infant vocabulary. Cognitive Psychology, 50, 86–132.
  Journal of Memory and Language, 44, 548–567.                     Teh, Y., Jordan, M., Beal, M., & Blei, D. (2006). Heirarchi-
Johnson, M. (2008). Unsupervised word segmentation for               cal dirichlet processes. Journal of the American Statistical
  sesotho using adaptor grammars. In Proceedings of the              Association, 101(476), 1566–1581.
  tenth meeting of the acl special interest group on compu-        Thiessan, E., & Saffran, J. (2003). When cues collide: Use
  tational morphology and phonology (pp. 20–27).                     of stress and statistical cues to word boundaries by 7- to 9-
Johnson, M., Griffiths, T., & Goldwater, S. (2007). Adap-            month-old infants. Developmental Psychology, 39(4), 706–
  tor grammars: A framework for specifying compositional             716.
  nonparametric bayesian models. Advances in Neural Infor-         Werker, J., & Tees, R. (1984). Cross-language speech per-
  mation Processing Systems, 19, 641–648.                            ception: Evidence for perceptual reorganization during the
Jusczyk, P., & Aslin, R. (1995). Infants’ detection of the           first year of life. Infant Behavior & Development, 7, 49–
  sound patterns of words in fluent speech. Cognitive Psy-           63.
  chology, 29, 1–23.
                                                               2780

