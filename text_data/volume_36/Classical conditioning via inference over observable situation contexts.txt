UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Classical conditioning via inference over observable situation contexts

Permalink
https://escholarship.org/uc/item/6390m7wh

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Srivastava, Nisheeth
Schrater, Paul

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Classical conditioning via inference over observable situation contexts
Nisheeth Srivastava (nsrivastava@ucsd.edu)
Department of Psychology, University of California San Diego
San Diego, CA 92093 USA

Paul R Schrater (schrater@umn.edu)
Department of Psychology, University of Minnesota
Minneapolis, MN 55455 USA
Abstract
In this paper, we demonstrate that predicting stimulus cooccurrence patterns in a Bayes-optimal manner endogenously
explains classical conditioning. Simulated experiments with
a standard Bayesian implementation of this model show that
it is capable of explaining a broader range of effects than any
previous theory of classical conditioning. By simplifying the
mathematical structure of statistical modelling of conditioning
and demonstrating its ability to explain a large set of experimentally observed effects, our work advances Bayes-optimal
inference about stimulus co-occurrence as a rational principle
explaining classical conditioning.
Keywords: learning; Bayesian modelling; computer simulation; decision-making

Introduction
Classical conditioning is a form of associative learning
wherein animals are trained to respond positively or negatively to some stimulus towards which they were previously
neutrally disposed. The classic example of such conditioning arises from its accidental discovery by Ivan Pavlov, who
discovered that dogs kept in his lab to be used as experiment subjects would salivate as if they were about to feed at
the sound of a bell that typically heralded mealtime (Pavlov,
1927). Such transference of somatic response from a positive stimulus (food) to a prima facie neutral one (bell sound)
through situational co-occurence has since been called classical (or Pavlovian) conditioning. In any classical conditioning
experiment, a stimulus for which an animal is known to have
a positive or negative response (called unconditioned stimulus, or US) is paired with a neutral one (called the conditioned stimulus, or CS) until the animal transfers the somatic
response typically evinced when encountering the US to encounters with CS. When such a conditioned response (CR) is
elicited, the animal is considered to have been conditioned.
Despite the importance and long lineage of research in
classical conditioning, formal theories still find it difficult to
explain a wide variety of conditioning-related behaviors seen
in experiments. The Rescorla-Wagner model (Rescorla &
Wagner, 1972) is the most influential formal model of conditioning, but cannot discriminate non-linear cue combinations and other interesting conditioning effects. The comparator class of theories has multiple formal instantiations,
all of which share in the intellectual attempt to coopt environmental cues beyond the labeled CS to help predict the
US. Attention-based models explain conditioning effects using information-theoretic measures of informativeness of various CS. Both these latter theories can explain some things

that Rescorla-Wagner can’t, but are perceived to have their
own limitations, particularly in that they remain formally underspecified. Thus, there is no theoretical consensus on modelling classical conditioning, and until recently, little hope of
arriving at one.
Recently, sophisticated modelling by Courville et
al (Courville, Daw, & Touretzky, 2006) and (Gershman &
Niv, 2012) has shown that comparator-type theories formally
instantiated as Bayesian inference about the latent structure
of an animal’s environment have substantial predictive
power. These formal models statistically ground previously
somewhat heuristic presentations of the comparator hypothesis (Stout & Miller, 2007) by using animals’ known
propensity to make situational frequency judgments (Hasher
& Zacks, 1984) to inform conditional probability estimates
of the form p(US|CS,US, S) , where S are non-CS environmental factors that can help predict US. Simulation
studies demonstrate that such Bayesian latent variable
comparator models explain substantially more conditioning
effects than earlier less formal comparator accounts. For
instance, Courville et al. (2006) review a large number of
studies documenting effects that have traditionally been
explained using attentional models, and demonstrate that
each one of them can be explained using a latent variable
model that postulates that animals try to infer what cause
could have led to their current stimulus set observation.
Gershman and Niv (2012) present a different latent cause
model and demonstrate its utility in explaining a number of
conditioning effects, including ones that comparator theories
have erstwhile been hard pressed to explain. These modelling advances have made a concrete case for investigating
context-sensitive US prediction as a primary explanation for
classical conditioning.
However, while latent cause modelling is a promising new
direction, the theory is still immature, with a number of different formal specifications possible, each with a different set
of potentially implausible statistical assumptions. For example, (Courville et al., 2006) assume that animals learn the
rate of change of parameters for a fixed set of latent models. In contrast, (Gershman & Niv, 2012) use infinite mixture
modelling to infer latent causes dynamically, but are forced
to treat causes as clusters of observation vectors, assume a
Dirichlet process prior on the set of causes, and impute only
MAP estimation to the cause inference. It is not currently
clear which assumptions in these models are essential to the

1503

theory, which are simply modelling requirements, and which
are entirely superfluous.
In this paper, we adopt a simpler third interpretation for
these latent variables, viz. that they are not latent but rather
simply index stimuli co-occurrences the animal has observed
in the past. We show that this interpretation leads to a simple
formal specification of the comparator account of classical
conditioning that expands upon the explanatory power of latent cause-based models, while additionally being observable
and directly testable. As evidence for the predictive ability
of our model, we present simulated replications of ten classic
conditioning effects by agents using our model. Its success
further strengthens the case for normative Bayesian inference
as a rational basis for animal behavior (Knill & Pouget, 2004).

The key quantity of interest is the likelihood term
p(US(t),CS(t), S(t)|c). Both within the temporal constraints
of conditioning experiments and in the real world, animals
will typically encounter situations where biologically irrelevant stimuli S and CS are observed, and biologically important US is to be predicted, making the separate computation of p(US|CS, S) ecologically natural. It is easy to derive
the probabilistic strength of association p(US|CS) from this
computation, and we believe that the stimulus specific CRs
measured in conditioning experiments are simply behavioral
measurements of this quantity. Thus, we see that our likelihood term matches the interpretation of CR in the conditioning paradigm, resulting in an overall interpretation of conditioning responses as playing a facilitative role in the animal’s
deeper goal of situational context prediction.
In our representation, each context has an associated set of
stimuli c j ∈ c, and the probability that an incoming observation vector o is generated from this context simply requires
an assessment of set membership mismatches. Let p(oi |c j )
be the probability that the ith element of the observation vector o matches the jth element of c. Then, the probability that
stimulus x = oi is generated by an object set c is,

The situation prediction model
The fundamental novelty of our approach to modelling classical conditioning is that we don’t try to model it. Instead, we
try to model what we believe is a superordinate goal for animals - predicting situations and their corresponding task-sets.
We consider it more ecologically natural to think of animals
being driven by the need to orient themselves to their environments by constantly making adaptive predictions. If we
assume that animals do partition the environment as discrete
situations, trying to predict which one they are in becomes a
natural and essential goal. It is this essential process that we
try to model.
We model this basic orienting process as sequential
Bayesian updating, where animals use evidence about stimulus co-occurrences observed in the past o1:t−1 to predict the
likelihood of being in situation context c and having to respond to it at time t. The standard Bayesian formulation of
this inference is,
p(c|o1:t ) ∝ p(ot |c) × p(c|o1:t−1 ).

p(x|c) = 1 −

(1)

To specialize this model to the classical conditioning
paradigm, we simply define observations in a specific way.
We assume that, in addition to generic environmental stimuli S, the animal can observe CS and US in the conditioning setup. We therefore model an observation at time t as
ot = {US,CS, S}(t), where each stimulus in turn is a binary
attribute which is either present or not present in the observation vector ot . We interpret c as the observation-indexed
situation context within which an animal has to respond to
stimuli that are biologically relevant (US). Formally, we simply index c using o, thereby instantiating C as the set of all
previous observations unique with respect to observation set
membership.
With these additional assumptions constraining our interpretation of the model defined in (1), we obtain a specialization calculating p(c|{US,CS, S}(1 : t)) as,
p(c|{US,CS, S}(1 : t))

(2)

∝

p({US,CS, S}(t)|c)

×

p(c|{US,CS, S}(1 : t − 1)).

β
|c|

|c|

∑(1 − δ(x − c j ))

(3)

j

where β is a parameter controlling the magnitude of the
penalty imposed for each mismatch observed, with p(x|o)
similarly defined.
Predictive evidence for US associated with each context
p(US|x, c) is imputed individually. As a rule of thumb, if a
context does not contain US, it is unlikely to predict future
US and vice versa. This evidence is compiled across all previously inferred c ∈ C to predict strength of association with
US for any x, conditional on it being present in the current
observation vector ot . While only the CS is relevant for modelling conditioning, our model is designed to predict strength
of association with all possible stimuli. In settings where the
environmental stimulus set S is fixed, our model predicts that
the conditioning response CR will be proportional to,
∑Cc p(US(t)|CS(t), c)p(CS(t)|c)p(c|ot )
,
∑Cc p(CS(t)|c)p(c|ot )
(4)
where p(c|ot ) is the posterior distribution across contexts
given we have observed ot , in turn computed as,
p(US(t)|CS(t)) =

p(c|ot ) =

∑x p(x|ot )p(x|c)p(c)
.
∑c ∑x p(x|ot )p(x|c)p(c)

(5)

Changes in the environmental context can be easily incorporated by marginalizing over S. Additionally, we can
also compute cumulative conditioning responses arising from
multiple stimuli, e.g. {CS1 ,CS2 , S} in cue combination settings by marginalizing across the subset X of the cues in ques-

1504

(B)0.6

p(US|S)
p(US|CS)

0.8

Context probability

Conditioned response

(A) 1

0.6

0.4

0.2

0

0

20

40

Trial

60

80

0.5
0.4
0.3
0.2
US, CS, S
CS, S
S

0.1
0

100

0

20

40

Trial

60

80

100

Figure 1: Simulation illustrating the basic operation of our model. We assume that agents can estimate the likelihood of
seeing a stimulus worth responding to conditioned on the probability of being in particular situations. (A) Our Bayesian model
estimates conditional probabilities of US with respect to multiple environmental cues, giving us the traditional CR as a special
case. (B) The principal component of our model is situation inference, which gates the accumulation of reinforcement evidence.
tingency; all values lower than this can reflect absence of CR
depending on training conditions. Values higher than 0.5 will
always imply the existence of a CR.

X

C

x

x

c

(6)
Figure 1 shows the basic operation of our model as a simulation, with the measured conditioning response associated
with both CS and S plotted across an acquisition-extinction
episode in panel A and the corresponding latent context probabilities plotted in panel B. For the first 20 trials in this experiment, the agent is exposed to the unreinforced CS in the
environmental condition S, resulting in a high context probability for {CS, S}. Then, during acquisition between trials 20
and 60, the context {US, CS, S} expectedly becomes prominent. Finally, the agent is exposed to the unreinforced CS in a
different environmental condition, resulting in the dominance
of the context indexed by {CS}. Our simulation of CR (dotted line) shows the correct acquisition and extinction behavior
expected of a model of classical conditioning.

Results
Our theory makes accurate predictions for a large number
of conditioning-related effects. In the interests of succinctness, we restrict ourselves to reporting here 10 simulated effect replications, selected for their prominence across multiple theoretical accounts of conditioning. No existing model
of conditioning can account for all 10 of the effects that we
explain below. In all the following figures, trial numbers are
counted from the last reinforced trial, i.e., the last reinforced
presentation occurs at trial 0. For all subsequent trials, the
simulated agent sees unreinforced situation contexts in configurations determined by the corresponding test scenarios.
Individual training and pre-exposure blocks, where specified,
consisted of 5 trials in each of our simulations. Finally, since
US is a binary random variable, p(US|CS) = 0.5 will indicate
absence of conditioning if the training sequence is zero con-

(A)

(B)

0.9

0.9
CS1

0.8

CS1 + CS2

0.7

p(US|CS1)

X

CR = ∑ p(US(t)|x)p(x) = ∑ p(US(t)|x) ∑ p(x|c)p(c|ot ).

Conditioning response

tion,

0.6
0.5
0.4
0.3
0.2
0.1
0

2

4

6

Trials

8

10

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

AB+

A−

Training condition

B−

Figure 2: Stimulus generalization. Replicating (A) external
inhibition, where the trained CS is accompanied by a novel
stimulus during testing and (B) non-linear (positive) patterning, where individual elements A and B are presented unreinforced, while the combined cue AB is reinforced during
training.
The first pair of effects, illustrated in Figure 2, can both
be seen as instances of animals generalizing US-CS contingency information in interesting ways that simple RescorlaWagner (RW) models find hard to replicate. For example, the
example of non-linear patterning seen in 2(B) poses a major challenge for RW, since positive contingency of the US
with AB must necessarily transfer to both A and B by its predictions. Instead, real animals, comparator-based accounts
and our simulation all show CR in the presence of AB, but
not A or B, as shown in 2(A). Our model explains patterning
through separate evidence accumulation for the situation contexts triggered by the presence respectively of A,B and AB.
External inhibition occurs when the presence of a novel stimulus during testing reduces CR, as shown in 2(A). This effect
is, in fact, known since the earliest conditioning experiments,

1505

(A) 0.9

0.5

{CS1, CS2}

0.7

(B) 1

(B) 0.55

CS1

0.8

0.8

0.5
0.4
0.3

p(US|CS)

p(US|CS)

0.4

0.2

0

2

4

Trials

6

8

10

1

0.3
0.25
0.2

0.1
2

3

Trials

4

5

0.05

1

2

3

Trials

4

5

0.4

0.2
Normal
Pre−exposed

0

0.6

CS1+

0.35

0.15

0.1
0

0.6

CS2+

0.4

0.6

0.2

0.8

Control
CS2−

0.45

p(US|CS2)

(A) 1

exposure block presenting CS reinforced with weak US as
defined above, as illustrated in 3. As with learned irrelevance,
no attention or surprise-related concepts are invoked.
When multiple conditioning stimuli are used, it turns out
that presenting one stimulus reinforced alone and unreinforced when paired with another stimulus causes the second
stimulus to become a conditioned ‘inhibitor’, viz. its presence
suggests that US will likely not appear. Presenting both stimulus configurations for one trial block each leads to a replication of conditioned inhibition in our simulation, as shown
in 4(A). Bayesian inference provides an extremely natural explanation for this effect, since negative evidence for US availability accumulates transparently in the {CS1 ,CS2 } situation
context in our model. Since CR is computed by marginalizing across all such contexts, incorporating evidence from this
context reduces p(US|{CS1 ,CS2 }), which, by the logic of our
model is the same as measuring CR in a summation test.

p(US|CS)

when Pavlov noticed the effects of extraneous noises on his
dogs’ CRs during testing. Our model explains this effect via
a reduction in the likelihood p(x|c) for an observation containing novel stimuli.
Another simple manipulation of the basic conditioning experiment involves pre-exposing a test group of subjects to the
US or CS before training begins. Learned irrelevance is a
prominent effect that arises in such settings, often invoked
by attention-based modelers, wherein prior exposure to US
intermittently paired with CS retards subsequent acquisition
of CR for CS. Figure 3(A) illustrates our model’s replication
of this effect using two pre-exposure blocks containing together five reinforced and five unreinforced presentations of
CS in random order, with the reduced sensitivity to training
emerging from a flattened prior distribution p(c|o) of possible
situations where US is expected. In other words, the model
anticipates that US will be present in a large range of situations, the presence of CS being one of them. This dilutes
the probabilistic binding p(US|CS), leading to lower CR, and
slower acquisition until p(c|o) becomes sufficiently peaked
through repeated exposure to CS.

0

0

Normal
Pre−trained
2

4

Trials

6

8

10

Figure 3: Pre-exposure effects. Replicating pre-exposure effects like, (A) Learned irrelevance through random prior presentation of US and CS leads to no initial CR (see trial 2)
and slower acquisition of CR compared to normal conditioning without pre-exposure to the random trials. (B) The HallPearce effect, where pre-training with a weaker version of the
US retards subsequent acquisition with normal US.
Note that our explanation does not invoke notions of
surprise and salience, like (Mackintosh, 1975) and other
attention-based accounts of this effect. The explanation for
retarded CR acquisition arises entirely from our straightforward Bayesian formalism. A similar resolution occurs for
the well-known Hall-Pearce effect, wherein pre-training with
a weaker version of the US retards subsequent CR acquisition with a stronger version. While our model does not permit explicit representations of stimulus strength, we model
this effect by modifying our set membership computation in
Equation 3 to permit partial matches. For our purposes, this
modification is restricted to defining p(x = weak US|c) =
0.5, ∀c s.t.US ∈ c and p(x = US|c) = 0.5, ∀c s.t.weak US ∈
c, following the intuition that a weak version of the same
US will be judged similar to the US. With this assumption,
our model replicates the Hall-Pearce effect using one pre-

Figure 4: Conditioned inhibition. Replicating (A) the basic
conditioned inhibition effect, where interleaved presentation
of reinforced CS1 and an unreinforced combination of CS1
and CS2 causes CS2 to be inhibited, as measured by summation tests, and (B) variations thereof testing the effects of
subsequent inflation and deflation of the inhibited CS.
As Gershman and Niv (2012) point out, there are multiple
variations of the basic conditioned inhibition result. For instance, once a stimulus has been trained as an inhibitor, subsequently reinforcing it attenuates the inhibition, while extinguishing it has little impact on the conditioning response.
This pattern is borne out in our simulations using one posttraining block, as illustrated in 4(B). The y-intercept is the key
observation in this figure, and shows clearly that the CS2 −
condition yields a similar CR to the baseline conditioned inhibition setting, while CS2 + leads to increased CR at test trial
1, though still inhibitory with respect to CS2 . However, our
theory fails, like Gershman’s model, to explain an observation (Amundson, Wheeler, & Miller, 2005) that post-training
inflation of the conditioned excitor (CS1 +) enhances conditioned inhibition of CS2 . Our theory predicts the opposite result, using positive evidence for US −CS1 binding to increase
the overall conditioning response, without reducing the relative share of CS2 .
Latent variable models also find it difficult to explain other
cue competition based conditioning effects. The observable nature of our context variables renders our theory somewhat more successful in explaining such data. Overshadow-

1506

ing is a classic conditioning effect, and has heretofore been
one of the most compelling pieces of evidence supporting
value-based models of conditioning. In overshadowing, the
CR for a stimulus trained jointly with another stimulus is
weaker than the CR obtained when training with it alone.
Rescorla-Wagner and other value-based models find it easy
to explain this result as a sharing of value across multiple
sites in the compound conditioning case. Our model explains this effect, as illustrated in 5(A) via a simple conditionalization argument. Given the same number of trials in
each case, evidence for CS1 in the compound case has to be
weighted by the observation likelihood of encountering CS1
alone. Since this quantity is sub-unity by the design of the
experiment, overshadowing emerges naturally. Note that it is
our model’s use of observation-indexed context variables that
permits likelihood computation. Latent variable models using
more abstract context variables cannot compute such quantities, which makes it harder for them to explain cue competition effects.

0.6

0.6

0.5
0.4

0.5
0.4

0.3

0.3

0.2

0.2
2

3

Trials

4

5

0.1
1

2

3

Trials

4

5

(B)

1

0.9

Complete
Partial

0.8

0.8
0.7

p(US|CS)

0.7

0.1
1

Normal
BL
UB

0.8

CS1+

0.7

p(US|CS2)

p(US|CS1)

0.8

(A)

(B) 0.9

CS1 CS2+

Relative conditioning response

(A) 0.9

text. Here, adding a novel environmental stimulus reduces the
relevance of the original CS1 trials in the context probability
calculation, resulting in a relatively higher value for contexts
containing CS2 than the blocking case.
The last pair of effects we consider have been been difficult to explain in the past, particularly for latent variable
models. The first - the partial reinforcement extinction effect
(PREE) refers to the observation that CRs trained using intermittent and variable schedules are larger in magnitude and
take longer to extinguish. As we show in 6(A), our model predicts the second aspect of this effect, but not the first. In doing
so, it joins the model of (Courville et al., 2006), who make
precisely the same prediction. Our model explains this aspect
of PREE following much the same outline as (Gershman &
Niv, 2012) and (Courville et al., 2006). Intermittent observation of the reinforcing context makes it harder for the inductive algorithm to judge when it is no longer in a reinforcing
trial block, thereby taking longer to extinguish the CR.

0.6
0.4

0.6
0.5
0.4
0.3
Control
LI
LI + OV

0.2

0.2

0.1

0

0

5

10

Trials

15

20

0

1

2

3

Trials

4

5

Figure 5: Cue competition. Replicating effects like (A) overshadowing, where compound conditioning with CS1 and CS2
results in a weaker conditioning response than training with
either of the individual CS, and (B) the classic blocking effect, where reinforcement with CS1 followed by reinforcement with {CS1 ,CS2 } elicits no trained response for CS2 as
well as an unblocking effect, where blocking is attenuated by
testing in a new environmental context.

Figure 6: Tricky effects. The situational context model
makes interesting predictions for effects that have proved difficult to explain such as (A) the partial reinforcement extinction effect, where intermittent and variable reinforcement
schedules retard future cue extinction. and (B) pre-exposure
overshadowing, where unreinforced pre-exposure to CS1 appears to eliminate the over-shadowing effect of subsequent
combined training with CS1 and CS2 .

Figure 5(B) illustrates our model’s replication of Kamin’s
classic blocking effect, wherein it is found that reinforcing
the compound {CS1 ,CS2 } after reinforcing CS1 yields no
training response for CS2 . The existence of this effect motivated the use of a maximum (saturation) level of training
associated with any US in the Rescorla-Wagner framework.
It is also explained in attention-based frameworks by positing that since CS1 already predicts US, the animal doesn’t
need to learn a new predictor CS2 . Our model provides
a novel inductive explanation. The observation likelihood
p(x = CS2 |c = {CS1 ,CS2 }) reduces the positive evidence for
p(US|CS2 ), the prior encounters with the context containing
just CS1 lower the prior context probability p(c|o1:t ) of inferring the context {CS1 ,CS2 } itself. These sequential dilutions multiplicatively reduce the p(US|CS2 ) computation to
the value we see in 5(B). Also, our model replicates the unblocking effect described by (Courville et al., 2006), wherein
blocking is attentuated by testing in a new environmental con-

Courville et al. (2006) also describe preexposure overshadowing (Experiment 3 in their paper), where unreinforced
preexposure to CS1 eliminates the overshadowing effect of
subsequent compound training with {CS1 ,CS2 }. This is,
on the surface, a surprising result, since it is known that
(i) pre-exposure to a stimulus tends to retard future acquisition (latent inhibition), and (ii) pairing two stimuli also
leads to slower learning (overshadowing). Blaisdell and colleagues (Blaisdell, Bristol, Gunther, & Miller, 1998) demonstrated that combining both these conditions actually attenuates the learning deficit. In fact, as a mark of its intricacy, (Blaisdell et al., 1998) set it up as a challenge for noncomparator accounts of conditioning. Our model replicates
this effect, as shown in 6(B), and explains it thus: prior exposure to CS1 tilts the context probability p(c|o) in favor of contexts containing only CS1 as opposed to the pair {CS1 ,CS2 }.
This causes evidence for the compound to disproportionately
raise p(US|CS1 ) above the overshadowing baseline.

1507

Courville, Daw & Touretzky

Latent
causes

Latent
causes

Gershman, Niv & Blei

Srivastava & Schrater

Situation
contexts

Stimuli

Situation
contexts

Stimuli

Figure 7: A comparison of the generative models underpinning our theory and its closest relatives - Courville’s latent cause
model and Gershman’s infinite capacity latent cause model. The key difference is the observability of the context variables in
our theory which permits more granular likelihood computations and a richer set of effect descriptions.

Discussion

References

The principal source of variation between the models in
Figure 7 is in the interpretation of the context variables.
Courville et al. (2006) assume that the latent variables are
generative models that the animal thinks could explain the observations it sees. Gershman and Niv (2012) assume that latent variables are clusters of observations, imputing a specific
generative model (Dirichlet process mixtures) to the clustering process. Our interpretation indexes contexts using observation co-occurence directly. The consequent transparency
of representation allows our model to reproduce the predictions of its competitors, and predict some effects they cannot.
The main contribution of this work is a streamlining of the
assumptions underlying the inferential view of conditioning,
thereby improving its explanatory power and testability.
An important limitation of our model is that it is eventbased, rather than time-based. While the time elapsed between events is certainly important for many kinds of learning, including reinforcement tasks that have explicit time dependence on the delivery and availability food or reinforcers,
our methods have focused on another ubiquitous type of decision task, where the options selected are freely available
within a context, and the context determines what should
be selected. Such tasks are likely to be well-described by
context-dependent conditioning, wherein ventromedial prefrontal cortex and hippocampus loops have been neurophysiologically implicated in context-specific retrieval of value information (Kalisch et al., 2006).
In a broad sense, value-based theories of conditioning describe a world where understanding is cheap and decisions are
difficult. Such a description is apt for artificial control systems, the study of which, not coincidentally, gives us much
of the mathematics that governs value-based learning theories. It is not, however, a fitting description of the way welladapted animals engage with their natural environments. The
inference-based view of conditioning gives a better description of such a world - where understanding is difficult, and
action selection, once the situation context is understood, is
easy. The success of our simple model in explaining a variety
of conditioning effects further strengthens this belief.

Amundson, J. C., Wheeler, D. S., & Miller, R. R. (2005).
Enhancement of pavlovian conditioned inhibition achieved
by posttraining inflation of the training excitor. Learning
and motivation, 36(3), 331–352.
Blaisdell, A. P., Bristol, A. S., Gunther, L. M., & Miller, R. R.
(1998). Overshadowing and latent inhibition counteract
each other: Support for the comparator hypothesis. Journal
of Experimental Psychology: Animal Behavior Processes,
24(3), 335.
Courville, A. C., Daw, N. D., & Touretzky, D. S. (2006).
Bayesian theories of conditioning in a changing world.
Trends in cognitive sciences, 10(7), 294–300.
Gershman, S. J., & Niv, Y. (2012). Exploring a latent cause
theory of classical conditioning. Learning & behavior,
40(3), 255–268.
Hasher, L., & Zacks, R. T. (1984). Automatic processing of
fundamental information: the case of frequency of occurrence. American Psychologist, 39(12), 1372.
Kalisch, R., Korenfeld, E., Stephan, K. E., Weiskopf, N.,
Seymour, B., & Dolan, R. J. (2006). Context-dependent
human extinction memory is mediated by a ventromedial
prefrontal and hippocampal network. The Journal of neuroscience, 26(37), 9503–9511.
Knill, D. C., & Pouget, A. (2004). The bayesian brain:
the role of uncertainty in neural coding and computation.
TRENDS in Neurosciences, 27(12), 712–719.
Mackintosh, N. J. (1975). A theory of attention: Variations
in the associability of stimuli with reinforcement. Psychological Review, 82(4), 276.
Pavlov, I. P. (1927). Conditioned reflexes. DoverPublications.
com.
Rescorla, R. A., & Wagner, A. R. (1972). A theory of pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. Classical conditioning
II: Current research and theory, 64–99.
Stout, S. C., & Miller, R. R. (2007). Sometimes-competing
retrieval (socr): A formalization of the comparator hypothesis. Psychological Review, 114(3), 759.

1508

