UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A comprehensive model of spoken word recognition must be multimodal: Evidence from
studies of language mediated visual attention
Permalink
https://escholarship.org/uc/item/73w1w3b1
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Smith, Alastair
Monaghan, Padraic
Huettig, Falk
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

  A comprehensive model of spoken word recognition must be multimodal: Evidence
                             from studies of language mediated visual attention
                                           Alastair C. Smith (alastair.smith@mpi.nl)
                                      Max Planck Institute for Psycholinguistics, Wundtlaan 1,
                                                 Nijmegen, 6525 XD, The Netherlands
                                    Padraic Monaghan (p.monaghan@lancaster.ac.uk)
                                          Department of Psychology, Lancaster University,
                                                       Lancaster, LA1 4YF, U.K.
                                                Falk Huettig (falk.huettig@mpi.nl)
                                      Max Planck Institute for Psycholinguistics, Wundtlaan 1,
                                                 Nijmegen, 6525 XD, The Netherlands
                             Abstract                                 information involved in this mapping and the temporal
                                                                      structure of this process.
   When processing language, the cognitive system has access to
   information from a range of modalities (e.g. auditory, visual)        Huettig and McQueen (2007), presented participants with
   to support language processing. Language mediated visual           scenes that contained objects that overlapped with the
   attention studies have shown sensitivity of the listener to        spoken target word (e.g. beaker) in either a visual dimension
   phonological, visual, and semantic similarity when processing      (e.g. bobbin), a semantic dimension (e.g. fork) or shared
   a word. In a computational model of language mediated              their phonological onset (e.g. beaver). They observed that
   visual attention, that models spoken word processing as the        participants looked first towards items that shared their
   parallel integration of information from phonological,
   semantic and visual processing streams, we simulate such
                                                                      phonological onset, then once the speech signal
   effects of competition within modalities. Our simulations          disambiguated between phonological representations of the
   raised untested predictions about stronger and earlier effects     target and onset competitor, participants looked more
   of visual and semantic similarity compared to phonological         towards items that overlapped in either a visual or semantic
   similarity around the rhyme of the word. Two visual world          dimension.
   studies confirmed these predictions. The model and                    Such eye gaze data has been used to index the timing of
   behavioral studies suggest that, during spoken word                activation of specific forms of information by the speech
   comprehension, multimodal information can be recruited
   rapidly to constrain lexical selection to the extent that          signal and further has been offered as a measure of the
   phonological rhyme information may exert little influence on       relative influence of information types during spoken word
   this process.                                                      comprehension. For example, the influence of phonological
                                                                      rhyme overlap on eye gaze in visual world studies is often
   Keywords: The Visual World Paradigm, Connectionist
   Modeling, Visual Attention, Spoken Word Comprehension.             only marginally significant, and less robust than onset
                                                                      overlap effects (Allopenna et al., 1998;McQueen & Huettig,
                          Introduction                                2012). This exposes features of the underlying mechanism
                                                                      that have been used to constrain models of speech
   Words are complex entities that link representations               processing. For example empirical evidence of rhyme
across multiple modalities (e.g. phonological, orthographic,          effects has proved influential as they are predicted by
semantic, visual …). When processing spoken words in                  continuous mapping models of spoken word recognition
natural, ‘real world’ settings the cognitive system often has         (e.g. TRACE: McClelland & Elman, 1986).
access to information from many modalities each of which                 Evidence provided by these studies demonstrates that as a
may provide a reliable source of information that can be              spoken word unfolds information associated with the word
used to constrain lexical selection. Yet comparatively little         in phonological, visual and semantic dimensions is rapidly
is known about how these various sources of information               activated. Further this information can be utilized by the
interact and the temporal structure of this multimodal                cognitive system to connect the unfolding speech signal to
process.                                                              information that has been activated through other
   Language mediated visual attention requires the ability to         modalities. In the case of language mediated visual attention
map between information activated by the visual                       to map to information activated by the visual environment.
environment and information activated by spoken language.                Although it has been established that phonological rhyme
Empirical studies of this process conducted using the visual          overlap can influence gaze behavior this has only been
world paradigm, in which participants view a visual display           demonstrated under heavily constrained conditions in which
and simultaneously hear a spoken utterance while their eye            a phonological mapping provides the only connection to
gaze is recorded, have helped isolate the types of                    spoken target words. Therefore its influence under more
                                                                  1449

natural conditions, when overlapping information in other          direction of attentional focus as a consequence of the
modalities (e.g. visual or semantic) is available, is unknown.     integrated multimodal input. Each unit in the eye layer was
Within this study we examine the influence of phonological         associated with one of the four locations in the visual field.
rhyme on language mediated visual attention under                  The models ‘gaze’ was interpreted as directed towards the
conditions in which competition is provided by items that          location associated with the most activated eye layer unit.
share semantic and visual relationships with spoken target
words. We first simulate the effects of this multimodal            Representations To train and test the network an artificial
competition in a model of language mediated visual                 corpus was constructed consisting of 200 items, with each
attention in which the processing of spoken words involves         item assigned unique visual, phonological and semantic
the parallel integration of information concurrently available     representations. Within the corpora were embedded 20
in phonological, visual and semantic domains and then test         target items each of which was paired with a different
whether such a model successfully predicts the behavioral          semantic, visual and phonological rhyme competitor. The
consequences of the multimodal competition induced within          distance between targets and competitor representations was
two visual world studies. We discuss the results of these          on average half the distance of that between a target and
experiments both in respect to the mechanisms driving              unrelated item in the modality that defined the competitor
language mediated eye gaze and more broadly the possible           class (see Table 1).
implications for models of spoken word recognition.
                                                                      Table 1: Relationships defining target, competitor (Com.)
       Simulating multimodal competition in                                           and distractor (Un.) items
        language mediated visual attention                         Mod.      Item     Constraint                        Cosine
                                                                                      (Features shared with target)     Distance
Model                                                              Pho.      Com.     Final 3 of 6 phonemes             .259
Simulations were conducted using the amodal shared                           Un.      Max. 2 consecutive phonemes       .496
resource model of language mediated visual attention which         Sem.      Com.     4 of 8 semantic features          .500
has previously been shown to replicate a broad range of                      Un.      Max. 1 semantic feature           .959
word level effects reported in the visual world paradigm (         Vis.      Com.     Min. 5 of 10 visual features      .264
see Smith, Monaghan & Huettig, 2013a; Smith, Monaghan                        Un.      Features shared with p = (0.5)    .506
& Huettig, 2013b). A diagram of the model’s architecture is
displayed in Figure 1.                                             Training The model was trained on four cross modal
                                                                   mapping tasks, these were: to activate an item’s semantic
                                                                   representation when fixating on its visual representation; to
                                                                   activate an item’s semantic representation when presented
                                                                   with its phonological representation; to activate the eye unit
                                                                   associated with the location of an item indicated by the
                                                                   presence of its phonological representation (phonological
                                                                   orienting) and to activate the eye layer unit associated with
                                                                   the location an item indicated by the presence of its
                                                                   semantic representation (semantic orienting). All four tasks
                                                                   were randomly interleaved although the task of mapping
                                                                   from speech to location was four times less likely to occur
                                                                   than all other tasks. Initial connection weights were
                                                                   randomized and adjusted over the course of 850 000 training
                                                                   trials using recurrent back propagation (learning rate 0.05).
                                                                   Once trained the model performed all training tasks
                                                                   accurately for over 99% of items in the training corpus.
                 Figure 1: Network Architecture.
                                                                   Simulations
Architecture The network consists of four modality-                Simulation 1 The visual input presented to the model at
specific layers connected via a central resource. Input is         trial onset consisted of the visual representations of a rhyme
provided by visual, semantic and phonological layers. The          competitor and three unrelated distractors. 5 time steps
visual layer simulates the extraction of visual information        followed display onset to enable pre-processing of visual
from four locations in the visual field, the phonological          information before the first phoneme of the target word was
layer simulates the extraction of phonological information         presented to the phonological layer. An additional phoneme
from the speech signal over time, and the semantic layer           was provided at each subsequent time step until the entire
allows the network to associate semantic features with a           phonological representation of the target word has unfolded.
given object or spoken word. Output behavior is represented        The most active unit in the eye layer was recorded at each
by the eye layer which provides a measure of the models            time step. In total 480 trials were simulated, with all 20
                                                               1450

target – competitor pairs tested with distractors in all                Comparing semantic competitor – distractor ratios
possible locations in the visual field (n = 24).                    showed increased fixation of semantic competitors from
    Figure 2 presents the change in the proportion of fixations     time step 13 [M = -0.324, SD = 0.299, tsimulation(7) = -3.068,
directed towards each category of item (rhyme competitor            p = 0.018 ; M = -0.291, SD = 0.241, titem(19) = -5.393, p <
or average distractor) from word onset.                             0.001], semantic competitors remained fixated above
    To examine whether the model fixated rhyme competitors          distractor levels for all remaining time steps.
more than distractors we first calculated the proportion of             Finally, comparing rhyme competitor – distractor ratios
time steps in the display preview period (ts 0 - 5) in which        showed that rhyme competitors were first fixated more than
the rhyme competitor was fixated. We then calculated the            distractors in time step 17 [M = -0.376, SD = 0.366,
same measure for the unrelated distractors. As there were           tsimulation(7) = -2.904, p = 0.029; M = -0.349, SD = 0.411,
three distractors and only one competitor, distractor fixation      titem(19) = -3.796, p = 0.001], rhyme competitors continued
proportions were divided by 3. We then compared using               to be fixated more than distractors in all subsequent time
paired t-tests the mean log-transformed ratio of the                steps.
proportion of fixations toward rhyme competitors /                      We also calculated for each competitor the competitor –
proportion of fixations toward unrelated distractors in the         distractor ratio over the entire post word onset period (ts 6 –
preview period to the same ratio calculated for each time           29) and compared this between competitor types using
step post word onset (ts 6-29). Results of the analysis             paired t-tests. We observed a greater visual competitor
showed that the model first displayed a bias toward fixating        effect than either semantic or rhyme effects
rhyme competitors over distractors from time step 13 [M = -         [visual/semantic: M = 0.121 SD = 0.164, tsimulation(7) = -
0.247, SD = 0.207, tsimulation(7) = -3.374, p = 0.012; M = -        2.098, p = 0.074; M = 0.151, SD = 0.204, titem(19) = 3.305,
0.258, SD = 0.352, titem(19) = -3.267, p = 0.004]. This bias        p = 0.004; visual/rhyme: M = -0.500, SD = 0.231,
continued for all subsequent time steps.                            tsimulation(7) = 6.134, p < 0.001; M = 0.536, SD = 0.305,
                                                                    titem(19) = 7.860, p < 0.001], while the semantic competitor
                                                                    effect was greater than the rhyme effect [semantic/rhyme:
                                                                    M = 0.379, SD = 0.272, tsimulation(7) = 3.938, p = 0.006; M =
                                                                    0.386, SD = 0.253, titem(19) = 6.822, p < 0.001].
     Figure 2: Change in fixation proportions from trial onset
                 for simulations of Experiment 1.
Simulation 2 An identical procedure was followed as
described for simulations 1 yet scenes now contained a
                                                                         Figure 3: Change in fixation proportions from trial onset
rhyme competitor, a visual competitor, a semantic
                                                                                     for simulations of Experiment 2.
competitor and an unrelated distractor. Figure 3 displays the
change in the proportion of fixations to each category of           Discussion
item from word onset.
    For each competitor type separate analysis was conducted        Simulations predict that the effect of visual and semantic
following the same procedure used in simulation 1.                  overlap will be greater than that of rhyme overlap and that
Comparing visual competitor – distractor ratios showed that         visual effects will precede semantic effects, with both
the model first fixated visual competitors more than                preceding rhyme effects. Finally, the model predicts that
distractors in time step 12 [M = -0.262, SD = 0.276,                added competition from semantic and visual competitors
tsimulation(7) = -2.682, p = 0.031; M = -0.275, SD = 0.281,         will lead to a delay in the emergence of rhyme effects.
titem(19) = -4.375, p < 0.001], the model continued to fixate
visual competitors more than distractors for all subsequent
time steps.
                                                                1451

    Experiment 1: Effects of rhyme overlap in                        whose name corresponded to the spoken target word was
                   target absent scenes                              presented along with the images of three unrelated distractor
                                                                     objects. In target absent displays images of four unrelated
An initial visual world experiment was conducted to                  distractors were presented.
establish that the materials constructed captured the effect of
phonological rhyme overlap on language mediated visual               Procedure A tower mounted eye tracker was used to record
attention.                                                           participant’s eye movements as they viewed displays on a
                                                                     computer monitor and listened to sentences through
Participants 40 participants aged between 18 and 30 (mean            headphones. Participants were asked to look at the display
= 21.6) participated in this experiment. All were native             while listening to the spoken sentences. Within the
speakers of Dutch.                                                   experiment the 15 experimental trials, 15 target absent trials
                                                                     and 15 target present trials were randomly interleaved. Each
Materials 15 experimental trials were constructed each               trial proceeded as follows, replicating the procedure in
consisting of a visual display and spoken Dutch sentence.            Huettig & McQueen, 2007). First a fixation cross appeared
Each sentence consisted of a target word embedded in a               in the center of the screen for 500 ms, this was followed by
neutral carrier sentence in which the target word was not            a blank screen for 600 ms. Then a scene consisting of four
predictable (e.g. Dutch: “Zij begrepen niet waarom de roos           images was presented, at which point a spoken sentence
verwelkt was.” English translation: “They could not                  began to unfold. The location of each item was randomized
understand why the rose was withered.”).                             across items and participants.
                                                                     Results Figure 5 presents a time course graph recording the
                                                                     difference from target word onset, in the proportion of
                                                                     fixations directed towards phonological rhyme competitors
                                                                     and unrelated distractors for the first 1600ms post target
                                                                     word onset. Average distractor fixation proportions were
                                                                     calculated by dividing the total proportion of fixations
                                                                     towards unrelated distractors by three.
 Figure 4: Example of a visual display from an experimental
trial in Experiment. In this trial the target word was cent, the
  rhyme competitor tent and the three unrelated distractors
            pop (doll), ster (star) and fles (bottle).
    Experimental displays contained a phonological rhyme
competitor and three unrelated distractors. Phonological
rhyme competitors differed only in their initial phoneme
from the target words phonological representation. The
following relationships were controlled between the target
word, and competitors and distractors: word frequency,
number of syllables, number of letters, number of shared                  Figure 5: Change in the proportion of fixations directed
phonemes, visual similarity, semantic similarity. Separate            towards rhyme competitors and average unrelated distractor
semantic similarity and visual similarity norming studies             from word onset displayed by participants in Experiment 1.
were conducted to gain measures of the similarity between
each of the images presented in the visual display and the              For analysis we divided the first 1600 ms period post
paired target word. All images used within the study were            word onset into four 400 ms bins and compared behavior in
black and white line drawings. To ensure that the names              each of these periods to behavior in the 400 ms prior to
attributed to displayed images were well motivated a picture         target word onset. For each bin, in each test trial we
name correspondence pre-test was conducted.                          calculated the empirical log odds of fixating each category
  In addition to the 15 experimental trials, 15 target absent        of item (competitor or distractor). To form our dependent
and 15 target present filler trials were constructed. These          variable we calculated the difference between the log-odds
also consisted of a spoken target word embedded in a                 of fixating the rhyme competitor and the log-odds of
neutral sentence paired with a display containing four black         fixating a distractor, this variable reflects the difference in
and white line drawings. In target present displays an image         fixation behavior as a consequence of phonological rhyme
                                                                 1452

overlap. This measure was then analyzed using linear mixed         between the baseline window and the 400ms directly
effects models to examine whether for each 400ms window            following word onset. Fixation of visual competitors in
post target word onset the difference between fixation of          relation to distractors did differ from baseline levels in
distractors and rhyme competitors differed from the                windows 401 – 800ms [β = 0.67; t = 2.24; p = 0.03], 801 –
difference observed in the baseline window prior to target         1200ms [β = 0.80; t = 2.68; p = 0.01] and 1201 – 1600ms [β
word onset. The model used a fixed effect of window and            = 0.58; t = 2.01; p = 0.05]. Throughout this period there was
random effects of subject and item including random                an effect of visual similarity with visual competitors fixated
intercepts and slopes for time window both by subject and          more than distractors in comparison to behavior in the
item. To derive p-values we assume t-values were drawn             baseline window. Differences between semantic competitor
from a normal distribution.                                        fixations and unrelated distractor fixations did not differ
   We observed a significant effect of rhyme overlap 801–          from baseline levels in first 800 ms post word onset. There
1200 ms post word onset [β = 0.68; t = 2.22; p = 0.03] with        was however a marginal difference in the 801-1200ms
participants fixating rhyme competitors more than                  window [β = 0.45; t = 1.79; p = 0.07], with semantic overlap
distractors in this window compared to the baseline period.        leading to increased fixation in this period compared to the
There was also a marginal increase in fixation of                  baseline window. This increase over baseline levels was
phonological rhyme competitors in the window 1201–1600             significant in the final 400ms window [1201 – 1600 ms: β =
ms post word onset in comparison to the baseline period [β         0.66; t = 2.51; p = 0.01]. There was however no evidence
= 0.05; t = 1.85; p = 0.06].                                       for an influence of phonological rhyme overlap at any point
   Experiment 1 establishes that the level of phonological         post word onset.
rhyme overlap embedded within the materials is sufficient
to induce increased fixation of rhyme competitors over
distractors replicating previous rhyme effects reported in the
literature.
    Experiment 2: Effects of Rhyme overlap in
       scenes containing Semantic and Visual
                        competitors
A second experiment examined the influence of competition
from items that overlapped in either a visual or semantic
dimension on the previously observed rhyme effect.
Participants 39 participants aged between 18 and 30 (mean
= 25.3) participated in experiment 2. All participants were
native speakers of Dutch.
Materials Experiment 2 used the same materials as used in              Figure 6: Change in the proportion of fixations directed
experiment 1 other than in each experimental display one             towards rhyme competitors, semantic competitors, visual
unrelated distractor was replaced by a visual competitor,              competitors and unrelated distractors from word onset
while a second was replaced by a semantic competitor.                        displayed by participants in Experiment 2.
   To ensure that visual and semantic competitors shared
greater visual and semantic similarity respectively with their        When presented with scenes containing a visual
paired target word, visual and semantic similarity norming         competitor, a semantic competitor, a rhyme competitor, and
studied were conducted on all experimental scenes.                 an unrelated distractor participants displayed a bias towards
Additional controls ensured that competitor sets only              fixating visual competitors from 401 – 800ms post word
differed from distractors in their relationship to the target      onset. Participants also displayed at later time points a bias
word in the dimension intended.                                    toward fixating semantic competitors from 801 – 1200 ms.
                                                                   However, in contrast to the results of experiment 1, no
Procedure The procedure applied in experiment 1 was                evidence was found for an influence of phonological rhyme
replicated in experiment 2.                                        overlap on fixation behavior.
Results Figure 6 displays the difference in the proportion of                          General Discussion
fixations from display onset directed toward each category
of item displayed.                                                    Our two visual world studies demonstrate that visual and
   We applied the same method of analysis to the result of         semantic relationships exert a greater influence on language
experiment 2 as used in experiment 1. The difference               mediated visual attention than phonological rhyme. Further
between the log-odds of fixating a visual competitor and           they show that the presence of visual and semantic overlap
those of fixating an unrelated distractor did not differ           can eliminate the influence of phonological rhyme on such
                                                               1453

behavior. For such effects to be observed visual and                  Our results provide further evidence for a rapid
semantic information relating to the unfolding spoken target        recruitment of multimodal information to constrain lexical
word must have been activated and available to map onto             processing. Based on our findings we propose that spoken
pre-activated information, before phonological rhyme                word comprehension in natural settings, in which semantic
overlap could begin to exert an influence on eye gaze, which        and visual information is likely to be pre-activated, semantic
from experiment 1 we know that it can. Our results therefore        and visual information is recruited rapidly by the cognitive
provide further evidence that visual and semantic                   system to the extent that later phonological information
information can be activated rapidly when processing                often exerts little or no influence on this process.
spoken words and that this information can be used to                 Although models of spoken word recognition that focus
constrain selection of items in the visual environment.             purely on phonological information processing (e.g.
   Our simulations predicted a greater influence of visual          TRACE: McClelland & Elman, 1986; Shortlist B: Norris &
and semantic overlap on visual attention in comparison to           McQueen, 2008) provide an important contribution to our
phonological rhyme overlap. In the model the rhyme                  understanding of the manner in which information carried in
competitor effect is delayed when visual and semantic               the acoustic signal is used to constrain lexical processing,
competitors are also present in the scene. This is driven by        our results indicate that as models of day to day spoken
the model’s gaze being directed towards only the most               language processing, such models provide a narrow view of
salient item. In scenes in which rhyme provides the only            the cognitive processes involved, describing the contribution
connection to the target, rhyme competitors are likely to be        of only one component of a complex multimodal system.
the most salient item and therefore attract attention.              Our data suggests that under conditions in which
However, overlapping visual and semantic features of the            information from other modalities is available to constrain
corresponding competitors are more salient than features of         lexical access the role of phonological processing post word
the overlapping phonological rhyme. Therefore, when such            uniqueness point is often marginal or inconsequential.
items are present in the scene rhyme competitors are less           Spoken word recognition models must therefore be
likely to be the most salient item and therefore less likely to     multimodal to offer a comprehensive description of day to
be fixated.                                                         day spoken language processing.
    What drives the visual and semantic competitor
advantage within the model is the contrast in the temporal                                    References
structure of representations across modalities. Unlike visual       Allopenna, P. D., Magnuson, J. S., and Tanenhaus, M. K.
and semantic representations, phonological representations            (1998). Tracking the time course of spoken word
possess a temporal component. In the model initial                    recognition using eye movements: evidence for
phonemes present a good predictor of the intended target              continuous mapping models. Journal of Memory and
and are therefore more influential than phonemes in the               Lanugage, 38, 419–439.
rhyme, that become available after the system has sufficient        Huettig, F., and McQueen, J. M. (2007). The tug of war
information to identify the target item. The current study            between phonological, semantic, and shape information in
indicates that such a mechanism leads to a greater saliency           language-mediated visual search. Journal of Memory and
of overlapping visual or semantic information than                    Language. 54, 460–482.
phonological rhyme, to the extent that phonological rhyme           McClelland, J. L., & Elman, J. L. (1986). The TRACE
information did not have an observable behavioral influence           model of speech perception. Cognitive psychology, 18(1),
on fixation behavior when in competition with visually or             1-86.
semantically overlapping items.                                     McQueen, J. M., & Huettig, F. (2012). Changing only the
   We know from earlier modelling (see Smith, Monaghan                probability that spoken words will be distorted changes
and Huettig, 2013a) that the addition of noise to the                 how they are recognized. The Journal of the Acoustical
phonological input in the training stage modulates the level          Society of America, 131, 509-517.
to which such initial phonemes predict the target item, and         Norris, D., & McQueen, J. M. (2008). Shortlist B: a
therefore the weight the model places on the influence of             Bayesian model of continuous speech recognition.
none overlapping phonemes on fixation of rhyme                        Psychological review, 115(2), 357.
competitors. Previous empirical work has demonstrated that          Smith, A. C., Monaghan, P., & Huettig, F. (2013a). An
the amount of noise in the speech signal can modulate the             amodal shared resource model of language-mediated
influence of phonological rhyme (McQueen & Huettig.,                  visual attention. Frontiers in Psychology, 4, 00528.
2012). It would therefore be interesting to examine whether         Smith, A.C., Monaghan, P., & Huettig, F. (2013b).
under conditions in which information across multiple                 Modelling language-vision interactions in the hub-and-
modalities can be recruited to map between items, noise is            spoke framework. In J. Mayor, & P. Gomez (Eds.),
able to dynamically adapt the influence of information                Computational Models of Cognitive Processes:
types, does visual noise lead to an increase in visual overlap        Proceedings of the 13th Neural Computation and
effects, and does auditory noise lead to an emergence of              Psychology Workshop (NCPW13). Singapore: World
phonological rhyme effects.                                           Scientific Publishing.
                                                                1454

