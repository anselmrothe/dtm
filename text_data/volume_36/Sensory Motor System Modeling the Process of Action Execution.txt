UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Sensory Motor System: Modeling the Process of Action Execution
Permalink
https://escholarship.org/uc/item/2hj8987f
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Dong, Daqi
Franklin, Stan
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                 Sensory Motor System: Modeling the Process of Action Execution
                                              Daqi Dong (DDONG@Memphis.Edu)
                                         Stan Franklin (FRANKLIN@Memphis.Edu)
                Department of Computer Science and the Institute for Intelligent Systems, University of Memphis,
                                                       Memphis TN 38152, USA
                              Abstract                                executable—in other words, “what to do” and “how to do
                                                                      it”. They proposed two cortical systems, the ventral and
   This paper presents a cognitive model—the Sensory Motor
   System (SMS)—for an action execution process, as a new             dorsal streams, providing “vision for perception” and
   module of the LIDA systems-level cognitive model. Action           “vision for action” respectively. Regarding the roles of the
   execution refers to a situation in which a software agent or       two streams in the guidance of action, the perceptual
   robot executes a selected goal-directed action in the real         mechanism in the ventral stream identifies a goal object, and
   world so as to output pertinent movement. Action execution         helps to select an appropriate course of action, while the
   requires transforming a selected goal-directed action into         dorsal stream “is critical for the detailed specification and
   lower-level executable actions, and executing them. A
   sensorimotor system derived from the subsumption
                                                                      online control of the constituent movements that form the
   architecture has been implemented into the SMS; and several        action” (Milner & Goodale, 2008, p. 775).
   cognitive neuroscience hypotheses have been incorporated as           Following the hypothesis of the two visual systems, the
   well, including the two visual systems and others. A               dual aspects of action are represented in the LIDA Model as
   computational SMS has been created inside a LIDA-based             the distinct processes of action selection and action
   software agent in Webots to model the execution of a grip          execution. Action selection has been described in previous
   action. The grip’s design is inspired by the arm controller of     work (Franklin, Madl, D’Mello, & Snaider, 2013); here we
   the robot Herbert and the current study of human’s action.
   Simulated results are compared to human performance.               specify the action execution in the form of the Sensory
                                                                      Motor System (SMS) to extend LIDA. The SMS responds
   Keywords: Sensory Motor System (SMS); action execution;            by transforming a desired understandable action, a selected
   LIDA model; subsumption architecture; two visual systems;          behavior in LIDA, into an executable low-level action
   grip action; robot Herbert; Webots; cognitive modeling.
                                                                      sequence, a sequence of motor commands, and executing
                                                                      them.
                        1. Introduction                                  The next section describes the LIDA Model and its
Action presents two aspects. On the one hand, the agent               relationship to the SMS. Section 3 contains an overview of
(Franklin & Graesser, 1997) selects the action motivated              the subsumption architecture (Brooks, 1986, 1991), which is
from inside as a result of mental processes. Thus, the agent          used as the SMS’s prototype; and the SMS’s concept is
understands what it will do before the execution begins.              described in Section 4 in detail. Section 5 introduces the
However, this understanding of the action is not executable           simulation of a specific action execution process, gripping.
in the real world, because the needed low-level                       One aspect of human grip performance, the grip aperture,
environmental information is not yet involved. On the other           has been compared to the simulated results.
hand, the action’s execution may not be understandable to                We are currently comparing SMS to other models of the
the agent, because the environmental elements involved are            action execution process. Also, besides the grip aperture, we
low-level raw data without explicit meaning, while that               plan to simulate other aspects of human grip performance in
which is understandable must have some form of meaning                future, such as the grip force, velocity, etc.
for the agent. As an example, the agent does not directly
understand the raw stimulus data retrieved by its sensors                                2. The LIDA Model
from the environment; rather, the data must be transformed
                                                                      The LIDA model is a systems-level cognitive model
into high-level meaning by a perception process; that is, the
                                                                      (Franklin et al., 2013). It implements and fleshes out a
transformation produces an understandable representation of
                                                                      number of psychological and neuropsychological theories,
the sensed data. Action execution performs a transformation
                                                                      but is primarily based on Global Workspace Theory (Baars,
similar to that of perception, but in reverse: converts an
                                                                      1988, 2002). The model is grounded in the LIDA cognitive
understandable action into low-level movements.
                                                                      cycle. The simulated human mind can be viewed as
   Milner & Goodale have proposed a hypothesis in their
                                                                      functioning via a continual sequence of these cycles. Each
work on the two visual systems1 (1992; 2008), which
                                                                      cognitive cycle consists of three phases: 1) The LIDA agent
supports a model for how a human maintains and integrates
                                                                      first senses the environment, recognizes objects, and builds
these two facets of action: the understandable and the
                                                                      its understanding of the current situation; 2) By a
                                                                      competitive process, as specified by Global Workspace
   1
     In the LIDA Model, the concept of ventral and dorsal streams     Theory (Baars, 1988), it then decides what portion of the
for the transmission of visual information has been extended to       represented situation should be attended to and broadcasted
multimodal transmission.                                              to the rest of the system; 3) Finally, the broadcasted portion
                                                                  2145

of the situation supplies information allowing the agent to              level tasks; they play a role in connecting an understandable
choose an appropriate action to execute, and modulates                   action to executable motor commands.
learning.                                                                   Furthermore, the subsumption architecture typically has
   The Sensory Motor System (SMS) is proposed to                         no central control, and the environment is used as the
complete a model for the process of action execution in                  communication medium because “[the] world is its own best
LIDA. Two LIDA modules, Action Selection and Sensory                     model” (Brooks, 1990, p. 3). This fact is consistent with our
Memory, provide relevant information—a selected behavior                 design requirement, as Jeannerod proposed above, for the
and the sensory data through a dorsal stream channel 2—as                absence of an understandable action’s “explicit character” in
inputs to the SMS separately. The selected behavior is a                 the action execution process. This explains why action
data structure resulting from the preceding action selection             execution remains outside the awareness of the agent,
in the LIDA Model. It is comprised of three components: a                although it could become aware of the execution indirectly;
context, an action3, and a result. With some reliability, the            we will introduce an example regarding this indirect
result is expected to occur when the action is taken in its              awareness later in Section 5.4.
context. The SMS sends out motor commands as its output
to the environment.                                                              4. The Sensory Motor System (SMS)
           3. The Subsumption Architecture                               4.1 The Motor Plan and Online Control
The subsumption architecture is a parallel and distributed               The output of the SMS, a sequence of motor commands, is
computation formalism for controlling a robot using a type               sent out in a certain order; however, this “ordering” effect is
of reactive structure connecting sensors to actuators                    not a plan working inside the SMS to determine when each
(Brooks, 1986, 1991). Its capabilities match many required               motor command will be sent out. Since the action execution
features of action execution as we plan to model it. First, it           process is running in a real world with unlimited data
fulfills the requirements for modeling online control of                 available, much of this heavily affects the order of the motor
action execution because the sensor is directly linked to the            commands in real time. It is hard to anticipate such
motor that drives the actuators.                                         environmental situations fully enough to prepare a specific
   Second, in the subsumption architecture, specific                     sequence of motor commands before the execution begins.
behaviors are merged into a comprehensive classification,                   Citing the work of Herbert Simon (1969), Rodney Brooks
organized in multiple layers; it fulfills the need for                   built upon the concept that complex behavior need not
transforming an understandable action into executable                    necessarily be a product of an extremely complex control
motor commands. Marc Jeannerod built upon the concept                    system; rather, it may simply be the reflection of a complex
that covert action representation is followed by overt real              environment (Brooks, 1986). Therefore, a reactive structure
executed action. In detail, “the conceptual content, when it             is introduced to model the source of ordered motor
exists (i.e. when an explicit desire to perform the action is            commands (Figure 4-1). Inside the SMS, first a set of motor
formed), is present first. Then, at the time of execution, a             commands are built in; each of them is represented by a ©,
different mechanism comes into play where the                            which is independent of any timestamp. Next is a set of
representation loses its explicit character and runs                     triggers, represented by Tx; a trigger activates a specific
automatically to reach the desired goal” (2006). We equate               command in order to send it out as a part of the SMS output
the concepts used in the SMS with Jeannerod’s, although                  when the input sensory data matches one or more of the
our terminologies differ.4                                               trigger’s conditions. The subscript x stands for the number
   The subsumption architecture supports the decomposition               of conditions the trigger contains. Third, before sending out
of the desired goal into separate sub-goals to be                        the commands, a choice function chooses a command from
accomplished with low-level tasks, so as to run                          possibly multiple candidates as the final output at each
automatically to reach the desired goal without “its explicit            moment. The set of motor commands, the triggers, and the
character”. “It’s a method of decomposing a robot’s control              choice function are referred to as a Motor Plan (MP), which
architecture into a set of task-achieving behaviors or                   specifies what to do in a particular situation, independently
competences” (Dawson, n.d.). Competences refer to low-                   of time.
                                                                            An environment module located outside the SMS is
   2
     In LIDA, a dorsal stream channel directly passes sensory data
                                                                         shown in Figure 4-1 as well; it provides environmental data
from the sensory memory to the action execution process.                 to the SMS through the dorsal stream. These sensory data
   3
     In this context, this term refers to a component of a behavior.     are classified based on different modalities, such as visual,
This differs from the general usage, such as in the phrase “action       tactile, etc., and sent to the triggers. The output of the SMS,
execution”. In this paper, we use “action” in the general sense,         a sequence of motor commands, executes using the agent’s
while “action of a behavior” refers to a particular component of         actuators, and thereby acts on the environment. These
that behavior.                                                           processes occur cyclically between the environment module
   4
     ‘An explicit desire to perform the action’ refers to a selected     and the SMS, which models the hypothesis regarding one of
behavior; ‘a different mechanism’ is our SMS; and ‘the                   the dorsal stream’s roles, online control.
representation loses its explicit character’ indicates that the
action’s execution may not be understandable to the agent.
                                                                     2146

                                   Environment                                                                                 Environment
                                   Online control                                                                              Online control
                  SMS                                                                                       SMS
                                                                                                                        Motor Plan Template (MPT)  Motor Plan (MP)
                                           Motor Plan (MP)
                                                                                                                                                                                     Motor
                                                                                                                                           ©
                                                                                                              Visual      T1                                                       commands
                              T1             ©                                              Sensory Data                                        ©                  choice      ©    ©   …     ©
  Sensory Data      Visual                                                                                               …
                                                                            Motor            through the          …                        …           …
   through the                                      ©
                              T2             ©                            commands          dorsal stream
  dorsal stream                                                                                                                                                Specification
                    Tactile                                                                                                                       Update
                                                    ©        choice   ©    ©   …     ©                                             …                       S
                              …              ©
                        …                                …                                   A selected       Context
                                                                                                                                   …
                                                    ©
                                                                                              behavior
                              Tx              …                                                                   …        MPT selection
                                                                                                                                       …
                                                                                                                               …           MPTs
  Figure 4-1: SMS with a MP and the online control process                                  Figure 4-2: All of SMS’s components. See text for details.
  As shown in Figure 4-1, the SMS resembles a wrapper for                                  The data sensed through the dorsal stream provides
the MP, supporting pre-processed sensory data, and passing                               environmental features’ true value, such as a numeric value
the MP’s output to the agent’s actuators.                                                of positive five as an object’s width, while the context of a
                                                                                         selected behavior supports the semantic values “large” or
4.2 Motor Commands                                                                       “small” for the object’s size. Usually, the command values
A motor command (MC) is applied to an actuator of an                                     specified in the motor commands are only relying on the
agent. Since they are the output of the SMS, their general                               sensory data, although the context affects the command
format has been defined. Every MC has two components: a                                  values in a few conditions (Milner & Goodale, 2008).
motor name, and a command value. The motor name                                          Accordingly, to implement the relationship of the effects of
indicates to which motor of an actuator the MC specifically                              sensory data and the context, a suppress operation is
controls, while the command value of a MC encodes the                                    represented by an encircled uppercase S in Figure 4-2.
extent of the command applied to the motor.                                                There are some types of MCs whose command values are
                                                                                         conceptually specified in the process of online control but
4.3 Specification: From a Motor Plan Template to a                                       not in the specification process (Grafton, 2010). To model
Motor Plan                                                                               this situation in the SMS, the pertinent command values are
                                                                                         set with a default value in the specification process first, and
A set of motor commands (MCs) is prepared inside a Motor                                 are then updated—really specified—in the online control by
Plan (MP) and bound with fixed command values. In order                                  an update process; it is represented in Figure 4-2 as well.
to specify a MC’s command value before the execution
begins—thus modeling one of the dorsal stream’s                                          4.4 MPT Selection
hypothesized roles, specification—a Motor Plan Template
(MPT) is proposed and a specification process is created in                              A MPT awaits initiation by an incoming selected behavior
the SMS as depicted in Figure 4-2.                                                       before being specified as a concrete MP. From a general
  A MPT is an abstract motor plan whose MCs are not yet                                  engineering viewpoint, a special process called MPT
bound with specific values. After a specification process,                               selection has been proposed. MPT selection chooses one
the motor commands inside the MPT are bound with                                         MPT from others associated with the selected behavior.
specific command values, instantiating the MPT into a
concrete MP. MPTs and MPs have very similar structures.                                             5. Modeling the Execution of a Grip
Their major differences are 1) an MPT is persistently stored                             Different actions execute variously, due to vastly different
in a long-term memory, while an MP is short-term, and                                    actuators, goals, or contexts. In other words, we need a
created anew each time it is used; and 2) most of an MP’s                                Sensory Motor System (SMS) that allows the modeling of
command values have been specified, while those of an                                    the action’s distinctive characteristics in the execution
MPT have not.                                                                            process.
  Both sensory data through the dorsal stream and the                                       We have implemented a computational SMS to model the
selected behavior determine the specification process. As                                execution of a grip action inside a LIDA-based software
shown in the Figure 4-2, two cylinders lie under the set of                              agent. Our software robot and the experimental environment
motor commands (©s); they receive the sensed data and the                                are introduced in Section 5.1. In the remaining sections, we
context of a selected behavior separately, and provide                                   introduce the implementations of the grip SMS’s data
specific command values to motor commands mainly                                         structures (MPT and MP) and processes (Online control,
through a specification process—the update process is                                    Specification, and MPT selection). The implementations
another option described later. Each of these cylinders                                  follow the design principle of the Herbert (Connell, 1989a)
represents a set of associations; every association transforms                           arm controller, and embody certain hypotheses and
relevant environmental features into a command value.                                    observations regarding human grip; related computational
                                                                                         experiments are described as well.
                                                                                     2147

5.1 The youBot, the LIDA Framework, and Webots
                                                                                                       a                            a
The youBot is a software robot. Its actuators are a mobile                                                     Target
                                                                                                               Object
base, an arm, and two grippers. We chose this robot on the                      Target
                                                                                Object
basis of its similarity to Herbert, whose arm controller                                                                     e
                                                                                                  d              f
serves as the prototype of the computational SMS for the                          e
                                                                                                                                 c
                                                                                                                           d
execution of a grip action. As shown in Figure 5.1 (a), the                                     c
youBot arm comprises multiple segments linearly connected                                 (a)          b               (b)          b
by joints; the end segment plays the role of a hand, and two                Figure 5-2: The trajectories produced by the simulated
grippers are attached to it as fingers. Following the
                                                                         Herbert arm controller in different domains.
configuration of sensors in Herbert, we have extended the
youBot sensors by additionally simulating two infra-red                     Two of Herbert’s grip experiments have been duplicated.
(IR) beams sensing the area in front of the hand, one IR                 Figure 5-2 (a) represents a grip retrieving an object on the
beam between the grippers as their closing trigger, and                  ground surface. The lines show the path followed by the tips
touch sensors on the grippers (Figure 5.1 (b)).                          of the grippers. The grip starts from point a, going through
   The LIDA Framework is an underlying computational                     the rest of the points exploring for the target object, and
software framework. We use it to create a simulated human                finally carrying the object back. In Figure 5-2 (b), the same
mind as the controller of our software robot, youBot. “[The              controller retrieves the object from a pedestal. These
LIDA Framework] allows the creation of new intelligent                   simulations successfully replicate the execution of a grip
software agents and experiments based [on] the LIDA                      action driven by the simulated Herbert arm controller,
model. Its design and implementation aim to simplify this                lending support to the idea of utilizing the subsumption
process and to permit the user to concentrate [on] the                   architecture as a prototype for an SMS model of the action
specifics of the application” (Snaider, McCall, & Franklin,              execution process.
2011). The computational SMS is embedded into the
Framework as a submodule for the model of a grip.                        5.3 Biologically Inspired Modification
   Webots is a mobile robot simulation software package. It              The computational SMS implemented in Section 5.2, a
offers an environment for rapid prototyping a 3D virtual                 simulated Herbert arm controller, is modified in order to
world, an array of ready-made sensors and actuators, and                 implement the specification process and a grip Motor Plan
programmable controllers controlling robots living in the                Template (MPT) in the SMS, as designed in Section 4.3.
virtual world (www.cyberbotics.com). We use Webots as an                 Here, two sets of associations are created. In each of them, a
experimental environment in which to manipulate the                      single type of association is implemented, transforming the
youBot, controlled by the LIDA Framework, in order to run                object’s width into a value for a particular motor command
a computational SMS for gripping.                                        known as the grip aperture of the grippers.
                                                                            As represented in Figure 5-3, the simulated grip aperture
5.2 The Simulation of Herbert’s Arm Controller                           is sampled at unit intervals in Webots virtual time during a
Herbert’s arm controller drives the robot to pick up a soda              grip execution that is as same to the execution described by
can, and bring it back to a home location (Connell, 1989a).              Figure 5-2 (a); these simulated grip apertures are analyzed
   We simulated Herbert’s arm controller5 in a newly created             and compared in detail below with hypotheses and
SMS embedded in a LIDA-based software agent in Webots                    observations of human gripping.
to execute the grip. This simulation implements the online                  First, the grip action is executed using the unmodified arm
control process and a Motor Plan (MP) for gripping in the                controller as an experimental control. As shown in Figure 5-
SMS, as designed in Section 4.1.                                         3 (a), whatever its starting value, the grip aperture almost
                                                                         always reaches 0.0656m (the maximum grip aperture, or
                                                                         MGA) before the grip closes around the target object. The
                                                                         grippers squeeze the target object, and thus the resulting
                                                                         grip aperture is smaller than the original target object width.
                                                                            Second, an association (the upper cylinder in Figure 4-2)
                                                                         has been implemented by connecting the object’s width, as
                                              (b)
                                                                         sensed through the dorsal stream, to the value of the grip
                                                                         aperture. As shown in Figure 5-3 (b), the grip aperture
                 (a)
                                                                         reaches the specified value of 0.03m before the value falls
  Figure 5-1: (a) A snapshot of the youBot’s arm, and (b) the            as the grippers close. Compared to the maximum grip
  touch sensors on the tip of grippers (bottom view).                    aperture (MGA), the value specified here is much closer to
                                                                         the target object width. This simulated calibration is
   5
     In comparison with the original design (Connell, 1989b), the        qualitatively the same as saying that “the dorsal stream
cradle level, the back module, and the edge module were removed          plays a central role in the programming of actions (i.e. the
in the simulation because either their function is substituted for by    pre-specification of movement parameters)” (Milner &
the Webots simulated environment, or they are irrelevant to the
                                                                         Goodale, 2008, p. 776), because currently it is the sensory
hand and arm actuators.
                                                                     2148

data through the dorsal stream which affects the grip                                The specified value in the simulation is larger than the
aperture’s value during the specification process.                                object width: 0.03m > 0.025m, since experimentally, “the
                                                                                  [human] finger grip opens more than required by the size of
        Grip aperture (m)                                                         the object” (Jeannerod, 1981, 2006). The first MGA peak is
                                                                                  modeled by setting a fixed MGA value to the grip aperture
                     Maximum grip aperture                                        for a short while when the execution starts, in keeping with
                                                                                  the observed human behavior that people open their fingers
                                                                                  maximum when starting a grip (Farnè, Pavani, Meneghello,
                                                                                  & Làdavas, 2000; Jeannerod, 2006). The second MGA peak
                                                                                  occurs because the grippers touch the surface; this behavior
                                                                                  both tracks the object’s width value and adapts to an
                                                                                  unpredicted collision.
                        Target object                                                Third, Instead of the data being sensed through the dorsal
                            width                                                 stream, the selected behavior’s context may affects the
                                                          Time (virtual unit)
                                                                                  relevant command values in several conditions (Milner &
                                        (a)
       Grip aperture (m)
                                                                                  Goodale, 2008). We simulated two of these conditions: 1)
                                                                                  Deleting the association that connects the object’s width
                    Maximum grip
                                                                                  through the dorsal stream to the grip aperture, in effect
                    aperture                                                      rendering the skill unfamiliar to the agent, or 2) Terminating
                                                                                  the relevant data received from the dorsal stream, so as to
                                                                                  simulate a delay in the dorsal stream.
                                                                                     Additionally, another association (the bottom cylinder in
                                            Specified value                       Figure 4-2) has been implemented by connecting the object
                                                                                  width represented in the context component of a selected
                                                                                  behavior to the grip aperture value. Since the object width
                      Target object                                               represented in a behavior’s context is a semantic value, such
                          width
                                                                                  as “large” or “small,” which are not precise, its value is
                                      (b)               Time (virtual unit)       designed to be distributed in a range, so that the represented
       Grip aperture (m)                                                          object width approximates its true value. As shown in
                                                                                  Figure 5-3 (c), five executions of the same grip produced a
                                                                                  range of context-specified values rather than a precise value.
                                                                                  We argue that these imprecise movements result from an
                                                                                  association connecting the selected behavior’s context to a
                   Specified values
                      (behavior’s                                                 command value. This interpretation of these imprecise
                        context)             Specified value                      results agrees with the conclusion we reached above that the
                                              (sensory data)
                                                                                  dorsal stream plays a central role in specification process.
                                                                                  Additional evidence is found in patients suffering from
                                                                                  bilateral optic ataxia caused by damage to the dorsal
                                                                                  stream—these patients show deficits in calibrating their grip
                                                                                  aperture (Jakobson, Archibald, Carey, & Goodale, 1991;
                                      (c)               Time (virtual unit)
       Grip aperture (m)
                                                                                  Jeannerod, Decety, & Michel, 1994; Milner & Goodale,
                                                                                  2008).
                                                                                     Fourth, an update process is implemented to specify the
                                                                                  grip aperture during the execution. As shown in Figure 5-3
                                                                                  (d), the grip aperture value comes closer to the object width
                                                                                  than the specified value mentioned previously in Figure 5-3
                                                                                  (b) and (c); it follows that the sensory data provided through
                                            Specified value                       the update process are more precise than the context of the
                                                                                  specification process, because the situation becomes clearer
                                                                                  to the agent as it executes the action.
                      Target object
                          width
                                                                                  5.4 Linking the Modified Simulation to LIDA
                                      (d)               Time (virtual unit)       The grip Motor Plan Template implemented in Section 5.3
  Figure 5-3: The simulated grip aperture sampled in                              is mapped one-to-one onto the action component of a
Webots virtual time during certain grip executions.                               selected grip behavior. This is a simple implementation of
                                                                                  MPT selection following the SMS concept introduced in
                                                                                  Section 4.4.
                                                                              2149

  As discussed in Section 2 and shown in Figure 4-2, both                 Dawson, M. R. W. (n.d.). Dawson's Margin Notes On
the data sensed through a dorsal stream channel and a                         "Understanding Intelligence" (Rolf Pfeifer, Christian
selected behavior corresponding to a goal-directed action                     Scheier,                    2001).                   from
are input to the SMS, and the SMS’s output is sent out to the                 http://www.bcp.psych.ualberta.ca/~mike/Pearl_Street/
LIDA Environment module. These I/Os are implemented in                        Margin/Pfeifer/chap7.html
the LIDA-based agent including the SMS.                                   Faghihi, U., McCall, R., & Franklin, S. (2012). A
  Additionally, in order to let the agent monitor the                         computational model of attentional learning in a
execution status, an expectation codelet (Faghihi, McCall, &                  cognitive agent. Biologically Inspired Cognitive
Franklin, 2012) is created when the grip behavior is                          Architectures.
selected6; this codelet—a small and special purpose                       Farnè, A., Pavani, F., Meneghello, F., & Làdavas, E. (2000).
computational process—contains the expected result                            Left tactile extinction following visual stimulation of a
component of the currently selected behavior. It checks                       rubber hand. Brain, 123(11), 2350-2360.
whether this result has been reached (sensed and recognized               Franklin, S., & Graesser, A. (1997). Is it an Agent, or just a
by the agent) at run time. The checking result is sent to                     Program?: A Taxonomy for Autonomous Agents
LIDA’s Global Workspace module, where it competes for                         Intelligent agents III agent theories, architectures, and
the agent’s attention (Baars, 1988). In this way, the agent’s                 languages (pp. 21-35): Springer Berlin Heidelberg.
awareness of its own action execution is indirectly achieved.             Franklin, S., Madl, T., D’Mello, S., & Snaider, J. (2013).
                                                                              LIDA: A Systems-level Architecture for Cognition,
6. Concluding Comments                                                        Emotion, and Learning. IEEE Transactions on
The Sensory Motor System (SMS) is proposed to model the                       Autonomous Mental Development.
human action execution process. It is based on the LIDA                   Goodale, M. A., & Milner, A. D. (1992). Separate visual
Model, the subsumption architecture, the two visual                           pathways for perception and action. Trends in
systems, as well certain other cognitive neuroscience                         neurosciences, 15(1), 20-25.
hypotheses. Furthermore, a computational SMS has been                     Grafton, S. T. (2010). The cognitive neuroscience of
implemented for the execution of a grip behavior, and its                     prehension: recent developments. Experimental brain
simulated results have been compared to the values of the                     research, 204(4), 475-491.
grip aperture in human gripping experiments. This                         Jakobson, L., Archibald, Y., Carey, D., & Goodale, M. A.
biologically inspired design, together with a computational                   (1991). A kinematic analysis of reaching and grasping
verification by comparing the model with human behaviors,                     movements in a patient recovering from optic ataxia.
supports that the SMS is a qualitatively reasonable cognitive                 Neuropsychologia, 29(8), 803-809.
model for the execution of a human action.                                James, T. W., Culham, J., Humphrey, G. K., Milner, A. D.,
                                                                              & Goodale, M. A. (2003). Ventral occipital lesions
                          References                                          impair object recognition but not object‐directed
                                                                              grasping: an fMRI study. Brain, 126(11), 2463-2475.
Baars, B. J. (1988). A cognitive theory of consciousness.                 Jeannerod, M. (1981). Intersegmental coordination during
     New York: Cambridge University Press.                                    reaching at natural visual objects. Attention and
Baars, B. J. (2002). The conscious access hypothesis:                         performance IX, 9, 153-168.
     origins and recent evidence. Trends in cognitive                     Jeannerod, M. (2006). Motor cognition: What actions tell
     sciences, 6(1), 47-52.                                                   the self: Oxford University Press.
Brooks, R. A. (1986). A robust layered control system for a               Jeannerod, M., Decety, J., & Michel, F. (1994). Impairment
     mobile robot. Robotics and Automation, IEEE Journal                      of grasping movements following a bilateral posterior
     of, 2(1), 14-23.                                                         parietal lesion. Neuropsychologia, 32(4), 369-380.
Brooks, R. A. (1990). Elephants don't play chess. Robotics                Milner, D., & Goodale, M. A. (2008). Two visual systems
     and autonomous systems, 6(1), 3-15.                                      re-viewed. Neuropsychologia, 46(3), 774-785.
Brooks, R. A. (1991). How to build complete creatures                     Milner, D., Perrett, D., Johnston, R., Benson, P., Jordan, T.,
     rather than isolated cognitive simulators. Architectures                 Heeley, D., . . . Terazzi, E. (1991). Perception and
     for intelligence, 225-239.                                               action in ‘visual form agnosia’. Brain, 114(1), 405-428.
Connell, J. H. (1989a). A behavior-based arm controller.                  Simon, H. A. (1969). The sciences of the artiﬁcial.
     Robotics and Automation, IEEE Transactions on, 5(6),                     Cambridge, MA.
     784-791.                                                             Snaider, J., McCall, R., & Franklin, S. (2011). The LIDA
Connell, J. H. (1989b). A colony architecture for an                          framework as a general tool for AGI Artificial General
     artificial creature: DTIC Document.                                      Intelligence (pp. 133-142): Springer Berlin Heidelberg.
                                                                          www.cyberbotics.com. Webots, a commercial mobile robot
                                                                              simulation software developed by Cyberbotics Ltd.
  6
    At the time of submission of the paper, this work is still in
process. Currently, instead of dynamically creating an expectation
codelet when a behavior is selected, the codelet is simply built into
the LIDA agent.
                                                                      2150

