UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Amortized Inference in Probabilistic Reasoning
Permalink
https://escholarship.org/uc/item/34j1h7k5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Gershman, Samuel
Goodman, Noah
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Amortized Inference in Probabilistic Reasoning
          Samuel J. Gershman1 (sjgershm@mit.edu) and Noah D. Goodman2 (ngoodman@stanford.edu)
                                            1 Department   of Brain and Cognitive Sciences, MIT
                                              2 Department   of Psychology, Stanford University
                               Abstract                                   similar or related queries. For example, as you view an im-
   Recent studies of probabilistic reasoning have postulated
                                                                          age, your head and eyes are continuously moving, generating
   general-purpose inference algorithms that can be used to an-           an infinitude of slightly different queries. For these queries, it
   swer arbitrary queries. These algorithms are memoryless, in            may be inaccurate to reuse a stored inference without modifi-
   the sense that each query is processed independently, without          cation. This raises the problem of amortized inference: how
   reuse of earlier computation. We argue that the brain oper-
   ates in the setting of amortized inference, where numerous             to flexibly reuse inferences so as to answer a variety of re-
   related queries must be answered (e.g., recognizing a scene            lated queries. Recently, Stuhlmüller et al. (2013) addressed
   from multiple viewpoints); in this setting, memoryless algo-           this problem by using stored samples to estimate local condi-
   rithms can be computationally wasteful. We propose a simple
   form of flexible reuse, according to which shared inferences           tional distributions, and then approximating answers to more
   are cached and composed together to answer new queries. We             complex queries by composing the local distributions. The
   present experimental evidence that humans exploit this form            work described in this paper seeks experimental evidence for
   of reuse: the answer to a complex query can be systematically
   predicted from a person’s response to a simpler query if the           a similar kind of flexible reuse in human reasoning.
   simpler query was presented first and entails a sub-inference             We presented subjects with a simple Bayesian network and
   (i.e., a sub-component of the more complex query). People are
   also faster at answering a complex query when it is preceded           asked them to answer a series of queries about it. One of
   by a sub-inference. Our results suggest that the astonishing ef-       these queries (the “target”) could be answered by reusing the
   ficiency of human probabilistic reasoning may be supported by          answer to another query (the “sub-query”). We hypothesized
   interactions between inference and memory.
                                                                          that the effects of reuse would be evident compared to an in-
   Keywords: induction, Bayesian inference, memory                        ference with the same structure but no re-usable sub-query.
   “Cognition is recognition.” – Hofstadter (1995)                        Further, we hypothesized that this effect would be present
                                                                          only if the target was presented after the sub-query. Accord-
                           Introduction                                   ingly, we manipulated (between subjects) whether the target
One view of probabilistic reasoning holds that our brains are             came before or after the sub-query. This design allowed us
equipped with general-purpose inference algorithms that can               to look for two key signatures of reuse: correlations between
be used to answer arbitrary queries (Griffiths et al., 2012;              related inferences (Experiment 1) and faster responses for in-
Pouget et al., 2013). An under-appreciated property of such               ferences that exploit reuse (Experiment 2).
algorithms borrowed from computer science is that they are
memoryless: each query is (at least in principle) processed
independently of others. While this property guarantees that
inferences will not interfere with one another, it can also
lead to gross computational inefficiency, since inferences are
never reused; memorylessness implies that answering the
same query twice requires the same amount of computation
as answer two unique queries.1
   Whatever inference algorithms the brain uses, they are un-
likely to be memoryless. Consider, for example, the image
in Figure 1 (Gregory, 1970). Upon viewing it for the first
time, most observers find it extremely difficult to identify
what the image depicts.2 However, once the image has been
deciphered, all subsequent views are instantly recognized.
Clearly, the visual system is not running a computationally
expensive inference algorithm upon each viewing; the infer-                           Figure 1: What does this image depict?
ence is simply reused.
   In reality, it is rare to be faced with the exact same query
multiple times. Much more pervasive is the appearance of                      Amortized inference in Bayesian networks
    1 To  be fair, inference algorithms for dynamical systems, like       In this paper, we will restrict our attention to amortized in-
Kalman filtering, involve reuse in a certain sense. However, these
algorithms are not designed to reuse inferences when applied to sev-      ference for Bayesian networks. Let p(x) denote a probability
eral independent time series (even if the time series are identical).     distribution on variables x = {x1 , . . . , xM }. A Bayesian net-
    2 Answer: a dalmatian.                                                work G is a directed acyclic graph with nodes corresponding
                                                                      517

             A!                B!                C!
         Query 1:!! ! ! = ! ! ! !(!)/!(!)!
         !
         Query 2:!! ! ! = !            ! ! ! !(!|!)!
                                    !
Figure 2: A Bayesian network in which variable A is ob-
served. Query 1 is a sub-query of Query 2. The reused con-
ditional distribution is shown in blue.
to variables and edges corresponding to probabilistic depen-
dencies. The graph expresses a factorization of p(x) into a
product of conditional distributions:
                            M                                                 Figure 3: Bayesian network presented to subjects.
                   p(x) =  ∏   p(xm |paG (xm )),               (1)
                           m=1
                                                                       where the computations for the simple query can be reused.
where paG (xm ) is the set of parents of node m in graph G. A
                                                                          We should note an important subtlety to this argument: at
query q is a tuple {Q , E , y}, where Q ⊆ {1, . . . , M} denotes
                                                                       least in principle, reuse could still occur if the complex query
a set of unobserved (latent) variables and E ⊆ {1, . . . , M} \ Q
                                                                       precedes the sub-query, since the same sub-computations
denotes a set of observed variables with values y. An infer-
                                                                       may be invoked regardless of order. However, a complex
ence algorithm is any function that takes as input q and re-
                                                                       query can be answered in a number of different ways, which
turns the conditional distribution p(xQ |xE = y). Many algo-
                                                                       may or may not invoke the same sub-computations as the
rithms are available for this task, such as belief propagation,
                                                                       sub-query. We conjecture that query order biases the com-
Markov chain Monte Carlo, and importance sampling (Koller
                                                                       plex query to be answered in different ways based on what
& Friedman, 2009).
                                                                       sub-computations are available for reuse. This conjecture is
   Almost all widely used inference algorithms are memory-
                                                                       consistent with our finding below of order effects in correla-
less: their operation does not depend on a memory trace of
                                                                       tions and prediction errors (Experiment 1), but more research
past inferences. In contrast, we will consider amortized infer-
                                                                       is needed to understand this issue completely.
ence algorithms that reuse past inferences. One simple form
of flexible reuse is caching (or, in computer science lingo,
                                                                                               Experiment 1
“memoizing”; Michie, 1968) sub-computations that are in-
voked by multiple queries. A simple example is shown in Fig-           We presented subjects with a sequence of queries about a
ure 2, where the conditional distribution computed for Query           Bayesian network representing a hierarchy of military offi-
1 can be reused to answer Query 2. We refer to Query 1 as a            cers (Figure 3). Subjects were told that the enemy was at-
“sub-query” of Query 2, and its corresponding inference as a           tempting to bribe officers, and that their job was to infer
“sub-inference.”                                                       whether a particular officer would defect based on informa-
   Memoized reuse has a number of implications for human               tion about the defection of other officers. We constructed the
reasoning, which we test in the experiments reported below.            queries such that one query (the “target”) was a sub-query
Let us imagine a simple query that is presented earlier than,          of another. Thus, we provided subjects with the opportunity
and entails sub-computations of, a more complex query. The             to reuse their sub-inference. For comparison, we had a sep-
most immediate implication of caching (tested in Experiment            arate group of subjects answer the same queries, but in this
2) is that answers to the more complex queries should be               case the sub-query was presented after the target query. We
faster compared to similar queries where reuse is unavail-             hypothesized that when the sub-query could be reused, indi-
able, since retrieval of an inference is presumably faster than        vidual responses for the sub-query could be used to predict
computing the inference from scratch. A second implication             responses to the larger query—that is, the two queries would
(tested in Experiments 1 and 2) is that variation in answers           be non-independent.
for the complex query should be systematically predictable
from the corresponding answers to the simpler query. In other          Methods
words, individual differences in the answer to a simple query          Subjects. 146 subjects (73 in each condition) were recruited
should propagate to more complex queries, under conditions             through Amazon Mechanical Turk and paid $0.50.
                                                                   518

                            A                B                C                     D                E                 F
                 S1:        1                2                3                     4                5                 6
                 S2:        1                2                6                     4                5                 3
Figure 4: Experiment 1 design. Each query (labeled A-F) is shown, along with the serial positions for each condition (S1 and
S2). Subjects in both experiments were assigned to either S1 or S2. On each trial, subjects were asked to make a guess about
whether the queried officer (indicated by a question mark) would defect or stay loyal. Observed variables are shown by colored
squares (green = loyal, red = defect).
                1                                                              subjective probabilities, we first sought to confirm that this
                                                 Figure 5: Average             mapping is well-calibrated with the true posterior probabili-
              0.75
                                                 observed probabili-           ties. Figure 5 shows the “observed” probabilities (i.e., con-
                                                 ties in Experiment
   Observed
                                                                               verted confidence ratings) plotted against the posterior prob-
               0.5                               1 plotted against the         abilities predicted by from the Bayesian network via Bayes’
                                                 true posterior prob-          rule, collapsing across conditions. While some systematic de-
              0.25                               abilities. Error bars         viations are evident, the two sets of probabilities are strongly
                                                 show standard error           correlated (r = 0.92, p < 0.01). Thus, we can reasonably
                0
                 0   0.25   0.5   0.75   1
                                                 of the mean.                  use these observed probabilities as proxies for subjects’ in-
                        Posterior
                                                                               ferences.
                                                                                  If subjects in condition S1 are reusing their inference for
Procedure. At the beginning of the task subjects were shown                    Query C to answer Query E, then we should be able to sys-
a hierarchy of military officers (Figure 3), and told that the                 tematically predict their answers to Query E from their an-
enemy was attempting to bribe the officers; the probability                    swers to Query C. We tested this hypothesis by plugging each
that an officer defects is 0.7 if his/her superior defects, and 0.3            subject’s answer to Query C into the computation of Query E
if his/her superior remains loyal. In addition, the general at                 using probability theory. In detail, take the natural (forward)
the top of the hierarchy defects with probability 0.5. On each                 decomposition of the Bayes net in Figure 3 to be
trial, subjects were presented with one of 6 queries, shown
in Figure 4, and asked to make a binary guess about whether                     P(X,Y, M, Z, L) = P(X|M)P(Y |M)P(M|L)P(Z|L)P(L), (2)
the queried officer defected or not, followed by a confidence
                                                                               where X and Y are the two leaf nodes, M and Z are the
rating using a slider bar. The set of queries were shown in
                                                                               two middle nodes, and L is the root node. Then Query C is
two orders: subjects in condition S1 saw the order A, B, C,
                                                                               P(M|X,Y ) and Query F is P(L|X,Y, Z). The two are related
D, E, F, and subjects in condition S2 saw the order A, B, F,
                                                                               by:
D, E, C. The only difference between these conditions is that
the serial positions of C and F are swapped. The main queries                        P(L|X,Y, Z) = ∑ P(L, M|X,Y, Z)
of interest were C, D and E (as we explain below); the other                                          M
queries were included to help ascertain how well calibrated                                               P(L|M, Z)P(M|X,Y )P(Z|M)
subjects’ responses were with the true posterior probabilities.                                    =∑                              ,       (3)
                                                                                                      M           P(Z|X,Y )
Results
                                                                               where the reused computation is shown in blue. We com-
Binary judgements with their confidence ratings were con-                      pared this predicted probability to the reported probability for
verted to probabilities by linearly rescaling the confidence,                  Query E. As shown in Figure 6A, the observed and predicted
such that minimum confidence is mapped to probability 0.5,                     probabilities were significantly correlated in condition S1
using the choice to determine if the probability was above or                  (r = 0.28, p < 0.05), but not in condition S2 (r = −0.11, p =
below 0.5. Because this mapping might not correspond to                        0.36). Further corroborating our hypothesis, we found that
                                                                         519

                                       S1
                        A                                                B
                                       S2                                                                         1                    Query E
                   1
   Observed (E)                                 Prediction error
                                                                   0.4                                                                 Query D
                                                                                                                 0.8
                                                                   0.3
                                                                                                   Correlation
                  0.5
                                                                   0.2                                           0.6
                                                                   0.1
                   0                                                                                             0.4
                                                                    0
                        0        0.5        1                                S1   S2
                            Predicted (E)                                                                        0.2
                        C                                                D
                   1                                                                                              0
   Observed (D)                                 Prediction error
                                                                   0.4                                             0   10     20       30        40
                                                                   0.3
                                                                                                                       Number of samples
                  0.5
                                                                   0.2
                                                                                             Figure 7: Simulation of reuse in a sample-based approximate
                                                                   0.1                       inference system. See text for details.
                   0
                                                                    0
                        0        0.5        1                                S1   S2
                            Predicted (D)
                                                                                             ment. Imagine an approximate inference system that answers
                                                                                             queries by generating samples from the desired conditional
Figure 6: Results of Experiment 1. (A) Relationship between                                  distribution. In the setting of the defection task, where all the
observed and predicted probabilities for Query E, where the                                  variables are binary, the average of these samples is a Monte
predictions are computed by plugging each subject’s answer                                   Carlo estimate of the conditional probability. Reuse in this
to Query C into Bayes’ rule. Least-squares lines are superim-                                system is implemented by caching and retrieving these Monte
posed on individual data points. (B) Average prediction error,                               Carlo estimates. Figure 7 shows the results of simulating this
defined as the absolute difference between the predicted and                                 system (with a small amount of noise corrupting the Monte
reported probabilities for Query E. Error bars show standard                                 Carlo estimates) on the same queries given to subjects, and
error of the mean. (C and D) Same format as A and B, but for                                 performing the same correlation analyses on the simulated
Query D instead of Query E.                                                                  inferences. The Y-axis shows the correlation between the pre-
                                                                                             dicted and observed inferences, demonstrating that for Query
                                                                                             E reuse induces a strong correlation, whereas for Query D
the absolute difference between the reported and predicted                                   the lack of reuse leads to a correlation of 0. Note that even
probabilities (the prediction error; Figure 6B) was signifi-                                 the very small fluctuations in Monte Carlo estimates based on
cantly higher in S2 compared to S1 [t(144) = 2.06, p < 0.05].                                dozens of samples are enough to induce a strong correlation
   As a control, we repeated the same analysis using Query                                   (though these small fluctuations could be quickly swamped
D instead of Query E. Subjects are never shown a sub-query                                   by independent sources of response noise).
of Query D, and hence we do not expect any reuse. Nonethe-                                      In summary, we found that answers to complex queries are
less, we can still plug the answer to Query C into the infer-                                predictable from answers to sub-queries, but this predictabil-
ence for Query D, since the conditional distribution on the left                             ity only occurs under specific circumstances that increase the
branch of the Bayesian network is the same in both queries                                   likelihood of reuse (i.e., when a complex query is preceded
(due to symmetries in the probabilistic model). The results                                  by a sub-query).
of this control analysis are shown in panels C and D of Fig-
ure 6. There was no correlation between the observed and                                                                Experiment 2
predicted probabilities for either condition (both p > 0.05),                                In Experiment 2, we tested the prediction that reuse should
and the prediction errors did not differ significantly (p = 0.6).                            lead to faster inferences. We used the same query orders as
Thus the order manipulation specifically affects the relation-                               in Experiment 1, but we no longer asked subjects to make
ship between Query C and Query E.                                                            a confidence rating; instead, subjects made a speeded binary
   Our data do not constrain hypotheses about particular in-                                 choice using the keyboard.
ference algorithms used for the individual queries except in
requiring them to decompose into sub-queries (a condition on                                 Methods
re-use) and to have an element of stochasticity or individual                                Subjects. 134 subjects were recruited through Amazon Me-
variation (a necessity for inducing the reported correlation).                               chanical Turk and paid $0.50. We only analyzed data from
To show that our results are indeed expected from such al-                                   subjects who chose the more likely hypothesis (defect) for
gorithms, we provide here one concrete example of how a                                      Query E, resulting in 50 subjects in condition S1 and 53 sub-
sampling algorithm (see Griffiths et al., 2012; Vul et al., in                               jects in condition S2.
press) can give rise to the correlations observed in this experi-                            Procedure. The procedure was identical to the procedure
                                                                                       520

                                                                         complex query. Experiment 2 showed that the same condi-
                     0.8
                                                                         tions lead to faster inferences for complex queries, consis-
                                                                         tent with the idea that retrieving an inference from memory is
                     0.6                                                 faster than recomputing it.
      Facilitation
                                                                            Our results place new constraints on rational process mod-
                     0.4                                                 els of cognition (see Griffiths et al., 2012, for a review). In
                                                                         particular, these models need to be augmented with storage
                                                                         and retrieval mechanisms for reusing inferences. However,
                     0.2                                                 we are still far from a detailed computational understanding
                                                                         of amortized inference in human reasoning. One open ques-
                                                                         tion is the inference algorithms people use even for isolated
                      0
                           S1                S2                          inferences in tasks like those in our experiments. Currently
                                                                         one of the most promising hypotheses is that the brain uses
                                                                         some form of sample-based approximate inference, such as
    Figure 8: Median facilitation effect in Experiment 2.
                                                                         Markov chain Monte Carlo (MCMC; Gershman et al., 2012;
                                                                         Lieder et al., 2012) or importance sampling (Shi et al., 2010).
used in Experiment 2, except that subjects were asked to                 We showed that a simple sample-based algorithm augmented
make speeded binary responses (defect/loyal) using the key-              with sample reuse can give rise to the observed correlation
board.                                                                   and RT effects. Stuhlmüller et al. (2013) proposed a more
                                                                         sophisticated framework for reusing samples within MCMC.
Results                                                                  More research will be required to directly investigate the in-
The results of Experiments 1, as well as the experimental de-            ference algorithms and methods of reuse in human reasoning.
sign, suggest that one condition (S1) provided opportunity                  A key challenge going forward will be determining the
for reuse of a sub-inference, and the other condition (S2),              flexibility of inference reuse—when can stored inferences
did not. In particular, the sub-query C was presented be-                be used compositionally to answer larger questions? It will
fore F in S1, but after F in S2. To quantify the advantage               require more complex probabilistic models than the simple
of reuse in S1, we computed a “facilitation effect,” defined as          Bayesian network we used in our experiments to investigate
log RTD − log RTF , where RTF is the response time (in mil-              this question. However, training people on complex Bayesian
liseconds) for Query E. We use the RT for Query D as a base-             networks is difficult; it is well known that people show sys-
line, since it has the same underlying structure as Query E,             tematic biases in their interpretation of probabilities (Kahne-
but lacks a sub-query among the other trials. A larger fa-               man & Tversky, 1982), and complex networks may also tax
cilitation effect means that responses are faster for the target         working memory. One alternative would be to present the net-
query relative to the baseline.                                          work in a frequency format by generating samples. Another
   To reduce sensitivity to outliers, we compared the median             alternative would be to exploit complex probabilistic mod-
(rather than the mean) facilitation effect in the two condi-             els that people have already learned, such as intuitive physics
tions, as shown in Figure 8. Consistent with our hypothe-                (Battaglia et al., 2013).
sis, the facilitation effect was larger in condition S1 com-                More complex models also raise the question of which in-
pared to S2 (z = 2.09, p < 0.05, rank sum test), indicating              ferences to store, since the memory cost of storing all infer-
a speed advantage when reuse is available. Furthermore,                  ences may be prohibitive. A number of trade-offs are in-
the median facilitation effect was significantly greater than            volved: storing more complex inferences provides greater
0 in S1 (z = 3.68, p < 0.005, signed rank test), but not in S2           savings in computation time, but incurs a larger memory cost;
(p = 0.16, signed rank test). We conclude that the availability          complex inferences should not be stored if they can be de-
of reuse facilitates the speed of inference.                             composed into simpler inferences that are already stored, and
                                                                         conversely simple inferences should be stored if they can be
                                Discussion                               composed into larger inferences; storage of frequent infer-
Most algorithms for probabilistic inference assume that                  ences should be preferred to storage of rare inferences. Opti-
queries are processed independently. Our experiments show                mally balancing these intuitive trade-offs is subtle; it may ad-
that this assumption is incorrect as a description of human              dressable via resource-rational analysis, which dictates how
reasoning: Multiple related queries are not processed inde-              the cost of computation is balanced against the accuracy of
pendently. Specifically, queries influence each other when the           inference (Howes et al., 2009; Vul et al., in press).
answer to one query supplies a memoizable sub-computation                   Memory mechanisms have figured prominently in exem-
for another query. Experiment 1 showed that the answer to                plar models of inductive reasoning (e.g., Dougherty et al.,
a complex query can be systematically predicted from a per-              1999; Estes, 1994; Heit, 1992; Heit & Hayes, 2011; Juslin
son’s response to a simpler query if the simpler query was               & Persson, 2002), which assert that inductive judgments are
presented first and entails a sub-computation of the more                formed by taking a similarity-weighted average of exemplars
                                                                   521

stored in memory. These models draw support from exper-             Griffiths, T. L., Vul, E., & Sanborn, A. N. (2012). Bridg-
iments showing correlations between measures of reasoning             ing levels of analysis for probabilistic models of cogni-
and memory (Hayes & Heit, 2013; Heit & Hayes, 2011). It               tion. Current Directions in Psychological Science, 21,
has even been suggested that exemplar models may provide              263–268.
a general method for performing probabilistic inference (Shi        Hayes, B. K., & Heit, E. (2013). How similar are recognition
et al., 2010), based on the idea that exemplars correspond to         memory and inductive reasoning? Memory & Cognition,
samples from a generative model. The framework of amor-               1–15.
tized inference makes rather different claims about the role of     Heit, E. (1992). Categorization using chains of examples.
memory in inductive reasoning: inferences (rather than stim-          Cognitive Psychology, 24, 341–380.
ulus exemplars or samples from the prior) are stored in mem-
                                                                    Heit, E., & Hayes, B. K. (2011). Predicting reasoning from
ory and reused in sophisticated ways. For example, stored in-
                                                                      memory. Journal of Experimental Psychology: General,
ferences may be composed together, along with freshly com-
                                                                      140, 76.
puted inferences, to answer a more complex query (it is also
possible to construct memory-based inference systems that           Hofstadter, D. R. (1995). Fluid Concepts and Creative Analo-
lack this form of compositionality).                                  gies: Computer Models of the Fundamental Mechanisms
   Amortized inference also suggests a number of ways in              of Thought. Basic Books.
which ideas from memory research can be applied to in-              Howes, A., Lewis, R. L., & Vera, A. (2009). Rational adap-
ductive reasoning (see Heit & Hayes, 2011, for another per-           tation under task and processing constraints: implications
spective). For example, do stored inferences interfere with           for testing theories of cognition and action. Psychological
each other proactively and retroactively? Is there a tempo-           Review, 116, 717.
ral gradient—analogous to a forgetting function—such that           Juslin, P., & Persson, M. (2002). PROBabilities from EX-
older inferences are less likely to be reused? Can we prime           emplars (PROBEX): A lazy algorithm for probabilistic in-
particular inferences using contextual reminders?                     ference from generic knowledge. Cognitive Science, 26,
   Our experiments provide initial evidence that human infer-         563–607.
ence is an active and ongoing process of reuse and recombi-         Kahneman, D., & Tversky, A. (1982). On the study of statis-
nation, jointly solving myriad related questions over time—           tical intuitions. Cognition, 11, 123–141.
amortized inference. Thus the astonishing efficiency of hu-         Koller, D., & Friedman, N. (2009). Probabilistic Graphical
man probabilistic reasoning may be explained partly by inter-         Models: Principles and Techniques. The MIT Press.
actions between inference and memory.                               Lieder, F., Griffiths, T. L., & Goodman, N. D. (2012). Burn-
                                                                      in, bias, and the rationality of anchoring. Advances in Neu-
                    Acknowledgments                                   ral Information Processing Systems, 2699–2707.
We thank Andreas Stuhlmüller for helpful discussions. This         Michie, D. (1968). Memo functions and machine learning.
work was supported by the MIT Intelligence Initiative, a              Nature, 218, 19–22.
John S. McDonnell Foundation Scholar Award, grants from             Pouget, A., Beck, J. M., Ma, W. J., & Latham, P. E. (2013).
the ONR, the IARPA ICARUS program, and the Center for                 Probabilistic brains: knowns and unknowns. Nature Neu-
Brains, Minds and Machines (CBMM), funded by NSF STC                  roscience, 16, 1170–1178.
award CCF-1231216.
                                                                    Shi, L., Griffiths, T. L., Feldman, N. H., & Sanborn, A. N.
                         References                                   (2010). Exemplar models as a mechanism for performing
                                                                      bayesian inference. Psychonomic Bulletin & Review, 17,
Battaglia, P. W., Hamrick, J. B., & Tenenbaum, J. B. (2013).          443–464.
   Simulation as an engine of physical scene understanding.         Stuhlmüller, A., Taylor, J., & Goodman, N. (2013). Learn-
   Proceedings of the National Academy of Sciences, 110,              ing stochastic inverses. In Advances in neural information
   18327–18332.                                                       processing systems (pp. 3048–3056).
Dougherty, M. R., Gettys, C. F., & Ogden, E. E. (1999).             Vul, E., Goodman, N. D., Griffiths, T. L., & Tenenbaum, J. B.
   MINERVA-DM: A memory processes model for judg-                     (in press). One and done? optimal decisions from very few
   ments of likelihood. Psychological Review, 106(1), 180–            samples. Cognitive Science.
   209.
Estes, W. K. (1994). Classification and Cognition. Oxford
   University Press.
Gershman, S. J., Vul, E., & Tenenbaum, J. B. (2012). Mul-
   tistability and perceptual inference. Neural Computation,
   24, 1–24.
Gregory, R. L. (1970). The Intelligent Eye. Oxford University
   Press.
                                                                522

