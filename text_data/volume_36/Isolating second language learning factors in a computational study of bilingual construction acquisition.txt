UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Isolating second language learning factors in a computational study of bilingual
construction acquisition
Permalink
https://escholarship.org/uc/item/26c9c2mq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Matusevych, Yevgen
Alishahi, Afra
Backus, Ad
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                               Powered by the California Digital Library
                                                                 University of California

               Isolating second language learning factors in a computational study
                                          of bilingual construction acquisition
                                             Yevgen Matusevych (Y.Matusevych@uvt.nl)
                                             Department of Culture Studies, Tilburg University
                                                    Afra Alishahi (A.Alishahi@uvt.nl)
                               Department of Communication and Information Sciences, Tilburg University
                                                    Ad Backus (A.M.Backus@uvt.nl)
                                             Department of Culture Studies, Tilburg University
                                              PO Box 90153, 5000 LE Tilburg, the Netherlands
                                Abstract                                  of SLA (see an overview by Li, 2013), most of which simu-
                                                                          late learning the phonetic representations of words and their
   The study of second language acquisition (SLA) is often hin-
   dered by substantial variability in the background of learners,        association with meaning (Li, 2009; Cuppini, Magosso, &
   their learning process and the input they receive. This diver-         Ursino, 2013, etc.) or with grammatical categories (Monner,
   sity often makes it difficult to isolate specific learning factors     Vatz, Morini, Hwang, & DeKeyser, 2013). To our knowl-
   and study their impact on L2 development. We present a com-
   putational study of SLA as an alternative methodological ap-           edge, the only existing model that focuses on sentence struc-
   proach. By applying a usage-based computational model of               ture and constructions in SLA is that of Rappoport and Shein-
   construction learning on bilingual (German and English) input          man (2005), but in fact, it learns only one language (see the
   data, we analyze various learning variables in isolation. In par-
   ticular, we investigate three factors: ratio between the amount        section Related computational studies for a more detailed de-
   of L1 and L2 input, age of L2 onset, and L2 frequency dis-             scription of these models).
   tribution. Our results are in line with experimental findings on          What is lacking is a computational framework which al-
   the facilitatory effect of lower L1/L2 ratio and balanced L2 fre-
   quency distribution. We found no negative effect of later age of       lows us to study the acquisition of linguistic constructions in
   L2 onset on proficiency, which might be due to positive cross-         L1 and L2 as an intertwined process, to systematically ma-
   linguistic transfer between German and English constructions.          nipulate various types of learning variables mentioned ear-
   Keywords: second language acquisition, computational cog-              lier, and to study their impact on linguistic performance. In
   nitive modeling, learning factors, construction grammar                this paper, we take a first step in this direction by presenting
                                                                          a computational study of L1 and L2 construction acquisition,
                            Introduction                                  using an adaptation of an existing usage-based computational
Second language (L2) learners show substantial variation                  model (Alishahi & Stevenson, 2008). We report several ex-
in their developmental trajectory and linguistic proficiency.             periments on how L2 proficiency is affected by a number of
A systematic study of Second Language Acquisition (SLA)                   factors related to the learning process and the input.1
must account for multiple factors regarding the characteristics
of the learner (e.g., mother tongue or L1, learning abilities,            Learning factors
motivation), the learning process (e.g., implicit vs. explicit,           In the current study we manipulate three learning factors: the
age and rate of L2 exposure, opportunities for language use)              age of L2 onset, the ratio between the amount of L1 and L2
and the linguistic input (e.g., its qualitative and quantitative          input, and frequency distribution in L2 input. The first two
properties, linguistic distance between L1 and L2) (see, e.g.,            factors have been extensively studied in the SLA literature
DeKeyser, 2013). The main obstacle for conducting such                    and shown to play a crucial role in L2 development, whereas
studies is finding large, homogeneous populations which al-               experimental evidence on the impact of the third factor is in-
low for manipulating one factor at a time while controlling               conclusive and at times contradictory.
for the rest, a costly and at times impossible task.                      L1/L2 Ratio. The amount and proportion of L2 input that
   In the light of these difficulties, it is surprising that until        a learner receives is often estimated by the amount of time
recently SLA has received little attention from the computa-              they spend on learning and using L2. Muñoz (2011) reviews
tional modeling community. Computational models can pre-                  a number of studies showing that this factor correlates with
dict the impact of each learning factor on L2 development,                learners’ performance in various L2 proficiency tests.
and their prediction can suggest fruitful directions for human
subject studies. In first language acquisition research, com-             Age of L2 Onset (AO). The impact of AO on L2 proficiency
putational models have been widely used for studying the im-              has been attributed to multiple sources, including biological
pact of the characteristics of input and the learning mecha-              constraints and the cognitive, socio-cultural and environmen-
nisms on behavioral patterns and developmental trajectory,                    1 Preliminary results on a small data set were reported by
both at the level of words and constructions (see, e.g., Chater           Matusevych, Alishahi, and Backus (2013), see Input data for a com-
& Manning, 2006). However, there are only a few models                    parison.
                                                                      988

tal factors (see Han, 2004, for an overview). Within cognitive           The example-based learning mechanism of Alishahi and
linguistics, the automatization of the L1 system (caused by          Stevenson’s (2008) model and its flexibility in simulating var-
L1 neural entrenchment) is believed to negatively affect L2          ious aspects of language use makes it a suitable candidate for
learning (e.g., MacWhinney, 2006).                                   investigating how input-dependent factors (of the type dis-
Distribution of Input. It is subject to debate whether learn-        cussed in the section Learning factors) affect SLA. In an SLA
ing a new linguistic construction (both in L1 and L2) can be         setup, the learner may receive input data which includes a
facilitated by a skewed frequency distribution of its instances      mixture of usages from two different languages, although the
in the input (for example, when one or two of the verbs which        underlying processing mechanism is the same. This is in line
appear in a construction are much more frequent than oth-            with views in cognitive linguistics, in particular the Unified
ers) (Boyd & Goldberg, 2009). While some studies demon-              Competition Model, which claims that the same cognitive
strate a positive effect of skewed input (e.g., Goldberg, Casen-     mechanisms are used for L1 and L2 learning, and the differ-
hiser, & Sethuraman, 2004), others do not (Year & Gordon,            ence between L1 and L2 proficiency levels can be attributed
2009), or even show quite the opposite (e.g., McDonough &            to factors such as L1 entrenchment (see MacWhinney, 2013).
Nekrasova-Becker, 2012).
                                                                     Model architecture
Related computational studies                                        We make the simplifying assumption that upon hearing an
Perhaps the most fruitful computational research in bilingual-       utterance in a perceptual context, the learner can recognize
ism has been done using a family of self-organizing neural           words in the utterance and also form a conceptualization of
networks (see an overview by Li, 2009). Some experiments             the described event. Furthermore, we assume that the learner
with these models study the pattern of lexical organization          knows the idiosyncratic meaning of words in the utterance
in L2 as a function of AO. These experiments show that the           and can identify their referent in the corresponding scene.
acquired L2 lexicon is independent and coexists with L1 lex-             The model represents each individual verb usage as an
icon in early L2 learning, but ‘parasitizes’ on L1 lexicon in        argument structure frame, a collection of features that the
late L2 learning (Zhao & Li, 2010). This difference is ex-           learner can induce from the utterance and the observed event
plained by decreased neural network plasticity and increased         it refers to. These features include the predicate (corresponds
L1 entrenchment over time.                                           to the main event) and its semantic properties, the num-
   Monner et al. (2013) use a connectionist model to study po-       ber of arguments that the predicate takes, argument heads,
tential impact of L1 entrenchment and memory development             their cases, their lexico-semantic and event-based (or the-
on L2 performance deficits. Their experiments also involve           matic proto-role) properties, and finally the syntactic pattern
the manipulation of AO, and show a negative effect of L1 en-         (which in this case only reflects the order of arguments) and
trenchment on the acquisition of L2 grammatical gender. The          prepositions used in the utterance. In a bilingual setup, some
model learns to associate each word form with the correct            features (i.e., semantic) share their range of values in L1 and
gender category over time.                                           L2, while other features (lexical) take language-specific val-
   Rappoport and Sheinman (2005) model the acquisition of            ues. A sample verb usage and its corresponding argument
L2 constructions, but their model suffers from inconsistency         structure frame are shown in Table 1.
between L1 and L2 representations: L1 knowledge is static,               A construction represents a group of frames with simi-
in contrast to the emerging L2 system, which eliminates any          lar features. By detecting and clustering similar frames, the
possible effect of factors such as AO or L1/L2 ratio. Besides,       model can abstract away from individual verb usages and
they represent L1 only in terms of words and their relations,        form probabilistic associations between various features.
while the L2 system is purely syntactic – this discrepancy           Table 1: An example frame extracted from a verb usage I ate
prevents cross-linguistic transfer of L1 forms into L2.              a tuna sandwich.
                   Computational model                                 predicate               eat
                                                                       event properties        consume, take in, prep
In the current study we use an adapted version of an exist-            arg. count              2
ing model of argument structure acquisition by Alishahi and            arg1                    I
Stevenson (2008). The model learns abstract constructions              arg2                    sandwich
such as transitive and intransitive from instances of verb us-
                                                                       arg1 lexical props      self, person, ..., entity
age, and can use these constructions in a variety of language
                                                                       arg2 lexical props      snack food, dish, ..., entity
comprehension and production tasks. The model is informed
                                                                       arg1 role props         living thing, entity, ..., organism
by usage-based linguistics and is compatible with the Con-
                                                                       arg2 role props         solid, substance, ..., entity
struction Grammar view that the building blocks of language
                                                                       arg1 case               N/A
are form–meaning pairings (Goldberg, 1995), but it proposes
an alternative interpretation of linguistic constructions as a         arg2 case               N/A
probabilistic association between lexical, syntactic and se-           syntactic pattern       ARG 1 VERB ARG 2
mantic features.                                                       prepositions            N/A
                                                                 989

Learning mechanism. The model receives one frame at a                 between the original feature value and the value probabilities
time and processes it using an incremental clustering algo-           predicted by the model. For single-valued features such as
rithm which finds the most suitable construction for a new            frame predicate, this is estimated as the predicted probability
frame. This can be an existing construction or a new one:             of the original value. For features with a set value (e.g., event
            BestConstruction(F) = argmax P(k|F)               (1)     properties), this is estimated by measuring the Mean Average
                                            k                         Precision2 for the list of the predicted values ranked accord-
where k ranges over the indices of all constructions (index 0         ing to their probability, compared to the original set.
represents the new construction). Using Bayes rule and drop-             In this study, we test PAi for three frame features – the pred-
ping P(F) which is constant for all k:                                icate, its semantic properties, and arguments’ role properties.
                        P(k)P(F|k)                                    Conceptually, predicting these features corresponds, respec-
             P(k|F) =                   ∝ P(k)P(F|k)          (2)     tively, to tasks of predicate selection, predicate comprehen-
                            P(F)
The prior probability P(k) indicates the degree of entrench-          sion, and interpreting the (thematic) role of each argument
ment of construction k:                                               in the described event. In our preliminary experiments these
                            Nk                  1                     three tasks proved to be most informative compared to others.
                  P(k) =         , P(0) =                     (3)     For example, predicting syntactic pattern and prepositions ap-
                          N +1                N +1
                                                                      peared to be easy for the learner, due to the fact that probabil-
where Nk is the number of frames already contained in con-
                                                                      ity mass functions for values of these features were strongly
struction k, and N is the total number of frames observed so
                                                                      skewed towards a certain value. Finally, in the reported ex-
far. The posterior probability of a frame F is expressed in
                                                                      periments we use a language proficiency index (LPI) defined
terms of the probabilities of its features, which are assumed
                                                                      as the average PAi for the three (n = 3) features:
to be independent:
                                                                                                           ∑n PAi
                  P(F|k) =        ∏        P(Fi |k)           (4)                                LPI = i=1                           (6)
                             i∈Features(F)
                                                                                                             n
where Fi is the value      of the ith feature in    the frame F,                                   Input data
and P(Fi |k) is the probability of displaying the value Fi            In previous work (Matusevych et al., 2013), we compiled a
within construction k. This probability is estimated using a          small set of frames from usages of 6 German and 6 English
smoothed maximum likelihood formula. For single-valued                verbs. The frames were manually extracted from German
features such as the head verb, likelihood is calculated by           child-directed speech (L1) and English classroom material
simply counting those members of construction k whose                 presented to German elementary school students (L2). Care-
value for feature i exactly matches value Fi . For features with      ful annotation of the conversations yielded a relatively noise-
a set value such as the semantic properties of the verb and the       free data set, but the small size of our sample made the distri-
arguments, the likelihood is calculated by comparing sets.            bution of verbs and constructions unrealistic, and the outcome
Using constructions. Linguistic productivity is simulated             of our experiments unreliable.
as predicting a missing value for a particular feature in a              For the experiments reported in this paper, we automat-
frame given the other available feature values. For example,          ically extract frames for the same languages (German and
verb comprehension can be seen as predicting the best value           English) from a number of available resources. Considering
for the feature “event properties” given the lexical features         the frame features (see Table 1), we needed a syntactically
(such as predicate and argument heads), the syntactic features        parsed and POS-tagged corpus, also annotated with seman-
(pattern and prepositions) and some semantic features (argu-          tic role labels. For German, the TIGER corpus (Brants et al.,
ments’ lexical and role properties). The probability that the         2004) appeared to be a good candidate, since it has been en-
missing feature i displays value Fi given other observed fea-         riched with semantic role annotation in the SALSA project
ture values in a partial frame F can be estimated as:                 (Burchardt et al., 2006). For English, we used the WSJ part
                                                                      of Penn Treebank (Marcus et al., 1994), together with Propo-
   P(Fi |F) = ∑ P(Fi |k)P(k|F) ∝ ∑ P(Fi |k)P(k)P(F|k)         (5)     sition Bank (PropBank) containing argument structure infor-
                k                      k
                                                                      mation for WSJ (Palmer, Gildea, & Kingsbury, 2005). Al-
The probabilities P(k), P(F|k) and P(Fi |k) are estimated as          though neither TIGER nor WSJ contained the kind of lan-
before (see equations 3 and 4). Ranging over the possible             guage that children or most L2 learners receive as input, we
values of feature i, the value of an unobserved feature can           used these corpora as the only large sources for English and
be predicted by sampling possible values from the estimated           German that contained all annotations we needed.
P(Fi |F) distribution.                                                   From SALSA and PropBank, we extracted all verb-
Evaluating language proficiency. To evaluate the learner’s            centered frames, each containing the main predicate (verb)
language proficiency at a certain moment in time, we test the         and its arguments (labeled with their semantic roles and
model on a language task where one of the features in a test          cases), as well as prepositions and word order. As for the
frame is removed, and the model’s prediction for the missing              2 Mean Average Precision is a standard measure in Information
feature is compared to the original value. The prediction ac-         Retrieval, where a set of relevant items are expected to show up at
curacy of feature i, or PAi , is estimated based on the match         the top of a ranked list of results.
                                                                  990

latter, many German frames originated from verb-final em-
                                                                                       0.0 0.2 0.4 0.6 0.8 1.0                                                           0.0 0.2 0.4 0.6 0.8 1.0
                                                                                                                            English                                                                          L1 English
                                                                                                                            German                                                                           L2 German
bedded clauses, but in our setup frames represented simple
main clauses, thus we had to recover German V2 word order                      LPI                                                                                 LPI
by manually changing the predicate position.
   We extracted the lexical properties of the noun arguments
from WordNet (Miller, 1995). For verbs, we extracted fea-                                                        0              100        200     300       400                                    0            100      200      300       400
tures from VerbNet (Schuler, 2006) as well as WordNet. For                                                                        Input frames                                                                      Input frames
adjectives and adverbs which are not hierarchically structured                                                    (a) Early bilinguals                                                              (b) Late L2 learners
in WordNet, we used synonyms instead of hypernyms. To                        Figure 1: LPI change over time in two specific settings
maximize semantic consistency, we used WordNet and Verb-                 ence between English and German data sets – as mentioned
Net for extracting the lexical properties of German words as             before, the total number of values for arguments’ role prop-
well (by translating them into English). Finally, we manually            erties is larger in the German data set, which makes the task
compiled a set of lexical properties for frequent pronouns.              of predicting this feature more difficult in German than in En-
   Arguments’ role-based properties were also extracted from             glish. However, a combination of larger R and AO can reverse
WordNet through an existing mapping between FrameNet se-                 this effect. In the late L2 learning scenario (Figure 1(b)) the
mantic roles and WordNet (Bryl, Tonelli, Giuliano, & Ser-                lower level of L2 proficiency could be caused both by differ-
afini, 2012). This procedure resulted in two German and En-              ent R and AO values. The following experiments investigate
glish data sets containing 3370 and 3803 frame instances, re-            the impact of each of the two variables in isolation.
spectively. The data sets are comparable in terms of overall
number of values for each feature, with the largest difference
                                                                         L1/L2 Ratio
observed (obviously) for linguistic case, but also for argument          To investigate the impact of the proportion of L2 input data
role properties (353 for German vs. 195 for English) due to              on proficiency, we ran a number of experiments with varying
differences in granularity of the semantic annotated roles in            R ∈ {1, 2, 5, 10, 20} while keeping the total number of frames
SALSA and PropBank. In the experiments described below,                  and the age of L2 onset constant (N = 400, AO = 0). Figure 2
we used both German and English as L1 or L2.                             shows the developmental pattern (depicted by the change in
                                                                         L2 proficiency, or LPI) over time in varying R conditions. At
               Experiments and results                                   the end of learning, LPI was negatively correlated with R both
In a simulation of an SLA scenario, the model receives and               for L2 English (Kendall’s tau τ = −.57, p < .001) and for L2 German
incrementally processes a sequence of N frames. Typically                (τ = −.60, p < .001). Figure 3 highlights this trend: the final LPI
during the early stages of learning, all frames represent us-            value significantly decreases as R increases.
ages of L1. However, after a certain point in time (corre-                   This result is in line with experimental and observational
sponding to our AO variable), the model receives a mixture               findings that L2 proficiency is influenced by the amount of
of L1 and L2 frames, the proportion of which is determined               L2 exposure and contact with native speakers (see overview
by our Ratio variable (henceforth R). To depict the develop-             by Muñoz, 2011). However, there is no agreement yet on
mental trajectory of each language over time, we interrupt the           whether this effect is only limited to the initial period of learn-
training process at fixed intervals, and test the proficiency of         ing. Although our results suggest a long-term effect, larger-
the model on 20 test frames using the LPI measure (equa-                 scale simulations are needed to make a more reliable conclu-
tion 6). Both training and test frames are sampled from the              sion.
                                                                                1.0                                                                                                       1.0
data sets described in the previous section. In the experiments                                                      R=1
                                                                                                                     R=2
                                                                                                                                                                                                             R=1
                                                                                                                                                                                                             R=2
                                                                                0.8                                                                                                       0.8
reported here, we test the model at intervals of 20 frames, and                                                      R=5
                                                                                                                     R=10
                                                                                                                                                                                                             R=5
                                                                                                                                                                                                             R=10
                                                                                0.6                                  R=20                                                                 0.6                R=20
the results are averaged over 10 simulations unless specified            LPI                                                                                         LPI
                                                                                0.4                                                                                                       0.4
otherwise. Each simulation corresponds to a learner with a
                                                                                0.2                                                                                                       0.2
different history of linguistic input, and the 20 test frames
                                                                                0.0                                                                                                       0.0
differ for each learner as well.                                                                    0                  100            200        300     400                                         0            100       200        300     400
                                                                                                                                 Input frames                                                                           Input frames
   Figure 1 shows L1 and L2 learning curves for two com-
                                                                                                                     (a) L2 German                                                                           (b) L2 English
mon scenarios: (a) early bilingual learners who receive equal
amounts of L1 and L2 input from the start (R = 1, AO = 0);                     Figure 2: L2 LPI change over time for different R values
and (b) learners who are exposed to L2 input at a later stage                         0.8                                                                                                          0.8
                                                                                                                                                                                                         ●
                                                                                                                                                                                                             ●
and with a lower amount compared to L1 (R = 5, AO = 200).                                                          ●                                                                                     ●   ●
                                                                                                                                                                                                             ●      ●        ●
                                                                         LPI                                                                                         LPI
                                                                                                                 ●          ●                                                                            ●
                                                                                                                                                                                                         ●   ●
                                                                                      0.5                                                                                                          0.5
                                                                                                                 ●●
                                                                                                                 ●          ●                                                                            ●   ●
                                                                                                                                                                                                             ●      ●        ●
                                                                                                                 ●●●        ●          ●                                                                 ●
                                                                                                                                                                                                         ●   ●               ●
                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                    ●        ●
In both cases, the model receives a total of N = 400 frames.                                                     ●
                                                                                                                 ●●
                                                                                                                   ●
                                                                                                                            ●
                                                                                                                            ●
                                                                                                                            ●
                                                                                                                            ●
                                                                                                                                       ●
                                                                                                                                       ●
                                                                                                                                       ●
                                                                                                                                       ●
                                                                                                                                                         ●
                                                                                                                                                         ●
                                                                                                                                                         ●
                                                                                                                                                         ●
                                                                                                                                                                                                                    ●
                                                                                                                                                                                                                    ●
                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                               ●
                                                                                                                            ●                            ●
                                                                                                                                                         ●
                                                                                                                                       ●
As can be seen, the L1 and L2 learning curves of the early                            0.2                                                                                                          0.2
bilinguals show the same developmental trajectory, whereas                                                       1          5          10                20                                              1          5       10                20
                                                                                                                                      Ratio                                                                                Ratio
for the late L2 learners, the L2 curve straggles behind L1.
                                                                                                                     (a) L2 German                                                                           (b) L2 English
   It must be noted that under equal conditions, learning En-
glish for our model is easier than learning German (as re-               Figure 3: Final level of L2 proficiency (LPI) in each simula-
flected in Figure 1(a)). This can be explained by the differ-            tion for different R values, with LOESS curves fitted
                                                                   991

Age of L2 Onset                                                                                                            0.8
                                                                                                                                                                   balanced
                                                                                                                                 ***         **          *         skewed
To study the impact of AO on L2 proficiency, we ran a num-                                                                 0.6
ber of experiments with varying AO ∈ {0, 100, 200, 300, 400}                                                         LPI   0.4
(frames) while keeping R and N constant (R = 1, N = 800).
                                                                                                                           0.2
For each AO value the model received the same amount of
mixed L1/L2 input (hence the truncated curves). Figure 4                                                                   0.0
                                                                                                                                  50        100          150      200
shows the change in L2 proficiency over time for different                                                                                  Input frames
AO values. As we can see, there is no noticeable difference                                                  Figure 5: L2 LPI at 4 learning steps by the type of input
in the final LPI value across conditions. That is, we found no                                            predicates appearing in this construction. In each simulation,
significant correlation between AO and the resulting LPI, ei-                                             10 randomly selected predicates were used for training, and
ther for English L2 (τ = .09, p > .05) or German L2 (τ = .06, p > .05).                                   the other 5 for testing. In the balanced condition, train pred-
      1.0
                 AO=0
                                                        1.0
                                                                   AO=0                                   icates were uniformly distributed, while in the skewed con-
                 AO=100                                            AO=100
      0.8        AO=200                                 0.8        AO=200                                 dition two randomly selected predicates were 20 times more
                 AO=300                                            AO=300
      0.6
                 AO=400
                                                        0.6
                                                                   AO=400                                 frequent than the others. We ran the model with parameters
LPI                                               LPI                                                     N = 400, AO = 200, R = 2, and calculated LPI 3 (which in
      0.4                                               0.4
      0.2                                               0.2
                                                                                                          this case reflected the knowledge of a single construction) at
                                                                                                          4 learning steps (50 frames each) after AO. The results (aver-
      0.0                                               0.0
            0   100 200 300 400 500 600 700 800               0   100 200 300 400 500 600 700 800         aged over 30 simulations) are shown in Figure 5.
                          Input frames                                      Input frames
                                                                                                             Applying Wilcoxon signed-rank test showed that after n =
                 (a) L2 German                                     (b) L2 English
                                                                                                          50 mixed L1 and L2 frames, LPI was significantly higher for
  Figure 4: L2 LPI change over time for different AO values                                               balanced (median Mdn = 0.53) than skewed input (Mdn = 0.49, T = 46,
   These results are contrary to the L1 entrenchment account,                                             p < .001, r = −.49). The same effect was observed for n = 100
which predicts that a more entrenched L1 uses up memory                                                   (Mdn = 0.55 vs. 0.52, T = 89, p < .01, r = −.38) and n = 150 (Mdn = 0.56 vs.
resources and yields lower L2 proficiency (Zhao & Li, 2010;                                               0.52, T = 127, p < .05, r = −.28), but there was no significant differ-
Monner et al., 2013). However, considering the typologi-                                                  ence for n = 200 (Mdn = 0.56 vs. 0.53, T = 155, p > .05).
cal similarity between English and German, we believe that                                                   The results support experimental findings that balanced in-
a positive transfer effect might be at play here, where L2                                                put facilitates novel construction learning (Nakamura, 2012).
learning in higher AO conditions is facilitated by the exist-                                             McDonough and Nekrasova-Becker (2012), who found the
ing knowledge of similar L1 constructions. Such effects must                                              same effect for an L2 construction that had a counterpart
be observed for (shared) semantic features (e.g., event prop-                                             in the learners’ L1, suggested that balanced input promotes
erties), but semantic features take set values, and it is difficult                                       broader category generalization. At the same time, other stud-
to trace the origin of each set element in the input. Neverthe-                                           ies on learning a novel L1 construction found the opposite fa-
less, the presence of transfer can be confirmed by looking at                                             cilitatory effect of skewed input (see an overview by Boyd &
L2 predicate prediction. Predicting the L2 German predicate                                               Goldberg, 2009). Nakamura (2012) explains this mismatch
sometimes resulted in producing its L1 English counterpart                                                by the fact that adult L2 learners, unlike L1 learners, engage
(e.g., occur instead of geschehen [to occur], increase instead                                            in explicit learning. Our results support this argument, since
of steigen [to increase]), and vice versa (existieren [to exist]                                          our model performs an explicit categorization task by looking
instead of exist). Thus, an absence of an AO effect might be                                              for regularities in instances, thus the learning is rather more
due to the opposite directions of L1 entrenchment and posi-                                               explicit than implicit.
tive transfer, and needs further investigation.
                                                                                                                                       Conclusion
Frequency distribution in the input
                                                                                                          We present a computational study of learning second lan-
To investigate whether the type of verb frequency distribution
                                                                                                          guage constructions. Employing a usage-based computa-
in L2 input affects L2 construction learning, we adopted a de-
                                                                                                          tional model allows us to control the specifications of the
sign from several experimental studies (e.g., Year & Gordon,
                                                                                                          learning process and the characteristics of input, and to simu-
2009; Nakamura, 2012) where participants learn a new L2
                                                                                                          late specific populations of L2 learners such as balanced bilin-
construction which has no counterpart in their L1, and where
                                                                                                          gual children and late L2 learners. This approach enables us
the distribution of verbs in this construction is either skewed
                                                                                                          to isolate the impact of each learning factor on L2 develop-
or balanced. Since it was difficult to find an English argument
                                                                                                          ment by manipulating one variable at a time – a methodolog-
structure construction in our data set with no counterpart in
                                                                                                          ical advantage that is absent from studies on human subjects.
German, in this experiment we only ran simulations on L1
                                                                                                             Here we have investigated the impact of three learning vari-
English and L2 German. The construction of interest was a
                                                                                                          ables: L1 to L2 ratio in the input, age of L2 onset, and L2 fre-
ditransitive with reversed order of arguments (THEME PRED .
                                                                                                          quency distribution. Our experimental results showed that a
AGENT PATIENT, e.g., das gab ich dem Herren [I gave it to
the gentlemen]), which was absent in the English data set.                                                    3 In this experiment, learners never encountered test predicates in
We manually prepared a small set of frames with 15 different                                              the input, thus instead of PApredicate we used PAsynt.pattern .
                                                                                                    992

decreasing L1 to L2 ratio facilitates L2 development, as pre-        Han, Z. (2004). Fossilization in adult second language ac-
dicted by existing literature. Our analyses of L2 input dis-           quisition.
tribution showed that balanced input facilitates construction        Li, P. (2009). Lexical organization and competition in first
learning, which is in line with some existing experimental             and second languages: computational and neural mecha-
findings. However, our simulations did not show a similar              nisms. Cognitive Science, 33(4), 629–664.
positive effect for early age of L2 onset. We suggest that this      Li, P. (2013). Computational modeling of bilingualism: How
might be due to an interaction between two conflicting fac-            can models tell us more about the bilingual mind? Bilin-
tors, L1 entrenchment and positive transfer from L1 to L2.             gualism: Language and Cognition, 16, 241–245.
   Our model represents both L1 and L2 as complex systems            MacWhinney, B. (2006). Emergent fossilization. In Z. Han
that comprise different features and can compete with each             & T. Odlin (Eds.), Studies of Fossilization in Second Lan-
other. This framework allows for studying the concurrent ac-           guage Acquisition (pp. 134–156).
quisition of both languages, and modeling phenomena such             MacWhinney, B. (2013). The logic of the unified model. In
as linguistic transfer. To our knowledge, this is the first mod-       S. Gass & A. Mackey (Eds.), The Routledge Handbook of
eling attempt of this kind. However, larger-scale and more             Second Language Acquisition (pp. 211–227).
diverse experimental investigation is needed for depicting a         Marcus, M., Kim, G., Marcinkiewicz, M. A., Macintyre, R.,
detailed picture of SLA and its parameters. In addition, fu-           Bies, A., Ferguson, M., . . . Schasberger, B. (1994). The
ture research must include other language pairs with different         Penn Treebank: Annotating predicate argument structure.
degrees of typological similarity in order to study the relative       In Proc. of the workshop on Human Language Technology
impact of cross-linguistic transfer.                                   (pp. 114–119).
                                                                     Matusevych, Y., Alishahi, A., & Backus, A. (2013). Compu-
                    Acknowledgements                                   tational simulations of second language construction learn-
We thank Grzegorz Chrupała and Seza Doğruöz for their                ing. In Proc. of CMCL-2013 (pp. 47–56).
valuable comments.                                                   McDonough, K., & Nekrasova-Becker, T. (2012). Com-
                                                                       paring the effect of skewed and balanced input on En-
                         References                                    glish as a foreign language learners’ comprehension of the
Alishahi, A., & Stevenson, S. (2008). A computational model            double-object dative construction. Applied Psycholinguis-
   of early argument structure acquisition. Cognitive Science,         tics, FirstView, 1–24.
   32(5), 789–834.                                                   Miller, G. A. (1995). WordNet: A lexical database for En-
Boyd, J. K., & Goldberg, A. E. (2009). Input effects within a          glish. Communications of the ACM, 38(11), 39–41.
   constructionist framework. The Modern Language Journal,           Monner, D., Vatz, K., Morini, G., Hwang, S.-O., & DeKeyser,
   93(3), 418–429.                                                     R. M. (2013). A neural network model of the effects of en-
Brants, S., Dipper, S., Eisenberg, P., Hansen-Schirra, S.,             trenchment and memory development on grammatical gen-
   König, E., Lezius, W., . . . Uszkoreit, H. (2004). TIGER:          der learning. Bilingualism: Language and Cognition, 16,
   Linguistic interpretation of a German corpus. Research on           246–265.
   Language and Computation, 2(4), 597–620.                          Muñoz, C. (2011). Input and long-term effects of starting age
Bryl, V., Tonelli, S., Giuliano, C., & Serafini, L. (2012). A          in foreign language learning. IRAL, 49(2), 113–133.
   novel Framenet-based resource for the semantic web. In            Nakamura, D. (2012). Input skewedness, consistency, and or-
   Proc. of SAC-2012 (pp. 360–365).                                    der of frequent verbs in frequency-driven second language
Burchardt, A., Erk, K., Frank, A., Kowalski, A., Pado, S., &           construction learning. IRAL, 50(1), 1–37.
   Pinkal, M. (2006). The SALSA corpus: a German corpus              Palmer, M., Gildea, D., & Kingsbury, P. (2005). The propo-
   resource for lexical semantics. In Proc. of LREC-2006.              sition bank: An annotated corpus of semantic roles. Com-
Chater, N., & Manning, C. D. (2006). Probabilistic models of           putational Linguistics, 31(1), 71–106.
   language processing and acquisition. Trends in Cognitive          Rappoport, A., & Sheinman, V. (2005). A second language
   Sciences, 10(7), 335–344.                                           acquisition model using example generalization and con-
Cuppini, C., Magosso, E., & Ursino, M. (2013). Learning the            cept categories. In Proc. of PsychoCompLA-2005 (pp. 45–
   lexical aspects of a second language at different proficien-        52).
   cies: A neural computational study. Bilingualism: Lan-            Schuler, K. K. (2006). Verbnet: A broad-coverage, compre-
   guage and Cognition, 16, 266–287.                                   hensive verb lexicon. Unpublished doctoral dissertation.
DeKeyser, R. M. (2013). Age effects in second language               Year, J., & Gordon, P. (2009). Korean speakers’ acquisition
   learning: Stepping stones toward better understanding.              of the English ditransitive construction: The role of verb
   Language Learning, 63, 52–67.                                       prototype, input distribution, and frequency. The Modern
Goldberg, A. E. (1995). Constructions: A construction gram-            Language Journal, 93(3), 399–417.
   mar approach to argument structure.                               Zhao, X., & Li, P. (2010). Bilingual lexical interactions in an
Goldberg, A. E., Casenhiser, D. M., & Sethuraman, N.                   unsupervised neural network model. International Journal
   (2004). Learning argument structure generalizations. Cog-           of Bilingual Education and Bilingualism, 13(5), 505–524.
   nitive Linguistics, 15(3), 289–316.
                                                                 993

