UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Some arguments are probably valid: Syllogistic reasoning as communication
Permalink
https://escholarship.org/uc/item/5nm2h7pv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Tessler, Michael
Goodman, Noah
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

      Some arguments are probably valid: Syllogistic reasoning as communication
                                                   Michael Tessler, Noah D. Goodman
                                                      {mtessler, ngoodman}@stanford.edu
                                                Department of Psychology, Stanford University
                               Abstract
   Syllogistic reasoning lies at the intriguing intersection of natu-
   ral and formal reasoning, of language and logic. Syllogisms
   comprise a formal system of reasoning yet use natural lan-
   guage quantifiers, and invite natural language conclusions.
   How can we make sense of the interplay between logic and
   language? We develop a computational-level theory that con-
   siders reasoning over concrete situations, constructed proba-
   bilistically by sampling. The base model can be enriched to
   consider the pragmatics of natural language arguments. The
   model predictions are compared with behavioral data from a
   recent meta-analysis. The flexibility of the model is then ex-
   plored in a data set of syllogisms using the generalized quan-
   tifiers most and few. We conclude by relating our model to
   two extant theories of syllogistic reasoning – Mental Models
   and Probability Heuristics. Keywords: Reasoning; language;
   QUD; Bayesian model
                                                                              Figure 1: How will the reasoner interpret the experimenter’s
   Consider for a moment that your friend tells you: “Every-                  argument?
one in my office has the flu and, you know, some people with
this flu are out for weeks.” Do you respond with “Everyone
in your office has the flu.” Do you respond with “Pardon me,                  is no relation between A & C which is true in every situa-
there is no inference I can draw from what you just said.”                    tion in which the premises are true. This is the case with
Or do you respond “I hope your officemates are not out for                    the argument above. Often in these cases, however, people
weeks and I hope you don’t get sick either.”                                  are perfectly comfortable drawing some conclusion. A recent
   The first response – while true – does not go beyond the                   meta-analysis of syllogistic reasoning showed that over the
premises; the second response attempts to go beyond the                       population, the proper production of no valid conclusion re-
premises by strict classical logic, and fails; the final response             sponses for invalid arguments ranged from 76% to 12%. For
goes beyond the premises, to offer a conclusion which is                      valid arguments, the accuracy of producing valid conclusions
probably useful and probably true. This cartoon illustrates a                 ranged from 90% to 1% (Khemlani & Johnson-Laird, 2012):
critical dimension along which cognitive theories of reason-                  people do not seem to find drawing deductively valid conclu-
ing differ: whether the core and ideal of reasoning is deduc-                 sions particularly natural.
tive validity or probabilistic support. A separate dimension                     Perhaps because of this divergence between human behav-
concerns the extent to which principles of natural language—                  ior and deductive logic, syllogistic reasoning has been a topic
pragmatics and semantics—are necessary for understanding                      of interest in cognitive psychology for over a hundred years
reasoning tasks. In this paper, we explore the idea that the                  (Störring, 1908), and before that in philosophy, dating back
formalism of probabilistic pragmatics can provide insight into                to Aristotle. Syllogisms are undoubtedly logical; indeed, the
how people reason with syllogisms.                                            syllogistic form was the only formal system of logic for mil-
   The form of the argument above resembles a syllogism:                      lennia. At the same time, the arguments use natural language
a two-sentence argument used to relate two properties (or                     quantifiers and invite natural language conclusions; precisely
terms: A, C) via a middle term (B); the relations used in syl-                pinning down the meaning and use of quantifiers has been an
logisms are quantifiers. Fit into a formal syllogistic form, this             ongoing area of inquiry since Aristotle (e.g. Horn, 1989).
argument would read:                                                             Many theories of syllogistic reasoning take deduction as
   All officemates are out with the flu                                       a given and try to explain reasoning errors as a matter of
   Some out with the flu are out for weeks                                    noise during cognition. Errors, then, may arise from im-
   Therefore, some officemates are out for weeks                              proper use of deductive rules or biased construction of log-
                                                                              ical models. Many other kinds of reasoning, however, can be
The full space of syllogistic arguments is derived by shuffling               well-explained as probabilistic inference under uncertainty.
the ordering of the terms in a sentence (“All A are B” vs. “All               Probability theory provides a natural description of a world
B are A”) and changing the quantifier (all, some, none, not                   in which you don’t know exactly how many people are in the
all1 ). Most syllogisms have no valid conclusion, i.e. there
                                                                              that in sentence-form, the last two quantifiers are typically presented
    1 For distinctiveness, we will refer to the quantifiers as such. Note     as “No A are B” and “Some A are not B”, respectively.
                                                                          1574

hallway outside your door, or whether or not the lion is going                Here the helper function all-true simply checks that all ele-
to charge. We suggest that combining probabilistic reason-                    ments of a list are true, i.e. that all the As are indeed Bs.
ing with natural language semantics and pragmatics is a use-                  The function map applies the given function —(lambda ...)— to
ful approach in that knowledge can describe distributions on                  each element of the list objects. Similarly we can define some,
possible situations, and these distributions can be updated by                none, not-all to have their standard meanings. For a first test
sentences with new information. In this formalism, deduction                  of the model, we assume sets are non-empty, i.e. all and none
emerges as those arguments which are always true and syllo-                   cannot be trivially true.
gistic reasoning becomes a process of determining that which                      The key observation to connect these truth-functional
is most probable, relevant, and informative.                                  meanings of quantifier expressions to probability distribu-
                                                                              tions over situations is that an expression which assigns a
         A pragmatic Bayesian reasoner model                                  Boolean value to each situation can be used for probabilis-
Our model begins with the intuition that people reason prob-                  tic conditioning. That is, these quantifier expressions can be
abilistically about situations populated by objects with prop-                used to update a prior belief distribution over situations into a
erties. To represent this type of richly structured model, we                 posterior belief distribution. For syllogistic reasoning we are
must go beyond propositional logic and its probabilistic coun-                interested not in the posterior distribution over situations per
terpart, Bayesian networks. We instead build our model us-                    se, but the distribution on true conclusions that these situa-
ing the probabilistic programing language Church (Goodman,                    tions imply. In Church this looks like:
Mansinghka, Roy, Bonawitz, & Tenenbaum, 2008), a kind                         ( query
of higher-order probabilistic logic in which it is natural to                   ( define objects ( list ’o1 ’o2 ... ’on ))
                                                                                . . . define A ,B ,C . . .
describe distributions over objects and their properties. For                   . . . define all , some , no , not-all . . .
                                                                                ( define conclusion ( conclusion-prior ))
background and details on this form of model representation,
see http://probmods.org.                                                        conclusion
    Situations are composed of n objects:                                       ( and ( conclusion A C)
                                                                                      ( premise-one A B)
( define objects ( list ’o1 ’o2 ... ’on ))                                            ( premise-two B C)))
(Ellipses indicate omissions for brevity, otherwise models are                    The first arguments to a query function are a generative
specified via runnable Church code2 .) Properties A, B, and C                 model: definitions or the background knowledge with which
of these objects are represented as functions from objects to                 a reasoning agent is endowed. Definitions for which a prior
the property value. We assume properties are Boolean, and                     is stipulated (e.g. conclusion) denote aspects of the world over
so property values can be true or false. We assume no a priori                which the agent has uncertainty. The second argument, called
information about the meaning of the properties and thus they                 the query expression, is the aspect of the computation about
are determined independently:                                                 which we are interested; it is what we want to know. The fi-
( define A ( mem ( lambda (x) ( flip br ))))                                  nal argument, called the conditioner, is the information with
( define B ( mem ( lambda (x) ( flip br ))))
( define C ( mem ( lambda (x) ( flip br ))))
                                                                              which we update our beliefs; it is what we know. We assume
                                                                              that the prior distribution over conclusions (and premises, be-
Note that the operator mem memoizes these functions, so that                  low) is uniform.
a given object has the same value each time it is exam-
ined within a given situation, even though it is initially de-                Recursion and pragmatics
termined probabilistically (via flip). Previous probabilistic                 We have suggested viewing syllogistic reasoning as a case
models (Oaksford & Chater, 1994) have invoked a principle                     of communication, and this in turn suggests that reasoning
of rarity from the observation that properties are relatively                 should go beyond the semantics of language, to its pragmat-
rare of objects in the world3 . For us, this simply means the                 ics.
base rate, br, of properties is small.                                            Following the rational speech-act (RSA) theory (Goodman
    We interpret quantifiers as truth-functional operators, con-              & Stuhlmüller, 2013; Frank & Goodman, 2012), we imag-
sistent with standard practice in formal semantics. A quan-                   ine a reasoner who receives premises from an informative
tifier (e.g. all) is a function of two properties (e.g. A and B)              speaker. The speaker conveys information about which only
which maps to a truth value by consulting the properties of                   she has access – in RSA, her access was a current state of
the objects in the current situation. For instance:                           the world. By being informative with respect to the world-
( define all                                                                  state, the speaker is able to communicate enriched meanings
   ( lambda (A B)                                                             (e.g. scalar implicature – that “some” may also imply “not
      ( all-true ( map ( lambda (x) ( if (A x) (B x) true ))
                         objects ))))                                         all”). It is known, however, that standalone scalar implica-
                                                                              tures do a poor job of accounting for reasoning with syllo-
    2 A fully-specified version of this model can be accessed at:
                                                                              gisms (M. J. Roberts, Newstead, & Griggs, 2001). Indeed, a
http://forestdb.org/models/syllogisms-cogsci14.html
    3 This article is an article and it’s about reasoning, but it’s not a     preliminary analysis of a standard Gricean-listener model in
cat, and it’s not a car, nor an elephant nor the color red. In fact,          this framework was consistent with this account.
there’s a very large number of things which this article is not.                  However, a listener (our reasoner) may consider the
                                                                          1575

premises in a wider, conversational setting: she may ask                     increases, the premises becomes more informative with re-
herself why the experimenter chose to give these particular                  spect to the uniquely-implicated conclusions (unique, that is,
premises, as opposed to alternative arguments. This requires                 for those premises). When depth is 0, the model collapses to
a closer look at what the reasoner believes to be at issue                   produce the P(conclusion | premises), which we refer to as
in this “conversation”—the Question Under Discussion, or                     the literal Bayesian reasoner. We refer to the model with
QUD (C. Roberts, 2004). In a syllogistic context, we take the                              5
                                                                             depth equal to 1 as the pragmatic Bayesian reasoner.
QUD to be “what is the relationship between A & C (the end                      The three parameters of the model—n_objects, br, and
terms)?”, very often the actual context in which the experi-                 alpha—were fit by maximum-likelihood estimation. These fit
ment is presented.                                                           parameter values were 5, 0.25, and 4.75, respectively.
   In this setup, pragmatic inferences will differ from the
standard local implicatures; for instance, “Some A are B”                                                   Results
may not lead to a “Not all A are B” implicature if “All A                    To test the predictions of the model we used data from
are B” wouldn’t provide additional information about the A-                  the meta-analysis of syllogistic reasoning tasks presented by
C relationship. The enriched meanings come from the fol-                     Chater and Oaksford (1999). These data were compiled from
lowing counter-factual consideration: “why did this experi-                  five studies on syllogistic reasoning, completed from 1978-
menter present me with this argument and not any other argu-                 1984. The data include percentage response for conclusions
ment?” The pragmatic reasoner enriches the conclusions that                  that contain each of the 4 quantifiers as well as for “No
are more uniquely determined by the particular argument the                  Valid Conclusion” (NVC). The Bayesian reasoning models
experimenter provides.                                                       described so far are not equipped to handle NVC6 . We re-
   The A-C QUD is naturally captured by a reasoner who                       moved the NVC responses from the meta-analysis and renor-
considers an experimenter who considers the conclusions the                  malized so the endorsement of all conclusions for a syllogism
reasoner would draw about A & C (not the reasoner’s                          adds to 100. Some studies in the meta-analysis asked partici-
inferences about the whole world-state, which would—                         pants to draw conclusions which were restricted to the classi-
superfluously—include B).                                                    cal ordering of terms (C-A) while others allowed conclusions
   We can combine the above intuitions about pragmatic com-                  in either direction (A-C or C-A). To accommodate this, we
prehension into a model in which reasoner and experimenter                   allowed our model to draw conclusions in either order and
jointly reason about each other. Critically, each agent reasons              collapsed responses across these two orderings to compare it
about the other at recursive depth of comprehension:                         to this data set.
( define ( experimenter conclusion depth )
   ( query                                                                   Qualitative results
     ( define premises ( premise-prior ))
                                                                             For each model, we report the total number of syllo-
     premises
                                                                             gisms for which the model’s modal response is the same
     ( equal ? conclusion ( softmax ( reasoner premises depth )
            alpha ))))                                                       as for in the meta-analysis data. This is a qualitative
                                                                             assessment of fit.          The table below shows the num-
( define ( reasoner premises depth )
   ( query                                                                   ber of modal responses for which the model matched
     ( define objects ( list ’o1 ’o2 ... ’on ))
     . . . define A ,B ,C . . .                                              the data (columns “matches”). We separate these into
     . . . define all , some , no , not-all . . .
     ( define conclusion ( conclusion-prior ))
                                                                             valid and invalid syllogisms7 .             The total numbers of
                                                                             valid and invalid syllogisms are 24 and 40, respectively.
     conclusion
                                                                               Model            matchesvalid matchesinvalid rvalid rinvalid
     ( and ( conclusion A C)
        ( if ( depth 0)                                                        Prior                  5                24           -.46        .41
                ( and (( first premises ) A B)                                 Literal               17                20           -.20        .64
                      (( second premises ) B C))
                ( equal ? premises ( experimenter conclusion (-                Pragmatic             17                26            .77        .74
                      depth 1) ))))))
                                                                                As a baseline, we first examined the posterior distribution
                                                                             of conclusions conditioned only on the truth of the conclusion
The reasoner and experimenter functions produce a distribution
                                                                             (what we refer to as the “Prior”) to see if it alone accounted
over conclusions and premises4 , respectively. Since we take
                                                                             for human reasoning patterns. It did not (Figure 3, column 1).
these functions to represent actual persons in a communica-
tive setting, we take premises to be selected from these dis-                    5 To a first approximation, increasing depth to greater than 1 pro-
tributions according to a Luce choice, or softmax, decision rule             duces results similar to increasing alpha.
                                                                                 6 In each possible situation, at least one of the four conclusions
with a parameter alpha that denotes the degree to which argu-
ment is chosen optimally (Luce, 1959). This takes the distri-                will be true. In fact, since the four possible quantifiers form two
                                                                             pairs of logical contradictions, exactly two conclusions will be true
bution, raises it to a power alpha and renormalizes. As depth                in each situation. For example, all and not all cannot both be true,
                                                                             but one must be true. The same is the case for none and some.
    4 As   a first pass, we consider the alternative premises generated          7 Since the response format in the meta-analysis varied across
by premise-prior to be the set of all premises of the same term or-          studies, the number of valid syllogisms was also not the same. Here
derings, i.e. alternative quantifiers, keeping the structure of the sen-     we count as valid only the syllogisms that would have been consid-
tences fixed.                                                                ered valid in all studies.
                                                                         1576

                                                                     model is able to accommodate more than one plausible con-
                                                                     clusion. Example [4] in Figure 2 is one such example. This
                                                                     is a syllogism with a valid conclusion, but one which people
                                                                     find difficult to draw. The literal reasoner model tells us why:
                                                                     in many of the possible situations in which the premises are
                                                                     true, a none conclusion is true. In addition, none is a difficult
                                                                     conclusion to convey in an argument—relative to not all—
                                                                     and so the pragmatic Bayesian strengthens the plausible but
                                                                     invalid none.
                                                                         Though this is encouraging qualitative data, there are a
                                                                     number of syllogisms for which reasoning patterns are not
                                                                     accounted for by the pragmatic Bayesian reasoner. Many of
                                                                     these are syllogisms use two negative quantifiers (not all or
                                                                     none) as the premises. For these arguments, the predictions
                                                                     of the literal reasoner do not differ appreciably from the pre-
                                                                     dictions of the Prior (Figure 2, [5]), because the rarity prior
                                                                     assumes most relations will be false to begin with.
Figure 2: Five example syllogisms. [1] Literal reasoner has
no preference among equally valid conclusions; the symme-            Model fit
try is broken by the pragmatic reasoner who considers the            To assess our models’ quantitative fits we examine corre-
argument in the space of possible arguments. [2] Literal rea-        lations across all 256 data points (64 syllogisms x 4 con-
soner alone captures the modal response and pragmatics en-           clusions), shown in Figure 3. The Prior’s predictions are
riches the quantitative fit. [3] Relatively informative premises     the same for all syllogisms and the overall fit is poor (r =
suggest some is the most likely interpretation. [4] Models are       0.36). After conditioning on the truth of the premises, the
able to capture multiple preferred conclusions. [5] Models do        model is able to make graded responses. These responses
poorly in matching subjects’ responses in an uninformative,          are a reflection of the types of situations consistent with the
invalid syllogism.                                                   premises. The overall correlation is appreciably higher (r =
                                                                     0.64). Among valid conclusions, however, (squares in Fig-
                                                                     ure 3) the fit is terrible (r = -0.20 for valid conclusions only).
Since not all X are Y is the most likely conclusion to be true,      This is a direct consequence of the reasoner’s literalness: the
the Prior matches only the syllogisms with a not all modal           model has no preference among multiple valid conclusions,
response. The literal Bayesian reasoner matches the modal            since a valid conclusion – by definition – is one which is true
response on 37 of the 64 syllogisms. The 29 syllogisms for           in every situation in which the premises are true8 .
which not all was the modal response are qualitatively unaf-             This symmetry is broken by the reasoner who interprets the
fected. The model also matches 8 syllogisms for which some           premises as coming from a pragmatic experimenter (Figure 3,
and none are favored (e.g., Figure 2, [2]). Probabilistic rea-       column 3), and the overall fit improves (r = 0.77). The model
soning introduces gradation to inference which accounts for          is now able to make graded responses among valid conclu-
an appreciable portion of the variance.                              sions (r = 0.77 for valid conclusions only).
   Conversational pragmatics can enrich the meaning of the
premises given to the pragmatic reasoner by considering                                Generalized quantifiers
“why has the experimenter produced this argument — these             Our model is based on a truth-functional semantics and as
premises — given that she may have given other arguments?”           such, it is able to accommodate any quantified sentence with a
The pragmatic Bayesian maximally-prefers the modal re-               truth-functional meaning. The meaning of generalized quan-
sponse of subjects for 43 out of 64 syllogisms. As well, it          tifiers like “most” and “few” is a topic of debate in formal
picks up on some of the subtle phenomena present in syllo-           semantics, but can be modeled to a first approximation as a
gistic reasoning. Example [3] in Figure 2 is one such case.          thresholded function. As a first test of the generality of the
The premises considered literally are relatively uninforma-          model, we define most and few by a threshold of 0.5 such
tive. The literal reasoner is very similar to the Prior (not         that “most As are Bs” is true if more than half of the As are
shown in Figure 2; but see Figure 3, column 1). Many ar-             Bs. Once we have added these lexical items, the Bayesian
guments in the syllogistic space, however, do not update the         reasoning models extend naturally. We compare our model
prior substantially. As such, the most probable conclusion           predictions to two studies carried out by Chater and Oaksford
given all arguments is not all X are Y. Since the argument in        (1999) on syllogisms using the generalized quantifiers most
[3] is more informative relative to others (e.g. the argument in
                                                                         8 An upper bound of 50 percent endorsement emerges from the
[5]), the most likely intention of the imagined experimenter
                                                                     fact that the 4 quantifiers form 2 sets of logical contradictions. Each
was to convey that some A are C.                                     pair of quantifiers has something true in each situation; thus, the
   In addition to capturing many of the modal responses, the         maximum endorsement after normalization is 50.
                                                                 1577

Figure 3: Human subject percentage endorsement vs. model predictions. Columns (from L to R): predictions based only on the
prior—P(conclusion); literal Bayesian reasoner—P(conclusion | premises); and the pragmatic Bayesian reasoner (see text).
and few e.g. Most artists are beekeepers; Few chemists are                                         Discussion
beekeepers. Participants were told to indicate which, if any,
                                                                         The inspiration for the pragmatic Bayesian reasoning model
of the four quantifier conclusions followed from the premises
                                                                         comes from the idea that syllogistic reasoning cannot be dis-
and were allowed to select multiple options. The set of syl-
                                                                         entangled from language understanding. Natural language se-
logisms was divided into two experiments to avoid subject
                                                                         mantics alone seems to be insufficient to explain the variabil-
fatigue.
                                                                         ity in reasoning, however. We have shown that a combination
   We find good correspondence between the experimen-                    of semantics and conversational pragmatics provides insight
tal data and the model, even with only a local parameter                 into how people reason with syllogistic arguments.
search9 (Figure 4). In Experiment 1, the quantifiers all,                   A recent meta-analysis carved the space of reasoning theo-
most, few, and not all were used. In Experiment 2, the                   ries into three partitions: those based on models or diagram-
quantifiers most, few, some, and none were used. Note                    matic reasoning, those based on formal logical rules, and
again the total number of syllogisms in an experiment is 64.             those based on heuristics (Khemlani & Johnson-Laird, 2012).
  Model            matchesExp1 matchesExp2 rExp1 rExp2                   We see the space slightly differently. In one dimension, theo-
  Prior                  23                23          .55      .34      ries are based on the direct application of derivation rules—be
  Literal                42                36          .79      .65      they heuristic or logical—or they are based on the construc-
  Pragmatic              47                35          .83      .67      tion of concrete representations or models. In another dimen-
                                                                         sion, theories may fundamentally be interested in deductive
   The fit is appreciably better for Experiment 1 than for Ex-
                                                                         validity or probabilistic support. This theoretical partition-
periment 2, and the same was true for the Probability Heuris-
                                                                         ing places the Bayesian reasoning models presented here in a
tics Model (r = 0.94 vs r = 0.63). Overall, the proportion of
                                                                         previously unexplored quadrant of the two-dimensional the-
no valid conclusion responses in the experimental data, which
                                                                         oretical space described: we consider probabilistic reasoning
we do not model, was much higher in Experiment 2 than in
                                                                         over concrete situations.
Experiment 1. This may explain why the pragmatic reasoner
                                                                            Mental Models Theory (MMT) was offered to capture the
tends to give high endorsement to many conclusions which
                                                                         intuition that people are able to reason about sets of things
people do not (Figure 4, rightmost scatterplot). A model that
                                                                         explicitly and with respect to context by constructing mental
takes into account NVC may alleviate this effect.
                                                                         representations of individuals over which to reason. The sit-
                                                                         uations described in our computational models are analogous
                                                                         to mental models. To address the problem of determining
    9 n_objects fit to 6, br to 0.30, alpha to 4.75. The words “most”    which models come into existence, however, MMT relies on
and “few” might pragmatically implicate sets of substantially larger     a number of complex heuristics. By contrast, we derive a dis-
size, and thus the data might be captured better by searching over a     tribution over models (or situations) from natural language
larger parameter space for n_objects. In this analysis, we examined
only a small search radius around the parameter estimates used to        semantics and pragmatics, with no further assumptions.
model the meta-analysis data.                                               Chater and Oaksford (1999) introduced the Probability
                                                                     1578

Figure 4: Human subject percentage endorsement vs. model fits for 2 experiments using generalized quantifiers. Experiment 1
(left) used the quantifiers {all, most, few, not all}. Experiment 2 (right) used the quantifiers {most, few, some, none}.
Heuristic Model (PHM) which derives a set of probabilis-             tally, syllogisms are a tool used to convince others. The re-
tic rules for syllogistic reasoning; to account for informativ-      sults of the pragmatic Bayesian reasoner recast the ancient
ity and other effects, the PHM then augments these proba-            idea that human reasoning behavior is as much reason as it
bilistic rules with a complex set of heuristics (for example,        is human. Gauging degrees of truth or plausibility alone is
informative-conclusion heuristics). Our model differs in two         not sufficient. An agent needs to be posited at the other end
respects. First, the probabilistic “rules” emerge from the se-       of the line so that a conclusion makes sense; so that an argu-
mantics of quantifiers by reasoning about situations. Second,        ment may convince!
we strengthen inferences by employing previously-proposed
formalisms for pragmatic reasoning. This gives rise to many                                   References
of the same effects, such as informativity, without postulating      Chater, N., & Oaksford, M. (1999). The Probability Heuris-
heuristics de novo.                                                     tics Model of Syllogistic Reasoning. Cognitive psychology,
   The syllogistic reasoning task involves reading a pair of            258, 191–258.
sentences and producing or evaluating a conclusion. We have          Frank, M. C., & Goodman, N. D. (2012). Quantifying prag-
considered the pragmatics of argument interpretation—the                matic inference in language games. Science, 336, 1–9.
problem the reasoner faces when given some sentences. Nat-           Goodman, N. D., Mansinghka, V. K., Roy, D. M., Bonawitz,
ural language pragmatics may also enter into the production             K., & Tenenbaum, J. B. (2008). Church : a language for
of a conclusion (for tasks that require production). The rea-           generative models. Uncertainty in Artificial Intelligence.
soner is likely tempted to produce conclusions which are not         Goodman, N. D., & Stuhlmüller, A. (2013). Knowledge
only true but also good, or informative. At the same time, the          and implicature: modeling language understanding as so-
option of “no valid conclusion”—of saying nothing—looms                 cial cognition. Topics in cognitive science, 5(1), 173–84.
large for the reasoner. We leave for future work the incorpo-        Horn, L. R. (1989). A natural history of negation. Chicago:
ration of production of informative conclusions as well as the          University of Chicago.
ability to say “nothing follows”.                                    Khemlani, S., & Johnson-Laird, P. N. (2012). Theories of
                                                                        the syllogism: A meta-analysis. Psychological bulletin,
                          Conclusion                                    138(3), 427–57.
This is early work and we have found promising evidence,             Luce, R. D. (1959). Individual choice behavior. New York,
both qualitative and quantitative, that this framework will al-         NY: Wiley.
low for a more explicit understanding of syllogistic reason-         Oaksford, M., & Chater, N. (1994). A rational analysis of
ing.                                                                    the selection task as optimal data selection. Psychological
   A major virtue of the pragmatic reasoning framework is               Review, 101(4), 608–631.
that it extends naturally to incorporate any terms for which         Roberts, C. (2004). Information structure in discourse. Sem-
a truth-functional semantics can be given. For instance, we             anatics and Pramatics(5), 1-69.
tested the model on most and few using the simplest, most            Roberts, M. J., Newstead, S. E., & Griggs, R. A. (2001).
standard semantics (most is more than half, etc). It is likely          Quantifier interpretation and syllogistic reasoning. Think-
that these quantifiers actually have more complex semantics,            ing & Reasoning, 7(2), 173–204.
but even so we accounted for a significant fraction of the data.     Störring, G. (1908). Experimentelle untersuchungen uber
   In this framework, a syllogism is read as an argument given          einfache schlussprozesse. Arch. f. d. ges. Psychol, 1-127.
as a part of discourse between interlocutors. Indeed, this is
how syllogisms were used in the time of Aristotle and in the
long tradition of scholastic philosophers since. Fundamen-
                                                                 1579

