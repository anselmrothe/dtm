UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simplicity and Goodness-of-Fit in Explanation: The Case of Intuitive Curve-Fitting
Permalink
https://escholarship.org/uc/item/4xg79414
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Johnson, Samuel
Jin, Andy
Keil, Frank
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                      University of California

                                   Simplicity and Goodness-of-Fit in Explanation:
                                             The Case of Intuitive Curve-Fitting
                                         Samuel G. B. Johnson (samuel.johnson@yale.edu)
                                            Department of Psychology, Yale University
                                          2 Hillhouse Ave., New Haven, CT 06520 USA
                                                     Andy Jin (ajin@live.unc.edu)
                          Department of Psychology, University of North Carolina, Chapel Hill
                                       235 E. Cameron Ave., Chapel Hill, NC 27599 USA
                                                 Frank C. Keil (frank.keil@yale.edu)
                                            Department of Psychology, Yale University
                                          2 Hillhouse Ave., New Haven, CT 06520 USA
                              Abstract                                 reasoning (Lombrozo, 2007). The posterior odds favoring
   Other things being equal, people prefer simpler
                                                                       the simple explanation [H1] over the complex explanation
   explanations to more complex ones. However, complex                 [H2,H3] is the product of the prior odds [P(H1)/P(H2,H3)],
   explanations often provide better fits to the observed data,        representing the probability of each hypothesis being true
   and goodness-of-fit must therefore be traded off against            before observing the evidence, and the likelihood ratio
   simplicity to arrive at the most likely explanation. In three       [P(E1,E2|H1)/P(E1,E2|H2,H3)], representing the probability
   experiments, we examine how people negotiate this trade-            of the evidence being observed under each hypothesis. If
   off. As a case study, we investigate laypeople’s intuitions         we assume that the simple explanation (influenza) and the
   about curve-fitting in visually presented graphs, a domain
   with established quantitative criteria for trading off              complex explanation (hay fever and Strep throat) lead to
   simplicity and goodness-of-fit. We examine whether people           both symptoms with the same probability, then the
   are well-calibrated to normative criteria, or whether they          likelihood ratio is 1. Lombrozo (2007) noted, however,
   instead have an underfitting or overfitting bias (Experiment        that the prior odds often favor simple explanations: If H1,
   1), we test people’s intuitions in cases where simplicity and       H2, and H3 have equal base rates, then P(H2,H3) =
   goodness-of-fit are no longer inversely correlated                  [P(H1)]2. Since the complex explanation has a lower prior,
   (Experiment 2), and we directly measure judgments
                                                                       the posterior odds favor the simpler explanation.
   concerning the complexity and goodness-of-fit in a set of
   curves (Experiment 3). To explain these findings, we posit             However, the posterior odds do not always favor the
   a new heuristic: That the complexity of an explanation is           simpler explanation, because the evidence is often made
   used to estimate its goodness-of-fit to the data.                   more likely (or, put differently, is “better modeled”) by a
                                                                       complex explanation than by a simple explanation,
   Keywords: Explanation; causal reasoning;            intuitive
   statistics; simplicity; diagnostic reasoning.                       leading the likelihood ratio to favor the complex
                                                                       explanation. For example, consider a patient who has a
                          Introduction                                 runny nose and a stomach ache. One explanation is that
                                                                       the patient has only a cold, which would make a runny
The simplest explanation is often the most likely to be                nose very likely and would make a stomach ache
true. Suppose, for example, that a patient has two                     plausible (but not especially likely). Alternatively, the
symptoms: a runny nose (E1) and a cough (E2). Three                    patient could have both a cold and a stomach virus, which
diagnoses are available: influenza (H1), which explains                would make both symptoms very likely. The more
both symptoms; Hay fever (H2), which explains only the                 complex explanation has a lower prior, but a higher
runny nose; and Strep throat (H3), which explains only the             likelihood. This is often the case: The more (generative)
cough. If these diseases are equally common, then any                  causes invoked by an explanation, the lower its prior, but
reasonable doctor would surely posit influenza (H1) to                 the more likely it is to predict the observed effects
explain both symptoms, rather than hay fever to explain                because each added cause has the potential to produce the
the runny nose and Strep throat to explain the cough (H2               observed effects. How do people negotiate this trade-off
& H3). Laypeople share these intuitions: Other things                  between simplicity and goodness-of-fit?
being equal, adults and children prefer explanations                      One possibility is that people would require
invoking fewer causes and believe they are more likely to              disproportionate evidence to abandon a simpler
be true (Bonawitz & Lombrozo, 2012; Lombrozo, 2007).                   explanation in favor of a more complex one. Lombrozo
   These intuitions relate to normative probabilistic                  (2007) found that people use a simplicity heuristic,
                                                                  701

assigning higher priors to simpler explanations, with              result in underfitting—failing to take advantage of all the
many participants recalling simpler explanations as                information available in the original dataset for
having higher base rates than warranted by the data. This          identifying the underlying trend, again leading to poor
heuristic led to non-normative explanatory preferences             predictions. This trade-off between simplicity and
when probabilities were manipulated explicitly: When a             goodness-of-fit is made by optimizing model selection
simple and complex explanation had equal priors, 80% of            criteria known as Akaike’s Information Criterion (AIC)
participants preferred the simple explanation, and 40% of          and the Bayesian Information Criterion (BIC), which
participants preferred the simple explanation even when it         reward models for having good fits to the data and
was 10 times less likely than the complex explanation.             penalize models for using larger numbers of parameters.
   However, people could also use a complexity heuristic,             To see whether people make this trade-off in
wherein complexity is used to estimate the likelihood or           accordance with normative model selection criteria, we
goodness-of-fit. Since simpler explanations (i.e., invoking        generated a set of 16 scatterplots, 8 of which had
fewer generative causes) often have higher prior                   normatively quadratic fits according to both AIC and
probabilities, and complex explanations (i.e., invoking            BIC, and 8 of which had normatively cubic fits according
more generative causes) often have higher likelihoods,             to both AIC and BIC. Participants were asked to select the
this pair of opponent simplicity and complexity heuristics         best curve for each scatterplot from multiple choice
may at times allow for negotiation of the                          options of degrees 1 through 4 (see Figure 1-A). Two
simplicity/goodness-of-fit trade-off in a computationally          wordings were used to elicit these judgments, between
tractable manner, without the need for explicit                    subjects—asking which curve “best represents” the
probabilistic reasoning. When in operation, a complexity           underlying trend, and which curve would “best predict” a
heuristic would be in tension with a simplicity heuristic,         different set of data from the same population. The former
potentially leading to no bias or even a complexity bias.          wording might elicit more intuitive judgments, while the
   Here, we examined laypeople’s intuitions about curve-           latter wording might make the task clearer to participants.
fitting, a domain with established quantitative criteria for          If people use the complexity of a curve as a cue for
trading off these explanatory virtues (Forster & Sober,            estimating its fit to the data, we might find an overfitting
1994). Although curve-fitting and verbal explanation               bias. Alternatively, it is plausible that people would
tasks such as diagnostic reasoning are superficially quite         instead have an underfitting bias, since simpler
different, they share deep formal similarities in that both        explanations are assigned high priors in a biased manner
tasks require trade-offs among explanatory virtues.                (Lombrozo, 2007). This would also be consistent with
Intuitions about curve-fitting are therefore a useful test         Little and Shiffrin’s (2009) finding of an underfitting bias
case for explanatory reasoning more broadly—one where              in the generation of curves for scatterplot data. Although
the virtues of simplicity and goodness-of-fit are                  generating hypotheses (here, best fit curves) involves
operationalized in an especially direct way.                       computational challenges beyond evaluating hypotheses,
   In these studies, we collected judgments of what family         this result nonetheless motivates the possibility that
of curve was most appropriate when fitting scatterplot             underfitting would extend to an evaluation task.
data, comparing those judgments to normative
benchmarks (Experiment 1) and to judgments in matched              Method
cases where simplicity and goodness-of-fit no longer               Participants We recruited 80 participants from Amazon
competed (Experiment 2). We also sought direct evidence            Mechanical Turk; five were excluded from analysis
for a complexity heuristic by measuring both perceived             because they failed a check question (see below).
complexity and perceived goodness-of-fit for a set of              Materials The materials were 16 datasets displayed in
curves (Experiment 3). If people use a complexity                  scatterplots, and their best fit curves of degrees one
heuristic, we would expect an illusory increase in                 through four (see Figure 1-A). Each scatterplot plotted a
perceived goodness-of-fit for more complex curves.                 dataset including 41 data points, sampled at intervals of
                                                                   0.25 from 0 to 10 on the x-axis. The y-values were
                      Experiment 1                                 determined by taking the values of second and third
Consider the task of choosing how complex of a curve to            degree polynomials and adding Gaussian noise to each
use in fitting a set of datapoints (see Figure 1). It is           data point. Two quadratic functions and two cubic
assumed that these data were produced by both an                   functions were used, and four random datasets were
underlying signal (the same each time a sample is drawn            generated from each of these functions—two at relatively
from the population) and random noise (which is different          high levels of noise, and two at relatively low levels of
each time a new sample is drawn). Choosing a very                  noise (mean R2 = .279 vs. .475). In addition, the best fit
complex curve will result in a tight fit to the current set of     curves of degrees one through four always differed from
data points, but such a curve is likely to overfit—fitting         each other by at least 7% at one or more points, to ensure
the noise in addition to the underlying trend, resulting in        that the best fit curves could be discriminated from each
poor predictive value for a new sample from the same               other. In addition, the normative complexity of the data
population. In contrast, choosing a very simple curve may          was always the same as that of the data-generating
                                                               702

                       (A) Experiment 1                                             (B) Experiment 2
   Figure 1: Example stimulus items: (A) An item from Experiment 1. (B) The matched version of that item from Experiment 2.
      The top panels show scatterplots without curves, and the bottom panels show response options (curves of degrees 1–4).
function. For the quadratic functions, the mean R2 was              for a different sample of [mineral name]” in the predicts
.276, .390, .411, and .434 for the best fit curves of degrees       condition. The datasets were presented in a random order,
1–4, respectively (and the quadratic fit is best according          and the response options were randomized for each item.
to AIC and BIC), and for the cubic curves, the mean R2                 After the main task, participants completed a check
was .183, .364, .469, and .490 for fits of degrees 1–4 (and         question (a dataset for which the quadratic fit was clearly
the cubic fit is best according to AIC and BIC).                    optimal). Five participants were excluded from data
Procedure Participants were instructed that they would              analysis because they answered this question incorrectly.
see sets of data plotting the relationship between two
properties of minerals called ‘caltedness’ and ‘limency’,           Results and Discussion
and that each dataset would correspond to a different               The multiple choice options corresponded to the best fit
mineral. Fictitious physical properties were chosen                 curves for each dataset for degrees one through four, and
because participants would likely have prior expectations           therefore formed an interval scale from 1 to 4. Unbiased
(if any) of a linear relationship, providing a stronger test        performance on this task would yield a score of 2.5 on
against the possibility of overfitting.                             this scale (the midpoint), because half of the curves were
   For each dataset, participants were shown a scatterplot          of degree 2 and half were of degree 3. Instead,
(e.g., the top panel of Figure 1-A) and told that “The              participants selected curves with mean degree 2.72 (SD =
following scatter plot shows multiple measurements of               0.70), which is significantly greater than 2.5, t(74) = 2.74,
caltedness and limency for a sample of the mineral                  p = .008, d = 0.32. A mixed-model ANOVA with degree
[mineral name]. Each measurement is affected by both                (quadratic or cubic) and noise (high or low) as within-
the inherent relationship between caltedness and limency            subjects factors and wording (represents or predicts) as a
in [mineral name], as well as by random errors such as              between-subjects factor revealed only a main effect of
variability from sample to sample and imprecision in                degree, F(1,73) = 23.81, p < .001, ηp2 = .25, because
measuring equipment,” where a different mineral name                participants fit higher degree curves to the normatively
was given for each dataset. On the next page, participants          cubic (M = 2.85, SD = 0.76) than to the normatively
were presented with four multiple choice options (e.g., the         quadratic (M = 2.59, SD = 0.72) datasets. In particular,
bottom panel of Figure 1-B), each an image of the dataset           there was no main effect of wording, F(1,73) < 0.01, p =
(displayed in blue) with a best fit curve (displayed in             .97, ηp2 < .01, indicating that participants overfitted
black) overlaid, of degrees one through four. Between-              equally regardless of whether they were selecting the
subjects, participants were told either to select the option        curve that best represented the data or the curve that
“that you believe best represents the relationship between          would best predict a different set of data.
caltedness and limency for [mineral name]” in the                      Could these effects can be accounted for by a response
represents condition, or “that you believe would best               strategy such as random responding, centering, or
predict the relationship between caltedness and limency
                                                              703

response variation? Although there appears to have been           experiment (Exp. 1 or Exp. 2) and wording (represents or
some regression to the mean (hence the slight underfitting        predicts) as between-subjects factors revealed only a main
for the cubic curves), these strategies would not lead to         effect of experiment, F(1,136) = 24.15, p < .001, ηp2 =
biased responses above the midpoint. Since the normative          .15. There was no main effect of wording, F(1,136) =
responses were degrees 2 and 3, and response options              0.18, p = .67, ηp2 < .01, nor an interaction of wording with
were curves of degrees 1–4, these strategies would lead to        experiment, F(1,136) = 0.22, p = .64, ηp2 < .01, showing
an unbiased mean near the midpoint of the scale.                  that these effects did not depend on whether participants
   This overall overfitting bias is surprising in light of an     were selecting the curve that best represented the data or
underfitting bias in curve generation (Little & Shiffrin,         would best predict a different set of data.
2009) and the tendency to overestimate the priors of                 These results are consistent with Lombrozo’s (2007)
simple explanations (Lombrozo, 2007). This bias may               finding that simplicity is used as a proxy for prior
occur because people use the complexity of a curve as a           probability. This experiment also acts as a control for
cue to goodness-of-fit, compensating for the simplicity           Experiment 1, showing that the overfitting found in
heuristic that would push people toward underfitting.             Experiment 1 occurred as a consequence of the increasing
However, an alternative explanation is that the simplicity        values of R2 associated with increasingly complex
heuristic—that is, using simplicity to estimate prior             curves—when R2 was approximately constant between
probability—is not at work in this task, and people would         curves, people tended to choose relatively simple curves.
choose relatively complex curves regardless of how well              Nonetheless,     participants     still   chose    curves
they fit the data. We test this possibility in Experiment 2.      considerably above the floor of the scale—the mean of
                                                                  2.12 indicates that participants chose quadratic curves on
                      Experiment 2                                average. Although scale-use strategies (e.g., centering or
It is a mathematical truism that the best fit curve of a          response varying) may at least partially account for this
higher-degree polynomial family will be a better fit to the       result, one might nonetheless expect participants to more
data than the best fit curve of a lower-degree polynomial         frequently choose linear curves, since they were both the
family. However, it is not the case that any curve of             simplest and the best-fitting curves for each scatterplot.
higher degree will be a better fit than any curve of lower        One possibility is that people’s estimates of goodness-of-
degree. By randomly perturbing the datasets used in               fit were distorted by the complexity of the curves. If
Experiment 1, we generated a new set of scatterplots for          people used complexity to estimate goodness-of-fit, then
which the curves used in Experiment 1 no longer                   they might choose more complex curves simply because
exhibited the characteristic property that more complex           they believed they were better fits to the data. This
curves are better fits to the data (see Figure 1-B). If           possibility was tested in Experiment 3.
people use simplicity as a proxy for prior probability
(Lombrozo, 2007) in this task, then they should no longer                        Experiments 3A and 3B
choose complex curves for these scatterplots. In contrast,        To test directly whether complexity is used as a heuristic
if people choose relatively complex curves for any dataset        for estimating goodness-of-fit, participants in Experiment
(regardless of actual fit), then the results of Experiment 2      3A provided their estimates of how well the curves fit the
would be similar to Experiment 1.                                 data for the 64 curves used as response options in
                                                                  Experiment 2. Because perceived complexity is not
Method                                                            necessarily a linear function of the curve’s degree, we
Participants We recruited 80 participants from Amazon             collected perceived complexity judgments in Experiment
Mechanical Turk; 15 were excluded because they failed             3B. We expected that both actual goodness-of-fit (as
the check question used in Experiment 1.                          measured by R2) and perceived complexity would
Materials The curves were identical to those used in              independently influence goodness-of-fit judgments.
Experiment 1, but the datasets were perturbed randomly
so that the quartic curves were no longer the best fits.          Method
Instead, for each dataset, the linear curve was a slightly        Participants We recruited 120 participants from Amazon
better fit than the quadratic curve, and so forth, subject to     Mechanical Turk for Experiment 3A, and 40 participants
the constraint that R2 for the linear curve be no more than       for Experiment 3B. (A greater number of participants
.03 greater than R2 for the quartic curve (see Figure 1-B).       were necessary for Experiment 3A due to lower between-
Procedure The procedure was the same as Experiment 1.             items variance.) Seven participants from Experiment 3A
                                                                  and zero participants from Experiment 3B were excluded
Results and Discussion                                            because they failed check questions (see below).
Even though the curves used in Experiment 2 were                  Materials The materials for Experiment 3A were the 64
identical to those in Experiment 1, participants selected         scatterplots and curves of degrees 1 through 4 used as
curves of mean degree 2.12 (SD = 0.74), which is                  response options in Experiment 2 (see Figure 1-B).
significantly below the midpoint of the scale, t(64) =            Therefore, the R2 values were slightly higher for the linear
−4.17, p < .001, d = −0.52. A two-way ANOVA with                  than for the quartic curves (see Table 1). These curves
                                                              704

   Table 1: Means and SDs in Experiments 3A and 3B.                  though they actually had the highest R2 values (albeit only
                                                                     slightly). Quadratic and cubic curves were judged the best
Degree                   1         2          3          4           fits, and quartic curves somewhat worse. Possible reasons
Goodness-of-Fit       51.47     54.02      54.06      52.48          for this non-monotonic pattern are discussed below.
  Exp. 3A             (19.55)   (19.17)    (19.18)    (19.18)           Participants in Experiment 3B used degree to judge
Complexity            9.90      51.64      63.94      71.40          complexity, F(3,117) = 297.29, p < .001, ηp2 = .88, giving
  Exp. 3B             (1.22)    (3.57)     (7.36)     (5.04)         higher complexity ratings with increasing degree (see
Actual R2             .523      .515       .507       .499           Table 1). However, degree had diminishing returns on
Arclength             30.36     53.01      63.16      68.19          perceived complexity, resulting in a large boost between
                                                                     linear and quadratic curves, but a more modest boost
also varied in noise, since higher and lower noise datasets          between cubic and quartic curves.
were used in Experiments 1 and 2. The materials for                     These results are not what would be expected if
Experiment 3B were the same 64 curves, but with the                  participants were judging goodness-of-fit based solely on
datapoints omitted.                                                  R2. One possibility is that the nonmonotonic pattern in
Procedure For Experiment 3A, participants were                       Experiment 3A occurred because participants used both
instructed that for each graph, they would “judge how                perceived complexity and the actual R2 to estimate
closely the black line fits the blue data points” and were           goodness-of-fit. According to this explanation, since there
given examples of two identical quadratic curves, one                was a large increase in perceived complexity between the
with data that it fit poorly and the other with data that it fit     linear and quadratic curves but only a small decrease in
well. They were then shown each of the 64 scatterplots               actual R2, participants would judge the quadratic curves
with best fit lines, and rated “how closely you think the            better fits than the linear curves. In contrast, there was a
black line fits the blue data points” on a scale from 0              much smaller increase in perceived complexity between
(“Very poor fit”) to 100 (“Very close fit”). After the main          the cubic and quartic curves but the same decrease in
task, participants responded to two check questions with             actual R2. This would lead to the overall decrease in
linear curves that were, respectively, very close and very           perceived goodness-of-fit found in Experiment 3A.
poor fits. Participants who rated the close fitting curve no            As a first test of this possibility, we computed for each
more than 20 points higher than the loose fitting curve              of the 16 datasets the partial correlation between
were excluded from analysis.                                         simplicity ratings (Exp. 3A) and goodness-of-fit ratings
   For Experiment 3B, participants were instructed that for          (Exp. 3B) across degrees, controlling for actual R2. The
each graph, they would “judge how complex the line is”               mean partial correlation for each dataset was r = .54,
and told that “relatively simple curves can be described in          which is significantly different from 0 in a one-sample t-
a small amount of information, while relatively complex              test, t(15) = 3.66, p = .002, d = 0.92. This shows that
curves require more information to describe.” Participants           when R2 is held constant, more complex curves tend to be
were given examples of a less complex (linear) curve and             rated better fits to the data.
a more complex (quadratic) curve. They were then shown                  We followed up with a more fine-grained path analysis
each of the 64 best fit lines without the datapoints, and            (Kline, 1998) with the 64 scatterplots as the units of
rated “how complex you think the line is” on a scale from            analysis, and mean ratings of goodness-of-fit (from Exp.
0 (“Very simple”) to 100 (“Very complex”). After the                 3A) and complexity (Exp. 3B) as endogenous (dependent)
main task, participants responded to two check questions             variables. To explore other factors that might affect
with curves of degrees 1 and 5. Every participant rated the          complexity ratings, we computed each curve’s arclength
curve of degree 5 more complex than the curve of degree              and used this as an exogenous (predictor) variable, along
1 by at least 20 points, so no participants were excluded            with actual R2 and each curve’s degree.
from analysis.                                                          As shown in the path diagram (Figure 2), degree (β =
                                                                     .69, p < .001) and arclength (β = .33, p < .001) both
Results and Discussion                                               contributed to perceived complexity, with curves of
Participants in Experiment 3A based their goodness-of-fit            higher degree and greater arclength receiving higher
ratings both on the noisiness of the data and on the                 complexity ratings. Most importantly, perceived
complexity of the curve (see Table 1 for item means and              complexity was a significant predictor of goodness-of-fit
SDs). A repeated measures ANOVA was conducted with                   ratings (β = .57, p = .005) after all other variables were
degree (linear, quadratic, cubic, or quartic) and noise              taken into account, showing that people used complexity
(high or low) as within-subjects variables. There was a              as a proxy for goodness-of-fit. The actual R2 also
main effect of noise, F(1,112) = 938.96, p < .001, ηp2 =             contributed to goodness-of-fit ratings (β = .77, p < .001).
.89, because the high noise curves were judged looser fits           Curiously, controlling for the other variables, curves of
than the low noise curves (M = 35.35, SD = 13.14 vs. M =             greater arclength were actually perceived as worse fits to
70.66, SD = 9.99). More interestingly, however, there was            the data (β = −.76, p < .001). This may have occurred
also a main effect of degree, F(3,336) = 9.68, p < .001,             because the relative density of the datapoints compared to
ηp2 = .08, with linear curves judged the loosest fit even            the length of the curve is lower for longer curves. The
                                                                 705

                                                                 of how well a curve fit a set of datapoints were influenced
                                                                 by the perceived complexity of the curve.
                                                                    Why might people use a complexity heuristic? One
                                                                 possibility is that people are sensitive to the normative
                                                                 structure of the environment, where more complex
                                                                 explanations (in the sense of having more generative
                                                                 causes) often provide better fits to the data. Alternatively,
                                                                 this heuristic may involve pragmatic or pedagogical
                                                                 inferences. Since more complex explanations are selected
         Figure 2: Path diagram for Experiment 3.                from a larger hypothesis space compared to simpler
      Paths marked with ** are significant at p < .01.           explanations, people may infer that more complex
                                                                 explanations are unlikely to be selected unless there was a
negative association between arclength and perceived fit         reason for selecting that one in particular—in particular,
speaks against the possibility that the relationship             that it had a better fit to the data. Converging evidence
between perceived complexity and fit occurred because            from other tasks such as verbal diagnostic reasoning can
participants were judging absolute distance to the curve         help to tease apart these possible accounts.
rather than vertical distance (measured by R2). If that             Evidence from other tasks can also help to clarify the
were the case, one would expect arclength to be positively       relationship between these findings and other lines of
associated with fit ratings, since longer curves have more       research. For instance, a complexity heuristic could in
variability along the y-axis and hence more opportunities        part explain why people seem to prefer verbal
for R2 and absolute distance to differ.                          explanations involving more technical vocabulary
   These results support our hypothesis that complex             (Weisberg, Keil, Goodstein, Rawson, & Gray, 2008).
explanations create an illusion of goodness-of-fit, at least     Another direction for future work is to clarify the
in intuitive curve-fitting. Increases in perceived               relationship     between     cognitive    and     perceptual
complexity were accompanied by increases in perceived            explanation. The results of Experiment 2 suggest a visual
goodness-of-fit, even when factors such as degree,               simplicity heuristic complementing Lombrozo’s (2007)
arclength, and actual goodness-of-fit are controlled for.        results from verbal tasks. This raises the possibility that
                                                                 explanatory heuristics may be used widely across
                   General Discussion                            cognition, and perhaps even perception.
In three experiments, we investigated how people
negotiate the trade-off between simplicity and goodness-                            Acknowledgments
of-fit in explanations by testing intuitions about curve-        This research was supported by a grant from the National
fitting. In Experiment 1, participants showed an overall         Institutes of Health to F.C. Keil. We thank the members
overfitting bias—a surprising result in light of                 of the Cognition & Development Lab for helpful
Lombrozo’s (2007) finding that people assign higher prior        feedback.
probabilities to simple explanations in a biased manner. In
Experiment 2, we showed that when simplicity and                                        References
goodness-of-fit no longer compete, people prefer simpler
                                                                 Bonawitz, E.B., & Lombrozo, T. (2012). Occam’s rattle:
curves, consistent with Lombrozo (2007). To explain
                                                                    Children’s use of simplicity and probability to constrain
these findings, we hypothesized that people use a
                                                                    inference. Developmental Psychology, 48, 1156–1164.
complexity heuristic, in which complexity is used to
                                                                 Forster, M., & Sober, E. (1994). How to tell when
estimate goodness-of-fit. In Experiment 3, we provided
                                                                    simpler, more unified, or less ad hoc theories will
direct evidence for this claim, with more complex curves
                                                                    provide more accurate predictions. The British Journal
judged better fits to the data, after factors such as the
                                                                    for the Philosophy of Science, 45, 1–35.
actual goodness-of-fit are taken into account.
                                                                 Kline, R.B. (1998). Principles and practice of structural
   Overall, these findings support an opponent heuristic
                                                                    equation modeling (1st Ed.). New York: Guilford Press.
account of simplicity preferences, with simplicity used in
                                                                 Little, D.R., & Shiffrin, R.M. (2009). Simplicity bias in
two opposing ways when evaluating explanations. First,
                                                                    the estimation of causal functions. Proceedings of the
people appear to assign higher prior probabilities [P(H)]
                                                                    31st Annual Conference of the Cognitive Science
to simpler explanations. Lombrozo (2007) showed this
                                                                    Society (pp. 1157–1162). Austin, TX: Cognitive
directly, with participants systematically overestimating
                                                                    Science Society.
the recalled base rates of simple explanations. Similarly,
                                                                 Lombrozo, T. (2007). Simplicity and probability in causal
participants in our Experiment 2 showed a simplicity
                                                                    explanation. Cognitive Psychology, 55, 232–257.
preference when goodness-of-fit was held constant.
                                                                 Weisberg, D.S., Keil, F.C., Goodstein, J., Rawson, E., &
Second, people appear to assign higher likelihoods
                                                                    Gray, J.R. (2008). The seductive allure of neuroscience
[P(E|H)] to complex explanations. We provided direct
                                                                    explanations. Journal of Cognitive Neuroscience, 20,
evidence for this claim in Experiment 3, where judgments
                                                                    470–477.
                                                             706

