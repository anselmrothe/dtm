UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Predicting Behavior from the World: Naive Behaviorism in Lay Decision Theory
Permalink
https://escholarship.org/uc/item/1pm9k1j7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Johnson, Samuel
Rips, Lance
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                        Predicting Behavior from the World:
                                    Naïve Behaviorism in Lay Decision Theory
                                      Samuel G. B. Johnson (samuel.johnson@yale.edu)
                                            Department of Psychology, Yale University
                                          2 Hillhouse Ave., New Haven, CT 06520 USA
                                          Lance J. Rips (rips@northwestern.edu)
                                        Department of Psychology, Northwestern University
                                          2029 Sheridan Road, Evanston, IL 60208 USA
                           Abstract                                 situational constraint), that the Mercury would leave
  Life in our social world depends on predicting and
                                                                    sufficient space for his Honda (an end-state). Using this
  interpreting other people’s behavior. Do such inferences          non-mentalistic, behaviorist system only requires seeking
  always require us to explicitly represent people’s mental         out and representing information about the world—and no
  states, or do we sometimes bypass such mentalistic                inferences about the mental states of the Mercury’s driver.
  inferences and rely instead on cues from the environment?            Infants can use world-based cues such as efficiency
  We provide evidence for such behaviorist thinking by              constraints to reason about behavior before achieving a
  testing judgments about agents’ decision-making under             representational theory of mind (Gergely & Csibra, 2003),
  uncertainty, comparing agents who were knowledgeable
  about the quality of each decision option to agents who           suggesting that a primitive, behaviorist system is present
  were ignorant. Participants believed that even ignorant           in infancy. The behaviorist system therefore seems to
  agents were most likely to choose optimally, both in              precede the mentalistic system in development (see also
  explaining (Experiment 1) and in predicting behavior              Povinelli & Vonk, 2004 on chimpanzee theory of mind).
  (Experiment 2), and assigned them greater responsibility          However, it is unclear whether the behaviorist system
  when acting in an objectively optimal way (Experiment 3).         used by infants is replaced by the mentalistic system that
  Keywords: Theory of mind; lay decision theory;                    we use as adults, or whether instead these systems coexist
  explanation; prediction; rationality.                             in adulthood. If these systems coexist, many of our
                                                                    everyday inferences about behavior may bypass mental-
                       Introduction                                 state inferences altogether, relying instead on directly
Sunny turned on his Honda’s right blinker as he drove               observable information about the world, coupled with
down Dixwell Avenue. The Mercury to his right slowed                more general assumptions such as the efficiency of
down, and Sunny changed lanes. In changing lanes,                   actions in achieving optimal end-states.
Sunny wagered with his life—gambling that the driver of                Here, we test the possibility of a behaviorist system by
the Mercury would leave enough space for his Honda to               studying judgments about agents making decisions under
enter the right lane—and he won. Indeed, his track record           uncertainty, contrasting inferences about knowledgeable
with such wagers is remarkable. How is Sunny able to                agents—those who know the efficacies of each option
make such successful predictions about others’ behavior?            under consideration—and inferences about ignorant
  One strategy that Sunny may have followed in this case            agents—those who do not know the efficacies of the
was to infer the driver’s behavior based on his or her              options. For example, consider Jill, who wants her hair to
inferred mental-states. That is, Sunny may have reasoned            smell like apples and is deciding which of three brands of
that the Mercury’s slowing down was a signal of the                 shampoo to purchase: one with a high probability of
driver’s intention to let him change lanes, based on the            leading to her goal (“Best”), one with a medium
driver’s assumed beliefs about road behavior and folk               probability (“Middle”), and one with a low probability
physics, and the driver’s assumed goals of being a good             (“Worst”). Which option will Jill choose?
road citizen and avoiding a collision. Using this                      Two principles could potentially be used for predicting
mentalistic system requires inferring and representing the          Jill’s choice. First, people might use the Efficiency
agent’s mental states, then predicting and interpreting             Principle (Dennett, 1987), which would lead Jill to
actions on the basis of those inferred mental states. This          choose Best—the optimal action relative to her goals.
seems to accord with how we typically experience the                This principle alone would not lead Jill to be any more
process of making behavior inferences in day-to-day life.           likely to choose Middle than to choose Worst, since both
  But Sunny could have reached the same conclusion                  are inefficient relative to Best. Second, people might use a
using a different strategy, inferring the Mercury’s                 Preference Principle, which would lead Jill to form
behavior based on observable states of the world. Sunny             preferences for the options in proportion to their quality,
may have inferred from the Mercury’s change in speed                and be more likely to choose more preferred options—
(an action), combined with the geometry of driving (a               that is, to be most likely to choose Best, less likely to
                                                              695

choose Middle, and least likely to choose Worst.                   also participated in another experiment, with the order of
   To see how this task can give evidence for a behaviorist        the experiments counterbalanced. Sixteen participants
system, first consider what a normative response pattern           were excluded from data analysis because they incorrectly
would be if people correctly use mental-state inferences.          answered more than 33% of a series of check questions
If Jill knows the probabilities of all three options (i.e., if     designed to ensure that participants had attended to the
she is a knowledgeable agent), then either the Efficiency          details of the vignettes (including whether the agent was
or the Preference Principle potentially apply, and we              knowledgeable or ignorant). However, including all
would certainly expect her to be more likely to choose a           participants does not qualitatively alter these results.
higher-quality option. On the other hand, if Jill does not            Participants read three vignettes. The agent’s choice
know the efficacies of the options (i.e., she is an ignorant       (Best, Middle, Worst) varied within-subjects across three
agent), then we should normatively conclude that she is            cover stories using a Latin square, and the agent’s
equally likely to choose any of the three options, because         knowledge about the options (knowledgeable or ignorant)
she does not have any relevant beliefs. Thus, if people            varied between-subjects. In the knowledgeable condition,
rate Jill’s likelihood of choosing the three options               the agent knew the efficacies of each option. For example:
differently even when she is ignorant, this inference could           Jill is shopping for a new shampoo, and wants her hair
not be produced by veridical mental-state reasoning.                     to smell like apples. She is considering three brands
Instead, people might overgeneralize these principles to                 of shampoo to use.
ignorant agents for whom they do not apply—using                      She knows that if she uses Variety JLR, there is a 70%
behaviorist reasoning that bypasses reasoning about the                  chance that her hair will smell like apples; that if she
agents’ beliefs. It is particularly plausible that behaviorist           uses Variety WYQ, there is a 50% chance that her
reasoning could lead to overgeneralization of the                        hair will smell like apples; and that if she uses
Efficiency Principle, since young infants can use                        Variety HPN, there is a 30% chance that her hair
efficiency to constrain behavior predictions in a                        will smell like apples.
presumably non-mentalistic manner (Gergely & Csibra,                  Jill chooses Variety [JLR/WYQ/HPN], and her hair
2003).                                                                   smells like apples.
   We compare inferences about knowledgeable and                   In the ignorant condition, the agent was said to believe
ignorant agents, using judgments about explanation                 (incorrectly) that all three formulas had a 70% efficacy,
(Experiment 1), prediction (Experiment 2), and                     but the actual probabilities were listed for the participant.
responsibility (Experiment 3). We also test whether                The Best, Middle, and Worst versions of each problem
people conceptualize suboptimal actions and omissions              differed only in Jill’s actual choice (JLR, WYQ, or HPN).
differently (Experiment 2), and whether people reinterpret            Participants then completed the need for explanation
mental states to rationalize otherwise suboptimal behavior         measure (“To what extent do you feel that an explanation
(Experiment 3), for knowledgeable and ignorant agents.             is necessary for Jill’s behavior?”) on a 0-to-10 scale (0:
Throughout these experiments, we gather evidence for a             “explanation definitely not necessary”; 5: “neither
non-mentalistic, behaviorist system with distinct                  necessary nor unnecessary”; 10: “explanation definitely
signatures from the representational theory of mind that           necessary”). Vignettes were presented in a random order.
we are accustomed to using in everyday experience.
                                                                   Results and Discussion
                       Experiment 1                                Participants took both the efficacy of the agent’s choice
In our first study, we used participants’ ratings of the need      and the agent’s knowledge into account in determining
for an explanation to measure expectations about                   whether an explanation was necessary. As Figure 1
behavior. Since anomalous events act as triggers for               shows, in both conditions, participants rated Best choices
explanation (e.g., Hilton & Slugoski, 1986), participants          as least in need of explanation, but the effect of choice
should indicate a higher need for explanation to the               differed between the knowledgeable and ignorant
degree that agents’ choices violate their expectations, just       conditions. There was no main effect of knowledge,
as infants look longer at suboptimal than at optimal               F(1,82) = 1.82, p = .18, ηp2 = .02, but both the main effect
actions (e.g., Gergely & Csibra, 2003). If people use only         of choice, F(2,164) = 46.35, p < .001, ηp2 = .36, and the
normative mentalistic reasoning, one would expect them             interaction between knowledge and choice, F(2,164) =
to rate optimal decisions less surprising than suboptimal          5.90, p = .003, ηp2 = .07, were significant. Knowledgeable
decisions for agents who are aware of the relative quality         agents’ decisions were rated more in need of explanation
of the choices. But if people supplement mental-state              for Middle than for Best, t(45) = 5.22, p < .001, d = 0.77,
inferences with behaviorist thinking, then they may also           and more for Worst than for Middle, t(45) = 4.23, p <
predict optimal choices even for ignorant agents.                  .001, d = 0.62. In contrast, although ignorant agents’
                                                                   decisions were rated more in need of explanation for
Method                                                             Middle than for Best, t(37) = 3.21, p = .003, d = 0.52, the
We recruited 100 participants from Amazon Mechanical               difference between Worst and Middle only reached
Turk in exchange for a small payment. These participants           marginal significance, t(37) = 1.72, p = .095, d = 0.28.
                                                               696

                                                                                       Experiment 2
                                                                Our primary goal in Experiment 2 was to replicate these
                                                                findings using a different dependent measure—explicit
                                                                behavior predictions. In addition, we manipulated whether
                                                                the Worst option was framed as an action or as an
                                                                omission (e.g., Ritov & Baron, 1992). In contrast to
                                                                Experiment 1, where suboptimal choices were seen as
                                                                equally surprising for ignorant agents, behaviorist
                                                                thinking could potentially lead people to distinguish
                                                                between suboptimal actions and suboptimal omissions,
                                                                since an option’s being an action or an omission is a
                                                                salient feature of the world.
                                                                Method
                                                                We recruited 100 participants from Amazon Mechanical
  Figure 1: Results of Experiment 1. Bars represent ±1 SE.      Turk in exchange for a small payment. These participants
                                                                additionally participated in another experiment that is not
  For knowledgeable agents, people rely on the                  reported here, with the order of the experiments
Preference Principle, finding knowledgeable agents’             counterbalanced. Three participants were excluded from
decisions to be increasingly surprising in proportion to        analysis because they incorrectly answered more than
their poorness. More surprisingly, however, people also         33% of the check questions.
take the quality of the options into account in evaluating         Participants read two vignettes, with worst-option
the decisions of ignorant agents. Although correct              framing (action or omission) varied within-subjects across
mentalizing would lead people to predict the agent’s three      two different cover stories, and knowledge of the
possible decisions as equally likely, and hence equally         probabilities (knowledgeable or ignorant) varied between-
surprising, they nonetheless found the optimal choice less      subjects. In the knowledgeable condition, the agent was
surprising than the middle or worst choice. Further, they       said to know the probabilities of each option leading to
did not robustly distinguish between the Middle and             their goal. For example (differences between the action
Worst options, suggesting that these inferences about           and omission conditions in brackets):
ignorant agents were made using the Efficiency Principle.          Angie has a shrub, and wants the shrub’s flowers to
Since both the Middle and Worst options were suboptimal              turn red. She is thinking about applying a fertilizer,
or inefficient relative to the Best option, the Efficiency           and has three options: applying [Formula LPN /
Principle alone would not distinguish between these two              nothing], applying Formula PTY, or applying
inefficient actions.                                                 Formula NRW.
  We take these results as evidence of behaviorist                 She does not know anything about the differences
thinking in behavior predictions—that is, relying directly           between these options, except that she knows that if
on information about the world rather than on the agents’            she applies [Formula LPN / nothing] there is a 10%
mental states. Could these results instead be explained by           chance that the flowers will turn red, that if she
participants’ incorrectly attributing knowledge of the               applies Formula PTY there is a 50% chance that the
probabilities to the agents, either through inattentiveness          flowers will turn red, and that if she applies Formula
to the vignettes or through a perspective-taking error               NRW there is a 70% chance that the flowers will turn
(Birch & Bloom, 2007)? Inattentiveness is an unlikely                red.
explanation because participants who failed check               In the ignorant condition, the second paragraph instead
questions (including questions about the agents’                stated that the agent did not know the probabilities. In
knowledge) were removed from the analysis. In addition,         contrast to Experiment 1 (where this was described as a
these explanations would not account for the qualitative        false belief), the agent was described as having no
interaction, in which participants used the Preference          relevant beliefs, to test the generality of our effects.
Principle for knowledgeable agents (distinguishing                 After reading each vignette, participants were asked to
between all three options) but the Efficiency Principle for     “Please rate below how likely you think it is that she will
ignorant agents (distinguishing between optimal and             choose each option.” Participants then rated each decision
suboptimal options, but not among different suboptimal          alternative on a 0-to-10 scale (0: “Very unlikely”; 5:
options). In contrast, use of the Efficiency principle is a     “Neither likely nor unlikely”; 10: “Very likely”). The
signature of infants’ non-mentalistic behavior predictions      assignment of action or omission framing to the Worst
(Gergely & Csibra, 2003) and is therefore quite consistent      option was counterbalanced across the two cover stories,
with our behaviorist account. We nonetheless sought             and items were presented in a random order.
converging evidence in Experiments 2 and 3.
                                                            697

Results and Discussion                                                            (A) Action Framing of Worst Option
As shown in Figure 2-A, the results for the action framing
condition were similar to the results in Experiment 1.
Under this framing, the Worst option was the choice of a
particular product (e.g., Formula LPN). Here,
knowledgeable agents were thought more likely to choose
Best than Middle, t(49) = 14.56, p < .001, d = 2.06, and
more likely to choose Middle than Worst, t(49) = 8.49, p
< .001, d = 1.20. However, ignorant agents were thought
more likely to choose Best than Middle, t(46) = 2.94, p =
.005, d = 0.43, but equally likely to choose Middle and
Worst, t(46) = 0.95, p = .35, d = 0.14. This difference led
to a significant interaction between choice and knowledge
in the action condition, F(2,190) = 87.30, p < .001, ηp2 =
.48. Mental-state inferences would lead to the prediction
that an ignorant agent is equally likely to choose any of
the options; nonetheless, even ignorant agents were
judged more likely to choose the optimal option—a
further demonstration of behaviorist thinking. Mirroring                      (B) Omission Framing of Worst Option
Experiment 1, however, people thought Middle more
likely than Worst only for the knowledgeable agents.
   However, Figure 2-B shows that the omission framing
produced a quite different pattern of results. Considering
just the omission condition, in which the Worst option
was described as doing nothing, the interaction between
choice and knowledge is again significant, F(2,190) =
43.21, p < .001, ηp2 = .31. But this time, the interaction
occurred because participants made more conservative
predictions about the ignorant agent, rather than because
they failed to differentiate among some of the options.
Participants thought the knowledgeable agents more
likely to choose Best than Middle, t(49) = 12.94, p < .001,
d = 1.83, and more likely to choose Middle than Worst,
t(49) = 8.91, p < .001, d = 1.26. Likewise, ignorant agents
were judged more likely to choose Best than Middle, t(46)
= 3.12, p = .003, d = 0.46, and more likely to choose
Middle than Worst, t(46) = 6.09, p < .001, d = 0.89. That          Figure 2: Results of Experiment 2. Bars represent ±1 SE.
is, when a suboptimal option is framed as an omission,
people think even ignorant agents are less likely to choose      may have been acting under a different set of beliefs or
it. This result too is consistent with behaviorist thinking,     goals—a process we can call rationalizing an action
because actions and omissions are qualitatively different        (Baker, Tenenbaum, & Saxe, 2009; Buchsbaum, Gopnik,
choices not only in the agent’s mind, but in the world,          Griffiths, & Shafto, 2011). For example, consider Jill’s
with actions and omissions tacitly thought to have distinct      shampoo-purchasing decision. The Efficiency Principle
affordances (Ritov & Baron, 1992).                               predicts that Jill should prefer a shampoo with a higher
   As in Experiment 1, it is unlikely that participants were     probability of resulting in a luscious apple smell. This
incorrectly attributing knowledge of the probabilities to        inference, however, relies on the assumption that Jill’s
the ignorant agents, because inattentive participants were       only goal is making her hair smell like apples, and that
removed from the analysis and because such attributions          she had accurate information. If Jill chooses an
would lead participants to predict Middle as more likely         objectively suboptimal action (from the point of view of
than Worst. Furthermore, such explanations could not             making her hair smell like apples), we can rationalize
straightforwardly account for the difference between the         Jill’s action by denying either of these assumptions. One
action and omission conditions, whereas this difference is       might infer, for example, that Jill had changed her goal or
a natural consequence of behaviorist thinking.                   that Jill did not realize that Variety JLR was superior.
                                                                    In Experiment 3, we used this idea to provide further
                      Experiment 3                               evidence that the inferences about ignorant agents in
When an agent makes an objectively suboptimal choice,            previous experiments were due to behaviorist thinking.
we can use the Efficiency Principle to infer that the agent      We used responsibility judgments as the dependent
                                                             698

measure because previous studies show that people assign         Turk in exchange for a small payment. These participants
greater responsibility to decision-makers who behave             additionally participated in other experiments that are not
optimally than to those who behave suboptimally                  reported here, with the order of the experiments
(Johnson & Rips, 2013). In all cases, the agent was              counterbalanced. Forty-nine participants were excluded
deciding between options with higher and lower                   from analysis because they incorrectly answered more
probabilities of the outcome, and always chose the higher        than 33% of the check questions.
probability option. To vary the optimality of an action, we        Participants read three vignettes (similar to that given
manipulated the agent’s attitude toward that outcome             above) in a random order. The agent’s goal (desires
(desires the outcome, indifferent toward the outcome, or         outcome, indifferent to outcome, or desires that the
desires that the outcome not occur). We also varied              outcome not occur) varied within-subjects across three
whether the agent knew or did not know the efficacies of         cover stories using a Latin square, and the agent’s
the options, as in Experiments 1 and 2. The vignettes in         knowledge about the probabilities (knowledgeable or
the knowledgeable condition were of the format:                  ignorant) varied between-subjects. After reading each
   Jill is shopping for a new shampoo, and is deciding           vignette, participants rated their agreement with a
      whether to purchase Variety JLR or Variety WYQ.            responsibility statement (“Jill is responsible for her hair
   [She wants her hair to smell like apples. / It does not       smelling like apples”) on a 0-to-10 scale (0: “Disagree”;
      matter to her whether her hair smells like apples. /       5: “Neither Agree nor Disagree”; 10: “Agree”).
      She wants her hair not to smell like apples.]
   She does not know anything about the differences              Results and Discussion
      between Variety JLR and Variety WYQ, except that           Responsibility ratings varied both with the agent’s goal,
      she knows that if she uses Variety JLR, there is a         F(2,416) = 8.76, p < .001, ηp2 = .04, and with the agent’s
      50% chance that her hair will smell like apples, and       knowledge of the probabilities, F(1,208) = 38.63, p <
      if she uses Variety WYQ, there is a 30% chance that        .001, ηp2 = .16. As Figure 3 illustrates, however, these
      her hair will smell like apples.                           effects were qualified by a significant interaction,
   Jill chooses Variety JLR, and her hair smells like            F(2,416) = 5.56, p = .004, ηp2 = .03.
      apples.                                                      We consider first the differences between the optimal
In the ignorant condition, the third paragraph instead           (desires the outcome) and the baseline (indifferent to the
stated that the agent did not know the probabilities.            outcome) conditions. Knowledgeable agents were rated
   When Jill is indifferent to the outcome, there is no          marginally more responsible in the optimal than in the
optimal choice, so this condition acts as a baseline in both     baseline condition, t(96) = 1.89, p = .062, d = 0.19. This is
the knowledgeable and ignorant conditions. We would              consistent with previous work showing that agents who
expect choices perceived as optimal (either because their        behave optimally are assigned greater responsibility than
action is objectively optimal or because their action is         those who do not (Johnson & Rips, 2013). In addition,
rationalized and made subjectively optimal) to be assigned       ignorant agents were assigned greater responsibility in the
increased responsibility. Since people appear to apply the       optimal than in the baseline condition, t(112) = 3.91, p <
Efficiency Principle even to ignorant agents, both               .001, d = 0.37. This is consistent with Experiments 1 and
knowledgeable and ignorant agents should be assigned             2, in that behaviorist thinking leads people to expect
greater responsibility when they act efficiently (i.e., when     efficient behavior for ignorant agents.
Jill desires the outcome that is made likelier by her
choice). However, the agent’s decision is objectively
suboptimal when she desires that the outcome not occur
but nonetheless chooses the action that makes that
outcome more likely. If this suboptimal action is
rationalized, then responsibility judgments should be
higher when she desires the outcome not occur than in the
baseline condition when she is indifferent. This is because
people would attribute mental states to the agent (e.g., an
additional goal such as choosing a less expensive option)
that would make that apparently suboptimal choice
rational. If inferences about ignorant agents are made with
the behaviorist strategy, one might expect people not to
rationalize the actions of ignorant agents, leading to a
difference between the baseline and suboptimal
conditions for knowledgeable but not for ignorant agents.
Method
                                                                    Figure 3: Results of Experiment 3. Bars represent ±1 SE.
We recruited 259 participants from Amazon Mechanical
                                                             699

   Our main interest, however, was in the differences            made only for knowledgeable but not for ignorant agents
between the suboptimal (desires the outcome not occur)           (Experiment 3). These findings all are naturally accounted
and baseline conditions, which would speak to whether            for by behaviorist thinking that relies on cues such as
participants were rationalizing the actions of suboptimal        efficiency and direct information about the world.
decision-makers. Knowledgeable agents were rated more               These results complement other approaches to theory of
responsible in the suboptimal than in the baseline               mind that involve multiple systems. For example, Apperly
condition, t(96) = 4.29, p < .001, d = 0.44, suggesting that     and Butterfill (2009) proposed two systems for reasoning
participants rationalized the agent’s suboptimal action.         about beliefs—a flexible system tracking beliefs and a
However, ignorant agents were rated equally responsible          less flexible system tracking belief-like states such as
in the suboptimal and in the baseline conditions, t(112) =       perceptual registration. Here, we have provided evidence
0.78, p = .44, d = 0.07, suggesting that suboptimal actions      for an additional system that does not make mental-state
were not rationalized for ignorant agents.                       inferences of any sort but instead makes inferences using
   These results show that rationalizing inferences (e.g.,       environmental cues together with the Efficiency Principle.
attributing an additional goal to the agent to make their           We often seem to infer behavior by pondering mental
suboptimal actions seem rational from the agent’s point of       states. But to the extent that behavior can be inferred from
view) are made when people follow a mentalizing                  efficiency considerations alone (Dennett, 1987), the
strategy, leading to the counterintuitive finding that           behaviorist system may often suffice. It is an open
knowledgeable agents can be rated more responsible for           question how often we unleash the behaviorist within.
an outcome when they desire that it not occur than when
they are indifferent toward it. This finding did not hold                           Acknowledgments
for ignorant agents, consistent with our interpretation of       This research was partially supported by funds awarded to
Experiments 1 and 2—that people used behaviorist                 the first author by the Yale University Department of
thinking in interpreting the actions of the ignorant agents.     Psychology. We thank Laurie Santos and an audience at
If participants had incorrectly attributed knowledge to the      Yale University for helpful discussion.
ignorant agents (either because of a perspective-taking
error or because of inattentiveness), we would not expect
this interactive effect.
                                                                                         References
                                                                 Apperly, I.A., & Butterfill, S.A. (2009). Do humans have
                   General Discussion                               two systems to track beliefs and belief-like states?
                                                                    Psychological Review, 116, 953–970.
Every day, we successfully predict what others do, and           Baker, C.L., Saxe, R., & Tenenbaum, J.B. (2009). Action
these successes often seem to be accompanied by                     understanding as inverse planning. Cognition, 113,
inferences about mental states. In three experiments, we            329–349.
provided evidence that these inferences are sometimes            Birch, S.A.J., & Bloom, P. (2007). The curse of
made solely on the basis of observable states of the world,         knowledge in reasoning about false beliefs.
using a behaviorist system for interpreting actions.                Psychological Science, 18, 382–386.
Behaviorist thinking manifested in participants’                 Buchsbaum, D., Gopnik, A., Griffiths, T.L., & Shafto, P.
inferences about agents who were ignorant about the                 (2011). Children’s imitation of causal action sequences
efficacy of their decision options, but who were                    is influenced by statistical and pedagogical evidence.
nonetheless expected to choose actions that led to their            Cognition, 120, 331–340.
goals optimally (Experiments 1 and 2). A mentalistic             Dennett, D.C. (1987). The intentional stance. Cambridge,
strategy would instead lead participants to predict that            MA: MIT Press.
ignorant agents are equally likely to choose each option.        Gergely, G., & Csibra, G. (2003). Teleological reasoning
   Is it possible, however, that people were following a            in infancy: The naïve theory of rational action. Trends
mentalistic strategy, but incorrectly attributed knowledge          in Cognitive Sciences, 7, 287–292.
to the ignorant agents? Inattentiveness is not a likely          Hilton, D.J., & Slugoski, B.R. (1986). Knowledge-based
explanation, since participants failing manipulation                causal attribution: The abnormal conditions focus
checks were excluded from these analyses. However, a                model. Psychological Review, 93, 75–88.
more plausible possibility is that participants made a           Johnson, S.G.B., & Rips, L.J. (2013). Good decisions,
perspective-taking error known as the curse of knowledge            good causes: Optimality as a constraint on attribution of
(e.g., Birch & Bloom, 2007), and were unable to separate            causal responsibility. Proceedings of the 35th Annual
their own perspective from that of the agent. This                  Conference of the Cognitive Science Society (pp. 2662–
explanation could account for some inferences about the             2667). Austin, TX: Cognitive Science Society.
ignorant agents, but could not explain why people only           Povinelli, D.J., & Vonk, J. (2004). We don’t need a
distinguished between Middle and Worst options for                  microscope to explore the chimpanzee’s mind. Mind &
knowledgeable agents (Experiments 1 and 2), why actions             Language, 19, 1–28.
and omissions were treated in qualitatively different ways       Ritov, I., & Baron, J. (1992). Status-quo and omission
(Experiment 2), or why rationalizing inferences were                biases. Journal of Risk and Uncertainty, 5, 49–61.
                                                             700

