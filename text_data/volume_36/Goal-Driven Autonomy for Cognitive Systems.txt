UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Goal-Driven Autonomy for Cognitive Systems
Permalink
https://escholarship.org/uc/item/5vq1h9jc
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Paisner, Matthew
Cox, Michael
Maynord, Michael
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Goal-Driven Autonomy for Cognitive Systems
                                              Matt Paisner (mpaisner@umd.edu)
                                              Michael T. Cox (mcox@cs.umd.edu)
                                           Michael Maynord (maynord@umd.edu)
                                                Don Perlis (perlis@cs.umd.edu)
                                        Computer Science Department, A.V. Williams Bldg.
                                                    College Park, MD 20742 USA
                             Abstract                                as much about problem recognition as it is problem-solving
                                                                     (Cox, 2013).
   Complex, dynamic environments present special challenges to
   autonomous agents. Specifically, agents have difficulty when         Consider a fire that breaks out at a construction site. This
   the world does not cooperate with design assumptions. We          is a problem in many ways, not the least of which is that
   present an approach to autonomy that seeks to maximize            preconditions for actions (e.g., the integrity of building
   robustness rather than optimality on a specific task. Goal-       materials) will become unsatisfied. A standard planning
   driven autonomy involves recognizing possibly new                 algorithm might therefore generate a subgoal to extinguish
   problems, explaining what causes the problems and                 the fire so that construction can continue. However a
   generating goals to solve the problems. We present such a
   model within the MIDCA cognitive architecture and show
                                                                     subsequent fire in quick succession might justify an
   that under certain conditions this model outperforms a less       investigation into a long-term threat to the construction site.
   flexible approach to handling unexpected events.                  One possible explanation would be the presence of an
                                                                     arsonist, leading to the goal of having the perpetrator in jail.
   Keywords: goal generation; anomaly handling; interpretation
   and explanation; TF-Tree; cognitive architecture; intelligent
                                                                     Hence a direct reactive approach to fires would be to put
   autonomy.                                                         them out; a GDA approach to this same situation would
                                                                     recognize the underlying problem in terms of its threat to
                         Introduction                                the future of the enterprise.
Humans are astonishingly versatile, dealing with a wide                 This paper will examine the distinction between such
range of unanticipated circumstances while still making              approaches to intelligent reasoning and behavior in a
headway on high-level goals. Humans can also recognize               metacognitive architecture called MIDCA and will report
new problems and opportunities when they arise and react             the results of a simple empirical study to evaluate these
appropriately to them. Yet for the most part our machines            differences. In section 2, we present the MIDCA
cannot; they are like idiot-savants, very good at one narrow         architecture containing an implemented instantiation of the
task and useless for anything else, even tasks very similar to       GDA model. In section 3 we evaluate the performance of
the one they were designed for. This is the so-called                systems making use of three distinct goal generation
brittleness problem, a major stumbling block for AI. What            methods: exogenous goals; statistically generated goals;
we appear to need is the opposite of expert systems:                 goals produced by a knowledge rich explanation system.
machines that might not excel at anything, but that can              Section 4 presents an overview of future work, section 5
muddle through a wide range of circumstances and keep a              surveys related work, and section 6 concludes.
strategic perspective. Yet more than 50 years of intense
effort has failed to produce such machines. One approach to
                                                                                      Goal-Driven Autonomy
the problem of brittleness uses what we call goal-driven                            in a Cognitive Architecture
autonomy in a cognitive architecture. Here we describe               The Metacognitive, Integrated, Dual-Cycle Architecture
some benefits of this approach in dynamic environments.              (MIDCA) (Cox, Maynord, Paisner, Perlis, & Oates, 2013)
   Goal-Driven Autonomy (GDA) is a unique conception that            consists of “action-perception” cycles at both the cognitive
gives full independence to autonomous agents (Cox, 2007;             (i.e., object) level and the metacognitive (i.e., meta-) level.
Klenk, Molineaux, & Aha, 2013; Munoz-Avila, Jaidee,                  Figure 1 shows the implemented components of the object
Aha, Carter, 2010). Rather than arbitrary anomaly-detection,         level with the meta-level abstracted. The output side of each
the agent searches for problems in the context of its current        cycle consists of intention, planning, and action execution,
goals and mission. Not all anomalies are problems, nor are           whereas the input side consists of perception, interpretation,
all problems important enough to attend to. Rather than              and goal evaluation. A cycle selects a goal and commits to
general assessment of an entire world state, the agent should        achieving it. The agent then creates a plan to achieve the
abductively explain the causal factors giving rise to the            goal and subsequently executes the planned actions to make
problem. Given an explanation, a GDA agent may generate              the domain match the goal state. The agent perceives
a (possibly new) goal that solves the problem (e.g., by              changes to the environment resulting from the actions,
removing its supporting conditions). In these terms, GDA is          interprets the percepts with respect to the plan, and
                                                                     evaluates the interpretation with respect to the goal. At the
                                                                 2085

object level, the cycle pursues goals that change the                                                          available to MIDCA to deal with fires. The three new
environment (i.e., ground level). At the meta-level, the cycle                                                 actions are as follows:
pursues goals that change the object level. That is, the
                                                                                                               • light-on-fire (block) if block not on fire, lights it
metacognitive “perception” components introspectively
                                                                                                               • put-out-fire (block) if block on fire, extinguishes it
monitor mental processes and state changes at the cognitive
                                                                                                               • apprehend (arsonist) imprisons arsonist
level. The “action” component consists of a meta-level
controller that mediates reasoning over an abstract                                                               MIDCA_1.1’s task is to build houses while also dealing
representation of the object level cognition.                                                                  appropriately with fire. In the next subsection, we describe
                                                                                                               the techniques it uses in this task.
                               Executive Shell
                                          goal input
                                                         goal                                                  MIDCA_1.1 Reasoning Components MIDCA_1.1 is
                       subgoal                       insertion
                                     Goals
                                                                                                               implemented by a series of components, centered about a
                                                                                                               core memory structure. Each of these components
          Intend                                                  Evaluate
                                                                                                               implements a single phase of the MIDCA cognitive loop
                                   Memory
 Problem
 Solving                             Goals( )
                                                                            Comprehension
                                                                                                               shown in Figure 1. Running MIDCA_1.1 is equivalent to
          SHOP2                  Semantic Memory                  Interpret                                    repeatedly running each of these components in the order
                                                          | XP
                Actions
                                    & Ontology
                                   Plans( ) &                 Percepts                                         shown in Figure 1, beginning with the perceive component.
                                                                             Goal Gen
            Act
                                   Percepts ( )
                                                                  Perceive
                                                                                    XP
                                                                                            Goal Gen
                                                                                                  anomaly
                                                                                                               Components interact by storing information in memory,
                                                                             Explain
                                                                                   problem
                                                                                             Detect
                                                                                                  percepts
                                                                                                               where it can be accessed and used later in the cycle and in
                                  World =Ψ
                                                                            Recognize
                                                                                   percepts
                                                                                                               future cycles. The individual implementations are described
                                                                                                               below.
Figure 1: The MIDCA_1.1 object level structure. Note that
execution-time subgoaling (dashes) is not currently implemented.                                               Perceive. The perceive phase is implemented very simply.
TFT stands for TF-Tree, and XP stands for eXplanation Pattern.                                                 The perceive component makes a copy of the current world
                                                                                                               state (defined in a predicate logic representation) and stores
Metacognitive Integrated Dual-Cycle Architecture                                                               it in memory. As a result, MIDCA_1.1 always has a perfect,
Version 1.1                                                                                                    noise-free view of the current world state, though it has no
                                                                                                               direct knowledge of the arsonist’s actions (it only sees that
MIDCA_1.1 is an early version of the architecture whose
                                                                                                               fires have started, not how). In our simple blocksworld
components are shown in the schematic of Figure 1. It
                                                                                                               example, MIDCA_1.1 copies to memory the same predicate
implements each phase of the cognitive loop, allowing the
                                                                                                               representation of block relationships and attributes that the
MIDCA agent to notice, analyze and respond to events in
                                                                                                               world simulator maintains as the current state.
various simple domains.
                                                                                                               Interpret. The interpret phase has been at the core of our
                                                                                                               research efforts. It is implemented as a GDA procedure that
Performance Domain To evaluate the performance of
                                                                                                               uses both a bottom-up, data-driven track and a top-down,
MIDCA in goal generation, we place the system in a
                                                                                                               knowledge rich track (Cox, Maynord, Paisner, Perlis, &
modified blocksworld domain. This version of blocksworld
                                                                                                               Oates, 2013). MIDCA_1.1 uses both of these processes to
includes both rectangular and triangular blocks, which
                                                                                                               analyze the current world state and determine which, if any,
compose the materials for simplified housing construction.
                                                                                                               new goals it should attempt to pursue. The details of this
The overarching goal in this domain is to build “houses”
                                                                                                               process are described below. In our example, this is the
consisting of towers of blocks with a roof (triangle) on each.
                                                                                                               phase in which MIDCA_1.1 notices an anomaly in the
Specifically, the housing domain cycles through three goal
                                                                                                               blocksworld (e.g., a block on fire) and decides what to do
states in building new houses. Figure 2 shows the three
                                                                                                               about it.
states and the goals that transition the system between them.
                                                                                                               Evaluate. In the evaluate phase, the goal generated during
                                                                                                               the previous step is evaluated. The system searches through
                                                                                                               the world representation stored during the perceive phase,
                                                                                                               and checks if the goal predicate exists in the world state. If
                                                                                                               so, MIDCA_1.1 notes that goal has been achieved.
                                                                                                               Additionally, during evaluate MIDCA_1.1 checks on the
                                                                                                               progress of its broader goals and updates the relevant
   Figure 2: Three classifiers generate goals for subsequent states.                                           performance metrics. In blocksworld, MIDCA_1.1 checks if
    We use a simple world simulator in which actions,                                                          its current goal, for example on(A, B) has been achieved. It
specified using predicate logic, are given prior to startup in                                                 then checks to see if a new tower has been built and if so
a domain file. MIDCA’s actions will be simulated, as well                                                      how many blocks in it are on fire. All this data is stored in
as actions performed by other agents and natural events. For                                                   memory, and used later to score MIDCA_1.1’s success at
the purpose of generating interesting anomalies for MIDCA                                                      achieving its goals.
to deal with, we have added a hidden arsonist, who can set                                                     Intend. The intend component determines which goals to
blocks on fire. Furthermore there are two additional actions                                                   pursue. If the evaluate phase reports that the previous goal
                                                                                                           2086

has been achieved, MIDCA_1.1 checks to see if a new goal            streams of predicate counts in the perceptual input (Cox,
was generated during the interpret phase. If so, it adopts that     Oates, Paisner, & Perlis, 2012), yielding a measurement of
goal. Otherwise, it will do nothing until a new goal is             how the distributions of predicates differ from a base state.
generated. If the previous goal has not been achieved, it will      This enables MIDCA to detect regions in which statistical
also do nothing unless a goal with higher priority is               distributions of predicates differ from previously observed
generated, like a goal to put out a fire. In the latter case        input. MIDCA’s implicit assumption is that where change
MIDCA_1.1 adopts the high-priority goal and puts the                occurs problems may exist.
previous goal on hold. In MIDCA_1.1, goal priorities have              When a change is detected, its severity and type can be
been predetermined so that fire goals will be executed              determined by reference to a neural network in which nodes
before construction goals. In blocksworld, the intend               represent categories of normal and anomalous states. This
component converts the goal that has been generated into a          network is generated dynamically with the growing neural
task that can be taken as input by the planner. For example,        gas algorithm (Paisner, Perlis, & Cox, 2013) as the D-track
the goal onfire(A) would be transformed into put-out-              processes perceptual input. This process leverages the
fire(A).                                                            results of analysis with A-distance to generate anomaly
Plan. For the planner, we use SHOP2 (Nau et al., 2003), a           prototypes, each of which represents the typical member of
domain-independent task decomposition planner. If the               a set of similar anomalies the system has encountered.
intend component specified a new task, SHOP2 generates a            When a new state is tagged as anomalous by A-distance, the
plan to achieve that task given the current world state stored      GNG net associates it with one of these groups and outputs
in memory. Otherwise, it does nothing. The actions and              the magnitude, predicate type, and valence of the anomaly.
methods that are used to achieve each task in blocksworld              Goal generation is achieved in MIDCA_1.1 using TF-
are specified in a domain file that we supply.                      Trees (Maynord, Cox, Paisner, & Perlis, 2013), machine-
Act. MIDCA chooses the next action from the current plan,           learning classification structures that combine two
if one exists. Otherwise, it does not perform an action. If an      algorithms which work over the predicate representation of
action is chosen, it is sent to the world simulator, which uses     the blocksworld domain. The first of these algorithms is
it to compute the next world state. An example of such an           Tilde (Blockeel, & De Raedt, 1997), which is itself a
action might be unstack(A,B) if SHOP2 had generated a               generalization of the standard C4.5 decision tree algorithm.
plan containing that step.                                          The second algorithm is FOIL (Quinlan, 1990), an
                                                                    algorithm which, given a set of examples in predicate
Interpretation                                                      representation reflecting some concept, induces a rule
The interpret phase of MIDCA has been the subject of much           consisting of conjunctions of predicates that identify the
of our work, and is the focus of the experiments described          concept. Given a world state, a TF-Tree first uses Tilde to
below. It is implemented by two GDA processes that                  classify the state into one of a set of scenarios. Each
combine to generate new goals based on the features of the          scenario is then associated with a rule generated by FOIL.
world the agent observes. We call these processes the D-            Once that rule is obtained, groundings of the arguments of
track, which is a data driven, bottom-up approach, and the          the predicates in that rule are permuted until either a
K-track, which is knowledge rich and top-down. A                    grounding that satisfies the rule is found (in which case a
statistical anomaly detector constitutes the first step of the      goal is generated) or until all permutations have been
D-track, a neural network identifies low-level causal               eliminated as possibilities (in which case no goal is
attributes of detected anomalies, and a goal classifier,            generated). The structure of a TF-Tree is a tree where in
trained using methods from machine learning, formulates             internal nodes are produced by Tilde and leaf nodes are
goals. The K-track is implemented as a case-based                   rules produced by FOIL. Figure 3 depicts the structure of
explanation process.                                                the TF-Tree MIDCA_1.1 uses in cycling through the 3
   The representations for expectations significantly differ        block arrangements.
between the two tracks. K-track expectations come from
explicit knowledge structures such as action models used for
planning and ontological conceptual categories used for
interpretation. Predicted effects in the former and attribute
constraints in the latter constitute expectations. By contrast,
D-track expectations are implicit. Here the implied
expectation is that the probabilistic distribution from which
observations are sampled will remain the same. When the             Figure 3: Depiction of the TF-Tree used in cycling through the 3
difference between expected and perceived distribution is           block configurations.
statistically significant, an expectation violation is raised.         For example given the middle state of Figure 2, triangle D
                                                                    is clear, it is on the table, and the table is a table. Thus we
D-Track Goal Generation The D-track interpretation
                                                                    take the right branch labeled “yes.” Now triangle D is also a
procedure uses a novel approach for noting anomalies. We            triangle, so again we take the “yes” branch to arrive at the
apply the statistical distance metric called the A-distance to      right-most leaf of the tree. The leaf rule then binds the
                                                                2087

variable Y to the clear square C, and the resulting goal is to      pattern (see Table 1), or XP, retrieved from memory
have triangle D on square C.                                        instantiates this explanation, and the system incorporates it
   The construction of a TF-Tree requires a training corpus         into the current model of the actions in the input “story” and
consisting of world states and associated correct and               passes it as output to MIDCA.
incorrect goals. In simple worlds TF-Trees can be
                                                                               Table 1: The arsonist explanation pattern
constructed which have perfect or near perfect accuracy
                                                                    (define-frame ARSONIST-XP
using small training corpora. Corpora have to be constructed           (actor (criminal-volitional-agent))
by humans, as labels need to be attached to potential goals            (object (physical-object))
in various world states. For simple worlds corpus                      (antecedent (ignition-xp
construction does not carry an excessive burden, but that                                 (actor =actor)
                                                                                          (object =object)
burden increases with the complexity of the world. Because                                (ante (light-object =l-o
a TF-Tree is a static structure trained on the specifics of the                                     (actor =actor)
world, when the world changes, even in minor ways, a new                                            (instrumental-object
                                                                                                     (ignition-device))))
training corpus has to be constructed and a new TF-Tree                                   (conseq =heat)))
trained. However, the corpus to create a simple tree for               (consequent (forced-by-states
reacting to fires (see Figure 4) consisted of only four                                   (object =object)
examples.                                                                                 (heat =heat)
                                                                                          (conseq (burns =b
                                                                                                       (object =object)))))
                                                                       (heat (temperature (domain =object)
                                                                                               (co-domain very-hot.0)))
                                                                       (role (actor (domain =ante))
                                                                                       (co-domain =actor)))
       Figure 4: TF-Tree that generates goals to put out fires         (explains =role)
                                                                       (pre-xp-nodes(=actor =consequent =object =role))
K-Track Goal Generation The K-track GDA procedure                      (internal-nodes nil.0)
uses the XPLAIN system (Cox & Burstein, 2008). XPLAIN                  (xp-asserted-nodes (=antecedent))
is built on top of the Meta-AQUA introspective story                   (link1 (results
                                                                                  (domain =antecedent))
understanding system (Cox and Ram 1999) and is used in                            (co-domain =consequent)))
MIDCA to detect and explain problems in the input                      (link2 (xp-instrumental-scene->actor
perceptual representations. The system’s interpretation task                      (actor =actor)
is to “understand” input by building causal explanatory                           (action =l-o)
                                                                                  (main-action =b)
graphs that link subgraph representations in a way that                           (role =role))))
minimizes the number of connected components. XPLAIN                   The ARSONIST-XP asserts that the lighting of the block
uses a multistrategy approach to this problem. Thus, the top-       caused heat that together with oxygen and fuel (the block
level goal is to choose a comprehension method (e.g., script        itself) caused the block to burn. The arsonist lit the block
processing, case-based reasoning, or explanation generation)        because he wanted the block’s burning state that resulted
by which it can understand an input. When an anomalous or           from the burning. The objective is to counter a vulnerable
otherwise interesting input is detected, the system builds an       antecedent of the XP. In this case the deepest antecedent is
explanation of the event, incorporating it into the preexisting     the variable binding =l-o or the light-object action. This can
model of the story. XPLAIN uses case-based knowledge                be blocked by either removing the actor or removing the
representations implemented as frames tied together by              ignition-device. The choice is the actor, and a goal to
explanation-patterns (Cox & Ram, 1999) that represent               apprehend the arsonist is thereby generated.
general causal structures.
   XPLAIN relies on general domain knowledge, a case                    Evaluation: Autonomous goal formulation
library of prior plan schemas and a set of general                  The fires are problems because of their effect on housing
explanation patterns that are used to characterize useful           construction and the supposed profits of the housing
explanations involving that background knowledge. These             industry, and the threats they pose to life and property. Our
knowledge structures are stored in a (currently) separate           approach to understanding fire problems is to ask why the
memory sub-system and communicated through standard                 fires were started and not just how. A scientific explanation
socket connections to the rest of MIDCA_1.1. XPLAIN                 of how the fire started would relate the presence of
uses an interest-driven, variable depth, interpretation             sufficient heat, fuel, and oxygen with the combustion of the
process that controls the amount of computational resources         blocks. For example, generating the negation of the
applied to the comprehension task. For example an assertion         presence of the oxygen would result in the goal ¬oxygen,
that triangle-D is picked up generates no interest, because it      which would put out the fire. But this does not address the
represents normal actions that an agent does on a regular           reason the fire started in the first place. One might arrive at
basis. But XPLAIN classifies block-A burning to be a                multiple answers to this question. Poor safety conditions
violent action and, thus according to its interest criterion,       might have led to fire, or an arsonist may have lit it. In the
interesting. It explains the action by hypothesizing that the       latter case, the arsonist causes the presence of the heat
burning was caused by an arsonist. An abstract explanation          through a lighting action, which is hidden from the agent.
                                                                2088

Given this explanation the agent can nevertheless anticipate                           Table 2: Scoring metrics for testing
the threat of more fires and generate a goal to remove the
                                                                        Towers          Total number of 3- and 4-block towers completed
threat by finding the arsonist. Apprehending the arsonist               Completed       in 1000 cycles
then removes the potential of fires in the future rather than
just reacting to fires that started in the past.                        Fire            The number of blocks on fire times the number of
   We tested the effectiveness of three methods for goal                Prevalence      time steps they were on fire. If 3 blocks burn for 3
generation under these conditions. The first method was a                               time steps and go out simultaneously the score is 9
simple baseline using predetermined, exogenous goals. The               Overall         Awards 1 point per block that is not on fire in a
second method used the statistical, D-Track GDA method                  Score           completed tower. A 4-block tower with 2 blocks on
described in Section 2.2.1. The third method combined the                               fire scores 2 points
D-Track approach with additional analysis using K-Track
GDA as described in Section 2.2.2. Details appear in Table                 The agent that used only exogenous goals completed the
2. For each test, MIDCA was run for 1000 time steps                     most towers, but, because it did not deal with fires in any
(equivalent to executing 1000 actions). At each step, the               way, most of the towers were burning as they were
arsonist would have a probability p of starting a fire unless           completed and received very low scores. Certainly, this
he had previously been apprehended. The value of p in the               baseline behavior does not seem to be sufficient for a fully
experiments described below was 0.4, allowing for enough                autonomous house construction agent. The second agent
fires to be significant without precluding progress in the              used behavior dictated by TF-Trees to fight fires directly. It
tower construction project.                                             did not complete as many towers because it divided its
             Table 1: Methods for goal generation                       attention between construction and extinguishing fires, but
                                                                        the towers it did construct were consequently much less
Exogenous      Used a predetermined goal list that cycled between       likely to be on fire. Its total score was 367, 54.2% better
Goals          the 3 states constructing towers. Did not deviate        than the baseline agent. Finally, the dual-track GDA agent
                                                                        analyzed the problem logically using XPLAIN, and thereby
               from list in response to fires. Goals were [on(C,A),
                                                                        suggested an explanation of the fires as potentially caused
               on(D,C), on(D,A), on(C,A), … on(D,A)]
                                                                        by arson. As such, it generated a goal early in the process to
                                                                        apprehend the arsonist. This took some time, but afterwards
D-Track        Generated goals using TF-Trees. Trees were               it was able to devote its full attention to house construction
GDA Goal       trained and implemented such that when no fire           without devoting time to firefighting. It completed nearly as
Generation     was present, they would generate the next goal in        many towers as the baseline agent, and did so with almost
               the 3-part cycle, but when a fire was present, they      no incidence of fire, since no fires started after the arsonist
               would instead generate a goal to put it out.             was apprehended. The dual-track agent achieved a score of
                                                                        584, 245.4% better than the baseline agent.
2-Track        Generated goals using a combination of TF-Trees
GDA Goal       and a K-Track approach using XPLAIN. XPLAIN
Generation     contained knowledge about possible arsonists and
               suggested a goal to search and apprehend an
               arsonist given fire. TF-Trees generated other goals
               as in 2 above
   We tracked three scoring metrics: the number of towers
completed; the overall prevalence of fires; and a combined
score measuring completion of fire-free towers. Details on
each scoring metric are shown in Table 2. At each time step
in which a tower was completed – e.g. a triangular block
was placed on a stack of rectangular blocks, – all fires were
automatically put out, and the agent started on a new
construction project.
   Preliminary empirical results show that GDA approaches
using only the D-Track as well as using both D-Track and
                                                                        Figure 5: Results of testing using 3 methods. Note that the value of
K-Track perform significantly better than a baseline that               GDA Goal Generation in the Fire Prevalence panel is 2, which is
does not use GDA. Also, the combined D- and K-Track                     too small to show clearly in the graph.
implementation outperforms the purely statistical variant by
a large margin. Figure 5 shows the detailed results of                     It should not be surprising that an agent that is capable of
testing.                                                                reacting to the unanticipated problem posed by fire performs
                                                                        better than one that heedlessly continues on a predetermined
                                                                    2089

course of action. Perhaps more telling is the large advantage                              Acknowledgments
gained by the dual-track agent, which has the knowledge to
                                                                    This is supported by ONR Grants N00014-12-1-0430 and
identify and address the true source of the problem, rather
                                                                    N00014-12-1-0172 and by ARO Grant W911NF-12-1-0471.
than simply treating its symptoms. Though this example is
too simple to easily generalize, these results at least suggest                                 References
the importance of combining a knowledge-rich approach               Blockeel, H., & De Raedt, L. (1997). Lookahead and discretisation
with low-level data analysis to achieve the best possible             in ILP. Proc. of the 7th intl. workshop on inductive logic
results.                                                              programming (pp. 77–84) Berlin: Springer
                                                                    Cox, M. T. (2007). Perpetual self-aware cognitive agents. AI
                      Related Work                                    Magazine 28(1), 32-45.
                                                                    Cox, M. T. (2013). Question-based problem recognition and goal-
Work has been done to expand the capacities of agents by              driven autonomy. Goal Reasoning: Papers from the ACS
making use of goal manipulation. (Hanheide et al., 2010)              workshop (pp. 10-25). (Tech. Rep. No. CS-TR-5029). College
created a framework for managing goals to be used by a                Park, MD: Univ. Maryland, CS Dept.
robot exploring an unknown space which autonomously                 Cox, M. T., & Burstein, M. H. (2008). Case-based explanations
classifies rooms into categories. They ran the robot with and         and the integrated learning of demonstrations. Künstliche
without the framework, and concluded that a framework for             Intelligenz 22(2), 35-38.
goal management increases the performance of the robot.             Cox, M. T., Maynord, M., Paisner, M., Perlis, D., & Oates, T.
                                                                      (2013). The integration of cognitive and metacognitive
   Schermerhorn, Benton, Scheutz, Talamadupula, &
                                                                      processes with data-driven and knowledge-rich structures. Proc.
Kambhampati (2009) sought to use modification of a robot's            of Annual Meeting of the Intl. Association for Computing and
goal structure to confront the challenges of a partially              Philosophy.
observable, non-deterministic domain in which prior                 Cox, M. T., Oates, T., Paisner, M., & Perlis, D. (2012). Noting
knowledge about the domain is limited, knowledge                      anomalies in streams of symbolic predicates using A-distance.
acquisition is non-monotonic, planning is subject to real             Advances in Cognitive Systems 2, 167-184.
time constraints, and goals and utilities can dynamically           Cox, M. T., & Ram, A. (1999). Introspective multistrategy
change during execution. Counterfactuals determine actions            learning. Artificial Intelligence, 112, 1-55.
that lead to goal opportunities, and when opportunities are         Hanheide, M., Hawes, N., Wyatt, J., Göbelbecker, M.,
detected, the goal structure can be modified. Other work has          Brenner, M., Sjöö, K., Aydemir, A., Jensfelt, P., Zender,
taken advantage of the GDA model which we use in our                  H. & Kruijff, G. J. (2010). A framework for goal generation
work. For example, Munoz-Avila, Jaidee, Aha, and Carter               and management. AAAI Workshop on Goal-Directed Autonomy.
                                                                    Klenk, M., Molineaux, M., & Aha, D. (2013). Goal-driven
(2010) merged the GDA framework with case based
                                                                      autonomy for responding to unexpected events in strategy
reasoning (CBR) and ran a comparison between a GDA                    simulations. Computational Intelligence, 29(2), 187–206.
system using CBR, a rule based variant of GDA, and a non-           Maynord, M., Cox, M. T., Paisner, M., & Perlis, D. (2013). Data-
GDA based agent. The CBR based GDA system                             driven goal generation for integrated cognitive systems. C.
outperformed the others, and functioned by making use of a            Lebiere & P. S. Rosenbloom (Eds.), Integrated Cognition:
case base that mapped goals to expectations and a case base           Papers from the 2013 Fall Symposium (pp. 47-54). Menlo Park,
that mapped mismatches to new goals.                                  CA: AAAI Press.
   The ARTUE GDA system (Molineaux, Klenk, & Aha,                   Molineaux, M., Klenk, M., Aha, D. (2010). Goal-driven autonomy
2010) is a domain independent autonomous agent with the               in a Navy strategy simulation. Proceedings of the Twenty-
                                                                      Fourth AAAI Conference on Artificial Intelligence. Menlo Park,
capacity to dynamically determine which goals to pursue in
                                                                      CA: AAAI Press.
unexpected situations. ARTUE uses hierarchical task                 Munoz-Avila, H., Jaidee, U., Aha, D. W., Carter, E. (2010). Goal-
networks for planning, takes advantage of explanations, and           driven autonomy with case-based reasoning. I. Bichindaritz & S.
manages goals.                                                        Montani (Eds.), Case-Based Reasoning. Research and
                                                                      Development, 18th International Conference on Case-Based
                        Conclusion                                    Reasoning, ICCBR 2010 (pp. 228-241). Berlin: Springer.
A major contribution of this work is the synergy between D-         Nau, D., Au, T., Ilghami, O., Kuter, U., Murdock, J., Wu, D., &
track and K-track approaches. We have described the use of            Yaman, F. (2003). SHOP2: An HTN planning system. Journal
data-driven techniques in anomaly detection (A-distance),             of Artificial Intelligence Research 20, 379–404
                                                                    Paisner, M., Perlis, D., & Cox, M. T. (2013). Symbolic anomaly
neural networks (growing neural gas), and machine learning
                                                                      detection and assessment using growing neural gas. Proceedings
(Tilde; FOIL) as well as a predicate logic state                      of the 25th IEEE Intl. Conf. on Tools with Artificial Intelligence
representation and techniques for explanation generation              (pp. 175-181). Piscataway, NJ: IEEE Press.
(Meta-AQUA) and planning (SHOP2) that rely on high                  Quinlan, J. R. (1990). Learning logical definitions from relations.
level formalisms. Both high level and low level approaches            Machine Learning 5, 239-266.
to AI have been used with great success in their individual         Schermerhorn, P., Benton, J., Scheutz, M., Talamadupula, K.,
spheres. We believe that the integration of these approaches          Kambhampati, S. (2009). Finding and exploiting goal
is one of the most promising opportunities in modern AI,              opportunities in real-time during plan execution. Proc. 2009
and one of the central focuses of MIDCA.                              IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (pp.
                                                                      3912-3917). Piscataway, NJ: IEEE Press.
                                                                2090

