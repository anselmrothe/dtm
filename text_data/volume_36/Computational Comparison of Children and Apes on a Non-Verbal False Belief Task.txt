UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Computational Comparison of Children and Apes on a Non-Verbal False Belief Task
Permalink
https://escholarship.org/uc/item/5gz1v4c5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Ciraolo, Margeaux
O'Hanlon, Samantha
Doumas, Leonidas
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

Computational Comparison of Children and Apes on a Non-Verbal False Belief Task
                                          Margeaux F. Ciraolo (ciraolo@hawaii.edu)1
                                      Samantha M. O’Hanlon (sohanlon@hawaii.edu)1
                                     Leonidas A. A. Doumas (alex.doumas@ed.ac.uk)1,2
                         1
                           Department of Psychology, University of Hawai‛i at Mānoa, Honolulu, HI, USA
              2
                School of Philosophy, Psychology and Language Sciences; University of Edinburgh; Edinburgh, UK
                             Abstract                                 Penn et al. argue that this ability underlies the flexibility and
                                                                      structural sensitivity required for many uniquely human
   The key difference between the cognitive abilities of humans
   and other animals may be the ability to reason relationally;       capabilities (e.g., language production, art, science, and
   models of relational reasoning are one way to demonstrate          mathematics; see also, Medin, Goldstone, & Gentner, 1993).
   this proposed difference. The present work uses the DORA           In order to reason relationally, a system must be able to
   model to simulate a task designed to assess the theory of mind     represent relations as explicit entities that can be
   capabilities of 4- and 5-year-old children and apes. In the        dynamically bound to arguments (i.e., they must be
   original experiment, the apes and children successfully            predicated; Doumas & Hummel, 2005). Penn et al. (2008)
   completed a number of control tasks in which they used cues
   from an experimenter to reason about the hiding location of a
                                                                      argue that it is this precise capacity that differentiates human
   reward. However, only the children succeeded on the critical       and non-human cognition, and they make a strong argument
   manipulation in which it was necessary to infer what the           that, thus far, there is insufficient evidence to conclude that
   experimenter knew. The simulations presented herein                any non-human species possess this ability.
   demonstrate that the apes’ performances across all tasks can          The current research attempts to address the second
   be accounted for by simple rule use. Conversely, the 4-year-       question within the context of a non-verbal false belief task
   olds succeeded via relational inference and learning; 5-year-      (i.e., that of Call & Tomasello, 1999). A series of computer
   olds alone had the requisite relational structures predicated
   beforehand.                                                        simulations utilizing the DORA model of human relational
                                                                      learning (Doumas, Hummel, & Sandhofer, 2008) was
   Keywords: relational reasoning; cognitive development;             conducted in order to demonstrate that the capacity for
   computational models; comparative cognition.                       relational reasoning can explain the differences in task
                                                                      performance between apes and human children, as well as the
                         Introduction                                 developmental trends observed in 4- and 5-year-old children.
There is a long tradition in behavioral research of comparing
the cognitive achievements of humans and non-human                                                  Methods
animals in order to assess the similarities and differences in
                                                                      The following sections describe the non-verbal false belief
their thinking and reasoning. Interestingly, many of the
                                                                      tasks that were given to children and apes, a brief
cognitive capabilities once thought to be the most “human”            description of the LISA/DORA models of relational
(e.g., transitive inference, language, relational thinking,           reasoning (for a more thorough explanation, see Doumas et
hierarchical reasoning, mental state attribution) are claimed         al., 2008), and how the DORA model was used to simulate
to have been observed in various animal species (see e.g.,
                                                                      the behavioral data collected by Call and Tomasello (1999).
Bergman, Beehner, Cheney, & Seyfarth, 2003; Cook &
Wasserman, 2007; Dally, Emery, & Clayton, 2006; Gentner,              Task Description
Fenn, & Margoliash, 2006; Lazareva et al., 2004). However,
despite the striking similarities in the abilities of human and       Theory of mind tasks can be understood as relational in
non-human animals, human cognition remains singular in                nature because they require a subject to reason about the
the animal kingdom. Specifically, human cognition appears             mental contents of another, which involves using a higher-
to possess a flexibility not observed in other animals (see           order relational structure to cast a belief state on some
below). The differences between humans’ and nonhuman                  proposition (Penn & Povinelli, 2007). 1 Theory of mind is a
animals’ cognition raise two very important questions. First,         hotly debated topic within the comparative literature (see
what are the cognitive processes that allow for the behavioral
flexibility observed in human reasoning but not in that of               1
                                                                            For example, knows(communicator, contains(box, reward)).
other species? Second, to what extent are the mechanisms              Words in italics represent predicated relational concepts (i.e.,
underlying these processes shared across species?                     abstracted relations that are independent of the objects to which
   In an attempt to address the first question, Penn, Holyoak,        they are bound). The objects within the parentheses denote the
and Povinelli (2008) suggest that the cognitive process that          actors fulfilling these roles. In this example: box (actor; the object
lies at the heart of the observed differences between human           doing the containing) contains (predicated relational concept)
                                                                      reward (patient; the object being contained). Knows is another
and nonhuman animals is relational reasoning. Relational
                                                                      predicated relational concept that is taking the contains(box,
reasoning, in short, is reasoning about some object based on          reward) predicate as the patient (the thing that is known about),
the role that it plays rather than its physical features alone.       thereby forming a higher-order relational structure.
                                                                  2044

Penn & Povenilli, 2007, for a discussion). Call and                      moved before the communicator marked the box she
Tomasello (1999) demonstrated that 4- and 5-year-old                     believed the reward to be in (Task 4), they failed to choose
children are capable of reasoning about the false beliefs of             the unmarked box when they had seen the boxes moved
an observer (a type of theory of mind task) and attempted to             before the communicator marked one (Task 5).
test whether chimpanzees (Pan troglodytes) and orangutans
(Pongo pygmaeus) also possess this ability.                              Model Description
   The original experiment was separated into four control                  Although there are many models of relational reasoning
tasks and one false belief task. In all five tasks, the hider            (e.g., Falkenhainer, Forbus, & Gentner, 1989; Holyoak &
would put a reward in one of two boxes, out of view of the               Thagard, 1989), of particular interest to the proposed study
participant and in full view of the communicator. The                    are LISA (Learning and Inference with Schemas and
communicator would then place a marker on the box that                   Analogies), developed by Hummel and Holyoak (1997,
she saw the reward go into and the participant had to choose             2003) and DORA (Discovery of Relations by Analogy),
the box that contained the reward. 2 Each control task                   developed by Doumas et al. (2008). Collectively, LISA and
evaluated participants’ abilities to perform an individual               DORA account for over 90 phenomena from the human
component of the false belief task. Task 1 addressed the                 cognitive development literature (e.g., Doumas et al., 2008;
question of whether the participant was able to choose the               Hummel & Holyoak 1997, 2003). DORA was developed
marked box in order to obtain a reward. In Task 2, the                   from LISA in response to the criticism that the LISA model
communicator marked the location of the reward, then the                 was not able to account for where the structured
hider moved the reward from one box to the other in full                 representations it uses might originate (Munakata &
view of the participant; this task assessed the participant’s            O’Reilly, 2003; O’Reilly & Busby, 2002; O’Reilly, Bubsy,
ability to track the movement of the reward when it was                  & Soto, 2003). DORA solves this particular problem by
visibly displaced. In Task 3, the communicator marked the                offering a neurally plausible instantiation of how structured
location of the reward, and then the hider moved the boxes               representations can be learned from unstructured examples
(one of which contained the reward) rather than the reward               observed in the environment and thus provides an account
itself. In Task 4, the hider moved the reward from one box to            of how children (and adults) acquire the representations that
the other in full view of the participant (as in Task 2) but out         allow them to reason relationally.
of the sight of the communicator before the communicator
marked a box; to choose the box containing the reward, the
participant had to ignore the communicator’s mark when the
communicator was known to be wrong (i.e., the participant
had seen the reward being placed in the other box).
   In the fifth and final manipulation of the task (i.e., the
false belief task), understanding what the communicator did
and did not know became essential for selecting the box
containing the reward. Specifically, the hider switched the
locations of the boxes in full view of the participant (as in
Task 3) but out of the sight of the communicator before the
communicator marked a box (as in Task 4). Of critical
importance, when the communicator marked the box in
which she had seen the reward hidden, it was the wrong one
because she did not know that the boxes had been moved.                        Figure 1. The proposition “box contains reward” is
Thus, Task 5 addressed whether the participant understood                       represented at the various levels of localist units.
that the communicator had been fooled. Tasks 1 - 4 do not                    These representations are distributed in the sense that
require the participant to reason about the mental contents of                units in the layer above conjunctively code for units
another while Task 5 requires the participant to recognize                                      in the lower layers.
that the communicator holds a false belief. All of the apes
performed below chance on these false belief trials (Task 5),            Nature of Representations Representations within
despite the fact that they performed well above chance on                LISA/DORA exist as a hierarchy of distributed and localist
the component tasks (Tasks 1 - 4). Thus, although the apes               units in a layered connectionist architecture (see Figure 1).
demonstrated that they were capable of choosing the                      On the bottom layer of the representational structure are
unmarked box when they themselves had seen the reward                    semantic units coding for the features of objects and roles
                                                                         (or predicates) in a distributed fashion. In LISA/DORA,
   2
                                                                         semantic units are shared between predicates and objects for
     The marker was removed after a few seconds when the                 two important reasons. First, it is important for the meaning
children were performing the task. In contrast, the marker               of some property of an object and the explicit predicate of
remained on the box for the apes because performing the task with
the marker removed proved too difficult for all but one of the apes,
                                                                         that property to mean the same thing (Doumas et al., 2008).
possibly due to working memory constraints (Read, 2008).                 That is, without a shared pool of semantic units, ‘blue’ as a
Otherwise, the tasks were the same for the children and the apes.        feature of the ocean would be unlike ‘blue’ as a predicate,
                                                                     2045

which can be cast upon any object (Doumas et al., 2008).            model with representations that include the strengths of both
Localist predicate-object (or PO) units in the layer above the      symbolic systems (i.e., structure sensitivity) and connectionist
semantic units act as tokens for individual predicates and          systems (i.e., distributed representations), while suffering
objects. Above the PO units, localist role-binding (RB) units       the limitations of neither (see, e.g., Doumas & Hummel,
link predicate and object units into role-filler pairs.             2005, 2010; Hummel & Holyoak, 1997, 2003).
Proposition (P) units in the top layer link sets of RB units
together to form whole propositions.                                Mapping and Relational Learning Generally speaking,
                                                                    mapping (i.e., the process of comparison) creates
                                                                    opportunities for DORA to predicate new properties.
                                                                    Mappings between units in the driver and the recipient
                                                                    indicate that these units have some properties in common.
                                                                    DORA’s mapping algorithm is the same as LISA’s; when
                                                                    units are active in both the driver and recipient
                                                                    simultaneously, the model attempts to map them by learning
                                                                    connections between them. Therefore, as units in the driver
                                                                    become active (i.e., as DORA ‘thinks’ about them), they
                                                                    will activate structurally and semantically similar units in
                                                                    the recipient through any shared semantic feature units. As a
                                                                    consequence, DORA maps structurally and semantically
                                                                    similar propositions across the driver and the recipient.
                                                                       In DORA, learning is a function of the ability to compare
                                                                    (see Doumas et al., 2008 for details). DORA begins with
                                                                    simple feature vector representations of objects (i.e., a PO
                                                                    unit connected to semantic units). As DORA goes through
    Figure 2. Relational learning in DORA; a new PO unit            the process of comparing two objects, and they become co-
    is recruited that codes for the featural overlap between        active, the corresponding features of those objects also fire
      two objects. This new PO unit becomes an explicit             in unison. Any semantic units that the two objects have in
                representation of these features.                   common become highlighted by virtue of receiving twice
                                                                    the activation that unshared units receive (see Figure 2a).
Flow of Control In LISA/DORA, propositions are divided              DORA then recruits a new PO unit and learns connections
into two mutually exclusive sets as they enter working              between said unit and the active semantic units in proportion
memory. The first set, the driver (analogous to what the            to their activation via a Hebbian learning rule (i.e., stronger
model is “attending to” at any given time; see Figure 2a)           connections to more active units; see Figure 2b). This
controls the sequence of firing events. The patterns of             process generates an explicit representation of all of the
activation imposed on the semantic units by tokens in the           properties shared between the two objects, including those
driver allow LISA/DORA to retrieve propositions from long           which may be irrelevant. For example, if a red apple is
term memory into the second set, the recipient (analogous to        compared to a red fire engine, the explicit representation of
active memory; Cowan, 2001; see Figure 2a), thereby making          ‘red’ learning by the model will also carry with it any other
them available for mapping to propositions in the driver.           features shared by the compared objects (e.g., both objects
Activation in the model then flows from the driver into the         also might also contain the feature ‘shiny’). Consequently,
shared pool of semantic units, which, in turn, causes token         additional examples of ‘red’ are needed in order to rid the
units in the recipient to become active (Doumas et al., 2008).      representation of extraneous features. As DORA compares
   When a proposition becomes active in the driver, role-           multiple instances of ‘red' objects extraneous features wash
filler bindings must be represented dynamically on the units        out, leaving only the essential features of the concept (see
that maintain role-filler independence (see, e.g., Hummel &         Figure 2c). Doumas et al., (2008) demonstrated how this
Holyoak, 1997). Unlike LISA (in which binding                       process, applied over a range of examples, allows DORA to
information is carried via synchrony of firing), DORA               learn explicit structured representations of object properties
carries binding information via systematic asynchrony of            and relational roles that can be linked together to create
firing. Specifically, roles and the arguments to which they         complex relational structures (see Figure 2d).
are bound fire in direct sequence as asynchronous couplets.
The result is a pattern in which bound role-filler pairs fire in    Simulations
direct sequence and out of synchrony with other bound role-         The goal of the simulations presented herein is to explain
filler pairs. Carrying binding information by when units fire       the behavioral data of Call and Tomasello (1999) by
allows identity information to be carried independently by          demonstrating that the types of relational structures that are
which units fire. Thus, DORA solves the dynamic binding             available to the reasoner (in this case, the ape or child)
problem while processing structured symbolic representations        influences his/her performance on theory of mind tasks. We
in a fundamentally connectionist architecture. The result is a      accomplish this by manipulating the types of knowledge
                                                                2046

structures that are available to the model and comparing its           The results of Simulation 1 are depicted in Figure 3. The
performance to the behavior observed in the original                model was 100% accurate on all of the control task
experiment. More specifically, simple knowledge structures          simulations (Tasks 1 - 4). In comparison, the apes’ scored
may be able to account for nonhuman primate data while              87% correct on the task in which they had to choose the
more complex (i.e., abstract/relational) knowledge                  marked box (Task 1), 95% correct on the task in which they
structures may be required to account for the performance of        witnessed the hider move the reward after the communicator
4- and 5-year old children. That is not to say that humans do       had marked the boxes (Task 2), 92% correct on the task in
not use simpler knowledge structures, but that false belief         which they witnessed the hider switch the locations of the
tasks require these complex structures. The purpose of the          boxes before the communicator marked one (Task 3), and
present simulation is not to demonstrate how relational             93% correct on the task in which they had seen the location
representations are acquired; therefore, these structures are       of the reward and had to ignore the communicator’s
built-in from the onset of the simulation. However,                 (incorrect) mark (Task 4). 3 Similarly, the model performed
importantly, all of the structures we use in the simulation         at 0% on the false belief manipulation (Task 5), while the
can be easily learned via DORA’s predicate learning                 apes performed at 10.7%. Thus, DORA’s performance
routines. For a detailed account of how these structures are        closely resembled the behavioral data collected from all five
learned see Doumas et al. (2008).                                   of Call and Tomasello’s (1999) tasks. For these simulations,
                                                                    we assumed that the model had perfect attention and
Simulation 1: Apes To simulate the apes’ performance on             focused only on the boxes and the task criteria. The small
the non-verbal false belief task, we assumed that, instead of       differences that were observed between the model’s
reasoning based upon the actions of an observer, the apes in        behavior and the behavioral data could be fit by adding
the study were using selection criteria based on                    noise into the simulations.
combinations of visual features present in the experimental
context. Specifically, if the reward is seen in a particular        Simulation 2: 4-Year-Old Children Both the children and
location, choose that location; otherwise, choose the box           the apes had little difficulty selecting the location of the
with the marker on it. Each task was coded with box1 and            reward if they had seen where it had gone, and neither group
box2 objects (represented by PO units); the features of these       had difficulty using the marker as a cue for the location of
objects included generic features of boxes, whether they had        the reward. Simple rule use can easily account for this
a mark, and whether the reward was seen being put into              pattern of behavior, so we assumed that the 4-year-old
them. Two objects representing selection criteria were created      children were initially reasoning about the task in much the
and then placed in the driver while the representations of the      same way as the apes did. However, unlike the apes,
boxes were loaded into the recipient. The model was then            children would likely be building and refining more
allowed to generate mappings between the selection criteria         complex representational structures for the task across
in the driver and the boxes in the recipient. Whichever             manipulations and trials.
selection criterion DORA mapped to in the driver was taken             Therefore, Simulation 2 focused specifically on how the
as DORA’s “choice” of the box to investigate for the                performance of the 4-year-old children changed during the
reward. Note that mapping in this manner utilizes only the          course of the false belief task. This simulation was
featural (as opposed to relational) aspects of the task and         conducted by first placing the proposition hasMark(box) +
can therefore be entirely accounted for by associative              select(box) in the driver and hasMark(box1) and
learning mechanisms. There were four possible mappings              noMark(box2) in the recipient.4 Each trial consisted of first
DORA could make. A success was counted when the proper              allowing DORA to map the representations in the driver to
selection criterion was placed in correspondence with the           the hasMark(box1) and noMark(box2) in the recipient, and
proper object; the other three mappings were considered             then use relational inference to select a box. If the model
misses. A total of ten trials per manipulation were simulated.      inferred the representation select(box2), it was recorded as a
                                                                    hit and all other inferences were counted as misses. 5
                100                                Apes             Fourteen blocks of four trials each were run for a total of 56
                                                   DORA             trials. The 4-year-old children and the model both
                75                                                  performed below chance on the false belief task and
    % Correct
                                                                       3
                50                                                       Due to the unavailability of the experimental data, percentages
                                                                    from tasks 2, 3, and 4 have been estimated from the figures and t-
                25                                                  statistics reported by Call and Tomasello (1999).
                                                                       4
                                                                         Here, “+” denotes binding simple representational structures into
                 0                                                  propositions (i.e., multi-place predicates). See Doumas et al. (2008)
                      1   2      3        4        5                for further discussion of how propositions are encoded and used for
                               Tasks                                reasoning in DORA.
                                                                       5
                                                                         The box1 and box2 objects differed only in regard to whether
   Figure 3. The comparison of the apes’ performance to             they carried semantic units for being marked or having the reward.
          that of the model used in Simulation 1.                   Therefore, counter-balancing which box had the ‘reward’ semantic
                                                                    unit was unnecessary.
                                                                 2047

exhibited gradual improvement across trials. The 4-year-             authors provide an alternative explanation, speculating that
olds’ average performance across all four trials was about           the task may have been too difficult for the apes, as success
38% correct and the model’s was about 41% correct.                   would have involved coordinating many different small
   According to the changes in DORA’s representations                pieces of evidence. This interpretation does not preclude apes
across trials, this increase in accuracy is due to the fact that     from possessing theory of mind per se; however, there has yet
the mark always predicted the presence of the reward; thus           to be a definitive demonstration of theory of mind capabilities
DORA’s representation of the task initially had the features         in apes (see Penn & Povenelli, 2007 for further discussion).
‘mark’ and ‘reward’ bound to the same PO unit. In regard to             In support of Call and Tomasello’s conclusion, their
the children, this translates to their representations of these      results were simulated without any information from the
features being conflated. Therefore, 4-year-old children             observer or the hider. Therefore, it is unlikely that the
would have had to update their conflated representations             observer’s behavior had any impact on the apes’ reasoning.
and generalize a new rule before they could succeed on the           DORA’s ability to account for these behavioral data without
false belief task. Likewise, DORA’s representation was               the structured representations typically thought of as being
refined over successive trials (see the above section titled         necessary for relational reasoning suggests that apes
Relational Learning for a description of how DORA                    succeeded on the control tasks by using simple associative
accounts for this error and its resolution).                         learning alone; namely, retrieving memories of receiving
                                                                     rewards and the associated perceptual features of the task
Simulation 3: 5-Year-Old Children Seventy-nine percent               configuration, then mapping those features onto the test
of the 5-year-old children in Call and Tomasello’s (1999)            configurations. This claim is further substantiated by the
study were successful on their first attempt at the false belief     apes’ failure on the false belief task, in which using
manipulation; we therefore focused on their performance in           relational inference was necessary for reasoning about the
the first trial and assumed that, by this age, children have         mental contents of another.
built a representation of the rules “If knows(x), then                  The results from the simulations of 4- and 5-year-olds
accurate(x),” and “If notKnows(x), then inaccurate(x).” On           provide evidence that children are using relational
all trials in which the notKnows(x) + inaccurate(x)                  knowledge (in addition to associative learning mechanisms)
proposition      was     placed    into    the    driver    and      to reason about the task. The difference between the
notKnows(communicator) was placed into the recipient, the            performances of 4- and 5-year-olds seems to be whether
model was able to infer that, because the communicator did           they possess the particular relational representation required
not know the location of the reward, the communicator’s              to reason about false beliefs (i.e., notKnows(x)). Although
mark was inaccurate and, therefore, selecting the marked             these simulations do not provide conclusive evidence that
box was not the correct choice. It is worth noting that the          apes lack theory of mind capabilities, they support the
model had perfect attention and task execution, whereas              notion of relational reasoning being critical to both the
some portion of the children’s errors may be attributable to         observed differences in apes’ and humans’ performance on
loss of attention and lack of inhibitory control. Together,          false belief tasks and in human and nonhuman animal
attention and inhibition are likely explanations for the             cognition in general.
discrepancy between the model’s perfect performance and
children’s slightly less than perfect performance. Our goal in                               References
these simulations was not to adjust parameters unnecessarily         Bergman, T. J., Beehner, J. C., Cheney, D. L., & Seyfarth,
(e.g., by adding noise) to more closely fit the data. Instead           R. M. (2003). Hierarchical classification by rank and
we were concerned with qualitative fits and making the                  kinship in baboons. Science, 302, 1234-1236.
fewest additional assumptions possible. As such, we did not          Call, J., & Tomasello, M. (1999). A nonverbal false belief
include properties like reduced attention or noise, but rather          task: The performance of children and great apes. Child
sought to simulate general trends using slight variations in            Development, 70, 381-395.
the types of knowledge representations available to the              Cook, R. G., & Wasserman, E. A. (2007). Learning and
model. Specifically, we were able to simulate the behavior              transfer of relational matching-to-sample by pigeons.
of the apes using only holistic feature properties, whereas             Psychonomic Bulletin and Review, 14, 1107-1114.
structured representations were required to simulate the             Cowan, N. (2001). The magical number 4 in short-term
behavior of the children. While these structures can be                 memory: A reconsideration of mental storage capacity.
learned from holistic feature vectors (see Doumas et al.,               Behavioral and Brain Sciences, 24, 87-114.
2008), Penn et al., (2008) argue that it is precisely the            Dally, J. M., Emery, N. J. & Clayton, N. S. (2006). Food-
capacity to learn and manipulate these structures that                  caching western scrub-jays keep track of who was
differentiates human and non-human cognition.                           watching when. Science, 312, 1662-1665.
                                                                     Doumas, L. A. A., & Hummel, J. E., (2005). Approaches to
                           Conclusion                                   modeling human mental representations: What works,
Call and Tomasello (1999) concluded that the apes were not              what doesn’t and why. In K. J. Holyoak and R. Morrison
capable of utilizing the mental contents of the observer to             (Eds.), The Cambridge handbook of thinking and
reason successfully on the false belief task. However, the              reasoning. Cambridge: Cambridge University Press.
                                                                 2048

Doumas, L. A. A., & Hummel, J. E., (2010). A
  computational account of the development of the
  generalization of shape information. Cognitive Science,
  34, 698-712.
Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M.
  (2008). A theory of the discovery and predication of
  relational concepts. Psychological Review, 115, 1-43.
Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The
  structure mapping engine: Algorithm and examples.
  Artificial Intelligence, 41, 1-63.
Gentner, T. Q., Fenn, K.M., Margoliash, D., & Nusbaum,
  H.C. (2006). Recursive syntactic pattern learning in
  songbirds. Science, 440, 1204-1207.
Holyoak, K. J., & Thagard, P. (1989). Analogical mapping
  by constraint satisfaction. Cognitive Science, 13, 295-355.
Hummel, J. E., & Holyoak, K. J. (1997). Distributed
  representations of structure: A theory of analogical access
  and mapping. Psychological Review, 104, 427-466.
Hummel, J. E., & Holyoak, K. J. (2003). A symbolic-
  connectionist theory of relational inference and
  generalization. Psychological Review, 110, 220-264.
Lazareva, O. F., Smirnova, A. A., Bagozkaja, M. S., Zorina,
  Z. A., Rayevsky, V. V., & Wasserman, E. A. (2004).
  Transitive responding in hooded crows requires linearly
  ordered stimuli. Journal of the Experimental Analysis of
  Behavior. 82, 1-19.
Medin, D. L., Goldstone, R. L., & Gentner, D. (1993).
  Respects for similarity. Psychological Review, 100,
  254-278.
Munakata, Y., & O’Reilly, R. C. (2003). Developmental
  and computational neuroscience approaches to cognition:
  The case of generalization. Cognitive Studies, 10, 76-92.
O’Reilly, R.C., & Bubsy, R. S. (2002) Generalizable
  relational binding from coarse-coded distributed
  representations. In T.G. Dietterich, S. Becker, & Z.
  Ghahramani (Eds.), Advances in neural information
  processing systems (NIPS) (Vol. 14). Cambridge, MA:
  MIT Press.
O’Reilly, R. C., Bubsy, R. S., & Soto, R. (2003). Three
  forms of binding and their neural substrates: Alternative
  to temporal synchrony. In A. Cleeremans (Ed.), The unity
  of consciousness: Binding, integration, and dissociation.
  Oxford: Oxford University Press.
Penn, D. C., Holyoak, K. J. & Povinelli, D. J. (2008).
  Darwin’s mistake: Explaining the discontinuity between
  human and nonhuman minds. Behavioral and Brain
  Sciences, 31, 109-178.
Penn, D. C., & Povinelli, D. J. (2007). On the lack of
  evidence that non-human animals possess anything
  remotely resembling a ‘theory of mind.’ Philosophical
  Transactions: Biological Sciences, 362, 731-744.
Read, D. W. (2008). Working memory: A cognitive limit to
  non-human primate recursive thinking prior to hominid
  evolution. Evolutionary Psychology, 6, 676-714.
Sandhofer, C. M., & Doumas, L. A. A. (2008). Order of
  presentation effects in learning color categories. Journal
  of Cognition and Development, 9, 194-221.
                                                              2049

