UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cutting In Line: Discontinuities in the Use of Large Numbers by Adults
Permalink
https://escholarship.org/uc/item/7tb2h41q
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Landy, David
Charlesworth, Arthur
Ottmar, Erin
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

           Cutting In Line: Discontinuities in the Use of Large Numbers by Adults
          David Landy (dlandy@indiana.edu)                                 Arthur Charlesworth (acharles@richmond.edu)
       Department of Psychological & Brain Sciences                           Department of Mathematics and Computer Science
             Indiana University, Bloomington IN                                    University of Richmond, Richmond VA
                                            Erin Ottmar (erin.ottmar@richmond.edu)
                                                        Department of Psychology
                                                  University of Richmond, Richmond VA
                              Abstract                                 experiences of this many individual items are vanishingly
                                                                       rare, but small enough to play important roles in sciences
   Perceptual tools such as telescopes allow the application of        such as geology, astronomy, and macroeconomics, and in
   robust internal perceptual systems to apply beyond the range        political contexts such as budget discussions. There is little
   of their unadorned capacity. This paper explores how
   reasoning over culturally provided representations enables the      reason to think that evolution would have specially prepared
   perception of conceptually distant structures. In particular,       us to deal with quantities of this magnitude. How do we
   this paper examines the behavior of typical adults estimating       come to access them, and take advantage of their properties?
   the position of large numbers (1 thousand to 1 billion) on a
   number line. Participants—even those who closely match              Representations that Contribute to Quantity
   linear placement—show discontinuities in placement in the
   immediate vicinity of 1 million. This pattern was predicted by         For small numbers, it appears that matching numbers to
   a theoretical account in which linear behavior across many          magnitudes requires the coordination of several systems.
   orders of magnitude is achieved through highly linear patterns      For instance, small exact set sizes may result from the active
   of placement on smaller lines that are recycled and scaled to       coordination of memorized count lists, pointing procedures,
   larger numerosities. Just as the telescope allows perception of     and a perceptual system that responds selectively to
   the imperceptibly distant, reasoning processes over the natural     numerosity (Feigenson, Dehaene, & Spelke, 2004; Carey,
   numbers appear to allow intrinsically limited magnitude-
                                                                       2009). Although exact numbers over 20 are typically not
   perception systems to apply (with distortion) to much larger
   scales.                                                             well linked to perceived set sizes (Izard & Dehaene, 2008;
                                                                       Sullivan & Barner, 2012) the linearity of the metric scale of
   Keywords: mathematical cognition, concepts, high-level              the numbers extends out much further (Siegler & Opfer,
   reasoning, numerical cognition                                      2003). Still, at some point even a log-based neural scale
                                                                       must run out. We simply cannot have lognormal response
                           Introduction                                nodes that span the natural numbers, since our brains are
   Much reasoning in mathematics involves taking structures            finite in size, nor can we have created the entirety of the
well-defined in particular concrete domains and extending              natural numbers through a completed infinity of recursions.
them to new less accessible contexts. For example,                     Furthermore, typical environments do not require the
exponents are often presented initially to learners as                 individuation of sets as large as 10^9 (1 billion). How do
repeated multiplications: x2=x*x. This idea is then extended           we deal with these quantities when we do encounter them?
to zero exponents, fractional and real exponents, and even                One possibility is that we induce new tokens as needed
complex-valued exponents. This paper focuses on a very                 throughout life, extending a process essentially identical to
elementary instance of the extension from the concrete to              that used to induce numbers small enough to encounter
the abstract: the extension of the natural numbers beyond              frequently (Leslie, Gelman, and Gallistel, 2009; Gelman,
the feasibly countable range. Mathematics often deals with             2011). We might call this the domain continuity hypothesis.
numbers far outside any normal experience. For instance,               Numbers in the range of 10^9 might be recursively
currently the largest known prime number (the 48th                     generated through successorship. On this account, our
Mersenne prime) would contain 17,425,170 digits if written             cognitive systems do not represent a completed infinity, but
as an Arabic numeral.                                                  represent the natural numbers through unbounded
   It is easy enough to order these numbers from smallest to           extensibility. A plausible but (to our knowledge) novel
largest; it is much, much harder to have any sense of their            hypothesis is that a lognormal representation system could
actual size. Nor is their actual size of any importance,               be extended to include large numbers, as needed, by the
except for practical reasons of computation. Almost                    creation of new, log-normally responsive tokens with some
exclusively, when magnitude is important for very large                spacing. Representing the entirety of numbers up to 10^12
numbers, it is in comparison to other numbers related by               this way requires less than 100 times the resources required
some thread of reasoning in the same problem.                          to get from 2-3. While we cannot hope to construct a
   In this paper, we examine much more prosaic “big                    representation of a large Mersenne prime this way, we
numbers”: those numbers just beyond the limit of practical             might well deal with large government deficits using the
countability—in the range of about 10^6-10^12. These                   same log-normally distributed quantity representations that
numbers fall into an important boundary: so large that                 seem to be shared across many other species. Alternatively,
                                                                   815

to the degree that linear representation schemes and                       Table 1. Stimuli used in the Experiment
logarithmic internal resources are combined to form linear                    Number Range         Stimuli Used
number representations for smaller numbers (Carey, 2009;                      Thousands          10, 60, 100, 150, 230, 250, 310,      380,
Thompson & Opfer, 2010), a plausible domain continuity                                           420, 480, 500, 580, 640, 680, 720,    780,
hypothesis might extend this process to larger numbers,                                          840, 890, 940, 950
extending linear behavior out to any desired range.                           Millions           1, 2, 3, 4, 60, 100, 150, 230, 250,   310,
   Alternatively, it might be that when numbers exceed some                                      380, 420, 480, 500, 580, 640, 680,    720,
endogenous or exogenous boundary, the manner in which                                            780, 840, 890, 940, 950
neural resources are coopted to capture magnitude
qualitatively shifts from a more-or-less direct one-step                   one for numbers under, and one for numbers over 1 million
mapping from the metric structure of quantities or number                  (more generally, the theory posits one line for each number
words into spatial layout, to a more complex strategy. That                range involved in the task). This strategy raises a
is, people may reason about how to line up number words                    coordination problem not present in other versions of this
and number lines. Landy, Goldin, and Silbert (2013) found                  task: the right end of the ‘thousands’ line must be aligned
evidence for such mediated reasoning processes in the                      with the ‘left’ end of the millions line. The four panels of
behavior of college-aged adults and adults recruited online.               Figure 1 indicate possible outcomes. The left panel indicates
On a number-line placement task with boundaries of 1                       truly linear behavior. Note however that the x-axis has been
thousand and 1 billion, about 40% of participants placed                   scaled quite unusually. We have highlighted behavior
marks in a ‘piecewise linear’ pattern: the position of 1                   around 1 million by placing 1 million at the middle of the x-
million was very wrong (about 37% from the left edge of                    axis, and scaling the rest of the axis linearly. This allows the
the page), but numbers between 1 million and 1 billion were                examination of the theoretical predictions more easily than
placed extremely linearly, as were numbers between 1                       log-scaling the axes, since this way the predictions involve
thousand and 1 million. Note that on this task, also used in               straight-line behaviors. In the leftmost panel of Figure 1, the
the current article, the correct linear location of 1 million is           location of 1 million has been correctly placed by the
quite far to the left. Because there are 1 thousand millions               hypothetical participant very close to the left hand edge;
in 1 billion, the location of 1 million lies about one                     judgments are linear for smaller and larger numbers.
thousandth of the way from one thousand to one billion.                       The next three panels show varying kinds of
   One interpretation is that the “piecewise linear”                       discontinuity. The second panel indicates the kind of
participants were successfully applying their understanding                behavior reported by Landy et al (2013): a single fixed
of linearity over the two sub-ranges and simply adjoining                  ‘million’ location, with linear behavior left and right of it.
the two line segments to yield a combined mapping1, with                   The right two panels illustrate the coordination problem
the millions range slightly larger than the thousands. We                  mentioned above: if two separate lines are adjoined to
will call this a reuse hypothesis (Anderson, 2010), since the              accomplish the task, then there is no reason the left edge of
resources normally used to process small numbers are                       one should align with the right edge of the other. There
rearranged and recycled (rather than extended) to handle                   might be a gap (third panel) or overlap (rightmost panel).
numbers outside their typical domain.                                         These two theoretical accounts can be discriminated by
                                                                           examining closely the boundary around 1 million. On the
Behavioral Predictions                                                     domain continuity hypothesis, performance should be very
   The central theoretical question here concerns the                      close to linear, and any strong deviations are likely to be
proportion of participants who respond nearly linearly on                  symmetric and continuous, roughly fitting power-law or
larger number lines. How do they achieve this accuracy?                    linear performance (Barth & Paladino, 2011; Opfer, Siegler,
There are two clear possibilities: one is that people continue             & Young, 2011). On the reuse hypothesis, although
the process of constructing linear magnitude representations               performance in the aggregate may be linear for some
that is used to construct representations of smaller range. On             participants, both the linear and non-linear responders
the other hand, it may be that people shift strategies, and                should show evidence of ‘joining’ their lines: there should
that linearity is achieved through the deliberate cooption and             be discontinuities in placement behavior in the vicinity of 1
reuse of pre-existing processes.                                           million. On this account, participants must first make a
   If linearity is achieved through strategic deployment of                judgment about which line a particular item belongs on—
small-number resources, then linear-like behavior is, like                 whether the element is smaller or larger than 1 million.
piecewise behavior, achieved through the use of two lines:                 After this, they place the mark appropriately relative to the
                                                                           endpoints of the selected line segment. If so, linear
   1
     Several minor points are worth noting: Nearly all participants        responders might still have a ‘cut’ in the line at one million,
in these populations can correctly model the relevant number               but know where the cut goes. One very simple version of
words as numerals, and vice versa. In Landy et al 2013, results            this would be to simply use two lines with the left endpoint
were similar when all stimulus numbers were over 1 million,                of both simply treated as 0. This would cause an overlap,
suggesting that these patterns are not a result of particular stimulus     but on a line from 1,000 to 1 billion the deviation from
distributions. Analogous results obtained when the endpoints were          linearity for the stimuli used would be less than one percent.
1 and 1 billion instead of 1 thousand and 1 billion.
                                                                       816

              True Linear                 Continuous Piecewise          Discontinuous with Gap        Discontinuous with Overlap
   right
    left
                1                                1                              1                               1
                  m                               m                               m                              m
                    illion                           illion                         illion                          illion
   Figure 1: Possible response patterns on the number line placement task. Unlike the number line shown to participants,
which showed 1 thousand and 1 billion without showing 1 million, the x-axis here is scaled to place 1 million at the center,
and linearly scale on each side, which facilitates detection of discontinuity at 1 million. The left panel indicates truly linear
behavior. The next panel indicates continuous placement with 1 million shifted to the right of its normative position. The two
right hand panels illustrate two possible discontinuities. The rightmost panel indicates a non-monotonicity, in which some
numbers in the thousands are placed to the right of some numbers over 1 million.
                             Experiment                                   The experiment started with 10 warm-up trials, with
                                                                       distinct stimuli in the same range as the test stimuli. Each
Method                                                                 stimulus was estimated 4 times by each participant;
Participants. 200 participants were recruited from                     judgments were untimed and separated into blocks of 43
Amazon’s Mechanical Turk (MTurk). MTurk is an online                   unique stimuli. Because of variations in screen size, a line
marketplace in which participants volunteer to complete                with a fixed small number of pixels was used. The stimuli
typically short online tasks in exchange for typically slight          presented in the test phase are presented in Table 1.
compensation. This task took about 20 minutes to complete.                Because the effect of number representation is of interest
In general, participants recruited from MTurk have been                here, format was manipulated between participants: 100
found to behave similarly to other participants on a range of          participants received numerals, such as “54,000,000”; the
cognitive tasks when experiments are carefully conducted               other 100 received hybrid notation stimuli, as in “54
(Crump, McDonnell, & Gureckis, 2013), and have been                    million”. The two stimulus types essentially serve as
extensively used as subject populations in prior work.                 independent samples to validate conclusions. Results
   Design. Instructions showed an image of a small line                indicate that there were no noticeable differences between
(labeled from 0-8), and indicated the placement of ‘6’ as a            formats, so they are collapsed here.
sample. Participants were informed that the endpoints would
be larger than in the sample.                                          Analysis
   Participants were then shown a number line with “1                  Data were analyzed in several steps. First, large “order of
thousand” under the left end, and “1 billion” under the                magnitude” errors were culled. Second, people were
other. Because the study took place on Mechanical Turk,                individually classified into linear and piecewise groups;
the physical length of the stimulus line cannot be                     these groups were further subdivided to isolate groups of
determined. Participants were sequentially presented                   highly linear responders. Finally, each individual’s
numbers in a random order, and selected with the mouse                 responses were separately fitted to behavioral models using
their chosen location for each number. Participants made               a maximum-likelihood procedure, and the models were
182 number line placements. Stimulus numbers were                      compared using a likelihood ratio test to find the best-fitting
selected to sample the ranges under 1 million and over 1               model.
million roughly evenly. Twenty numbers under 1 million,                Culling of Order Errors. Several responses were highly
and twenty numbers above it, were chosen to be integers                compatible with the idea that the participant mis-encoded
with one or two significant non-zero digits, and to be close           the order of magnitude, e.g., by reading “thousand” for
to uniformly spaced within the two subranges. Because the              “million” and vice versa. A two-step process was used to
numbers in the vicinity of 1 million were of particular                prune these data: first a piecewise linear model was fitted to
interest, the range just over 1 million was over-sampled: the          the data for each subject (see below). Then, if a data point
exact numbers 1 million 2 million, 3 million, and 4 million            fit the predicted position for an order of magnitude error
were also included. Landy et al, (2013) found little shift in          better than it fit the predicted position for the actual
participant behavior in response to adjustments of the range           stimulus, it was removed from analysis. Then, the models
of stimuli; the same was expected here.                                were refit to the pruned data. This cleaning process made
                                                                 817

the results more precise, but affected none of the                    the discontinuous model was used to generate two locations
conclusions reached here.                                             for 1 million: one generated from numbers under one
Categorization of Participants. Participants were divided             million, and one from numbers over 1 million. The results
into four groups. The first partition was based on whether            are shown in Figure 3. As in Landy et al (2013), two
the participant responses best fit into the linear or the             clusters of participants can be seen: one group places 1
piecewise cluster (a threshold of 0.3 for the estimated               million far to the left; the other exhibits a broader
million point was used as a rough partition). Participant             distribution, but places 1 million roughly 40% of the way
responses were very well fit by either the linear or piecewise        across the line. Here, however, we can further see strong
linear patterns; however, these responses were distributed            systematicity in the discontinuity pattern: non-linear
bimodally, with one cluster of participants behaving                  participants systematically leave a large “gap” between the
relatively linearly, and a second broader cluster centered            thousand and million scales; very linear participants show
around 0.4 (40% of the way from the left-hand endpoint)               slight but meaningful overlap. A simple test applied to the
(Landy et al, 2013). Because we are here interested in the            four groups (binned, recall, on the mean 1 million location)
behavior of especially highly linear people, we further               finds that all four significantly deviate from point-continuity
divided each of these groups by a median split, leaving one           (Most Linear 95% CI=[-0.025, -0.012; More Linear CI = [-
cluster with “million points” of less than 0.05, another with         0.018, -0.002], More Segmented CI = [0.017, 0.078]; Most
million points between 0.05 and 0.3, a third between 0.3 and          Linear CI = [0.085, 0.15]); the more linear two quartiles
0.48, and a final group with million points above 0.48.               show a significant overlap, while the less linear groups
Other partitions resulted in identical patterns.                      show a significant gap. The data are consistent with the idea
Individual Model Fitting. To detect whether participant               that the most linear participants treat the left hand edge of
responses were continuous and smooth at the location of 1             the line as both “1 million” and as “1 thousand”—a simple
million, we initially fit three models to each participant. The       strategy that would lead to overlapping lines, but also high
first was a simple linear regression (the true linear model):         accuracy.
the endpoints were allowed to deviate from the extreme left
and right, so this model had two free parameters. The data                                       Discussion
were also fitted by a piecewise linear model with a point             We often speak as though natural number is a singular
discontinuity in its slope at 1 million (continuous                   concept, and as though the processing of aligning number
piecewise), and by a model with a discontinuity in both               names with implicit magnitude and individuation
slope and value (discontinuous): in this model, the location          representations—gives us access to the entire structure.
of ‘1 million’ depended on whether it was treated as the              Here we have argued that not only does such an alignment
upper bound of the thousands or the lower bound of the                come over long developmental stretches, it is never fully
millions. In each case, a normal response model was used              completed. Larger numbers whose magnitude can be
for simplicity. Response models were fit by a maximum                 successfully mapped onto a line are not mapped through a
likelihood method, using the R function optim (R                      process of systematically integrating into a common linear
Development Core Team, 2008), and compared using a                    scale. Instead, it seems that both linear and non-linear
likelihood ratio test.                                                responders on the task share a common approach consisting
                                                                      of dividing the scale into culturally given multiplicative
Results                                                               regions, and applying linear responses over those subscales.
   Figure 2 presents mean participant responses, as well as           These subscales must then be coordinated with each other to
deviations away from the best fitting piecewise linear                approximate a single line.
model. A clear pattern of slope discontinuity can be                     Empirically, two novel observations support this
observed in the figure, starting in the vicinity of 1 million.        interpretation: (1) discontinuities in the derivative of the
Indeed, for 75% of participants, the fully discontinuous              response, located at 1 million, for all groups of participants,
model improved the fit of the true linear and piecewise               and (2) systematic patterns of location discontinuity,
linear models (α = 0.05, using a χ2 likelihood ratio test for         shifting from a positive discontinuity or ‘gap’ for non-linear
nested models); an additional 13% were better fit by the              responders, to a small but significant overlap for highly
piecewise than the true linear model. These patterns held for         linear responders. These patterns replicated with both hybrid
the most linear participants: of those in the first quartile, the     and numeric stimuli, suggesting that they result from
fully discontinuous model provided the best fit for 73%,              participants’ numerical reasoning and their construal of the
while 6% of fits were improved by the piecewise model).               task.
   Given that systematic discontinuities in placement                    Although the multiple overlapping lines account does
occurred around 1 million, it is interesting to explore how           predict point and slope discontinuities near 1 million, it does
participants located the million point. For each participant,         not predict the very salient pattern in those discontinuities:
                                                                  818

                                                                                                                                                                                                    0.15
                                            right       Response Bin
                                                                                                                                                                                            Bias
                                                                                                                                                                                                                                                                      ●         ●●
                                                                                                                                                                                                                                                                          ● ●
                                                         ●   Most Piecewise                                                                                                                           0        ●
                                                                                                                                                                                                                   ●
                                                                                                                                                                                                                       ● ●   ●
                                                                                                                                                                                                                              ● ●
                                                                                                                                                                                                                                    ●● ●
                                                                                                                                                                                                                                        ●
                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                     ●   ●
                                                                                                                                                                                                                                                                                             ● ●●
                                                                                                                                                                                                                                                                                                      ● ●●
                                                                                                                                                                                                                                                                                                           ●
                                                                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                                                                               ● ●
                                                                                                                                                                                                                                                                                                                        ●
                                                                                                                                                                                                                                                                                                                        ●
                                                         ●   Piecewise                                                                                                             ●                                                               ●●● ●
                                                                                                                                                                                                                                                         ● ●
                                                                                                                                                                                   ●                                                                         ●
            Response (Proportion Of Line)
                                                                                                                                                                                   ●
                                                                                                                                                                                   ●
                                                                                                                                                                                   ●
                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                   ●
                                                                                                                                                                                   ●
                                                         ●   Linear
                                                                                                                                                                                 ●
                                                                                                                                                                                 ●
                                                                                                                                                                               ●●●
                                                                                                                                                                                                   −0.15
                                                         ●   Most Linear                                                                                                         ●
                                                                                                                                                                           ● ● ●
                                                                                                                                                                               ●
                                            0.75                                                                                                                   ●●                               0.15
                                                                                                                                                                           ● ●
                                                                                                                                                                             ●
                                                                                                                                                               ●
                                                                                                                                                          ●●               ●                                                                                          ●
                                                                                                                                                                       ●
                                                                                                                                                                                            Bias
                                                                                                                                                  ●●                                                                                                              ●       ● ●
                                                                                                                                                                   ●                                                                                                            ●●
                                                                                                                                         ●● ●
                                                                                                                                                               ●       ●
                                                                                                                                                                                                      0        ●
                                                                                                                                                                                                                   ●
                                                                                                                                                                                                                       ● ●   ●●
                                                                                                                                                                                                                                ●   ●
                                                                                                                                                                                                                                        ● ●
                                                                                                                                                                                                                                           ●
                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                   ●     ●
                                                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                                                                 ●●
                                                                                                                                                                                                                                                                                                      ● ●●
                                                                                                                                                                                                                                                                                                               ●         ●
                                                                                                                                                                                                                                                                                                                   ● ● ● ●
                                                                                                                                     ●                                 ●                                                                       ● ●●
                                                                                                                             ●●                       ● ●●         ●
                                                                                                                                                                   ●                                                                                  ● ● ● ● ●
                                                                                                                                                                                                                                                              ●
                                                                                                                                                  ●
                                                                                                                                                               ●                                   −0.15
                                             0.5                                                                         ●
                                                                                                                         ●
                                                                                                                         ●
                                                                                                                         ●
                                                                                                                                         ●●
                                                                                                                                              ●
                                                                                                                                     ●                    ●
                                                                                                                             ●●                           ●
                                                                                                                                                          ●
                                                                                                                                                                                                    0.15
                                                                                                                     ●
                                                                                                                     ●
                                                                                                                 ●       ●                            ●
                                                                                                             ●
                                                                                                                                                                                            Bias
                                                                                                                         ●
                                                                                                       ● ●
                                                                                                   ●
                                                                                                                         ●
                                                                                                                                                ●
                                                                                                                                                                                                      0        ● ●● ●        ●● ●   ● ● ●●     ● ●●● ● ● ● ●
                                                                                                                                                                                                                                                           ●
                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                             ● ●●
                                                                                                                                                                                                                                                                  ●             ●●
                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                                      ● ●●
                                                                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                                                                   ● ● ●
                                                                                                                                                                                                                                                                                                                         ●
                                                                                                                                                                                                                                                                                                                         ●
                                                                                               ●                                                                                                                                                                                   ●         ●
                                                                                                                                                                                                                                                                                                 ●
                                                                                           ●                                                  ● ●
                                                                                       ●                                                                                                                                                                                                 ●
                                                                                      ●
                                            0.25                                                                                              ●
                                                                          ●
                                                                              ●
                                                                                  ●
                                                                                                             ●
                                                                                                                 ●●
                                                                                                                  ●                      ●●
                                                                                                                                          ●                                                        −0.15
                                                                     ●●                         ● ●                                      ●
                                                                                               ● ●                                   ●
                                                                                           ●
                                                             ●
                                                                 ●
                                                                   ●
                                                                              ● ● ●●
                                                                                                                             ●
                                                                                                                                 ●
                                                                                                                                                                                                    0.15
                                                          ●     ●●                                                                   ●
                                                            ●●                                                           ●
                                                                                                                         ●       ●
                                                                                                                                                                                            Bias
                                                        ●●                                                               ●
                                                        ●            ● ● ●● ● ● ● ●
                                                                                    ● ●●● ●                                  ●                                                                        0        ● ●● ●        ●● ●   ● ● ●●
                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                           ● ●
                                                                                                                                                                                                                                               ● ●●● ● ● ● ●   ●●                            ● ●●
                                                                                                                                                                                                                                                                                                      ● ●●
                                                                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                                                                   ● ● ●
                                                                                                                                                                                                                                                                                                                         ●
                                                                                                                                                                                                                                                                                                                         ●
                                                            ● ● ●● ●                                                     ●
                                                                                                                         ●                                                                                                                                                 ●    ●● ●
                                                          ●●  ● ●● ● ● ● ●● ● ● ● ● ● ● ● ●
                                                                                          ●
                                             left       ●●
                                                        ●                                                                                                                                                                                                                                ●
                                                                                                                                                                                                   −0.15
                                                    1                         50                                 1                                50                             1                         1                        50                      1                            50                            1
                                                    th                                0                              m                                    0                                                th                            0                    m
                                                                                                                                                                                     llio
                                                                                                                                                                                                                                                                                                 0
                                                        ou                             th                                illi                                 m                    bi                          ou                          th                     illi                            m                      billio
                                                          sa                               ou                                on                                illi o                  n                           sa                          ou                     on                              illi o                 n
                                                                 nd                            sa                                                                  n                                                    nd                         sa                                                    n
                                                                                                   nd                                                                                                                                               nd
                             Stimulus Magnitude                                    Stimulus Magnitude
     Figure 2: (Left) Mean responses by stimulus condition, binned into groups. Error bars are standard errors around the
   within-group mean. (Right) Mean residual bias (response-prediction) for the piecewise linear model with a single slope
               discontinuity at 1 million. For both panels, the x-axis is piecewise linear (see text description).
overlap for the most linear participants, and large gaps—                                                                                                                                     necessary to “pack” a large number of items near the edge.
about ten to twenty percent of the total line—for the least                                                                                                                                   Finally, if as proposed here number representations in the
linear. Moreover, these results contradict Landy et al., 2013,                                                                                                                                near large range are constructed through processes of
who found a singular ‘million point’ with a mean of around                                                                                                                                    reasoning, it makes sense that they would be task-specific in
0.35-0.4 for non-linear participants. The current modeling                                                                                                                                    character. Although on number line estimation, the multiple-
approach—which unlike previous approaches allows for a                                                                                                                                        overlapping-lines system seems to dominate when numbers
discontinuity at one million—finds two locations for 1                                                                                                                                        have very different magnitude, it may well be that on other
million, one of which is near 0.5 for the segmented groups.                                                                                                                                   tasks, other approaches are used.
The gap between the end of the thousands and the beginning                                                                                                                                      Even for natural numbers just barely beyond the range of
of the millions identified for the segmented groups may be                                                                                                                                    common experience, rather than directly extending core
inferred from the fact that the millions range typically starts                                                                                                                               conceptual tools, people engage in processes of constructive
very close to the midpoint (see Figure 3): participants may                                                                                                                                   perception (Landy & Goldstone, 2005; Goldstone & Landy
integrate a tendency to align the millions scale with a                                                                                                                                       2010): they coopt existing perceptual analyzers (Carey,
visually salient location (the midpoint) with a realization                                                                                                                                   2009) that work well to form linear mappings of smaller
that the millions cover a ‘larger’ range of numbers than the                                                                                                                                  number ranges (not accurate numerosity counts), and
thousands do—leading to a compressed thousand scale.                                                                                                                                          compose and iterate them to create new number ranges,
   It may be tempting to note that the task participants were                                                                                                                                 much in the same manner as external notation systems such
asked to perform was unreasonable—putting half the marks                                                                                                                                      as power towers or Knuth up-arrow notation do. We have
within a pixel of the left-hand end of the line, and thus to                                                                                                                                  found that 1 million is a location for a discontinuity (of
dismiss the observed patterns as ‘task demands’. Such an                                                                                                                                      course, it may not be the only or even the smallest such
explanation would overlook the nature of the experimental                                                                                                                                     boundary)—it might have been the case that familiarity or
situation. Participants are always asked to engage in                                                                                                                                         psychophysical factors created a boundary in strategy at any
particular, usually unusual behaviors. The ways people                                                                                                                                        arbitrary number. The observed pattern suggests that people
grapple with task requirements are informative about the                                                                                                                                      use the culturally provided numeral system to select
resources available to them (Stenning & Van Lambalgen,                                                                                                                                        appropriate magnitudes at which to begin recycling
2008). In this case, it appears people can construct “small”                                                                                                                                  cognitive resources.
linear ranges of around 3 orders of magnitude; beyond that,                                                                                                                                     Telescopes provide an apt metaphor for these cognitive
people make use of culturally available and visually salient                                                                                                                                  tools: they extend the natural bounds of perception by
reference points. Furthermore, while the pattern of                                                                                                                                           connecting them to new contents while also distorting those
discontinuity was quite similar between very linear and very                                                                                                                                  contents. For example, understanding the magnitude of 2
non-linear responders, the perceived task demands shift                                                                                                                                       billion might be less like perceiving its quantity than like
considerably; for the non-linear responders, it is not                                                                                                                                        believing a system of facts that involve magnitude systems.
                                                                                                                                                                                       819

   The natural numbers have amazing properties that derive                                 References
entirely from the successorship function. It appears,            Anderson, M. L (2010). Neural reuse: A fundamental
however, that human representations of natural numbers, at         organizational principle of the brain. Behavioral and
least beyond a paltry few hundred thousand iterations, rely        Brain Sciences, 33(4), 245-313.
on resources quite distinct from successorship or even a         Barth, H., & Paladino, A.M. (2011). The development of
metric “number line”. A fundamental mistake made by                numerical estimation: evidence against a representational
classical empiricism was to assume that the inner                  shift. Developmental Science, 14, 125–135.
representations were iconic—that they were like the outer        Carey, S. (2009). The origin of concepts. New York: Oxford
represented. When reasoning about large numbers, we                University Press.
appear to rely on representations that are fundamentally         Crump MJC, McDonnell JV, Gureckis TM (2013)
unlike the numbers themselves.                                     Evaluating Amazon's Mechanical Turk as a Tool for
                                                                   Experimental Behavioral Research. PLoS ONE 8(3):
                    Acknowledgments                                e57410. doi:10.1371/journal.pone.0057410
   This research was partially funded by Department of           Feigenson, L., Dehaene, S., & Spelke, E. (2004). Core
Education, Institute of Education Sciences grant                   systems of number. Trends in Cognitive Science, 8(7),
R305A110060, as well as an undergraduate research grant            307-314.
from the University of Richmond. Zach Davis, Megan               Gelman, R. (2011) The case of continuity. Behavioral and
DeLaunay, and Brian Guay made valuable suggestions.                Brain Sciences, 34(3), 127-128.
                                                                 Goldstone, R. L. & Landy, D. (2010). Domain creating
                                                                   constraints. Cognitive Science, 34(7), 1357-1377.
                                                                 Izard, V. & Dehaene, S. (2008). Calibrating the mental
                                                                   number line. Cognition, 106, 1221-1247.
                                                                 Landy, D. & Goldstone, R. L. (2005). How we learn about
                                                                   things we don’t already understand. Journal of
                                                                   Experimental and Theoretical Artificial Intelligence, 17,
                                                                   343-369.
                                                                 Landy, D., Silbert, N. & Goldin, A. (2013). Estimating large
                                                                   numbers. Cognitive Science, 37(5), 775-799. doi:
                                                                   10.1111/cogs.1202.
                                                                 Leslie, A. M., Gelman, R., & Gallistel, C. R. (2008). The
                                                                   generative basis of natural number concepts. Trends in
                                                                   cognitive sciences, 12(6), 213-218.
                                                                 Moyer, R. S., & Landauer, T. K. (1967). Time required for
                                                                   judgments of numerical inequality. Nature, 215, 1519-
                                                                   1520.
                                                                 Opfer, J., Siegler, R., & Young, C. (2011). The powers of
                                                                   noise-fitting: reply to Barth and Paladino. Developmental
                                                                   Science, 14, 1194–1204
                                                                 R Development Core Team (2008). R: A language and
                                                                   environment for statistical computing. R Foundation for
                                                                   Statistical Computing, Vienna, Austria. ISBN 3-900051-
                                                                   07-0, URL http://www.R-project.org.
                                                                 Siegler, R. S., & Opfer, J. E. (2003). The Development of
                                                                   Numerical       Estimation     Evidence    for    Multiple
                                                                   Representations of Numerical Quantity. Psychological
                                                                   Science, 14(3), 237-250.
                                                                 Stenning, K., & Van Lambalgen, M. (2008). Human
                                                                   reasoning and cognitive science. MIT Press.
                                                                 Sullivan, J., & Barner, D. (2013). How are number words
                                                                   mapped to approximate magnitudes?. The Quarterly
                                                                   Journal of Experimental Psychology, 66(2), 389-402.
Figure 3: Estimated locations of 1 million in the                Thompson, C. A., & Opfer, J. E. (2010). How 15 hundred is
discontinuous model.      The line indicates continuous            like 15 cherries: Effect of progressive alignment on
behavior; points above the line indicate gaplike behavior,         representational changes in numerical cognition. Child
while points below the line indicate an overlap in the best-       Development, 81, 1768-1786.
fitting lines.
                                                             820

