UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Theory Comparison for Generalized Quantifiers
Permalink
https://escholarship.org/uc/item/5x74c9mq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Ragni, Marco
Singmann, Henrik
Steinlein, Eva-Maria
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Theory Comparison for Generalized Quantifiers
                                     Marco Ragnia (marco.ragni@cognition.uni-freiburg.de)
                            Henrik Singmannb (henrik.singmann@psychologie.uni-freiburg.de)
                                 Eva-Maria Steinleina (eva.steinlein@jupiter.uni-freiburg.de)
                                       a Center for Cognitive Science, b Department of Psychology
                                                            University of Freiburg
                              Abstract                                                       (2)   Some X are not Y .
                                                                                                   Few Y are Z.
   Premises and conclusions in classical syllogistic reasoning are
   formed using one of four quantifiers (All, Some, Some not,            From these premises a reasoner could conclude “Few X are
   None). In everyday communication and reasoning, however,              Z” although again (logically) nothing follows. An additional
   statements such as “most” and “few” are formed as well. So            advantage of using generalized quantifiers is that they can
   far only Chater and Oaksford’s (1999) Probability Heuristics
   Model (PHM) makes predictions for these so-called general-            provide a new benchmark for theories of classical syllogis-
   ized quantifiers. In this article we (i) extend existing and de-      tic reasoning.
   velop new theories, (ii) develop multinomial processing tree              The remainder of this article is structured as follows: We
   (MPT) models for these theories, and (iii) conduct an ex-
   periment to test the models. The models are evaluated with            first review the only existing theory for the generalized quan-
   G2 , Akaike’s (AIC) and Bayesian Information Criteria (BIC),          tifiers most and few – the PHM (Chater & Oaksford, 1999).
   and Fisher’s Information Approximation (FIA). Mental model-           In a second step we extend successful approaches for classical
   based accounts and PHM provide an equal account to the data.          syllogistic reasoning. Specifically, we extend the Matching
   Keywords: Syllogistic Reasoning; Generalized Quantifiers;             Hypothesis and develop two additional mental model-based
   MPTs; Model Selection
                                                                         accounts – one based on minimal models and the other on
                                                                         preferred mental models. Finally, all theories are formalized
                          Introduction                                   via multinomial processing tree (MPT) models and their em-
Syllogistic reasoning derives a conclusion from two quanti-              pirical performance is assessed on data from a new experi-
fied statements. Each statement is formed using one of the               ment.
four quantifiers: all (A), some (I), some not (O), or none (E).
Consider, a simple syllogism, e.g.,                                              Theories for Generalized Quantifiers
          (1)    All cognitive scientists are intelligent.               Established Theory: Probability Heuristics Model
                 Some intelligent people are rich.                       Chater and Oaksford (1999) proposed a Probability Heuris-
Most individuals erroneously infer from these statements that            tics Model (PHM) that accounts for the four classical and two
“Some cognitive scientists are rich” (Khemlani & Johnson-                generalized quantifiers M and F. It predicts that conclusions
Laird, 2012). The only logically valid response is, how-                 are chosen by their likelihood. Chater and Oaksford (1999)
ever, that nothing follows. A meta-analysis by Khemlani and              argue that quantifiers can be ordered according to their re-
Johnson-Laird (2012) investigating twelve theories shows                 spective informativeness:
that there is still no psychological theory that provides a com-                            A > M > F > I > E >> O
prehensive account for human syllogistic reasoning. The as-
sessed theories can be categorized into one of the following             with A being the most informative quantifier as no excep-
three classes: heuristic theories, logical theories, and model-          tions are allowed. Simple heuristics like the min-heuristic
based theories. The findings indicate that heuristic-based               and p-entailments describe the conclusion drawn by individ-
theories (such as the Matching Hypothesis by Wetherick &                 ual reasoners. The min-heuristic postulates that the quanti-
Gilhooly, 1990) and the Probabilistic Heuristics Model (PHM              fier of the conclusion is the same as the one in the least in-
by Chater & Oaksford, 1999) and model-based theories (such               formative premise. Hence, for Example (2) above, the min-
as the Theory of Mental Models, see Johnson-Laird, 2006)                 heuristic predicts reasoners conclude that “Some X are not
performed better overall than theories of mental logic.                  Z” as the first premise (containing O) is less informative than
   It has been criticized that classical quantifiers are too lim-        the second one (containing F). The conclusion drawn by this
ited with respect to everyday contexts. The quantifiers A and            heuristic is called min-conclusion. If more than one conclu-
E are too strict, not allowing any exceptions, whereas I and             sion can be derived from a given problem, the following con-
O are considered too weak requiring only a single individ-               clusions are called p-entailments (i.e., they are probabilisti-
ual (Pfeifer, 2006). In contrast, everyday human reasoning is            cally entailed) of the min-conclusion. For Example (2) the
“based [. . . ] on beliefs, in which there are varying degrees of        min-conclusion “Some X are not Z” entails that “Some X are
confidence” (Evans, 2002, p. 980). In accordance with that,              Z.”
we consider the generalized quantifiers most (M) and few (F),                The predictions were evaluated in two experiments (Chater
e.g.,                                                                    & Oaksford, 1999). Participants received two premises and
                                                                     1228

had to choose one, multiple, or none of four response op-            memory capacity. Additionally, heuristics guide the reason-
tions. Each answer option contained a different quantifier           ing process: Reasoners first construct a model in which they
and related the third term Z to the first term X. The first ex-      try to verify a conclusion with a quantifier from one of the
periment investigated the quantifiers A, M, F, and O, while          premises. The minimal mental model for Example (2) is:
a second experiment considered the quantifiers M, F, I, and                                      X
E. Forcing participants to draw Z − X inferences (though in                                      X     Y Z
good tradition as they argue in their paper) influences the re-                                        Y
sults; experiments in which both orders are permitted (e.g.,                                           Y
Bucciarelli & Johnson-Laird, 1999) have shown that partici-
                                                                     Consequently the reasoner chooses a quantifier from the
pants (sometimes) prefer the X − Z order. An additional point
                                                                     premises and verifies whether it holds in the initial model.
is that multiple responses are more difficult to interpret.
                                                                     Empirical data suggests that this choice is based on the fol-
Extending Classical Theories                                         lowing ordering of quantifiers:
Matching Hypothesis. Another heuristic approach to syl-
                                                                                        E >I≥F >O>M>A
logistic reasoning is the Matching Hypothesis (Wetherick &
Gilhooly, 1990). This theory claims that the quantifier of the       As F appears before O in this order, F is checked and the ini-
conclusion is selected according to the quantifier of the most       tial model of Example (2) supports the conclusion that “Few
conservative premise, i.e., referring to the smallest number         X are Z.” Note that during the construction of the initial
of individuals. Ordered from most to least conservative the          model, the preferred strategy is to minimize the number of
quantifiers are:                                                     individuals, which implies a maximization of the overlap be-
                       E > O = I >> A                                tween individuals.
A strength of this theory is that it can easily be generalized          Although this might in some ways resemble the heuristics
to additional quantifiers. By assuming that M and F are less         of the Unified Theory (for a detailed description, see Johnson-
conservative than I and O – as they not only make statements         Laird & Khemlani, 2014), there is one important difference:
about an arbitrary number, but also impose quantitative re-          The Unified Theory assumes that an initial model is con-
strictions – we get the order:                                       structed first and only with this model in mind do heuristics
                                                                     affect the derivation of a conclusion. In contrast to this, our
                  E > O = I > M = F >> A                             account of Minimal Models predicts that heuristics play a role
For Example (2) above, the predicted responses by the Match-         with regard to the construction of the initial model, which is
ing Hypothesis are “Some X are not Z”, and “Some Z are not           governed by the quantifiers.
X”. This approach, however, is weak in that it cannot explain
instances in which nothing follows from the premises since a         Preferred Mental Models. In a current analysis (Ragni,
least conservative quantifier always exists. Although the pos-       Schrögendorfer, & Nebel, in prep) we formalized the MMT
tulated order of quantifiers differs from the order predicted by     as spatial models, i.e., a mental model can be seen as a map-
the PHM, the underlying mechanisms are quite equivalent.             ping from the set of premises P onto a discrete space N2 . The
                                                                     preferred model is the one which has minimal extension. To
Mental Models and Heuristics. An important non-                      provide an example:
heuristic approach is the Mental Model Theory (MMT)                           (3)    Few of the Architects are Beekeepers.
(Bucciarelli & Johnson-Laird, 1999; Khemlani & Johnson-                              Some of the Beekeepers are Chemists.
Laird, 2012). This theory claims that deductive reasoning               We identify all the architects with a set of instances A, the
consists of the construction and manipulation of mental mod-         beekeepers with a set of instances B, and the set of instances
els.                                                                 of chemists with C for each premise. The syllogism above
   While the classical MMT (Bucciarelli & Johnson-Laird,             is P1 := (Few, A, B) and P2 := (Some, B,C). The preferred
1999) does not provide predictions for reasoning with gen-           mental model for Example (3) is constructed as the minimal
eralized quantifiers (but, see Neth & Johnson-Laird, 1999)           interpretation Ω1 and a map ϕ1 : Ω1 → N2 satisfying premise
a new approach has been proposed by Johnson-Laird and                P1 .
Khemlani (2014) – a Unified Theory – which integrates
heuristics into the MMT. This theory is implemented in a                                                 ˙ B
                                                                                                 Ω1 := A ∪
computer program called mReasoner1 . It contains a seman-                                          0  00
                                                                                      A1 := {a, a , a }, B1 := {b}
tic for the generalized quantifier most (M) in addition to the
                                                                                      ϕ1 :    a 7→ (1, 1) a0 7→ (1, 2)
classical quantifiers.
   We extend the classical theory with the principle of parsi-                           a00 7→ (1, 3) b 7→ (2, 1)
mony, i.e., we assume that reasoners construct Minimal Mod-
                                                                        The graph of ϕ1 is shown in Figure 1 on the upper left
els. This approach receives support from the limited working
                                                                     and consists of the instances {a, a0 , a00 , b}. The instances a
    1 http://mentalmodels.princeton.edu/models/mreasoner/            and b share the same row. Therefore, exactly one A-instance
                                                                 1229

                                                                           Besides heuristics and mental models, another important
                                                                        approach in syllogistic reasoning are theories based on for-
                                                                        mal rules, like for example the PSYCOP model (Rips, 1994).
                                                                        According to this theory, reasoners rely on formal rules of in-
                                                                        ference which they apply to propositional representations of
                                                                        the premises. So far this approach is limited to the classical
                                                                        quantifiers and thus not included in our analysis.
                                                                                Model Comparison and MPT-Analysis
                                                                        One of our main goals was to assess the empirical adequacy
                                                                        of the presented theories. To achieve this in a statistical
                                                                        sophisticated manner, we resorted to formalizing the theo-
                                                                        ries as multinomial processing tree (MPT) models (Riefer
                                                                        & Batchelder, 1988). MPT models are a class of cognitive
                                                                        measurement models for multinomial (i.e., categorical) data
                                                                        that describe observed response frequencies as resulting from
                                                                        latent cognitive states. The probabilities that the cognitive
                                                                        states are reached are estimated from the data and provide
Figure 1: Graphs of preferred mental models to syllogisms               a measure of the contribution of said states to the observed
of the form F-O (ul), and I-M (ur), the conclusion models in            responses. To formalize all models in a consistent manner,
lower row implying the conclusion F (ll), and I (lr)                    we assumed that responses can be produced by one of two
                                                                        (mutually exclusive) cognitive states: A response is either (a)
                                                                        produced by the reasoning processes assumed by the theories,
                                                                        in which case a response predicted by the theories is given, or
a is a B-instance, whereas the A-instances a0 and a00 are not
                                                                        (b) a response is guessed in which case any possible response
B-instances. Thus, the premise P1 is satisfied, and it easily
                                                                        can be given (see Oberauer, 2006, for a similar approach for
follows that Ω1 is chosen with minimal cardinality.
                                                                        conditional reasoning).
   We now choose a proper extension of the model ϕ1 to get
the preferred mental model ϕ of Example (3) shown in Figure                More specifically, regarding (a) we assumed that for each
1 on the upper left. The formal model ϕ2 is minimal. Thus,              syllogism with probability ri (where i represents the specific
to satisfy P2 := (Some, B,C) exactly the B-instance b is row            syllogism) a reasoning state is reached. In the reasoning state,
equivalent to c ∈ C. Therefore, A := {a, a0 , a00 }, B := {b, b0 },     one of the predicted responses is invariantly given (i.e., we as-
and C := {c}. This model is constructed to be minimal, par-             sume the absence of post-reasoning response processes such
simonious, and to satisfy premise P2 . Consider Example (4):            as motor errors). If a theory predicts more than one response
                                                                        for a given syllogism, the probability with which each of the
          (4)   Some of the Artists are not Bakers.                     predicted responses is given is estimated freely from the data
                Most of the Bakers are Cheerleaders.                    (if only one response is predicted, this response is given). One
   On the upper right side of Figure 1 the preferred mental             exception existed for PHM which assumes that two distinct
model ϕ0 of the syllogism                                               processes, min-heuristic and p-entailment, can generate con-
                                                                        clusions and min-heuristic is the preferred process. Conse-
               ((Some Not, A, B), (Most, B,C))                          quently, we imposed a weak-order on the multinomial distri-
                                                                        bution predicted by the reasoning state of PHM such that the
can be found. The model ϕ01 (that is restricted to a, a0 ,
                                                                        probability of responses by min-heuristic was equal or greater
b or formally, ϕ0 |{a,a0 ,b} ) is minimal and satisfies the first
                                                                        than the probability of responses by p-entailments.2
premise P10 := (Some Not, A, B), and is a proper submodel of
ϕ. Through extension of the map ϕ01 to a minimal and parsi-                Regarding (b), we assumed that in cases where the reason-
monious model which satisfies P20 the preferred mental model            ing state is not reached a guessing state is entered with prob-
ϕ0 is constructed.                                                      ability (1 − ri ). Further, we assumed that the guessing state
   Examine the A-C-submodels of ϕ and ϕ0 to draw conclu-                was identical across all syllogisms (i.e., across all i). Within
sions (from these models). The models for Example (3) and               the guessing state, the probability with which each response
Example (4) are given in the lower row of Figure 1. The                 is given is estimated freely from the data. In other words,
submodel ϕAC to example (3) uniquely satisfies the premise              whereas the guessing tree can in principle account for any
P := (Few, A,C), and the submodel ϕ0AC to example (4) holds             observed data pattern, the models are restricted in such a way
P0 := (Some, A,C). As nothing else holds, we conclude from              that the predicted guessing pattern needs to be identical for all
the constructed preferred mental models for problem (3) that                2 In cases where one of the two processes predicted more than one
“Few of the Architects are Chemists.” and for problem (4)               response (which occurred several times), this restriction pertained to
that “Some of the Artists are Cheerleaders”.                            the sum of the predictions from one of the processes.
                                                                    1230

                   Table 1: Reliable responses for all 40 syllogisms and the corresponding response proportions.
                                                                             2. Premise
    1. Prem.    Concl. Type         A               M               I                   F                  E                 O
        A           X-Z                      M(72%), I(24%)                          F(60%)
                    Z-X                      M(56 %), I(32%)                         F(68%)
       M            X-Z         M(84%)           M(84%)          I(68%)              F(60%)         E(36%), F(36%)        I(56%)
                    Z-X         M(68%)       M(56%), I(36%)      I(60%)          F(56%), I(36%)     E(44%), F(28%)        I(52%)
        I           X-Z                          I(76%)                          F(56%), I(32%)
                    Z-X                          I(68%)                              F(52%)
        F           X-Z          F(76%)          F(64%)          F(64%)              F(84%)         E(40%), I(28%)    F(44%), I(32%)
                    Z-X          F(72%)      F(56%), I(32%)  I(40%), F(36%)          F(68%)             E(44%)        F(32%), I(28%)
        E           X-Z                          E(68%)                              E(64%)
                    Z-X                          E(72%)                              E(56%)
       O            X-Z                      I(48%), F(36%)                      F(48%), I(24%)
                    Z-X                          I(56%)                          F(56%), I(24%)
  Note. Responses which occurred significantly often (>22%). For one item the modal response (M, in bold) was given significantly more
  often than a second reliable response (I).
syllogisms for a given theory (i.e., guessing is constant across      and type their answer (i.e., only the quantifier) into a provided
syllogisms).                                                          response field (see example below). Participants could only
   The advantages of formalizing the theories in such a               proceed to the next syllogism if they entered one of the six
way are basically threefold. First, formalizing all theories          quantifiers into the response field. In order to enhance rea-
within one model class allows a consistent statistical treat-         soning and avoid fast responses, “nothing follows” was not
ment across theories. Second, MPT models are a statistically          provided as a response option. An example item follows:
well developed model class (see Singmann & Kellen, 2012,                     All brokers are waiters.
for an overview). Specifically, in addition to assessing model               Few waiters are agents.
fit via the G2 statistics we can employ model selection in-
                                                                             What follows?
dices that provide a sort of automatic Occam’s razor by taking
both model fit and model complexity into account. Here we                                   of the brokers are agents.
use the well-known Akaike information criterion (AIC), the
Bayesian information criterion (BIC), as well as the Fisher                  Quantifiers: All, Some, Some Not, Most, Few, None.
Information Approximation (FIA Wu, Myung, & Batchelder,                  In half of the trials the conclusion related the subject of the
2010) a measure that estimates the flexibility of a model.            first premise (i.e., X) to the end-term of the second premise
Third, by separating and estimating the contribution of rea-          (i.e., Z), and vice versa in the remaining 20 trials; all 40 tasks
soning versus guessing, we can evaluate the contribution of           were of the same form as Example (2) above (i.e., X − Y
both types of processes across theories, but also across syl-         Y − Z, which is also known as Figure I). Each set of 20 syl-
logisms. We now describe the experimental data obtained to            logisms consisted of the following items: 6 syllogisms in
compare the formalized theories.                                      which most appeared as first quantifier and each quantifier
                                                                      appeared as second quantifier once, 6 syllogisms in which
                              Method                                  few appeared as first quantifier and each quantifier appeared
                                                                      as second quantifier once, 4 syllogisms in which each of the
Participants.                                                         four standard quantifiers (i.e., A, E, F, I) appeared as first
Twenty-five English native speakers (M = 30.8 years) partic-          quantifier once and most appeared as second quantifier, and
ipated in this experiment. They were recruited by Amazon              4 syllogisms in which each of the four standard quantifiers
Mechanical Turk and paid for their participation.                     appeared as first quantifier once and few appeared as second
                                                                      quantifier. The syllogisms were presented in a individually
Materials, Procedure, and Design.                                     randomized order. Different professions and hobbies con-
The experiment was conducted as an online experiment via              stituted the content of the terms (e.g., Chater & Oaksford,
Amazon Mechanical Turk. Each participant completed 40                 1999).
syllogistic reasoning tasks and additionally one easy test
problem which was excluded from the analysis. The tasks
                                                                                                    Results
consisted of two premises at least one of which contained             Descriptive Results
a generalized quantifier (F or M). Simultaneously with the            Table 1 presents the reliable responses (i.e., responses which
premises, the question “what follows?” as well as a response          occurred significantly often, >22%) and the corresponding
field for the conclusion appeared. The participants had to gen-       response proportions for all 40 syllogisms. For one item
erate a conclusion using one of the six quantifiers (A, E, F,         (printed in bold) the modal response (M) was given signifi-
I, M, O), which were displayed at the bottom of the screen,           cantly more often than a second reliable response (I).
                                                                 1231

Table 2: Predictions of the four theories for selected syllo-                            Table 3: Model Comparison
gisms (X-Z conclusion) and significant choices.
                                                                       Theory           k       G2     AIC     BIC       FIA    CFIA
  Syll.    Data    PHM     Matching      PMM      Min. Models
                                                                       PMM             45    235.8   325.8    546.6    197.8      79.9
  IF        F, I   I, (O)       I          F           F, I            Min. M.         49    223.5   321.5    562.0    195.7      83.9
  FI         F     I, (O)       I          F           F, I            Matching        49    261.7   359.7    600.1    214.2      83.4
  FO        F, I   O, (I)      O            I           F              PHM           101     187.2   389.2    884.9    182.4      88.8
  OF        F, I   O, (I)      O            I           F
                                                                     Note. k is the number of model parameters, the total number
  MO          I    O, (I)      O            I           O
                                                                     of available df is 200 (i.e., model df = 200 − k). All p < .001.
  OM        I, F   O, (I)      O            I           O
                                                                     Theories are ordered by the number of parameters. The small-
Note. Predictions in parentheses indicate predictions by the         est value per column is printed in bold. FIA gives the value of
non-preferred process, i.e., p-entailments for PHM.                  the Fisher Information Approximation and CFIA is the penalty
                                                                     term for FIA representing the flexibility which is estimated us-
                                                                     ing 1 million Markov chain Monte Carlo (MCMC) samples.
MPT analysis
For each of the 40 syllogisms in our data we created predic-
tions from the four theories. A few examples in which the            ferences in number of parameters and predictions between
theories give specifically diverging predictions are presented       e.g., PMM and PHM, this is odd. It most likely reflects the
in Table 2 along with the reliable responses given by the par-       asymptotic nature of FIA, which only perfectly captures flex-
ticipants. From the predictions we constructed MPT models            ibility differences for n → ∞, and our small sample size (only
as described above. The full model for each theory consisted         n = 25 per tree; where n in both cases is the number of items).
of 40 trees, each representing one syllogism. Each tree con-         Hence, we interpret the results that the model that strikes the
tained an individual ri parameter estimating the probability         best balance between model fit and flexibility is either one of
with which a response was produced by a reasoning or guess-          the two mental model-based theories or PHM.
ing state. As described above, the probabilities of responses            In the next step of the analysis we looked at the ri parame-
within the reasoning branch of the trees were freely estimated       ters. As shown in Table 4, the theories differ wrt. the amount
(with the restriction regarding the min-heuristic for PHM) and       of reasoning compared to guessing they assume. In line with
the parameters in the guessing tree were constant across all         the G2 values, PHM estimated the greatest probability for rea-
trees (i.e., each model only had one set of five guessing pa-        soning based responses. However, even for PHM the mean
rameters for all 40 syllogisms).                                     probability for a reasoning based response was .5. In other
   We fitted each model to the aggregated data via the maxi-         words, even for the best fitting theory (i.e., ignoring the issue
mum likelihood method using MPTinR (Singmann & Kellen,               of model flexibility), half of the responses were produced by
2012). The full dataset had 5 × 40 = 200 available degrees           guessing processes and only the other half of the responses
of freedom for a total of 25 × 40 = 1000 responses. Model            by the reasoning processes the theories assume. This finding
comparison data is presented in Table 3. In terms of model           may well be responsible for the overall unsatisfactory model
fit as measured by the G2 statistic the first important obser-       fit given that the guessing process which was responsible for
vation is that all models provide an inadequate account (i.e.,       at least 50% of the responses was assumed to be constant
all p < .001). Furthermore, PHM provided the best account            across all 40 syllogisms (i.e., only 5 parameters for 50% of
(smallest ∆G2 = 36.30). This is not too surprising given that        the responses across 40 trees).
it makes the most predictions and has the most parameters.               Finally, we analyzed the ri parameters with a mixed
   When considering both model fit and model flexibility             ANOVA (i.e., an item-wise analysis) with theory as within-
the picture somewhat changes. The two “naive” measures
AIC and BIC (which operationalize model flexibility only via
numbers of parameters) favour the two Mental Model based
theories (AIC: Minimal Models; BIC: PMM). But it should                     Table 4: Comparison of Reasoning (ri ) Parameters
be noted that AIC and BIC are somewhat inappropriate for
                                                                        Theory                Mean    SD    Median      Min    Max
models where parameters impose order restrictions as is the
case for PHM. For such a case, FIA is a more appropriate                PMM                   .44     .21   .46         .00    .82
measure as it estimates the flexibility of a model, taking order        Minimal Models        .46     .21   .48         .00    .82
restrictions into account (see Wu et al., 2010, for a discus-           Matching              .38     .26   .39         .00    .83
sion). According to FIA, PHM provides the best account.                 PHM                   .51     .25   .53         .08    .93
However, when inspecting the FIA penalty terms (which are             Note. Although .00 is the smallest value for three theories, it
added to 21 G2 ) estimated model flexibility only minimally dif-      does not occur at the same syllogism for all of them.
fers (maximal difference is 8.9). Given the rather huge dif-
                                                                 1232

subject factor and generalized quantifier (M vs. F), po-             theories on a new and more precise level and allow for distin-
sition of generalized quantifier (first vs. second premise),         guishing between competing theories in a unified framework.
and conclusion (X-Z vs. Z-X) as between-subjects fac-
tors. The analysis revealed, besides a main effect of the-                                   References
ory (F(2.59, 83.00) = 10.36, p < .001), a significant theory         Bucciarelli, M., & Johnson-Laird, P. N. (1999). Strategies
× generalized quantifier interaction (F(2.59, 83.00) = 11.22,          in syllogistic reasoning. Cognitive Science: A Multidisci-
p < .001).3 With the exception of the Minimal Model the-               plinary Journal, 23(3), 247–303.
ory were the reasoning parameters consistently larger for M          Chater, N., & Oaksford, M. (1999). The probability heuris-
than for F (differences are .10 for PMM, -.03 for Minimal              tics model of syllogistic reasoning. Cognitive psychology,
Models, .13 for Matching, and .21 for PHM). This indicates             38(2), 191–258.
that most theories predicted more reasoning when M was the           Evans, J. S. B. T. (2002). Logic and Human Reasoning:
generalized quantifier compared to F.                                  An Assessment of the Deduction Paradigm. Psychological
                                                                       Bulletin, 128(6), 978–996.
                          Discussion                                 Johnson-Laird, P. N. (2006). How we reason. New York:
                                                                       Oxford University Press.
Everyday reasoning is based on degrees of belief rather than
                                                                     Johnson-Laird, P., & Khemlani, S. (2014). Toward a unified
absolute certainty. To this end, we investigated syllogisms
                                                                       theory of reasoning. Psychology of Learning and Motiva-
with generalized quantifiers such as “Most” (M) and “Few”
                                                                       tion, 59, 1 - 42.
(F). There is currently only one approach – the Probability
                                                                     Khemlani, S., & Johnson-Laird, P. N. (2012). The processes
Heuristics Model (Chater & Oaksford, 1999) – that makes
                                                                       of inference. Argument and Computation, 1(1), 1–17.
any predictions about possible inferences. We extended the
                                                                     Neth, H., & Johnson-Laird, P. N. (1999). The search
Matching Hypothesis and developed two model-based ap-
                                                                       for counterexamples in human reasoning. In M. Hahn &
proaches for generalized quantifiers, formalized them as MPT
                                                                       S. C. Stoness (Eds.), Proceedings of the twenty-first annual
models and evaluated them on a new dataset.
                                                                       conference of the cognitive science society (p. 806). Mah-
   Our results show that MPT models can be used to success-            wah: Lawrence Erlbaum.
fully compare reasoning theories. In terms of model fit, how-        Oberauer, K. (2006). Reasoning with conditionals: A test of
ever, all discussed theories provide an inadequate account to          formal models of four theories. Cognitive Psychology, 53,
the data. Nevertheless, differences between these approaches           238–283.
exist in their predictive power. PHM and the mental model-           Pfeifer, N. (2006). Contemporary syllogistics: Compar-
based approaches clearly outperform the Matching Hypothe-              ative and quantitative syllogisms. In G. Kreuzbauer &
sis (which shows a good fit to the data on classical syllogistic       G. J. W. Dorn (Eds.), Argumentation in Theorie und Praxis:
reasoning; Khemlani & Johnson-Laird, 2012). Deciding be-               Philosophie und Didaktik des Argumentierens (pp. 57–71).
tween the remaining three theories seems to require a larger           Wien: LIT.
number of responses as indicated by the inconclusive results         Ragni, M., Schrögendorfer, D., & Nebel, B. (in prep). Formal
from the different model selection indices employed. Specif-           Mental Model Theory in Syllogistic Reasoning.
ically the small differences in FIA penalty given the rather         Riefer, D. M., & Batchelder, W. H. (1988). Multino-
dramatic differences in the predictions between the theories           mial modeling and the measurement of cognitive processes.
point to this conclusion.                                              Psychological Review, 95(3), 318.
   While the results indicate that no current theoretical ap-        Rips, L. J. (1994). The psychology of proof: Deductive
proach captures the full set of responses, one further take            reasoning in human thinking. Cambridge, MA: The MIT
home message can be distilled from our analysis: Disen-                Press.
tangling the contribution of reasoning and guessing based            Singmann, H., & Kellen, D. (2012). MPTinR: Analysis of
responses reveals that almost all theories are more success-           multinomial processing tree models in R. Behavioral Re-
ful in predicting participants’ responses when reasoning with          search Methods, 45, 560–575.
“Most” compared to “Few”. This result shows that our MPT             Wetherick, N. E., & Gilhooly, K. J. (1990). Syllogistic
modelling can help in providing specific insight for further           reasoning: Effects of premise order. In K. J. Gilhooly,
theoretical development.                                               M. T. G. Keane, R. H. Logie, & G. Erdos (Eds.), Lines
   In contrast to other analysis strategies, MPT modeling al-          of thinking: Reflections on the psychology of thought, vol.
lows to test specific, possibly ordered, predictions and uses          1 (pp. 99–108). Chichester: Wiley.
raw response frequencies instead of transformed data. Fur-           Wu, H., Myung, J. I., & Batchelder, W. H. (2010). Minimum
thermore, the ability to disentangle latent cognitive processes        description length model selection of multinomial process-
such as reasoning and guessing provides important theoreti-            ing tree models. Psychonomic bulletin & review, 17(3),
cal insights. From this perspective, MPT models are an excel-          275–286.
lent cognitive modeling methodology for assessing reasoning
    3 df are Greenhouse-Geisser corrected.
                                                                 1233

