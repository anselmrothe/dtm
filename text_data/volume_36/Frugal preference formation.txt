UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Frugal preference formation
Permalink
https://escholarship.org/uc/item/98b562nt
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Srivastava, Nisheeth
Schrater, Paul
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                               Frugal preference formation
                                          Nisheeth Srivastava (nsrivastava@ucsd.edu)
                                      Department of Psychology, University of California San Diego
                                                        San Diego, CA 92093 USA
                                               Paul R Schrater (schrater@umn.edu)
                                          Department of Psychology, University of Minnesota
                                                       Minneapolis, MN 55455 USA
                               Abstract                                 option, and that once the quantity of evidence reaches a cer-
                                                                        tain threshold, a decision is made. The biggest difference be-
   Most theories explaining how animals form preferences for            tween the two approaches is that whereas accumulator mod-
   their actions agree upon a basic outline: animals discover
   what is preferable through interactions with the world, store        els are deterministic in selecting the first option to attain a
   this information in memory, and recall it to help them de-           preset evidence threshold, random walk theories like DFT
   cide what to do in a new situation. However, no single the-          require the difference between multiple options’ evidence to
   ory currently explains both how preferences are learned, and
   how they are recalled in a way that is compatible with empir-        reach a preset threshold in order to output a stochastic choice.
   ical data. We advance precisely such a proposal in the form
   of a stochastic choice model where the decision agent learns
   what to do based on scale-free comparisons between options              The latest generation of process theories borrows the basic
   it observes in the world and at each decision instance recalls a     evidence accumulation structure of its forebears, but differs
   subset of these comparison experiences in a manner that min-         in being more specific in defining the nature of evidence be-
   imizes the metabolic costs of memory recall. In simulation,
   this model makes qualitatively accurate predictions connect-         ing compiled. For example, Chater and colleagues (Stewart,
   ing agent choices with various dynamic choice correlates doc-        Chater, & Brown, 2006) have proposed a system of infer-
   umented in the literature on choice process models.                  ring choices that dispenses with the need to map payoffs to
   Keywords: Decision-making; cognitive science; Bayesian               intrinsic value scales. In their proposal, the payoff’s sub-
   modeling; computer simulation; learning; memory; mathemat-           jective value emerges from ordinal binary comparisons to
   ical modeling; artificial intelligence
                                                                        a sample of payoffs drawn from memory. The means by
                                                                        which certain payoffs are preferentially recalled, though, are
                          Introduction                                  left unspecified, so this model cannot predict the behavior of
While economists are primarily concerned with representing              choice process correlates like reaction time and neural acti-
decision-makers’ static preferences, psychologists are more             vation. A more recent proposal, due to Dickhaut and col-
interested in investigating the processes by which animals              leagues (Dickhaut, Rustichini, & Smith, 2009), uses a sig-
make the choices they do. Naturally, there are also differences         nal detection analogy to describe the choice process, with the
in the analysis tools that the two disciplines bring to bear            agent’s goal being to estimate utility from noisy observations
in addressing decision-making under uncertainty. Economic               of the world state with minimum cognitive effort. Crucially,
theories of choice tend to axiomatically impose conditions on           existing process models leave the question of the origin of
when subjects’ preferences can be said to be originating from           preferences unanswered.
some latent function measuring the desirability of various op-
tions. In contrast, cognitive theories of the choice process em-           In this paper, we develop a theory of the choice process that
phasize algorithmically modelling the deliberative process by           specifies both the manner in which preferences are learned
which agents accumulate evidence and make choices. Theo-                from the world, and the manner in which they are recalled for
ries of the choice process, therefore, differ substantially from        future decisions. The basis for this development is a recent
static theories of decision-making under uncertainty both in            theoretical advance (Srivastava & Schrater, 2012), where we
means and methods.                                                      demonstrated that optimal Bayesian inference about which
   Choice process models have a long history. Procedural                options in the world an agent has to select between, as well
theories like elimination-by-aspects, suppresion-of-aspects,            as which options in these option subsets are the best, yields
lexicographic heuristics etc. can be considered the earliest            preferences that are economically rationalizable under some
choice process theories. Computational theories of the de-              general constraints on the agent’s observation history. In our
cision process originate in the duelling visions of two sep-            present work, we build upon this theory of preference forma-
arate research programs: Busemeyer’s decision field theory              tion by adding embodiment constraints via a requirement of
(DFT) (Busemeyer & Townsend, 1993), and McClelland’s                    effort-sensitive computation. By doing so, we obtain a com-
leaky competing accumulator models (McClelland, 2001).                  putationally tractable choice model that can jointly make pre-
The basic insight shared by both frameworks, and indeed                 dictions both for the static revealed preferences of subjects
most succeeding models, is that evidence (as a function of              and dynamic process correlates like error rate, reaction time,
payoffs) for decisions accumulates independently for each               and neural activation.
                                                                    1509

                  Modeling the choice process                           remapped on to the larger set of options by defining a rela-
 Our theory can be distilled into three specific claims:                tive desirability across all possibilities r(x, o) = m, x ∈ o and
                                                                        zero otherwise.
1. Animals infer what to do from choices they have made in                 We further assume that agents infer the situation of the
    the past concerning different stimulus configurations.              world that they are required to respond to using the option
                                                                        sets they encounter, both as a way to orient themselves with
2. Animals perform this inference frugally, using a limited             respect to the environment and be able to respond flexibly to
    subset of past experiences.                                         novel situations. While the set of contexts inferred C by an
                                                                        agent from its observation history can be latent in general, a
3. Animals are smart about which experiences to use - they              crucial novelty of our framework was to restrict the nature
    select them in order of expected informativeness.                   of these contexts as bijective maps of observed option sets,
                                                                        i.e. C ⊆ P (X ). In our framework, the computation corre-
    In the three subsections below, we operationalize each of           sponding to utility is desirability p(r|x, o), which is obtained
 these claims computationally.                                          by marginalizing over C ,
 Bayes-optimal preference formation                                                                           ∑Cc p(r|x, c)p(x|c)p(c)
                                                                                  D(x) = p(r|x, o) =                                    ,     (1)
 Real subjects, unlike traditional economic agents, need not                                                      ∑Cc p(x|c)p(c|o)
 consider the set of all possible options in the world at every
                                                                        where it is understood that the context probability p(c|o) =
 decision instance. Instead, options tend to have typical co-
                                                                        p(c|{o1 , o2 , · · · , ot−1 }) is a distribution on the set of all possi-
 occurrence relations - such that which options co-occur be-
                                                                        ble contexts incrementally inferred from the agent’s obser-
 comes itself a signal that allows the agent to establish the
                                                                        vation history. From the definition of desirability, we can
 context in which an option’s desirability is to be evaluated.
                                                                        also obtain a simple definition of the desirability probability
 Therefore, in (Srivastava & Schrater, 2012), we outlined a
                                                                        p(r|x, c) as p(ri |xi , c) = 1 iff ri xi = 1 and zero otherwise.
 theory of preference formation wherein the basic atom of
                                                                           To instantiate equation (1) concretely, we must also instan-
 value includes both information about which option(s) are
                                                                        tiate the observation probability p(o|c). Multiple definitions
 desirable and the set of options it is desirable amongst, us-
                                                                        that obtain the highest possible value for c = o and penalize
 ing modal frames as a mathematical formalism for express-
                                                                        mismatches in set membership are plausible. This likelihood
 ing an instantaneous judgment of desirability for human sub-
                                                                        function is used to update the agent’s posterior belief about
 jects. Compiling desirability across multiple such objects to
                                                                        the contexts it considers viable at decision instance t, given
 retrieve an analogue of traditional value computation required
                                                                        its observation history as,
 the development of a new framework for inferring prefer-
 ences which we detail in (Srivastava & Schrater, 2012) and                                                 p(o(t) |c)p(c|o(1:t−1) )
 briefly review here.                                                               p(c(t) |o(1:t) ) =      C                         ,       (2)
                                                                                                          ∑c p(o(t) |c)p(c|o(1:t−1) )
    Consider a standard choice formulation where an agent is
 presented with the set of options X . Traditional treatments           which, in conjunction with the desirability based state prefer-
 of preference learning assume that there is some hidden state          ence update, and a simple decision rule (e.g. MAP, softmax)
 function U : X → R+ such that x  y iff U(x) > U(y). Pref-             yields a complete decision theory.
 erence learning, in such settings, is reduced to a task of statis-
 tically estimating a monotone distortion of U. In (Srivastava          Effort-sensitive preference formation
 & Schrater, 2012), we showed that assuming the existence of            Whereas the computational aspect of our theory is fully spec-
 such a U is incompatible with a number of behavioral results           ified in terms of a Bayesian agent seeking to accumulate ev-
 on choice behavior. Our alternative strategy was to demon-             idence for future choices based on past choice experiences,
 strate that the set of options o ∈ P (X )1 actually observed at        at the mechanistic level, there are further considerations that
 any decision instance can be used instead to directly infer fu-        are expected to constrain it. The principal constraint we con-
 ture preference using preferences revealed at previous deci-           sider is a requirement of biological organisms to reduce the
 sion instances without having to resort to intermediate utility        metabolic costs of thinking.
 computations.                                                             Cognitive dynamics form a large fraction of the body’s
    Formally, we introduce preference information into our              basal metabolic requirements. It is reasonable, therefore,
 system via a desirability function d that simply points to the         to assume that achieving efficiency in cognitive processing
 best option in a given context, i.e. d (o) = B, where B is an          would promote natural selection. Thus, it is not unnatural to
 accessibility relation (o, o, m) corresponding to the Kripke           assume, as we do in this paper, that animals’ mechanisms
 frame ho, Bi, designed to point to the best option in the ob-          of cognitive dynamics have evolved to be sensitive to the
 served set by defining mi = 1 iff oi  oi0 ∀oi0 ∈ o \ {oi } and        metabolic costs of choice selection, and that animals allocate
 zero otherwise. The desirability indicated by d (o) can be             resources for cognitive processing rationally.
                                                                           Given the computational goal of a statistically optimal
     1 P (·) references the power set operation.                        preference-learning agent outlined in the preceding section,
                                                                    1510

we develop a model of effort-sensitive preference formation                  where k is a positive integer-valued parameter controlling the
by assuming that while the brain does perform the Bayesian                   amount of deliberation an agent is willing to undergo before
updates we have described above, it does so using a subset of                making an explicit choice.
previous observations, not the entire history to impute desir-                  An animal will express desirability Dk∗ as an observable
ability. Thus, we model the choice process as animals trying                 decision when it believes it has constructed a sufficiently use-
to solve a tradeoff between the amount of choice-relevant in-                ful preference. Modeling the transition from fluid internal
formation they must recall to choose wisely in any particu-                  preferences to static revealed preference is equivalent to es-
lar decision instance and the amount of metabolic effort they                timating k∗ in our framework. As we describe below, and
must incur in doing so.                                                      illustrate in Figure 1, we believe that animals are sensitive to
   We model the process of memory recall as the activation                   the amount of information that particular memory particles
of a subset M of all decision-relevant memory particles. Us-                 can bring to bear on a decision problem, and that they likely
ing this notation, a general belief formation model could be                 select the particles they use to form preferences in order of
expressed as,                                                                informativeness. Thus, a reasonable form for k∗ inference
                                                                             would be a stopping rule
                   p(x) =         ∑      p(x|m)p(m),                   (3)
                              m∈M                                                               k∗ = argmax KL(pk (r|x)kpk−δ (r|x)) < ε,               (6)
                                                                                                                   k
where x ∈ X are the choices available to the agent, and m ∈ M                reflecting diminishing marginal informativeness of incremen-
are memory particles corresponding to past choice selections.                tal evidence accumulation.
Here, the probability distribution p(m) - which we call the
memory prior - encodes the likelihood of recalling the mem-
ory of experience m, while the distribution p(x|m) encodes
beliefs about outcomes learned during the experience corre-                                                                                        ε
sponding to the memory particle m.
                                                                                  Information
                                                                                                                       )                       δ
                                                                                                                   m
                                                                                                                p(
   Instead of the idealized context inference in Equation 2, the                                       ar
                                                                                                            t
                                                                                                  Sm
memory-constrained preference learning agent will employ
an update,                                                                                                                           p(
                                                                                                                                       m
                                                                                                                                           )
                                                                                                                                at
                                                                                                                           Fl
                            p(o|c, m)p(c|Mold )
         p(c|o, m) =              C               ,
                           ∑c p(o|c, m)p(c|Mold )
                           Mk
                                      p(o|c, m)p(c|m(1:k−1) )p(m)
     ⇒ pk (c|o(t) ) =      ∑                                       ,                                                   Number of particles
                              m        ∑Cc p(o|c, m)p(c|m(1:k−1) )
                           Mk
                                      p(o|c)p(c|m(1:k−1) )p(m)               Figure 1: Smartly selecting memory particles for preference
                     =     ∑                                    ,      (4)
                              m        ∑Cc p(o|c)p(c|m(1:k−1) )              formation leads to frugal but accurate computations.
where p(o|c, m) = p(o|c) follows from the fact that the obser-                  The amount of cognitive effort an animal is willing to
vation likelihood of a particular option set o conditioned on                invest in a decision will depend both on the quality of its
having seen the same option set before in context c will be in-              constructed preference and the existence of other concurrent
dependent of which memory particle was responsible for re-                   goals that it is currently seeking to fulfill. This intuition is
calling context c. Note that the index k in Equation 4 indicates             naturally integrated in our model by permitting the effort pa-
the temporal order in which evidence from various memory                     rameters {δ, ε} to be calculated by a higher level hierarchical
particles is accumulated during preference formation during                  controller. Once the high-level controller has assigned the
a particular decision. Also note that, while the set C still re-             effort parameters, the agent constructs the best possible pref-
tains its original definition as the set of inferred contexts, this          erence within the effort constraint and outputs it as a decision.
set will now be determined by the set of memory particles                       For our present purposes, we assume that we already pos-
presently activated, not by directly indexing past choice sets               sess accurate point estimates for these parameters. Realisti-
as was possible earlier.                                                     cally, estimates of the effort parameters may also be uncer-
   The relative desirability computation in Equation 1 also                  tain. Weak posterior distributions on the effort parameters
changes to reflect the dependence of the computation on the                  will yield behavior in our model resembling the very human
result of a race between multiple memory particles to influ-                 ability of contradictory decisions being made on very short
ence the agent’s choice. In particular, the kth arrival will de-             timescales2 . However, exact modelling of the higher-level
termine that the relative desirability of option x is,                          2 Waiter:  “What dressing would you like with your salad?”.
                          C                                                  Diner: “Umm, French. No wait, ranch. Uhh..., actually let’s just
                         ∑c p(r|x, c)p(x|c)pk (c|o)                          go with French.” Waiter: “Ok, I’ll be right back.” Diner (mutter-
             Dk (x) =                               ,                  (5)
                            ∑Cc p(x|c)pk (c|o)                               ing):“I should have asked for vinaigrette.”
                                                                         1511

controller lies outside the scope of this article.                                                       Results
Sparse but smart preference formation                                     Due to its commitment to a particular embodied form of pref-
The final piece of our modelling is defining the criterion that           erence dynamics, our model requires relatively few param-
agents use to activate memory particles, practically reflected            eters to relate dynamic choice correlates to static choice se-
in the choice of p(m) in Equation 4. A flat p(m) would corre-             lections. The present specification uses four parameters: the
spond to an agent that is indifferent to the information content          mismatch penalty weight β used in computing observation
of various memory particles. Such an agent though, would be               likelihood p(o|c), the salience scaling parameter λ, and the
information-theoretically inefficient, as outlined in Figure 1.           effort parameters {δ, ε}, controlling the amount of evidence
A more useful strategy would be to selectively use maximally              an agent will recall before revealing its preference. Unlike
informative particles.                                                    existing process models, the size of our parameter set does
   We use a particular information-theoretic construction to              not increase with the number of choice options. In the exper-
operationalize this assumption. Deviations in the amount of               iments conducted below, λ and β were found to not influence
information communicated by a particular memory particle                  the results significantly, and remained fixed at the value of 3
is hypothesized to correspond to its decision salience in neu-            in all cases.
ral computation. We implement this strategy in our model in                  The ideal version of preference inference has already been
the following way. We begin with a standard specification of              shown to conform with normative rational expectations of
prediction error using an information divergence,                         choice behavior in (Srivastava & Schrater, 2012). In this
                                                                          paper, we focus on demonstrating that our model of effort-
                                                      p(r|x)
          R(p(r|x), p(r|x, m)) =     ∑ p(r|x) log p(r|x, m) ,     (7)     constrained preference inference generates the right profiles
                                    x∈X                                   of dynamic choice correlates that other process models have
where, p(r|x) is the currently computed desirability, and                 sought to model. Specifically, we demonstrate the ability of
p(r|x, m) is the desirability content of memory particle m,               our model to qualitatively replicate the absolute identifica-
measured as the relative desirability we would impute in                  tion results of (Lacouture & Marley, 2004), which (Brown
Equation 5 using M = {m} in Equation 4. We instantiate                    & Heathcote, 2008) have set up as a benchmark for testing
the memory prior as a softmax function of particle salience,              accumulator models.
                                                                             The basic setup of the experiment involves showing sub-
                                  exp(λA(m))
                     p(m) =                         ,             (8)     jects 40 copies each of n stimuli, and asking them to assign
                              ∑m∈M exp(λA(m))                             number labels 1 · · · n to them. The underlying assumption in
where λ is a parameter controlling the scale of salience and              previous models has been that subjects possess some internal
the particle salience A(m) itself is instantiated as a convex             scale to which they map stimuli lengths, with some amount
function of the prediction error, e.g.                                    of noise inherent to this process. We assume, on the other
                                                                          hand, that subjects can learn relative magnitude information
                A(m) = cos(απR(p(r|x), p(r|x, m))),               (9)     by comparing between the stimuli they are seeing. For ana-
   where α is a normalizing        constant3 . The intuition behind       lytical tractability, we restricted ourselves to considering only
this relationship between salience and prediction error de-               pairwise comparisons, i.e. we assumed that agents are com-
rives from the need for cognitively salient memories to ei-               paring the presently seen stimulus to the stimulus seen imme-
ther reinforce existing policies, or support switching away               diately prior. On each trial, agents updated their estimates for
from them. This dual requirement privileges both low error                p(r|xt , o = {xt , xt−1 }) following our model. Note that the only
conditions (generated by reinforcing particles) and high error            comparison permitted in our model was judging which one
ones (generated by highly contrasting ones). In contrast, in              was longer. No absolute magnitude information was stored.
a domain where on-task behavior is relatively automatic (eye                 We found that simulated agents operating under these con-
movements), only high contrast samples need be considered                 straints were able to learn the relative ordering of stimuli
salient, which is indeed what is seen empirically (Itti & Koch,           lengths using a relatively small number of comparisons (40
2001).                                                                    presentations of each stimulus, as used in (Lacouture & Mar-
   Algorithmically, the salience computation arises dynami-               ley, 2004)). While our results are presented using a smaller
cally as the contexts are being compiled to generate relative             stimulus set than the original experiment, the qualitative
desirability at the present decision instance. When the set of            trends match exactly (see Figure 2). The fraction of correct
compiled contexts is empty, there are no salience weights on              responses appears as a convex function of stimulus order, and
any of the memory particles. Once contexts begin being com-               the response time appears as a concave function of stimulus
piled, we use our definitions of prediction error and salience            order, precisely matching the profiles observed by (Lacouture
anchoring on the incomplete context frame set to sequentially             & Marley, 2004) (also see Figure 10 in (Brown & Heathcote,
update weights for memory particles.                                      2008)). Additionally, manipulating the effort parameters per-
    3 In practice, α is an uninteresting parameter. We simply normal-     mits us to make predictions about the behavior of the re-
ize with the largest value we know the KL between two vectors of          sponse time and error curves respectively in speed-emphasis
size |X | will take.                                                      and accuracy-emphasis. Our results are qualitatively in agree-
                                                                      1512

                            0.8
                                                   a                                        4.5
                                                                                                                        b
                                                                                            4.3     Accuracy
                                                                        Response time (k)
         Fraction correct
                                                                                                     (δ = 3)
                            0.6
                                  Accuracy                                                  4.1
                                   (δ = 3)
                                                                                            3.9
                            0.4
                                   Speed                                                    3.7
                                   (δ = 1)                                                           Speed
                                                                                                     (δ = 1)
                            0.2                                                             3.5
                                       1     2         3   4   5                                       1       2        3        4        5
                                                 Stimuli                                                              Stimuli
Figure 2: Our model replicates patterns of error rate and response time as a function of stimulus magnitude order previously
observed in human subjects in an absolute identification task. Task parameters were chosen to replicate Experiment 1 in
(Lacouture & Marley, 2004) - 40 trials per stimulus per session; results averaged across 12 simulation sessions. (a) error rate
is lowest for extreme stimuli; intermediate magnitude stimuli are predicted incorrectly significantly more often. Error bars are
2 SD across. (b) response time is also lowest for extreme-valued stimuli, and increases for intermediate stimuli. Error bars are
2 SE across (repeated measurements). In both cases, simulations emphasizing speed over accuracy change the profile of the
curves in the same manner observed in human subjects by (Ratcliff & Rouder, 1998).
ment with data for such a manipulation collected by (Ratcliff                                  Having modeled a difficult benchmark for existing process
& Rouder, 1998) (see Figure 7 in (Brown & Heathcote, 2008)                                  models, we also demonstrate an effect that accumulator mod-
for a visual comparison). The major quantitative difference is                              els and decision field theory find difficult to account for, but
that whereas human subjects do not lose significant accuracy                                originates endogenously in ours - the increase in choice re-
in the speed condition, our artificial subjects, trained on a lim-                          sponse time as a function of choice set size. Since other com-
ited set of trials, lose considerably more.                                                 putational models of the choice process model evidence accu-
   The model’s capacity to identify absolute stimuli arises                                 mulation for each option individually, they end up predicting
from its ability to accumulate evidence from pairwise com-                                  that response time should be independent of choice set size.
parisons and recall a small number of these comparisons to                                  Instead, as Hick’s law formalizes, RT is empirically seen to
dynamically estimate the order of the present stimulus. This                                increase logarithmically with set size (Hick, 1952). Accumu-
linkage of preference with history renders transparent the re-                              lator models have sought to remove this discrepancy by as-
lationship between the psychophysical bowtie effect seen in                                 suming that the response threshold increases logarithmically
identification experiments (Lacouture & Marley, 2004) and                                   with the option set size, but rationales for such assumptions
the economic distance effect (Dickhaut, Smith, Xin, & Rus-                                  (which verge upon assuming the consequent) are unclear.
tichini, 2013) observed in multiple behavioral economics ex-                                   Response times increase naturally in our model, though the
periments where it is found that extreme choice valence (dis-                               rate of increase appears to be closer to linear than sub-linear
tance in utility) appears to be correlated with lower error rate,                           (see Figure 3). That RT should increase with choice set size
response times and interestingly, levels of neuronal activation                             is a natural consequence of our model; larger option sets need
as measured by fMRI (Dickhaut et al., 2013).                                                more comparison information to draw useful inferences from.
   The same simulation also replicates a complementary                                      The fact that our model fails to show a sub-linear Hicksian
decision-theoretic observation - high response times are usu-                               trend suggests that there are aspects of hierarchical clustering
ally associated with high error rates, and in turn with largely                             of option sets that our current framework does not accommo-
indifferent choice (Dickhaut et al., 2013). The working of                                  date.
our model illustrates that differences in the amount of cogni-
tive effort required to disambiguate options that are close in                                                       Discussion
value arise from the fact that such options have both been pre-                             Earlier efforts at designing choice models have almost uni-
viously chosen while members of different option sets. As-                                  formly reified the notion of value as an easily accessible exter-
similating conflicting evidence requires more samples for the                               nal signal. If value is easily accessible in the form of payoffs,
desirability distribution to stabilize, resulting in greater effort,                        then we need not worry about learning it. However, evidence
correlated with higher RT and brain activation.                                             is compiling that value learning is not simple, nor unneces-
                                                                       1513

                  6                                                  in their choice decisions, a prediction that is supported em-
                       Model results                                 pirically (Bruhin, Fehr-Duda, & Epper, 2010).
                                                                        In summary, we have modelled the choice process of an-
                  5    Hicks prediction                              imals as statistically efficient memory retrieval, and shown
       Time                                                          that such a model can explain important regularities in the re-
                                                                     lationship between memory samples, choice predictions, and
                  4
     (notional)
                                                                     choice prediction response times. Our results improve upon
                                                                     previous explanations for a number of response time effects,
                  3                                                  because they connect prior choice history to these variables.
                                                                     Our model is not just rationalizable, it is also substantially
                                                                     normative; optimizing a dual objective of adapting to envi-
                  2                                                  ronmental frequencies while reducing the internal processing
                   3    4         5       6      7        8
                                  Set size                           costs of such adaptation. Outlining a tractable form for this
                                                                     optimization is the key contribution of this work.
Figure 3: While our model differs from existing process mod-                                 References
els in predicting increasing response time as a function of          Brown, S. D., & Heathcote, A. (2008). The simplest complete
choice set size, it does not converge to Hick’s law’s predic-           model of choice response time: Linear ballistic accumula-
tion of sub-linear increases.                                           tion. Cognitive psychology, 57(3), 153–178.
                                                                     Bruhin, A., Fehr-Duda, H., & Epper, T. (2010). Risk and
                                                                        rationality: Uncovering heterogeneity in probability distor-
sary, and in fact, it is not clear if we should be thinking in          tion. Econometrica, 78(4), 1375–1412.
terms of option-specific value signals at all (Vlaev, Chater,        Busemeyer, J., & Townsend, J. (1993). Decision field theory:
Stewart, & Brown, 2011). Recognizing this ambiguity, our                A dynamic cognition approach to decision making. Psy-
own earlier efforts have focused on developing a rational the-          chological Review, 100, 432-459.
ory of preference learning that does not require intermedi-          Dickhaut, J., Rustichini, A., & Smith, V. (2009). A neuroe-
ate value computations. In this paper we have connected                 conomic theory of the decision process. PNAS, 106(52),
these ideas with limited, frugal computation to generate an             22145-22150.
integrated theory of metabolically frugal preference learning.       Dickhaut, J., Smith, V., Xin, B., & Rustichini, A. (2013).
The resulting theory can both predict which option an ob-               Human economic choice as costly information processing.
server will select, and also how much time (relative to other           Journal of Economic Behavior & Organization, 94, 206–
options) they will take to do so, depending on subjects’ his-           221.
tory of experience. Crucially, ours is a rationalizable theory       Hick, W. E. (1952). On the rate of gain of information. Quar-
of the choice process - it can both explain what choices an             terly Journal of Experimental Psychology, 4(1), 11–26.
animal will make, and why, by outlining the mechanism by             Itti, L., & Koch, C. (2001). Computational modelling of
which previous choice inform future ones.                               visual attention. Nature reviews neuroscience, 2(3), 194–
   Sensitivity to initial conditions, while possibly a limitation,      203.
is a very interesting feature of our model. Its path-dependent       Lacouture, Y., & Marley, A. (2004). Choice and re-
construction of preferences constrains us to predict that the           sponse time processes in the identification and catego-
options that animals predict will depend significantly on the           rization of unidimensional stimuli. Perception & psy-
order of evidence. Since we model the activation propen-                chophysics, 66(7), 1206–1226.
sity of memory particles as a function of the preference being       McClelland, J. L. (2001). The time course of perceptual
formed, which particles arrive first strongly influence which           choice: The leaky, competing accumulator model. Psycho-
ones will be recalled later. In a binary choice, for instance,          logical review, 108(3), 550–592.
a rare particle (pointing to an infrequently chosen option) ar-      Ratcliff, R., & Rouder, J. N. (1998). Modeling response
riving first will essentially make it impossible for further rare       times for two-choice decisions. Psychological Science,
particles to participate. Conversely, if the initial particle set       9(5), 347–356.
is typical (pointing to the frequently chosen option), rare par-     Srivastava, N., & Schrater, P. (2012). Rational inference of
ticles will have a greater impetus to participate in preference         relative preferences. In Proceedings of advances in neural
construction. It is not unreasonable to expect animals to be-           information processing systems 25.
have this way; and predictions from this aspect of our model         Stewart, N., Chater, N., & Brown, G. D. (2006). Decision by
are testable. For example, in economic choices between a                sampling. Cognitive Psychology, 53(1), 1 - 26.
safe and a risky option, our model predicts that subject popu-       Vlaev, I., Chater, N., Stewart, N., & Brown, G. (2011). Does
lations will segment into two cohorts: one that select the risky        the brain calculate value? Trends in Cognitive Sciences,
option with probabilities matching empirical frequencies of             15(11), 546 - 554.
success, and one that overweights the probability of success
                                                                 1514

