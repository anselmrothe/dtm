UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visualizing Theory of Mind with Multiple Intrinsic Frames of Reference
Permalink
https://escholarship.org/uc/item/1dn3z2fp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Liang, Chen
Sun, Yanlong
Wang, Hongbin
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

            Visualizing Theory of Mind with Multiple Intrinsic Frames of Reference
                                                Chen Liang (chen.liang@uth.tmc.edu)
                                            University of Texas Health Science Center at Houston
                                              7000 Fannin Suite 600, Houston, TX 7030 USA
                                                   Yanlong Sun (ysun@tamhsc.edu)
                                                Hongbin Wang (hwang@tamhsc.edu)
                                                Texas A&M University Health Science Center
                                     2121 West Holcombe Blvd, Suite 1109, Houston, TX 77030 USA
                               Abstract                                 reveal distinct processes of generating segmented FOR-based
   Research in the field of spatial cognition has advocated a frame
                                                                        internal representations and transformation among these
   of reference (FOR) -based cognitive representation system to         representations (Colby, Duhamel, & Goldberg, 1995;
   account for human’s spatial reasoning and navigation                 Duhamel, Colby, & Goldberg, 1991; Samson et al., 2005).
   capacities. It has been argued that such mental models may also      This permits a computational description of how the human
   contribute to the underlying mechanisms of Theory of Mind            brain processes spatial information in different contexts,
   (ToM). In the present study, we investigated how people made         including (1) coexistent, yet temporally discrete (merge in
   rapid judgments about the number of visible objects from their       secession) representations, and (2) reconciliation and
   own perspectives (egocentric frame of reference, EFOR) and
   from others’ perspectives (intrinsic frame of reference, IFOR).      transformation between multiple representations in different
   We examined both behavioral and eye tracking responses, and          FORs. For instance, when people judge spatial relationships
   the results suggest that a FOR-based representation system           from other’s perspective (perspective taking), EFOR-based
   promotes the efficiency and flexibility of ToM functions. Our        and IFOR-based representations would interact with each
   findings support the notion of a possible conceptual link            other in order to resolve potential incongruences (Kessler &
   between spatial and social cognitive processes.                      Rutherford, 2010; Kessler & Thomson, 2010). Moreover, a
   Keywords: theory of mind; visual perspective taking; intrinsic       growing body of research suggest that low-level spatial
   frame of reference; eye movement                                     representations in spatial tracking, predictive encoding and
                                                                        attention shifting are essential in supporting sophisticated
                           Introduction                                 abilities during social interactions (Corbetta, Patel, &
Researchers have become increasingly interested in bridging             Shulman, 2008; Frith & Frith, 2012; Mitchell, 2006; Perner,
the conceptual gaps between "Theory of mind" (ToM), which               Mauer, & Hildenbrand, 2011).
examines people's ability to judge other's intentions, beliefs             A FOR-based account of ToM may provide a fresh
and mental states (Frith & Frith, 2012), and spatial cognition,         approach to understanding the intrinsic nexuses between
which examines people's ability to reason about spatial                 ToM and spatial cognition. Particularly, one’s ability to infer
relationships and organize spatial representations. Frame of            others’ views, intensions, and beliefs occurs as one adopts
reference (FOR) has been used to account for the mechanisms             others' perspectives (Gallagher & Frith, 2003). This process
underlying spatial cognition in terms of processing spatial             requires the inhibition of one's egocentric perspective, so as
representations and their relationships (May & Klatzky,                 to make someone else's perspective more accessible (Samson
2000; Shelton & McNamara, 2001; Sun & Wang, 2010,                       et al., 2010). In a complex task environment, inhibitory
2014; Tamborello, Sun, & Wang, 2012; H. Wang, Johnson,                  competitions may exist not only between one’s EFOR and
& Zhang, 2001). In ToM judgments, investigations of                     IFOR representations, but also between multiple IFOR
egocentric visual perspective and allocentric visual                    representations. In addition, active maintenance of multiple
perspective have also hinted at the relevance of a FOR-based            representations is required when the spatial layouts of the task
internal representation system (Samson, Apperly,                        environment are evolving dynamically over time (Morton &
Braithwaite, Andrews, & Bodley Scott, 2010; Samson,                     Munakata, 2002; Perner & Ruffman, 2005). Recently, it has
Apperly, Kathirgamanathan, & Humphreys, 2005).                          been proposed that the maintenance of FOR-based
   Depending on the reference point of a spatial                        representations is driven by expectation towards an efficient
representation, three classes of FORs have been proposed:               and flexible partitioning of the spatio-temporal statistics in
egocentric frame of reference (EFOR, self-centered),                    the task environment (Sun & Wang, 2014). By comparing the
allocentric frame of reference (AFOR, world-centered), and              results from a direction-pointing spatial task (Tamborello et
intrinsic frame of reference (IFOR, anchored to other person            al., 2012) and a false-belief task (Onishi & Baillargeon,
or object) (Chen & McNamara, 2011; Sun & Wang, 2014; H.                 2005), Sun and Wang (2014) argued that FOR-based spatial
Wang, Johnson, Sun, & Zhang, 2005; R. Wang & Spelke,                    representations are the common factor in both tasks.
2002). Multiple FORs are often used together when people                Therefore, spatial and social abilities may share a common
judge complex spatial relationships. Neurological studies               origin at the level of spatio-temporal association and
                                                                    851

predictive encoding, and, FOR-based spatial representations        trial ended or the trail ended after the time of limit of 1500
may provide building blocks for general ToM abilities.             ms had been reached. The response time was recorded with
   If FOR-based representations can indeed account for the         the zero reading locked with the onset of the picture. The inter
performance in the false-belief task, it remains to be             trial interval was 1000 ms.
demonstrated that the same mechanism might be also at work
in other types of ToM tasks, such as those involving number        Results
cognition. Here we report a study using a recently developed       Data for one participant were removed from the analysis due
task, in which participants perform rapid ToM judgments            to low accuracy (<50%). Twenty participants' data were
from the perspectives of themselves or a computer-generated        included in the data analysis. Data for included participants
avatar (McCleery, Surtees, Graham, Richards, & Apperly,            showed an average accuracy of 92.7% (SD = 0.3%).
2011; Samson et al., 2010). We modified the task so that              We conducted a repeated measure analysis of variance
conflicts and competitions may exist not only between the          (ANOVA) with IFOR-IFOR Consistency (Consistent vs.
self-perspective (i.e., EFOR representation) and the avatar-       Inconsistent) and Matching (Match vs. Mismatch) as the
perspective (i.e., IFOR representation), but also between          within subject variables and reaction time (RT) and accuracy
different avatar-perspectives (i.e., multiple IFOR                 as the dependent variables (Figure 2). Only trials with correct
representations). This change allowed us to investigate more       responses and response time within 1500 ms (98.2% of the
complex interactions between multiple conflicting FORs.            total trials) were included in the analyses.
More importantly, it provided a direct comparison between a           IFOR-IFOR Consistency × Matching interaction reached
typical ToM task and a spatial reasoning task so that we could     statistical significance, F(1, 19) = 9.02, p < .01, ηp2 = .29. The
examine the common spatial representations in both tasks.          ANOVA revealed a main effect of IFOR-IFOR Consistency,
                                                                   F(1, 17) = 274.30, p < .001, ηp2 = .97, as well as a main effect
                       Experiment 1                                of Matching, F(1, 18) = 35.67, p < .001, ηp2 = .84. In the error
                                                                   analysis, time-out trials (1.8%) were counted as erroneous
Methods                                                            trials. The ANOVA revealed a main effect of IFOR-IFOR
Participants Twenty-one participants (aged from 18 to 50,          Consistency, F(1, 19) = 22.6, p < .001, ηp2 = .48.
mean age: 30.2 years), composed of graduate students and
staff from the University of Texas Health Science Center at
Houston, were recruited to participate in the experiment.
They received gift cards in return for their participation.
Stimuli The visual stimuli consisted of a picture showing two
avatars (“Michael” and “Rachel”) standing in a room facing
each other (Figure 1). Avatars’ relative positions exchanged
randomly across trials. A certain number of red discs
(randomly chosen from 1, 2, and 3) were displayed in the
room such that two avatars would see either (1) the same
number of discs (IFOR-IFOR consistent condition) or (2)            Figure 1: Examples of the visual stimuli used in the
different numbers of discs (IFOR-IFOR inconsistent                 experiments. The visual stimulus (dimension: 504 × 315
condition).                                                        pixels) was presented in the center of the computer screen
   Before the display of the visual stimuli, participants were     (dimension: 1024 × 768 pixels) with a white canvas as
prompted with a spoken sentence (by a male voice in                background.
English). Example sentences were, “Michael sees N” (50%
of the trials) or “Rachel sees N” (50% of the trials), where N
could be 1, 2, or 3 with equal probabilities. The spoken
sentence either correctly (Match condition) or incorrectly
(Mismatch condition) described the visual stimuli from the
prompted avatar’s perspective. Half of the trials were
matched and half of the trials were mismatched.
Procedure Each trial began with a fixation cross in the center
of the screen. After 600 ms, a spoken sentence lasting around
2000 ms was presented. Following the spoken sentence, the
screen maintained a fixation cross in the center with
randomized duration of 150, 250, and 350 ms. Next, a probe
picture showing a lateral view of the room appeared on the
screen. The participants’ task was to indicate, as quickly and     Figure 2: Experiment 1 response times (left) and accuracy
accurately as possible if the picture matched the spoken           (right) by IFOR-IFOR Consistency and Matching conditions.
sentence they just heard, by pressing a response key. Once a       Error bars depict standard errors of the mean.
response was made, either the picture disappeared and the
                                                               852

   In order to investigate the effect of IFOR-EFOR conflicts       irrelevant IFOR. Yet, participants’ performance was still
on participants' RTs and accuracy, we conducted another            influenced by the task irrelevant IFOR, despite the fact that
repeated measures ANOVA. Note that previously, a 2 × 2             the task relevant IFOR was explicitly prompted by the spoken
within subject design was used with IFOR-IFOR Consistency          sentence. This result confirms the previous finding that
(Consistent vs. Inconsistent) × Matching (Match vs.                people process multiple IFORs, but with limited cognitive
Mismatch) as the independent variables. IFOR-EFOR                  capabilities in handling conflicting IFORs (Tamborello et al.,
conflicts appeared only in IFOR-IFOR inconsistent                  2012).
condition, in which half of the IFOR-IFOR inconsistent trials         In the second round of ANOVA, we separated two kinds
were in task relevant IFOR-EFOR conflict and second half in        of IFOR-EFOR conflicts from the IFOR-IFOR inconsistent
task irrelevant IFOR-EFOR conflict. With Matching (Match           condition. Longer response times were observed when EFOR
vs. Mismatch) remaining the same, we have four conditions:         was in conflict with the task irrelevant IFOR, as compared to
(1) Task relevant IFOR-EFOR Inconsistent - Match (TR-M),           when EFOR was in conflict with the task relevant IFOR. This
(2) Task relevant IFOR-EFOR Inconsistent - Mismatch (TR-           finding suggests that participants might be influenced by their
MM), (3) Task irrelevant IFOR-EFOR Inconsistent - Match            own visual experience (EFOR) even when they were
(TIR-M), and (4) Task irrelevant IFOR-EFOR Inconsistent -          instructed to judge what the avatar saw. Recent findings
Mismatch (TIR-MM). Using this design, we employed                  indicate that people experience difficulty inhibiting their own
another round of repeated measures ANOVA with the 2 × 2            perspective when judging other's perspective (Samson et al.,
array proposed above. See Figure 3.                                2010). It is therefore likely that EFOR plays a somewhat
   The ANOVA revealed a main effect of IFOR-EFOR                   dominant role in processing spatial representations. For
consistency, F(1, 17) = 23.47, p < .001, ηp2 = .94. We also        example, people may encode external spatial information
found a main effect of Matching, F(1, 18) = 17.10, p < .001,       based on multiple FORs, yet depend on EFOR. One
ηp2 = .50. With respect to error analysis, we found a two-way      possibility is that EFOR plays a critical role in updating
interaction (IFOR-EFOR Inconsistency × Matching), F(1,             spatial representations based on the transformation between
19) = 12.39, p < .01, ηp2 = .11.                                   self (EFOR) and object (the most salient IFOR) (Kessler &
                                                                   Rutherford, 2010; Kessler & Thomson, 2010; Mou &
                                                                   McNamara, 2002; Zacks & Michelon, 2005). Regardless, we
                                                                   were unable to directly test this hypothesis because IFOR-
                                                                   EFOR conflicts were confounded with the IFOR-IFOR
                                                                   conflicts in this version of the task.
                                                                      Interestingly, the behavioral patterns we observed in the
                                                                   second round of ANOVA differed from previous findings in
                                                                   terms of how the task irrelevant IFOR played a role in
                                                                   performance. Since they knew in advance which avatar
                                                                   (Michael or Rachel) was task relevant, presumably
                                                                   participants should have had longer response times when
                                                                   EFOR was in conflict with task-relevant IFOR but not with
                                                                   the task irrelevant IFOR. Hence it would have been more
Figure 3: Experiment 1 response times (left) and accuracy          efficient for participants to have identified the task relevant
(right) by IFOR-EFOR Consistency and Matching. TIR: Task           IFOR as soon as visual stimulus appeared. One possibility is
irrelevant IFOR - EFOR consistent. TR: Task relevant IFOR          that people can detect multiple IFORs during an early stage
- EFOR consistent. Error bars depict standard errors of the        of visual processing while their limited cognitive resources
mean.                                                              may only afford to support one or a few of the FORs to be
                                                                   further processed. In this scenario, we would expect to
                                                                   observe distinctive eye movement patterns in different
Discussion                                                         conditions. This hypothesis was tested in Experiment 2.
For the present experiment, we examined the role of two
IFORs when people encoded spatial representations and                                      Experiment 2
judged spatial relationships in a modified ToM task. Both RT
and accuracy results revealed that the demanding cognitive         Methods
processes came from the inconsistency between the two
                                                                   Fourteen participants (aged from 18 to 50, mean age: 31.6
IFORs. More precisely, we found longer RTs as well as a
                                                                   years), composed of graduate students and staff from the
higher percentage of inaccurate responses when the
                                                                   University of Texas Health Science Center at Houston, were
judgments about Michael's perspective differed from
                                                                   recruited to participate in the experiment. In order to ensure
judgments about Rachel's perspective (e.g., IFOR-IFOR
                                                                   good eye-tracking results, participants were required to have
inconsistent condition). Our results indicate that people were
                                                                   either normal vision or corrected normal vision with contact
able to process and maintain multiple avatars' perspectives.
                                                                   lenses. Each participant received gift cards in return for their
Note that in order to complete the task, it was not necessary
                                                                   participation.
for them to take the perspective of the avatars in the task-
                                                               853

   The design of Experiment 2 was the same as Experiment 1,        Results
except that participants’ eye movements were recorded with         The percentages of RT and accuracy outliers found in
a SmartEye 5.2 eye tracker (SmartEye AB, Gothenburg,               Experiment 2 data were in a similar range as those found in
Sweden). Each participant was seated approximately 50 cm           Experiment 1, and were therefore omitted here. In the
in front of the computer screen, leading to a 22.6° visual         following, we focus on the analyses of eye movement data.
angle for the entire visual stimulus image. The SmartEye           Figure 4 shows the five areas of interest (AOI) for fixation
program was run on a different computer than the computer          analyses, and Figure 5 shows the scatter plots of actual eye
running the experimental task. An in-house E-Prime package         fixations aggregated over all trials in each condition.
was used to synchronize the stimulus presentation and the eye         To compare the eye fixations across conditions, we
tracker, which automatically collected and recorded eye            computed the mean fixation duration in each condition as the
fixations in real-time.                                            total time of fixations divided by the number of trials with
                                                                   correct responses in that condition (see Figure 6). We
                                                                   conducted a repeated measures ANOVA with the mean
                                                                   fixation duration as the dependent variable and AOI (AOI 1
                                                                   to 5) and conditions (C-M, C-MM, TR-M, TR-MM, TIR-M,
                                                                   TIR-MM) as the within subject variables. The interaction
                                                                   between AOI and Condition reached significance, F(17, 142)
                                                                   = 10.78, p < .001, ηp2 = .49. We found a main effect of AOI,
                                                                   F(4, 29) = 7.37, p < .001, ηp2 = .35, and a main effect of
                                                                   Condition, F(5, 49) = 79.34, p < .001, ηp2 = .86. Follow-up t-
                                                                   test indicated a significant difference between C-M and TIR-
                                                                   M on AOI 3, t(13) = 9.39, p < .001. Significant differences
                                                                   were also found for AOI 2 between C-M and TR-M, t(13) =
                                                                   19.72, p < .001, and between C-MM and TR-MM, t(13) =
                                                                   20.27, p < .001. Similarly, comparisons between TR-M and
Figure 4: Areas of interest (AOI, marked by yellow
                                                                   TIR-M on AOI 2 showed significant differences, t(13) = 6.91,
rectangles) and an example of eye movements (green dots for
                                                                   p < .001, and comparisons between TR-MM and TIR-MM on
saccades and pink dots for fixations). AOI 2 and AOI 3 cover
                                                                   AOI 2 also showed a significant difference, t(13) = 4.30, p <
the task relevant and task irrelevant avatars, respectively.
                                                                   .001.
AOI 1 covers the area that is visible to both avatars. AOI 4
and AOI 5 cover the areas that are visible to only one of the
avatars (e.g., Michael cannot see objects displayed in AOI 4).
                                                                   Figure 6: Duration of fixations attributed to individual AOIs.
Figure 5: Scatter plots for the distribution and durations (in     Error bars depict standard errors of the mean.
milliseconds) of eye fixations across six conditions: IFOR-
IFOR Consistent - Match (C-M), IFOR-IFOR Consistent -                 Figure 7 shows the mean duration for each AOI over the
Mismatch (C-MM), Task relevant IFOR-EFOR Inconsistent              ordinal number of eye fixations. Note that the duration of
- Match (TR-M), Task relevant IFOR-EFOR Inconsistent -             fixations for AOI 3 for both the TIR-M and TIR-MM
Mismatch (TR-MM), Task irrelevant IFOR-EFOR                        conditions projects an upward momentum on the second
Inconsistent - Match (TIR-M), and Task irrelevant IFOR-            fixations, t(13) = 2.06, p < .05. Note also that for the second
EFOR Inconsistent - Mismatch (TIR-MM). AOI 0 indicates             fixations, although the duration of fixations on AOI 2 reveals
those fixations falling outsides AOI 1~5.                          a clear upward momentum starting from the second fixations,
                                                                   t(13)= 2.47, p < .05, in TR-M and TR-MM conditions it
                                                                   shows an even more remarkable increment, t(13) = 2.57, p <
                                                                   .05.
                                                               854

                                                                      based spatial processing serves as a basis for ToM
                                                                      processing. It was also found that participants spent more
                                                                      time judging trials during which EFOR presented
                                                                      inconsistent information with the task irrelevant IFOR. This
                                                                      result is consistent with previous studies showing that people
                                                                      are unable to inhibit a third person's perspective when
                                                                      instructed to judge a ToM task from their own perspective
                                                                      (Samson et al., 2010). In our view, the conflicts between an
                                                                      individual’s perspective and a third person's perspective
                                                                      reflect the incompatibility between EFOR representations
                                                                      and IFOR representations. Moreover, when the task involved
                                                                      multiple IFORs, resolving the incompatibility between
                                                                      IFORs and that between IFOR and EFOR contributed
                                                                      significantly to the overall performance.
Figure 7: Mean duration of fixations over ordinal fixations.             The intricate interactions between multiple IFORs and
There were up to 6 fixations in each trial, listed in the             EFOR representations found in the present study suggest
chronological order on x-axis. Error bars depict standard             possible functional processes by which people abstract
errors of the mean.                                                   complex spatial information from the task environment. In
                                                                      particular, we found that perspective taking could be
                                                                      triggered by both task relevant and irrelevant IFORs (e.g.,
Discussion                                                            slower response times in the task irrelevant IFOR-EFOR
The results of Experiment 2 revealed that task relevant IFORs         inconsistent condition). Consider that participants had been
received significantly more eye fixations as compared with            given an audio prompt of the task relevant avatar before the
task irrelevant IFORs. Since participants were aware of the           visual stimuli, and the eye fixation results showed that
task relevant avatar prior to the appearance of the visual            participants’ attention was engaged onto the task relevant
stimuli, searching for the task relevant avatar was necessary         avatar fairly early in the task. Together, these observations
in order to optimize the performance. However, comparisons            indicated that participants could have spontaneously
between conditions showed that when EFOR conflicted with              established multiple IFOR representations even before their
task irrelevant IFOR, the task irrelevant avatar received more        visual attention was completely shifted towards the task
eye fixations than in the other conditions. When there were           relevant avatar. As a result, perspective taking could take
conflicts between EFOR and task relevant IFOR, task                   place almost simultaneously during the process of identity
relevant avatars received more eye fixations. However, the            recognition.
considerable amount of eye fixations found for task irrelevant           In closing, we claim that the FOR-based representations in
avatars suggests that participants did attend to those.               both spatial and social cognitive processing may offer a
Therefore, it is possible that participants detected the conflict     viable alternative explanation concerning whether the
between task irrelevant IFOR and EFOR.                                domain-general ToM abilities are supported by a separate and
   By separating the duration of fixations in chronological           innate system or intertwined with domain-specific spatial
order of fixations, it appears that the shift in eye fixations        abilities. In our view, complex and abstract cognitive
conformed to the same pattern as depicted in Figure 6.                achievements such as number cognition and theory of mind
Interestingly, the observed pattern appears for the second            may nevertheless rest on a set of fundamental processes by
fixations, which seem to follow the onset of the visual stimuli       spatial processing and spatio-temporal association (Sun &
very closely, suggesting the possibility that participants were       Wang, 2014). That is, different sets of cognitive abilities may
able to immediately detect the IFOR-EFOR conflicts and                not be domain specific per se. Rather, given their common
recognize the identity of the avatar. Note that in both Figure        low-level substrates, they are constrained by the statistical
6 and Figure 7, AOI 1 received significantly longer durations         structures of the task environment and subject to the
of eye fixations, most of which occurred at participants' first       competing demands of computational efficiency and
eye fixations. This finding was likely an artifact of the             flexibility. In the effort of partitioning the variances in the
instruction to look at the center of the screen, which also           environmental statistics, the internal representations evolve
happened to be the center of AOI 1, before the onset of the           by first developing FOR-based representations, and then,
visual stimuli. Hence the second fixations permitted                  encoding the achieved invariance at different levels of
observation of participants' visual attention at an early stage       abstraction. Since the statistical structures include not only
of the task.                                                          the spatial relations between static configurations but also the
                                                                      temporal relations between sequential events, predictive
                   General Discussion                                 encoding serves the key to integrating and selecting various
The results from the present investigation showed rapid               representations. Together, abstract representations of the task
encoding of segmented internal representations based on               environment would eventually emerge from the competitions
multiple FORs. These results strongly suggest that FOR-               among multiple FOR-based spatial representations.
                                                                  855

                     Acknowledgments                                Morton, J. B., & Munakata, Y. (2002). Active versus latent
                                                                      representations: A neural network model of perseveration,
This work was supported by the Office of Naval Research
                                                                      dissociation, and decalage. Developmental Psychobiology,
(ONR) grant number N00014-08-1-0042, and Intelligence
                                                                      40(3), 255-265. doi: 10.1002/dev.10033
Advanced Research Projects Activity (IARPA) via
                                                                    Mou, W., & McNamara, T. P. (2002). Intrinsic frames of
Department of the Interior (DOI) contract number
                                                                      reference in spatial memory. Journal of Experimental
D10PC20021. The US Government is authorized to
                                                                      Psychology: Learning, Memory, and Cognition, 28(1),
reproduce and distribute reprints for governmental purposes
                                                                      162-170. doi: 10.1037//0278-7393.28.1.162
notwithstanding any copyright annotation therein. The views
                                                                    Onishi, K. H., & Baillargeon, R. (2005). Do 15-month-old
and conclusions contained herein are those of the authors and
                                                                      infants understand false beliefs? Science, 308(5719), 255-
should not be interpreted as necessarily representing the
                                                                      258. doi: 10.1126/science.1107621
official policies or endorsements, either expressed or implied,
                                                                    Perner, J., Mauer, M. C., & Hildenbrand, M. (2011). Identity:
of IARPA, DOI, or the US Government. We thank for Dr.
                                                                      Key to children’s understanding of belief. Science,
Paul J. Schroeder and Ping Chen for their helpful comments.
                                                                      333(6041), 474-477. doi: 10.1126/science.1201216
                                                                    Perner, J., & Ruffman, T. (2005). Infants' insight into the
                         References                                   mind: How deep? Science, 308(5719), 214-216. doi:
Chen, X., & McNamara, T. (2011). Object-centered                      10.1126/science.1111656
  reference systems and human spatial memory.                       Samson, D., Apperly, I. A., Braithwaite, J. J., Andrews, B. J.,
  Psychonomic Bulletin & Review, 18(5), 985-991. doi:                 & Bodley Scott, S. E. (2010). Seeing it their way: evidence
  10.3758/s13423-011-0134-5                                           for rapid and involuntary computation of what other people
Colby, C. L., Duhamel, J. R., & Goldberg, M. E. (1995).               see. Journal of Experimental Psychology: Human
  Oculocentric spatial representation in parietal cortex.             Perception and Performance, 36(5), 1255.
  Cerebral Cortex, 5(5), 470-481.                                   Samson, D., Apperly, I. A., Kathirgamanathan, U., &
Corbetta, M., Patel, G., & Shulman, G. L. (2008). The                 Humphreys, G. W. (2005). Seeing it my way: a case of a
  reorienting system of the human brain: From environment             selective deficit in inhibiting self-perspective. Brain,
  to theory of mind. Neuron, 58(3), 306-324. doi:                     128(Pt 5), 1102-1111. doi: 10.1093/brain/awh464
  10.1016/j.neuron.2008.04.017                                      Shelton, A. L., & McNamara, T. P. (2001). Systems of spatial
Duhamel, J., Colby, C. L., & Goldberg, M. E. (1991).                  reference in human memory. Cognitive Psychology, 43(4),
  Congruent representations of visual and somatosensory               274-310. doi: 10.1006/cogp.2001.0758
  space in single neurons of monkey ventral intra-parietal          Sun, Y., & Wang, H. (2010). Perception of space by multiple
  cortex (area VIP) Brain and space. NY: Oxford University            intrinsic frames of reference. PLoS ONE, 5(5), e10442. doi:
  Press.                                                              10.1371/journal.pone.0010442
Frith, C. D., & Frith, U. (2012). Mechanisms of social              Sun, Y., & Wang, H. (2014). Insight into others' minds:
  cognition. Annual Review of Psychology, 63(1), 287-313.             Spatio-temporal representations by intrinsic frame of
  doi: 10.1146/annurev-psych-120710-100449                            reference. Frontiers in Human Neuroscience, 8:58. doi:
Gallagher, H. L., & Frith, C. D. (2003). Functional imaging           10.3389/fnhum.2014.00058
  of 'theory of mind'. Trends in Cognitive Sciences, 7(2), 77-      Tamborello, F. P., Sun, Y., & Wang, H. (2012). Spatial
  83.                                                                 reasoning with multiple intrinsic frames of reference.
Kessler, K., & Rutherford, H. (2010). The two forms of                Experimental psychology, 59(1), 3-10. doi: 10.1027/1618-
  visuo-spatial perspective taking are differently embodied           3169/a000119
  and subserve different spatial prepositions. Frontiers in         Wang, H., Johnson, T. R., Sun, Y., & Zhang, J. (2005).
  Psychology, 1.                                                      Object location memory: The interplay of multiple
Kessler, K., & Thomson, L. A. (2010). The embodied nature             representations. Memory & cognition, 33(7), 1147-1159.
  of spatial perspective taking: Embodied transformation            Wang, H., Johnson, T. R., & Zhang, J. (2001). The mind’s
  versus sensorimotor interference. Cognition, 114(1), 72-88.         views of space. Paper presented at the Proceedings of the
May, M., & Klatzky, R. L. (2000). Path integration while              Third International Conference of Cognitive Science.
  ignoring irrelevant movement. Journal of Experimental             Wang, R., & Spelke, E. (2002). Human spatial representation:
  Psychology: Learning, Memory, and Cognition, 26(1), 169.            insights from animals. Trends in Cognitive Sciences, 6(9),
McCleery, J. P., Surtees, A. D., Graham, K. A., Richards, J.          376.
  E., & Apperly, I. A. (2011). The neural and cognitive time        Zacks, J. M., & Michelon, P. (2005). Transformations of
  course of theory of mind. The Journal of Neuroscience,              visuospatial images. Behavioral and Cognitive
  31(36), 12849-12854. doi: 10.1523/JNEUROSCI.1392-                   Neuroscience        Reviews,     4(2),      96-118.     doi:
  11.2011                                                             10.1177/1534582305281085.
Mitchell, J. P. (2006). Mentalizing and Marr: An information
  processing approach to the study of social cognition. Brain
  Research,             1079(1),           66-75.          doi:
  10.1016/j.brainres.2005.12.113
                                                                856

