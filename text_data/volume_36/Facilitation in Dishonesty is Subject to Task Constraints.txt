UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Facilitation in Dishonesty is Subject to Task Constraints

Permalink
https://escholarship.org/uc/item/1bw4z3ms

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Tabatabaeian, Maryam
Dale, Rick
Duran, Nicholas

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Facilitation in Dishonesty is Subject to Task Constraints
Maryam Tabatabaeian (mtabatabaeian@ucmerced.edu)
Rick Dale (rdale@ucmerced.edu)
Cognitive & Information Sciences, UC Merced,
Merced, CA 95343 USA

Nicholas D. Duran (nicholas.duran@asu.edu)
School of Social and Behavioral Sciences, Arizona State University
Phoenix, AZ 85004 USA
Abstract
A recent line of research suggests that in a tempting situation, a
dishonest decision can be executed more quickly and easily than an
honest one. Some theories have purported that dishonesty is a
default and automatic tendency, while honesty requires a more
deliberative process. We argue that the facilitation observed in past
studies is closely dependent on the nature of the task. In the current
study we added a memory constraint to a cognitive task that
prompts dishonest responses. Participants were rewarded for their
accuracy in privately predicting the outcome of computerized coin
flips. They reported their prediction by clicking their mouse on one
of the two options on the screen (i.e., heads or tails). We collected
the mouse movements for each participant and analyzed the mouse
trajectories to study decision-making dynamics. Results revealed
that patterns of facilitation are subtle and likely shaped by task
constraints, rather than dishonesty simply being “automatic.”
Keywords: Decision-making, Dishonesty, Action Dynamics.

Introduction
Deception appears to be a surprisingly common element of
everyday social interactions (DePaulo, Kashy, Kirkendol,
Wyer, & Epstein, 1996). People often choose to behave
dishonestly because they find an advantage in lying.
Although this advantage could be motivated by a variety of
reasons it is often rooted in self-interest. People are tempted
to lie when it serves their self-interest, be it financial, social,
or emotional. This prompts an important question: In a
tempting situation where being dishonest is self-beneficial,
are people cognitively facilitated to lie or do they have to
actively inhibit the truth in order to serve their self-interest?
There are at least two competing theories that seem to
tackle this debate by addressing the underlying processes of
dishonest decisions. One theory, inspired by Spinoza’s
hypothesis about the inevitable truth bias in human belief
systems (Gilbert, 1991), suggests that honesty is the
grounded process and is therefore more accessible and
immediate. This theory suggests that in order to act
dishonestly one has to overcome a truth bias, which results
in additional time and effort (Duran, Dale, & McNamara,
2010; Duran & Dale, 2012; McKinstry, Dale, & Spivey,
2008; Spence, Farrow, Herford, Wilkinson, Zheng, &
Woodruff, 2001). In fact, a great proportion of the studies
that address the mechanisms underlying deception imply
that lying is more cognitively costly (Vrij, Mann, Fisher,
Milne, & Bull, 2008).

Some evidence supporting this view is provided by
Spence et al. (2001). They used fMRI in a behavioral task to
show that lying takes significantly more time, and results in
reliable activation within brain regions that are associated
with response inhibition. The authors relate activation in
these areas to withholding the truth. Additional evidence is
presented by a study on action dynamics of overcoming the
truth bias. Duran et al. (2010) showed that participants who
are instructed to give false responses to autobiographical
questions exhibit more complex response dynamics. They
tracked participants’ arm movements while choosing the
false or truthful answer by a Nintendo Wii Remote. Arm
trajectories revealed an ongoing competition during the
course of false responses.
A more recent line of research, however, argues that
dishonesty can be greatly facilitated, perhaps even be
“automatic,” in any tempting situation where lying pays.
This hypothesis predicts that when dishonesty serves selfinterest, people will need extra time and self-control to be
honest and refrain from cheating (Shalvi, Eldar, & BerebyMeyer, 2012). It is also consistent with the literature
concerning how depletion of self-control can increase the
chance of performing dishonestly (Gino, Schweitzer, Mead,
& Ariely, 2011).
To support this hypothesis, Shalvi and colleagues (2012)
have shown that when people are tempted to cheat under
time pressure, dishonesty appears to be the default response.
They asked participants to privately roll a die and self-report
the outcome to win money (more money for higher
numbers). Participants who completed the task under time
pressure tended to lie significantly more often. The authors
conclude that when lying pays, people will automatically
choose dishonesty over truth unless they have enough time
to deliberately refrain from lying. Furthermore, it has been
argued that when self-control resources are depleted in a
non-related task, people are more likely to behave
dishonestly (Gino et al., 2011).
Additionally, Greene and Paxton’s (2009) study on the
neural bases of honest and dishonest choices offers evidence
in favor of this view. In a behavioral task where participants
were also imaged with fMRI, Greene and Paxton covertly
encouraged cheating. Participants were rewarded for correct
self-reported predictions and lost points for wrong ones.
Dishonest participants showed robust brain activation in
control-related areas when refraining from lying. The

1562

authors suggest that when temptation is present it takes extra
effort and control to be honest.

Action Dynamics
Rather than emphasizing on variables that measure only the
outcome of a decision (e.g. reaction times), we explored the
unfolding decision processes that give rise to the outcome.
Using a methodology that tracks the dynamics of movement
over time, we investigated the changes in people’s behavior
as they make a decision, from the earliest moments of
movement initiation to final execution.
It has been shown that spatial and temporal dynamics of
motor movements can shed light on the progression of highlevel cognitive processes such as decision-making (for
reviews see Spivey & Dale, 2006; Song & Nakayama, 2008;
Freeman, Dale, & Farmer, 2011). This growing line of
research on action dynamics suggests that, despite what
traditional interpretations assume, a decision is not
necessarily finalized in the brain by the time action is
initiated. Instead, the ongoing competition between
alternative options is reflected in a person’s movement
dynamics such as eye movements or reach movements. In
this trend of work we hope to characterize dishonest
decisions by investigating micro-behavioral properties of a
response by tracking reach movements as participants use a
computer mouse.

Previous Work
In a previous study (Tabatabaeian, Dale, & Duran, 2013),
we utilized a novel task to test the two competing
hypotheses concerning the cognitive processes involved in
dishonesty (described above). We indirectly tempted
participants to cheat and collected their mouse movements
while performing the deceitful action. The goal was to track
the action dynamics of potentially dishonest decisions to
investigate underlying cognitive processes.
Participants completed an online task, in which they were
instructed to privately predict the outcomes of a series of
virtual coin flips and report their accuracy. They were
rewarded for each accurate prediction. In order to report
their accuracy, after each coin flip, participants were led to a
page with two options on the top left and top right of the
screen (“Correct” and “Wrong”). Participants were not
explicitly asked to cheat; nevertheless, opportunities to act
in a dishonest manner were present. As a cover story for the
task, participants were told that we were interested in the
influence of monetary rewards in the implicit learning of
head and tail sequence patterns.
We analyzed the temporal and trajectory properties of the
mouse movements. The goal was to differentiate dishonest
and honest decisions based on these trajectories. The results
revealed that people show less complexity in their mouse
trajectories when they are being dishonest in incentivized
tasks. “Dishonest” participants (who reported more than
70% accuracy while the expected accuracy was at the

chance level),1 showed facilitated action dynamics in
choosing the “Correct” response. While being dishonest,
they exhibited significantly shorter reaction times and more
direct mouse trajectories, which did not deviate towards the
alternative truth option. Moreover, changes in direction of
mouse movements happened less often in “Dishonest”
participants, indicating that they had more confidence in
their decision. In contrast, “Honest” participants
experienced more hesitation, which was reflected in their
longer reaction times, more complex trajectories, and more
attempts to change the direction of the mouse cursor. This
all suggests the facilitation of dishonesty in a self-serving
situation where lying is beneficial.

The Current Study
In the previous work, participants were instructed to click
on the box labeled “Correct” if their prediction matched the
actual outcome of the coin flip and click on “Wrong”
otherwise. One possible criticism of this procedure is the
ease of the task; one can automatically choose “Correct” all
the time without getting engaged in decision-making
processes throughout the experiment. In other words,
participants can decide to always immediately click on
“Correct” regardless of their actual accuracy. In order to
address this concern we added difficulty to the task.
Participants were instructed to click on boxes labeled as
“Heads” and “Tails” instead of “Correct” and “Wrong.” We
hypothesize that by doing so, participants cannot decide
about the answer at the beginning of a trial; instead they
need to actively track the outcome of the coin flips in order
to cheat. Thus, it is impossible to win extra money if they
are not actively engaged in the task. If dishonesty is always
facilitated in a tempting situation, independent from the task
nature, we expect to replicate the results from the previous
work.

Experiment
Participants
We recruited 91 participants online through Amazon’s
Mechanical Turk (AMT). They were paid $0.40 for their
time. A numeric code on the server was assigned to the
participants to ensure that they had actually completed the
task, and approved their payment on AMT.

Procedure
Participants were instructed to privately predict the outcome
of a computerized coin flip 20 times. They were notified
that there is a pattern across the coin flips that they may or
may not notice. The instructions informed participants that
they would be rewarded for each correct prediction. After
1

As we note below, this "Dishonest" designation is a
convenience; some responses may in fact have been honest.
However, given the low probability of such performance in a
random task, it is plausible to suspect that many of these responses
were dishonest.

1563

Results

5
5

Number
of Subjects
of Subjects
Number

10
10

Ten subjects failed to complete all 20 trials and were
excluded from the analysis. Data from 81 remaining
participants were used to run the statistical analysis. Trials
with total times greater than 5000ms were discarded prior to
analysis (0.4% of data). As participants’ predictions were
private, we detected lying by comparing the distribution of
self-reported accuracy with the expected distribution of fair
coin-flips. The distribution of reported correct predictions
(M= 12.70, SD = 3.1) was significantly different from a fair
distribution of random coin-flips (M = 10), t(80) = 7.70, p <
.001. The analysis suggests that participants have been
dishonest at the group level. Figure 2 shows the distribution
of self-reported percent correct. Even though the task set up
makes it impossible to distinguish dishonesty on an
individual basis, dishonest responses are expected to be
more prominent in the rightmost portion of the distribution.
Here we investigate the shape and properties of the mouse
trajectories for potential honest and dishonest decisions.

0
0

seeing the instructions, participants were shown a page
where they were asked to make a prediction. When ready,
the participants could click on a button labeled as “Flip,”
which triggered a computer animated coin flip. The outcome
of the coin flip was determined using a list made by a
random generator with equal probability for heads and tails
(50% chance of heads/tails throughout the experiment).
Once the coin landed, participants clicked on a button that
led them to a page, where they could report their prediction.
This page contained two boxes labeled as “Heads” and
“Tails” on the top left and top right of the screen. The
assignment of the labels to each side of the screen was
counterbalanced between subjects. The mouse cursor was
automatically placed on the bottom center of the screen and
the participants were expected to move the mouse towards
the desired option. The trial only finished after the
participants finalized their decision by clicking on one of the
responses. If their prediction was consistent with the actual
outcome of the coin flip, they were shown a message
indicating that they have won a bonus. Otherwise, they were
informed that no bonus was awarded. The mouse trajectory
and final response for each trial were collected for further
analysis. It is important to note that this procedure implicitly
assured participants that they would never be caught
cheating and therefore enhanced the temptation to lie. At the
end, every participant received the same bonus payment
($0.25 total). Following the last trial, participants were
asked if they noticed any patterns in the sequence of heads
and tails. Finally, they were debriefed that the study was
about response movements of people who tend to cheat
when lying serves self-interest and there is no risk of being
caught. Figure 1 displays the task sequence.

30
30

35
35

40
40

45
45

50
50

55
55

60
60

65
65

7070

75
75

80
80

85
85

90
90

95
95

100
100

Self-Reported
%Accuracy
Self-reported
% Accuracy

Figure 2: The distribution of percentage of
self-reported correct predictions.
Predict

Flip

HEADS

Heads

Tails

Nice prediction!
You will get a bonus

Figure 1: Task sequence: subjects 1) make a
prediction, 2) flip the virtual coin, 3) see the outcome
and 4) report their prediction by clicking on one of
the two boxes on top of the screen (i.e. Heads and
Tails) which were assigned to left or right side
counterbalanced. 5) They will be informed that they
got a bonus (or not) if their report was consistent (or
inconsistent) with the actual outcome.

Mouse-trajectory shape. Participants were labeled as
“Honest” and “Dishonest” based on their performance in the
experiment. 31 participants with more than 70% accuracy
were classified as “Dishonest” while other participants were
considered as “Honest.” 70% was chosen as a point where is
significantly beyond what was expected from a binomial
distribution considering conventional .05 level probability
cutoffs. It is worth noting that these labels are assigned to
participants based merely on their performance in the
current task, and do not stand for any general personality
categorization of the participants.
In order to investigate the average performance of each
group, we interpolated mouse trajectories of “Honest” and
“Dishonest” participants to 101 time steps. The time steps
were superimposed to produce average trajectories, which
are represented in Figure 3. Trials in which the reported
prediction (heads or tails) was consistent with the outcome
of the coin flip were considered “Correct” and trials of the
opposite kind were marked as “Wrong.” Showing a different
pattern from the previous findings, average trajectories for
correct do not illustrate any significant disparity between
“Honest” and “Dishonest” participants. However,

1564

surprisingly, the difference appears to be captured by wrong
trajectories. A possible explanation, given that there is
approximately no difference between “Honest” and
“Dishonest” in correct trajectories, is the influence of
repetition priming. In correct trials participants only have to
choose the option that is consistent with what they saw on
the screen (heads or tails), thus they are much faster in
choosing the matching option. On the other hand, when
reporting a wrong prediction, they have to click on an option
that is inconsistent with what they were shown on the
screen. Thus they are expected to take more time to respond.
However, there is a substantial difference between “Honest”
and “Dishonest” trajectories in wrong trials with
“Dishonest” participants exhibiting more complexity when
being honest. Their average trajectory captures a desire to
report the alternative deceitful option. Although, both
groups are slower in reporting an inconsistent response,
“Dishonest” people are slower with more deviated
trajectories. Next, we compare these trajectory shapes by
extracting measures from them and conducting further
analysis on their quantified properties in terms of extent,
complexity, etc. Figure 3 demonstrates the difference
between the current findings (the graph on top) and the
previous study (bottom graph).

600

350

250

150

Dishonest CORRECT
Honest CORRECT
Dishonest WRONG
Honest WRONG

0

150

250

350

600

350 250 150

0

Dishonest CORRECT
Honest CORRECT
Dishonest WRONG
Honest WRONG

150 250 350

Figure 3: The figure on top shows the average
trajectories of “Honest” (black) vs. “Dishonest”
(gray) subjects while reporting correct (solid line) or
wrong (dashed line) predictions in the current
experiment. The bottom figure shows the
corresponding trajectories from the previous study
(Tabatabaeian et al., 2013).

Mouse-trajectory properties. The participants’ mouse
movements offer a variety of dependent variables that can
be extracted by analyzing the trajectory (x,y) coordinates
across time. The measures are interpreted together to reveal
overall patterns of cognitive processes underlying the
decisions. In the current study we extracted four variables to
characterize the temporal and trajectory behavior of
participants in each trial:
•

•

•

•

Total time: This includes the overall time of one trial
from the moment participants see the page containing
two choices (Heads, Tails) to the moment they click
on one of the two.
Distance: The Euclidean distance traveled by the
trajectory from the initiation point until clicking on the
final answer (Heads or Tails).
x-flips: Number of x-ﬂips indicates the number of
times the mouse cursor changes direction along the xaxis (i.e., the axis of decision). This variable can be
understood as a measure for hesitation, or response
complexity.
x-range: This is defined as the absolute distance
between the smallest and the largest x-coordinate that
the mouse reached through transition towards the
chosen answer. This measure can capture the pull
toward the alternative response, interpreted loosely as
the competition between the responses.

The total time and motion time are temporal measures,
whereas other variables mainly capture the dynamic changes
along the mouse trajectory coordinates. Table 1 provides the
mean values and standard deviations of the dependent
variables for correct and wrong trajectories grouped by
honesty. For each of the four dependent variables, we
conducted a linear mixed effects model with a fully
specified random effects structure. We used honesty
(Honest vs. Dishonest), response type (Correct vs. Wrong),
and the interaction term between them as fixed effects. As
random effects, we had intercepts for subjects, as well as
by-subject random slopes for the fixed effects.
In the previous work, we treated total accuracy as both a
continuous and discrete effect (Tabatabaeian et al., 2013).
For simplicity and clarity of presentation, in the present
work, we report the results more clearly by classifying the
participants into “Dishonest” (total accuracy >= 70%) and
“Honest” (total accuracy < 70%). Thus, in the current
analysis we chose honesty as a discrete fixed effect. A
summary of results is provided in Table 2.
The models for temporal measures showed that response
type has significant effects on total time (B = -138.42, p <
.001). All participants exhibited shorter reaction times
(about 138 millisecond faster) when reporting a correct
prediction; by clicking on the response that was consistent
with the outcome of the coin flip. The results fit with the
intuitive interpretation that emphasizes the effect of
repetition priming.

1565

Table 1: Means and standard deviations of the mouse-trajectory variables by honesty and response type
Dishonest
Correct
Variable
Total time (ms)
Distance (pixels)
x-range(pixels)
x-flips

M
1021.89
853.88
447.63
0.90

Honest
Wrong

SD
420.70
271.50
128.58
1.01

M
1184.05
963.79
484.33
1.46

SD
634.22
383.46
152.07
1.45

Correct
M
SD
1025.47
465.72
874.51
376.02
457.60
181.74
0.95
1.07

Wrong
M
SD
1138.90
630.03
896.76
357.27
463.55
163.87
1.17
1.26

Table 2: Coefficient estimates from mixed-effects models predicting variables
Variable
Total time (ms)
Distance (pixels)
x range(pixels)
x flips

B
11.17
14.16
2.72
0.10

Dishonesty
SE
65.76
47.58
22.07
0.11

t
0.17
0.30
0.12
0.90
* p<.05.

The model for x-range also supports the effect of response
type. Reporting a trial as correct is a significant predictor of
x-range (B = -25.2, p < .001). Correspondingly, we found a
marginally significant interaction between response type
and dishonesty for x-range (B = -26.91, p = .08), suggesting
that “Dishonest” participants had less curved mouse
trajectories when answering correct versus wrong. However,
“Honest” participants experienced a less dramatic change in
their x-range when reporting a correct versus a wrong
prediction. This offers some preliminary evidence that
mouse trajectories of “Dishonest” participants were pulled
towards the deceitful alternative when they were being
honest, whereas “Honest” participants did not show any
substantial difference in their trajectories regardless of the
response type. Figure 4 illustrates the interaction between
response type and honesty.

460

470

Dishonest

450

mean of x-range

480

Honest

Wrong

Correct

Figure 4: Average x-range grouped by honesty and response
type.
The number of x-flips, which can be an indicator of
hesitation, is significantly influenced by response type (B =
-0.31, p < .001). When reporting a correct prediction,
participants changed the direction of their mouse cursor

Response type
B
SE
-138.42
33.65
-70.45
18.04
-25.20
7.32
-.31
0.06
** p<.01.

t
-4.11**
-3.90**
-3.44**
-4.93**

B
-65.21
-84.88
-26.91
-0.20

Interaction
SE
t
72.42
-0.90
40.26
-2.10*
15.49
-1.73
0.13
-1.49

about 30% less compared to trials reported as wrong. This
suggests that all participants experienced less hesitation
while choosing the consistent response either truthfully or as
a deceptive answer.
The other variable that shows the cognitive process
correspondent to the mouse trajectory is the absolute
distance that the mouse cursor has traveled. Distance is
significantly predicted by response type (B = -70.45, p <
.001), as correct trials contain shorter and more direct
trajectories. Moreover, there is a significant interaction
between honesty and response type (B = -84.8, p = .03),
suggesting that “Dishonest” participants had longer and
more curved mouse trajectories while reporting a prediction
as wrong.

General Discussion
A recent line of research suggests that in a situation where
dishonesty serves self-interest, acting dishonestly is an
“automatic” tendency, while honesty requires a more
deliberative process (Shalvi, Dana, Handgraaf, & De Dreu,
2011; Shalvi, et al., 2012). In a previous study we used
action dynamics to investigate people’s behavior when they
were naturally tempted to act dishonestly (Tabatabaeian et
al., 2013). Consistent with this new line of research, our
previous findings showed that in a tempting situation where
lying pays, people are more facilitated in lying than telling
the truth. In the current study, however, we argue that the
facilitation observed in past studies is closely dependent on
the nature of the task. We added a level of difficulty to a
cognitive task that tempts people to cheat. Participants were
rewarded for their accuracy in privately predicting the
outcome of a computerized coin flip. They reported their
prediction by clicking the mouse on one of the two options
on the screen (Heads and Tails instead of Correct and
Wrong). The new task differs from the previous tasks, as it
increases the level of engagement. In the previous study

1566

participants could passively choose a response (Correct or
Wrong), however, the current task forces them to actively
track the outcome of the coin flip in order to win. We
analyzed participants’ mouse trajectories to study their
decision-making dynamics. Hence, in the current task, it is
not dishonesty that is facilitated; rather the more intuitive
process that maintains response consistency is the dominant
process.
The difference between “Honest” and “Dishonest”
participants, which was previously captured in correct
trajectories, is now evident in wrong trajectories. Put
another way, “Dishonest” participants merely exhibit a
deviation from others when they are reporting their
prediction as wrong (i.e. being honest). In such situations
their trajectories demonstrate a pull towards the deceitful
answer, indicating a desire for lying. More than facilitation
in lying, the results revealed a signature of temptation to
cheat in “Dishonest” participants, while being honest. Thus,
it appears that changing the nature of the task directly
influences the facilitated process. In the current task, it is
not dishonesty that is facilitated; rather the more intuitive
process that maintains response consistency is the dominant
process.
One possible explanation for the collapse of the difference
between average trajectories in correct trials is provided by
repetition priming. The task setup dictates an advantage for
responses that are consistent with the outcome of the coin
flip. These responses happen to be the tempting option and
therefore make it difficult to study the dynamics of
dishonest responses. Although repetition priming makes
correct responses easier for all participants, it helps
distinguish “Honest” and “Dishonest” participants when
they select an answer opposite to what they were shown. It
is hard for everyone to report an inconsistent response but
more so for “Dishonest” participants, as they attempt to
develop a self-serving strategy as well. The results revealed
that the task modification forces the difference between the
two groups to appear in wrong trajectories rather than
correct trajectories. “Dishonest” participants tended to be
slower and more hesitant compared to “Honest”
participants. They showed longer and more curved
trajectories, indicating their desire to lie when they chose
the truthful option.
The current study suggests that task variables indeed
determine whether and how self-serving biases are reflected
in cognitive dynamics. The present manipulation of the task
seems to offer a more realistic picture of naturalistic
deception by capturing the temptation to behave
dishonestly. In a tempting situation, dishonesty is not
always the facilitated tendency; rather it is one of the
competing processes that may or may not come to govern
responses.
Importantly, it is not easy to disentangle all different task
variables that are producing the effects. We cannot be sure if
repetition priming is responsible for all of the observed
effects. However, these findings start a promising trend for
discussion.

References
DePaulo, B. M., Kashy, D. A., Kirkendol, S. E., Wyer, M.
M., & Epstein, J. A. (1996). Lying in everyday life.
Journal of personality and social psychology,70(5), 979.
Duran, N. D. & Dale, R. (2012). Increased vigilance in
monitoring others’ mental states during deception. In N.
Miyake, D. Peebles, & R. P. Cooper (Eds.), Proceedings
of the 34th Annual Conference of the Cognitive Science
Society (pp. 1518-1523). Austin: TX: Cognitive Science
Society.
Duran, N. D., Dale, R., & McNamara, D. S. (2010). The
action dynamics of overcoming the truth. Psychonomic
Bulletin & Review, 17, 486–91.
Freeman, J. B., Dale, R., & Farmer, T. A. (2011). Hand in
motion reveals mind in motion. Frontiers in Psychology,
2, 59.
Gilbert, D. T. (1991). How mental systems believe.
American Psychologist, 46, 107-119.
Gino, F., Schweitzer, M. E., Mead, N. L., & Ariely, D.
(2011). Unable to resist temptation: How self-control
depletion promotes unethical behavior. Organizational
Behavior and Human Decision Processes, 115, 191–203.
Greene, J. D., & Paxton, J. M. (2009). Patterns of neural
activity associated with honest and dishonest moral
decisions. Proceedings of the National Academy of
Sciences of the United States of America, 106, 12506–11.
McKinstry, C., Dale, R., & Spivey, M. J. (2008). Action
dynamics reveal parallel competition in decision making.
Psychological Science, 19, 22–24.
Shalvi, S., Dana, J., Handgraaf, M. J. J., & De Dreu, C. K.
W. (2011). Justified ethicality: Observing desired
counterfactuals modifies ethical perceptions and behavior.
Organizational Behavior and Human Decision Processes,
115, 181–190.
Shalvi, S., Eldar, O., & Bereby-Meyer, Y. (2012). Honesty
requires time (and lack of justifications). Psychological
Science, 23, 1264–70.
Song, J. H., & Nakayama, K. (2008). Target selection in
visual search as revealed by movement trajectories.
Vision research, 48(7), 853-861.
Spence, S. A., Farrow, T. F., Herford, A. E., Wilkinson, I.
D., Zheng, Y., & Woodruff, P. W. (2001). Behavioural
and functional anatomical correlates of deception in
humans. Neuroreport, 12, 2849–53.
Spivey, M. J., & Dale, R. (2006). Continuous dynamics in
real-time cognition. Current Directions in Psychological
Science, 15, 207–211.
Tabatabaeian, M., Dale, R., & Duran, N. (2013). Is
dishonesty an automatic tendency? In P. Bello, M.
Guarini,
M.
McShane,
&
B.
Scassellati
(Eds.) Proceedings of the 35th Annual Meeting of the
Cognitive Science Society, Berlin, Germany.
Vrij, A., Mann, S. A., Fisher, R. P., Leal, S., Milne, R., &
Bull, R. (2008). Increasing cognitive load to facilitate lie
detection: the benefit of recalling an event in reverse
order. Law and human behavior, 32(3), 253.

1567

