UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Speaker-gaze Modulates the Inter-personal Repetition of Hand Gestures
Permalink
https://escholarship.org/uc/item/3bj348qz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Mol, Lisette
Althof, Milou
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

          Speaker-gaze Modulates the Inter-personal Repetition of Hand Gestures
                                            Lisette Mol (l.mol@tilburguniversity.edu)1,2
                             1
                               Tilburg center for Cognition and Communication (TiCC), Tilburg University
                                         P.O. Box 90135, NL-5000 LE Tilburg, The Netherlands
                   2
                     Cognitive Interaction Technology - Center of Excellence (CITEC), Faculty of Technology,
                                                  Bielefeld University, Bielefeld, Germany
                                              Milou Althof (miloualthof@gmail.com)1
                                Abstract                                 Brennan, 1991). This means that as gesture forms converge,
  One study found that observers retained more information               the associated concepts converge as well and interlocutors
  from hand gestures that speakers gazed at, possibly because            incrementally arrive at common ground.
  speaker-gaze shifted observers' attention covertly. Speaker-             To draw their addressee's attention to their gestures,
  gaze may thus modulate the role of gestures in                         speakers might employ gaze (e.g., Goodwin, 1981; Gullberg
  communication. One hypothesized communicative function of              & Holmqvist, 1999, 2006; Streeck, 1993). Consistent with
  gestures, and specifically of the inter-personal repetition of
  gestures, is to facilitate the process of creating common              this hypothesis, addressees gain more information from
  ground (grounding). Therefore, speaker-gaze may also                   gestures that speakers gazed at (Gullberg & Kita, 2009).
  influence the inter-personal repetition of gestures. In an             This shows that speaker-gaze can modulate gestures' role in
  experimental study, we found that participants were more               communication. Would speaker-gaze therefore also
  likely to repeat another speaker's gestures if the original            influence the inter-personal repetition of gestures, thereby
  speaker gazed at the gestures. Moreover, speaker-gaze was a
  better predictor of this repetition than participants' own gaze.       potentially modulating gestures' role in grounding?
  This supports the hypothesis that speakers' gaze at their                This study is a first step in testing if and how speaker-gaze
  gestures leads to covert attention shifts in observers, causing        modulates the inter-personal repetition of gestures and
  the gestures to be processed differently. Speaker-gaze could           ultimately grounding. By comparing the role of speaker-
  therefore be a valuable cue to the processing and production           gaze and observer-gaze, we also shed light on how gestures
  of gestures by artificial systems that interact with humans.
                                                                         are attended to.
  Keywords:      Gesture;       Gaze;    Perception;    Alignment;
  Adaptation                                                             Gestures, Gaze, and Information Uptake
                                                                         In human-human dialogue, addressees mostly gaze at the
                          Introduction                                   speaker's face, rather than the speaker's hands (Argyle &
Speech tends to be accompanied by hand gestures (Kendon,                 Cook, 1976; Kendon, 1990). Studies using eye-tracking
2004; McNeill, 1992, 2005), which can depict aspects of the              report an average percentage of time participants fixated on
content we convey (representational hand gestures),                      a speaker's face ranging from 84.9% to 98.4% (Beattie,
emphasize certain parts of it (beats), or regulate our                   Webster, & Ross, 2010; Gullberg & Holmqvist, 1999,
interaction (interactive gestures), (Bavelas, Chovil, Lawrie,            2006). Participants were reported to gaze at a speaker's
& Wade, 1992). Next to several for-speaker functions,                    hands only a small percentage of time (<.5% - 2.1%).
representational gestures are likely to serve for-addressee                Gaze at hand gestures has been studied in more detail. The
functions (e.g., Alibali, Heath, & Myers, 2001; Bavelas,                 percentage of hand gestures that addressees gaze at, varies
Gerwing, Sutton, & Prevost, 2008; Jacobs & Garnham,                      as a function of certain properties of the gestures (Beattie, et
2007; Mol, Krahmer, Maes, & Swerts, 2011; Özyürek,                       al., 2010; Gullberg & Kita, 2009), related to the properties
2002). Importantly, people can gain semantic information                 of peripheral vision. For example, for iconic gestures from a
from representational gestures (e.g., Beattie & Shovelton,               character viewpoint (CVP)1, more gestures with a smaller
1999b; Cassell, McNeill, & McCullough, 1998).                            movement span were fixated on (17/30) than gestures with a
  Numerous studies have found that perceiving others'                    larger movement span (9/30) (Beattie, et al., 2010). For
representational hand gestures influences how we shape our               these iconic CVP gestures1, participants also gazed at the
own (Holler & Wilkin, 2011; Kimbara, 2006, 2008; Kopp &                  low span gestures for a longer percentage of their stroke2,
Bergman, 2013; Mol, Krahmer, Maes, & Swerts, 2012;                       compared to the high span gestures (Beattie, et al., 2010).
Parrill & Kimbara, 2006). That is, interlocutors tend to
repeat each other's representational hand gestures. This                    1
                                                                              Iconic CVP gestures are gestures that depict part of a story, as
inter-personal repetition of gestures is thought to facilitate           though the speaker were the character in the story. For example,
grounding (Holler & Wilkin, 2011), analogous to the inter-               speakers may pretend to throw a ball if the character was doing so.
                                                                            2
personal repetition of referring expressions (Clark &                         The stroke is the most meaningful phase of a gesture and in
                                                                         this case also the most energetic part.
                                                                    2645

Interestingly, in other studies, iconic CVP gestures with low             Cassell, et al., 1998). Then this information, in the form of
span were found to be more informative to addressees                      one or more semantic representations, will be linked to one
(Beattie & Shovelton, 1999a, 2002). There may thus be a                   or more representations of the observed gesture form.
relation between addressees' information uptake from a                    Therefore, when the observer subsequently wants to express
gesture and their gaze at a gesture (Beattie, et al., 2010). Yet          this information, the representation(s) of gesture form will
although these general trends were found for particular                   get activated and the observed gesture (or a similar one)
types of gestures, correlations between gaze and uptake                   may be reproduced. This is predicted both by theories that
have not been found within individuals.                                   assume automated priming underlying the inter-personal
  Gullberg and Kita (2009) found little evidence for a direct             repetition of linguistic behaviors (Pickering & Garrod,
relation between addressees' fixations at speakers' gestures              2004) and by theories in which this inter-personal repetition
and their information uptake from these gestures. Making                  is part of a deliberate grounding process (Clark & Brennan,
use of gestures from a previously collected data set, they                1991; Holler & Wilkin, 2011). A similar argument may hold
found that addressees (i.e. observers of clips) were more                 for beat gestures and information on importance/stress.
likely to fixate on gestures that the speaker had gazed at                  Now if it is the case that the gestures that a speaker gazes
(gestures with speaker-gaze), as well as on gestures that                 at are attended to more closely by observers, this will lead to
contained a post-stroke hold3. Interestingly, onset latencies             higher activations of observers' internal representations. It is
of addressees' fixations were longer for gestures with                    therefore expected that observers are more likely to repeat
speaker-gaze than for gestures with a post-stroke hold.                   gestures that they saw with speaker-gaze than those they
Gullberg and Kita explain this as addressees gazing at                    saw without speaker-gaze. If the associated attention shift
gestures with speaker-gaze for top-down, social reasons                   indeed happens covertly, speaker-gaze is expected to be a
(social alignment), whereas they gaze at gestures with a                  better predictor of the inter-personal repetition of gestures
post-stroke hold for bottom-up, stimulus driven reasons.                  than observer-gaze.
Information uptake was not found to be larger for gestures                  On the other hand, eye-contact was found to facilitate the
with a post-stroke hold, yet addressees did gain more                     deliberate repetition of hand movements (Wang, Newport,
information from gestures with speaker-gaze. Addressees                   & Hamilton, 2011). Hand movements were repeated faster
were more likely to retain non-vital information (direction               if the gaze of a person in a video-clip, who performed the
of movement) when they had observed a gesture with                        movements, was directed towards the person watching the
speaker-gaze. However, Gullberg and Kita found little                     clip, who needed to repeat the movements. Therefore, the
evidence that the effect of speaker-gaze on information                   (deliberate) repetition of hand gestures may be facilitated by
uptake was mediated by addressees' own gaze. Rather, there                eye-contact. Hence, gestures that are gazed at by a speaker
seemed to be a direct effect of speakers' gaze to their                   may be less likely to be repeated by an observer, since there
gestures on addressees' uptake from these gestures.                       is less eye-contact. However, in communication the
  Posner (1988) describes that locations of visual stimuli                repetition of a hand gesture by another interlocutor can
can be attended covertly, that is "without any change in eye              happen at any later time (Holler & Wilkin, 2011). This may
or head position", and that this covert attention to a location           reduce the role of eye-contact in the repetition of gestures.
can change the priority of a stimulus in the covertly attended            Moreover, speakers tend to alternate their gaze between
location (Posner & Petersen, 1990, p. 27). It may thus be                 their gesture and the addressee (Streeck, 1993).
the case that a speaker's gaze to a gesture guides the                      Gullberg and Kita (2009) hypothesized that addressees
addressee's attention to this gesture covertly (i.e. without the          may gaze at gestures with speaker-gaze for social reasons
addressee gazing at the gesture), resulting in more efficient             (social alignment). Since social reasons can also underlie the
processing of the gesture and ultimately better information               inter-personal repetition of behaviors (Cheng & Chartrand,
uptake, or recall. Gullberg and Kita (2009, p. 269)                       2003), gestures that are gazed at by a speaker may be more
speculated that "although overt gaze-following is not                     likely to be copied for social reasons as well. In this case,
automatic, covert attention shift to the target of a speaker’s            observer-gaze may be more strongly correlated to the inter-
gaze location may well be". Yet they state that their finding,            personal repetition of gestures than speaker-gaze, since both
which was not completely replicated in a more controlled                  gaze-following and the repetition of the gesture would be
experiment in which gaze was manipulated artificially,                    instances of social alignment.
needs to be consolidated in further studies.
                                                                          Present Study
Gaze and the Repetition of Gestures                                       As a first step in testing if and how speaker-gaze modulates
Suppose that observers gain semantic information from                     the inter-personal repetition of gestures, we tested whether a
representational gestures (e.g., Beattie & Shovelton, 1999b;              speaker's gaze at her own gestures affected the likelihood of
                                                                          these gestures being subsequently repeated by another
                                                                          speaker. In this first study, we minimized effects of social
   3
     During a post-stroke hold, the hands are steady for a bit, before    processes and of deliberate processes involved in grounding,
returning to a resting position or moving towards the next stroke.
                                                                      2646

by having participants see the gestures performed by one
person and then talk to another person themselves. This
allowed us to first reveal any automated mechanisms at
play.
  We used life-sized projections of a speaker as stimuli.
This way, speaker-gaze could be manipulated reliably and
participants' eye-movements could be tracked with a
freestanding eye-tracker, allowing us to measure the effect
of speaker-gaze and of observer-gaze.
Research Question and Hypotheses
RQ: Are people more likely to repeat gestures that they
perceived with than without speaker-gaze?
Hypothesis 1: When participants observe and retell a
narration that includes gestures, they are more likely to
repeat the gestures that the original speaker gazed at.
Hypothesis 2: Speaker-gaze is a stronger predictor of
whether a gesture will be repeated than is participants' own
gaze while perceiving the narration (observer-gaze).                 Figure 1. Stimulus movie snapshots. Top: gesture with
                                                                   speaker-gaze. Bottom: same gesture without speaker-gaze.
                           Method
                                                                  camera. One group of participants saw the speaker gaze at
Participants                                                      one half of her gestures (stimulus movie 1) and the other
Twenty-five (16 female) Dutch students of Tilburg                 group at the other half (stimulus movie 2).
University participated in this study for course credit             Out of the 24 iconic gestures, 15 were from a character
(excluding one participant who knew the aim of the study).        viewpoint (CVP), e.g. pretending to grab Tweety, and 9
                                                                  were from an observer viewpoint (OVP), e.g. outlining
Design                                                            manner and path of how Sylvester rolled down the street.
Whether the speaker gazed at a gesture or not was                 The number of CVP and OVP gestures with speaker-gaze in
manipulated within participant. The dependent variable            stimulus movie 1 and 2 was balanced. All beats were
consisted of the number of gesture that participants repeated     performed in the same manner: lifting the joined hands
in their own retellings of the stimuli.                           briefly from their position in the speaker's lap. They mostly
  To control for any factors related to the gestures as such,     accompanied character names.
two versions of the stimulus movie were created and each
was shown to half of the participants who did the retelling.      Procedure and Task
In either version, the same speaker performed the same            Two participants came to the lab and were each assigned to
narration with the same gestures. However, in one movie,          the role of narrator or listener. It was taken into account that
she gazed at one half of her gestures and in the other she        the narrator's gaze needed to be tracked. Therefore, if one
gazed at the other half of her gestures (Figure 1). This way,     participant wore glasses, they would be the listener.
if participants were more likely to repeat the gestures that        The narrator took place in a seat with a freestanding eye-
the speaker gazed at, this could not be due to intrinsic          tracker placed in front of it, on a laptop stand. This seat was
properties of the gestures, such as movement span or              facing a white wall, on which stimulus movie 1 or 2 was
perspective.                                                      projected life-sized. Before each episode, the eye-tracker
  Additionally, participants' eye-movements were tracked          was calibrated. Then the narrator watched the episode
with a free-standing eye-tracker, to test if participants' own    (sound was played over speakers), while the listener listened
gaze was a better predictor of the repetition of gestures than    to music over headphones, in a chair that was facing away
was speaker-gaze.                                                 from the projection.
                                                                    After watching an episode, the narrator took place in a
Material                                                          chair that was aligned with the chair of the speaker in the
The gestures in the stimulus movie were taken from                stimulus movie and the listener sat across (Figure 2, next
previously collected retellings of a Tweety and Sylvester         page). The experimenter switched on the camera capturing
cartoon (Mol, Krahmer, Maes, & Swerts, 2009; Mol, et al.,         the narrator and the narrator related the story of the cartoon
2011). The speaker in the stimulus movies produced 24             episode to the listener. Afterward, the experimenter
iconic gestures and 10 beats, half of which she gazed at          switched off the camera. Then the listener answered some
(alternating). The rest of the time, she looked into the          questions on the story, while listening to music and facing
                                                              2647

                                                                          Mean number of repeated gestures
                                                                                                             2.00
                                                                                                             1.75
                                                                                                             1.50
                                                                                                             1.25
                                                                                                             1.00
                                                                                                             0.75
                                                                                                             0.50
                                                                                                             0.25
                                                                                                             0.00
                                                                                                                    Speaker-gaze   No Speaker-gaze
                      Figure 2: Setting                             Figure 3: Mean number of repeated gestures with and
                                                                     without speaker-gaze. Error bars represent SEM.
away from the projection. At the same time, the eye-tracker     units participants mentioned. No significant differences
was calibrated and the narrator watched the next episode.       between the gaze and no-gaze condition were found for the
This was repeated for all five episodes and all participants.   other categories (partial repetition p = .47, other iconic
                                                                gesture p = .58, other beat gesture p = 1, no gesture p = .59,
Coding & Analyses                                               all these categories combined p = .17).
The resulting videos were coded using Elan (Wittenburg,           The stimulus movie contained 24 iconic gestures and 9
Brugman, Russel, Klassmann, & Sloetjes, 2006). For each         (version 1) or 10 (version 2) beats. Thirteen participants saw
content-unit that had occurred with a gesture in the            version 1 and twelve saw version 2, rendering 837 gesture
stimulus-movie (e.g. throwing a bowling ball, swinging          tokens. In total, participants repeated 57 observed gestures
across), it was determined whether participants mentioned it    in their own retelling (6.8 %), including 14 out of 237 beats
verbally and if so, whether they simultaneously produced: a     (5.9%) and 43 out of 600 iconics (7.2%).
repetition of the observed gesture, a partial repetition,         For each of these repeated gestures, it is known whether
another gesture, or no gesture. This decision was based on:     the speaker in the stimulus clip gazed at it (speaker-gaze)
hand shape, hand orientation, location and movement             and it was measured whether the participant fixated on the
(speed, direction, size). Twenty percent of the data was        gesture while watching the stimulus clip (participant-gaze).
double coded. Percentage agreement on whether a content-        Therefore, using the binomial distribution, we can compute
unit was mentioned was 95%. Cohen's kappa on the original       whether gestures seen with speaker-gaze or being produced
four gesture labels was .61. The coders disagreed most on       with participant-gaze were over-represented in the set of
partial repetitions. Cohen's kappa for whether there was a      repeated gestures.
full repetition was .80, indicating substantial agreement         The speaker in the stimulus clip gazed at 425 out of 837
(Landis & Koch, 1977). We report full repetitions.              gestures, that is, with a chance (p) of .508. Out of the 57
  Unfortunately, it turned out that one beat was missing in     repeated gestures (n), 27 iconics and 10 beats had been seen
stimulus movie 1. Since there cannot be gaze to a gesture       with speaker gaze, making for 37 gestures with speaker-
that was not performed, this data point is not informative to   gaze (k). This renders a binomial z-ratio of 2.00, indicating
our hypothesis. It was therefore treated as missing data for    that the number of gestures with speaker-gaze in the set of
participants who saw stimulus movie 1.                          gestures that were repeated is higher than chance (one-tailed
  The eye-tracking data was pre-processed with BeGaze by        test: p = .023).
SMI. This rendered a movie clip for each participant, in          In sum, participants gazed at 159 out of 837 gestures.
which the participants' fixations were shown as a small         However, in 201 cases (24%), there was missing data,
circle projected onto the stimulus movie. Elan was used to      because calibration was off, or no circle appeared on the
manually code whether participants gazed at each gesture.       clip, leaving it unclear whether the participant fixated on the
  Unfortunately, our video-recordings did not allow us to       gesture. The latter could either mean the participant looked
code participants' gaze to their own gestures.                  elsewhere (not on the clip), or the tracker lost track of the
                                                                participant's gaze. Thus, participants gazed at a gesture in
                         Results                                159 out of 636 observed cases, that is, with a chance (p) of
A paired-samples t-test revealed that, consistent with          .25. Out of the 57 (n) repeated gestures 12 (k) iconics were
hypothesis 1, participants repeated more gestures that the      fixated on by participants (4 cases missing) and no beats (3
speaker gazed at (M=1.48, SD=1.42) than that she did not        cases missing). The number of gestures with participant-
gaze at (M=.80, SD=1.00), t(24)=2.37, p=.026, 95% CI of         gaze in the set of repeated gestures did not differ from
difference = (.09, 1.27), see Figure 3. Results were similar    chance (binomial z-ratio = -.54, one-tailed test: p = .30), not
for iconics (p=.061) and beats (p=.11). Similar patterns were   even when assuming all cases of missing data were gestures
also observed when controlling for the number of content-       with observer-gaze. The data therefore support hypothesis 2.
                                                            2648

              Discussion and Conclusion                             look at his goal (Tweety), rather than his paws. The repeated
This study is first to show that speakers' gaze towards their       CVP-gestures were: having a ball in one's stomach, lifting a
gestures can increase the repetition of these gestures by           rug, hitting with an umbrella, carrying luggage, drawing,
another speaker. This is consistent with the hypothesis that        throwing a weight, grabbing Tweety, holding Tweety (while
speaker-gaze can signal the communicative import of a               shooting up). The following CVP gestures were never
gesture (Goodwin, 1981; Gullberg & Holmqvist, 1999,                 repeated: climbing up, throwing a ball, playing an organ,
2006; Streeck, 1993) and it shows that addressees are               giving a coin, throwing away a suitcase, rubbing hands,
sensitive to this. This is relevant to work on embodied             holding Tweety (while falling down). From this, we see no
conversational agents.                                              evidence that the effect was caused by unnatural gaze.
  Consistent with findings on gaze and information uptake             Future studies need to assess whether speaker-gaze plays a
(Gullberg & Kita, 2009), we found that speaker-gaze was a           larger role when interacting in dialogue, with the same
better predictor of whether a gesture would be repeated than        partner being present throughout the conversation. Since
was the observer's own gaze. This is in line with the               dialogue allows for (deliberate) grounding, both automated
explanation that speaker-gaze leads to a covert attention           and flexible processes may influence the inter-personal
shift in the observer. This shift may be to the location of the     repetition of gestures in dialogue (Kopp & Bergman, 2013).
gesture, causing the gesture to be processed differently,           Hence, more inter-personal repetition of gestures is
analogous to the way in which other stimuli in attended             expected and possibly a larger role for speaker-gaze. Yet
locations are processed differently from those in unattended        although the percentage of repeated gestures in our data
locations (Posner, 1988). Apparently, this difference in            (7%) may seem small, it is not too far from rates found in
processing caused the gesture to be more prone to repetition        natural interaction (Mdn = .04, Range = .11), (Holler &
(this study) and for the information from the gesture to be         Wilkin, 2011). Holler and Wilkin used a very different task,
more likely retained (Gullberg & Kita, 2009).                       involving the description of tan gram figures. It would be
  Interestingly, our results were obtained without dialogue         highly interesting to compare the inter-personal repetition of
between the speaker who originally performed the gesture            gestures and the effect of speaker-gaze on it between a
and the speaker repeating it. Thus, the repetitions we found        dialogue setting and a setting like in the current study, yet
cannot be instances of deliberate social alignment, nor could       with similar tasks. Since dialogue also allows for social
they be part of a deliberate grounding process between the          alignment, the correlation between an observer's gaze to a
original performer and the repeater. Rather, a link between a       speaker's gestures and their repetition of these gestures may
representation of gesture form and a representation of the          also be larger in dialogue, as observers may both follow a
associated meaning seems to have been formed as a result of         speaker's gaze and copy their gesture for social reasons.
automated processes, causing the observer to be more likely
to reproduce the observed gesture when later expressing the                            Acknowledgements
same meaning (cf. Pickering & Garrod, 2004).                        We thank Karin van Nispen for being the speaker in our
  Given that we found similar patterns for iconic gestures          stimulus clips, Rein Cozijn for assistance with the eye-
and beats, it seems that it does not matter whether this            tracking equipment and data-processing, Stefan Kopp, Fons
meaning is semantic, or pragmatic (stress/import) in nature.        Maes, Jorrig Vogels and the anonymous reviewers for their
It is somewhat surprising though that beat gestures were            helpful comments to earlier versions. This research was
repeated across individuals too. To our knowledge, this has         enabled by a Veni Grant from the Netherlands Organisation
not been shown or tested before. Even though the original           for Scientific Research (NWO), awarded to the first author.
speaker always performed the same beat gesture, this
gesture was more likely to be repeated with parts of the                                     References
story in which she had gazed at it. However, it may be the          Alibali, M. W., Heath, D. C., & Myers, H. J. (2001). Effects
case that participants interpreted these beats as deictic              of visibility between speaker and listener on gesture
gestures, indicating the location of the (usually)                     production: Some gestures are meant to be seen. Journal
concurrently mentioned character. An informal analysis of              of Memory and Language, 44, 169-188.
an existing gesture corpus showed that speakers hardly gaze         Argyle, M., & Cook, M. (1976). Gaze and mutual gaze.
at their beats. Hence, speaker-gaze may have affected the              Cambridge: Cambridge University Press.
interpretation of the beat gestures. Therefore, the finding         Bavelas, J., Chovil, N., Lawrie, D. A., & Wade, A. (1992).
that beats were repeated inter-personally too needs to be              Interactive gestures. Discourse Processes, 15, 469-489.
interpreted with caution, until it is replicated for different      Bavelas, J., Gerwing, J., Sutton, C., & Prevost, D. (2008).
beats and supported by observational studies.                          Gesturing on the telephone: Independent effects of
  One could argue that for some iconic character-viewpoint-            dialogue and visibility. Journal of Memory and
gestures, it does not make sense to gaze at the gesture and            Language, 58, 495-520.
therefore these gazed-at gestures are more likely repeated.         Beattie, G., & Shovelton, H. (1999a). Do iconic hand
For example, when climbing up a drainpipe, Sylvester may               gestures really contribute anything to the semantic
                                                                2649

  information conveyed by speech? An experimental.                Kopp, S., & Bergman, K. (2013). Automatic and strategic
  investigation. Semiotica, 123, 1-30.                              alignment of co-verbal gestures in dialogue. In I.
Beattie, G., & Shovelton, H. (1999b). Mapping the range of          Wachsmut & J. P. De Ruiter (Eds.), Alignment in
  information contained in the iconic hand gestures that            Communication: Towards a New Theory of
  accompany spontaneous speech. Journal of Language and             Communication. Amsterdam: John Benjamins Publishing
  Social Psychology, 18, 438-462.                                   Company.
Beattie, G., & Shovelton, H. (2002). An experimental              Landis, J. R., & Koch, G. G. (1977). The measurement of
  investigation of some properties of individual iconic             observer agreement for categorical data. Biometrics, 33,
  gestures that affect their communicative power. British           159-174.
  Journal of Psychology, 93(2), 179-192.                          McNeill, D. (1992). Hand and Mind: What gestures reveal
Beattie, G., Webster, K., & Ross, J. (2010). The fixation and       about thought. Chicago and London: The University of
  processing of the iconic gestures that accompany talk.            Chicago Press.
  Journal of Language and Social Psychology, 29(2), 194-          McNeill, D. (2005). Gesture and Thought. Chicago and
  213.                                                              London: University of Chicago Press.
Cassell, J., McNeill, D., & McCullough, K.-E. (1998).             Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2009). The
  Speech-gesture mismatches: Evidence for one underlying            communicative import of gestures: Evidence from a
  representation of linguistic & nonlinguistic information.         comparative analysis of human-human and human-
  Pragmatics & Cognition, 6(2), 1-33.                               machine interactions. Gesture, 9(1), 97-126.
Cheng, C. M., & Chartrand, T. L. (2003). Self-monitoring          Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2011).
  without awareness: Using mimicry as a nonconscious                Seeing and being seen: The effects on gesture production.
  affiliation strategy. Personality and Social Psychology,          Journal of Computer-Mediated Communication, 17(1),
  85(6), 1170-1179.                                                 77-100.
Clark, H. H., & Brennan, S. E. (1991). Grounding in               Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2012).
  communication. In L. B. Resnick, J. Levine & S. D.                Adaptation in gesture: Converging hands or converging
  Teasley (Eds.), Perspectives on socially shared cognition.        minds? Journal of Memory and Language, 66(1), 249-
  Washington, DC: APA.                                              264.
Goodwin, C. (1981). Conversational organization:                  Özyürek, A. (2002). Do speakers design their cospeech
  Interaction between speakers and hearers. New York:               gestures for their addressees? The effects of addressee
  Academic Press.                                                   location on representational gestures. Journal of Memory
Gullberg, M., & Holmqvist, K. (1999). Keeping an eye on             and Language, 46(4), 688-704.
  gestures: Visual perception of gestures in face-to-face         Parrill, F., & Kimbara, I. (2006). Seeing and hearing double:
  communication. Pragmatics & Cognition, 7, 35-63.                  The influence of mimicry in speech and gesture on
Gullberg, M., & Holmqvist, K. (2006). What speakers do              observers. Journal of Nonverbal Behavior, 30(4), 157-
  and what listeners look at. Visual attention to gestures in       166.
  human interaction live and on video. Pragmatics &               Pickering, M. J., & Garrod, S. (2004). Toward a mechanistic
  Cognition, 14, 53-82.                                             psychology of dialogue. Behavioral and Brain Sciences,
Gullberg, M., & Kita, S. (2009). Attention to speech-               27(2), 169-225.
  accompanying gestures: eye movements and information            Posner, M. I. (1988). Structures and functions of selective
  uptake. Journal of Nonverbal Behavior, 33(4), 251-277.            attention. In T. Boll & B. Bryant (Eds.), Master Lectures
Holler, J., & Wilkin, K. (2011). Co-speech gesture mimicry          in Clinical Neuropsychology. Waschington, DC: Am.
  in the process of collaborative referring during face-to-         Pshych. Assoc.
  face dialogue. Journal of Nonverbal Behavior, 35, 133-          Posner, M. I., & Petersen, S. E. (1990). The attention system
  153.                                                              of the human brain. Annual Review of Neuroscience, 13,
Jacobs, N., & Garnham, A. (2007). The role of                       25-42.
  conversational hand gestures in a narrative task. Journal       Streeck, J. (1993). Gesture as communication I: Its
  of Memory and Language, 56(2), 291-303.                           coordination with gaze and speech. Communication
Kendon, A. (1990). Conducting Interaction. Cambridge:               Monographs, 60, 275-229.
  Cambridge University Press.                                     Wang, Y., Newport, R., & Hamilton, A. F. (2011). Eye
Kendon, A. (2004). Gesture: Visible action as utterance.            contact enhances mimicry of intransitive hand
  Cambridge: Cambridge University Press.                            movements. Biol Lett, 7, 7-10.
Kimbara, I. (2006). On gestural mimicry. Gesture, 6(1), 39-       Wittenburg, P., Brugman, H., Russel, H., Klassmann, A., &
  61.                                                               Sloetjes, H. (2006). ELAN: a Professional Framework for
Kimbara, I. (2008). Gesture form convergence in joint               Multimodality Research. In Proceedings of the LREC
  description. Journal of Nonverbal Behavior, 32(2), 123-           2006, Fifth International Conference on Language
  131.                                                              Resources and Evaluation (pp. 1556-1559).
                                                              2650

