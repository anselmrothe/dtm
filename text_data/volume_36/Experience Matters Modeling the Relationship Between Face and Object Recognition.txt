UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Experience Matters: Modeling the Relationship Between Face and Object Recognition
Permalink
https://escholarship.org/uc/item/9jg5k71h
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Wang, Panqu
Gauthier, Isabel
Cottrell, Garrison
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Experience Matters: Modeling the Relationship Between Face and Object
                                                              Recognition
                                                   Panqu Wang (pawang@ucsd.edu)
                       Department of Electrical and Computer Engineering, University of California San Diego
                                              9500 Gilman Dr 0407, La Jolla, CA 92093 USA
                                         Isabel Gauthier (isabel.gauthier@vanderbilt.edu)
                                             Department of Psychology, Vanderbilt University
                                                 301 Wilson Hall, Nashville, TN 37240 USA
                                                   Garrison Cottrell (gary@ucsd.edu)
                        Department of Computer Science and Engineering, University of California San Diego
                                              9500 Gilman Dr 0404, La Jolla, CA 92093 USA
                               Abstract                                 2011), and even on novel objects when subjects are suffi-
   Some research has suggested that face and object recognition         ciently trained in the lab ( “Greeble” experts, (Gauthier, Tarr,
   are independent abilities. Recently, however, it has been shown      Anderson, Skudlarski, & Gore, 1999)). Single-cell record-
   that they are not, and that the relationship is moderated by ex-     ings in macaque show highly face-selective cell patches, but it
   perience with the object categories (Gauthier et al., in press).
   Gauthier et al. suggest that a domain general ability under-         is unknown whether the macaques had expertise in any other
   lies face and object recognition that is expressed when people       category (Tsao, Freiwald, Tootell, & Livingstone, 2006).
   have sufficient experience in that category. Using the Cam-          However, McGugin, Gatenby, Gore, and Gauthier (2012) re-
   bridge Face Memory Test (CFMT) and Vanderbilt Expertise
   Test (VET), they showed that as experience with non-face ob-         ported a linear correlation between behavioral car expertise
   ject categories grows (averaged over all eight categories of the     and a reliable response to cars in the FFA using HR-fMRI,
   VET), the shared variance between the CFMT and VET perfor-           and suggest experience with a category may be sufficient to
   mance increased monotonically. This theory fits with our neu-
   rocomputational model (“The Model”, TM, Cottrell and Hsiao           create this activation.
   (2011)), since in TM, categories differentiated at the subordi-         Recently there has been more focus on individual differ-
   nate level are recruited by the face network (Tong, Joyce, &         ences in face and object recognition and the relationship be-
   Cottrell, 2008). We model “domain general ability” as the re-
   sources available for the mapping from images to labels (the         tween them. The development of the Cambridge Face Mem-
   number of hidden units), and “experience” as the number of           ory Test (CFMT) (Duchaine & Nakayama, 2006) has pro-
   training epochs with non-face objects. We show that, as in the       vided a valid and reliable measure of these differences in
   data, the shared variance between the performance on faces
   and the performance on subordinate-level object categoriza-          the normal population. In a study on the heritability of face
   tion increases as experience grows. Our results thus suggest         recognition, Wilmer et al. (2010) assessed the independence
   that a potential source for the variance in the “domain general      of face recognition by measuring the correlation between the
   ability” between individuals is the amount of representational
   resources available for fine-level discrimination. One might         CFMT and a similar test about abstract art, and found the
   have expected that faces and objects compete for this shared         correlation is low (less than 0.26). Similarly, Dennett et al.
   resource, leading to a negative correlation between them. Our        (2011) designed the Cambridge Car Memory Test (CCMT),
   analysis of the hidden unit representations shows that they
   share a “spreading” transform, that moves similar objects apart      and found it only accounted for 13.6% of the shared variance
   in representational space, consistent with our previous analy-       in CFMT.
   ses suggesting that this is why the the Fusiform Face Area is           The results above suggest that face recognition is indepen-
   recruited by new categories of expertise (Tong et al., 2008).
   Keywords: face recognition; neural network; individual dif-
                                                                        dent from non-face object recognition. However, Gauthier
   ferences; Fusiform Face Area (FFA); object recognition.              et al. (in press) challenged this idea, arguing that there is a
                                                                        domain-general visual ability, v, for discriminating visually
                          Introduction                                  similar objects that underlies face and non-face object recog-
Extensive progress has been made in discovering how com-                nition, and that this ability is only expressed in full within a
plex objects, particularly human faces, are processed by the            category when people have sufficient experience, E, in that
visual cortex. At the same time, there is no consensus                  category. I.e., Abilitycat = v ∗ Ecat . In order to test this hy-
on whether face and non-face object recognition are per-                pothesis, they performed the following experiment: From
formed independently. Some fMRI studies of the Fusiform                 256 subjects, they collected three measures. First, the sub-
Face Area (FFA) suggest there is a domain-specific response             jects took the CFMT to obtain a measure of their ability with
to faces compared to other object categories in that region             faces. The CFMT involves studying 6 target faces, and then
(Kanwisher, McDermott, & Chun, 1997), while other studies               discriminating them from other faces. The catch is that at
show that the FFA also responds to non-face objects of exper-           test time, the target faces and the distractor faces are in dif-
tise, such as cars, birds (Gauthier, Skudlarski, Gore, & Ander-         ferent lighting, pose, or both, from the study faces. This is
son, 2000), chessboards (Bilalić, Langner, Ulrich, & Grodd,
                                                                    1754

followed by a second study phase, and then a discrimination              Finally, we analyze the hidden unit activations, and show
test where the targets and distractors are embedded in Gaus-         that the effect of experience is to populate a larger region of
sian noise. Second, the subjects took the Vanderbilt Expertise       representational space - that is, to spread the representation of
Test (VET; McGugin, Richler, Herzmann, Speegle, and Gau-             individual objects out. This is the same phenomenon that we
thier (2012)), a test structured to be similar in format to the      have demonstrated in our model of how the FFA is recruited
CFMT, but using 8 non-face object categories. This test gives        for other tasks Tong et al. (2008).
a measure of their abilities with objects (O-PERF). Finally,             In the next section, we provide a detailed description of
they collected self-ratings from the subjects of their experi-       how we use TM to simulate the experiment in Gauthier et al.
ence with the 8 categories, on a scale from 1 to 9 (O-EXP).          (in press). The result section will present our findings and
   According to their hypothesis, if there is a common ability       analysis of the hidden unit activations. We conclude with a
v that is expressed through experience, then their performance       discussion.
on the VET should be more correlated with their performance
on the CFMT as their experience with the object categories                                     Methods
grows. Hence they divided their subjects into six levels of          Model Architecture
experience, based on their standard deviation from the mean          The version of TM we use is shown in Figure 1. TM’s struc-
experience (see Figure 2, bottom row). Then for each experi-         ture is layered from low-level visual features to high-level ob-
ence group, they regressed the CFMT score against the VET            ject categories. The first layer is a Gabor filter layer (five
score. They showed that, as predicted, as experience grows,          scales, eight orientations) that models the response of com-
the shared variance between the CFMT and VET increased               plex cells in V1 (Daugman, 1985). In the second layer, we
monotonically. When subjects have considerable experience            perform Principal Component Analysis (PCA) on the Gabor
with objects, if they perform well (poorly) with faces, they         filter responses to reduce the dimensionality. PCA can be im-
will also perform well (poorly) on non-face objects.                 plemented using Hebbian learning (Sanger, 1989), and simu-
   Our model of face processing (“The Model” (TM); Dailey            lates the structural encoding level beyond primary visual cor-
and Cottrell (1999); Cottrell and Hsiao (2011)) fits well with       tex, up to the lateral occipital region level. The third layer
this hypothesis, because in TM, as more subordinate-level ex-        is a hidden layer in the neural network that learns feature
perience is gained with a category, the face processing net-         representations in the service of the task. If the task is face
work is recruited for the category. Hence any resources in the       recognition, the hidden layer will develop representations for
face processing network are shared with expert object pro-           faces adaptively over training, and we assume that the hidden
cessing. TM has been successfully used to simulate percep-           layer corresponds to the FFA. The last layer is a categoriza-
tual phenomena such as facial expression perception (Dailey,         tion layer, which controls the level of discrimination between
Cottrell, Padgett, & Adolphs, 2002), the recruitment of FFA          different stimuli, and provides labels for them to perform the
for other categories of expertise (Tong et al., 2008), and the       final object recognition task. The last two layers are fully
development of hemispheric lateralization of face processing         connected, and are trained using online backpropagation.
(P. Wang & Cottrell, 2013).
   The basic structure is similar to the expert network de-
scribed in Tong et al. (2008), where a two-layer error-driven
artificial neural network is trained after preprocessing the im-
ages with Gabor filters and PCA. We map the domain general
ability, (v), to the number of hidden units in TM, and expe-
rience, (E), to the number of training epochs when we train
on a non-face object category. We train on faces first to sim-
ulate the abilities expressed by the scores on the CFMT, and
then on non-face objects to simulate the abilities tested by
the VET. We apply our model to four different object cate-
gories: faces, butterflies, cars and leaves. We show that, as in
Gauthier et al.’s data, the shared variance between the perfor-
mance on faces and the average performance on non-face ob-
jects increases as experience with the non-face objects grows.
   In addition, we make a prediction. Gauthier et al. did not
observe the correlation between scores on the VET and on the
CFMT at the level of experience with one particular category,                         Figure 1: Model Architecture
but instead, of overall experience with all eight categories.
Here we demonstrate that this correlation with experience on         Dataset and Preprocessing
one category can be observed in our computational model,             We used four categories of objects in our studies: faces, but-
given sufficient training data.                                      terflies, cars and leaves. As there is no single dataset that
                                                                     contains sufficient images for all these four expert categories,
                                                                 1755

we collected the images from four different datasets: 1) faces:       with the second category.
NimStim Face Stimulus Set (Tottenham et al., 2009); 2) but-
terflies: Leeds Butterfly Dataset (J. Wang, Markert, & Ever-                          Experiments and Analysis
ingham, 2009); 3) cars: Multi-View Car Dataset (Ozuysal,              Experiment 1: Modeling Gauthier et al. (in press)
Lepetit, & Fua, 2009); 4) leaves: One-hundred Plant Species
                                                                      We first modeled the psychological experiment in Gauthier et
Leaves data Set (Mallah, Cope, & Orwell, in press). For each
                                                                      al. (in press), described above. In the experiment, they ob-
category, we randomly selected 16 images each from 10 indi-
                                                                      tained the CFMT performance, VET performance (O-PERF),
viduals to form the training set (12 images per individual) and
                                                                      and self-rating experience scores (from 1-9, O-EXP) on each
test set (4 images per individual). We transformed each image
                                                                      category for each of the 256 human subjects. According to
to grayscale first and cropped them to 64 × 64 pixels. The Ga-
                                                                      the average O-EXP scores across the eight categories of the
bor filtering stage consists of passing the image through the
                                                                      VET, Gauthier et al. divided the subjects into 6 groups based
classical Gabor filter bank (Lades et al., 1993) with 5 differ-
                                                                      on their standard deviation from the mean (see the legend to
ent scales and 8 orientations ranging from 0 to 7π/8. We then
                                                                      Figure 2). In each group, they performed a regression on the
computed the Gabor magnitude, subsampled these vectors to
                                                                      subjects’ CFMT scores against their object performance (O-
an 8 × 8 grid, and normalized the response across orienta-
                                                                      PERF), and computed the correlation between them. They
tions for each scale. The Gabor filtering process resulted in a
                                                                      found that as O-EXP increases, the shared variance between
2560-dimensional vector to represent a single image. In order
                                                                      CFMT and O-PERF increases monotonically from 6.2×10−6
to extract a small number of features to represent the image
                                                                      to 0.59. This result indicated that people with considerable
efficiently and separate the response from each scale of the
                                                                      experience on VET object categories show a high correla-
Gabor filter, PCA is performed separately on each spatial fre-
                                                                      tion between their performance with face and non-face ob-
quency component in the vectors (bandpass PCA). We kept
                                                                      jects. Figure 2(a) shows their result. The bottom of the Figure
the eight most significant eigenvectors for each scale, thus
                                                                      shows which level of (self-reported) experience the subjects
obtaining a 40-dimensional vector to represent each image
                                                                      in that panel had with the VET objects.
prior to training the neural network.
                                                                         To model these results, we make a one-to-one mapping be-
Model Subjects Initialization and Training                            tween each subject and a network. Since, according to Gau-
                                                                      thier et al.’s hypothesis, their score on the CFMT represents
There are two key variables in the psychological experiment
                                                                      the expression of their v (because it is assumed that all sub-
performed by Gauthier et al. (in press): the hypothesized do-
                                                                      jects have high and relatively similar experience with faces),
main general visual ability, v, and the measured experience
                                                                      we use this score to decide each network’s representational
with a category, E. Here we assume that v corresponds to
                                                                      resources. Hence, for each human subject at each experience
representational resources for fine-level discrimination, and
                                                                      level, we initialize a network with a number of hidden units
hence we map visual ability (v) to the number of hidden units.
                                                                      based on their CFMT score. For each network subject snet ,
With more hidden units, the network is able to generate more
                                                                      we assign the number of hidden units from its corresponding
accurate (higher dimensional) features for a given object cat-
                                                                      human subject shum according to the following formula:
egory, thus achieving better performance. Second, we map
experience (E) to the number of training epochs on non-face
                                                                               Nhidden (snet ) =    f loor(8 ×CFMT (shum )),
object categories. To model the experiment, we make these
two variables a function of the data from the 256 human sub-          where CFMT (s) represents the fraction of correct responses
jects (see below), with one network per subject.                      for the given subject shum . The CFMT scores range from
   We first train each network on subordinate-level face              0.4722 to 1, so the hidden unit numbers range from 3 to 8.
recognition, as this is the first kind of expertise for most          The number “8” in the formula above was chosen arbitrarily,
humans. We then train the network on an object class,                 but 10 (for example) gives similar results.
subordinate-level classification of butterflies, cars, or leaves.        Similarly, we mapped the self-rated experience (O-EXP) to
Hence an extra set of output nodes are added for the sec-             a number of training epochs for objects as follows:
ond task, and error backpropagated from them will change
the hidden unit representation. For Experiment 1, below, this                       Nepoch (snet ) = 10 × O-EXP(shum )
is performed three times for each network starting with the
same weights learned on faces (i.e., we “xerox” the network           O-EXP ranges from 1 to 9, so our training epochs range from
and run three experiments on it). The test set accuracy after         10 to 90. Note that while O-EXP is a noisy measure of ex-
training, averaged across the three tasks, is our model of their      perience (being based on self-report), here we are converting
score on the VET. Note that we continue training on faces             this to an exact measurement.
during the second task in order to avoid interference between            Stochastic gradient descent (online-backprop) is used to
the tasks. This is reasonable given that humans are nearly al-        perform the network training. We set the learning rate to
ways exposed to faces every day. In the second experiment,            0.015 and momentum term to 0.01 in all experiments. All
we perform the same kind of analysis, but using only one ob-          weights between input layer to hidden layer, and hidden layer
ject category, and varied training times, to simulate expertise       to output layer were set randomly between 0 and 1. As noted
                                                                  1756

Figure 2: Gauthier at al. results and model results. Subjects are divided into groups according to their self-reported experience
with the VET categories (O-EXP) (bottom row). For example, the first column (top row) shows the data from subjects whose
O-EXP scores fell below 1.5 standard deviations (SD) from the mean. The top row shows the regressions for each group of
their CFMT scores against their VET scores. The second row shows the results of our simulation. Each point in our graphs
corresponds to a single network whose parameters (v and E) are set based on one of the subjects in the graph above them.
above, the training begins with faces. The stopping crite-            iment we use a much larger number of “subjects” and ability
ria for face training is either when the training error is be-        levels. Theoretically, we should see the same result as with
low 0.005 (determined by cross-validation), or the number             the averaged category experience.
of training epochs hits 200. Hence, either the network be-               As there is no psychological data corresponding to this ex-
comes an expert at faces and stops training, or it receives 200       periment, we created the initialization of the networks’ v and
passes through the training set if it can’t reach that error cri-     E manually: 1) we map v to a range of hidden unit numbers,
terium. Then training is continued on an object category for          Nhidden ∈ {1, 2, 3, 5, 6, 8, 12, 16, 20, 24, 28, 32} and 2) we map
Nepochs (snet ). As noted above, this is repeated three times for     E to a set of number of training epochs for non-face objects
each network, once for each category, and the results aver-           Nepoch ∈ {1, 5, 10, 20, 40, 60}. Instead of having 256 subjects
aged across the three networks. At the end of training, we            in Experiment 1, we created 800 samples for each of the three
measured the recognition rate for face and non-face objects           non-face categories in this experiment, and then assigned the
for all 256 network subjects and calculated the shared vari-          number of samples at each level of E and v according to a
ance between the performance on faces and averaged perfor-            Gaussian distribution, which is used to simulate the fact more
mance on non-faces. The result is shown in Figure 2(b).               people should have intermediate level of E and v. The train-
   From Figure 2(b), we can clearly see that as experience            ing procedure is exactly the same as Experiment 1, except
(O-EXP) grows, the correlation between the recognition per-           that we computed the correlation based on the performance
formance on faces and the average non-face scores increases           on faces and a single non-face category.
monotonically from 0.057 to 0.698, which matches the result              The results are shown in Figure 3. As can be seen from
from Gauthier et al. (Figure 2(a)) qualitatively. This result         the figure, as experience grows, the correlation between the
suggests our mapping for E and v to the network are reason-           performance on faces and the performance on all three non-
able, and the potential source for the variance in the “domain        face categories increases monotonically, regardless of what
general ability” between individuals is the amount of repre-          the object category is. We performed the experiment multi-
sentational resources (hidden units in the neural network).           ple times and the result is stable. This result proves that our
                                                                      intuition is correct: sufficient data is a critical issue in observ-
Experiment 2: Correlation with One Category                           ing the experience moderation effect. One phenomena worth
One issue with the Gauthier et al. experiment is that the cor-        mentioning is the moderation differs for each category at the
relation was only found when experience across all categories         end point (last column of Figure 3). For example, the R2 ends
of the VET was combined. The same results did not obtain              at 0.683 for the car category but ends at 0.307 for the but-
when the analysis was restricted to a single category. This is        terfly category. The end point distinction indicates the varied
also true of our results in Experiment 1 (data not shown for          difficulties of different tasks.
lack of space). This is a serious problem if our goal is to show
that face recognition is not independent of any non-face ob-          Internal Representation Given the results above, we may
ject category. We believe that this lack of correlation could         wonder how the experience moderation effect occurs during
be the result of too small a sample size. Hence in this exper-        training. Given that the two processes are competing for the
                                                                  1757

                                                                     Figure 4: Visualization of hidden unit activations. The figure
                                                                     shows how the representational space of the hidden units (the
                                                                     second and third principal components of the activations) de-
                                                                     velops over network training. We take samples from epochs
Figure 3: Experiment result (single category) of shared vari-        1 and 200 of face training (first and second column), epoch 1
ance (R2 ) between performance of face and non-face expert           of car training (third column). The remaining column shows
(butterflies, cars and leaves) as a function of experience. The      the difference between an experience level of 5 epochs of
data points are shown as colored dots in each subplot.               car training (top row) and 200 epochs of car training (bot-
                                                                     tom row). Colored dots correspond to different subordinate
same resources, one might expect the correlation between             categories - in the left two columns, the colors correspond
them to be negative. On the other hand, if the resource was          to individuals, in the right two columns, they correspond to
split in half, then it makes sense that more resources for one       individual car models.
task means more resources for the other. The evidence that it
is neither of these possibilities is based on the analysis used      improving the recognition rate.
in Tong et al. (2008). They demonstrated that the hidden                For an untrained non-face object category, the performance
unit representation formed during subordinate-level training         must be low, regardless of how many hidden units there are,
generalizes to new categories. That is, there is a “spreading        so the correlation is low. With more training, performance
transform” that separates similar-looking items on the hid-          improves and become more dependent on the representational
den layer, and this transform generalizes to new examples.           resources, leading to the shared variance increasing. By vi-
To demonstrate this, we visualize the development of internal        sualizing the development of internal representation, we can
representation by applying PCA to the hidden unit activations        see how experience moderates face and object recognition.
of the training data over learning, and plotting the second and         At the same time, we can observe that in the third column,
third principal components (PCs) on a two-dimensional sub-           even without training on cars, the projections are already sep-
space (the first principal component just represents the mag-        arated to some extent, especially compared to the first col-
nitude of the activations, which reflects the growth in the          umn, where the network has just start training on faces. As
weights).                                                            in our previous work Tong et al. (2008), this shows that the
   The results of this analysis with the car category are shown      spreading transform learned for faces generalizes to new cat-
in Figure 4. The plot clearly illustrates how experience con-        egories. This is an important characteristic of a subordinate-
tributes in the discrimination task. For faces, the data points      level classifier.
for each individual become separated after training (left two
columns). For cars, more experience also leads to more sep-                                   Conclusion
aration (fourth column). This inter-class separation is not          We showed that by instantiating the theoretical concept of a
only observed visually, but also statistically. The average          shared resource, v, as the number of hidden units in our net-
between-class distance (measured using Euclidean distance            work, we could replicate the moderation of experience on the
between the center of each cluster in the right-hand column)         relationship between face and object recognition. Experience
is 8.448 for the network trained for 200 epochs (bottom row)         allows the network to express this resource in performance
and 6.405 for the network trained for five epochs (top row).         on the second task. We also used TM to predict that the same
This indicates that more experience leads to more separation         phenomena will be observed at the individual category level,
between individuals. In addition, the within-class distance          given sufficient training data. Finally, analysis of the develop-
(measured using Euclidean distance between each data point           ing internal representation shows how experience moderates
belonging to a single individual to the average of that individ-     the visual ability and recognition performance.
ual’s locations) in the network trained for 200 epochs is 2.849,        One potential critique of this work is that the CFMT and
much lower than the value 8.496 for the network trained for          the VET are memory tests, and we use the recognition rate
5 epochs (top row). This suggests more experience also gen-          of unseen data to model this. However, we believe that if the
erates a more condensed and accurate data distribution, thus         recognition rate is high, the internal representation is well-
                                                                 1758

developed for the task. In a memory test, this would lead to          area increases with expertise in recognizing novel objects.
better representations in memory as well. In future work, we          Nature Neuroscience, 2, 568–573.
intend to evaluate this idea more directly by using the models’     Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The
internal representations in an exemplar-based memory model.           fusiform face area: a module in human extrastriate cortex
                                                                      specialized for face perception. Journal of Neuroscience,
                    Acknowledgments                                   17, 4302–4311.
This work was supported by NSF grant SMA 1041755 to                 Lades, M., Vorbrggen, J., Buhmann, J., Lange, J., Malsburg,
the Temporal Dynamics of Learning Center, an NSF Sci-                 C. von der, Wrtz, R. P., et al. (1993). Distortion invariant
ence of Learning Center (GWC and IG), VVRC (Grant P30-                object recognition in the dynamic link architecture. Com-
EY008126) (IG) and NEI (Grant R01 EY013441-06A2) (IG).                puters, IEEE Transactions on, 42(3), 300–311.
We thank Benjamin Cipollini and Akinyinka Omigbodun for             Mallah, C., Cope, J., & Orwell, J. (in press). Plant leaf clas-
discussions on this work, and the rest of Gary’s Unbelievable         sification using probabilistic integration of shape, texture
Research Unit (GURU) for their comments.                              and margin features. Signal Processing, Pattern Recogni-
                                                                      tion and Applications.
                          References                                McGugin, R. W., Gatenby, C. J., Gore, J. C., & Gauthier, I.
                                                                      (2012). High-resolution imaging of expertise reveals reli-
Bilalić, M., Langner, R., Ulrich, R., & Grodd, W. (2011).            able object selectivity in the ffa related to perceptual perfor-
  Many faces of expertise: fusiform face area in chess experts        mance. Proceedings of the National Academy of Sciences,
  and novices. Journal of Neuroscience, 31(28), 10206–                109(42), 17063–17068.
  10214.                                                            McGugin, R. W., Richler, J. J., Herzmann, G., Speegle, M.,
Cottrell, G. W., & Hsiao, J. H. (2011). Neurocomputational            & Gauthier, I. (2012). The vanderbilt expertise test reveals
  models of face processing. In A. J. Calder, G. Rhodes,              domain-general and domain-specific sex effects in object
  M. Johnson, & J. Haxby (Eds.), The Oxford Handbook of               recognition. Vision Research, 69, 10–22.
  Face Perception. Oxford, UK: Oxford University Press.             Ozuysal, M., Lepetit, V., & Fua, P. (2009, June). Pose esti-
Dailey, M. N., & Cottrell, G. W. (1999). Organization of face         mation for category specific multiview object localization.
  and object recognition in modular neural network models.            In Conference on computer vision and pattern recognition.
  Neural Networks, 12, 1053–1073.                                     Miami, FL.
Dailey, M. N., Cottrell, G. W., Padgett, C., & Adolphs, R.          Sanger, T. D. (1989). Optimal unsupervised learning in
  (2002). EMPATH: A neural network that categorizes fa-               a single-layer linear feedforward neural network. Neural
  cial expressions. Journal of Cognitive Neuroscience, 14(8),         Network, 2, 459–473.
  1158–1173.                                                        Tong, M. H., Joyce, C. A., & Cottrell, G. W. (2008). Why
Daugman, J. G. (1985). Uncertainty relation for resolution in         is the fusiform face area recruited for novel categories of
  space, spatial frequency, and orientation optimized by two-         expertise? A neurocomputational investigation. Brain Re-
  dimensional visual cortex filters. Journal of the Optical           search, 1202, 14–24.
  Society of America, 2, 1160–1169.                                 Tottenham, N., Tanaka, J. W., Leon, A. C., McCarry, T.,
Dennett, H. W., McKone, E., Tavashmi, R., Hall, A., Pid-              Nurse, M., Hare, T. A., et al. (2009). The nimstim set
  cock, M., Edwards, M., et al. (2011). The cambridge car             of facial expressions: Judgments from untrained research
  memory test: A task matched in format to the cambridge              participants. Psychiatry Research, 168(3), 242–249.
  face memory test, with norms, reliability, sex differences,       Tsao, D. Y., Freiwald, W. A., Tootell, R. B., & Livingstone,
  dissociations from face memory, and expertise effects. Be-          M. S. (2006). A cortical region consisting entirely of face-
  havior Research Methods, 44(2), 587–605.                            selective cells. Science, 311, 670–674.
Duchaine, B., & Nakayama, K. (2006). The cambridge face             Wang, J., Markert, K., & Everingham, M. (2009). Learn-
  memory test: results for neurologically intact individuals          ing models for object recognition from natural language
  and an investigation of its validity using inverted face stim-      descriptions. In Proceedings of the british machine vision
  uli and prosopagnosic subjects. Neuropsychologia, 44(4),            conference.
  576–585.                                                          Wang, P., & Cottrell, G. W. (2013). A computational model
Gauthier, I., McGugin, R. W., Richler, J. J., Herzmann, G.,           of the development of hemispheric asymmetry of face pro-
  Speegle, M., & Gulick, A. E. V. (in press). Experience              cessing. In Proceedings of the 35th annual conference of
  moderates overlap between object and face recognition,              the cognitive science society. Austin, TX: Cognitive Sci-
  suggesting a common ability. Journal of Vision.                     ence Society.
Gauthier, I., Skudlarski, P., Gore, J. C., & Anderson, A. W.        Wilmer, J. B., Germineb, L., Chabrisc, C. F., Chatterjeeb, G.,
  (2000). Expertise for cars and birds recruits brain areas           Williamsd, M., Lokene, E., et al. (2010). Human face
  involved in face recognition. Nature Neuroscience, 3(2),            recognition ability is specific and highly heritable. Pro-
  191–197.                                                            ceedings of the National Academy of Sciences, 107(11),
Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P., &         5238–5241.
  Gore, J. C. (1999). Activation of the middle fusiform face
                                                                1759

