UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Autonomous Movement Predicts Children’s Moral Regard and Prosocial Behavior Towards a
Social Robot Dog

Permalink
https://escholarship.org/uc/item/7q40n776

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Chernyak, Nadia
Gary, Heather

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Autonomous Movement Predicts Children’s Moral Regard and Prosocial Behavior
Towards a Social Robot Dog
Nadia Chernyak (nc98@cornell.edu)
Human Development, Cornell University
Ithaca, NY 14853 USA

Heather E. Gary (heg38@uw.edu)
Department of Psychology, University of Washington – Seattle
Seattle, WA 98195 USA
Abstract
Young children are remarkably prosocial towards
humans. However, it is less clear what drives children’s
prosociality towards non-human others. Here we explore the
possibility that children’s moral regard stems from their
understanding of others as autonomous beings. To
investigate this possibility, we asked five and seven-yearold children to interact with a robot dog that appeared to be
either moving autonomously (displaying self-generated
movement), or appeared remote-controlled by the
experimenter. Compared with controlled robot, the
autonomous robot caused children to ascribe higher
emotional and physical sentience to the robot, to reference
the robot as having desires and physiological states, and to
reference moral concerns as applying to the robot. Children
who owned a dog at home were also more likely to behave
prosocially towards the autonomous robot. Results imply a
potential role of technology on children’s developing social
cognition and prosocial behavior.
Keywords: human-robot interaction, autonomous movement,
preschoolers, prosocial behavior, moral cognition

Introduction
“It’s a machine, Schroeder. It doesn’t get pissed off, it
doesn’t get happy, it doesn’t get sad, it doesn’t laugh at
your jokes…” – Short Circuit, 1986
At the crux of the movie Short Circuit, lay the
philosophical dilemma of whether a robot, Number 5,
should be saved from disassembly. Some felt that No.5 had
displayed emotional sophistication proving it worthy of
moral regard, while others felt that No.5 was merely a tool,
no more worthy of being helped than a stereo or a vacuum
cleaner.
Although such philosophical dilemmas are most
dramatically portrayed in movies, determining who and
what is worthy of our moral regard is a critical cognitive
achievement.
In present day, young children are
increasingly bombarded with interactive social technologies
(e.g., Furbys, iPads, Roomba vacuum cleaners) that are
designed to interact with humans in a range of life-like
ways, some of which include the ability to move around

autonomously (Kahn, Gary, & Shen, 2013). Due to their
relative historical novelty, the manner in which such
technologies are presented to young children is
understudied. As such, little is known about how presenting
technology to young children impacts their conceptions of
and regard for it. In this work, we explore how a brief fiveminute interaction with an either autonomously moving or
controlled robot impacted children’s beliefs in the robot as a
sentient being, endorsement of the robot as having moral
standing, and prosocial behavior towards the robot.
Our research question motivated by two concerns. First,
we wished to understand the developing link between our
moral cognition and our understanding of others as sentient
beings (see Gray, Gray, & Wegner, 2007 and Sytsma &
Machery, 2012 for demonstrations of this link with adults).
Robots share similarities to agents across a wide array of
features. A large body of literature has found that even in
infancy, children make social evaluations of entities based
on such features, including eyes (Hamlin, Wynn, & Bloom,
2007), contingent interaction (Beier & Carey, 2014;
Johnson, Slaughter, & Carey, 1998), and goal-directed
movement (e.g., see Gergely & Csibra, 2003; Heider &
Simmel, 1944; Saxe, Tenenbaum, & Carey, 2005;
Woodward, Sommerville, Gerson, Henderson, & Buresch,
2009; see also Gao, McCarthy, & Scholl, 2010 for a
demonstration with adults). In fact, many of these studies
arguably employ social robots (e.g., Beier & Carey, 2014).
Interactive technologies present a unique problem as they
often display all of these cues, and yet, at least by adults, are
not considered to be sentient beings worthy of our moral
regard. Therefore, a second possibility is that higher order
concerns, such as whether an entity is “alive,” sentient, or
autonomous, plays into children’s moral regard for it.
Second, we wished to disambiguate prior work examining
children’s conception of social robots. On the one hand,
when prompted to interact with and talk about social robots,
children have been known to show a domain-confusion, and
fail to conceptualize robots neatly as the artifacts they are or
the living beings they emulate (Crick & Scasselatti, 2010;
Kahn et al., 2012; Kahn, Friedman, Perez-Granados, &
Freier, 2006). Such work has largely focused on children’s
ability to form relationships with, and thus conceive of
robots as moral and social beings. On the other hand, when
asked forced-choice questions about robots’ basic biological

2032

and psychological properties, children appear to understand
that robots lack in such properties, and thus separate robots
from prototypically “living” entities such as degus or
starfish (Jipson & Gelman, 2007).
One possibility for the seemingly disparate results may
therefore concern the difference between behavioral,
explanatory, and forced-choice responses (see Wellman,
2011). Another possibility is that children may understand
robots as non-living, but nonetheless be unable to inhibit
their moral regard for them. After all, children have been
shown to be prosocial even towards animal puppets (e.g.,
Aknin, Hamlin, & Dunn, 2012; Chernyak & Kushnir, 2013;
Vaish, Missana, & Tomasello, 2011). Finally, a third
possibility, and one that we were most interested in
exploring, is that the manner in which robots are presented
to young children can have important consequences for how
they are conceptualized. In an important demonstration,
Somanader, Saylor, and Levin (2011) showed that
preschool-aged children ascribed biological capacities to
robots, but not when the mechanism controlling the robots
(i.e., remote control) was made apparent (see also Gelman
& Gottfried, 2008). Here, we use a similar manipulation to
examine children’s understanding of robots across a broad
battery of questions (forced choice, explanatory, and
behavioral).
In this study, we asked two groups of children: those who
had not yet entered formal schooling (5-year-olds) and those
who had (7-year-olds), to interact with a social robot that
appeared to move in one of two ways: either in a controlled
manner (via a remote control held by the experimenter) or
autonomously (with no remote present). We chose these age
groups on the basis of prior work, which has found that the
ages of 4-7 are associated with changes in children’s
perceptions of robots (Bernstein & Crowley, 2008) and
children’s abilities to share fairly (Smith, Blake, & Harris,
2013).
We expected that children would be more likely to view
the autonomous robot as sentient and worthy of moral
regard, despite the fact that the surface behaviors of the
robots were identical across conditions. To test this
prediction, we introduced children to the robot and then
assessed their beliefs about three dimensions related to
moral regard: (1) Emotional and Physical Sentience, (2)
Moral Standing, and (3) Prosocial Behavior. Dimensions (1)
and (2) were assessed through both forced-choice and
explanatory responses; dimension (3) was assessed through
behavioral responses.

Method
All children were interviewed individually in a quiet corner
at a summer camp.

Participants
Participants were eighty children (40 5-year-olds; M =
5.50, SD = .30; and 40 7-year-olds; M = 7.35, SD = .36;
50% female), recruited from a local summer camp.

Introduction
Because we reasoned that children’s understanding of
robotic others may depend on their prior experience, all
children were asked whether they had a real dog at home.

Interaction
All children then took part in a 5-minute interaction with
a robot dog, AIBO. Children were first introduced to the
robot dog (“I want to introduce you to AIBO”) by being
shown the robot, and informed that they will be playing
with it. All children then watched AIBO engage in 12
separate behaviors (programmed to proceed in a randomized
order): waking up, sitting down, kicking a ball, head-butting
a ball, moving its head around, walking, making sounds,
whistling, shaking its head no, giving a paw, and waving
hello.

Manipulation
Forty-one children (“Autonomous movement” condition)
heard the experimenter narrate AIBO’s behavior in a way
that was consistent with autonomous movement (e.g,
“AIBO is kicking the ball.”) The other half (39 children;
“Controlled movement”) saw AIBO engage in identical
behaviors, but the experimenter appeared to be remotelycontrolling the robot via a video-game controller and
narrated AIBO’s behavior in a way that was consistent with
experimenter-generated movement (“I made AIBO kick the
ball.”). There were equal distributions of age groups and
genders in each condition.

Dependent Measures
We inquired about three dimensions related to children’s
moral regard: (1) Emotional and Physical Sentience; (2)
Moral Standing; and (3) Prosocial Behavior. Questions were
adapted
from
prior
work
assessing
children’s
conceptualization of robotic others (Jipson & Gelman, 2007;
Kahn, Friedman, Perez-Granados, & Freier, 2006; Kahn et
al., 2012), moral reasoning (Smetana, 1983), and prosocial
behavior (Chernyak & Kushnir, 2013). The questions and
coding scheme is described below and can be accessed here.
Emotional and Physical Sentience The forced choice
questions included questions about AIBO’s capacity to feel
physiological sensations (“If you tickle AIBO, can AIBO
feel it?”), physical and emotional pain (“If AIBO fell on the
ground, could he get hurt?”; “If someone was mean to
AIBO, could AIBO get upset?”), and neglect (“Is it OK or
not OK to leave AIBO in a closet for a week?”). We
additionally included a categorization question in which we
asked whether AIBO was more similar to an agent (a real
dog) or an artifact (a stuffed dog).
We also assessed emotional and physical sentience using
explanatory responses. For each question above, children
were asked to explain their choice (e.g., “Why/why not?”),
thus resulting in 5 explanatory responses. In addition, each
child was prompted for a Behavioral Cause Explanation:

2033

AIBO always performed one unexpected behavior (not
getting a tennis ball after the experimenter rolled it past
AIBO. The experimenter narrated the behavior (“Uh oh!
AIBO isn’t getting the tennis ball!”) and prompted the child
for an explanation (“Why did that happen?”). Thus, children
provided 6 total explanatory answers regarding their beliefs
about emotional and physical sentience; coding is described
in the Coding section below.
Moral Standing We asked children two forced choice
questions, namely whether the inhibition of two behaviors –
yelling at and hitting AIBO – was independent of authority
mandates (see Smetana, 1983; Turiel, 1983). Because
testing was conducted at a summer camp, we used a camp
counselor as the authority figure (“Is it OK to hit AIBO if
your counselor says it’s OK?”).
After each item, children were also prompted for an
explanatory response.
Prosocial Behavior Finally, we gave children the ability to
engage in two prosocial behaviors towards AIBO – a Costly
Behavior (giving AIBO a sticker or keeping it for
themselves), and a Noncostly Behavior (playing with AIBO
and a tennis ball vs. leaving the ball for another child).

Coding
Emotional and Physical Sentience: Forced Choice For
each item, answers were coded as 1 if the child’s answer
was consistent with AIBO having a sentient capacity (e.g.,
AIBO could feel being tickled; AIBO is more like a real dog
than a stuffed dog), and 0 otherwise (see Table 1). Answers
were summed such that each child received an Emotional
and Physical Sentience Forced Choice Score (0-5).
Emotional and Physical Sentience: Explanatory
Responses Each explanation was coded as either (a)
reference to desires and emotions (e.g., “AIBO doesn’t like
that”; “he’ll get so sad”); (b) reference to physiological
states (e.g., “he’s tired”; “he might starve or poop”), (c)
references to mental states (e.g., “AIBO doesn’t know
where the ball is”), (d) references to mechanical properties
(e.g, “he has batteries”; “he can’t feel anything because he’s
just a robot”; “he’s made of metal”), and (e) uncategorizable
responses (e.g., “I don’t know”). Answers for each category
type were summed across the 6 explanatory questions such
that each child received five scores indicating the number of
times the child provided each explanation type across the 6
questions: References to Desires and Mental States Score
(0-6), References to Physiological States Score (0-6),
References to Mental States (0-6), References to
Mechanical Properties Score (0-6), and Uncategorizable
Responses (0-6).
Moral Standing – Forced Choice Each answer was coded
as 1 if the child indicated that it was not OK to harm AIBO
even if the authority figure stated it was OK, and 0

otherwise. Answers were summed such that each child
received a Moral Standing Forced Choice Score (0-2).
Moral Standing – Explanatory Responses Each answer
was coded into one of the following categories: (a)
references to moral concern (indications of moral rules: “it
wouldn’t be fair” and references to harm: “it would make
AIBO sad”), (b) references to external consequences (e.g.,
“you would get in trouble”; “it might break”), or (c)
uncategorizable responses. Answers for each category type
were summed across the 2 explanatory questions such that
each child received three scores indicating the number of
times the child provided each explanation type across the
two questions: References to Moral Concern Score (0-2),
References to External Consequences Score (0-2), and
Uncategorizable Response Score (0-2).
Prosocial Behavior Behaviors were given a score of “1” if
the child engaged in the prosocial behavior towards AIBO
(e.g., gave AIBO the sticker or ball), and “0” if s/he did not.
Behaviors were summed such that each child received a
Prosocial Behavior Score (0-2).

Results
To investigate whether condition or age impacted
children’s moral regard, we ran a Condition
(autonomous/controlled) x Age Group (five-yearolds/seven-year-olds) ANOVA on each of the dependent
variables.
For explanatory assessments, a repeatedmeasures ANOVA was used with Explanation Type entered
as a within-subjects dependent variable.
We also explored for potential effects of gender and
experience with real dogs. For each model, we added the
factors Gender (male/female) and Experience with Real
Dogs (yes/no) separately, and removed each one if it was
non-significant (p > .05). Unless otherwise stated, no effects
for these variables were found.

Emotional and Physical Sentience
Our first question was whether children would be more
likely to ascribe emotional and physical sentience to the
robot dog when it was moving in a controlled manner.
Forced Choice Questions There was a significant effect of
Condition Type, F(1, 69) = 4.29, p < .05, and no other
significant effects. Therefore, children in the autonomous
condition ascribed higher emotional and physical sentience
(M = 4.11, SD =.14) to the robot than those in the controlled
condition (M = 3.61, SD = .20).
Explanatory Responses There was a significant main
effect of Age Group, F(1, 76) = 14.49, p < .001, and
Explanation Type, F(4, 73) = 104.32, p < .001.
Additionally, there was a significant Condition x
Explanation Type interaction, F(4, 73) = 3.14, p < .05, and
Age Group x Explanation Type interaction, F(4, 73) = 6.65,

2034

p < .001. Thus, the frequency of each explanation type
differed across conditions and ages.
Of critical interest was whether explanation types differed
between conditions. Planned t-tests were conducted to
assess differences in explanation type scores across
conditions (Figure 1). Children in the autonomous condition
had higher References to Desires and Emotional States
Scores than those in the controlled condition, t(78) = 1.96, p
= .05, as well as higher References to Physiological States
Scores, t(78) = 2.51, p < .05. In contrast, children in the
controlled condition had higher References to Mechanical
Properties Scores, t(78) = -2.71, p < .01. There were no
condition differences in the number of References to Mental
State Scores and Uncategorizable Responses Scores.

Explanatory Responses There was a significant main
effect of Explanation Type, F(2, 75) = 8.35, p < .01, a
significant Condition x Explanation Type interaction, F(2,
75) = 6.04, p < .01, and no other significant effects.
Planned t-tests were conducted to assess differences in
explanation type scores across conditions (Figure 2).
Children in the autonomous condition had higher
References to Moral Concern Scores than those in the
controlled condition, t(78) = 3.49, p < .001. There were no
condition differences in the number of References to
External Consequences and Uncategorizable Responses.

Figure 2: Means (bars represent standard errors) for Number
of Explanation Types Across Conditions for the Moral
Standing Explanatory Responses
Therefore, although most children in both conditions
indicated that it was not OK to harm the robot, children in
the autonomous condition were more likely to cite moral
reasons for their decisions.
Figure 1: Means (bars represent standard errors) for Number
of Explanation Types Across Conditions for the Emotional
and Physical Sentience Explanatory Responses
Therefore, as indicated through both forced choice and
explanatory responses, children ascribed higher physical
and emotional sentience as well as endorsed the robot as
having desires, emotions, and basic physiological properties
when the robot was autonomous.

Prosocial Behavior
Finally, our last question was whether children would be
more likely to behave prosocially towards a controlled robot
(Figure 3).

Moral Standing
Our next question concerned whether children would be
more likely to endorse moral standing for an autonomously
moving robot dog.
Forced Choice Responses There were no significant effects
of condition, age, or condition x age interaction for
children’s moral regard scores, all p’s > .05. A follow-up
analysis revealed that this was due to a ceiling effect – the
majority of children (54 of 77) had a Moral Standing Score
of 2, indicating that they believed that neither behavior
(yelling or hitting) was appropriate towards AIBO even if
an authority figure stated it was okay.

Figure 3: Means (bars represent standard errors) Across
Condition Type and Real Dog Experience Groups for
Prosocial Behavior Score
There was a significant Condition Type x Experience with
Real Dogs interaction in Prosocial Behavior scores, F(1, 71)

2035

= 4.57, p < .05, and no other significant effects. Follow-up
comparisons showed that children who owned a real dog
showed differentiation in their prosocial behavior between
conditions. That is, children in the autonomous condition
had higher Prosocial Behavior Scores, t(34) = 2.35, p < .05.
In contrast, children who did not own a real dog showed no
condition differences.
Comparisons of each of the four groups to chance levels
showed that only children who had experience with dog and
were in the autonomous condition had Prosocial Behavior
scores that were significantly above the midpoint, t(14) =
3.23, p < .01 (all other p’s > .20). Therefore, experience
with real dogs coupled with autonomous movement caused
increased prosocial behavior towards a robotic dog.

Discussion
Across a large battery of questions including forced
choice responses, explanatory responses, and behavioral
responses, we show that children’s moral regard for a robot
depended on evidence of the robots’ autonomous,
uncontrolled movement. Our findings join literature
suggesting that our perceptions and attributions of others
depend on our beliefs in their autonomy (Gray et al., 2007;
Somanader et al., 2011; Sytsma & Machery, 2012). We
extend this work by showing that cues to autonomous
movement also impact our beliefs about physical and
emotional sentience, moral standing, and prosociality, and
that these links appear relatively early in development. This
finding is important given the recent work on interactive
social robots (Bernstein & Crowley, 2007; Scaife & Van
Duuren, 1995) as well as work suggesting that even infants
make social evaluations about non-human others (e.g.,
shapes with eyes; Hamlin, Wynn, & Bloom, 2008). Based
on our findings, we suggest that the manner in which nonhuman others are presented to young children
fundamentally impacts children’s evaluations of and
behavior towards them.
Our dependent measures were drawn from four
theoretically distinct literatures: work on children’s
conceptual development, human-robot interaction, moral
cognition, and prosocial behavior. As such, we hope to paint
a broader understanding of how to tap into children’s
understanding of sentience and moral regard. For example,
we found that children rigidly endorsed harming others as
being wrong independent of authority mandates, a finding
that is well aligned with prior work (Turiel, 1983). At the
same time, children’s explanatory responses and behaviors
showed variation between children and between conditions.
It is important to note that we provided several cues to
autonomy: a lack of external cause (i.e., no remote control)
and experimenter testimony (i.e., “I’m making AIBO
move”). Prior work has found that the presence of a remote
control may be sufficient in causing preschoolers’
differentiation between autonomous and non-autonomous
others with respect to ascription of biological and
representational properties (Somanader et al., 2011), and

further work may disambiguate which specific features of
autonomy cause moral regard.
We also found experience-driven changes in children’s
discrimination between autonomous and controlled robots.
Children showed increased prosocial behavior towards an
autonomous robot only when they had previous experience
with a real dog. Prior work (see Inagaki & Hatano, 2002)
has found that the experience of raising goldfish caused
children to ascribe more biological properties to the goldfish
(e.g., having a heart). Here, children’s experience with an
agent (a pet dog) caused a greater prosocial behavior
towards autonomous robots, suggesting that experience with
animal agents may cause a greater understanding of how
agents do and do not differ from artifacts capable of
movement. We also found that even a five-minute
interaction with an autonomous robot caused children to
categorize and evaluate the robot in a different manner.
Two further questions are interesting to consider for
future inquiry regarding children’s early-emerging
prosociality. It may be interesting to consider whether with
age, children may increase their social obligation towards
robotic others, or alternatively: whether children selectively
target their behavior to exclude non-agentic others. The
latter possibility is consistent with findings suggesting that
young children target their behaviors selectively towards ingroup members (Dunham, Baron, & Carey, 2011), and
believe that others will do the same (DeJesus, Rhodes, &
Kinzler, in press; Weller & Lagattuta, 2012). Further work
may also investigate whether autonomous movement serves
as a cue for in-group status, moral obligation, or potential to
reciprocate.
These findings are interesting to consider with respect to
children’s beliefs about causal essences of animals and
artifacts (see Gelman, 2009; Gelman & Wellman, 1991;
Sobel, Yoachim, Gopnik, Meltzoff, & Blumenthal, 2007).
Prior work has found that children believe that the insides of
artifacts and animals reflected the object or animal’s “true”
or “essential” identity. Here we also find that although the
robot in both conditions displayed the same exact perceptual
properties and surface movements, children nonetheless
paid attention to the causal source of the robot’s movement.
We propose that rather than paying attention to surface
properties of technology, children are able to reason about
the causal movements and essences.
We believe our work paves the way to consider the
emerging role of non-human others in our daily lives –
whether in educational settings, childcare centers, or in our
own homes – as well as how apparent autonomy drives our
understanding of and behavior towards others more
generally.

Acknowledgments
We would like to thank Lauren Gary for assistance with
data collection and coding, Jessica Sommerville for helpful
comments, and Peter Kahn for kindly lending equipment.

2036

References
Beier, J. S., & Carey, S. (2014). Contingency is not enough:
Social context guides third-party attributions of
intentional agency. Developmental Psychology, 50, 889902.
Bernstein, D., & Crowley, K. (2008). Searching for signs of
intelligent life: An investigation of young children’s
beliefs about robot intelligence. The Journal of the
Learning Sciences, 17, 225-247.
Chernyak, N., & Kushnir, T. (2013). Giving preschoolers
choice increases prosocial behavior. Psychological
Science, 24, 1971-1979.
Crick, C., & Scasselatti, B. (2010). Controlling a robot with
intention derived from motion. Cognitive Science, 2, 114126.
DeJesus, J. M., Rhodes, M., & Kinzler, K. D. (2014).
Evaluations versus expectations: Children's divergent
beliefs about resource distribution. Cognitive Science, 38,
178-193.
Dunham, Y., Baron, A. S., & Carey, S. (2011).
Consequences of “minimal” group affiliations in children.
Child Development, 82, 793–811.
Dunfield, K. A., & Kuhlmeier, V. A. (2010). Intentionmediated selective helping in infancy. Psychological
Science, 21, 523-527.
Gao, T., McCarthy, G., & Scholl, B. J. (2010). The
wolfpack effect perception of animacy irresistibly
influences interactive behavior. Psychological Science,
21, 1845-1853.
Gelman, S. A. (2009). The Essential Child: Origins of
Essentialism in Everyday Thought. Oxford University
Press: New York, NY.
Gelman, S. A., & Wellman, H. M. (1991). Insides and
essences: Early understandings of the non-obvious.
Cognition, 38, 213-244.
Gergely, G., & Csibra, G. (2003). Teleological reasoning in
infancy: The naıve theory of rational action. Trends in
Cognitive Sciences, 7, 287-292.
Gray, H. M., Gray, K., & Wegner, D. M. (2007).
Dimensions of mind perception. Science, 315, 619-619.
Hamlin, J. K., Wynn, K., & Bloom, P. (2007). Social
evaluation by preverbal infants. Nature, 450, 557-559.
Heider, F., & Simmel, M. (1944). An experimental study of
apparent behavior. The American Journal of Psychology,
57, 243-259.
Inagaki, K. & Hatano, G. (2002) Young Children’s Naïve
Thinking about the Biological World. New York:
Psychology Press.
Jipson J. L., & Gelman S. A. (2007). Robots and rodents:
children’s inferences about living and nonliving kinds.
Child Development, 78, 1675-1688.
Johnson, S., Slaughter, V., & Carey, S. (1998). Whose gaze
will infants follow? The elicitation of gaze­‐following in
12­‐month­‐olds. Developmental Science, 1, 233-238.
Kahn, P. H., Jr. (2011). Technological Nature: Adaptation
and the Future of Human Life. Cambridge, MA: MIT
Press.

Kahn, P. H., Jr., Friedman, B., Perez-Granados, D. N., &
Freier, N. G. (2006). Robotic pets in the lives of preschool
children. Interaction Studies, 7, 405-436.
Kahn, P. H., Gary, H. E., & Shen, S. (2013). Children’s
social relationships with current and near-future robots.
Child Development Perspectives, 7, 32–37.
Kahn, P. H., Kanda, T., Ishiguro, H., Freier, N. G.,
Severson, R. L., Gill, B. T., Ruckert, J. H., & Shen, S.
(2012). “Robovie, you'll have to go into the closet now”:
Children's social and moral relationships with a humanoid
robot. Developmental Psychology, 48, 303-314.
Kahn, P. H., Saunders, C. D., Severson, R. L., Myers, O. E.,
& Gill, B. T. (2008). Moral and fearful affiliations with
the animal world: Children’s conceptions of bats.
Anthrozoos: A Multidisciplinary Journal of The
Interactions of People & Animals, 21, 375–386.
Kellert, S. (1996). The value of life. Washington, DC: Island
Press.
Meltzoff, A. N. (1995). Understanding the intentions of
others: re-enactment of intended acts by 18-month-old
children. Developmental Psychology, 31, 838-850.
Turiel, E. (1983). The Development of Social Knowledge:
Morality and Convention. Cambridge University Press.
Scaife, M., & Van Duuren, M. (1995). Do computers have
brains? What children believe about intelligent artifacts.
British Journal of Developmental Psychology, 13, 367–
377.
Schmidt, M. F., & Sommerville, J. A. (2012). Fairness
expectations and altruistic sharing in 15-month-old human
infants. PLoS One, 6, e23223.
Smith, C. E., Blake, P. R., & Harris, P. L. (2013). I should
but I won’t: Why young children endorse norms of fair
sharing but do not follow them. PLoS ONE, 8, e59510.
Sobel, D. M., Yoachim, C. M., Gopnik, A., Meltzoff, A. N.,
& Blumenthal, E. J. (2007). The blicket within:
Preschoolers' inferences about insides and causes. Journal
of Cognition and Development, 8, 159-182.
Somanader, M. C., Saylor, M. M., & Levin, D. T. (2011).
Remote control and children’s understanding of robots.
Journal of Experimental Child Psychology, 109, 239–247.
Sytsma, J., & Machery, E. (2012). The two sources of moral
standing. Review of Philosophy and Psychology, 3, 303324.
Warneken, F., & Tomasello, M. (2006). Altruistic helping in
human infants and young chimpanzees. Science, 311,
1301–1303.
Weller, D., & Lagattuta, K. (2012). Helping the in­‐group
feels better: Children’s judgments and emotion
attributions in response to prosocial dilemmas. Child
Development, 84, 253-268.
Woodward, A. L., Sommerville, J. A., Gerson, S.,
Henderson, A. M., & Buresh, J. (2009). The emergence of
intention attribution in infancy. Psychology of Learning
and Motivation, 51, 187-222.

2037

