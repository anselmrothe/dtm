UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bayesian Updating: A Framework for Understanding Medical Decision Making

Permalink
https://escholarship.org/uc/item/66x8k702

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Robbins, Talia
Hemmer, Pernille
Tang, Yubei

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Bayesian Updating: A Framework for Understanding Medical Decision Making
Talia Robbins (talia.robbins@rutgers.edu)
Pernille Hemmer (pernille.hemmer@rutgers.edu)
Yubei Tang (yubei.tang@rutgers.edu)
Department of Psychology, Rutgers University, New Brunswick
152 Frelinghuysen Road, Piscataway, NJ 08854
Abstract
Beliefs are a fundamental component of our daily decisions,
and as such, beliefs about our health have a huge impact on
our health behaviors. Poor medication adherence is a welldocumented problem and while it has been extensively
researched, it has yet to be addressed using a Bayesian
framework. This study aims to use a mixture model to
understand belief updating as it affects decision making.
Using an established experimental paradigm in categorical
perception, we test memory and prediction in order to
establish a model that can explain human belief updating.
Results indicate that a mixture model provides a good
explanation of participant behavior in this paradigm.
Keywords: Belief Updating; Decision making; Bayesian
Models.

Introduction
Our beliefs influence the way we navigate the world at all
times. If these beliefs are misaligned with reality, our
behaviors will be maladaptive. Some of our most important
beliefs are those about our health; indeed, medication
adherence, which is a significant hurdle for the public health
community, is thought to be affected by factors associated
with patient beliefs (Horne & Weinman, 1999). Doctors
continuously struggle with why patients do not follow their
medication schedules despite the negative consequences.
According to the American Heart Association, within
seven days of a heart attack, 24% of patients will not have
filled their prescription. Of those who do begin their
medication regimen, 34% will have stopped one prescribed
medication and 12% will have stopped all three prescribed
medications within a single month. Lastly, 60% of patients
will be completely non-adherent to their prescribed
medication after two years (Ho, Bryson, & Rumsfeld,
2009). The consequences of non-adherence in this case are
life threatening; patients who do not fill any of their
prescriptions have an 80% higher mortality rate within 120
days than those who do take their medication as instructed
(Baroletti and Dell’Orfano, 2013).
Many investigations have proposed explanations for
patients’ failure to take their medication. Patients have cited
forgetfulness (30%), other priorities (16%), lack of
information, (9%) and emotional factors (7%) as reasons for
failing to take their medication as prescribed (Ostenberg &
Blaschke, 2005). The non-adherence of patients has been
suggested to fit into six distinct categories: those who (1)

do not understand how adherence relates to their well-being;
(2) believe the costs of the medication outweigh the
benefits; (3) find the regimen too complex; (4) are not
vigilant; (5) hold inaccurate beliefs about medications; and
(6) do not perceive the medication to be effective (Marcum,
Sevick & Handler, 2013). Yet, no clear understanding of
these underlying components exists, and physicians have
argued that a model is necessary in order to tackle such a
complex problem (Vermeire, Hearnshaw, Royen, &
Denekens, 2001).
While such previous research suggests that people make
medication choices irrationally, Bayesian models of
cognition (a.k.a. rational models) present another way to
understand medical decision making. In light of this, we
propose a rational model that accounts for and makes
predictions about why people would behave in this way.
The rational approach suggests that improving medication
adherence is partly a problem of whether people are
updating their beliefs about themselves optimally. If
someone believes that they are a generally well person, they
will have to update their beliefs in the face of evidence
suggesting otherwise (e.g. a heart attack). After a heart
attack, there may be necessary lifestyle changes (e.g.
medication, exercise, and dieting), but without updating
their beliefs, people may fail to make the necessary changes.
Assuming that people do Bayesian inference in their head,
Bayes’ rule gives a principled account of how people should
update their beliefs in light of new evidence:
!!!!!!!!!!!!!!!!!!!! ! ! ∝ ! ! ! !(!)

Eq (1)

The posterior probability p(B|E) gives the probability of
the belief B given the observed evidence E. This posterior
probability is based on a combination of p(B), which is the
prior probability (or strength) of the belief, and p(E|B),
which is the likelihood of observing the current evidence
given the belief. After observing the evidence E, p(B|E)
becomes the new belief p(B) in the next iterative time step.
This approach is useful because it characterizes the
computational problem people face when trying to make
sense of the world given evidence with varying degrees of
uncertainty.
Bayes' rule predicts a tradeoff between prior beliefs and
observed evidence. When our prior belief is strong and we
encounter weak evidence, our new belief will closely reflect
the prior. Conversely, in situations with a weak prior belief
and strong evidence, the new belief will closely reflect the
evidence. In situations where both the evidence and prior

1299

belief are strong, the new belief will lie somewhere in
between. It is, however, unclear what constitutes either a
strong prior belief or strong evidence in human updating of
beliefs from real-world experiences.
The way evidence from a negative health event is
integrated into our belief system is also important.
Information has been shown to decay at different rates based
on the source (Yang, Mohan, Mehrotra & Varshney, 2002).
Therefore, information from the body is treated differently
than information communicated from a doctor. If a person is
informed of a problem but cannot feel it, they may integrate
this information differently or the information might decay
more rapidly. Some information will not decay until new
evidence is present, and some will decay at an exponential
rate after it is presented. This decay function modifies a
traditionally static belief-updating model (P(B|E)) to a timedependent conditional probability such that P(B:tB|E:tE)
(Yang et al., 2002).
In a standard belief-updating model, the prior distribution
for a given belief should be combined with the data from the
environment to create a posterior distribution. Afterwards,
the posterior distribution should become the new belief.
However, human behavior suggests that beliefs are not
updated as efficiently as this model would suggest; for
example, after a negative health event, people appear to
maintain the belief that they are healthy (i.e. there is a lag in
updating of beliefs). Lag in updating occurs when evidence
accumulates before an update is prompted. In order for the
belief system to update, there must be a sufficient amount of
evidence, which may take several trials to accumulate
(Sanborn, Griffiths, & Navarro, 2010). Even after the belief
is updated, people appear to slowly return to the belief that
they are healthy, which can be considered a regression back
to a baseline belief. This occurs when beliefs are initially
updated after evidence, but slowly return to the initial prior.
These factors might be explained by the inclusion of
multiple prior distributions. Rather than just one belief that
updates to include new evidence, there might be two or
more: one that remains relatively static and others that
update with new evidence. This suggests that people make
choices based on a mixture of these two distributions.
In the case of medical decision making, people may have
two prior distributions: one baseline prior and one updated
prior that integrates negative health information (e.g. a heart
attack). This baseline prior likely integrates information
about our wellness throughout our lives—both when we
were sick and when we were not—which may leave us with
a general impression that illnesses tend to come and go.
When deciding whether to take medication, people are
making a prediction about their future wellness, and to do
this they must choose from which prior—their baseline prior
or their updated prior—to sample. This choice may be based
on the relative strength of the priors; while the new prior
may be relevant at the moment, the baseline prior may be
used for making predictions about their health. When
choosing a distribution for prediction, they will likely

choose the one with more accumulated evidence, which is
often the baseline prior. If people sample from the baseline
prior, they might be less likely to take their medication
because they believe that this illness, like previous ailments,
is likely to come and go.
The existence of multiple distributions is further
supported by evidence in the animal literature on
spontaneous recovery. Spontaneous recovery occurs in rats
when they are trained on a reward schedule for a long period
of time, then trained on a new reward schedule, and after a
break, regress to the initial schedule (Gleitman, 1971). If
they are reminded of the new schedule after this recovery,
they will switch to it much more rapidly than during initial
training. Memory theorists have argued that rats are storing
two separate distributions: one for reinforcement and one
for non-reinforcement, and that these two distributions
compete (e.g. Gleitman, 1971).
In the current study, we investigate how the strength and
duration of evidence influences belief updating, and explore
possible factors affecting optimal belief updating and future
prediction, including lag and regression to baseline beliefs.
We model this data within a simple rational model that
assumes that memory and prediction are integrated with
beliefs about the underlying environment. To this end, we
have constructed an experimental paradigm to simulate real
world belief updating. The paradigm is based on previous
research on categorical perception (Huttenlocher, Hedges,
and Duncan, 1991) in which the authors found a regression
to the mean effect in recall, as predicted by Bayes rule. This
effect suggests a trade-off between memory and
environmental evidence.

Experiment
It is not ideal to manipulate people’s beliefs about their
health in the real world; therefore, in this experiment we
used an artificial paradigm that manipulates the same
components. The experiment tested the model’s predictions
of how variation in prior beliefs should influence stimulus
estimation. In this task, participants were asked to record the
location of a dot in a circle and reconstruct that location
from memory. Dots were presented inside a circle one at a
time in clusters at different locations around the circle, and
participants were asked to remember where they saw each
dot. The task was chosen because it has been demonstrated
that participants are able to learn the underlying distribution
of dots, thereby making it an effective tool for studying
belief updating (Huttenlocher et al., 1991). Our task extends
the Huttenlocher paradigm by including prediction in
addition to recall. These prediction trials were meant to
assess participants’ beliefs about the future. We predicted a
regression to the mean effect similar to that of Huttenlocher
et al. (1991) and a prediction bias such that predictions
further in the future will be biased further away from the
current cluster mean and toward the overall distribution.

1300

Method
Participants were recruited from Rutgers University, New
Brunswick. There were eight participants in this study and
they were compensated with $10 for their participation,
which lasted approximately 30 minutes.

removed, an “X” appeared on the screen and participants
were asked to report the color of the square (black or white)
previously in that location. Data from the distractor task was
recorded but not analyzed. After the completion of the
distractor task, participants were asked to reconstruct the
location of the dot from memory by clicking a spot in the
circle.
After every three trials, participants were asked to make a
prediction about a future dot location. Prediction trials
alternated between prediction for the next trial and
prediction for five trials from now. Each block (defined as a
cluster of trials at one mean) was followed by a prediction
for the expected dot location 10 trials from the current trial.
This resulted in a total of 280 trials: 80 prediction trials and
200 recall trials.

Results

Figure 1: This circle illustrates the stimuli presented to
participants. The dots represent two clusters, with the
centermost cluster illustrating baseline training. Axes
were not visible during the study.

Recall

Procedure In this experiment, participants were asked to
record the location of a dot presented in a circle (see Figure
1) and reconstruct that location from memory. Participants
were given a cover story in order to keep the task engaging;
they were told that the circle was a garden and the dots were
moles. In order to save their garden, they had to “catch” the
moles by clicking on the locations where they saw them.
Baseline was established over a training period by
presenting sequences of dots near the center of the circle.
Belief updating was measured by presenting a single dot or
sequence of dots either close to or far from baseline. Three
manipulations on dot location and distribution were used to
assess updating in this task: variance, location (consisting of
a distance and angle measure), and number of trials. The
distances and angle measures were informed by
Huttenlocher et al. (1991). There were 24 angle measures
including the axes, and the measures consisted of the same
relative angles in each quadrant. Four different distances
measuring out from the center of the circle to the
circumference were chosen, and represented in each
quadrant. Dots were presented in blocks (3, 6, 9, or 12
presentations in a cluster), sampled from a multinomial
normal distribution with a mean of a given radius and one of
three variances (0.01, 0.04, and 0.06 in a unit circle) chosen
respectively to represent weak, average, and strong
evidences. All presentations at baseline were at the smallest
variance in order to strengthen baseline evidence. Each of
the relative angles had a different distance, variance, and
number of trials. The trial order was randomized, starting
with 20 dots presented at baseline.
Each dot was viewed for one second followed by a
combined visual mask and distractor task designed to
remove the dot from participants’ visual field and introduce
uncertainty in the memory process. This mask consisted of a
grid of black and white squares; after this mask was

Figure 2, panel a, shows the mean radial bias (recalled
minus studied dot location) as a function of the five radius
locations. The dashed black line shows the regression of
radial bias on study radius averaged across time steps in a
cluster. As expected, participant responses regressed
towards the mean radius such that dots studied at smaller
distances from the circle center were overestimated while
dots studied at the larger distances from the circle center
were underestimated. This replicates the findings of
Huttenlocher et al. (1991).
Figure 2, panel a, also shows the mean bias for each of
four time steps within a cluster—at trial 1, 3, 6, and 9. This
suggests that bias is reduced as the strength of evidence in a
cluster increases; that is, after only one trial in a given
cluster there was a greater regression to the overall mean,
whereas after nine trials in a cluster there was significantly
less regression to the overall mean location and accuracy
was closer to the true mean of the current cluster. This
suggests that participants were learning the underlying
distribution of the dot cluster. Initial regression towards the
overall mean also appeared to be less for cluster locations
below the overall mean. This might be a result of the initial
baseline training. In addition, regression lines were fit to
recall performance at each of the time steps (see Table 1).

1301

Table 1. Recall bias as a function of study radius and
trial number within a dot cluster
One
Trial

Three
Trials

Six
Trials

Nine
Trials

Slope

-.15

-.11

-.076

-.054

Intercept

.07

.06

.04

.03

Prediction

a)

recall bias (recall radius - study radius)

Figure 2, panel b, shows prediction bias relative to the mean
of the current cluster as a function of cluster length and
prediction type. For predictions of the dot location on the
next trial, participants showed little bias and predicted the
future dot location to be close to the mean of the current
cluster with some initial underestimation. Predictions for
locations five trials in the future also fell close to the current
cluster mean, but with some initial overestimation.
Predictions for locations ten trials in the future are the most
interesting because they give some indication that subjects
might hold multiple beliefs about the stimulus
environment—one for the current cluster and one for the
overall dot distribution. After studying a twelve-dot cluster,
participants appeared to make predictions away from the
one
three
six
nine
avg

0.06

0.02
0
-0.02

-0.06

0

b)

0.3
0.5
study radius

predictionmean
cluster
radius
prediction
- mean
block
radius

0.2

c)

0.7

Discussion

0.9

next trial
5 trials from now
10 trials from now

0.1

0

-0.1

-0.2

3

6
block length
cluster
length

0.2

predictionradius
prediction mean
- meancluster
block radius

mean of the current cluster; specifically, they predicted the
future dot location to be closer to the circle center, with a
systematic 10% underestimation. This suggests that
predictions for the next dot location were drawn from the
belief about the current state of the environment as
quantified by the mean location of the current cluster. For
predictions of dot locations further in the future, participants
no longer appeared to use their belief about the current dot
environment; rather, they appeared to be using a different
belief based on the overall stimulus distribution and biased
to the circle center. This suggests that the baseline
manipulation influenced the direction of bias in the overall
distribution.
Figure 2, panel c, shows prediction bias relative to the
mean of the current cluster as a function of study radius and
prediction type. Again, prediction for the next trial showed
less overall bias, prediction for 5 trials from now showed
incrementally more bias, and prediction for 10 trials from
now showed a strong regression to the mean of the overall
stimulus distribution. Predictions while studying dot
locations at a .7 and .9 radius resulted in a greater regression
effect, with predictions at .9 showing a systematic 25%
underestimation relative to the current cluster mean.

9

12

next trial
5 trials from now
10 trials from now

0.1

0

-0.1

-0.2

-0.3
0

0.2

0.4
0.6
study radius

0.8

1

Figure 2: Panel a shows recall bias as a function of study
radius and trial number within a dot cluster (either trial 1, 3,
6, or 9). Panel b shows prediction bias relative to the mean
of the current dot cluster as a function of cluster length and
prediction trial. Panel c shows prediction bias relative to the
mean of the current cluster as a function of study radius and
prediction type.

The results suggest that people incrementally update their
beliefs and that this incremental updating may be based on
multiple prior distributions—one about the overall
distribution, and one about the local cluster. As time
progresses, it seems participants assign progressively more
weight to the evidence from the local cluster. This evidence
motivates our use of a Bayesian framework, which should
give an accurate representation of the data.
In terms of health beliefs, these findings suggest that
when deciding whether or not to take medication, people
might be sampling from one of two distributions: a
distribution with the recent evidence (e.g. a negative health
event), and the overall distribution (e.g. their wellness over
their lifetime). For predictions in the near future, they may
believe they will still be sick, but for long-term predictions
they may not believe that they will still have the ailment.
This reliance on the overall distribution for future
predictions may be based on the strength of their beliefs. If
their baseline prior is stronger (i.e. has accumulated more
evidence), it makes sense that people would sample from it
when trying to predict their future health. If the prior based
on the more recent evidence were to become stronger than
the baseline prior, it is possible that the former would
replace the latter and be used for future predictions. Based
on these findings, we model the relationship between the
environment, recall, and prediction using a rational model.
Furthermore, because it appears that participants are using
multiple prior distributions, we utilize a mixture model to
simulate this relationship.

1302

Modeling
The strength of rational models is that they can be used to
characterize the computational problems people face when
trying to make sense of the world given the sparse and noisy
input from the senses. For example, an observer in our
experimental task is faced with recalling features θ of a
stimulus presented at study (i.e. locations of dots). Based on
our experimental design we will assume that these features
are Gaussian distributed, θ ~ N (µ, τ), where µ and τ are the
prior mean and precision of the dot locations. When a
specific dot location θ is studied, we assume this leads to
noisy representations y in episodic memory, where y ~ N (θ,
ψ). That is, the memory representation is centered on the
original studied dot location and is stored with some noise
ψ, where ψ expresses the resemblance of the stored
representation to the studied location. The goal of the
observer on a test trial is to recall the studied dot location θ
as best as possible using noisy samples y retrieved from
memory. Extending Equation 1 to the memory task, the
inference problem for the observer is p (θ| y, ψ, µ, τ). The
posterior probability p (θ| y, ψ, µ, τ) describes how likely dot
locations θ are given the noisy memory contents y and prior
beliefs about the dot locations. We assume that the observer
has a prior belief that corresponds to the observed stimulus
distribution in the experiment (i.e., the environmental
statistics). Furthermore, experimental results suggest that
observers hold multiple beliefs about the environment: one
for the local cluster, and one for the overall stimulus
distribution. This can be modeled with a mixture model
where the mean and precision (µ, τ) of beliefs are a
combination of overall and cluster specific beliefs,!! =
!!! + (1 − !)!! , and ! = !!! + (1 − !)!! , where (µc, τc)
represents the belief associated with cluster ! and (µo, τo)
represents the overall belief about the stimulus distribution
(Hemmer & Steyvers, 2009). The variable z weights the
contribution of the cluster belief relative to the overall

belief. This weighting is determined by !~!"#$%&'((!!! ),
where χi is a constant that represents the familiarity of a
cluster. In this way, familiar clusters lead to a belief that is
more dependent on the cluster rather than the overall
distribution. This implements the intuitive notion that for
unfamiliar clusters it is unlikely that the cluster belief is
reliable and inference instead reverts to a higher-level belief
based on the overall stimulus distribution.
Standard Bayesian techniques (Gelman, Carlin, Stern &
Rubin, 2003) can be used to calculate the mean of the
posterior distribution:
! = !" + (1 − !)!
2

2

Eq (2)

2

where w=(1/σ0 )/[(1/σ0 )+(n/σm )] and n is the number of
samples taken from episodic memory. In this way, recall can
be modeled as a weighted linear combination of beliefs and
memory content, where the strength of the prior belief and
episodic memory trades off as described in the introduction.
Here, the rational analysis is applied to the experiment
without directly estimating any parameters. Instead, it is
assumed that the observer has a belief that corresponds to a
mixture of the local and overall environmental statistics. On
the first time-step, the observer is assumed to have a belief
about the mean stimulus location that is biased towards the
overall distribution, but by the 9th time step to have a belief
that is identical to the local cluster’s environmental
distribution (only time steps 1, 3, 6 and 9 are simulated
here). Therefore, χ (i.e., familiarity with the local cluster)
was set to 0.6, 0.7, 0.8, and 1 for each of the four successive
times in a cluster modeled here to simulate an increasing
level of familiarity with the cluster environment. The mean
of the overall distribution !! was set to 0.5 for all radius
locations, except radius 0, where !! was set to 0.35 to
reflect the baseline training. The precision for the overall
distribution !! was set to the exact precision in the total set
of observed data, except for radius 0 which was always
observed at the smallest variance manipulation. The means

Figure 3: The graphs above show recall bias as a function of study radius at one, three, six, and nine time-steps, with the
top row showing participant performance and the bottom row showing model predictions.

1303

for the local clusters !! was set to the true radius locations,
and the precision !! was set to the mean precision for
clusters at each radius. Finally, the memory noise ψ was set
to 0.11.
The goal of this analysis is to compare the predictions of
the rational model and the empirical data at a qualitative
level. As seen in Figure 3, the model produces results that
are qualitatively consistent with the responses given by
human observers. It appears as though participants
incrementally change their beliefs with an increasing
number of time-steps within a cluster. Results show that
memory estimation errors can be explained by the use of
beliefs about the environment, since smaller radius distances
from the circle center were later recalled to be further away
and larger radius distances were later recalled to be closer.
Furthermore, beliefs change as a function of increasing
familiarity with the underlying local environment.
The observer in our task was also asked to make
predictions about future stimulus locations. The posterior
predictive distribution of future dot locations p(θfuture| θ) is
determined by averaging the predictive probability across all
possible values of beliefs weighted by the strength of the
belief. The mean of the posterior predictive distribution can
then be shown to be equal to the prior mean, with the
variance drawn from both the variance of the observed
stimulus and the uncertainty in the current belief. Therefore,
prediction for a future stimulus is centered on the mean of
the current belief. Yet, as demonstrated in the experimental
results, this only holds for short-term predictions; for longterm predictions, people appear to use a mixture of the
current belief about the cluster and the overall belief, similar
to that of recall. It is now trivial to extend the rational model
to assume long-term predictions to be a mixture of belief,
but that will be outside of the scope of the current paper.

General Discussion
A rational model that makes predictions about belief
updating based on different types of evidence has important
applications for public policy, and could help tailor
treatment strategies for patients encountering new illnesses
like cardiovascular disease. By understanding which
methods of updating beliefs are the most effective, doctors
might learn how to help patients integrate their illnesses into
their belief system. The results indicate that people hold
multiple beliefs that simultaneously effect decision making:
one about their current environment and one about the
overall environment.
The results above provide preliminary support for the
existence of multiple distributions in belief updating. It was
found that bias decreased as time steps in a cluster
increased, and that a mixture model provided a good
explanation of this pattern. The inclusion of multiple prior
distributions was further supported by results from the
prediction trials. For predictions for one trial in the future,
participants appeared to sample from the current cluster
mean, while for predictions for ten trials in the future they

appeared to sample from the overall distribution. This
provides support for the initial hypothesis that people
sample from multiple prior distributions when making
future predictions. While this experimental paradigm was
successful in simulating a real world belief-updating
scenario, in order to further our understanding of how
people make choices about their health this investigation
should be expanded into more realistic environments.

Acknowledgements
This work was supported by a Rutgers University Research
Council Grant Award.

References
Baroletti, S., & Dell'Orfano, H. (2010). Medication
adherence in cardiovascular disease. Journal of the
American Heart Association, 121, 1455-1458.
Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B.
(2003). Bayesian data analysis. Boca Raton, FL:
Chapman & Hall.
Gleitman, H. (1971). Forgetting of long-term memories in
animals. In W. K. Honig & P. H. R. James (Eds.), Animal
memory (pp. 1- 44). New York: Academic Press.
Hemmer, P., & Steyvers, M. (2009). A Bayesian Account of
Reconstructive Memory. Topics in Cognitive Science, 1,
189-202.
Ho, P. M., Bryson, C. L., & Rumsfeld, J. S. (2009).
Medication adherence: Its importance in cardiovascular
outcomes. Journal of the American Heart Association,
119, 3028-30353.
Horne, R., & Weinman J. (1999). Patients’ beliefs about
prescribed medicines and their role in adherence to
treatment in chronic physical illness. Journal of
Psychosomatic Research, 47, 555-567.
Huttenlocher, J., Hedges, L. V., & Duncan, S. (1991).
Categories and particulars: Prototype effects in estimating
spatial location. Psychological Review, 98, 352-376.
Marcum, Z. A., Sevick, M., & Handler, S. M. (2013).
Medication nonadherence: A diagnosable and treatable
medical condition. Journal of the American Medical
Association, 309, 2105- 2106.
Ostenberg, L., & Blaschke, T. (2005). Adherence to
medication. New England Journal of Medicine, 353, 487497.
Sanborn, A. N., Griffiths, T. L., & Navarro, D. J. (2010).
Rational approximations to rational models: Alternative
algorithms for category learning. Psychological Review,
117, 1154-1167.
Vermeire, E., Hearnshaw, H., Van Royen, P., Denekens, J.
(2001). Patient adherence to treatment: three decades of
research. A comprehensive review. Journal of Clinical
Pharmacy and Therapeutics, 26, 331-342.
Yang, J., Mohan, C. K., Mehrotra, K. J., & Varshney, P. K.
(2002). A tool for belief updating over time in bayesian
networks. Proceedings of the 14th IEEE International
Conference on Tools with Artificial Intelligence.

1304

