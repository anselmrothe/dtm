UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automated scoring of originality using semantic representations
Permalink
https://escholarship.org/uc/item/17t264nk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Harbinson, J. Isaiah
Haarman, Henk
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                 Automated scoring of originality using semantic representations
                                           J. Isaiah Harbison (iharbison@casl.umd.edu)
                 Center for Advanced Study of Language and Department of Psychology, University of Maryland
                                             7005 52nd Avenue, College Park, MD 27642 USA
                                          Henk Haarmann (hhaarmann@casl.umd.edu)
                                   Center for Advanced Study of Language, University of Maryland
                                             7005 52nd Avenue, College Park, MD 27642 USA
                               Abstract                                  participant’s responses could be used to predict that partici-
                                                                         pant’s flexibility, the number of responses categories included
   Originality, a key aspect of creativity, is difficult to measure.
   We tested the relationship between originality and similarity         in their output (Blok, Harbison, Haarmann, Bloodgood, &
   in two semantic spaces: latent semantic analysis (LSA) and            Berens, 2011). The current plan is to use the distance be-
   pointwise mutual information (PMI). Similarity in both spaces         tween the responses of all participants relative to a common
   was negatively correlated with human judgments of originality
   of responses on a test of divergent thinking. PMI was corre-          point of comparison as a measure of originality.
   lated more strongly both with human judgments of similarity              We will first discuss LSA and PMI and test their ability to
   and human judgments of originality. In particular, the average        account for human judgments of individual word similarity
   PMI between two phrases was found to be the strongest predic-
   tor of phrase similarity and originality, even performing better      and phrase similarity. LSA has a standard method for rep-
   than participants’ self assessments of their originality.             resenting phrases, but PMI does not. Therefore, we tested
   Keywords: creativity; originality; semantic spaces; PMI; LSA          three different methods of phrase representation with PMI.
                                                                         The final step was testing the spaces against the originality
                     Scoring Originality                                 data using similarity as the measure of originality.
Current methods of scoring creativity assessments have draw-
backs. Trained human raters, the gold standard for scoring                   Semantic Representations and Originality
creativity, require time for training, time to perform the scor-         For over a decade, methods of using the context of word
ing, and time for adjudication between raters. In addition,              use to create semantic representations have proved to be pre-
consistency between raters is often difficult to obtain due to           dictive of a variety of human intuitions concerning word
the inherent subjectivity of the task. Automated scoring pro-            meaning. Latent Semantic Analysis (LSA), the predominant
vides an alternative to human raters and can provide immedi-             method of generating these representations, has been success-
ate scores, potentially useful for giving participants feedback          fully applied to a wide variety of material: from predicting
and making it easier to incorporate creativity assessments in            human judgments of word similarity, to performing tests of
experiments. However, these methods are currently blind to               English as a second language, to scoring essays (Landauer,
the content of the response. Two such methods include Elab-              Laham, & Foltz, 2003).
oration, a count of the total number of words in a response,                Particularly relevant for the present context, LSA has also
and Fluency, the total number of responses. A participant                been applied to evaluating creativity. Wang, Chang, and Li
could score highly on these measures by making the same                  (2008) used LSA to grade responses to a creative problem
long response many times.                                                solving task. Similar to uses of LSA for grading essays, they
   The present research tests the potential of semantically in-          compared each response to several ideal responses to deter-
formed automated scoring methods, automated methods that                 mine if the essays contained the relevant concepts. Forster
are not blind to content but instead capture some aspect of hu-          and Dunbar (2009) used LSA to predict human judgments of
man judgment concerning similarity between responses. The                creativity on the Uses of Objects Task and found that LSA
goal is to develop a scoring method that captures human in-              similarity correlated at .60 with human judgments. Blok et
tuition but has the ability to provide instantaneous scoring             al. (2011) examined LSA’s ability to score a component of
for potential use as feedback to participants. To this end,              creativity, flexibility. Flexibility is how varied a participant’s
we tested the ability of two computational methods of rep-               responses are from each other. We tested multiple methods of
resenting semantic content, latent semantic analysis (LSA)               using the similarity of the participants’ responses as a mea-
and pointwise-mutual information (PMI), to score the origi-              sure of flexibility and found that the distance in the semantic
nality (or rarity) of responses on a creativity task. Both LSA           space did well predicting this aspect of creativity. The present
and PMI have proved successful in predicting human judg-                 work builds on that of Blok et al. (2011) by applying LSA to
ments of similarity and there is some evidence that similar-             another key component of creativity: originality.
ity could be used a measure of overall creativity (Forster &                In contrast to LSA, PMI has not yet been applied to cre-
Dunbar, 2009). Here we continue our examination of the po-               ativity data. However, it has shown promise, correlating more
tential of LSA and PMI to predict individual components of               strongly with human data than LSA due to its ability to make
creativity. Previously, we found that the distance between a             use of larger copora. Both LSA and PMI create summary
                                                                     2327

statistics based on word use, creating matrices that track how          not compared to each other, but instead the PMI between the
often words occur within a specific context. With LSA, the              two words is used. PMI is a measure of whether the joint
number of times each word occurs within each document of                probability of the co-occurrence of two words differs from
corpus is tracked. Within the resulting matrix, the number              what is expected by chance, with higher values of PMI in-
of words represented in the semantic space determines the               dicating greater than chance co-occurrence. Specifically, the
number of rows and the number of documents processed de-                PMI between words i and j is:
termines the number of columns. A new column is added
with each new document. Though the number of columns are                                                         p(i, j)
                                                                                               pmii, j = log2             .          (1)
reduced through singular value decomposition (SVD) after                                                        p(i)p( j)
the entire corpus has been processed, LSA places a relatively
large demand on computational resources in order to create its             In the present work, we followed the example of Recchia
word representations. In contrast, PMI uses a word-by-word              and Jones (2009) and used a modified version of the standard
matrix and the only words that need to be included are the tar-         PMI equation. Here the frequency of each word was used in
get words (i.e., the words that will be included in a compar-           place of its probability and the frequency of co-occurrence
ison). If there are 600 relevant words, then the PMI space is           was used for the joint probability. We also removed the log
a 600 by 600 matrix no matter the number of documents that              transformation, so the resulting equation was:
are processed. That is, the size of the word representations,
even during initial processing, are not a function of the num-                                              f req(i, j)
                                                                                             pmi∗i, j =                     .        (2)
ber of documents in the corpus. As a result, PMI can process                                            f req(i) f req( j)
much larger corpora than LSA and due to the use of larger
corpora, it is able to outperform LSA (Bidiu, REF; Recchia                  Similarity Judgments and Semantic Space
& Jones, 2009) despite being a much simpler algorithm. Here                                          Predictions
we test if PMI can outperform LSA when predicting original-             Before testing the semantic spaces against the originality
ity.                                                                    data, we tested their ability to predict human judgments of
   For both LSA and PMI, the choice of corpus and how a                 similarity for individual words and two-word phrases. This
document is defined within the corpus is very important. For            was done to assure that the spaces, particularly the PMI
the purpose of this comparison, we used the Touchstone Ap-              space—as the present LSA implementation has been thor-
plied Science Associates (TASA) corpus for LSA. The TASA                oughly tested—properly reflect the underlying similarity be-
corpus was created to represent the word exposure expected              tween words, making the subsequent test of the ability of dis-
of individuals between kindergarten and the first year of col-          similarity to predict originality a valid one. The phrase simi-
lege (Zeno, Ivens, Millard & Duvvuri, 1995) and has often               larity test is particularly important to PMI as it has not often
been successfully used by LSA. We used the implementa-                  been tested for its ability to represent phrases.
tion of LSA found at lsa.colorado.edu. For PMI we made
use of its ability to utilize larger corpora, using all articles of     Word Similarity
Wikipedia as of January 2011 as the corpus. We restricted
                                                                        As an initial comparison, we tested both LSA and PMI on
the number of words in the space to non-stop words (e.g.,
                                                                        their ability to predict the human judgments of word similar-
short function words) present in the datasets below. This was
                                                                        ity from the WAS353 dataset (Finkelstein et al., 2002). This
a total of 10,461 words which created a 10,461 by 10,461
                                                                        dataset consists of judgments of similarity of 353 different
matrix. We defined “document” as a paragraph within an ar-
                                                                        word pairs, such as “coast”-“hill” and “rooster”-“voyage”.
ticle. If a word appeared in the same paragraph as another
                                                                        Table 1 displays the Spearman rank correlations between the
word, their co-frequency would be incremented but not other-
                                                                        two semantic spaces and the human data. The new PMI
wise. This definition was slightly different from that of Rec-
                                                                        space, at a correlation of 0.72, performed equivalently to the
chia and Jones (2009), who also used Wikipedia as their cor-
                                                                        space created by Recchia and Jones (0.73; 2009) and better
pus. They defined blocks of 10 consecutive sentences as their
                                                                        than LSA at 0.60. This suggests that the difference in the
documents.
                                                                        specification of the document, from 10 sentences to single
Word Representations                                                    paragraphs, did not undermine PMIs ability to predict word
Words are represented within LSA as vectors, a row where the            similarity.
number of columns, originally the number of documents, is
reduced through SVD to a number of columns determined by
                                                                        Table 1: Correlation between semantic space word similarity
the individual creating the space. To determine the similarity
                                                                        and human judgment of word similarity.
of two words, the cosine between the two word vectors is
calculated.                                                                                   New PMI         Previous PMI    LSA
   For PMI, words are also represented as vectors, where the                     WS353        .72             .73             .60
number of columns is the total number of target words. How-
ever, to evaluate the similarity of two words, the vectors are
                                                                    2328

Phrase Representation and Phrase Similarity                                     from avePMI in its sensitivity to smaller PMI values. The
Phrases would appear to be a challenge for both semantic                        use of the product of the individual relationships has been
spaces as both spaces are created treating documents as bags                    successful when modeling retrieval when there is a contri-
of words, ignoring word order and even whether or not the                       bution from both episodic memory and semantic memory
words appear in the same sentence. Furthermore, both spaces                     (Kimball, Smith, & Kahana, 2007).
consist of representations of individual words, not larger units
of language, making it is necessary to combine the individual                   We tested these four methods of calculating phrase similar-
word representations to generate phrase representations. De-                 ity against data collected by Mitchell and Lapata (2010). The
spite this, LSA has been successful modeling larger language                 rationale was the same for testing the new semantic space
units with the centroid method described below. PMI has not                  against the WS353 data: before using method of represen-
been applied to phrase data as much, with the one exception                  tation to test to something novel, such as its ability to cap-
being in predicting information search behavior (Fu & Pirolli,               ture originality judgments, it should be tested on some known
2007). In the present study, we compared four such methods                   data to establish that the spaces well represent the underlying
of phrase representation.                                                    phrase similarity. Neither LSA nor PMI have been previously
1. LSA Centroid                                                              tested against this data.
   The centroid is the standard method for representing                         The phrase data consisted of the human rated similar-
   phrases with LSA. Each phrase is represented as a vector.                 ity of 324 phrase pairs provided by 204 participants. Each
   For example, two words in a space with n columns would                    phrase consisted of two words arranged into three phrase
   be represented as W1 = a1 , a2 , ..., an and W2 = b1 , b2 , ..., bn .     types: adjective-noun (e.g., public building-central author-
   The centroid of a phrase consisting of W1 and W2 would                    ity), compound nouns (e.g., study group-computer company),
   be represented as a1 + b1 , a2 + b2 , ..., an + bn . The same             and verb-object (e.g., pass time-cross line). There were high,
   method is used to represent paragraphs and even entire doc-               medium, and low similarity phrase pairs with 36 at each level.
   uments. To judge similarity, the cosine between the two                   Table 2 shows the results from the four methods tested as well
   phrases are taken, the same calculation that was used for                 as the best previous correlations with this data set (Blacoe &
   comparing words.                                                          Lapata, 2012).
2. PMI First Word (w1PMI)
   As there are no current standards for how to represent                    Table 2: Correlation between human judgment and auto-
   phrases with PMI, we tested three different methods. The                  mated methods of evaluating phrase similarity.
   first served as a lower baseline for PMI phrase representa-
   tion. It included only the first (non-stop) word from each
   phrase (w1PMI). Comparison against this single word rep-                    Phrase type       Adj-noun     Compound noun        Verb-object
   resentation method provides an indication of how much is                    LSA Centroid      .542         .648                 .441
   gained by attempting to represent an entire phrase within                   w1PMI             .516         .546                 .544
   PMI using the methods presented below. For example, if                      avePMI            .661         .695                 .545
   w1PMI does as well as the other methods, then nothing                       prodPMI           .291         .670                 .374
   was gained by using the phrase representations.                             Best Prior        .48          .50                  .35
3. Average Pairwise PMIs (avePMI)
   As mentioned above, PMI representations allow for the                        The similarity between phrases was significantly correlated
   comparison of individual words based on their relative                    with the human judgments of similarity for each method of
   probability of joint occurrence. One method of represent-                 representation. The avePMI representations had the strongest
   ing the relationship between two phrases is to take the av-               correlation with human data for all three types of phrases,
   erage of these relationships between the words of the two                 ranging from .545 to .695. Perhaps most surprising result was
   phrases (avePMI). That is, we summed over all pairwise                    how well the w1PMI representations performed. Simply us-
   comparisons between the words of the two phrases and di-                  ing the first word of each phrase to represent each phrase was
   vided by the number of comparisons. This measure reflects                 sufficient to outperform the best performing method tested by
   how related the words of the two phrases are on average.                  Balcoe and Lapata (2012) and to tie the best method tested in
   This is similar to how PMI is used to calculate information               the present study for the Verb-Object phrase type. The LSA
   scent, which is used to predict information search behavior               Centroid method, while performing worse than avePMI, con-
   (Fu & Pirolli, 2007).                                                     sistently performed better that the best prior results as well.
4. Average Product PMI (prodPMI)                                                Given the single word and phrase similarity results, we felt
   The last method tested here used a similar method to                      confident that the different methods capture some aspect of
   avePMI but instead of using the sum of all the pairwise                   human similarity judgments and can be used to test the ability
   word PMIs it used their product. This measure differed                    of similarity to predicting judgments of originality.
                                                                         2329

                     Scoring Originality                              of comparison with the mean external rating of each response.
 The originality data was taken from an experiment testing            With one exception (LSA for the cloth scenario using the sce-
 the potential of brain wave entrainment to improve divergent         nario point of comparison), all of the correlations were sig-
 thinking (Haarmann et al., 2011). The task consisted of a set        nificant (p¡.001). Note that for this and subsequent tables,
 of scenarios and instructions for participants to generate as        only significant correlations are shown. The largest correla-
 many responses as possible and as creative responses as pos-         tions with the external raters was with the avePMI method of
 sible. The scenarios examined here were:                             representing phrases using the common words point of com-
                                                                      parison (-.542 for the light scenario and -.392 for the cloth
1. A light in the darkness                                            scenario). In general (for 7 of the 8 cases), the common word
                                                                      point of comparison leads to larger correlations with the ex-
2. Cloth in the breeze
                                                                      ternal raters than did the scenario point of comparison, repli-
    Note that the experiment included two other scenarios that        cating what was found by Forster and Dunbar (2009).
 were not examined: “Person A is lying down, person B is sit-
 ting and person C is standing” and “Person A walks, Person
                                                                      Table 3: Correlation between external rater judgments of
 B jumps”. These were excluded because it was thought they
                                                                      originality and automated methods.
 were too inherently compositional. After performing the task,
 participants were asked to rate their own responses, produc-                                     Measure        Light    Cloth
 ing a self-rating. In addition, six external raters, individuals            Scenario             avePMI         -.424    -.184
 not taking part in the experiment, rated the originality of each                                 prodPMI        -.357    -.322
 response. For the analyses below, we used the average of the                                     w1PMI          -.382    -.272
 external raters to determine the External Rater score for an                                     LSA            -.362
 individual response.
 Similarity and Originality                                                  Common Words         avePMI         -.542    -.392
                                                                                                  prodPMI        -.502    -.261
 To apply the methods of representing phrases to the original-
                                                                                                  w1PMI          -.387    -.273
 ity data, it was necessary to determine the point of compar-
                                                                                                  LSA            -.370    -.244
 ison. That is, to what should each response be compared to
 determine its originality? With the phrase data, we directly
                                                                             Other                Elaboration    .104
 compared the phrases to each other to determine their simi-
                                                                                                  Ext. Raters    .711     .679
 larity. The most straight forward method, would be to com-
                                                                                                  Self-Ratings   .380     .329
 pare each response to the scenario they are responses to. For
 example, given the response “a lightning flash in the sky”,
 the non-stopwords in the response (“lightning”, “flash”, and            Table 3 includes three other sets of results. The first is
 “sky”) would be compared with the non-stopwords in the sce-          the correlations between the Elaboration (word count) met-
 nario (“light” and “darkness”). However, previous research           ric and ratings of similarity. This measure correlates weakly
 has found that when using similarity to measure originality,         with originality for the light scenario (.104, p=.025) and not
 at least with LSA, it is better to compare the potentially cre-      significantly for the cloth scenario. The second is the average
 ative responses to non-creative responses (Forster & Dunbar,         correlation among external raters. This was calculated by cor-
 2009). Specifically, Forster and Dunbar gathered uncreative          relating each of the six external raters with the average of the
 data from a separate sample of participants; these participants      other five for all responses. On average, external raters were
 were asked to generate common uses of objects from the al-           correlated with each other at .711 for the light scenario and
 ternate uses task, instead of uncommon uses. The similar-            .679 for the cloth scenario. This could be seen as an upper
 ity between the common and uncommon uses produced the                limit of the degree to which the automated methods correlate
 greatest correlation with human judgments of creativity.             with the external raters.
    Therefore, in addition to the comparison with the scenario,          The final method reported in the table was the correlation
 we included a comparison of each response to common re-              between the external ratings and the self-ratings. This cor-
 sponses. In place of a data set of standard responses, we used       relation was much lower than that of the external raters to
 the most common five words in the responses to the two sce-          each other, perhaps not surprisingly. What is of interest is
 narios. We excluded stop words and the words from the sce-           that the avePMI method was more strongly correlated with
 nario (i.e., we excluded “light” and “darkness” from the first       external raters than were self-ratings. That is, the best of the
 scenario and “cloth” and “breeze” from the second). In addi-         automated scoring methods outperformed the human gener-
 tion to the common words point of comparison, we also tested         ated, self-ratings, when using human external raters as the
 the correlation between the similarity of the responses to the       gold standard.
 words in the scenario.                                                  One additional result shown in Table 3 worth noting is that
    Table 3 shows the correlation between the four different          of the eleven methods of predicting external ratings all of
 methods of representing phrases by the two different points          them performed worse for the cloth scenario than for the light
                                                                  2330

scenario. This included not only the automated methods but           ratings when participant scores were averaged. This com-
also the external and self-ratings. Also, only the avePMI with       bined with the fact that there was not a significant correlation
the common words point of comparison was able to perform             between self-ratings and the external raters for the light sce-
better than the self-ratings for the cloth scenario.                 nario, indicates that self-ratings are not the best indicators of
                                                                     originality.
Scoring Individual Participant Originality
Often assessments of creativity are used to assess individ-                                    Discussion
ual differences. It is therefore important to determine how          The goal of the present study was to test the ability of similar-
well the automated methods do scoring not just individual re-        ity of semantic representations to predict human judgments
sponses but also individual participants. To test this, we gen-      of originality. To this end, we compared a number of dif-
erated an average similarity score for each participant for each     ferent factors: type of semantic space, methods of compari-
scenario and scoring method. Also, as this was a measure that        son, and methods of phrase representation. We also compared
included multiple responses per participant, we were able to         the performance of semantically informed automated scoring
apply the Fluency metric (the count of number of responses           methods against automated methods blind to semantic infor-
per participant per scenario).                                       mation.
   As shown in Table 4, the correlations are generally at
least slightly smaller when scoring by participant relative to       Similarity and Originality
scoring by response. Again only significant correlations are         We found that similarity can be used to predict original-
shown (p¡.05). Perhaps the most striking difference is for           ity. Specifically, the similarity of a response to common re-
the automatic scoring methods when using the scenario point          sponse words to a scenario were negatively correlated with
of comparison, as none of them remained significant predic-          human judged originality of the response. This fits well with
tors of the external ratings for the cloth scenario. Consistent      our previous work on flexibility, which found that similarity
with the individual response results, the common-words point         within a participant’s set of responses was negatively corre-
of comparison leads to stronger correlations in all but one          lated with the flexibility of the participant’s responses (Blok
case (LSA). Overall, the avePMI representation performed             et al., 2011). Therefore, a next step would be to test if com-
the best, but was effectively tied (-.341, -.340, -.339 for the      bining these two aspects of creativity (originality and flexi-
LSA, Fluency, and avePMI scoring methods, respectively) in           bility) would provide a predictor of human judgments of cre-
predicting the cloth scenario with both LSA and the Fluency          ativity than the two separately.
metric. The Fluency metric performed surprisingly well for
both scenarios. It was not expected that simply counting the         LSA vs. PMI
number of responses per participant would relate so strongly         Comparing the semantic spaces, we found that PMI matched
with the average originality rating of the responses.                or exceeded the performance of LSA. These results pro-
                                                                     vide additional support for larger data trumping smarter al-
                                                                     gorithms (Recchia & Jones, 2009). Previous results indicate
Table 4: Correlation between external rater judgments and
                                                                     that PMI is unable to outperform LSA when given the same
automated methods by participant.
                                                                     corpus. It is the ability of PMI to make use of larger copora
                           Measure          Light    Cloth           (i.e., more data) that allows the model to outperform LSA in
       Scenario            avePMI           -.312                    general and specifically, in the present study. The corpus used
                           prodPMI          -.345                    for LSA was carefully created TASA corpus which is rather
                           w1PMI            -.416                    small compared to the entirety of Wikipedia, the corpus used
                           LSA              -.335                    by our PMI space.
                                                                     Point of Comparison
       Common Words        avePMI           -.571    -.339
                           prodPMI          -.391    -.309           The point of comparison, what participant responses were
                           w1PMI            -.483                    compared to for the originality scoring, had a large and con-
                           LSA              -.311    -.341           sistent impact on performance. The better point of com-
                                                                     parison for judging similarity was not the scenario or prob-
       Other               Elaboration                               lem participants were given but instead uncreative responses
                           Fluency          .464     .340            (Forster & Dunbar, 2009). This was approximated in the
                           Ext. Raters      .647     .726            present study by the most common words from the responses.
                           Self-Ratings              .313            This result was found both when using LSA and PMI.
                                                                     PMI phrase representation
   The avePMI method correlates more strongly with average           Unlike LSA, there is not an accepted standard for how to
participant originality than the self-ratings do. In addition,       represent phrases within PMI. Of the three methods tested
both LSA and the Fluency performed better than the self-             here, the average PMI between the words of the two phrases
                                                                 2331

worked the best for both predicting similarity judgments be-          ods in natual language processing and computational nat-
tween phrases and for predicting originality judgments. The           ural language learning (pp. 546–556). Stroudsburg, PA:
product of the pairwise comparisons performed well for cer-           Association for Computational Linguistics.
tain comparison types, for example, for predicting similarity       Blok, S., Harbison, J. I., Haarmann, H. J., Bloodgood, M.,
between two compound-noun phrases, but did not perform                & Berens, M. (2011). Determining the feasibility of auto-
consistently. Furthermore, prodPMI always produced corre-             matically scoring parts of the ardtt (Tech. Rep. Nos. Part
lations at least slightly less than the avePMI.                       B of TTO 3503 Improving assessment of analyst-relevant
   The first-word method (w1PMI), a method that only used             divergent thinking: test validation, automated scoring, and
the PMI between the first words of the two phrases and ignor-         brain signature). College Park, MD: University of Mary-
ing all the other words, performed surprisingly well. While it        land, Center for Advanced Study of Language.
was never the strongest method, it was also rarely the weak-        Budiu, R., Royer, C., & Pirolli, P. (2007). Modeling in-
est. This fact suggests that either the entirety of the phrase        formation scent: A comparison of LSA, PMI, and GLSA
was not that important for the present datasets or that the           similarity measures on common tests and corpora. In
methods tested in the present research to represent the phrases       Proceedings of the 8th annual conference of recherche
were unable to capture much of the added meaning from the             d’information assistee par ordinateur (RIAO) (pp. 314–
phrase. The latter possibility appears more likely.                   332). Pittsburgh, PA: Centre des Hautes Etudes Interna-
                                                                      tionales d’Informatique Documentaire.
Fluency and Elaboration                                             Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, R., Solan,
The two semantically uninformed automated scoring meth-               E., Wolfman, G., et al. (2002). Placing search in context:
ods could be considered straw man metrics. Indeed, the Elab-          The concept revisited. ACM Transactions on Information
oration metric, the count of the number of words in each re-          Systems, 20, 116–131.
sponse, did quite poorly relative to the other measures. How-       Forster, E. A., & Dunbar, K. N. (2009). Creativity evalu-
ever, Fluency, which was only applicable for predicting orig-         ation through latent semantic analysis. In Proceedings of
inality at the participant level, did remarkably well. It was         the 31st annual meeting of the cognitive science society
somewhat less accurate than the best PMI method tested for            (pp. 602–607). Amsterdam, The Netherlands: Cognitive
one scenario, but performed as well or better than LSA on the         Science Society, Inc.
two scenarios. This result, combined with the relative ease         Fu, W.-T., & Pirolli, P. (2007). SNIF-ACT: a cognitive model
of implementing the metric (i.e., tallying the number of re-          of navigation on the world wide web. Human-Computer
sponses per participant), suggests that this might be a worth-        Interaction, 22, 355–412.
while first-pass or heuristic method of scoring originality.        Haarmann, H. J., O’Rourke, P., George, T., Smaliy, A.,
                                                                      Grunewald, K., Dien, J., et al. (2011). Improving assess-
                          Conclusion                                  ment of analyst-relevant divergent thinking: test validation,
The present results suggest that similarity in semantic spaces        automated scoring, and brain signature (Tech. Rep. No.
can be used to predict originality in participant responses.          TTO 3503). College Park, MD: University of Maryland,
In particular, the average pairwise PMI between a response            Center for Advanced Study of Language.
and the most common responses to a scenario, performed the          Kimball, D. R., Smith, T. A., & Kahana, M. J. (2007). The
best at predicting originality. However, there are a number           fSAM model of false recall. Psychological Review, 114,
of caveats to these conclusions. First, the analysis was only         954–993.
conducted on two scenarios and the ability of the automated         Landauer, T. K., Foltz, P. W., & Laham, D. (1983). An intro-
methods to score these two scenarios varied noticeably. Sec-          duction to latent semantic analysis. Discourse Processes,
ond, when scoring individuals, not individual responses, the          25, 259–284.
Fluency metric, a tally of the number of responses per partic-      Mitchell, J., & Lapata, M. (2010). Composition in distribu-
ipant, did a surprisingly good job predicting originality. This       tional models of semantics. Cognitive Science, 34, 1388–
combined with the success of the first-word only representa-          1429.
tion of phrases indicates that there is much room for improv-       Recchia, G., & Jones, M. N. (2009). More data trumps
ing phrase representations with semantic spaces.                      smarter algorithms: Comparising pointwise mutual infor-
                                                                      mation with latent semantic analysis. Behavioral Research
                     Acknowledgments                                  Methods, 41, 647–656.
This research was supported in part by the University of            Wang, H. C., Chang, C. Y., & Li, T. Y. (2008). Assess-
Maryland Center for Advanced Study of Language with fund-             ing creative problem-solving with automated text grading.
ing from the Department of Defense.                                   Computers & Education, 51, 1450–1466.
                                                                    Zeno, S., Ivens, S., Millard, R., & Duvvuri, R. (Eds.). (1995).
                           References                                 The educator’s word frequency guide. Brewster, NY:
Blacoe, W., & Lapata, M. (2012). A comparison of vector-              Touchstone.
   based representations for semantic composition. In Pro-
   ceedings of the 2012 joint conference on empirical meth-
                                                                2332

