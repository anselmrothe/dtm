UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Testing the psychological validity of cluster construction biases
Permalink
https://escholarship.org/uc/item/1m5549s8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Austerweil, Joseph
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

                    Testing the psychological validity of cluster construction biases
                                      Joseph L. Austerweil (Joseph Austerweil@Brown.edu)
            Brown University, Department of Cognitive, Linguistic, and Psychological Sciences, Providence, RI 02912
                                Abstract                                 not due to lack of interest, but rather the difficulty of empir-
                                                                         ically comparing these models. Some challenges include the
   To generalize from one experience to the next in a world where
   the underlying structures are ever-changing, people construct         combinatorial explosion in the number of possible clusterings
   clusters that group their observations and enable information         for even a small number of items (e.g., there are more than
   to be pooled within a cluster in an efficient and effective man-      100,000 possible clusterings for 10 items; Pitman, 2002), the
   ner. Despite substantial computational work describing poten-
   tial domain-general processes for how people construct these          indirect and at times weak effect of cluster construction pro-
   clusters, there has been little empirical progress comparing dif-     cesses, and the sensitivity of the clusters reported by partici-
   ferent proposals to each other and to human performance. In           pants to instructions (e.g., providing a number of clusters af-
   this article, I empirically test some popular computational pro-
   posals against each other and against human behavior using the        fects participants’ responses; Pothos et al., 2011).
   Markov chain Monte Carlo with People methodology. The re-                In this article, I present one of the first empirical experi-
   sults support two popular Bayesian nonparametric processes,           ments that directly tests the psychological validity of com-
   the Chinese Restaurant Process and the related Dirichlet Pro-
   cess Mixture Model.                                                   putational models that construct clusters to group observa-
   Keywords: Clustering, Bayesian modeling, Connectionist                tions. This new approach avoids the combinatorial explo-
   modeling, Categorization                                              sion of having to test an insurmountably large number of
                                                                         stimuli on some measure. Instead, I test people’s prior ex-
                           Introduction                                  pectations for constructing clusters and compare them to
A child observing a 3-tined fork for the first time easily infers        model predictions using an adaptive experimental technique,
its function. She infers that it is more similar to the 4-tined          Markov chain Monte Carlo with People (MCMCP, which is
forks she typically uses than to other eating utensils such as           also called iterated learning; Griffiths & Kalish, 2007; San-
spoons and knives. To generalize information from one ob-                born, Griffiths, & Shiffrin, 2010). In this method, participant
servation (e.g., a 4-tined fork) to another observation (e.g.,           responses are used to guide the experiment towards testing
a 3-tined fork), people group their observations into clusters           clusters that are consistent with their prior expectations. Pre-
(e.g. forks). A cluster summarizes the information common                vious work has shown that MCMCP is especially effective for
to the stimuli within it, which enables efficient generaliza-            eliciting peoples prior expectations over a large set of possi-
tion and learning. In the example above, the child represents            bilities despite the combinatorial explosion (e.g., happy and
the category of utensils as a combination of three clusters:             sad faces; Martin, Griffiths, & Sanborn, 2012).
forks, spoons, and knives. A novel property learned about                   In this article I first describe previous work testing models
one fork should be generalized more to other forks (within-              that construct clusters. Next, I explain MCMCP and present
cluster) than to other utensils that are not forks. Given that           the experimental methods. Then, I describe the models tested
underlying structures of the world are ever-changing and in-             in this paper (Bayesian nonparametric models, SUSTAIN,
dividuals only observe limited information, the clusters that            and a few alternatives). Last, I discuss the results and con-
encode these structures need to be flexible to accommodate               clude with implications and directions for future work.
new types of items. However, a new item can be too different
to fit in any existing cluster, and a new cluster must be con-                           Previous Empirical Work
structed. For example, when the child sees her first pair of             There are few empirical tests comparing human behavior to
chopsticks, she knows they are part of the category utensils,            different computational models that construct clusters. One
but they do not fit within her current set of clusters (forks,           exception is Pothos et al. (2011), who tested how people
spoons, and knives). So she must create a new cluster to rep-            construct clusters in the domain of unsupervised categoriza-
resent chopsticks. How does the mind construct clusters to               tion without instructing participants to use a certain num-
represent observations?                                                  ber of clusters. Participants were asked to sort nine two-
   Cognitive scientists have proposed several domain-general             dimensional stimuli (spider-like images varying in the length
cluster construction processes with in a variety of domains,             of their “body” and “legs”) into groups that felt intuitive. The
such as categorization (Anderson, 1991; Love, Medin, &                   authors compared participant sortings to their “goodness” ac-
Gureckis, 2004), associative learning (Gershman, Blei, &                 cording to several unsupervised category learning models.
Niv, 2010), causal inference (Kemp, Tenenbaum, Niyogi, &                 Their results were equivocal, but generally, they supported
Griffiths, 2010), perceived orientation (Austerweil, Friesen,            SUSTAIN and a few other models better than the Rational
& Griffiths, 2011), and word segmentation (Goldwater, Grif-              Model of Categorization (a Dirichlet process mixture model
fiths, & Johnson, 2009). Despite the proliferation of differ-            using a particular approximation method; Anderson, 1991;
ent proposals, there have been few attempts to compare the               Neal, 1998). Their results are an informative first comparison
proposals and evaluate their psychological validity. This is             of human and model clustering in unsupervised categoriza-
                                                                     122

tion. However, they only tested nine of the potentially infinite       are interleaved so that participants do not realize their choices
number of stimulus sets (i.e., body-length × leg-length com-           determine future trials.
binations) within their domain. This limits the conclusions
one can draw from their results because it is unclear whether                            Experimental methods
their results reflect an experimental bias due to the stimulus         There were two conditions in the within-subjects MCMCP
sets picked by the experimenters or actual properties of hu-           experiment, each of which elicited a different type of expecta-
man cluster construction. For example, one might suspect               tion related to clustering. The first condition (Balls) explored
that the most preferred clustering would be a single cluster           peoples expectations as to the size of clusters. The state of
with all the items in it, but none of their stimulus sets afforded     each Markov chain in this condition was the assignment of
a single cluster solution. Thus, based on their results alone,         items to clusters. At the beginning of the experiment, each
we might suspect that people are biased against adopting a             chain was initialized to a different possible clustering. Transi-
single cluster to represent stimuli, which seems unintuitive           tions then reassigned one of the items to a new cluster (based
and is not necessarily true.                                           on the other cluster assignments). Because it is a MCMCP
                                                                       experiment, after sufficiently long, the Markov chains in the
     Markov Chain Monte Carlo With People                              Balls condition can be treated as samples from peoples prior
                                                                       expectations of the size of clusters. The second condition
                           (MCMCP)                                     (Sticks) explored peoples expectations over categories vary-
                                                                       ing on a single continuous dimension (vertical lines varying
In the studies presented here I use MCMCP to circumvent                in height). On each trial of this condition, participants ob-
the problem of how to pre-select stimulus sets that are most           served seven vertical lines of different heights and produced
informative about how people construct clusters. MCMCP                 the height of an eighth line. Biases due to clustering expec-
is an experimental methodology that adapts MCMC algo-                  tations should influence participant judgments. For example,
rithms to construct experiment stimuli online, based on the            if a participant observed four short and three tall lines, they
participants previous response. MCMC algorithms are a class            should produce either a short or tall line, but not a line of
of methods that approximate a probability distribution by              medium height.
constructing a Markov chain that converges to that distribu-              There were 24 participants (Amazon Mechanical Turk)
tion (Gilks, Richardson, & Spiegelhalter, 1996). A familiar            paid $7.50 for completing the ≈45 minute experiment. The
MCMC procedure is shuffling a deck of cards (Aldous & Di-              order of the two conditions was counterbalanced across par-
aconis, 1986). The state of the Markov chain at each step is           ticipants. The within-subject procedure allows for the opti-
the order of cards in a deck. A “shuffle” transitions the deck         mal cluster construction parameter for each participant to be
from one order to another order. After sufficiently many shuf-         compared across conditions. The parameters are not neces-
fles, the deck will reach “stationarity,” meaning that if you          sarily related (e.g., their values could be domain-dependent),
stopped shuffling at any point, the probability of any order of        but if they are related, it would provide strong empirical sup-
cards would be the same. The distribution of states that the           port that the models are capturing some characteristic of a
chain visits (after sufficiently many transitions) is known as a       domain-general process.
stationary distribution.
   MCMC algorithms are methods for defining a Markov                   Balls: MCMCP Over Clusterings
chain whose stationary distribution is any complex distribu-           In each trial the colors of six balls were described, and a sev-
tion of interest (e.g., expectations over clusterings). They           enth ball was not described (hidden). Participants were al-
do so by defining the transition procedure to be a simplified          ways given verbal descriptions and never observed the image
form of the complex distribution. In a Gibbs sampling within-          of any colored balls. There were seven possible ball colors:
subjects MCMCP experiment, a Markov chain is a sequence                red, orange, yellow, green, blue, purple, and brown. Both
of trials within the experiment and the state of the Markov            the subjects and models were given the task of predicting the
chain is a sample from the desired probability distribution            color of the hidden seventh ball in the set, given the six ob-
(e.g., a clustering). The chain is initialized to a possible sam-      served colors. The choices on a trial included any observed
ple (e.g., 7 balls are clustered into one cluster of size 4 and a      color name, plus one additional color name. For example,
second cluster of size 3). On each trial, participants observe         if they were told there are 4 red balls and 2 green balls, their
the sample except for one of its items, which is hidden (e.g.,         options for the seventh ball were red, green and one other ran-
given that 6 balls are clustered into one cluster of size 4 and a      domly chosen color (e.g., blue). The Balls condition differs
second cluster of size 2, do you think a seventh ball will part        from standard probability matching experiments because the
of cluster 1, 2, or a new cluster?). Their choice becomes the          trials and number of choices change depending on participant
value for the hidden part of the sample (e.g., if the participant      responses.
chose cluster 1, there would now be 5 balls in cluster 1 and 2            This procedure was conducted for 15 MCMCP chains,
balls in cluster 2). On the next trial of the chain, participants      which all started at a different initial state. The state were
replace a different part of the sample. This is repeated many          defined by all possible combinations of cluster sizes, regard-
times. In these types of experiments, trials for multiple chains       less of color (e.g., (7), (6, 1), (5, 2), (5, 1, 1) and so forth un-
                                                                   123

til (1, 1, 1, 1, 1, 1, 1), where (a, b, . . . , ) means a cluster of a     & Griffiths, in press, for a review), the set of possible struc-
balls of color A, a cluster of b balls of color B, and so on).             tures is infinite, which allows them to capture a wide array
The color names assigned to each cluster were randomly de-                 of structures while maintaining explicit prior expectations
termined for each participant but were consistent during that              over the structures. In this subsection, I discuss the Chi-
participants session.                                                      nese Restaurant Process (CRP; Aldous, 1985), the Pólya Urn
   After the first iteration of each chain, the ball that the par-         (Blackwell & MacQueen, 1973), the two-parameter gener-
ticipant predicted replaced the hidden ball. On the next itera-            alization of the CRP called the Pitman-Yor Process (PYP;
tion, their response became part of the observed set of balls,             Pitman, 2002), the Dirichlet process mixture model (DPMM;
and a ball becomes hidden (different from the one of the pre-              Antoniak, 1974; Ferguson, 1973), and the Pitman-Yor pro-
vious iteration). Which ball becomes hidden was determined                 cess mixture model (PYPMM; Pitman, 2002).
randomly, with the constraint that every ball gets replaced
once before it is replaced again. By the end of the experi-                   A commonly used Bayesian nonparametric process is the
ment, all balls within a chain were replaced twice. Also, a                CRP with parameter α > 0 that governs the propensity for
ball was replaced in each chain before the next ball in a chain            constructing clusters. It is a culinary metaphor that defines
was replaced. This procedure resulted in 210 trials.                       a probability distribution directly over clusterings. Accord-
   Participants were told that they would be presented with a              ing to it, customers (observations) zN = (z1 , . . . , zN ) enter
series of urns filled with balls of different colors. On each trial        a restaurant with infinite tables of infinite capacity. The
they would be told the colors of 6 balls from an urn and would             first customer starts the process by sitting at the first ta-
be asked “what you thought was most likely to be the color                 ble. Customer N sits at occupied table k with probability
of the next ball drawn from the urn?”. To mitigate any inter-              mk /(N + α − 1), where mk is the number of customers at the
trial dependencies (and to stay faithful to the assumptions of             table, or an unoccupied table with probability α/(N + α − 1).
the cluster construction models), participants were told that              The PYP is equivalent to the CRP except that a small “dis-
“the urns are unrelated and so balls from one urn provide no               count” (parameter 0 ≤ d ≤ 1) is taken whenever a customer
information about the balls in another urn” and “although you              sits at a new table and given back to the probability of a fu-
get to see 6 balls from each urn, there are many balls in each             ture new table. So, for the PYP, customer N sits at occupied
urn.” Finally, each urn was labeled with a unique number.                  table k with probability (mk − d)/(N + α − 1) or an unoccu-
                                                                           pied table with probability (α + Kd)/(N + α − 1), where K
Sticks: MCMCP Over 1-D Categories                                          is the number of occupied tables. This defines a clustering
In each trial, the heights of seven sticks were visually pre-              of items where two items are in the same cluster when their
sented to participants. Analogous to the Balls condition, there            corresponding customers are sitting at the same table. Note
is an eighth hidden stick height. On each trial, the participants          that these processes implement forms of probability matching
and models predicted the height of the eighth stick, given the             (Shanks, Tunney, & McCarthy, 2002), where the probability
observed seven sticks. Participants controlled the length of               of choosing a previously unobserved value decreases in the
a stick on the screen by moving their mouse vertically and                 number of observed items. When each table k of the CRP is
clicked to submit their response.                                          associated with a parameter θk from an arbitrary distribution
   This procedure was conducted for 25 MCMCP chains,                       G(·), the process on (z, θ) = (z1 , . . . , zN , θ1 , . . .) is called the
all initialized to different states. To capture a diverse                  Pólya Urn (Blackwell & MacQueen, 1973) due to its equiva-
range of stimulus distributions, their heights were initial-               lence to a generative process where colored balls are sequen-
ized by sampling from the following Beta distributions: four               tially drawn from an urn, and each time a ball is drawn, it is
were Uniform (Beta(1,1)), four were centered on the Middle                 put back in the urn with an additional ball of the same color
stick height (Beta(5,5)), five were Bimodal at the extremes                (which inspired the Balls condition). The urn, balls, and col-
(Beta(0.2,0.2)), four were Very Small (Beta(0.2,1)), four were             ors are analogous to the restaurant, customers, and parameter
Very Large (Beta(1,0.2)), one was Small (Beta(5,1)), and one               associated with each table, respectively.
was Large (Beta(1,5)). The value was rescaled to 0.07 to 1.11
inches. The width of a stick was 0.02 inches. Otherwise the                   To connect clusters to observations, Bayesian nonparamet-
procedure was identical to the Balls condition. This resulted              ric models typically assume each cluster is associated with
in 368 trials.                                                             a parameter that determines a distribution over the observa-
                                                                           tions. I.e., observations in a cluster are generated from the
                     Constructivist Models                                 distribution determined by the cluster’s parameter. I assume
                                                                           that items given their cluster membership are normally dis-
Bayesian Nonparametric Models                                              tributed (xn |zn = k ∼ N(θk , σ2x )), where the cluster parameter
Bayesian models posit a set of possible structures, formulate              θk defines the mean of the observations and is generated from
prior expectations over these structures as probability distri-            a Normal distribution with known mean µ0 and variance σ20
butions, and then integrate observed information into the dis-             (G = N(µ0 , σ20 )). This mixture model is a DPMM or PYPMM
tribution over structures via Bayes’ rule. In Bayesian non-                when the CRP and PYP are used to generate cluster member-
parametric models (see Austerweil, Gershman, Tenenbaum,                    ship, respectively.
                                                                       124

Connectionist Model                                                                    (a)               Chain              (b)            After last trial
                                                                                                         initialization                    of each chain
                                                                                             300                                  300
Although many connectionist models use a fixed architecture,
one of the most popular connectionist models of category                                     250                                  250
learning, SUSTAIN (Love et al., 2004), changes its archi-                                    200                                  200
                                                                                     Frequency
tecture by constructing new nodes when it cannot explain its                                 150                                  150
current observation. There are a few variants of SUSTAIN,
                                                                                             100                                  100
which are used depending on whether categorization infor-
mation is given. Because participants do not get category                                        50                               50
information in the Experiment, I focus on the purely unsu-                                       0                                 0
                                                                                                     0       5       10                0      5       10
pervised variant of the model, where a layer of clusters com-                           prototype                exemplar    prototype            exemplar
pete to encode observations. SUSTAIN starts small (with one                                           # of clusters                     # of clusters
cluster centered on the first observation) and constructs new
clusters whenever the activation of the most activated clus-              Figure 1: Results of Balls condition. (a) The number of clus-
ter is below a threshold τ. The activation of a cluster k, hk ,           ters after the first response. The distribution is roughly uni-
for an input xn decays exponentially in the distance between              form over possible clusterings of the balls. (b) The number
the position of cluster k, θk , and the input hk = e−λd(x,θk ) ,          of clusters at the end of the experiment. The distribution is
where λ is the tuning of the input dimension and d(x, θ) is               tightly peaked at one cluster, which provides support to peo-
the distance between x and θ, which is the Hamming distance               ple being initially biased towards prototype representations.
(0 if equal, 1 otherwise) for discrete stimuli and 21 |x − y| for
continuous stimuli (following Love et al., 2004). This acti-
vation rule is equivalent to the activation rule used by Love             1978; Nosofsky, 1986). For both models, the same distance
et al. (2004) when inputs are one-dimensional. When a new                 function was used d(x, y) = λ|x − y|, where λ is the dimen-
cluster is created for an item, the cluster’s parameter is set            sional tuning parameter. The prototype model assumes that
to the current item’s value. Otherwise, the “winning” clus-               participants represent the given items as the average of their
ter (the one with largest activation) is updated according to             values. For the prototype model, the activation of a new item
∆θk = η(x − θk ), where η is the learning rate. When a new                y to the given items x is h = exp{−d(θ, y)}, where θ is the
cluster was not created, the dimensional tuning was also up-              average of the given items x. Conversely, the exemplar model
dated via ∆λ = ηe−λd(x,θk ) (1 − λd(x, θk )) where k is the index         assumes that participants represent the given items explicitly.
of the winning cluster. Following Love et al. (2004), the out-            For the exemplar model, the activation of a new item y to the
                                              β+1        β
put activation for item x was given by o = hk / ∑ j h j , where           given items x is h = ∑Nn=1 exp{−d(xn , y)}. For both models,
 j ranges over the network’s clusters and β is a nonnegative              the probability of a new item is given by the exponentiated
lateral inhibition parameter. To convert the output activations           Luce choice rule of the new item’s activation (as compared to
to a probability distribution over items, I used the exponen-             the other possible items) with parameter w.
tiated Luce choice rule with parameter w over the output ac-
tivation o for a given item (as compared to the activation of                                            Experimental Results
other possible items).
                                                                          Balls: MCMCP over Clusterings
Alternative Models                                                        Figure 1a shows the number of clusters at the start of the ex-
There were two sets of alternative models depending on the                periment and Figure 1b shows the numbers of clusters after
observable property of the given items. When the cluster as-              the last block of this condition of the experiment. At the end
signments were directly observed (the Balls condition of the              of the experiment, the distribution of the number of clusters
Experiment), I used two alternative models: Max + Noise and               per trial is peaked at one, which supports the hypothesis that
Random.1 With probability 1 − ε, the Max + Noise model                    given only a small number of items from a category, people
generated the modal cluster (the cluster with the most items)             are biased to represent the category using a prototype (Smith
and with probability ε it generated a random cluster from the             & Minda, 1998). Although the majority of chains converged
remaining options. Importantly, the sizes of the previously               to one cluster, some chains still contained more than one clus-
observed clusters only matter for determining the modal clus-             ter at the end of the experiment.2 Thus, the bias towards pro-
ter. The Random model simply chooses uniformly at random                  totype representations is not as strong as it could be.
from the possible choices.                                                   Figure 2 presents the Akaike Information Criterion (AIC;
   When the observable property of a given item was a dimen-              Claeskens & Hjort, 2008), a measure of model fit that penal-
sion, there were two alternative models: a prototype model                izes models with larger numbers of parameters, for the PYP
(Reed, 1972) and an exemplar model (Medin & Schaffer,                     (black), CRP (red), SUSTAIN (purple), Max+Noise (blue),
   1 For the Balls condition, the exemplar and prototype (defined             2 It is possible that every chain would converge to a single cluster
by the mode) models with an exponentiated Luce choice rule are            with further testing. This is unlikely because the distribution over
equivalent to the CRP and Max + Noise models, respectively.               the number of clusters barely changed over the last few trials.
                                                                    125

                                                Fit of the models to participants in the Balls condition                                                                                         Fit of the models to participants in the Sticks condition
                                  1000                                                                                                                                                  205
                                                  Worse Fit                             PYP
                                                                                                                                                                                                 Worse Fit
                                                                                                                                                                                                                                                                              PYPMM
                                            900                                         CRP                                                                                             200
         Average Akaike Information Criterion                                                                                                             Average Akaike Information Criterion
                                                                                        SUSTAIN                                                                                                                                                                               DPMM
                                                                                        Max + Noise                                                                                                                                                                           SUSTAIN
                                            800                                         Random                                                                                          195                                                                                   Exemplar
                                                                                                                                                                                                                                                                              Prototype
                                            700                                                                                                                                         190
                                            600                                                                                                                                         185
                                            500                                                                                                                                         180
                                            400                                                                                                                                         175
                                            300                                                                                                                                         170
                                                  Better Fit                                                                                                                                     Better Fit
                                            200                                                                                                                                         165
                                                     3         5       7        9       11      13                                                                                                                6
                                                                    Block number                                                                                                                                      Block number 11                                                     16
Figure 2: Average Akaike Information Criterion (AIC) fits of                                                     Figure 3: Average AIC fits of the PYPMM (black), DPMM
the PYP (black), CRP (red), SUSTAIN (purple), Max+Noise                                                          (red), SUSTAIN (purple), Exemplar (yellow), and Prototype
(blue), and Random (green) models for participants in the                                                        (blue) models for participants in the stick condition over the
Balls condition over the course of the experiment (Note: Bet-                                                    course of the Experiment (Note: Better fits have smaller val-
ter fits have smaller values). Although PY and CRP are barely                                                    ues). Although PYPMM and DPMM are barely distinguish-
distinguishable in aggregate (with PY having slightly better                                                     able in aggregate (with perhaps the Exemplar model being
CRP), CRP has significantly better AIC when compared to                                                          slightly better near the end of the experiment), DPMM has
the other models at the level of individual participants.                                                        significantly better AIC when compared to the other models
                                                                                                                 at the level of individual participants.
and Random (green) models over the 14 blocks of the exper-
iment (generating a clustering for each item twice).3 In this
condition of the experiment, SUSTAIN is equivalent to a two-
                                                                                                                 ate and tells a different result: The DPMM provides signif-
step generative process: first, decide to make a new cluster or
                                                                                                                 icantly better fit to the results of individual participants in
use an old cluster with some probability, and if an old clus-
                                                                                                                 the experiment (DPMM had the best AIC for 16 of 24 par-
ter is used, pick an old cluster uniformly at random. Unlike
                                                                                                                 ticipants; p < 0.05 for a Binomial sign test). The PYPMM
participants, it is not biased towards clusters of larger sizes,
                                                                                                                 and the Exemplar models provided the best fit for one and
and thus has poor fit to the results. Although it is tempting
                                                                                                                 seven participants, respectively. Thus, in corroboration with
to conclude that the PY model captures the results better than
                                                                                                                 the results of the Balls condition, the DPMM seems to pro-
the CRP model from Figure 2, this would be premature be-
                                                                                                                 vide the best description to people’s expectations over a one-
cause Figure 2 reports aggregate fits, rather than the results of
                                                                                                                 dimensional stimulus and the implicit bias of the clusters pro-
individual participants. Fitting each model to individual par-
                                                                                                                 vides a benefit over the simpler Exemplar model (though it is
ticipants provides a more appropriate analysis and different
                                                                                                                 too weak to show in the aggregate results).
results: the CRP provides significantly better fit to the results
of individual participants in the experiment (CRP had the best
AIC for 16 of 24 participants; p < 0.05 for a Binomial sign
test). The PY and random models fit five and three subjects
                                                                                                                   (a)                                                                                                      (b)
best, respectively. SUSTAIN fits the results poorly because,                                                                                         Best Fitting CRP−DPMM α Parameters                                                                     Best Fitting PYP−PYPMMα Parameters
                                                                                                                   Sticks Best−Fitting α Parameter                                                                        Sticks Best−Fitting α Parameter
                                                                                                                                                     8                       r = 0.31                                                                       8                      r = 0.03
unlike participants, it has no bias towards larger clusters. The
Max + Noise and Random models also fit the data poorly.                                                                                              6                                                                                                      6
                                                                                                                                                     4                                                                                                      4
Sticks: MCMCP Over 1-D Categories
                                                                                                                                                     2                                                                                                      2
Figure 3 presents the AIC of the PYMM (black), DPMM
(red), SUSTAIN (purple), Exemplar (yellow), and Prototype                                                                                            0                                                                                                      0
                                                                                                                                                      0                                          1            2       3                                      0           1          2          3
                                                                                                                                                          Balls Best−Fitting α Parameter                                                                         Balls Best−Fitting α Parameter
(blue) models over the 16 blocks of the experiment (replacing
the length of each stick twice). Although it might be tempt-
ing to conclude that the Exemplar model performs similar to                                                      Figure 4: Relation between the cluster construction parame-
if not better than the DPMM (which are better than the rest),                                                    ters of the (a) CRP-DPMM and (b) PYP-PYPMM fit to in-
again analyzing the individual participants is more appropri-                                                    dividual participants. Although neither correlation is signifi-
                                                                                                                 cant (p = .14 and p = .89 two-tailed, respectively), the CRP-
   3 Using the Bayesian Information Criterion (Claeskens & Hjort,
                                                                                                                 DPMM correlation is suggestive.
2008) yields the same statistical results as AIC for both conditions.
                                                                                                           126

Balls-Sticks Comparisons                                                Claeskens, G., & Hjort, N. L. (2008). Model selection and
                                                                          model averaging. Cambridge: Cambridge Univ. Press.
Given the within-subjects design, it is possible to explore
                                                                        Ferguson, T. (1973). A Bayesian analysis of some nonpara-
whether the parameters of the Bayesian nonparametric mod-
                                                                          metric problems. The Annals of Statistics, 1, 209-230.
els reflected an aspect of a domain-general cluster construc-
                                                                        Gershman, S., Blei, D., & Niv, Y. (2010). Context, learning,
tion process. Figures 4 (a) and (b) present the relation be-
                                                                          and extinction. Psychological Review, 117(1), 197–209.
tween the cluster construction parameters of the CRP-DPMM
                                                                        Gilks, W., Richardson, S., & Spiegelhalter, D. J. (1996).
(r = .31, p = .14 two-tailed) PYP-PYPMM (r = .03, p = .89
                                                                          Markov chain Monte Carlo in practice. Chapman and Hall.
two-tailed) fit to individual participants, respectively. Al-
                                                                        Goldwater, S., Griffiths, T. L., & Johnson, M. (2009). A
though neither correlation is significant, the CRP-DPMM
                                                                          Bayesian framework for word segmentation: Exploring the
correlation is suggestive (especially because there are outliers
                                                                          effects of context. Cognition, 112, 21-54.
and a one-tailed test is justified). Future work should test this
                                                                        Griffiths, T. L., & Kalish, M. L. (2007). Language evolu-
possibility further.
                                                                          tion by iterated learning with Bayesian agents. Cognitive
                                                                          Science, 31(3), 441-480.
                    Concluding Remarks                                  Kemp, C., Tenenbaum, J., Niyogi, S., & Griffiths, T. (2010).
This article describes results about how people and computa-              A probabilistic model of theory formation. Cognition,
tional models construct clusters by comparing different mod-              114(2), 165–196.
els to human performance. First, popular culinary metaphors             Love, B. C., Medin, D. L., & Gureckis, T. M. (2004). SUS-
from Bayesian nonparametrics (the CRP and PYP) imple-                     TAIN: A network model of category learning. Psychologi-
ment forms of probability matching and the CRP is equivalent              cal Review, 111, 309-332.
to an Exemplar model over cluster membership. Second, I                 Martin, J. B., Griffiths, T. L., & Sanborn, A. N. (2012). Test-
used the MCMCP methodology to compare how people con-                     ing the efficiency of Markov chain Monte Carlo with peo-
struct clusters to different computational proposals. The CRP             ple using facial affect categories. Cognitive Science, 36,
and DPMM best captured the expectations of individual par-                150-162.
ticipants over clusterings and the stimulus distribution. Fur-          Medin, D. L., & Schaffer, M. M. (1978). Context theory
ther work is needed to reconcile these results with those of              of classification learning. Psychological Review, 85, 207-
Pothos et al. (2011) and to follow up on the intriguing possi-            238.
bility that the cluster construction parameter in the CRP and           Neal, R. M. (1998). Markov chain sampling methods for
DPMM captures an important aspect of an underlying process                Dirichlet process mixture models (Tech. Rep. No. 9815).
used by people to construct clusters across domains.                      Department of Statistics, University of Toronto.
                                                                        Nosofsky, R. M. (1986). Attention, similarity, and the
                           References                                     identification-categorization relationship. JEP: General,
                                                                          115(1), 39–57.
Aldous, D. (1985). Exchangeability and related topics. In               Pitman, J. (2002). Combinatorial stochastic processes.
   École d’Été de probabilités de Saint-Flour xiii (pp. 1–198).       (Notes for Saint Flour Summer School)
   Berlin: Springer.                                                    Pothos, E. M., Perlmann, A., Bailey, T. M., Kurtz, K., Ed-
Aldous, D., & Diaconis, P. (1986). Shuffling cards and stop-              wards, D. J., Hines, P., & McDonnell, J. V. (2011). Mea-
   ping times. The American Mathematical Monthly, 93(5),                  suring category intuitiveness in unconstrained categoriza-
   333-348.                                                               tion tasks. Cognition, 121, 83-100.
Anderson, J. R. (1991). The adaptive nature of human cate-              Reed, S. K. (1972). Pattern recognition and categorization.
   gorization. Psychological Review, 98(3), 409–429.                      Cognitive Psychology, 3, 393-407.
Antoniak, C. (1974). Mixtures of Dirichlet processes with               Sanborn, A. N., Griffiths, T. L., & Shiffrin, R. (2010). Un-
   applications to Bayesian nonparametric problems. The An-               covering mental representations with Markov chain Monte
   nals of Statistics, 2, 1152-1174.                                      Carlo. Cognitive Psychology, 60, 63-106.
Austerweil, J. L., Friesen, A. L., & Griffiths, T. L. (2011). An        Shanks, D. R., Tunney, R. J., & McCarthy, J. D. (2002). A
   ideal observer model for identifying the reference frames of           re-examination of probability matching and rational choice.
   objects. In Advances in NIPS 24.                                       Journal of Behavioral Decision Making, 15, 233-250.
Austerweil, J. L., Gershman, S. J., Tenenbaum, J. B., & Grif-           Smith, J. D., & Minda, J. P. (1998). Prototypes in the mist:
   fiths, T. L. (in press). Structure and flexibility in Bayesian         The early epochs of category learning. JEP:LMC, 24(6),
   models of cognition. In J. R. Busemeyer, J. T. Townsend,               1411-1436.
   Z. J. Wang, & A. Eidels (Eds.), Oxford Handbook of Com-
   putational and Mathematical Psychology. Oxford Univer-
   sity Press.
Blackwell, D., & MacQueen, J. (1973). Ferguson distribu-
   tions via Polya urn schemes. The Annals of Statistics, 1,
   353-355.
                                                                    127

