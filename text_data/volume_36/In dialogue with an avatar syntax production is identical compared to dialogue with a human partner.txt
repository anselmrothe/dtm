UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
In dialogue with an avatar, syntax production is identical compared to dialogue with a
human partner
Permalink
https://escholarship.org/uc/item/6q604919
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Heyselaar, Evelien
Hagoort, Peter
Segaert, Katrien
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

             In Dialogue with an Avatar, Syntax Production is Identical Compared
                                           to Dialogue with a Human Partner
                                          Evelien Heyselaar (evelien.heyselaar@mpi.nl)
                                               Peter Hagoort (peter.hagoort@mpi.nl)
                                             Katrien Segaert (katrien.segaert@mpi.nl)
                                        Max Planck Institute for Psycholinguistics, Wundtlaan 1
                                                   Nijmegen 6525XD, The Netherlands
                             Abstract                                 avatar behavior in parameters that are nearly impossible
                                                                      to control in a confederate, an aspect that is particularly
   The use of virtual reality (VR) as a methodological tool is        attractive for dialogue research.
   becoming increasingly popular in behavioural research due
   to its seemingly limitless possibilities. This new method has         There is a rapidly growing interest in interactional
   not been used frequently in the field of psycholinguistics,        aspects of language. Language is increasingly studied in a
   however, possibly due to the assumption that human-                dialogue context, focusing on, for example, the turn-taking
   computer interaction does not accurately reflect human-human       event (Stivers et al., 2009), the role of the dialogue partner
   interaction. In the current study we compare participants’         (Branigan et al., 2003) and characteristics of the social
   language behaviour in a syntactic priming task with human
   versus avatar partners. Our study shows comparable priming         interaction (Balcetis & Dale, 2012). With this, there is an
   effects between human and avatar partners (Human: 12.3%;           increasing demand in the field to develop a methodology
   Avatar: 12.6% for passive sentences) suggesting that VR is a       where these factors can be stringently controlled.
   valid platform for conducting language research and studying          We put VR as a methodology to study language
   dialogue interactions.                                             behaviour to the test. In Experiment 1, we established which
   Keywords: virtual reality; human-computer interaction;             characteristics make an avatar more human in a rating
   syntactic priming.                                                 study. In Experiment 2, we investigated language behaviour
                                                                      in interaction with the most human avatar. We focused on
                          Introduction                                syntactic processing (specifying the syntactic relations
   The use of virtual reality (VR) as a method is becoming            between words in the sentence), a core aspect of language
increasingly prevalent in behavioural studies in a wide range         production and comprehension. To compare behaviour in a
of fields, including navigation research (Tarr & Warren, 2002)        human-human interaction and human-avatar interaction, we
and rehabilitation therapy (Rizzo et al., 2004). However this         used a syntactic priming task.
new trend does not seem to be catching on in the field of                Priming refers to the phenomenon in which an individual
psycholinguistics. This may be due to the assumption that             adapts the behavioural characteristics of their conversational
humans do not interact with computers in the same way that            partner. This can range from adapting the speech rate of your
they interact with other humans, making any behavioural               partner (Giles et al., 1992; Giles & Powesland, 1975) to
measure of language interaction with a computer-partner               more complex adaptations such as using the same sentence
(“avatar”) ecologically equivocal.                                    structure as your partner (Bock, 1986). It has been proposed
   However, research into human-computer interactions                 that speakers align syntactic choices and other linguistic
has suggested the opposite, at least with regards to desktop          behaviour to increase affiliation with a conversation partner
modules (Stoyanchev & Stent, 2009a; 2009b). Work by                   (Giles, Coupland, & Coupland, 1991) and to increase
Nass and Moon (2000) has repeatedly shown that humans                 conversation success (Pickering & Garrod, 2004). It is an
attribute human-like characteristics to their desktop computer        open question whether you do this to the same extent with an
partner, the most unintuitive of these findings being the use         avatar-partner as a human-partner.
of politeness when asked to evaluate the computer and the
implementation of social hierarchy. This behaviour was                                       Experiment 1
observed even in participants who, during the debrief, agreed         Experiment 1 was conducted to establish which characteristics
that “the computer is not a person and does not warrant               determine the humanness of an avatar. We asked participants
human treatment or attribution.”                                      to rate six avatars with different facial combinations on the
   VR is one step up from desktop modules as it offers an             amount of humanness, familiarity, quality of facial expression,
immersive 3D world that participants can move in and                  and quality of voice in order to isolate a combination of facial
interact with. However, as it is still a program, VR allows           features that causes the avatar to appear as human as possible.
experimental control over parameters that cannot be (as
finely) controlled in the real world. What is important for
psycholinguists is that VR offers the ability to finely control
                                                                  2351

                             Method                                    view. Mounted on the HMD was a set of 8 reflective markers
                                                                       linked to a passive infrared DTrack 2 motion tracking
Participants                                                           system from ART Tracking, the data from which was used
30 native Dutch speakers (13 male/17 female, Mage: 22.5;               to update the participant’s viewpoint as she moved her head.
SDage: 3.1) gave written informed consent prior to the                 Additionally, a single reflective marker was taped onto the
experiment and were monetarily compensated for their                   index finger of the participant’s dominant hand. This marker
participation.                                                         was rendered as a white ball in the VE, such that participants
                                                                       knew the position of their finger at all times. Sounds in the
Materials                                                              VE, including the voice of the avatar, were rendered with a
                                                                       24-channel WorldViz Ambisonic Auralizer System.
Avatars The avatar was adapted from a stock avatar produced
by WorldViz (“casual15_f_highpoly”). The avatar’s                      Procedure and Task
appearance suggested that she was a Caucasian female in her            The participants were informed that they would be rating six
mid-twenties, which matched the age of the Dutch speaker               different avatars. Exposure to each avatar started with the
who recorded her speech.                                               avatar giving a short introduction speech, followed by a short
   The six facial expressions to be tested involved                    matching card game.
combinations in blink rate, smiling and eyebrow habits                    The card game is identical to the one used in Experiment 2
(Table 1). Blinks happened once every 1 - 5 seconds. For               (for more detail see Methods of Experiment 2). But briefly:
versions with normal smiling and normal eyebrow habits we              the participant and the avatar would alternate in describing
explicitly programmed when the avatar would smile and/                 picture cards to each other. The participant would be
or raise her eyebrows, such that it would coincide with the            presented with six cards from which to freely choose one to
content of her speech. For example, the avatar would raise             describe. After the participants turn, the avatar would select
her eyebrows when asking a question, and smile when she                the described card, causing it to be replaced by a novel card.
was enthusiastic (“Come, let’s play another round!”). When             After the avatar’s turn, the participant would need to select
not speaking, she would smile once every 5 - 10 seconds, and           the card described in order for it to be replaced. The cards
raise her eyebrows once every 1 - 5 seconds such that she              consisted of single or paired actors depicting an action, the
would still differ from the no smile/no eyebrow version.               verb of which would be written underneath the picture.
                                                                          Between avatar versions, participants removed their
Virtual Environment The virtual environment (VE) was                   headset in order to fill out a pen-and-paper questionnaire.
a stock environment produced by WorldViz (“room.wrl”)                  Previous research has shown that if the subject evaluates the
adapted to include a table on which stood a wooden divider.            avatar in the presence of said avatar, they rate them more
The divider height was such that participants could view the           favourably (Nass & Moon, 2000).
top of the divider and the face of the avatar simultaneously.
The table in the VE matched in both dimension and position                                        Results
with a table in the physical world, such that participants could       A significant effect was found of avatar versions on the rating
actually touch the “virtual” table.                                    of humanness (F = 4.970, p <.001), familiarity (F = 3.065, p
   The experiment was programmed and run using WorldViz’s              = .01) and quality of facial expression (F = 5.097, p <.001).
Vizard software. Participants wore an NVIS nVisor SX60                 The voice ratings were not found to be significantly different
head-mounted display (HMD), which presented the VE at                  between avatar versions (F = 1.418, p = .220), which works
1280x1024 resolution with a 60 degree monocular field of               as a sanity check as the voice was exactly the same in each
                                                                       version.
               Table 1. Avatar Facial Expressions.                        A post hoc Tukey’s HSD test showed that avatars with
                                                                       eyebrow movement (3-6) were rated significantly more
    Avatar Blink Rate        Smiling Habit Eyebrow Habit               human than avatars without eyebrow movement (p < .05),
    1        No blink        No smile          No movement             whereas smiling habits made no significant difference, a
                                                                       result that is consistent with previous literature (Looser &
    2        Slow blink1     Random2           No movement             Wheatley, 2010). Additionally, the avatars with a normal
    3        Slow blink      Continuous        Constantly up           blink rate (4-6) were rated as having a significantly higher
    4        Normal          No smile          Random2                 quality of facial expression (p < .05) but had no impact on
    5        Normal          Normal            Random2                 humanness rating.
                                                                          As we were aiming to use the most human avatar in
    6        Normal          Normal            Normal                  Experiment 2, we drew linear correlations between familiarity
  1
    Duration of a slow blink was 0.5 seconds. Duration of a normal     and humanness (Figure 1A) and quality of facial expressions
  blink was 0.1 seconds.                                               and humanness (Figure 1B). For both, two-tailed Pearson’s
  2
    Random habits occurred once every 3 - 5 seconds.                   correlations were positive (familiarity: R2 = 0.64, p < .001;
                                                                   2352

                     A                                                                                B
                     5                                                                                5
                                                                   Avatar 1
                                                                                  Facial Expression
                     4                                             Avatar 2                           4
       Familiarity
                                                                   Avatar 3
                                                                   Avatar 4
                     3                                             Avatar 5                           3
                                                                   Avatar 6
                     2                                                                                2
                         2      3               4          5                                              2        3                  4                    5
                                    Humanness                                                                          Humanness
Figure 1. Rating of avatar versions. A. Correlation between the familiarity and humanness ratings, and B. correlation between
the quality of facial expression and humanness ratings for the six avatars. Avatars with eyebrow movement (3-6) were rated as
significantly more human (p < .001).
facial expression: R2 = 0.58, p <.001) and showed Avatar 6           card). The confederate/avatar description would serve as the
as being rated the highest in all three conditions. Therefore,       prime for the participants’ subsequent target description.
Avatar 6 will be used in Experiment 2.                                  The confederate’s deck was ordered identically to the
                                                                     participant’s deck, so the confederate/participant always
                             Experiment 2                            had the card described. In the VE block, the avatar was
In this experiment we investigate the language behaviour             programmed to randomly pick one of the participant’s cards
in interactions with an avatar and human partner. We used            to describe.
syntactic priming as a behavioural measure with which to                The confederate’s deck of cards showed the stimulus
compare human and avatar conditions.                                 picture but with a full sentence typed underneath, as such the
                                                                     confederate simply needed to read the sentence. 50% of the
                               Methods                               transitive sentences described the picture in the passive tense,
                                                                     50% described it in the active tense. In VE, the avatar was
Participants                                                         programmed to use 50% passives, 50% actives.
33 native Dutch speakers gave written informed consent                  Three conditions were included in the analysis: baseline
prior to the experiment and were monetarily compensated for          trials (intransitive prime followed by a transitive target),
their participation.                                                 active priming (active prime followed by a transitive
  Five subjects were not convinced that the confederate was          target), and passive priming (passive prime followed by
an ignorant participant or did not believe that the avatar was       a transitive target). To ensure an adequate number of trials
voice-recognition controlled and were a priori not considered        in each condition, 2/3 of the cards were transitive and 1/3
part of the data-set. Thus only 28 were included in the analysis     were intransitive. Post-hoc analysis showed that there was
(14 male/14 female, Mage: 20.6; SDage: 2.4).                         an average of 26.2 (SD: 8.5), 27.8 (SD: 3.9), and 25.9 (SD:
Task and Design
Participants conducted a longer version (240 cards) of the
task described in Experiment 1. All participants completed the
task in VE with an avatar as well as in the physical world with
a confederate (order was randomized and counterbalanced
across participants).
  In each block, the participant was presented with six
cards, with the belief that the confederate/avatar had their
own spread of six cards behind the divider (Figure 2). The
                                                                              Participant’s view in the VE Block         Participant’s view in the Human Block
participant and the confederate/avatar would alternate in
describing cards to each other. Participants were instructed
to describe the picture using one concise sentence (e.g., The        Figure 2. Setup for Experiment 2. Shows the experimental
man kisses the woman). If either member had a card that was          set-up from the view of the participant. The only difference is
described, both members would remove that card from the              that in VE the cards were presented at the top of the divider,
spread and replace it with a novel card from their deck (in VE       whereas in the Human block, the cards were laid out on the
this would happen automatically after the subject selected the       table.
                                                               2353

3.6) trials in the baseline, passive and active conditions         Partner Type, and Order for the per-participant random
respectively in the Human block and 21.0 (SD: 3.9), 25.1           intercept only. Per-item could not take any random slopes.
(SD: 3.6), and 24.9 (SD: 4.0) trials in the baseline, passive      We used dummy coding with baseline condition as reference
and active conditions respectively in the VE block.                level for the effect for prime, and deviation coding for the
   One subject was discarded as the difference in the              other factors. Multi-collinearity measures came back as non-
proportion of passive prime exposure between the two               significant (VIF <2.5).
blocks (Human: 0.40; VE: 0.65) fell two-and-a-half standard           Figure 3 summarizes the relative proportion of passive
deviations outside the mean difference between blocks              target responses after each prime structure. The fixed effects
(Mean: 0.01; SD: 0.09).                                            of the best model fit for these data are summarized in Table
                                                                   2. The negative estimate for the intercept indicates that in
Materials                                                          the baseline condition active responses were more frequent
                                                                   than passive responses. Following passive primes, more
Stimulus Pictures The photos used in this task have been           passive responses were produced compared to baseline (p
described elsewhere (Segaert et al., 2011) but briefly: our        < .001). Following active primes, there was no increase in
stimulus pictures depicted 40 transitive events such as            active responses compared to baseline (p = .152). A model
kissing, helping or strangling with the agent and patient of       with Partner Type as an interaction with Prime Structure was
this action. Each event was depicted by either one pair of         not significantly better than the current model (p = 0.32). In
adults or one pair of children. There was one male and one         this model, neither active nor passive priming interacted with
female actor in each picture and each event was depicted with      partner type (β = 0.28, p = .37; β = 0.55, p = .13 respectively)
each of the two actors serving as the agent. The position of       suggesting that the priming effect is the same in the Human
the agent (left or right) was randomized. These pictures were      and VE block.
used to elicit transitive sentences.                                  As the verbs depicted in the intransitive pictures were not
   Filler pictures were used to elicit intransitive sentences.     the same as in the transitive pictures, a separate model was
These fillers depicted events such as running, singing, bowing     created based on data that excluded the baseline condition
with one actor. The actor could be any of the actors used in       in order to analyze the effect of verb repetition on target
the transitive stimulus pictures.                                  choice. Figure 4 shows the proportion of passive responses
   The verb depicted in each picture was written underneath.       with verb repetition and without. Interestingly, there are no
                                                                   trials in which a passive response was produced following an
Procedure                                                          active prime with verb repetition. Therefore, in order to make
Participants were informed that our goal was to compare            the model converge, active primes were also removed from
how experiencing events differed in VE. To ensure that             the dataset. Table 3 summarizes the fixed effects of the best
the participants felt that they were communicating with a          model fit, indicating an influence of Verb Repetition on target
program and not a programmer, they were told that it worked        structure production (p < .001). A model with Partner Type
on voice-recognition, and hence no third party was necessary       as an interaction with Verb Repetition was not significantly
to operate the program.                                            better than the current model (p = .99), suggesting that passive
   Responses were manually coded as active or passive.             priming is boosted by verb repetition but the influence of
Target responses were included in the analysis only if 1) both     verb repetition on target production is the same in the Human
actors and the verb were used correctly and 2) no unnecessary      and VE block.
information was included in the description.                          Correlation analysis showed a positive correlation (R2
                                                                   = 0.37) between the priming effects for passives in the
                            Results                                Human and VE block. The correlation is significant with
We excluded 1.09% (71 out of 6485) of the target responses         both Pearson’s r (two-tailed, p < .001) and Spearman’s rho
because they were incorrect (criteria described under              (to control for the possible influence of outliers; two-tailed,
Procedure).                                                        p = .039), suggesting that participants primed comparably in
   The responses were analyzed using a mixed-effects logit         each condition (Figure 5).
model in R (R Development Core Team, 2009), the results
of which are shown in Table 2. Target responses were coded                                  Discussion
as 0 for actives and 1 for passives. We used a maximal             The first experiment showed that the amount of facial
random-effects structure (Barr er al., 2013): the repeated-        expression in the upper face (namely eyebrow movement)
measures nature of the data was modeled by including a             has a significant impact on the humanness of a virtual being,
per-participant and per-item random adjustment to the fixed        whereas other facial features such as smiling habits and blink
intercept (“random intercept”). We attempted to include as         rate increase the overall realism of the facial expression but
many per-participant and per-item random adjustments to            has no impact on the perceived humanness of the avatar.
the fixed effects (“random slopes”) until the model failed to      Previous studies in which participants rated faces on a
converge. The full model included random slopes for Prime,         desktop computer had suggested this relationship (Looser &
                                                               2354

                                                                                                           0.25
Table 2. Summary of fixed effects in the mixed logit model
                                                                      Proportion of Passives Responses
                                                                                                                          Human
    for the response choices based on prime structure.                                                     0.20
                                                                                                                          VE
    Predictor    coefficient    SE     Wald Z       p                                                      0.15
   Intercept       -3.38        0.31   -10.87     < .001   ***
                                                                                                           0.10
   (baseline)
   Passive          1.55        0.21    7.41      < .001   ***
                                                                                                           0.05
   Prime
   Active          -0.27        0.19    -1.43      .152                                                    0.00
   Prime                                                                                                                  Active                     Baseline                  Passive
                                                                                                                                                   Prime Type
  Partner          -0.17      0.20     -0.90       .366
  Type
                                                                      Figure 3. Proportion of passive responses per prime type.
  Note: N = 4019, log-likelihood = -1148.28
                                                                      There is no significant difference in syntactic priming effects
Wheatley, 2010) but it had yet to be verified in an immersive         in the Human and VE block. Passive production increases
environment such as VR.                                               with 12.3% for the Human block and 12.6% for the VE block
   The results of Experiment 2 show comparable syntactic              following a passive prime compared to the baseline condition.
priming effects when participants interacted with a human             production, it suggests the possibility that other behaviours
partner compared to an avatar partner.                                may also be consistent between VE and the real world.
   Three findings provide converging evidence that language           This provides a strong argument in favor of the use of
behaviour was similar when interacting with an avatar and             VR to investigate interaction behaviour in the field of
human: i). Syntactic priming effects were found in the VE as          psycholinguistics.
well as the Human block and the size of these effects did not           The use of a confederate is a key requirement when
differ; ii). In line with the literature, syntactic priming effects   studying dialogue, yet it is also a limitation for a variety of
showed an inverse preference effect (syntactic priming effects        reasons. Firstly, it is impossible for the confederate to behave
for passives, not for actives (Bock, 1986; Ferreira, 2003)) and       exactly the same (for example, maintaining the same tone
a lexical boost (larger syntactic priming effects when the verb       and speech rate), thereby causing between-subject variability.
between prime and target was repeated (Branigan, Pickering,           Additionally, the use of a human confederate also limits the
& Cleland, 2000)) and these again did not differ between              type of scenarios one can create.
the VE and Human block; and iii). Participants’ priming                 Both of these challenges can be overcome by replacing the
effect when interacting with a human was correlated with              confederate with a recording played on a desktop computer.
participants’ priming effects when interacting with the avatar.       This ensures that speech characteristics are kept consistent
   Our results therefore suggest that humans interacting with         across sessions and also allows more finely controlled voice
an avatar elicit the same language behaviour as if they were          manipulations (such as elongating vowels or decreasing pitch
interacting with a human partner. We are attributing this             range). Many studies have replicated priming behaviour in
finding to the humanness of the avatar. One limitation is             participants interacting with a desktop-computer module
that we have not manipulated the humanness of the avatar              (Branigan et al., 2010; Branigan et al., 2003; Weatherholtz,
in Experiment 2. Therefore, we are currently measuring the
influences of a low-humanness avatar on language behaviour
                                                                                                                              Human                                       VE
                                                                      Proportion of Passive Responses
in order to further support our claim.                                                                   1.0
   Although this study only provides evidence for syntactic                                              0.8
                                                                                                         0.6
Table 3. Summary of fixed effects in the mixed logit model                                               0.4
    for the response choices based on verb repetition.                                                   0.2
                                                                                                         0.0
                                                                                                                    Passive               Active                Passive          Active
    Predictor     coefficient    SE     Wald Z       p                                                                                             Prime Type
                                                                                                        Verb Repetition       No Verb Repetition
   Intercept        -0.71       0.26     -2.71     .0068   **
   (baseline)                                                         Figure 4. Proportion of passive responses with verb
   Verb              1.45       0.13    10.83     < .001 ***          repetition and without verb repetition for each block. The
   Repetition                                                         influence of verb repetition on passive target response is the
  Partner          -0.003     0.16      -0.02      .983               same for Humand and VE block. In both cases, there were
  Type                                                                no passive responses with verb repetition following an active
 Note: N = 1400, log-likelihood = -565.72                             prime.
                                                                  2355

                          0.70                                                               of the Cognitive Science Society, 186–191.
                          0.60                                                             Casasanto, L. S., Jasmin, K., & Casasanto, D. (1996).
                                                                                             Virtually accommodating: Speech rate accommodation
  Proportion of Priming
                          0.50
                                                                   R² = 0.3777               to a virtual interlocutor. Proceedings of the 32nd Annual
                          0.40
                                                                                             Conference of the Cognitive Science Society, 127–132.
      in VE Block
                          0.30                                                             Ferreira, V. S. (2003). The persistence of optional
                          0.20                                                               complementizer production: Why saying “that” is not
                          0.10                                                               saying “that” at all. Journal of Memory and Language,
                                                                                             48(2), 379–398.
-0.10                         0.00   0.10       0.20        0.30          0.40   0.50      Giles, H., Coupland, J., & Coupland, N. (1991). Contexts of
                          -0.10        Proportion of Priming in Human Block                  accommodation: Developments in applied sociolinguistics.
                                                                                             Cambridge University Press.
Figure 5. Correlation of passive priming effect between                                    Giles, H., Henwood, K., Coupland, N., Harriman, J., &
blocks. There is a significant positive correlation between the                              Coupland, J. (1992). Language attitudes and cognitive
passive priming effects seen in the Human and VE block.                                      mediation. Human Communication Research, 18(4), 500–
Campbell-Kibler, & Jaeger, 2012), and therefore desktops                                     527.
have provided a temporary solution.                                                        Giles, H., & Powesland, P. F. (1975). Speech styles and social
  However, advancements in interaction research are                                          evaluation. Academic Press.
severely hampered due to limitations in the scenarios we can                               Looser, C. E., & Wheatley, T. (2010). The tipping point of
create in the real world or using desktop computers. A key                                   animacy. How, when, and where we perceive life in a face.
example is the ability to realistically edit the external features                           Psychological Science, 21(12), 1854–62.
of the confederate, such as manipulating facial expressions                                Nass, C., & Moon, Y. (2000). Machines and Mindlessness:
or even more subtle changes such as varying pupil diameter.                                  Social Responses to Computers. Journal of Social Issues,
Manipulations such as these allow investigations into the                                    56(1), 81–103.
social influences on dialogue behaviour, for example does                                  Pickering, M. J., & Garrod, S. (2004). Toward a mechanistic
the attractiveness or perceived similarity (Balcetis & Dale,                                 psychology of dialogue. Behavioural and Brain Sciences,
2012) of your partner affect your word choice. These                                         27, 169–225.
questions cannot easily be answered using other techniques,                                Rizzo, A., Schultheis, M., Kerns, K. A., & Mateer, C.
and therefore VR provides an important platform on which                                     (2004). Analysis of assets for virtual reality applications
previously unanswerable questions can now be investigated.                                   in neuropsychology. Neuropsychological Rehabilitation,
                                                                                             14(1-2), 207–239.
                                     Acknowledgments                                       Segaert, K., Menenti, L., Weber, K., & Hagoort, P. (2011).
                                                                                             A paradox of syntactic priming: why response tendencies
We would like to thank our confederate Nadine de Rue for                                     show priming for passives, and response latencies show
playing the same game 33 times without complaint.
                                                                                             priming for actives. PloS one, 6(10).
                                                                                           Stivers, T., Enfield, N. J., Brown, P., Englert, C., Hayashi, M.,
                                            References                                       Heinemann, T., Hoymann, G., et al. (2009). Universals and
Balcetis, E. E., & Dale, R. (2012). An Exploration of Social                                 cultural variation in turn-taking in conversation, 106(26),
  Modulation of Syntactic Priming. Proceedings of the 27th                                   10587–10592.
  Annual Meeting of the Cognitive Science Society.                                         Stoyanchev, S., & Stent, A. (2009a). Lexical and syntactic
Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013)                                   priming and their impact in deployed spoken dialog
  Random effects structure for confirmatory hypothesis                                       systems. Proceedings of NAACL HLT 2009: Short Papers,
  testing: Keep it maximal. Journal of Memory and                                            189-912.
  Language, 68, 255-278.                                                                   Stoyanchev, S., & Stent, A. (2009b). Concept form adaptation
Bock, J. K. (1986). Syntactic Persistence in Language                                        in human-computer dialog. Proceedings of SIGDIAL 2009:
  Production. Cognitive Psychology, 18, 355–387.                                             the 10th Annual Meeting of the Special Interest Group in
Branigan, H. P., Pickering, M. J., & Cleland, A. (2000).                                     Discourse and Dialogue, 144-147.
  Syntactic co-ordination in dialogue. Cognition, 75(2),                                   Tarr, M. J., & Warren, W. H. (2002). Virtual reality in
  B13–25.                                                                                    behavioral neuroscience and beyond. Nature Neuroscience
Branigan, H. P., Pickering, M. J., Pearson, J., & McLean,                                    Supplement, 5, 1089–1092.
  J. F. (2010). Linguistic alignment between people and                                    Weatherholtz, K., Campbell-Kibler, K., & Jaeger, T. F. (2012).
  computers. Journal of Pragmatics, 42(9), 2355–2368.                                        Syntactic alignment is mediated by social perception and
Branigan, H. P., Pickering, M. J., Pearson, J., McLean, J.                                   conflict management. Architectures and mechanisms for
  F., & Nass, C. I. (2003). Syntactic Alignment Between                                      language processing (AMLaP 2012).
  Computers and People : The Role of Belief about Mental
  States. Proceedings of the Twenty-fifth Annual Conference
                                                                                        2356

