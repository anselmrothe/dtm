UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Toward Boundedly Rational Analysis
Permalink
https://escholarship.org/uc/item/7678k378
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Icard, Thomas
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                         Toward Boundedly Rational Analysis
                                                     Thomas Icard (icard@cmu.edu)
                                                  Department of Philosophy, Baker Hall 135
                                             Carnegie Mellon, Pittsburgh, PA 15213-3890 USA
                               Abstract                                       Anderson (1990) proposed his often-rehearsed six steps
                                                                           comprising the rational analysis strategy:
   The Bayesian program in cognitive science has been subject to
   criticism, due in part to puzzles about the role of rationality and    1. Precisely specify the goals of the cognitive system.
   approximation. While somewhat sympathetic with these con-
   cerns, I propose that a thoroughgoing boundedly rational anal-         2. Develop a formal model of the environment to which the
   ysis strategy can answer to some of them. Through simulation               system is adapted.
   results I illustrate the method by showing how one can retrod-
   ict recently reported results about particle filter models of cat-     3. Make minimal assumptions on computational limitations.
   egorization (Sanborn et al., 2010). I also introduce new obsta-
   cles that surface once we take bounded rationality seriously.          4. Derive the optimal behavior given items 1 through 3.
   Specifically, again through simulation, I show that the analy-
   sis of optimal sampling from Vul et al. (2014) is interestingly        5. Examine the empirical literature to see if the predictions of
   complicated by the introduction of agents capable of metarea-              the behavioral function are confirmed.
   soning. Under broad conditions, such agents outperform all
   uniform k-sampling agents. This motivates the computational            6. If the predictions are off, iterate.
   study of boundedly rational metareasoning in its own right.
                                                                           He then illustrated the methodology with four example do-
   Keywords: rational analysis, bounded rationality, algorithmic
   level, sampling, categorization, metareasoning.                         mains: memory retrieval, category learning, judging causal
                                                                           strength, and problem solving (i.e., decision making). In each
             The Rational Analysis Strategy                                case, he was able to show a good fit to a wide range of data,
                                                                           demonstrating that the strategy can be successful.
The program of rational analysis, pioneered by Marr and Pog-
gio (1976), and greatly extended by Anderson (1990), seeks                 Anderson’s Rational Model of Categorization
to understand cognition in terms of rational solutions to un-
                                                                           As a running example, consider Anderson’s (1990; 1991)
derlying problems the mind is assumed to be solving. Many
                                                                           analysis of categorization. One may object to some of the
cognitive phenomena can be characterized as inference prob-
                                                                           assumptions behind the model, but categorization per se is
lems under uncertainty, where some latent state must be in-
                                                                           not our focus—it is merely intended as a useful illustration.
ferred on the basis of observed information. For such prob-
                                                                              A subject is assumed to observe a sequence of objects with
lems Bayesian methods provide a robust and well understood
                                                                           various combinations of features; upon observing a new ob-
notion of optimality or rationality (DeGroot, 2004). Bayesian
                                                                           ject, the subject needs to make an inference about an unob-
models of cognition have become increasingly popular in re-
                                                                           served feature. Let Yi be the value of the feature of interest for
cent years, and have been applied to phenomena as diverse
                                                                           the ith observed object, and let Xi be the ith vector of values
as vision, causal learning, language understanding, and in-
                                                                           for the remaining features. Let us furthermore abbreviate the
tuitive physics (see Griffiths et al. 2008; Tenenbaum et al.
                                                                           conjunction of the first n values, Y1 , . . . ,Yn and X1 , . . . , Xn , as
2011). This work typically understands inference as condi-
                                                                           YN and XN , respectively. The problem facing the subject is to
tionalization on a probability distribution assumed to capture
                                                                           infer the value of Yn , given observations of XN and YN−1 , i.e.,
the subject’s ‘intuitive model’ of the situation or domain.
                                                                           to find the value of Yn that maximizes the posterior probability
   Rational analysis, and the Bayesian instantiation thereof, is
                                                                           P(Yn | XN , YN−1 ) of Yn given XN and YN−1 .
sometimes used to show in what sense a given behavior can
be understood as rational. Even when we have a mechanistic                    Anderson argued that the ideal way to determine such
understanding of how some cognitive function works, a ratio-               probabilities would be to consider all possible clusterings of
nal analysis can shed light on why it works the way it does,               the first n objects, figuring out the probability of each, and
often generating new testable predictions (e.g., Movellan and              using the clusterings to determine the probability of Yn given
McClelland 2001). A more ambitious use of the method is in                 Xn . In other words, one must determine the value of a latent
guiding our search for mechanisms in the first place. Indeed,              variable Zn , which corresponds to a clustering of the n ob-
one of the motivations behind Marr and Poggio’s and An-                    jects observed so far. Then we can determine the posterior
derson’s proposals was to narrow down the search space of                  probabilities by summing over the possible clusterings:
cognitive models, by assuming that the right model must be
                                                                              P(Yn | XN , YN−1 ) =    ∑ P(Yn | Zn ) P(Zn | XN , YN−1 ) .          (1)
one that at least approximately solves the underlying (e.g., in-                                      Zn
ference) problem. In that way, progress on the computational
level problem (Marr, 1982)—in addition to being worthwhile                 P(Zn | XN , YN−1 ) is given in terms of Bayes Rule:
in its own right—may also promise progress in the search for
more mechanistic, biologically detailed, models of cognition.                      P(Zn | XN , YN−1 ) ∝ P(XN , YN−1 | Zn ) P(Zn ) .               (2)
                                                                       637

The first term is just the likelihood of the features given a          Rationality and Approximation: Criticisms
clustering, which we also need to compute P(Yn | Zn ) in Eq.           Despite its success in modeling diverse cognitive phenomena,
(1). It is given by a beta distribution (features are assumed to       the Bayesian program as a whole has come under criticism
be independent, conditional on a clustering):                          recently (Jones and Love, 2011; Eberhardt and Danks, 2011;
                                       #v + β                          Bowers and Davis, 2012; Marcus and Davis, 2013). My focus
                      P(Yk = v|Zn ) =          .                       here will be on two recurrent themes of this criticism.
                                       # + 2β
                                                                           In light of the intractability of computations like that in (1)
Here # is the number of objects Zn clusters together with the          above, one might wonder what role these ‘ideal Bayesian’
kth object; and #v is the number of those objects in the same          models are supposed to play. As the categorization example
cluster that have v as their Y -value.                                 demonstrates, so far as concrete mechanisms are concerned,
   The prior term for P(Zn ) has one free parameter c, the cou-        the ideal model can at best help focus our search for tractable
pling parameter, which determines how likely an object is to           models, as approximations to that ideal. Once we give up on
belong to a new clustering. The explicit form of the prior             the ideal as a model for the cognitive mechanism, however,
is rather complicated (see Anderson 1990, 1991 or Sanborn              one might reasonably worry that the link to rationality is sev-
et al. 2010); it is easiest to understand as resulting from a se-      ered. If people are approximating Bayesian solutions, then in
quential process so that clustering Zn+1 extends Zn with dis-          what sense is their behavior really Bayesian? More broadly,
tribution P(Zn+1 = j|Zn ), given by cases:                             in what sense is a Bayesian approximation rational?
   ( c·M j                                                                 This worry is coupled with a related, empirical criticism.
      (1−c)+c·n    if j assigns the new object to an old cluster       In much of the experimental data used to support Bayesian
         1−c                                                           models, the distribution of responses is shown to match the
      (1−c)+c·n    if j assigns the new object to a new cluster
                                                                       posterior distribution for the proposed model. On the face of
M j is the number of objects already in the cluster to which j         it, this looks like a disconfirmation that people’s individual
assigns the new object, according to Zn . With this prior, the         behavior is Bayesian. Assuming MAP inference is the ideal,
more often objects are categorized as part of a particular clus-       it would appear that most individual subjects are behaving
ter, the more likely new objects are to fall under that cluster.       irrationally. This raises the challenge of specifying when a
   The computations required by Eq. (1) are intractable. As            given Bayesian analysis is vindicated by the data, and when
Anderson pointed out, the number of clusterings Zn grows ex-           people’s behavior has been genuinely rationalized. If the hy-
ponentially. For n = 10, there are already 115, 975 possible           pothesis that people are (in an appropriate sense) Bayesian is
clusterings, making the sum in Eq. (1) prohibitive in all but          to be falsifiable, it must be possible to find instances where a
the simplest of cases. This is not an atypical feature of ‘ide-        Bayesian analysis would be inappropriate.
ally rational’ Bayesian models. Step 3 of the methodology
above says to make minimal assumptions on such limitations.                             The Sampling Hypothesis
In addition to the constraint that the required computations           These criticisms have been partially addressed by a line of
should be tractable, Anderson also assumed that at any given           work proposing that people do not explicitly calculate poste-
time, a subject ought to have settled on a particular clustering       rior distributions, but rather sample from the appropriate pos-
of objects seen so far, so that as new objects are observed, the       teriors. This Sampling Hypothesis (e.g., Vul et al. 2014) ac-
only question is how to extend that partition to include the           counts for posterior matching under the assumption that each
new object. This led him to the following proposal:                    subject in an experiment is drawing relatively few, e.g., one
   L OCAL MAP A LGORITHM: Upon observation of a new                    or two, samples from the normative posterior.
   object with features Xn , let Zn∗ be the extension of the               Moreover, this behavior can be rationalized in a certain
   current partition Zn−1 that maximizes P(Zn | XN , YN−1 ).           sense. Assuming additional samples from a distribution come
   One can then estimate P(Yn | XN , YN−1 ) by calculating:            at a cost, under certain further assumptions about the utilities
                                                                       and probabilities, Vul et al. (2014) showed that it can be opti-
     P̃(Yn | XN , YN−1 ) = P(Yn | Zn∗ ) P(Zn∗ | XN , YN−1 ) .  (3)     mal to draw only a single sample before making a decision.
That is, instead of summing over all partitions every time one             In addition to the generic posterior matching phenomenon,
needs to make a prediction, Anderson’s local algorithm has             concrete sampling algorithms, e.g., based on Markov chain
the subject deterministically choosing the maximum a poste-            Monte Carlo, have been used to explain more specific cog-
riori (MAP) partition following each new data point. Eq. (3)           nitive phenomena (for many references, see Griffiths et al.
is supposed to be a tractable version of Eq. (1).                      2008; Tenenbaum et al. 2011), including in categorization.
   Anderson showed that his local MAP algorithm was able                   Sanborn et al. (2010), for example, showed that the fit
to account for a wide array of empirical phenomena collected           of Anderson’s model to the data on categorization could be
from over two decades of work on categorization, including             improved by replacing his Local MAP Algorithm with one
order effects, prototype effects, the relative ease of learning        based on the particle filter. Instead of choosing the MAP
different categories of Boolean concepts, and several more             clustering at each stage, the subject maintains at any given
(see Anderson 1990, 1991 for discussion).                              time a set of R ‘particles’, each corresponding to a clustering,
                                                                   638

and bases inferences on the whole set:                                  reasonable, however. Sometimes, once computational costs
                                                                        are properly taken into account, the optimal algorithm looks
    PARTICLE F ILTER A LGORITHM (S ANBORN ET AL .):                     nothing like the ideal model or any straightforward approxi-
    Upon observation of a new object with features Xn , draw            mation thereto (examples to follow).
                (1)       (R)
    samples Zn , . . . , Zn from P(Zn | XN , YN−1 ). One can               One of the primary messages of this paper is that, once we
    then approximate P(Yn | XN , YN−1 ) by calculating:                 take costs seriously, we should no longer think of the ‘prob-
                            R                                           lem being solved’ as being one of pure inference, inherited
                                     (r)      (r)
  P̃(Yn | XN , YN−1 ) =    ∑ P(Yn | Zn   ) P(Zn | XN , YN−1 ) . (4)     from the computational level; instead we should think of the
                           r=1
                                                                        algorithmic problem to be solved as one of constraint opti-
They compared the MAP Algorithm with the cases of R = 1                 mization: make the best guess subject to memory, time, en-
and R = 100 particles. For several empirical findings, all three        ergy, and other cost constraints. This idea is of course familiar
provided a good fit. For order effects, the single-particle-            from early work by Simon (1957), and emphasized by many
filter and the MAP algorithm were closer to the human data              since (e.g., Gigerenzer and Goldstein 1996). The ideal model
than the 100-particle-filter. However, one characteristic of a          in (1) epitomizes what Simon referred to as a substantively ra-
particle filter with few particles—not possessed by the MAP             tional solution. What we want, as part of a rational analysis,
algorithm—is its ability to predict individual variation. In            is a boundedly rational, or procedurally rational, solution.
line with the posterior matching behavior described above,
when two clusterings Z and Z 0 have roughly equal probabil-             Sketch of a Theory of Bounded Rationality
ity, but that of Z is marginally higher, the MAP algorithm              Let us model an agent’s environment using a prior probability
will always settle on Z, while the R-particle-filter will noisily       distribution P(H) over latent states of the world H, together
choose between Z and Z 0 . This behavior is in fact borne out in        with a likelihood function P(D1 , . . . , Dn |H) for sequences of
the experiments that Anderson himself described. Thus, the              n observations. Thus, upon making the first n observations
particle filter algorithm—also touted as being more rational            D = D1 , . . . , Dn , the posterior probability for H is given by
than the MAP algorithm, as it is an approximation to the ideal          Bayes Rule: P(H|D) ∝ P(D|H) P(H) . Our agent will face
model in a precise sense—models the human data at least as              a decision problem, with some set A = {A1 , . . . , Am , . . . } of
well as the MAP algorithm, and in some ways even better.                possible actions, and a utility u(Ai , H) ∈ R for all Ai ∈ A and
Does Sampling Answer to the Criticisms?                                 each value of H. Call the initial distribution, a sequence of
                                                                        observations, and a decision problem together a scenario.
The Sampling Hypothesis goes some way toward answering
                                                                           Making no assumptions about the agent’s computational
the criticisms described above. However, it leaves some im-
                                                                        limitations, we can define an agent function α to be a mapping
portant questions unanswered. First, the result from Vul et al.
                                                                        from observations D to a distribution α(D) over A . That is,
(2014)—that it may be optimal to draw only a few samples—
                                                                        α(D) assigns a probability to each Ai ∈ A . The fitness φ of an
assumes from the start that an agent will make its decision
                                                                        agent function α is given by:
on the basis of some number of samples from a given model.
In particular, the analysis does not compare drawing samples              φ(α) =   ∑ P(H) · ∑ P(D|H) · ∑ α(D)(A j ) · u(A j , H)        (5)
from the model with any other non-sampling algorithms. Un-                          H            D            j
less we have some independent reason for assuming sampling
                                                                        Nature chooses a state H and generates some observations D
is the only candidate algorithm, this strategy does not prop-
                                                                        based on H; then the agent must take an action Ai ; the payoff
erly follow step 4 of Anderson’s program.
                                                                        is the weighted sum of utility for each of the actions it might
    The same worry applies to both the MAP and particle fil-
                                                                        take. When it exists, an optimal (highest fitness) agent func-
ter approximations to the rational model of categorization.
                                                                        tion α∗ is one that never chooses an action Ai whose expected
Anderson (1991) made some informal remarks about why
                                                                        utility under the posterior distribution (conditioned on D) is
the MAP algorithm is rational, perhaps even optimal given
                                                                        dominated by another action A j :
certain constraints (412); and Sanborn et al.’s (2010) model
is pitched as a ‘more rational approximation’ because (4)                  O PTIMAL AGENT F UNCTIONS : α∗ is optimal if for all
asymptotically converges to the ideal (1). However, neither                Ai and D: α∗ (D)(Ai ) = 0, whenever there is A j ∈ A , such
has given a convincing argument for why one or the other                   that ∑H P(H | D) u(A j , H) > ∑H P(H | D) u(Ai , H).
is rational in any sense we would care about. Why would
an agent using an approximation to the model in (1) be well             This notion of optimality captures the computational level
adapted to its environment? In particular, why would such an            problem. On Anderson’s analysis of categorization, H is the
agent be better adapted than one who uses some other algo-              state of the world, a specification of all the properties of all
rithm that does not approximate the ideally rational model?             the objects in the world. The observations are sequences of
                                                                        objects; then upon viewing a new object, the agent must act
               Boundedly Rational Analysis                              appropriately, depending on an unobserved property of this
It is commonly assumed that a computational level analysis              new object. In many cases we can simply assume that the
constrains the algorithmic level analysis. This is not always           actions correlate one-to-one with the possible values of the
                                                                    639

unobserved variable (e.g., poisonous : avoid, nutritious : con-                        d = 3, N = 3      d = 5, N = 8     d = 3, N = 30
sume), and the utility is positive for a correct guess, and zero           reflex         0.561              0.555             0.654
or negative for an incorrect guess, for example.                           MAP            0.601              0.626             0.656
   Given that most problems of interest are hard, with the as-             R=1            0.573              0.603             0.625
sociated optimal agent functions intractable, we want to study             R=2            0.596              0.623             0.629
not just abstract agent functions, but more concrete represen-             R=5            0.606              0.626             0.642
tations of agents and the actual computations they perform.               R = 10          0.608              0.640             0.662
Suppose we have fixed some class Π of programs in a given
language. We can think of programs π ∈ Π as reflecting the
                                                                       Table 1: Average payoffs for categorization agents, with d
mental steps an agent goes through in the course of receiving
                                                                       binary dimensions (i.e. features) and N observations. The
data D and deciding which action Ai to perform. Following
                                                                       coupling parameter is set to c = 0.5. In all cases, β = 1.
each new data point Dk , there is some distribution over A re-
flecting the agent’s proclivities to perform various actions, at       look discouraging. However, with a boundedly rational anal-
that point in time. In this way π refines a more abstract agent        ysis, we would take costs into account.1 Under the tentative
function απ . Let us suppose, very abstractly, that we can as-         assumption that it costs more to reduce noise than to toler-
sociate with a given program π, under a certain scenario, an           ate some noise, it may be that the difference in expected fit-
expected cost: Cπ (D). The cost-adjusted fitness of π is then:         ness is made up for by this difference in cost. Furthermore,
                      φ(π) = φ(απ ) −Cπ ,                      (6)     the 2- and 5-particle-filter agents are already competitive with
                                                                       the MAP algorithm. While Sanborn et al. did not explicitly
where Cπ = ∑H P(H) · ∑D P(D | H) ·Cπ (D) is the overall ex-
                                                                       study these agents (A. Sanborn, p.c.), it is easy to see that such
pected cost. That is, we take the fitness of the program’s asso-
                                                                       algorithms would likely provide an equally good alternative.
ciated agent function less expected costs. An agent is bound-
                                                                       Recall that in many cases, the MAP, R = 1, and R = 100 algo-
edly rational to the extent that the cost-adjusted fitness of its
                                                                       rithms all matched the data well. For the other cases, particle
program is high (cf. Russell and Subramanian 1995).
                                                                       filters with 5 or fewer particles also exhibit order effects, and
   In this setup, we can interpret Vul et al.’s (2014) results as
                                                                       would predict individual variation. At the same time, if main-
showing that, if we take Π to include the k-samplers for all k,
                                                                       taining more particles comes at a cost, this cost would have to
then for certain values of C and in certain decision problems,
                                                                       be very low for the increase from R = 5 to R = 10 particles,
the 1-sampler is most boundedly rational.
                                                                       for example, to be worth the small gain in fitness.
Boundedly Rational Categorization                                          This small study is not conclusive, but it is quite sugges-
                                                                       tive. We can tentatively conclude that, under Anderson’s own
Finding a boundedly optimal algorithm can be difficult in
                                                                       assumptions about the nature of the environment, reasonable
general. However, it is often possible to compare the (cost-
                                                                       assumptions about cost would result in a particle filter with
adjusted) fitness of algorithms in simulated environments.
                                                                       between 1 and 5 particles being boundedly rational.
For illustration, we performed a comparison between Ander-
son’s local MAP algorithm, several particle filter algorithms          Calculation versus Look-up
(R = 1, 2, 5, 10), and a baseline ‘reflex agent’, which makes
                                                                       Note that in Table 1, when N = 30 the reflex agent outper-
random predictions on new observations, and maximizes with
                                                                       forms all but the MAP agent and the 10-particle-filter agent.
respect to count frequency on previously observed objects.
                                                                       Given the simplicity of the computations this agent performs,
   Specifically, we generated sequences of data according to           we would expect it to incur low costs, and thus to be quite
the Dirichlet process described above, consisting of N objects         boundedly rational in this scenario, according to the defi-
varying along d binary dimensions, before generating a test            nition given above, perhaps the most boundedly rational of
object with some feature hidden. Each agent observes the               all six agents. In this particular categorization example, we
N objects, updating its representation at each step, and then          might not want to assume the environment will be such that
makes an inference about the hidden feature, receiving payoff          an agent will observe 30 objects before having to make a pre-
1 if correct, 0 otherwise. With parameter settings typical of          diction. However, the example makes a more general point,
the categorization experiments reported in Anderson (1990,             that if we were to assume this did capture the structure of
1991), the results are depicted in Table 1.                            the environment, our boundedly rational analysis would not
   In all scenarios, the 10-particle-filter agent is optimal. The      justify hypothesizing a more complicated agent type.
next highest performing agent is highlighted in bold. With                 Consider a different example, inspired by a recent discus-
very few observations, the 5-particle-filter outperforms the           sion in the vision literature (Maloney and Mamassian, 2009).
MAP algorithm, while we find the opposite result with more             Imagine a point estimation problem in which the underly-
observations. With an intermediate number they are on a par.
   If a rational analysis is to be guided toward the algorithm             1 It is worth mentioning that with a higher coupling parameter,
that appears most rational, and the empirical results suggest          c = 0.75, the 1-particle-filter agent does outperform the local MAP
                                                                       agent, even ignoring costs. This is because the MAP agent is more
that the 1-particle-filter provides a better fit to human data         often fooled by ‘garden path’ sequences, whereas the particle filter
than the MAP algorithm, then these simulation results may              has some chance of escaping them (cf. Sanborn et al. 2010).
                                                                   640

ing state of the world is drawn from a normal distribution            fer, etc. (Tenenbaum et al., 2011), will also only surface
S ∼ N (µ, σ21 ), where µ is the mean and σ21 is the variance.         by considering iterated scenarios, in which the results from
The agent obtains a noisy reading D of S, which is also de-           one learning episode, for example, may benefit the learner
scribed by a normal distribution around the true point S, i.e.,       in a later episode. Psychologists have been keenly aware
D ∼ N (S, σ22 ), for some σ22 . With action space A = R, the          of the need for ‘inductive biases’ to model empirical learn-
utility function for making an estimate S̃ when the true value        ing dynamics. But there is a normative aspect as well, in
is S is given by the usual squared error, U(S̃, S) = −(S̃ − S)2 .     that agents exhibiting these general features will outperform
The optimal agent function is the one that maximizes fitness          agents lacking them in sufficiently broad scenarios. Impor-
according to Eq. (5) as given above (minimizing expected er-          tantly, approximations, such as sampling algorithms, inherit
ror, making the necessary adjustments to Eq. (5) for the con-         these general properties from the ideal models. A thorough-
tinuous setting). Once we consider agent programs, refining           going boundedly rational analysis would invoke such consid-
the more general agent function, several possibilities emerge.        erations to show that one or another approximation is indeed
The agent could separately represent information about the            more boundedly rational than the alternatives, if indeed it is.
state of the world and about the problem being solved and
combine them in some appropriate way. Alternatively, it is                     Boundedly Rational Metareasoning
possible for the agent to manifest the same behavior with a           Once we introduce enough uncertainty over what problem the
simpler method. Letting τ1 = 1/σ21 and τ2 = 1/σ22 —the preci-         agent will face, it becomes substantially more difficult to de-
sion of S and D, respectively (DeGroot, 2004, 38)—the op-             termine what a boundedly rational solution will look like. In
timal agent function can also be described by the following:          particular, we introduce the possibility that an agent may have
                            τ1         τ2                             the capacity to reason online about how to solve the problem
                  S̃ =           µ+         D,                        it finds itself facing; that is, we introduce the possibility of
                         τ1 + τ2    τ1 + τ2
                                                                      boundedly rational metareasoning agents. To take an exam-
as a function only of the data point D. In other words, per-          ple, in the work described above by Vul et al. (2014), there is a
forming optimally in this task requires merely being able to          single decision problem, and the analysis shows what the op-
apply a linear map of the form x 7→ a + bx.                           timal sampling strategy is for that decision problem. If there
    Simulating an agent that learns a and b through simple lin-       is uncertainty over the decision problem, it turns out a simple
ear regression, with different settings of the learning param-        metareasoner dominates all fixed k-samplers.
eter, we see how (boundedly) rational such an agent can be.              In computer simulations, we randomly drew parameters for
When the learning parameter is as high as 0.1, it does reason-        a Bayes net, a state and an observation, and then randomly
ably well after only 10 trials but soon after levels off in per-      generated a decision problem that depended on some subset
formance, remaining suboptimal. If it is set lower, e.g., near        of the (five) variables, with utilities ranging between 0 and
0.01, it takes much longer to perform well; but eventually, af-       100. A sample cost C was drawn from a normal distribution
ter about 100,000 trials, its performance is indistinguishable        with σ2 = 1.0 and µ ∼ Uniform(0, 3). We then compared
from the agent that straightforwardly computes Eq. (5) with           the performance of eight agents. The first seven drew fixed
known mean µ and variances σ21 and σ22 . If the scenario in           numbers k of (perfect) samples—1, 2, 3, 4, 5, 7, and 9—
which we are assessing agent fitness is one where training            from the network, conditioned on the observation, and then
time is cheap and trials are amply available, then this is an-        made a decision using the obvious rule from Vul et al. (2014),
other case where we would not be justified in assuming that           incurring kC reduction in utility on account of the k samples.
an agent adapted to this setting will implement something di-            The remaining metareasoning agent first applied a heuristic
rectly approximating Bayesian calculations. There would be            to determine how many samples to take. This heuristic χ was
no reason for an agent facing this environment to represent           an extremely simple stepwise function depending only on the
separate information about the world, since it can apply a very
                                                                                              
                                                                      cost of a sample:        1      if 2.5 < C ;
simple ‘look-up’ rule to decide what to do.
                                                                                              
                                                                                              
                                                                                                       if 1.5 < C < 2.5 ;
                                                                                              
                                                                                              2
                                                                                              
                                                                                              
Broader Scenarios                                                                     χ(C) = 4         if 1.0 < C < 1.5 ;
                                                                                              
In order to justify the complexity required by (even merely                                     9      if 0.5 < C < 1.0 ;
                                                                                              
                                                                                              
                                                                                              
                                                                                              
approximately) Bayesian calculations, we need to consider
                                                                                              
                                                                                              15 if C < 0.5 .
more complex scenarios, in which there is either uncertainty          The intended interpretation is that χ captures the relative im-
about the problem to be faced, a sequence of problems to be           portance of the problem compared to the cost of sampling.
faced, or both. For instance, if the categorizer may have to          Clearly, more sophisticated functions are conceivable, but this
make decisions after 3, 8, 10, 30, etc. observations, then it         is already sufficient to make the point. The results of the sim-
may be important to make accurate predictions with relatively         ulations are given in Table 2.
little data. Likewise, in the normal-normal example, the agent           Importantly, the metareasoning agent suffered the cost of
may not be able to go through 100,000 learning trials.                each sample it decided to take, but it was also charged for
    Other general features of Bayesian (and related) models,          the initial step of calculating χ(C). For the simulation re-
such as their capacity for generalization, abstraction, trans-        sults reported in Table 2, the cost of this step was assumed
                                                                  641

                                   average utility                                           References
                     1-sampler          65.6                        Anderson, J. R. (1990). The Adaptive Character of Thought.
                     2-sampler          67.4                           Lawrence Earlbaum Associates, Inc.
                     3-sampler          67.4                        Anderson, J. R. (1991). The adaptive nature of human cate-
                     4-sampler          66.8                           gorization. Psychological Review, 98(3):409–429.
                     5-sampler          65.9                        Bowers, J. S. and Davis, C. J. (2012). Bayesian just-so stories
                     7-sampler          63.5                           in psychology and neuroscience. Psychological Bulletin,
                     9-sampler          61.1                           138(3):389–414.
                 metareasoner           68.5                        DeGroot, M. H. (2004). Optimal Statistical Decisions. John
                                                                       Wiley & Sons.
        Table 2: Average payoffs, out of 100,000 runs.              Eberhardt, F. and Danks, D. (2011). Confirmation in the cog-
                                                                       nitive sciences: The problematic case of Bayesian models.
to be equal to the cost of a single sample, which is arguably          Minds and Machines, 21(3):389–410.
quite uncharitable for a simple step-function. Nonetheless,         Gigerenzer, G. and Goldstein, D. G. (1996). Reasoning the
the metareasoner still performed significantly better. We also         fast and frugal way: Models of bounded rationality. Psy-
ran 100,000 iterations without charging for the preprocessing          chological Review, 103(4):650–699.
step, and in this case the metareasoner’s average utility was       Griffiths, T. L., Kemp, C., and Tenenbaum, J. B. (2008).
70.6. Thus, even if the cost of this simple preprocessing step         Bayesian models of cognition. In Sun, R., editor, The Cam-
is constantly 3.0—on average twice the cost of a sample (av-           bridge Handbook of Computational Cognitive Modeling,
erage sample cost is 1.5)—the metareasoner still outperforms           pages 59–100. Cambridge University Press.
the best constant samplers (the 2-sampler and 3-sampler).           Icard, T. F. (2013). The Algorithmic Mind: A Study of Infer-
   In a broader scenario with multiple problems, if we include         ence in Action. PhD thesis, Stanford University.
a metareasoner among the possible agents, it turns out to be
                                                                    Jones, M. and Love, B. C. (2011). Bayesian Fundamentalism
optimal. Tellingly, Vul et al. (2014) found that people appar-
                                                                       or Enlightenment? On the explanatory status and theoreti-
ently do strategically adjust the number of samples they draw.
                                                                       cal contributions of Bayesian models of cognition. Behav-
                                                                       ioral and Brain Sciences, 34(4):169–231.
                           Conclusion
                                                                    Maloney, L. T. and Mamassian, P. (2009). Bayesian deci-
We have proposed a boundedly rational analysis strategy, as            sion theory as a model of human visual perception: Testing
a way of making progress on the search for algorithmic-level           Bayesian transfer. Visual Neuroscience, 26:147–155.
models. This strategy promises answers to some common               Marcus, G. F. and Davis, E. (2013). How robust are prob-
criticisms of Bayesian models in cognitive science. In the             abilistic models of higher-level cognition? Psychological
case of categorization, we have seen that such an analysis can         Science, 24(12):2351–2360.
retrodict the result observed by Sanborn et al. (2010) that a
                                                                    Marr, D. (1982). Vision. W.H. Freeman and Company.
particle filter with few particles models the human data better
                                                                    Marr, D. and Poggio, T. (1976). From understanding compu-
than the ‘ideal’ model or Anderson’s (1990; 1991) alternative.
                                                                       tation to understanding neural circuitry. MIT A.I. Memo
   The strategy requires taking a broad view of what bounded
                                                                       357.
(instrumental) rationality means, and considering more ex-
tended scenarios in which agent performance is compared.            Movellan, J. R. and McClelland, J. L. (2001). The Morton-
This will not preclude (approximate) Bayesian analyses—on              Massaro Law of Information Integration: Implications for
the contrary, I would conjecture—but it will not presuppose            models of perception. Psychological Review, 108:113–
them either. While this is arguably necessary to respond fully         148.
to the criticisms, it also poses new challenges and avenues for     Russell, S. and Subramanian, D. (1995). Provably bounded-
research. Specifically, we saw the need to consider metarea-           optimal agents. Journal of Artificial Intelligence Research,
soners in the space of possible agent algorithms. Does this            2:1–36.
open the door to an unmanageable search space, spoiling the         Sanborn, A. N., Griffiths, T. L., and Navarro, D. J. (2010).
apparent advantage of invoking rational analysis as a search           Rational approximations to rational models: Alternative
strategy? To close, I would like to suggest that here, as else-        algorithms for category learning. Psychological Review,
where in cognitive science, we can divide and conquer: per-            117(4):1144–1167.
haps computational cognitive science ought to take this kind        Simon, H. A. (1957). Models of Man. Wiley.
of metareasoning as an object of study in its own right.            Tenenbaum, J. T., Kemp, C., Griffiths, T. L., and Goodman,
                                                                       N. D. (2011). How to grow a mind: Statistics, structure,
                     Acknowledgements                                  and abstraction. Science, 331:1279–1285.
This paper draws from my Ph.D. thesis (Icard, 2013). I would        Vul, E., Goodman, N. D., Griffiths, T. L., and Tenenbaum,
like to thank my committee, and David Danks, for helpful               J. B. (2014). One and done? Optimal decisions from very
conversations, and the conference reviewers for comments.              few samples. Cognitive Science. forthcoming.
                                                                642

