UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Unsupervised Clustering of Morphologically Related Chinese Words
Permalink
https://escholarship.org/uc/item/5fx3k5k4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Lee, Chia-Ling
Chang, Ya-Ning
Liu, Chao-Lin
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             Unsupervised Clustering of Morphologically Related Chinese Words
                                               Chia-Ling Lee (r00922072@ntu.edu.tw)
                                     Department of Computer Science and Information Engineering,
                                                 National Taiwan University, Taipei, Taiwan
                                        Ya-Ning Chang (yaningchang@gate.sinica.edu.tw)
                                                            Institute of Linguistics,
                                                      Academia Sinica, Taipei, Taiwan
                                                 Chao-Lin Liu (chaolin@nccu.edu.tw)
                                                     Department of Computer Science,
                                                National Chengchi University, Taipei, Taiwan
                                           Chia-Ying Lee (chiaying@gate.sinica.edu.tw)
                                                            Institute of Linguistics,
                                                      Academia Sinica, Taipei, Taiwan
                                            Jane Yung-jen Hsu (yjhsu@csie.ntu.edu.tw)
                                     Department of Computer Science and Information Engineering,
                                                 National Taiwan University, Taipei, Taiwan
                              Abstract                                     words can facilitate Chinese word sense disambiguation and
   Many linguists consider morphological awareness a major                 help improve Chinese word segmentation (Navigli, 2009).
   factor that affects children’s reading development. A Chi-                 In this research, we employ natural language processing
   nese character embedded in different compound words may                 and computational linguistics techniques to differentiate the
   carry related but different meanings. For example, “商                   meanings of a particular character that is embedded in differ-
   店(store)”, “商品(commodity)”, “商代(Shang Dynasty)”, and
                                                                           ent Chinese words. We apply different methods which take
   “商朝(Shang Dynasty)” can form two clusters: {“商店”, “商
   品”} and {“商代”, “商朝”}. In this paper, we aim at unsuper-                 diverse factors into account, such as grammar, syntax, seman-
   vised clustering of a given family of morphologically related           tics, and context. We also aggregate all methods and build
   Chinese words. Successfully differentiating these words can             a better ensemble model. Furthermore, we conduct another
   contribute to both computer assisted Chinese learning and nat-
   ural language understanding. In Experiment 1, we employed               experiment in which we asked adults and children to do the
   linguistic factors at the word, syntactic, semantic, and contex-        same clustering task. Experimental results indicate that our
   tual levels in aggregated computational linguistics methods to          model can achieve the same level of performance as children
   handle the clustering task. In Experiment 2, we recruited adults
   and children to perform the clustering task. Experimental re-           in the clustering task.
   sults indicate that our computational model achieved the same              There is previous work related to morphological aware-
   level of performance as children.                                       ness. Wang, Hsu, Tien, and Pomplun (2012) predicted raters’
   Keywords: morphological awareness; human cognition; com-                transparency judgments of Chinese morphological character
   putational linguistics; Chinese character meaning
                                                                           based on latent semantic analysis (LSA) (Landauer, Foltz, &
                           Introduction                                    Laham, 1998). If a word is more similar to the primary mean-
                                                                           ing, it is more likely to be judged as semantically transparent,
Morphological awareness, defined as “children’s conscious
                                                                           and opaque otherwise.
awareness of the morphemic structure of words and their abil-
                                                                               Galmar and Chen (2010) tried to identify different mean-
ity to reflect on and manipulate that structure”, is associated
                                                                           ings of a Chinese character using LSA and semantic pat-
with children’s reading ability and comprehension (Liu &
                                                                           tern matching in augmented minimum spanning tree. Galmar
McBride-Chang, 2010; Kirby et al., 2012; Ku & Anderson,
                                                                           (2011) built a term-by-document matrix, and used the batch
2003). It is thought by many linguists to strongly affect read-
                                                                           version of self-organizing maps (Kohonen, 2001) to visualize
ing development in children (Liu & McBride-Chang, 2010).
                                                                           the interplay between morphology and semantics in Chinese
   A Chinese character embedded in different compound
                                                                           words.
words may carry related but different meanings. For exam-
                                                                              To discriminate Chinese character meanings, in addi-
ple, the meaning of the character “商/shang1/” in words“商
                                                                           tion to LSA techniques, we consider diverse information
店(store)” and “商品(commodity)” is commerce. In contrast,
                                                                           from comprehensive aspects. There are numerous word-to-
in “商代(Shang Dynasty)”, “商” refers to a Chinese dynasty.
                                                                           word semantic similarity or relatedness measures proposed
Successful clustering of related Chinese words would make
                                                                           in the past. In knowledge-based approaches, WordNet1 was
a contribution to Chinese learning. In addition, differentiat-
ing the character’s meanings in such morphologically related                   1 http://wordnet.princeton.edu
                                                                      2543

widely used (Pedersen, Patwardhan, & Michelizzi, 2004;
                                                                                                    target words of a
Patwardhan & Pedersen, 2006; Mihalcea, Corley, & Strap-                                            morphological family
                                                                                                                                 INPUT
parava, 2006). To compute word-to-word semantic sim-
ilarity, syntactic dependency (Lin, 1997; Padó & Lapata,
                                                                                                      word-to-word
2007), information content of the common subsumer of con-                                           similarity matrices
cepts (Resnik, 1995), and shortest path length between two
concepts (Leacock & Chodorow, 1998) were used. In ad-
dition to WordNet, some adopted HowNet2 as a knowledge                                                  ensemble
                                                                                                     similarity matrix
base for Chinese (Dai, Liu, Xia, & Wu, 2008). For corpus-
based approaches, perhaps the commonest one is the LSA.
For recognizing synonyms, Turney (2001) used pointwise                                               clustering result          OUTPUT
mutual information and information retrieval to measure the
similarity of pairs of words. Additionally, for taking statistics
and co-occurrence into account, Jaccard coefficient, Simpson
                                                                                  Figure 1: The framework of Experiment 1.
coefficient, and Dice coefficient are measured (Manning &
Schütze, 1999; Jackson, Somers, & Harvey, 1989)
                                                                      To begin with, we estimate word-to-word semantic similari-
                           Methods                                    ties. In this paper, we apply LSA and propose three different
Notations and Problem Definition                                      methods, which are elaborated as following. In each method,
                                                                      a word w is represented by a feature vector V (w). The simi-
We first introduce terminologies and notations used in this           larity is determined by cosine similarity:
paper. We denote a Chinese character by c, a word by w.
 f amily(c) is a set of Chinese words in which all words con-                          Simvec (wi , w j ) = cos(V (wi ),V (w j )).
tain a common character c. We call f amily(c) a morpholog-
ical family of a Chinese character c, each word in that set              LSA: LSA has been widely used in natural language pro-
a target word, and the shared character c a target character.         cessing, text mining, and information retrieval. LSA as-
Target words within a morphological family sharing the same           sumes that words with closer meaning will occur in similar
target character meaning compose a meaning group.                     documents. From our corpus, we first construct a term-by-
    Given a set of Chinese words, f amily(c), our goal is to dif-     document matrix T . The value of a cell Ti j is the normalized
ferentiate meanings of the target character c in each word and        frequency of word wi shown in a document d j . After pre-
to group them into clusters. Take the morphological family of         processing, truncated singular value decomposition (Golub &
“商” for example, the set {“商店”, “商品”, “商代”, “商朝”}                     Reinsch, 1970) is used to reduce the dimensions of T . In our
could be separated into two clusters: {“商店”, “商品”} and                case, we reduce to 100 dimensions. Each value of the feature
{“商代”, “商朝”}. This is because that the character “商”                  vector is mapped to a so-called latent topic. Thus, we get a
in both words within first cluster are related to commerce or         latent semantic feature vector Vlsa (w) for a target word w.
business whereas the meaning of the same character in the                Document: In this method, we would like to capture
second cluster is a dynasty in China history. In our work, we         document-category level context of a word. That is to say, we
assume a character has only one meaning in each word.                 view the category of the document where a target word occurs
                                                                      as a feature. We construct a matrix D where a row dimension
Experiment 1                                                          represents a target word and a column dimension is a type of a
                                                                      document. The value of a cell is the normalized frequency of
Framework Figure 1 illustrates the framework of Experi-
                                                                      a target word occurring in the corresponding document type.
ment 1. First, given a morphological family, we apply a cou-
                                                                      In our corpus, there is a total of 90 genres, styles, and topics.
ple of methods to calculate similarities between target words.
                                                                      A feature vector of the target word wi , Vdoc (wi ), is denoted by
In each method, we use different features to calculate similar-
                                                                      (Di,1 , Di,2 , ..., Di,90 ).
ity between words and get corresponding similarity matrices.
Given these matrices, we are able to ensemble them, and get              Relation: To the sentence level, we would also like to
an ensemble matrix. The final step is to cluster target words         know the relation between words in a sentence. Through the
by using a hierarchical clustering algorithm. In the end, we          tool of Stanford Parser3 , which provides the grammatical re-
get a clustering result of morphologically related words.             lations between words, a sentence could be parsed and repre-
                                                                      sented as several Stanford typed dependencies. The tool sup-
Word-to-word Similarity Harris (1954) proposed a hy-                  ports Chinese as well. A typed dependency is a triplet: name
pothesis that “words that occur in similar contexts tend to           of the relation, governor and dependent. Name of the relation
have similar meanings.” In Chinese compounds, a constituent           is what we focus on now. Take the sentence, “I love you.”, for
character provides some clues to the semantic of a compound.          example, one of dependencies is nsubj(love, I), which means
    2 http://www.keenage.com                                              3 http://nlp.stanford.edu/software/lex-parser.shtml
                                                                  2544

that the dependent “I” is a nominal subject of the governor            tween clusters is defined as below.
“love” and their relation is “nsubj”. We count how frequently                                                           sim(wi , w j )
a target word plays a role of a dependent in each kind of rela-                  simcluster (Ca ,Cb ) =      ∑
                                                                                                        wi ∈Ca ,w j ∈Cb   |Ca ||Cb |
tion. A grammatical feature vector Vrel (w) is generated.
   POS: Additionally, we are interested in another syntactic           We finally apply HAC on the matrix Mensemble and get a clus-
feature: part-of-speech (POS), such as noun, verb, adjective,          tering result.
etc. From segmented texts with POS tags, we construct a
matrix where column dimensions are POS tags and each row i
is mapped to a target word wi . Likewise, the value of a matrix
cell is the normalized frequency that a word is tagged by the
corresponding POS tag in a text. A syntactic feature vector of
a target word wi , Vpos (wi ), reflects a distribution of POS tags
of the word. We expect that two similar target words have
similar distributions of POS tags in a corpus.
Ensemble Until now, we have taken various aspects into
consideration, including semantic, topical, grammatical, and
syntactic. For each method, we generate one word-to-word
similarity matrix. Next step is to integrate them.
   Source of ensemble approach comes from these m similar-
ity matrices. Here, we denote a similarity matrix by M. We
then aggregate the similarity matrices by accumulating them                    Figure 2: Cluster dendrogram of f amily(“商”)
with different weights. The idea of this approach is that if
two words are similar in many aspects, there should be more            Experiment 2
matrices giving this pair a high similarity score, and the re-
                                                                       Participants What about human performance on our clus-
sultant score will be higher comparatively. Through weighted
                                                                       tering task and how does it compare with our computational
accumulation, scores of similar and dissimilar words will be
                                                                       results? In Experiment 2, we asked two groups of partici-
distanced. The aggregated matrix is defined mathematically
                                                                       pants, 14 adults and 9 children, to perform the clustering task.
as:
                                                                       14 adults were graduate students recruited from National Tai-
                                  1 m
                  Mensemble = ∑ (ωi × Mi )                             wan University and Academia Sinica. All were native speak-
                                 m i=1
                                                                       ers of Chinese. Child group consists of 9 children from fifth
where ωi is the weight of the word-to-word similarity of               to sixth grade of primary school students.
method i.                                                              Materials and procedure In adult group, a task of clus-
Clustering The objective of clustering is to group similar             tering of morphologically related Chinese words was com-
words together and separate dissimilar words into different            pleted by using a questionnaire. The questionnaire included
clusters. Clustering algorithms are classified into three main         11 morphological families. In each family, all target words
categories: hierarchical, partitional, and hybrid. Although a          were listed and participants were asked to group morphologi-
partitional clustering method (e.g., K-means) runs faster since        cally related words into clusters. The number of clusters were
it does not need to compare all pairs of items, the number of          not limited.
clusters is usually required to be given. In our case, the num-           In child group, instead of a questionnaire, we gave them
ber of clusters is not determined in advance, we thus employ           word cards to reduce task difficulty. For each target word in
a hierarchical agglomerative clustering (HAC) algorithm in             all 11 families, we made a word card with notional phonetic
this work.                                                             alphabets. Since our task of clustering is not very easy for
   When HAC starts, each target word is viewed as a sin-               most children, we separated the task into two stages. In each
gleton cluster. At each iteration, two most similar clusters           stage, a kid was asked to finish 4 to 7 families. Moreover,
are merged. We run iteratively until clusters similarity score         during the task, if they did not know a target word, we would
reaches a predefined threshold θ. We set θ to 0.15 based on            ask them to guess or put it to another group named “I do not
some pilot trials. If a similarity of two clusters is greater          know.” When evaluating, we would view each target word in
than the threshold, they will be merged and become a new               that group as a single cluster. (Among 285 target words, 8%
cluster. When no new cluster could be produced, the out-               words were not recognized on average per child.)
come is generated. Figure 2 illustrates a cluster dendrogram
of f amily(“商”). It demonstrates how HAC works on the tar-
                                                                                                     Results
get words of “商”.                                                      Corpus and Dataset
   Average link is adopted to estimate similarity between two          The corpus we used is the Academia Sinica Balanced Cor-
clusters. Given two clusters, Ca and Cb , the similarity be-           pus (ASBC) version 3 (Huang & Chen, 1998). ASBC is a
                                                                   2545

                                                                     sion of assigning two words to the same cluster. Mutual in-
Table 1: An example of easy-degree morphological fami-
                                                                     formation measures the amount of information by which our
lies, f amily(“商”). High-frequency target words are shown
                                                                     knowledge about the classes increases when we are told what
in boldface.
                                                                     the clusters are. Normalization is required to penalize large
  Target        Target Words                Meaning of target        cardinalities which will cause high mutual information.
  character                                 character                   However, we found a trend that we did not expect. In terms
  商/shang1/ 商 標, 商 務 , 商 品, 商               things      related      of F1, when the threshold θ of HAC increased, meaning that
                店 , 商 人, 商 場 , 商譽,          to commerce or           a larger number of clusters, F1 became worse. In contrast,
                商埠, 商船                      business                 when evaluated with NMI, the performance improved as the
                商議, 商量, 商討                  negotiation      or      number of clusters increased. Actually the tendencies may
                                            discussion               not be difficult to understand when we look deeper into the
                商代, 商朝                      a China dynasty          definitions of F1 and MNI. When the number of clusters be-
  花/hua1/       花 卉, 花 園, 花 草, 花            things related to        comes larger, there are less and less pairs of words within a
                香 , 花 瓣, 花店, 花農,            plants                   cluster, even one-word clusters. That is to say, to a certain ex-
                花季, 花海, 花蜜, 花苞                                       tent, we lose chances to gain F1. However, maximum mutual
                火 花, 浪 花, 雪 花, 花            patterns or styles       information can be gathered when clusters are further subdi-
                樣 , 花 紋, 花邊, 花布,                                     vided into smaller clusters. These trends are more obvious
                油花, 水花, 花式, 花招                                       especially in clustering on small data sets.
                花 費 , 花 錢 , 花 用, 花          expenditure      or         To prevent the threshold dominating our performance, in
                掉, 花光                       costs                    this paper, we propose a new metric named F-NMI to address
                花蓮                          a place name             the issue particularly. We define F-NMI as α ×F1 + (1 −α)×
                                                                     NMI and set α to 0.5 in our experiments.
                                                                     Experimental Results
balanced Chinese corpus with part-of-speech tagging. Each            We averaged performances across 11 families of each method
article in the corpus is classified and marked according to five     and each human group. Table 2 summarizes the results of
criteria: genre, style, mode, topic, and medium. The corpus is       Experiments 1 and 2.
also segmented according to the word segmentation standard
proposed by Huang, Chen, and Chang (1996). ASBC con-
tains more than 9 thousands articles, near 5 millions words,         Table 2: F1, NMI, and F-NMI of Experiment 1 (computa-
and 144 thousands unique words.                                      tional methods) Experiment 2 (human clustering result)
   Our input data and ground truth were provided by psy-
cholinguistic researchers of the Institute of Linguistics,             Method     NMI        F1       F-NMI     Frequency     Difficulty
Academia Sinica. There are 11 morphological families, in-                                                       Effects       Effects
                                                                                                Experiment 1
cluding 285 target words. To test word-frequency effects,              Random     8.34%      42.54% 25.44%      5.18%         -1.29%
we separated all words into two groups based on word fre-              LSA        27.51%     45.86% 36.68%      8.85%         7.05%
quency, a threshold of 20. The high-frequency group and                Document   7.95%      50.62% 29.28%      7.86%         -2.43%
low-frequency group contain 139 and 146 target words re-               Relation   19.07%     50.01% 34.54%      6.26%         0.59%
                                                                       POS        40.85%     54.05% 47.45%      -1.97%        0.96%
spectively. We expected that the high-frequency group would            Ensemble   40.85%     60.83% 50.84%      4.66%         6.73%
have better performance than the low-frequency one. In ad-                                      Experiment 2
dition, to test difficulty effects, the psycholinguists also an-       Adult      77.49%     76.12% 76.80%      3.22%         7.90%
                                                                       Child      56.46%     54.58% 55.52%      8.08%         2.84%
notated these morphological families with two degrees of dif-
ficulty: hard and easy. Hard-degree means that it is more
difficult to discriminate the target character’s meanings. In-          As expected, the ensemble method worked best in general
versely, a target character in a easy-degree family can be dif-      since they considered various linguistic factors. It achieved
ferentiated easier. These 11 families are divided into 6 hard-       the best performances compared with other computational
degree and 5 easy-degree ones.                                       methods across all three metrics: 40.85% of NMI, 60.83%
   Two examples of morphological families, f amily(“商”)              of F1, and 50.84% of F-NMI. In addition to the ensemble
and f amily(“花”), are shown in Table 1. Each row presents            method, the POS method had prominent performances as
a meaning group and high frequency target words are printed          well. Although other methods did not have distinguished
in boldface.                                                         performances, they all outperformed a random similarity in
                                                                     terms of F-NMI. In Experiment 2, adult group achieved
Evaluation                                                           77.49% of NMI, 76.12% of F1, and 76.80% of F-NMI in
To evaluate our performance, we use two metrics: F1 and              average. It shows a high agreement with our gold standard.
normalized mutual information (NMI) (Manning & Schütze,             The child group reached 56.46% of NMI, 54.58% of F1, and
1999). F1 describes how correctly when we make a deci-               55.52% of F-NMI. It is obvious that the performance of chil-
                                                                 2546

dren is far from the adult group. Moreover, although there
was some distance away from the adult group, the ensem-
ble method (F-NMI = 50.84%, s.d. = 20.41%) reached the
same performance level with child group (F-NMI = 55.52%,
s.d. = 10.56%) in terms of F-NMI.
   Both word-frequency effects and difficulty effects are also
what we are interested in. Figure 3 illustrates frequency ef-
fects. The child group had frequency effects (N = 9, one-
tailed, p = 0.035, t = 1.95) where the F-NMI score in high-
frequency words was higher than in low-frequency. How-
ever, probably due to small samples (11 families, 14 adults),
the difference between high and low-frequency words was
not statistically significant in the adult group and ensemble
method.
                                                                     Figure 4: Difficulty effects of adult group, child group, and
                                                                     the ensemble method.
                                                                     that it is hard to discriminate a Chinese character’s mean-
                                                                     ings by concerning only one factor. For example, both “商
                                                                     店(store)” and “商品(commodity)” often appeared in articles
                                                                     about commerce or business. However, some other words
                                                                     which are assigned into the same meaning group because
                                                                     their target character provides common implicit senses to the
                                                                     words and further impact the roles of the words in a sentence.
                                                                     Take another morphological family of “生/sheng1/” for in-
                                                                     stance. Target words “醫生(doctor)”, “女生(girl; woman)”,
                                                                     “出生(born)”, and “誕生(born)”, to some degree, often oc-
                                                                     cur in medicine or gynecology-related articles. Nonetheless,
Figure 3: Frequency effects of adult group, child group, and         these words can be divided into two groups: {“醫生”, “女
the ensemble method.                                                 生”} and {“出生”, “誕生”}. In the former group, “生” means
                                                                     “person”, and it is a noun. The latter means “to give birth
   Figure 4 depicts difficulty effects. The adult group had dif-     to” and it is a verb. Thus, POS tag distribution complements
ficulty effects (N = 14, one-tailed, p = 0.023, t = 2.09) where      the factor of document category. To summarize, even though
the performance in easy-degree families was better than hard-        each single method did not have distinguished performances
degree ones. Because we only have 5 hard-degree and 6 easy-          and could be improved further, all of these methods were es-
degree families, and the variation among 11 families are con-        sential to achieve the best system performance.
siderably large, in the child group and our ensemble method,            We observe that methods that consider internal structures
the differences between hard and easy-degree families were           of the words captured the meaning of the shared character
not significant.                                                     more precisely. In addition to the ensemble method, among
                                                                     other four computational methods, the POS method worked
                          Discussion                                 the best. Specifically, the POS method had the best perfor-
In this paper, we aim at differentiating the meanings of the         mance; LSA was second to POS; next one was the Relation
character shared by different target words. We propose sev-          method, and the Document method was the worst. A POS
eral computational methods to calculate word-to-word sim-            tag provides a clue to how a word functions in a sentence.
ilarities. Not only latent semantics but also various factors,       In contrast, document category was too abstract to help us
including document category, dependency, and POS tags, are           differentiate the characters’ meanings. The relation of a de-
taken into account. Through aggregating an array of methods,         pendency provided information at the sentence level and its
the ensemble method achieved the same level of performance           performance was between the document category method and
with the child group.                                                the POS method.
   It seems that the ensemble method could provide more                 Finally, although the ensemble method could achieve sim-
comprehensive information to us for discriminating the               ilar performances as children, it is still not as good as adults.
meanings of Chinese characters, compared with other non-             Some internal structure of the word may contain more use-
ensemble methods. The results of Experiment 1 suggest                ful information and should be further explored. In the future,
                                                                 2547

Chinese character-based computational techniques can be in-          duction to latent semantic analysis. Discourse Processes,
vestigated, such as character-level syntax tree and character-       25(2-3), 259–284.
based dependency (Zhang, Zhang, Che, & Liu, 2013; Zhao,            Leacock, C., & Chodorow, M. (1998). Combining local con-
2009). Moreover, we hope to build an e-learning platform             text and WordNet similarity for word sense identification.
and apply our methods to assist teachers in teaching students        In WordNet: An electronic lexical database. MIT Press.
to learn Chinese.                                                  Lin, D. (1997). Using syntactic dependency as local con-
                                                                     text to resolve word sense ambiguity. In Proceedings of
                     Acknowledgments                                 the thirty-fifth annual meeting of the association for com-
This work was supported in part by the grants NSC 99-2221-           putational linguistics and eighth conference of the euro-
E-002-139-MY3, NSC 101-2627-E-002-002, NSC101-2221-                  pean chapter of the association for computational linguis-
E-004-018, and NSC 102-2420-H-001-006-MY2 from the                   tics (pp. 64–71). Madrid, Spain.
National Science Council, Taiwan, and NTU 102R890864               Liu, P. D., & McBride-Chang, C. (2010). What is morpho-
from National Taiwan University, Taiwan.                             logical awareness? Tapping lexical compounding aware-
                                                                     ness in Chinese third graders. Journal of Educational Psy-
                         References                                  chology, 102(1), 62–73.
                                                                   Manning, C. D., & Schütze, H. (1999). Foundations of statis-
Dai, L., Liu, B., Xia, Y., & Wu, S. (2008). Measuring seman-         tical natural language processing. Cambridge, MA: MIT
   tic similarity between words using HowNet. In Proceed-            Press.
   ings of the international conference on computer science        Mihalcea, R., Corley, C., & Strapparava, C. (2006). Corpus-
   and information technology (pp. 601–605).                         based and knowledge-based measures of text semantic sim-
Galmar, B. (2011). Using Kohonen maps of Chinese morpho-             ilarity. In Proceedings of the twenty-first conference on ar-
   logical families to visualize the interplay of morphology         tificial intelligence (Vol. 21, p. 775). Boston, MA.
   and semantics in Chinese. In Proceedings of the twenty          Navigli, R. (2009). Word sense disambiguation: A survey.
   third conference on computational linguistics and speech          ACM Computing Surveys, 41(2), 1–69.
   processing (pp. 240–251). Taipei, Taiwan.                       Padó, S., & Lapata, M. (2007). Dependency-based construc-
Galmar, B., & Chen, J.-Y. (2010). Identifying different              tion of semantic space models. Computational Linguistics,
   meanings of a Chinese morpheme through semantic pattern           33(2), 161–199.
   matching in augmented minimum spanning trees. Interna-          Patwardhan, S., & Pedersen, T. (2006). Using WordNet-
   tional Journal of Computational Linguistics and Applica-          based context vectors to estimate the semantic relatedness
   tions(1-2), 153–168.                                              of concepts. In Proceedings of the EACL workshop on mak-
Golub, G. H., & Reinsch, C. (1970). Singular value decompo-          ing sense of sense: Bringing psycholinguistics and compu-
   sition and least squares solutions. Numerische Mathematik,        tational linguistics together (pp. 1–8). Trento, Italy.
   14(5), 403–420.                                                 Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). Word-
Harris, Z. S. (1954). Distributional structure. Word, 10, 146–       Net::similarity - measuring the relatedness of concepts. In
   162.                                                              Proceedings of the nineteenth national conference on arti-
Huang, C.-R., & Chen, K.-J. (1998). Academia Sinica                  ficial intelligence (pp. 38–41). San Jose, CA.
   balanced corpus (version 3). Taipei, Taiwan: Academia           Resnik, P. (1995). Using information content to evaluate
   Sinica.                                                           semantic similarity in a taxonomy. In (pp. 448–453). Mon-
Huang, C.-R., Chen, K.-J., & Chang, L.-L. (1996). Segmen-            treal, Canada.
   tation standard for Chinese natural language processing. In     Turney, P. (2001). Mining the web for synonyms: PMI-
   Proceedings of the sixteenth conference on computational          IR versus LSA on TOEFL. In Proceedings of the twelfth
   linguistics (pp. 1045–1048).                                      european conference on machine learning (pp. 491–502).
Jackson, D. A., Somers, K. M., & Harvey, H. H. (1989).               Freiburg, Germany.
   Similarity coefficients: measures of co-occurrence and as-      Wang, H.-C., Hsu, L.-C., Tien, Y.-M., & Pomplun, M.
   sociation or simply measures of occurrence? American              (2012). Estimating semantic transparency of constituents
   Naturalist, 133(3), 436–453.                                      of English compounds and two-character Chinese words
Kirby, J. R., Deacon, S. H., Bowers, P. N., Izenberg, L.,            using latent semantic analysis. In Proceedings of annual
   Wade-Woolley, L., & Parrila, R. (2012). Children’s mor-           meeting of the cognitive science society. Sapporo, Japan.
   phological awareness and reading ability. Reading and           Zhang, M., Zhang, Y., Che, W., & Liu, T. (2013). Chinese
   Writing, 25(2), 389–410.                                          parsing exploiting characters. In 51st annual meeting of the
Kohonen, T. (2001). Self-organizing maps. Verlog, Berlin:            association for computational linguistics.
   Springer.                                                       Zhao, H. (2009). Character-level dependencies in Chinese:
Ku, Y.-M., & Anderson, R. C. (2003). Development of mor-             Usefulness and learning. In Proceedings of the 12th con-
   phological awareness in Chinese and English. Reading and          ference of the european chapter of the association for com-
   Writing: An Interdisciplinary Journal, 16(5), 399–422.            putational linguistics (pp. 879–887).
Landauer, T. K., Foltz, P. W., & Laham, D. (1998). An intro-
                                                               2548

