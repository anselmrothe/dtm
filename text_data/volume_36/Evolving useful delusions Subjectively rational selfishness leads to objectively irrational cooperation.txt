UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Evolving useful delusions: Subjectively rational selfishness leads to objectively irrational
cooperation
Permalink
https://escholarship.org/uc/item/5kw8f77n
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Kaznatcheev, Artem
Montrey, Marcel
Shultz, Thomas
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                       University of California

     Evolving useful delusions: Subjectively rational selfishness leads to
                                    objectively irrational cooperation
                           Artem Kaznatcheev (artem.kaznatcheev@mail.mcgill.ca)
                      School of Computer Science and Department of Psychology, McGill University,
                                   3480 University Street, Montreal, QC H3A 0E9 Canada
                               Marcel Montrey (marcel.montrey@mail.mcgill.ca)
                                        Department of Psychology, McGill University,
                                    1205 Penfield Avenue Montreal, QC H3A 1B1 Canada
                                  Thomas R. Shultz (thomas.shultz@mcgill.ca)
                      Department of Psychology and School of Computer Science, McGill University,
                                    1205 Penfield Avenue Montreal, QC H3A 1B1 Canada
                           Abstract                               be conscious of the fact that decisions act on internal
                                                                  representations of rewards and beliefs about the conse-
   We introduce a framework within evolutionary game
   theory for studying the distinction between objective          quences of past and future actions. There is no a priori
   and subjective rationality and apply it to the evolution       reason to believe that these internal representations are
   of cooperation on 3-regular random graphs. In our sim-         perfectly aligned with external payoffs. In fact, the ex-
   ulations, agents evolve misrepresentations of objective
   reality that help them cooperate and maintain higher           perimental field of neuroeconomics reveals that there are
   social welfare in the Prisonerâ€™s dilemma. These agents         often marked differences between the objective and sub-
   act rationally on their subjective representations of the      jective rewards that participants experience (Lee, 2008).
   world, but irrationally from the perspective of an exter-
   nal observer. We model misrepresentations as subjec-           Decisions made on the basis of these internal representa-
   tive perceptions of payoffs and quasi-magical thinking as      tions can thus appear irrational to an external observer,
   an inferential bias, finding that the former is more con-      who is naÄ±Ìˆve about the agentâ€™s mental state and only
   ducive to cooperation. This highlights the importance
   of internal representations, not just observed behavior,       aware of the external rewards. However, from the agentâ€™s
   in evolutionary thought. Our results provide support for       perspective, these actions could be rational, given the
   the interface theory of perception and suggest that the        agentâ€™s internal representation. This is the concept of
   individualâ€™s interface can serve not only the individualâ€™s
   aims, but also society as a whole, offering insight into       subjective rationality. It is reasonable to explore the
   social phenomena such as religion.                             possibility that many of these subjective representations
   Keywords: evolution; rationality; cooperation; quasi-          are shaped by evolution.
   magical thinking; perception
                                                                     To illustrate this concept, we look at cooperationâ€”the
                       Introduction                               typical proving ground for EGT. Because cooperation in-
Economic theory has traditionally assumed it impossi-             volves paying a cost so that another individual can derive
ble, or at least unreasonably difficult, to directly ob-          a benefit, cooperators risk being exploited. Often, as in
serve preferences and beliefs, preferring to assess agents        the Prisonerâ€™s dilemma (PD) game, the objectively ratio-
by their behavior. A similar tradition exists in evolu-           nal strategy is to defect rather than cooperate, because
tionary biology and ecology, where internal factors are           defection exploits cooperators and prevents exploitation
seen as secondary to the behavior that determines fitness         at the hands of other defectors. Nevertheless, humans
and thus evolutionary outcomes. Given these roots, it is          playing PD often cooperate, even when experimenters
unsurprising that evolutionary game theory (EGT) has              are careful to exclude factors that encourage coopera-
adopted a similar attitude, embracing a behavior-centric          tion (Sally, 1995; Fehr & Fischbacher, 2003). Research
approach to describing model agents. While this has               suggests that this is caused by a propensity to consider
made a great deal of theoretical work tractable, it has           extraneous subjective factors, such as uncertainty (Shafir
also made human deviations from rationality difficult to          & Tversky, 1992; Croson, 1999), irrelevant goals (Bagassi
model. Our primary goal is to overcome this limitation            & Macchi, 2006; Sun, Li, & Li, 2008), aversion to
by introducing into EGT a framework for studying dif-             inequality (Fehr & Schmidt, 1999; Fehr & Camerer,
ferences between objective and subjective experiences.            2007), discounting of future rewards (Erev & Roth,
   Of central importance to classical economic theory is          1998; Lee, Conroy, McGreevy, & Barraclough, 2004),
the simplifying assumption of rationality. In traditional         counterfactual reasoning (Lohrenz, McCabe, Camerer,
theory, this rationality is taken literally and is assumed        & Montague, 2007; Camerer, 2011), in-group favo-
to apply at the objective level of explicit payoffs and be-       ratism (Kaznatcheev, 2010; Hartshorn, Kaznatcheev, &
havior. However, if we are to model humans, we should             Shultz, 2013), and judgments of reputation (Nowak &
                                                              731

Sigmund, 1998), trustworthiness (McNamara, Stephens,
Dall, & Houston, 2009) and other moral characteris-
tics (Delgado, Frank, & Phelps, 2005). We argue that,
while such behavior is objectively irrational, it could nev-
ertheless be rational from a subjective point of view. Hu-
man participants may be maximizing their payoffs; itâ€™s
just that the game they are perceiving may not be the
one that the experimenter intended. By directly mod-
eling the agentâ€™s subjective state, learning and decision
making process, we are embracing McNamaraâ€™s (2013)
suggestion that researchers should consider enriching
EGT models with features such as psychological mecha-
nisms, decision making, personality variations and novel
traits, with the aim of accounting for the extensive vari-
ation in empirical studies across both people and cul-
tures (Fehr & Fischbacher, 2003; Henrich et al., 2004).
Quasi-magical thinking
An interesting category of subjective effects is what            Figure 1: U-V plane partitioned into 12 regions accord-
Shafir and Tversky (1992) termed quasi-magical think-            ing to rank ordering of the payoffs; notable games are
ing (QMT). Whereas magical thinking refers to the mis-           named. Shading corresponds to the density of agentsâ€™
taken belief that an action affects an outcome that it           evolved subjective payoffs, with the blue agents from
cannot, QMT describes situations where behavior is con-          runs with objective reality of (U, V ) = (âˆ’0.3, 1.3) and
sistent with this belief without it being explicitly held.       red from (U, V ) = (âˆ’0.9, 1.9). A total of 10000 agents
Several counterintuitive findings in behavioral game the-        from 20 independent runs are plotted at the 2000th time
ory fall under this heading. For instance, humans co-            step. The inset shows the proportion of cooperation ver-
operate more readily when a partnerâ€™s choice is un-              sus evolutionary cycle, where each line is a run.
known (Shafir & Tversky, 1992)â€”a puzzling response
pattern consistent with the erroneous view that cooper-
ation will encourage reciprocity, even in one-shot games.        cooperateâ€”an objectively irrational choice. We further
Similarly, participants make more optimistic predictions         show that an inferential bias (QMT) also promotes coop-
about their partnerâ€™s chances of cooperation if they             eration, though to a lesser extent than misperceiving the
themselves have already decided to cooperate (Dawes,             payoffs does. This is our contribution to the mounting
McTavish, & Shaklee, 1977), as if their decision can in-         evidence that rationality and irrationality should not be
fluence their partner.                                           dichotomized and that internal representations are im-
   Though QMT seemingly violates rationality,                    portant to evolutionary dynamics. While humans cer-
Masel (2007) argues that it could result from a                  tainly behave irrationally in PD from an objective per-
reasonable inferential bias. When judging a partnerâ€™s            spective, in that they do not optimize the stated payoffs,
probability to cooperate, assuming that that partner is          they might be using a perceptual interface where subjec-
similar to oneself can yield a rapid, accurate prediction        tive payoffs reflect extraneous concerns in addition to in-
if information is scarce. A player might therefore benefit       dividual fitness effects. They might also be using QMT
from observing not just what a partner does, but also            as a reasonable inferential bias. Humans, in other words,
what they would have done in the partnerâ€™s position. If          may be acting rationally on their subjective rather than
the player is indeed similar to the population at large,         objective payoffs or using subjective knowledge in unan-
then this bias could yield valuable data. Masel (2007)           ticipated ways.
showed that, if used during periods of uncertainty, this
type of QMT could also lead to greater cooperation in                             Model and Method
a public-goods game.
   In the next section, we present a novel EGT framework         Game space
for representing and acting on subjective conceptions            In our model, an agent (Alice) engages in a game with
of reality. We use this framework to demonstrate that            an adjacent individual (Bob). The players independently
agents playing PD on a random 3-regular graph, when              choose between two pure strategies: to cooperate (C) or
allowed to evolve subjective representations of the game,        defect (D). By subtracting from all payoffs any constant
converge on an objectively incorrect representation of           offset and choosing our units,
                                                                                             the  payoff for Alice is given
the interaction. This misrepresentation of the objective                                      1 U
gameâ€™s payoffs leads our subjectively rational agents to         by the canonical matrix              where Aliceâ€™s choice
                                                                                              V 0
                                                             732

determines the row (first row for C, second for D) and           tion, as long as the rate is not unreasonably high.
Bobâ€™s the column (first column for C, second for D). We
can plot this parameterization of all two-player symmet-         Learning and quasi-magical thinking
ric games in the U-V plane, as shown in Figure 1. The            The last ingredient for decision making is estimating the
different possible rank orderings of the 4 payoffs divide        probability that a partner will defect or cooperate. Alice
the plane into 12 qualitatively distinct regions. Some           has a mind that consists of her estimate pÌ‚A of the proba-
of the well-known games are marked with their names;             bility p that her partner cooperates when she cooperates,
game 1, for instance, is Prisonerâ€™s dilemma (PD) and has         and qÌ‚A of the probability q that her partner cooperates
V > 1 > 0 > U . The typical representation of the PD             when she defects. Since (UA , VA ) do not change during
game, in terms of a cooperator providing a benefit (b)           Aliceâ€™s lifetime, we count it as genetically determined
to her partner at a cost (c) to herself, with b > c > 0,         and shaping the mind, but not a direct part of it. No
                             c
translates to (U, V ) = (âˆ’ bâˆ’c    b
                               , bâˆ’c ) in the canonical rep-     agent can condition their action on the action of their
resentation. A not-so-competitive (i.e., friendly) envi-         partner, p = q, but we avoid hard-coding this knowledge
ronment has bâˆ’c c
                   near 0, and a competitive envrionment         into Alice and allow pÌ‚A to differ from qÌ‚A .
      c
has bâˆ’c â‰¥ 1/2. The exact value of the right hand side               The agent is thus fully specified by 4 parameters:
depends on factors like the spatial structure and can be         her perceived game (UA , VA ) and her probability esti-
calculated from Ohtsuki-Nowak transform (Ohtsuki &               mates pÌ‚A and qÌ‚A . She acts rationally on this informa-
Nowak, 2006); 1/2 corresponding to the 3-regular ran-            tion, deciding to cooperate only if the expected subjec-
dom graph condition that we study.                               tive utility of doing so is greater than that of defection,
   If V < 1 (games 5â€“12), then cooperation is ratio-             pÌ‚A + (1 âˆ’ pÌ‚A )UA > qÌ‚A VA .
nal (and an evolutionarily stable strategy (ESS)), and              To ensure that Alice has a chance to sample both
if U < 0 (games 1,5,9 and 10) then defection is rational         strategies, we incorporate a small trembling-hand pa-
(and ESS); otherwise both pure strategies are irrational         rameter (Selten, 1975): With probability  = 0.1, Alice
without more information about the partner. For games            takes the action opposite of the one she intends.
5 (Assurance), 9 and 10 (i.e., when both U < 0 and                  Aliceâ€™s estimates of pÌ‚A and qÌ‚A are based on Bayesian
V < 1), cooperation and defection are both rational,             inference from an initially uniform distribution, resulting
with the rational behavior depending on further infor-           in rational learning, or calculation of the maximum likeli-
mation about the partner.                                        hood estimate (also the best Bayesian estimate given the
                                                                 squared error loss function; Griffiths & Yuille, 2006):
Subjective representations
For each run of the simulation, we fix a specific game                           nCC + 1                  nDC + 1
(U, V ) as objective reality. This gameâ€™s payoffs deter-              pÌ‚A =                   , qÌ‚A =                    (1)
                                                                            nCC + nCD + 2              nDC + nDD + 2
mine agentsâ€™ fitness and thus drive evolution. However,
for the agentâ€™s decision process (cooperation vs. defec-            For QMT agents, we adopt a strategy similar to Masel
tion), we do not allow explicit access to these objective        (2007) and modify the mechanism for belief updating. If
payoffs. Instead, each agent has an evolved internal rep-        Alice is a QMT agent, then she not only observes what
resentation of the gameâ€”their individual perception of           Bob does, but also simulates what she would have done
the payoffs. For instance, Alice might think the game            in his place and then uses both pieces of information in
is (UA , VA ) and Bob might think it is (UB , VB ). Sup-         her Bayesian learning. This results in:
pose Alice cooperates and Bob defects. Their fitness is
adjusted according to the real game, so Aliceâ€™s fitness                     2nCC + nCD + 1                   nDC + 1
changes by U and Bobâ€™s by V . However, Alice believes               pÌ‚A =                       , qÌ‚A =
                                                                           2(nCC + nCD ) + 2            2(nDC + nDD ) + 2
that the effect on her fitness is UA and Bob thinks the                                                                  (2)
effect on his is VB .                                               In both sets of equations, nij is the number of times
   These internal conceptions of the game can be mis-            Alice acted i and her partner acted j. The agents are
perceptions, emotional biases like inequality aversion, or       simple Bayesian learners that update their minds after
other ingrained beliefs about the underlying interaction.        each interaction. A newborn agent has nCC = nCD =
The representation of the game passes from parent to             nDC = nDD = 0 and thus pÌ‚ = qÌ‚ = 1/2.
offspring under the influence of natural selection. Suc-
cessful agents pass on their conception of the game (given       Structured interactions
by a value âˆ’2 < U < 2 and âˆ’1 < V < 3), subject to                Agents and the strategies they implement do not work
a small mutation rate: With probability 0.05 (mutation           in a vacuum: An agentâ€™s payoff is a function of both its
rate), the generational transmission is faulty and the off-      strategy and the context in which that strategy is exe-
spring is born with a game selected uniformly at random          cuted. The spatial (or interaction) structure of the world
from Â±0.1 (mutation size) the parentâ€™s U and V values.           is thus central to the question of cooperation and altru-
The qualitative results are robust to changes in muta-           ism in EGT (Albert & BarabaÌsi, 2002; SzaboÌ & FaÌth,
                                                             733

2007). In fact, without any interaction structure (an
inviscid environment), no matter what reasonable repre-
sentation of the agentsâ€™ behavior we choose, cooperation
will not emerge in PD.
   We consider a minimal spatial structure and gener-
ate random 3-regular graphs on 500 nodes. Using the
analytic theory of Ohtsuki and Nowak (2006) for ana-
lyzing these graphs, we expect to find cooperation when
the inverse of the competitiveness is between 0 and 1/2.
When bâˆ’c  c
             = 12 , we expect a rapid phase transition from
universal cooperation to universal defection.
   Agents inhabit the nodes of the graph (one agent per
node) and interact with adjacent agents. The simulation
begins from a random distribution of agents over the
graph and over genetic space (âˆ’2 < U < 2, âˆ’1 < V < 3
and whether the agent uses regular Bayesian inference or
QMT). Each evolutionary cycle alternates between gen-
erating fitness from interactions and reproducing. Dur-          Figure 2: Proportion of cooperative interactions versus
ing the interaction step, Alice decides her action inde-           c
                                                                 bâˆ’c . Blue shows the evolution of subjective payoffs;
pendently for each neighbor, updating her mind (pÌ‚A and          red, evolution of standard Bayesian and QMT agents;
qÌ‚A ) after each interaction. At each reproductive step,         green, co-evolution of both; and black, completely ratio-
10% of agents are randomly selected for death. This              nal Bayesian agents that do not evolve. Line thickness
death rate acts as a seperation of the interaction and           represents standard error from averaging 10 runs.
evolution time-scales; with 10% and 3-regular graphs,
an average agents has about 30 interactions during its
life, but the results are largely unchanged for reasonable       the only rational action is cooperation: Games 6-8 and
(not too high) death rates. Neighbors of the perished            11-12. No agents in the friendly environment evolve the
agents compete to repopulate the vacated cells with their        objectively correct PD representation.
offspring (known as death-birth updating; Ohtsuki &
                                                                     The benefit of misrepresenting reality is highlighted in
Nowak, 2006). The probability of Alice winning this
                                                                 the inset of Figure 1, which shows the proportion of coop-
competition is proportional to the objective payoff she
                                                                 eration versus evolutionary cycle. Blue lines correspond
accumulates from the current round of interactions with
                                                                 to the proportion of cooperation in 10 independent runs
all her neighbors.
                                                                 with (U, V ) = (âˆ’0.3, 1.3) and the red lines correspond to
                                                                 10 runs with (U, V ) = (âˆ’0.9, 1.9). Although the actions
                          Results                                of agents in the friendly environment are objectively irra-
Our primary results are presented in Figure 1. The main          tional, they are subjectively rational andâ€”through their
figure is a density plot of agents by their genetic internal     subjective misrepresentation of realityâ€”produce much
representation of the game. Darker regions correspond            higher levels of cooperation and greater social welfare
to more agents with those (U, V ) values. A total of 5000        than do the agents in the highly competitive environ-
agents of each color are plotted, recorded from the last         ment.
evolutionary cycle of 10 independent simulations. The                Introducing QMT highlights the relative importance
objective game is PD, with (U, V ) = (âˆ’0.3, 1.3) in blue,        of perception vs. inference. As can be seen in Figure 2,
and (U, V ) = (âˆ’0.9, 1.9) in red.                                the co-evolution of perception (subjective payoffs) and
   For the highly competitive world indexed by red data          inference (standard vs. QMT) results in the green curve
points, where the benefit of cooperation is only 19/9            that best approximates the expected transition from all
times the cost, most agents evolve toward an objectively         cooperation to all defection (offset of 0.1 from total sat-
                                                                                                                     c
correct conception of the game: The internal represen-           uration due to shaky hand in both cases) at bâˆ’c         = 21 .
tation of most of the agents corresponds to PD, with a           However, subjective payoffs and QMT evolving on their
minority evolving toward Hawk-Dove and Leader games.             own relax the transition in different directions. In par-
On the other hand, in the relatively friendly environment        ticular, if perception is fixed to objective truth and infer-
indexed by blue data points, where the benefit of coop-          ence is allowed to evolve then we get significationly lower
eration is only 13/3 times the cost, most agents evolve          levels of cooperation in the low competition regime (red
toward misrepresentations of objective reality that are          line). On the other hand, if perception evolves but in-
conducive to cooperation. In particular, most agents in          ference is fixed at rational (no possibility for QMT) then
the blue condition evolve internal representations where         cooperation is sustained in more competitive regimes
                                                             734

than expected. The social welfare from misperception              the fitness distributionâ€”something that depends on the
is greather than that of QMT, although both lead to               interaction between agent and objective reality.
significant cooperation in friendly environments.                    Our results extend beyond this to show that some-
                                                                  times tuning reflects not just the individual agentâ€™s, but
                        Discussion                                the populationâ€™s interaction with the world. Our agents
Our results demonstrate several key points concerning             evolve misrepresentations of objective reality that pro-
the relationship between behavior and internal represen-          vide them with incorrect fitness information to promote
tations. To start, it is not necessarily the case that agents     a social good. This happens despite the fact that the
evolve a true representation of the game they are play-           agents act rationally on their perceptions. Further, un-
ing. This agrees with findings in behavioral game theory          like Mark et al. (2010), we donâ€™t have to include a penalty
suggesting that humans often deviate from objectively             for more accurate representations. In fact, our agents
rational behavior by incorporating seemingly extrane-             are capable of overcoming an implicit penalty associated
ous factors into their decision-making process (Fehr &            with misrepresentation. In the less competitive environ-
Camerer, 2007; Sun et al., 2008; Lee, 2008). Use of such          ments where cooperation emerges, if Alice were to sud-
information is analogous to misinterpreting the gameâ€™s            denly switch to accurate perception of payoffs thenâ€”in
payoff matrixâ€”something that our simulated agents do              the short termâ€”she could exploit her neighbors to get
when the world is less competitive.                               a strictly higher fitness. In short, our results not only
   However, we also observe that misrepresentation is not         strengthen the case for the interface theory of perception,
universal. In highly competitive environments, agents             but also suggest regarding the individualâ€™s interface as
evolve an approximately correct representation of objec-          not just serving the aims of that individual, but those of
tive reality and do not succumb to QMT. This suggests             society as a whole.
an empirical test of our theory: Do humans misrepresent              An interesting domain for such social interfaces is re-
reality more in friendly social settings or competitive           ligion. Religion is often lauded for promoting cooper-
ones? Our study suggests that mental representations              ation and moral behavior (Brooks, 2003; Regnerus &
are more accurate in the latter case.                             Burdette, 2006) and often criticized for disseminating
   Furthermore, we show that misrepresenting reality is           incorrect and even delusional beliefs (Dawkins, 2006;
not necessarily detrimental to individual or group per-           Hitchens, 2007). When evaluating the net impact of re-
formance. In the friendly environment, agentsâ€™ mis-               ligion, these two well-supported positions are typically
representations allow cooperation to flourish, despite            placed in opposition. Our model is consistent with both
each agent being solely interested in maximizing its own          of these claims, while providing an explanation of how
payoff. This allows the population to overcome coop-              these tendencies can emerge from the same underlying
erationâ€™s risk of exploitation because the cooperators            process. Unlike previous work (Roes & Raymond, 2003;
become insensitive to the possibility of defectors tak-           Johnson & Bering, 2006), our model does not rely on
ing advantage of them. Inevitably, mutual cooperation             group-selection or punishment, so it applies to both mor-
emerges and, in the friendly environment, is sufficient to        alizing and non-moralizing gods, reaching more cultures.
sustain erroneous perception of payoffs.                             To sum up, by creating agents who lack an a priori
Realist vs. interface theories of perception                      understanding of the world, we demonstrate that such
                                                                  agents can evolve a misrepresentation of reality. Fur-
The most direct consequence of our results is for un-
                                                                  thermore, because evolution selects for adaptive behav-
derstanding the veridicity of perception. The orthodox
                                                                  ior rather than accurate internal representations, these
view (Yuille & Bulthoff, 1996; Palmer, 1999) is critical
                                                                  delusions may prove useful by encouraging a greater de-
realismâ€”perception resembles reality, although it does
                                                                  gree of cooperation than rationality would otherwise al-
not capture all of it. The typical evolutionary justifica-
                                                                  low. By offering an example of how internal representa-
tion for this is that veridicity has greater utility for an
                                                                  tions and their consequences for behavior can be studied
agent and will be selected for by natural selection. Our
                                                                  in a game theoretic context, we hope to pave a path for
results show that this is not always the case.
                                                                  understanding how and why humans deviate from objec-
   Hoffman (1998, 2009) provides an alternative, by hy-
                                                                  tive measures of rationality. Though often ignored, the
pothesizing that perception is an interface that hides un-
                                                                  key may be subjective experiences.
necessary complexity irrelevant to the agentsâ€™ aims. In
                                                                  Acknowledgements: This work is supported by a grant from the Social
the case of evolution, the â€œaimâ€ is maximizing fitness,
                                                                  Sciences and Humanities Research Council of Canada to TRS.
and thus perception does not need to be truthful, but
has to provide an interface through which the agent can
act to maximize its fitness. Mark et al. (2010) confirmed
                                                                                            References
this with an evolutionary model showing that fitness is           Albert, R., & BarabaÌsi, A. (2002). Statistical mechanics
more important than â€œtruthâ€ to the agent. If percep-                 of complex networks. Rev. Modern Phys., 74 (1), 47.
tion is expensive, then the agent will tune it to reflect         Bagassi, M., & Macchi, L. (2006). Pragmatic approach
                                                              735

  to decision making under uncertainty: The case of the           to changes in inter-personal interactions. In Complex
  disjunction effect. Thinking & Reasoning, 12 (3), 329â€“          Adapt. Syst. - AAAI fall symp.
  350.                                                          Lee, D. (2008). Game theory and neural basis of social
Brooks, A. (2003). Religious faith and charitable giving.         decision making. Nature Neuroscience, 11 (4), 404â€“
  Policy Rev., 121 .                                              409.
Camerer, C. (2011). Behavioral game theory: Exper-              Lee, D., Conroy, M., McGreevy, B., & Barraclough, D.
  iments in strategic interaction. Princeton University           (2004). Reinforcement learning and decision making in
  Press.                                                          monkeys during a competitive game. Cognitive Brain
Croson, R. (1999). The disjunction effect and reason-             Research.
  based choice in games. Organ. Behav. Hum. Dec.,               Lohrenz, T., McCabe, K., Camerer, C., & Montague, P.
  80 (2), 118â€“133.                                                (2007). Neural signature of fictive learning signals in
Dawes, R. M., McTavish, J., & Shaklee, H. (1977). Be-             a sequential investment task. Proc. Natâ€™l Acad. Sci.
  havior, communication, and assumptions about other              USA, 104 (22), 9493â€“9498.
  peopleâ€™s behavior in a commons dilemma situation. J.          Mark, J., Marion, B., & Hoffman, D. (2010). Natural
  Pers. Soc. Psych., 35 (1), 1.                                   selection and veridical perceptions. J. Theor. Biol.,
Dawkins, R. (2006). The god delusion. Boston:                     266 (4), 504â€“515.
  Houghton Mifflin.                                             Masel, J. (2007). A bayesian model of quasi-magical
Delgado, M., Frank, R., & Phelps, E. (2005). Percep-              thinking can explain observed cooperation in the pub-
  tions of moral character modulate the neural systems            lic good game. J. Econ. Behav. Organ., 64 (2), 216 â€“
  of reward during the trust game. Nature Neuroscience,           231.
  8 (11), 1611â€“1618.                                            McNamara, J. (2013). Towards a richer evolutionary
Erev, I., & Roth, A. (1998). Predicting how people play           game theory. J, R. Soc., Interface, 10 .
  games: Reinforcement learning in experimental games           McNamara, J., Stephens, P., Dall, S., & Houston, A.
  with unique, mixed strategy equilibria. American Eco-           (2009). Evolution of trust and trustworthiness: so-
  nomic Review , 848â€“881.                                         cial awareness favours personality differences. Proc.
Fehr, E., & Camerer, C. (2007). Social neuroeconomics:            R. Soc. B., 276 , 605â€“613.
  the neural circuitry of social preferences. Trends in         Nowak, M., & Sigmund, K. (1998). Evolution of indirect
  Cogn. Sci., 11 (10), 419â€“427.                                   reciprocity by image scoring. Nature, 393 , 573â€“577.
                                                                Ohtsuki, H., & Nowak, M. (2006). The replicator equa-
Fehr, E., & Fischbacher, U. (2003). The nature of human
                                                                  tion on graphs. J. Theor. Biol., 243 (1), 86.
  altruism. Nature, 425 , 785â€“791.
                                                                Palmer, S. (1999). Vision science: Photons to phe-
Fehr, E., & Schmidt, K. (1999). A theory of fairness,
                                                                  nomenology. The MIT press.
  competition, and cooperation. Quarterly Journal of
                                                                Regnerus, M. D., & Burdette, A. (2006). Religious
  Economics, 114 (3), 817â€“868.
                                                                  change and adolescent family dynamics. Sociol. Q.,
Griffiths, T., & Yuille, A. (2006). Technical introduction:
                                                                  47 , 175-194.
  A primer on probabilistic inference. Trends in Cogn.
                                                                Roes, F. L., & Raymond, M. (2003). Belief in moralizing
  Sci., 10 .
                                                                  gods. Evolution and human behavior , 24 (2), 126â€“135.
Hartshorn, M., Kaznatcheev, A., & Shultz, T. (2013).
                                                                Sally, D. (1995). Conversation and cooperation in social
  The evolutionary dominance of ethnocentric coopera-
                                                                  dilemmas a meta-analysis of experiments from 1958 to
  tion. J. Artif. Soc. Soc. Simulat., 16 (3).
                                                                  1992. Rationality and Society, 7 (1), 58â€“92.
Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E.,       Selten, R. (1975). Reexamination of the perfectness
  & Gintis, H. (2004). Foundations of human sociality:            concept for equilibrium points in extensive games. In-
  economic experiments and ethnographic evidence from             ternational Journal of Game Theory, 4 (1), 25â€“55.
  fifteen small-scale societies. Oxford University Press.       Shafir, E., & Tversky, A. (1992). Thinking through
Hitchens, C. (2007). God is not great: How religion               uncertainty: Nonconsequential reasoning and choice.
  poisons everything. New York: Twelve Books.                     Cognitive Psychology, 24 (4), 449â€“474.
Hoffman, D. (1998). Visual intelligence: How we create          Sun, Y., Li, S., & Li, Y. (2008). Reexamining the role
  what we see. WW Norton & Company.                               of the description of problem texts in the disjunction
Hoffman, D. (2009). The interface theory of perception.           effect. Journal of Psychology, 142 (3), 261â€“266.
  In S. Dickinson, M. Tarr, A. Leonardis, & B. Schiele          SzaboÌ, G., & FaÌth, G. (2007). Evolutionary games on
  (Eds.), Object categorization: Computer and human               graphs. Phys. Rep., 446 (4), 97â€“216.
  vision perspectives. Cambridge University Press.              Yuille, A., & Bulthoff, H. (1996). Bayesian decision the-
Johnson, D., & Bering, J. (2006). Hand of god, mind               ory and psychophysics. In D. C. Knill & W. Richards
  of man: Punishment and cognition in the evolution of            (Eds.), Perception as Bayesian inference. Cambridge
  cooperation. Evolutionary Psychology, 4 .                       University Press.
Kaznatcheev, A. (2010). Robustness of ethnocentrism
                                                            736

