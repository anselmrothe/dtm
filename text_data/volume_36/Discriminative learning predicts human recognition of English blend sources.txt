UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Discriminative learning predicts human recognition of English blend sources
Permalink
https://escholarship.org/uc/item/3p38k0gw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Seyfarth, Scott
Myslin, Mark
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

      Discriminative learning predicts human recognition of English blend sources
                                                Scott Seyfarth (sseyfarth@ucsd.edu)
                                                 Mark Myslı́n (mmyslin@ucsd.edu)
                                                          Department of Linguistics
                                                    University of California, San Diego
                                              9500 Gilman Drive, La Jolla, CA 92093-0108
                              Abstract                                   exists as a constituent elsewhere in the English lexicon (ex-
                                                                         cept perhaps in other blends like infotainment; Lehrer, 2007),
   Strict compositionality in morphological theory is problem-
   atic for explaining how language-users comprehend phenom-             so such forms cannot be learned distributionally as regular
   ena like the partial yet non-decomposable forms in phonaes-           combinative forms can. Nevertheless, language-users can re-
   themes and in blends like edutainment. An alternative account,        liably recognize the constituents education and entertainment
   based on discriminative learning, proposes that language-users
   associate linguistic cues (e.g., short segment or letter strings)     in edutainment even without context.
   with multiple simultaneous possible lexical and grammatical              Language-users might apply a general mechanism in which
   meanings. We evaluate this account on off-line human identi-          they attempt to match tainment to a list of possible source-
   fications of partial word-forms, using English blend words as
   our test case. We hypothesize that readers’ ability to parse out      words that contain this partial string (e.g., Lehrer, 1996).
   source meanings from written blend forms should be corre-             However, it is not totally clear—especially without context—
   lated with how strongly a naı̈ve discriminative reading model         how they would identify the source-word as entertainment
   associates the cues in each form with the correct source mean-
   ings. We provide evidence for this claim in two experiments,          and not attainment (which may be semantically more closely-
   in which the discriminative learning model reliably predicted         related to education) or containment.
   participants’ success rate in guessing the sources of both at-           In this paper, we extend an amorphous model of morpho-
   tested and novel blends. This finding supports discriminative
   learning as a realistic model of how readers parse wordforms          logical processing based on discriminative learning (Baayen,
   and map them to meanings. Further, the result points towards          Milin, Filipovic Durdevic, Hendrix, & Marelli, 2011, and ref-
   a novel, precise account of blend processing.                         erences within, summarized below) to explain how language-
   Keywords: blends; discriminative learning; parsing; morpho-           users recognize the source-words in blends like edutainment.
   logical processing; reading                                           Previous work has used this model to simulate lexical reading
                                                                         times in a way that accurately reflects a variety of known mor-
                           Introduction                                  phological processing phenomena (Baayen, 2010; Baayen et
Language-users are able to recognize the constituents of                 al., 2011; Baayen, Hendrix, & Ramscar, 2013). Here, we
morphologically-complex words like rewrite. Under the                    test human participants’ ability to recover English blend con-
dominant view of word processing, they accomplish this by                stituents, and find that the model reliably predicts their suc-
decomposing words into stems and affixes, and during this                cess rate at guessing each source-word of a set of attested and
process they activate the appropriate lexical and semantic rep-          novel blends. This empirical test provides evidence about the
resentations for the constituents (Taft & Forster, 1975; Taft,           potential for this processing model to capture offline parsing
1981; Stockall & Marantz, 2006). Among other things, this                intuitions in addition to online retrieval processes.
process requires representations for combinatve forms, such
                                                                         Discriminative learning
as affixes, which are most likely acquired by distributional
learning over sets of words that share semantic and phono-               In a discriminative learning model, individuals learn to ac-
logical properties (e.g., Finley & Newport, 2011; Finley &               quire associations between CUES and OUTCOMES as a result
Wiemers, 2013).                                                          of trials in which a cue co-occurs, or fails to co-occur, with a
   However, not all partial forms can be separately mapped to            particular outcome. If a cue Ci occurs simultaneously with a
distinct meanings. For example, phonaesthemes and blends                 particular outcome O, then a learner will increase their asso-
like edutainment include partial yet non-decomposable                    ciation weight Vi between the cue and outcome.
forms. While a blend is composed of multiple constituents
(education + entertainment), it is not generated by any regu-                                    ∆Vi = αi (λ −Vi )                     (1)
lar morphological process. There is no rule for concatenating               In this equation, α is a salience parameter, and λ is the the-
the first two syllables of one word and the last two syllables           oretical maximum association weight that a learner can have
of another word to create a wordform with a related meaning.             between a cue and an outcome. If Ci occurs but the outcome
Furthermore, blends are not decomposable in the same way                 O does not, the learner will decrease the association Vi .
that compounds like blackboard are decomposable: neither
edu nor tainment exists as an independent word. Blends are
                                                                                                 ∆Vi = αi (0 −Vi )                     (2)
also not decomposable in the way that inflected forms like
walked or derived forms like naturalness are decomposable.                  The size of each adjustment thus depends on the current
For any particular blend, neither of its partial forms likely            value of Vi . As Vi gets closer to the theoretical maximum
                                                                     1413

 association weight λ, each trial in which the cue and outcome                                Cat
                                                                                                                   Clef
 co-occur will increase Vi by a smaller amount. As Vi gets
 larger, each trial in which the cue and outcome fail to co-             #       t        a       b       l       e      s        #
 occur will decrease Vi by a larger amount.
    Crucially, when multiple cues occur together with an out-
 come, the learner does not treat them independently (Rescorla                  Table                                     3Sg
 & Wagner, 1972). The adjustment to a cue Ci is dependent
                                                                                                      Trouble
 on the summed association weight between the outcome and
                                                                                       Lab                                  Plural
 the full set of cues that are present. Here, CP represents the
 set of cues that are present simultaneously during the trial in
 which the outcome occurs, and β is a learning rate parame-           Figure 1: Association weights of different strengths (arrow
 ter. Equation 3 indicates the change in association between Ci       thicknesses) between some of the unigram and bigram letter
 and the outcome O when they occur together, and Equation             cues in the wordform tables and meaning outcomes (correct
 4 indicates the change in association when Ci occurs without         meanings in ellipses; other activated meanings in boxes)
 outcome O.
                      ∆Vi = αi β1 (λ −   ∑ Vj)                (3)     Morphological processing
                                        j∈CP
                                                                      In one linguistic version of the discriminative learning model,
                      ∆Vi = αi β2 (0 −   ∑   Vj)              (4)     the CUES are taken to be short segment or letter strings, and
                                        j∈CP                          the OUTCOMES are word meanings (Baayen et al., 2011;
    For example, imagine a learning trial in which a rat sees         Ramscar et al., 2010). A language-user learns to associate
 a blue light and a red light—two cues—immediately before             each cue with each outcome—they acquire associations be-
 receiving an electric shock—the outcome. If the rat has no           tween symbols and their semantic knowledge of the world.
 association between either light and the outcome, the trial          If a segment or letter string frequently co-occurs with a par-
 will cause it to increase both association weights (red light        ticular lexical or grammatical meaning, but not elsewhere, the
 → shock, and blue light → shock) by a large amount. In               language-user will learn a strong association between that cue
 later trials, both cues will be considered to be good predictors     and that meaning.
 of the shock. On the other hand, if the rat already strongly            For example, word-final s very often co-occurs in words
 associates the red light and the shock, while it is seeing the       with a PLURAL meaning, such as in tables, books, chairs, and
 blue light for the first time, the trial will cause only a small     many other nouns. Each time a language-user sees this co-
 increase in association between each cue and the shock. In           occurrence, they more strongly associate word-final s with
 later trials, the blue light will not be considered as good a        the meaning PLURAL. Word-final s also sometimes occurs
 predictor of the shock, unless it continues to reliably occur        without the PLURAL meaning, such as in guess or mass.
 with that outcome. The rat can learn to discriminate which           When the language-user sees word-final s without the PLU -
 cue is a good predictor of the shock (Ramscar, Yarlett, Dye,         RAL meaning, they decrease their association between s and
 Denny, & Thorpe, 2010).                                              PLURAL . It is important to note that, in this model, the learner
    In the long term, an equilibrium point can be derived for         does not necessarily assign any privileged morphemic status
 each V if the following things are known:                            to word-final s—they learn only that this cue is strongly as-
1. probability P(O | Ci ) of each outcome given each cue              sociated with a particular meaning (Ramscar & Yarlett, 2007;
                                                                      Baayen et al., 2011, pp. 450–451).
2. probability P(C j | Ci ) of each cue given each other cue             In previous literature, cues are taken to be letter unigrams
    In this naı̈ve model, outcomes are considered to be inde-         and bigrams. Word meanings typically include the lexeme
 pendent of each other. For each outcome, the equilibrium             name plus any inflectional information. For example, the
 weight Vi for each cue is found by solving the following sys-        meanings that occur with the word tables are TABLE and
 tem (Danks, 2003).                                                   PLURAL . Corpus data can be used to estimate relatively how
                                                                      frequently each meaning occurs with each cue, and how fre-
     
       P(C0 | C0 ) P(C1 | C0 )     ...   P(Cn | C0 )
                                                     
                                                         V0           quently the cues occur with each other. These relative fre-
     P(C0 | C1 ) P(C1 | C1 )      ...   P(Cn | C1 )  V1           quencies should be more or less stable in the long term, and
     
            ..           ..       ..         ..
                                                     
                                                      ..           so the system of equations in (5) can be used to derive the
             .            .          .        .     .             expected weights between the cues and outcomes. Figure 1
       P(C0 | Cn ) P(C1 | Cn )     ...   P(Cn | Cn )     Vn           illustrates the relative strength of the equilibrium association
                                                            (5)     weights between the cues in the form tables and a few pos-
                                                  P(O | C0 )
                                                 P(O | C1 )         sible outcomes.
                                             =                          When a reader encounters a word, the naı̈ve discrimina-
                                                           
                                                     ..     
                                                     .     
                                                                      tive learning model makes the following prediction. If the
                                                  P(O | Cn )
                                                                  1414

summed total association weight between each cue in the                cluded blends that appeared in the Corpus of Contemporary
word and the target outcome (the lexical meaning of the                American English (Davies, 2008) with a frequency greater
word) is high, it should be easier for the reader to retrieve the      than one per million.
lexical representation of that word. In particular, the reader            Blends were also excluded if they contained a productive
should read the word more quickly and they should have a               partial form, such as the –holic form in workaholic, shopa-
more reliable judgment about the meaning of the word.                  holic, chocoholic. Participants may have acquired new se-
   Previous literature has shown that the differential reading         mantics for these forms (e.g., –holic is related to addiction,
times predicted by a discriminative learning model account             not to alcoholism per se), and language-users may decom-
for a variety of known processing effects, such as inflec-             pose these forms as in normal derivation (Lehrer, 1998). A
tional regularity, frequency, and morphological family size            partial form was considered to be productive if it met either
(Baayen, 2010; Baayen et al., 2011, 2013). However, the                of the following criteria:
model has yet to be evaluated on the reliability of morpho-
logical judgments—previous work has focused on response                • it was categorized as a combining form in the appendix to
latencies. Further, it has yet to be used to predict either com-          Lehrer, 1998 (e.g., –thon, –jacking)
prehension speed or reliability for the constituents of novel          • it was named as a reusable form or possible bound mor-
words.                                                                    pheme in Lehrer, 2007 (e.g., –umentary in mockumentary)
Modeling the recognition of blend constituents                            Some further blends were not included in the stimuli set
Since the model does not attempt to decompose words into               because it seemed unlikely that any participant would suc-
morphological constituents, it can straightforwardly explain           cessfully guess the source-words. In particular, blends were
how blend source-words are recovered. When a reader ob-                excluded if either source-word had a frequency of less than
serves a string of letter cues, even if that string has never been     one per million in COCA, or if they involved words or con-
seen before, those cues cause the activation of various mean-          cepts not in contemporary use (e.g., torrible > torrid + horri-
ing outcomes.                                                          ble). Finally, blends were excluded if either source-word did
   Therefore, the model makes a quantified prediction:                 not appear in the English CELEX database used to train the
language-users should be more likely to guess a source-word            discriminative learning model.
of a blend when there is a strong summed association weight               Attested blends were also excluded if they were proper
between the orthographic cues in a blend and the meaning of            names (Craisins); or were not composed of nouns, adjectives,
that source-word. In other words, if the blend strongly acti-          or verbs (thon > that + one); or were composed of more than
vates one of its lexical source meanings, that lexical meaning         two source-words (skafrocuban > ska + Afro + Cuban).
should be easier to guess.                                                This left a final list of 89 attested blends used as stimuli in
                                                                       Experiment 1.
            Experiment 1: Attested blends
                                                                       Model Using the ndl package for R (Arppe, Milin, & Hen-
We asked English-speaking participants to guess the source-
                                                                       drix, 2012), a naı̈ve discriminative reading (NDR) model was
words of blends that are attested in English. We predicted that
                                                                       trained on the wordforms and frequency data in the English
their aggregate success rate at guessing each blend source-
                                                                       CELEX database (Baayen, Piepenbrock, & Gulikers, 1996).
word would be correlated with how strongly the blend acti-
                                                                       The meanings (outcomes) associated with each wordform in-
vates the lexical meaning of that source-word.
                                                                       cluded included the lexeme name in addition to the inflec-
Procedure 100 Mechanical Turk workers were paid $0.25                  tional meanings provided in the morphological wordform an-
for participation. Only participants with United States IP ad-         notations. For example, the meanings associated with the
dresses and who certified that they were native speakers of            form geese were GOOSE and PLURAL, and the meanings as-
American English were allowed to participate.                          sociated with the form driven were DRIVE, PARTICIPLE, and
   Each participant was presented with a random sample of 50           PAST . As in previous work, letter unigrams and bigrams were
attested blends, with presentation order randomized for each           used as cues to meaning. For example, the cues that appear in
participant. For each blend, participants were asked (1) to            the form geese are: g, e, s, #g, ge, ee, es, se, e#.
guess its two source-words and (2) to indicate whether or not
                                                                       Activation strength The trained NDR model was used to
they had seen the blend before in their prior experience.
                                                                       calculate the total activation strength between the cues in each
Stimuli Attested blend stimuli were taken from the lists               blend and the meanings of its source-words. The strength
provided by Lehrer (2007) and Pound (1914). We attempted               with which a blend activated a target meaning was considered
to address several possible confounds in the list of blends.           to be the sum of the association weights between that lexical
If participants had seen a blend before, they might already            meaning and each cue in the blend. We predicted that the total
know the source-words, either because they had been taught             activation of a source-word meaning like ENTERTAINMENT
the sources, or because they had inferred them from context.           by the cues in edutainment should be correlated with how
Therefore, we excluded trials in which the participant indi-           easily participants are able to guess that entertainment is one
cated that they had seen the blend before. Further, we ex-             of the source-words of edutainment.
                                                                   1415

Control variables Based on previous literature, we ex-               correctly if they correctly guessed the blend’s other source-
pected that a number of other factors would influence how            word (β = 1.65, z = 8.5, p < 0.0001). Finally, source-words
easily participants would be able to guess a blend source-           with higher CELEX word frequency were more likely to be
word (Lehrer, 1996). Control variables included:                     guessed correctly (β = 0.79, z = 2.3, p < 0.03).
• the number and percentage of letters from the target                              Experiment 2: Novel blends
   source-word that were retained in the blend
                                                                     One possible concern with using attested blends is that many
• the source-word’s frequency in CELEX                               of them survived as lexical items for a relatively long time.
• the number of word lemmas in CELEX that the ortho-                 It may be the case that these blends are exceptional in some
   graphic partial form could possibly have been taken from          way. For example, they might remain in use because they
   (e.g., how many words could tainment possibly be from)            are unusually easy to parse or understand, which would be a
                                                                     potential confound for the results in Experiment 1. Therefore,
• the ratio of the frequency of the correct source-word to the       we conducted a second experiment using novel blends that
   summed frequency of all other possible source-words               were constructed specifically for the experimental task.
• the average probability of letter trigrams in the source-          Stimuli To serve as the source-words for novel blends,
   word, according to an orthographic model trained on the           20 pairs of co-hyponyms were selected from WordNet
   Brown corpus                                                      (Fellbaum, 1998). The co-hyponymy relationship has been
                                                                     argued to be one of the most common semantic relationships
• the source-word’s minimum orthographic probability using           between the two source-words in a blend (Gries, 2012). In
   the same metric (following e.g., Hay & Baayen, 2003, who          each word, we marked the boundaries between orthographic
   argue that low phonotactic probability at a boundary facil-       syllables, and between the onset and rime, as possible split
   itates the perception of morphological complexity)                points. This was done to improve the phonological well-
                                                                     formedness of the resulting blends; the onset-rime boundary
• whether the participant correctly guessed the other source-
                                                                     has been shown to be a common split point for blends, at least
   word in the blend
                                                                     in English (Kelly, 1998; Gries, 2004).
• whether the source-word occurred second in the blend                  To construct blend stimuli for each pair, one of the split
                                                                     points was randomly selected in each source-word. For ex-
Results The lme4 package for R (Bates, Maechler, & Dai,              ample, in the pair insult and sting, we might select the bound-
2008) was used to fit a mixed-effects logistic regression pre-       aries in—sult (between the two syllables) and —sting (word-
dicting participants’ success rate at identifying each source-       initial). The material preceding the split point in one of the
word on the basis of the blend’s NDR activation of the source-       words was concatenated with the material following the split
word meaning and the control variables listed above. A               point in the other word, based on a random coin toss. This
source-word identification was marked as correct if a partic-        procedure only has the possibility of creating linear blends,
ipant guessed either the target word or an inflected form, but       and excludes possibilities like chortle > chuckle + snort, in
was marked as incorrect for other wordforms, including de-           which two disjoint parts of the first source are separated by a
rived forms containing the target word. Responses were ex-           word-medial piece of the second source. Novel blends were
cluded if the participant indicated that they had seen the blend     also constrained by the requirements to contain at least one
before, if the response was left blank, or if the response sug-      unique letter from each source-word, to contain at least one
gested that the participant misunderstood the task (e.g., writ-      orthographic vowel, to be shorter than the concatenation of
ing animal + king as the source-words of zebrule). The final         both full sources (i.e., no full compounds), and to be longer
analysis included 8,008 source-word guesses (72% correct).           than the shorter source-word.
   The model also included per-subject and per-source-word
                                                                        Using this method, four possible blends were generated for
random intercepts and slopes where they were justified by the
                                                                     each source-word pair, resulting in 80 total blends.
design, including per-subject NDR activation slopes and the
maximal structure that allowed the model to converge. The
results of the logistic regression are presented in Figure 2(a).                      Table 1: Sample novel blends.
   Crucially, NDR activation was found to be reliably predic-
tive of participants’ ability to guess blend sources (β = 0.53,        source pair              novel blends
z = 2.6, p < 0.01). Four control factors were also signif-
icant. The more material from the target source-word re-               {insult, sting}          insting, stingsult, stingult, stult
tained in the blend (measured in both raw number of let-               {sofa, stool}            sofool, sool, sostool, stoolfa
ters and percentage of letters), the more likely participants          {diagram, scribble}      diagribble, scribbagram, scribbam,
were to correctly guess the source-word (β = 0.49, z = 2.6,                                     scrigram
p < 0.01; β = 0.97, z = 5.7, p < 0.0001, respectively). Addi-
tionally, participants were more likely to guess a source-word
                                                                 1416

                                             (Intercept)                                                      (Intercept)          ●
             NDR activation of source−word meaning                            NDR activation of source−word meaning
         Percentage source−word characters retained                     Percentage source−word characters retained
                     Source−word characters retained                                  Source−word characters retained
                                Source−word frequency                                        (^) Source−word frequency                  ●
      Num. of orthographically possible source−words             (^) Num.
                                                                        ●   of orthographically possible source−words                 ●
            Freq ratio: actual / possible source−words                      Freq
                                                                             ●    ratio: actual / possible source−words                    ●
        Source−word average orthographic probability               (^) Source−word
                                                                           ●           average orthographic probability
       Source−word minimum orthographic probability                   Source−word
                                                                      ●               minimum orthographic probability               ●
        Other source−word in blend correctly guessed                   Other source−word in blend correctly guessed
                 Source−word occurs second in blend             ●             (^) Source−word occurs second in blend
                                                         −1.0 −0.5        0.0         0.5         1.0       1.5       2.0 −1             0          1         2
                                                                        Parameter estimate                                        Parameter estimate
                                                                        (a) Attested blends                                        (b) Novel blends
Figure 2: Results of logistic regression predicting human success rate in guessing source-words of (a) attested blends and (b)
novel blends. All continuous variables were centered and standardized. Points are parameter estimates β; bars reflect two
standard errors. Significant factors appear in black (reported p values are based on the Wald z statistic). For both experiments,
backward model selection was also performed to remove non-significant predictors, but the remaining significant effects were
found to be qualitatively the same as in the full models. For Experiment 1, condition number κ = 4.8; for Experiment 2, κ = 3.8,
which both indicate low collinearity.
Procedure The procedure was identical to that of Experi-                                        source-word, the less likely it was to be guessed (β = −0.53,
ment 1, except that participants were not asked whether they                                    z = −3.4, p < 0.001). In other words, the more orthograph-
had seen the blend before. 100 new participants were re-                                        ically unusual the source-word, the more likely participants
cruited. For each source-word pair, each participant saw ex-                                    were to recover it. Second, source-words in second position
actly one of the four novel blends, chosen at random.                                           in the blend were less likely to be recovered than those in first
                                                                                                position (β = −0.90, z = −2.7, p < 0.01). This may suggest
Results We fit a mixed-effects logistic regression, using the
                                                                                                that word-initial letters are slightly more salient to readers
same procedure as in Experiment 1, to predict participants’
                                                                                                than medial or final letters.
success rate at identifying each source-word on the basis of
the blend’s NDR activation of the source-word meaning in
addition to the same control variables. Random per-blend in-
                                                                                                                          Discussion
tercepts and slopes were also added to the model structure,                                     The amorphous letter-to-meaning associations of the naı̈ve
since there were multiple blends for each source-word. With                                     discriminative reading model were found to be good predic-
the exclusions described above, 3,736 source-word guesses                                       tors of human readers’ success at recovering the constituents
(50% correct) were included in the final analysis.1 The re-                                     of both attested and novel blends. If a blend contained or-
sults of this model are presented in Figure 2(b).                                               thographic cues that strongly activated the lexical meaning of
   NDR activation was again found to be reliably predictive of                                  one of its source-words, readers were better able to recognize
participants’ ability to guess blend sources (β = 1.04, z = 3.8,                                that source-word in the blend form. This effect was indepen-
p < 0.001). All of the significant control factors for attested                                 dent of source-word frequency, the length of the partial form,
blends were significant for novels, except source-word fre-                                     and a number of other control variables.
quency (letters retained: β = 1.15, z = 6.4, p < 0.0001; per-
centage of letters retained: β = 1.46, z = 9.8, p < 0.0001;                                     Discriminative learning and constituent recognition
other source-word guessed correctly: β = 1.70, z = 7.7,                                         The result extends previous literature, which has argued that
p < 0.0001). The difference in the frequency effect may be                                      an NDR-based model can account for morphological phe-
due to the different stimuli: there were only 40 source-words                                   nomena associated with reading times. In particular, the cur-
for the novel blends, and these were hand-selected and mostly                                   rent study supports a distinct prediction of the discriminative
of medium frequency.                                                                            learning account: meaning activations are correlated with the
   Two additional factors were significant for novel blends.                                    reliability and success with which readers recover morpho-
First, the higher the average orthographic probability of the                                   logical constituents offline, in addition to their speed at doing
                                                                                                so. Additionally, previous work has looked primarily at word-
    1 Responses      to one source-word pair (strength, advantage) were                         forms and constructions that are already known to the learner.
also excluded because these responses unusually inflated the vari-
ance of the random effects estimates; however, all results were qual-                           This study extends this work by showing that the model can
itatively the same with these responses included.                                               also account for comprehension effects in forms that a reader
                                                                                        1417

has not previously been exposed to. This provides evidence                                       References
that discriminative learning captures the effects of process-         Arppe, A., Milin, P., & Hendrix, P. (2012). ndl: Naive discriminative
ing mechanisms, rather than stored representations of existing          learning [Computer program]. (R package version 0.1.6)
                                                                      Baayen, R. H. (2010). Demythologizing the word frequency effect:
words.                                                                  A discriminative learning perspective. The Mental Lexicon, 5(3),
   This implementation of the NDR model describes the re-               436–461.
covery of the component meanings of word-forms and con-               Baayen, R. H., Hendrix, P., & Ramscar, M. (2013). Sidestepping
                                                                        the combinatorial explosion: An explanation of n-gram frequency
structions in isolation, but does not purport to provide an             effects based on naive discriminative learning. Language and
account of inference of whole-form meaning. For example,                Speech, 56(3), 329–347.
the blend dogbrella might mean “an umbrella for dogs” or              Baayen, R. H., Milin, P., Filipovic Durdevic, D., Hendrix, P., &
                                                                        Marelli, M. (2011). An amorphous model for morphological
“an umbrella with pictures of dogs.” Pragmatic and linguistic           processing in visual comprehension based on naive discrimina-
context as well as prior probability distributions over seman-          tive learning. Psychological Review, 118, 438–482.
tic relationships (Pollatsek, Drieghe, Stockall, & de Almeida,        Baayen, R. H., Piepenbrock, R., & Gulikers, L. (1996). CELEX-2
                                                                        (Tech. Rep.). Philadelphia: Linguistic Data Consortium.
2010) provide a basis for future extension of the model.              Bates, D., Maechler, M., & Dai, B. (2008). lme4: Linear mixed-
                                                                        effects models using s4 classes [Computer program]. (R package
Blend processing                                                        version 0.999375-28)
                                                                      Danks, D. (2003). Equilibria of the Rescorla-Wagner model. Jour-
The NDR model is designed to capture form-to-meaning re-                nal of Mathematical Psychology, 47, 109–121.
lationships without requiring formal decomposition. In par-           Davies, M. (2008). The Corpus of Contemporary American English:
ticular, it allows the extraction of multiple (lexical or gram-         450 million words, 1990–present. (http://corpus.byu.edu/coca/)
                                                                      Fellbaum, C. (1998). WordNet: An electronic lexical database.
matical) meanings from non-decomposable forms with mul-                 Cambridge, MA.
tiple constituents. Blends are an excellent test case for             Finley, S., & Newport, E. L. (2011). Morpheme segmentation in
such a model, because they conspicuously have multiple                  school-aged children. University of Rochester Working Papers in
                                                                        the Language Sciences.
constituents while at the same time they are not subject to           Finley, S., & Wiemers, E. (2013). Rapid learning of morphological
any kind of regular decompositional analysis. A purely-                 paradigms. In Proceedings of the 34th Annual Conference of the
compositional account such as that of Marantz (2013) is chal-           Cognitive Science Society. Austin: Cognitive Science Society.
                                                                      Gries, S. T. (2004). Shouldn’t it be breakfunch? A quantitative
lenged to explain how a conjunction of multiple partial lex-            analysis of blend structure in English. Linguistics, 639-668.
ical wordforms can be reliably parsed into its original con-          Gries, S. T. (2012). Quantitative corpus data on blend forma-
stituents. On our account, in contrast, blend processing is             tion: psycho-and cognitive-linguistic perspectives. In V. Renner,
                                                                        F. Maniez, & P. Arnaud (Eds.), Cross-disciplinary perspectives on
modeled as prediction of meanings based on many small cues,             lexical blending (pp. 145–167). New York: Mouton de Gruyter.
namely all (unigrams and bigrams of) letters in the blend.            Hay, J., & Baayen, H. (2003). Phonotactics, parsing and productiv-
   The discriminative learning model may help explain how               ity. Italian Journal of Linguistics, 1, 99–130.
                                                                      Kelly, M. H. (1998). To ‘brunch’ or to ‘brench’: Some aspects of
language-users recover entertainment from the partial form              blend structure. Linguistics, 36, 579–590.
tainment instead of plausible alternatives like attainment or         Lehrer, A. (1996). Identifying and interpreting blends: an experi-
containment. The cues in edutainment are collectively bet-              mental approach. Cognitive Linguistics, 7(4), 359–390.
                                                                      Lehrer, A. (1998). Scapes, holics, and thons: The semantics of
ter associated with entertainment than the alternatives, which          English combining forms. American Speech, 73(1), 3–28.
leads to a stronger activation of entertainment and thus a            Lehrer, A. (2007). Blendalicious. In Lexical creativity, texts and
greater likelihood that a reader will select the correct form.          contexts (pp. 115–133). Amsterdam: John Benjamins.
                                                                      Marantz, A. (2013). No escape from morphemes in morphological
   Our account additionally makes tractable predictions about           processing. Language and Cognitive Processes, 28(7), 905–916.
the structure and function of blends in natural language. One         Pollatsek, A., Drieghe, D., Stockall, L., & de Almeida, R. (2010).
communicative constraint on the formation of blends might               The interpretation of ambiguous trimorphemic words in sentence
                                                                        context. Psychonomic Bulletin & Review, 17(1), 88–94.
be that the meanings of individual source-words must be re-           Pound, L. (1914). Blends: their relation to english word formation.
coverable by comprehenders (Lehrer, 1996; Gries, 2004). If              Heidelberg: Winter.
this is true, we predict that cues (here, letter unigrams and bi-     Ramscar, M., & Yarlett, D. (2007). Linguistic self-correction in the
                                                                        absence of feedback: a new approach to the logical problem of
grams) that most strongly activate the intended meanings are            language acquisition. Cognitive Science, 31(6), 927–60.
most likely to become part of the blend, and that language-           Ramscar, M., Yarlett, D., Dye, M., Denny, K., & Thorpe, K. (2010).
users would judge blends with these cues to be better than              The effects of feature-label-order and their implications for sym-
                                                                        bolic learning. Cognitive Science, 34(6), 909–57.
blends with cues that less strongly activate these meanings.          Rescorla, R. A., & Wagner, A. R. (1972). A theory of pavlovian
This is the subject of ongoing research.                                conditioning: Variations in the effectiveness of reinforcement and
                                                                        nonreinforcement. In A. H. Black & W. F. Prokasy (Eds.), Clas-
                     Acknowledgments                                    sical Conditioning II: Current Research and Theory (pp. 64–99).
                                                                        New York: Appleton-Century-Crofts.
We are grateful to Roger Levy, Farrell Ackerman, Robert               Stockall, L., & Marantz, A. (2006). A single route, full decompo-
Malouf, Ryan Lepic, David Barner, Olivier Bonami, the                   sition model of morphological complexity: MEG evidence. The
                                                                        Mental Lexicon, 1(1).
UCSD CPL Lab, the morphology group at UCSD, and the                   Taft, M. (1981). Prefix stripping revisited. Journal of Verbal Learn-
audience at BLS 40 for insightful discussion and suggestions.           ing and Verbal Behavior, 20(3), 289-297.
We also thank Bill Presant for assistance with data annotation.       Taft, M., & Forster, K. I. (1975). Lexical storage and retrieval of
                                                                        prefixed words. Journal of Verbal Learning and Verbal Behavior,
Any errors or omissions are ours. This work was supported               14, 638–647.
by NSF Graduate Research Fellowships to both authors.
                                                                  1418

