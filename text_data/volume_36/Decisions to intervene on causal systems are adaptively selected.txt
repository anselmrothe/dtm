UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Decisions to intervene on causal systems are adaptively selected
Permalink
https://escholarship.org/uc/item/4p82x49p
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Coenen, Anna
Rehder, Bob
Gureckis, Todd
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   Decisions to intervene on causal systems are adaptively selected
                                              Anna Coenen, Bob Rehder, and Todd Gureckis
                           Department of Psychology, NYU, 6 Washington Place, New York, NY 10003 USA
                                             {anna.coenen, bob.rehder, todd.gureckis}@nyu.edu
                               Abstract                                   Furthermore, we show that this strategy mixture is not fixed
   How do people choose interventions to learn about a causal             but that people can change their strategies in response to the
   system? Here, we tested two possibilities: an optimal infor-           payoff structure in a given environment. On the basis of these
   mation sampling strategy which aims to discriminate between            findings we argue that people have a flexible and adaptive
   multiple hypotheses, and a second strategy that aims to confirm
   individual hypotheses. We show in Experiment 1 that individ-           repertoire for causal structure learning, rather than relying on
   ual behavior is best fit using a mixture of these two options. In      a single strategy. The structure of this paper is as follows.
   a second experiment, we find that people are able to adaptively        First, we will define two computational models of interven-
   alter the strategies they use in response to their expected payoff
   in a particular task environment.                                      tion selection. We then report an experiment aimed at distin-
   Keywords: causal learning; information sampling; interven-
                                                                          guishing the models. Based on the results, we present a sec-
   tions.                                                                 ond study in which we manipulate the expected payoff from
                                                                          each strategy to investigate the impact on people’s interven-
                           Introduction                                   tion decisions.
Interventions are an important instrument for learning about              Two models of intervention-based causal learning
causal structures. By manipulating causal variables we can
better discover the relationships between them. This ability is           Information Gain The IG model predicts that learners
crucial in many areas of human inquiry including empirical                should choose interventions that they expect to maximally re-
science, medical reasoning, or simply when learning how a                 duce their current uncertainty, H(G), about a set of causal hy-
new mechanism, like a smartphone, works. In this paper we                 potheses or graphs, G (Murphy, 2001; Tong & Koller, 2001).
ask how people decide which variables to manipulate when                  The expected Information Gain of an intervention a can be
they want to test specific hypotheses about a causal system.              calculated as:
   Previous work has most often sought a single strategy
                                                                                      EIG(a) = H(G) − ∑ P(y|a)H(G|a, y)                 (1)
or model that describes how people search for information                                                 y∈Y
when learning. In particular, two competing perspectives
have emerged. One set of models assumes that people se-                   where P(y|a) is the probability of outcome y ∈ Y , given ac-
lect information to optimally discriminate between different              tion a. Calculating EIG requires knowing the new uncertainty
hypotheses. Such rational sampling norms have been used                   after making intervention a and observing outcome y:
to model information search in many different domains (for
an overview see Nelson, 2005), including learning of causal                                                              1
                                                                                       H(G|a, y) =   ∑ P(g|a, y)log P(g|a, y)           (2)
structures. For example, Steyvers and colleagues (2003) ar-                                         g∈G
gue that participants use an Information Gain strategy (IG)
                                                                          where P(g|a, y) is the probability of graph g given in-
when choosing causal interventions. This strategy aims to
                                                                          tervention a and resulting outcome y.              To calculate
minimize a learner’s uncertainty about which out of a num-
                                                                          P(g|a, y), Bayes’ rule can be applied, yielding P(g|a, y) =
ber of graph descriptions (hypotheses) underly a particular
                                                                          P(y|g, a)P(g)/P(y|a). Finally, P(y|a) can be computed by
causal system.
                                                                          marginalizing over all possible graphs and their likelihood of
   On the other hand, research on hypothesis testing in other
                                                                          producing outcome y given intervention a, P(y|g, a).
domains, particularly in rule-learning tasks, has often argued
that people use confirmatory strategies to search for informa-            Positive testing There is no existing definition of positive
tion (Nickerson, 1998). For example, they might use the pos-              testing as a causal intervention strategy in the literature. PTS
itive testing strategy (PTS) which makes search queries that              has mainly been articulated in rule learning tasks, where it
they expect to be true under one hypothesis, irrespective of              constitutes a preference for search queries that lead to pos-
whether it helps to discriminate between different hypothe-               itive outcomes (i.e. “yes” rather than “no”) under a given
ses (Klayman & Ha, 1989; Wason, 1960). Although PTS can                   hypothesis (Klayman & Ha, 1989; Wason, 1960).
be optimal under certain circumstances (Navarro & Perfors,                   We propose that such a preference for positive outcomes
2011; Oaksford & Chater, 1994), it often runs counter to op-              might translate into a preference for creating positive effects
timal sampling norms such as IG.                                          in the causal learning scenario. Consequently, PTS could
   This paper challenges the view that people use a single                manifest as a preference for nodes that have high causal
strategy to test causal hypotheses via interventions, and in-             centrality in a hypothesis that is currently under evaluation
stead finds that people simultaneously use both discrimina-               (Sloman, Love, & Ahn, 1998; Ahn, Kim, Lassaline, & Den-
tory and confirmatory reasoning when making interventions.                nis, 2000), where centrality is measured by the number of di-
                                                                      343

     1. All nodes “off”
                       2. Click to intervene                                                                    Experiment 1
                                          3. Observe effects
                                                                                         Method
                                                             Choice of structure         Participants One hundred and five participants were re-
                                                             Which chip diagram
                                                                                         cruited via Amazon Mechanical Turk. Participants received
                                                                 is correct?             $2 for participation with the option of earning up to $1 bonus
                                                                                         based on performance in the task.
                                                                                         Stimuli and Materials On each trial of the experiment,
                                                                                         participants were shown a simple causal system (“computer
                  Repeat until confident
                                                                                         chip") and were asked to learn how it worked (see Figure 1).
                                                                                         Each chip had three components (nodes), which could either
Figure 1 An example trial. A chip was presented with all                                 be on or off as indicated by their color. Each chip could be-
components off. Two possible wiring diagrams were dis-                                   have according to one of two possible causal structure hy-
played above the chip. Participants selected a chip compo-                               potheses (wiring diagrams) that were visible at all times. One
nent to “activate" and observed the resulting effects on the                             of the two wiring diagrams was randomly selected to be the
system. Later participants were asked to choose which of the                             true underlying structure. On each trial, participants inter-
two diagrams best described the operation of the chip.                                   acted with the system to determine which diagram best de-
                                                                                         scribed its operation.
                                                                                            All three-node causal Markov structures with one or two
rect and indirect descendant causal links. If learners make in-                          links were used in the experiment, yielding four basic struc-
terventions on high-centrality nodes, they can gather positive                           ture types (Chain, Common Cause, Common Effect, and
evidence for a hypothesis by producing the expected effects                              One-Link) that were exhaustively paired with each other to
that are entailed by these descendant links (e.g. if a system                            form 27 unique hypothesis pairs (see Figure 2, top). All links
has an on/off structure, then turning on a high centrality node                          had causal strengths of 0.8 and there were no background
should cause its direct and indirect children to turn on also).                          causes that could activate a node spontaneously (i.e., with-
Because graphs can differ in the number of links that can be                             out an intervention or active parent node). Participants were
tested in principle, we will consider causal centrality relative                         told and quizzed about these details before starting the task.
to the total number links in a given graph. Thus, the PTS
value of intervening on a node n is determined by that node’s                            Procedure A trial began with all components of the chip
maximum relative causal centrality over all graphs that are                              switched off (red). The participant could then intervene on
currently under consideration:                                                           one component by clicking on it and thereby turning it on
                                                                                         (green). After a short delay (500ms) an animated white ring
                                          
                                            DescendantLinksn,g
                                                                                        appeared around all other components to indicate that they
               PT S(a) = max                                                     (3)     were updated as a consequence of the intervention. Compo-
                                      g          TotalLinksg
                                                                                         nents that were activated by the intervention changed their
                                                                                         color to green while all other components remained red. All
where descendant links are all the links that lead to direct or
                                                                                         components had to be reset to their original state (off) using a
indirect children of the node that is intervened on. To illus-
                                                                                         button press before another intervention could be made. Par-
trate the concept of PTS, a node will have a value of 1.0 if,
                                                                                         ticipants made as many interventions as they desired. After-
by intervening on it, all possible links of at least one hypothe-
                                                                                         ward, participants indicated which wiring diagram they felt
sized graph can be activated. If it can activate at most one out
                                                                                         was correct by clicking on one of the two options. They then
of two links, it receives a score of .5, and a score of zero if it
                                                                                         rated their confidence.
cannot lead to any outcomes at all. According to this strategy,
nodes become attractive if they have a high PTS score in at                                 To ensure that participants chose their interventions care-
least one hypothesis that is currently evaluated, irrespective                           fully, they were offered a bonus of up to $1 from one ran-
of the differences between hypotheses.                                                   domly chosen structure comparison at the end of the exper-
                                                                                         iment. The bonus was only paid if they chose the correct
Choice model For both models, the probability of choosing                                structure at the end of the selected trial, and it was further
one intervention ai out of a range of possibilities, A, given a                          reduced by $0.10 for every intervention made in that trial.
measure of the usefulness of the action, V (ai ), is:
                                                                                         Results
                                            exp(V (ai )/τ)                               Overall, participants were highly accurate in identifying the
                           P(ai ) =                                              (4)
                                         ∑ j exp(V (a j )/τ)                             correct wiring diagram after interacting with a chip. The per-
                                                                                         centage of correct choices averaged across individuals was
where V (a) is determined by either Eqn 1 or 3. Parameter τ                              87% (SD = 0.14, MD = 92%). Participants’ confidence rat-
determines the degree to which behavior resembles guessing                               ings mirrored their choices, with higher confidence ratings on
rather than choosing the action with the highest V (a) score.                            correct trials (M = 80.22), versus incorrect trials (M = 72.62),
                                                                                     344

                              1        2          3         4         5             6           7
       Experiment 1
                              8        9         10         11        12            13         14
                              15       16         17        18        19            20          21
                              22        23        24        25          26          27
                      PTS -                                                     PTS =
                          1        2         3         4          5                 1          2          3          4          5
       Experiment 2
                          6        7         8         9         10                 6          7          8          9         10
                          11       12        13        14        15                 11         12         13        14         15
                         16        17        18        19        20                 16         17         18        19         20
Figure 2 Top: All 27 structure comparisons used in Experiment 1. Each numbered comparison represents a trial in which
participants were asked to intervene to decide between the depicted two causal hypotheses. Comparisons highlighted with a
grey box were also used in the second phase of Experiment 2. Bottom: the problem types used in Experiment 2. The PTS- set
specifically discourages the use of the PTS strategy (nodes highly valued under this strategy result in confounded evidence).
The PTS= set is effectively neutral with respect to IG and PTS (using PTS is not harmful in this case).
t(89) = 3.66, p<.001.                                                         terior predictive model assessment (Gelman, Meng, & Stern,
Intervention decisions - Individual models Our critical                       1996) and compared samples of each model to the data. This
question concerns how people decide which node(s) to in-                      analysis (not shown graphically, in the interest of space, but
tervene on given a specific pair of hypotheses (wiring dia-                   summarized in Coenen & Gureckis, 2013 for the IG model)
grams)1 . Since we are modeling only a single choice per                      revealed that both models fit the data well on some of the 27
participant per problem type, there are unavoidable amounts                   problems, but also missed the key behavioral profile for other
of measurement noise. For example, even a participant per-                    problems. As a result neither the IG nor PTS model provided
fectly following the IG strategy might not choose the IG-                     a credible account of the empirical data (i.e., for both models
maximizing choice on a single trial (e.g., assuming Eqn 4).                   there was more than one problem for which behavior was well
To ensure that our model fit measures correctly accounted                     outside the 95% confidence contour even after accounting for
for this type of noise and uncertainty, we adopted a fully                    measurement noise).
probabilistic model-assessment approach using a hierarchal                    Intervention decisions - Combined model Given that nei-
Bayesian model (for an informal discussion see Coenen &                       ther the PTS or IG model provided a sufficiently credible fit
Gureckis, 2013). The generative model assumed a popula-                       to our behavioral data, we considered a range of alternative
tion level distribution over the τ parameter (Eqn 4) such that                models. In the interest of space, we describe here the best
for participant i, τi ∼ Gamma(α, β). This sampled value of                    alternative model from our exploration, shown in Bayesian
τi was then used along with the V (a) scores for the IG and                   Hierarchical form in Figure 3 (middle panel). This model
PTS models (Eqns 1 and 3) to derive choice probabilities for                  represents a linear combination of IG and PTS with a mixture
each of the three nodes on the circuit board. Finally, a single               weight θ which determines the degree to which participants
choice was sampled from these probabilities via a categorical                 match IG compared to PTS. Eqn 3 in the same Figure shows
distribution.                                                                 how choice probabilities arise from this linear combination.
   We performed Bayesian inference, conditioned on the be-                    The strategy reduces to a pure version of IG or PTS when
havioral data, to obtain posterior estimates of these hyperpa-                θ = 1 or θ = 0, respectively. Both θ and τ were fit individ-
rameters α and β, as well as τi for each participant. To then                 ually for each subject. At the hyperparameter level θ was fit
assess the quality of the model fit, we used the method of pos-               using a beta distribution that was reparametarized by its mean
                                                                              µ and standard deviation κ. The distribution of τ was param-
   1 On  average, participants made 1.56 (SD = 0.59) interventions            eterized as described above.
during a single chip test, and the majority of structure choices were            Using the posterior-prediction method described above, we
made after only one intervention. Given this, we focused our analy-           then also evaluated this combined model. Unlike for the in-
sis on the first intervention that participants made in any game.
                                                                        345

dividual models, none of the empirical data from individual               find strong support for the IG model. This was surprising be-
problems appear implausible in relation to this model (i.e., the          cause many aspects of our experiment were selected to make
behavioral data lie within the range of plausible data patterns           it particularly easy for participants to use IG (e.g., small num-
generated from the model).                                                ber of hypotheses explicitly visible at all times, economic in-
                                                                          centive to be efficient). One crucial question raised by this
Individual differences in strategy use The inferred θ pa-
                                                                          finding is what factors determine what strategy people use. In
rameters in the combined model provide an estimate of par-
                                                                          particular, we wondered whether the tendency to use a con-
ticipants’ individual tendency to behave according to IG com-
                                                                          firmatory strategy like PTS is a stable "bias" in how people
pared to PTS. The top plot of the left panel in Figure 3 shows
                                                                          approach such problems or whether it can be altered through
a histogram of the best-fitting values of θ for each partic-
                                                                          more, or different, experience with the task. This issue is ex-
ipant based on maximum-likelihood estimation2 . Interest-
                                                                          plored in Experiment 2.
ingly, rather than dividing into two groups, many participants
fall on a continuum between the two strategies. Thus, behav-                                      Experiment 2
ior does not only resemble a strategy in the aggregate; it does
so at the individual level, as well.                                      One important property of Experiment 1 was that even if par-
   In support of the parameter estimates, we found that par-              ticipants used PTS, the cost they incurred in accuracy com-
ticipants’ intervention strategies, measured by θ, were related           pared to using IG was relatively small. The present experi-
sensibly to other behavioral variables. For example, higher               ment was designed to test if people can learn to switch from
weightings of IG were negatively correlated with response                 using PTS to a more discriminatory strategy when PTS more
time, r(103) = .23, p < 0.05, but had a positive impact on ac-            obviously impairs performance. The experiment closely fol-
curacy, r(102) = .44, p < 0.001 (after controlling for τ, which           lowed the design of Experiment 1. However, participants first
indicates participants’ tendency to guess rather than decide in           completed a set of novel causal intervention problems that
line with any of the two models). This matches the intuition              were either designed to make PTS a lot less effective than IG
that IG is computationally more expensive than PTS, but also              (PTS- condition) or to make the strategies almost equally use-
more effective for learning the correct structure.                        ful (PTS= condition). In both conditions, participants were
   We also found a relationship between θ and measures of                 then tested on a critical subset of problems from Experiment
successful belief-updating in line with an optimal learner us-            1. If strategy use is flexible and adaptive to experience, we
ing Bayes’ rule. For instance, θ was positively correlated                expected that interventions would be more in line with the IG
with the proportion of times a participant chose the hypothe-             model in the PTS- condition compared to PTS=. However,
sis with the higher posterior probability given their interven-           if strategy use is a stable trait or bias, we expect to find no
tion outcomes, r(102) = .4, p < 0.001 (again, controlling for             difference between the conditions.
τ). This shows that differences in people’s intervention strate-
                                                                          Method
gies might also be connected with differences in their ability
to learn from these interventions, and that using PTS corre-              Participants We recruited 122 participants via Amazon
sponds to a higher tendency to deviate from optimal behavior.             Mechanical Turk. Compensation and incentive structure
   We did not find a significant relationship between θ and τ,            were the same as in Experiment 1.
r(103) = -0.07, p > 0.05 (calculated using log(τ), since the
estimates were strongly positively skewed).                               Stimuli, Materials, and Procedure In total, participants
Discussion                                                                completed 40 intervention problems. In the first half of the
                                                                          experiment they were given 20 new problems consisting of
The first experiment offered two insights. First neither the
                                                                          pairs of four-node causal networks (see Figure 2, bottom).
IG nor PTS model alone seem to provide a plausible account
                                                                          In the PTS- condition, each problem was designed such that
of participant’s intervention decisions. Instead, behavior was
                                                                          choosing interventions using PTS would often lead to out-
best explained by a mixture of these two strategies that varied
                                                                          comes that do not differentiate between the hypotheses. A
somewhat between participants. Second, we developed a new
                                                                          simulation of an optimal learner choosing interventions on
model assessment approach based on hierarchical Bayesian
                                                                          these problems resulted in only 62% accuracy after one inter-
modeling and posterior predictive simulation to assess model
                                                                          vention using PTS compared to 91% using IG (assuming the
fits. This approach enabled us to evaluate both population
                                                                          learner always chooses the option with the highest IG/PTS
and individual level difference in strategy use from relatively
                                                                          score on each trial). In the PTS= condition, simulated ac-
sparse data (a single choice per problem).
                                                                          curacy of PTS after one intervention was 93%, compared to
   Somewhat counter to the conclusion of past work on mod-
                                                                          95% with IG. To compare, in Experiment 1, PTS would have
eling intervention choices (Steyvers et al., 2003), we did not
                                                                          led to 85% and IG to 92% accurate choices, so the payoff
    2 Note, we used the maximum-likelihood estimates of θ instead         structure more closely resembled the PTS= condition.
of the fits from the Bayesian analysis in Figure 3 because the latter        In addition to these new problems, participants were then
were influenced by the hyperparamer distributions and thus did not
reflect the closest match to a participant’s actual choice data. MLE      tested on a selection of 20 of problem types from Experiment
values of θ and Bayesian fits were very highly correlated, however.       1 (specifically the subset for which IG and PTS made differ-
                                                                      346

       A      MLE of IG weight θ in all experiments         B       Hierarchical Model                            C           Hierarchical analysis: Samples of μ (mean of θ)
                  Exp 1
                                                                α         β       µ           κ
 Frequency
         10%                                                                                                                                                           Exp 1
             5%
                                                            Single Model                                             20%
                                                                                                                                                                       Exp 2 - PTS-
                                                                   τi                    θi                                                                            Exp 2 - PTS=
             0%
                   0.0          0.3     0.6           0.9
                                                            τi ∼ Gamma(α, β)
                  Exp 2: PTS=                                        exp(IGj p
                                                                             /τi )            EIGj                   15%
                                                            xij =   
                                                                      exp(IGj /τi ) )
                                                                                                             % Samples
                                                                               ij
 Frequency
         10%                                                yij ∼ Categorical(xij )           P T Sj
             5%                                                          yij                                         10%
             0%                                                                                   j trials
                   0.0          0.3     0.6           0.9
                                                            Combined Model
                                                                       i participants
                  Exp 2: PTS-                                                                                            5%
                                                            (1) τi ∼ Gamma(α, β)
 Frequency
         20%
                                                            (2) θi ∼ Gamma(µκ, (1 − µ)κ)
         10%                                                                                                             0%
                                                                         exp((θi EIGj +(1−θi )P T Sj )/τi )
             0%
                                                            (3) pij =   
                                                                          exp((θi EIGj +(1−θi )P T Sj )/τi ) )
                                                                                                                                       0.4            0.6            0.8
                   0.0          0.3     0.6           0.9
                                                            (4) yij ∼ Categorical(pij )                                                               μ
Figure 3 A: Histograms of best fitting θ parameters in all experiments. High θ indicates a better match of the data to IG
compared to PTS. B: Hierarchical Bayesian model of the combination of IG and PTS. Each trial, j, corresponds to one problem
type for which each participant chose one intervention, y. IG j And PT S j are three-vectors with model scores for the three
possible intervention on problem j. x is a three-vector of choice probabilities for each intervention. C: Distribution of samples
of the µ parameter (population mean of θ), fit to data in Experiment 1 and both conditions of Experiment 2.
ent predictions, assessed by their rank correlation). In Fig-                           µPT S− (method is similar to Kruschke, 2013). The 95% HDI
ure 2 (top) these problems are highlighted with a grey box.                             of this distribution did not include 0.0. As a result, we can be
  The overall procedure was the same as in Experiment 1.                                confident that there is a credible difference at the population-
                                                                                        level in the degree to which participants used IG in the two
Results                                                                                 experimental conditions, even when testing them on exactly
As before, participants were very accurate at choosing the                              the same problem set.
correct hypothesis at the end of a trial. In both conditions they
chose the correct graph on average 88% of the time (SD =
                                                                                        Discussion
0.13 and SD = 0.12 in PTS- and PTS=, respectively).                                     We found that participants were more prone to behave in
   Our main interest in this experiment was to see which in-                            a discriminatory (i.e., IG) fashion, after encountering a se-
terventions participants chose on the 20 three-node problem                             quence of problems for which PTS led to a lower expected
types that were already used in Experiment 1. The distri-                               payoff ( PTS-) than in another condition where PTS was not
bution of best fitting θ parameters is shown in the leftmost                            as detrimental to performance (PTS=). Importantly, we ob-
column of Figure 3 (bottom two plots). In the PTS- condition                            served this difference when we tested participants on the same
estimates of θ are shifted considerably towards 1.0 (i.e., pure                         set of problem types in both conditions following the same
IG strategy), compared to the PTS= condition.                                           overall number1   of trials. This shows that experience with par-
   To assess whether, at the population level, this new distri-                         ticular problem sets can carry over to others and induce a last-
bution of strategy weights was credibly different between the                           ing effect on people’s intervention strategies. More generally,
two conditions, we also fit the full Bayesian model described                           the results suggest that a tendency towards using PTS is not a
above (see middle panel in Figure 3) to participants’ choices.                          stable trait or bias and that people can adaptively select strate-
The right panel in Figure 3 shows the distributions of sam-                             gies based on overall features of a choice environment.
ples of the µ parameter from this Bayesian model for the two
new conditions and for Experiment 1. This parameter repre-                                                                    General Discussion
sents the population mean of θ, that is, the overall tendency of                        Previous work has argued that people adhere to optimal
all participants to choose interventions in line with IG, com-                          norms during information search in general (Nelson, 2005),
pared to PTS. As the figure shows, µ is shifted considerably                            as well as causal learning in particular (Steyvers et al., 2003).
towards higher IG-use in the PTS- condition of Experiment                               According to this view, people choose interventions that they
2, compared to PTS= and Experiment 1.                                                   expect to discriminate between a number of hypotheses and
   Another way of testing whether this change in behavior                               reduce their uncertainty about them. In contrast, we find that
between the two conditions is credible involves determining                             people were often better fit by a confirmatory positive testing
the 95% Highest Density Interval (HDI) of the distribution                              strategy or a mixture between discriminatory and confirma-
of the difference in µ in the PTS- and PTS= conditions. To                              tory models.
compute this difference, we took 10, 000 samples from each                                 We also found large variability in the degree to which in-
model, paired the samples randomly, and computed µPT S= −                               dividual participants used either strategy, suggesting that it is
                                                                               347

too simplistic to expect a single strategy to underlie people’s     everyday experience prior to entering the experiment primar-
interventions. Instead, our results imply that people have ac-      ily consists of sparse hypothesis spaces, and assuming it has
cess to multiple ways of addressing intervention problems,          a lower mental cost to compute, this might explain the overall
and, as shown by Experiment 2, also have control over which         prevalence of PTS in Experiment 1.
strategy to use in a given environment. We find this latter re-
sult particularly noteworthy, because it means that people are      Conclusion
perfectly capable of using the optimal strategy, but may only       In conclusion, we investigated how people interact with a
choose to do so if the payoff from the confirmatory strategy        simple causal system in order to discover how it works. We
is significantly reduced.                                           found that many participants did not behave in a purely dis-
                                                                    criminatory or confirmatory fashion, but at an individual level
Relation to other studies                                           show behavioral signatures of both strategies. Furthermore,
In contrast to our results, Steyvers and colleagues (2003)          people are able to adapt their strategies in response to cues
found that a version of the IG model fit their participants’        about the expected payoff of the strategy in the current task
intervention data well. However, there are several differences      context. These results suggest a much more adaptive view of
between their experimental design and the present study.            self-directed causal structure learning in humans than has so
Most importantly, by showing people only two hypotheses             far been considered in past research.
with equal prior likelihood, we avoided having to make as-          Acknowledgments. This work was supported by grant number
sumptions about which hypotheses participants consider at           BCS-1255538 from the National Science Foundation and the Intel-
any point in time. The best fitting model of Steyvers’ and col-     ligence Advanced Research Projects Activity (IARPA) via Depart-
leagues relied on the assumption that participants only con-        ment of the Interior (DOI) contract D10PC20023 to TMG.
sider their favorite hypothesis and its subgraphs, but this was
                                                                                                References
not made explicit to participants.
                                                                    Ahn, W.-k., Kim, N. S., Lassaline, M. E., & Dennis, M. J. (2000).
   Similar to our findings in Experiment 2, other work has             Causal status as a determinant of feature centrality. Cognitive
pointed out that hypothesis testing strategies can be changed          Psychology, 41(4), 361–416.
from confirmatory to discriminatory behavior. However,              Cheng, P. W., & Holyoak, K. J. (1985). Pragmatic reasoning
                                                                       schemas. Cognitive psychology, 17(4), 391–416.
these studies mainly manipulate different ways of framing           Coenen, A., & Gureckis, T.                      (2013).        When
the task altogether, for example by changing hypotheses to             does a rational model “fit”?                     Available from
be normative statements (e.g. Cosmides, 1989; Cheng &                  http://gureckislab.org/blog/?p=3710
                                                                    Cosmides, L. (1989). The logic of social exchange: Has natural
Holyoak, 1985). In addition to those findings, our results             selection shaped how humans reason? studies with the wason se-
show that people are sensitive to the expected payoff from             lection task. Cognition, 31(3), 187–276.
a strategy, even given the same framing of the task.                Gelman, A., Meng, X.-L., & Stern, H. (1996). Posterior predictive
                                                                       assessment of model fitness via realized discrepancies. Statistica
                                                                       Sinica, 6(4), 733–760.
Adaptive strategy selection                                         Klayman, J., & Ha, Y.-w. (1989). Hypothesis testing in rule dis-
                                                                       covery: Strategy, structure, and content. Journal of Experimental
By definition IG is always as good or better than PTS, which           Psychology: Learning, Memory, and Cognition, 15(4), 596.
raises the question why so many participants used PTS at all.       Kruschke, J. (2013). Bayesian estimation supersedes the t-test. Jour-
Since we showed in Experiment 2 that people shifted towards            nal of Experimental Psychology: General, 142(2), 573-603.
                                                                    Murphy, K. P. (2001). Active learning of causal bayes net struc-
IG, it does not seem to be the case that PTS use is a hard-            ture. Technical Report. Department of Computer Science, U.C.
wired “bias” or that people are universally unable to conform          Berkeley..
to the optimal model.                                               Navarro, D. J., & Perfors, A. F. (2011). Hypothesis generation,
                                                                       sparse categories, and the positive test strategy. Psychological
   One possibility is that PTS might be a simpler cognitive            review, 118(1), 120.
strategy to use, since it does not involve repeatedly simulat-      Nelson, J. D. (2005). Finding useful questions: on bayesian diag-
                                                                       nosticity, probability, impact, and information gain. Psychologi-
ing and comparing the outcome of interventions under both              cal review, 112(4), 979.
hypotheses, as IG does. When the decrement in performance           Nickerson, R. S. (1998). Confirmation bias: A ubiquitous phe-
from using PTS is fairly small (as in Experiment 1), the extra         nomenon in many guises. Review of General Psychology, 2(2),
                                                                       175.
computational costs involved in calculating something akin          Oaksford, M., & Chater, N. (1994). A rational analysis of the selec-
to IG could thus be outweighed by the benefit of simplicity.           tion task as optimal data selection. Psychological Review, 101(4),
   It is also possible that some people might use PTS by de-           608.
                                                                    Sloman, S. A., Love, B. C., & Ahn, W.-K. (1998). Feature centrality
fault due to prior positive experience with it. Multiple au-           and conceptual coherence. Cognitive Science, 22(2), 189–228.
thors have pointed out that PTS can be a good and even opti-        Steyvers, M., Tenenbaum, J. B., Wagenmakers, E.-J., & Blum, B.
mal strategy in situations when hypotheses are sparse, that is,        (2003). Inferring causal networks from observations and inter-
                                                                       ventions. Cognitive science, 27(3), 453–489.
when each hypothesis indexes only a small number of possi-          Tong, S., & Koller, D. (2001). Active learning for structure in
ble items in the world (Navarro & Perfors, 2011; Oaksford &            bayesian networks. In International joint conference on artificial
Chater, 1994). Under our causal interpretation of PTS, this            intelligence (Vol. 17, pp. 863–869).
                                                                    Wason, P. C. (1960). On the failure to eliminate hypotheses in a
translates to a case where hypotheses predict very different           conceptual task. Quarterly journal of experimental psychology,
effects (as in the PTS= condition of Experiment 2). Thus, if           12(3), 129–140.
                                                                348

