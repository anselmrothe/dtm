UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Hierarchical Adaptive Approach to the Optimal Design of Experiments
Permalink
https://escholarship.org/uc/item/4k29f6nk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Kim, Woojae
Pitt, Mark
Lu, Zhong-Lin
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

        A Hierarchical Adaptive Approach to the Optimal Design of Experiments
                       Woojae Kim1 (kim.1124@osu.edu), Mark Pitt1 (pitt.2@osu.edu),
                   Zhong-Lin Lu1 (lu.535@osu.edu), Mark Steyvers2 (mark.steyvers@uci.edu),
                      Hairong Gu1 (gu.124@osu.edu), & Jay Myung1 (myung.1@osu.edu)
                          1
                           Department of Psychology, Ohio State University, Columbus, OH 43210 USA
                     2
                         Department of Cognitive Sciences, University of California, Irvine, CA 92697 USA
                              Abstract                                   by adaptively taking into account what has been learned
  Experimentation is at the core of research in cognitive
                                                                         about the participant’s performance from past trials.
  science, yet observations can be expensive and time-
  consuming to acquire. A major interest of researchers is
  designing experiments that lead to maximal accumulation of                                                          Invisible
                                                                                             Contrast Sensitivity
  information about the phenomenon under study with the
  fewest possible number of observations. In addressing this
  challenge, statisticians have developed adaptive design
  optimization methods. This paper introduces a hierarchical                                                          Visible
  Bayes extension of adaptive design optimization that provides
  a judicious way to exploit two complementary schemes of
  inference (with past and future data) to achieve even greater
  accuracy and efficiency in information gain. We demonstrate
  the method in a simulation experiment in the field of visual
  perception.
                                                                                                                    Spatial Frequency
  Keywords: optimal experimental design, hierarchical Bayes,
  mutual information, visual spatial processing.
                                                                         Figure 1: Examples of stimuli (left) and a typical contrast
                                                                         sensitivity function (right). Sinewave gratings with varying
                         Introduction                                    contrast and spatial frequency are used to measure a
Experimentation advances cognitive science by providing                  person’s CSF.
quantified evidence for evaluating and testing theories.
From the standpoint of information theory (Cover &                          Their procedure was one implementation of algorithm
Thomas, 1991), one should design an experiment that across               technology being developed in the burgeoning field of
trials seeks to gain as much information as possible from the            design optimization (Atkitson & Donev, 1992; Amzal, Bois,
cognitive process under study. For example, experiments                  Parent, & Robert, 2006). Called adaptive design
often require choosing levels of an independent variable                 optimization (ADO; e.g., DiMattina & Zhang, 2008;
(e.g., stimuli of different sizes or intensities). These choices         Cavagnaro, Tang, Myung & Pitt, 2009), this method
impact the informativeness (or quality) of the resulting data,           capitalizes on the sequential nature of experimentation,
which in turn impacts what can be concluded about the issue              making each new measurement using the information
of interest.                                                             learned from previous measurements of a subject so as to
   As a concrete example, consider an experiment in visual               achieve maximal information about the cognitive process
psychophysics in which one is interested in estimating a                 under study.
viewer’s ability to see fine detail. When the sensitivity is                As currently used, ADO is tuned to optimizing a
measured with stimuli that vary not only in their contrast but           measurement process at the individual participant level,
also in their spatial frequency, the measurements form a                 without taking advantage of information available from data
contrast sensitivity function (CSF; Figure 1). A CSF                     collected from other individuals or testing sessions. To
characterizes a person’s vision more accurately than                     illustrate the situation using the example of CSF estimation,
traditional visual acuity measurements (i.e., using an eye               consider a space of CSFs in Figure 2, a point in which
chart) and is often useful for detecting visual pathologies              represents an individual’s measured CSF (e.g., the ones
(Comerford, 1983). However, because the standard                         shown with arrows). Suppose that one has already collected
methodology (e.g., staircase procedure) can require many                 CSFs from a group of participants (dots in the ellipse) and
hundreds of trials for accurate estimation of the CSF curve,             data are about to be collected from one more (triangle).
it is a prime candidate for improving information gain, and              Knowledge of what this person’s CSF function might look
Lesmes, Lu, Baek and Albright (2010) developed such a                    like can be informed by the group data, and thereby expedite
method. In each trial of the experiment, the to-be-presented             and improve data collection. Without the benefit of the
stimulus is chosen such that it maximizes information gain               group-level information, data collection would be more
                                                                   749

time-consuming because what constitutes a probable CSF                are observed and recorded. The observations are
would be unknown.                                                     subsequently used to update the prior to the posterior using
                                                                      Bayes' theorem. The posterior in turn is used to identify the
                                                                      optimal design for the next trial of the experiment. These
                                                                      alternating steps of design optimization, measurement, and
                                                                      updating of the individual-level data model are repeated in
                                                                      the experiment until a suitable stopping criterion is met.
                                                                               Next Individual        Higher-Level
                                                                                                       Prediction
                                                                                      Hierarchical
                                                                                    Model Updating
                         Space of CSFs
                                                                                                                           Posterior
Figure 2: Illustration of a situation in which contrast                                              Next Trial
sensitivity functions of a group of participants are measured
in an experiment.
                                                                                                          Individual Model
                                                                                                              Updating
   The purpose of the present investigation is to develop a
general design optimization framework that extends the                                               Optimal Design        Observed
                                                                                                                           Outcome
existing ADO methodology to incorporate the prior
knowledge of the population characteristics that are                                 Prior
                                                                                            Design               Measurement
available before the experiment to achieve even greater                                   Optimization
information gain. The proposed method, dubbed
hierarchical adaptive design optimization (HADO; Kim,
Pitt, Lu, Steyvers, & Myung, under review), is an                     Figure 3: The framework of HADO. The shaded area
integration of two existing techniques, hierarchical Bayesian         represents the conventional ADO framework and the
modeling (HBM) and adaptive design optimization. We                   peripheral part is the hierarchical extension of ADO.
begin by reviewing these two components briefly, followed
by a formal description of HADO and an application                               Hierarchical Extension of ADO
example.
                                                                      ADO optimizes designs using information available only on
                                                                      the individual participant level, without taking advantage of
        Adaptive Design Optimization (ADO)                            data collected from previous testing sessions. Hierarchical
The literature on optimal experimental design goes back to            Bayesian modeling (HBM; Good, 1965; Lee, 2006) not only
the pioneering work in the 1950s and 1960s in statistics              provides a flexible framework for incorporating this kind of
(Lindley, 1956; Box & Hill, 1967). The recent surge of                prior information but is also well suited for being integrated
interest in this field can be attributed largely to the advent of     within the existing Bayesian ADO. The basic idea of HBM
statistical computing, which has made it possible to solve            is to improve the precision of inference (e.g., parameter
more complex and a wider range of optimization problems.              estimation or power of a test) by taking advantage of
ADO is gaining traction in areas where data are costly to             statistical dependencies present in the data-generating
collect such as in neuroscience (e.g., DiMattina & Zhang,             structure that the individuals can be seen as being sampled
2008) and drug development (e.g., Miller, Dette, &                    from. From the Bayesian perspective, HBM can also be
Guilbaud, 2007). In psychology and cognitive science, ADO             viewed as a justified way to form an informative prior from
is gradually recognized and applied in research such as               real, observed data. Thus, on a conceptual level, HADO
retention memory (Myung, Cavagnaro, & Pitt, 2013),                    may be best described as a method for integrating the ADO
decision making (Cavagnaro, Pitt, Gonzalez, & Myung,                  technique with previously available information about the
2013), psychophysics (Lesmes, Jeon, Lu, & Dosher, 2006),              population structure, in a Bayesian prior distribution, to
and development of numerical representation (Tang, Young,             maximize the efficiency of data collection even further.
Myung, Pitt, & Opfer, 2010).                                             This is illustrated in Figure 3, HADO being described by
   ADO is formulated as a Bayesian sequential optimization            adding a loop over the conventional ADO. Being
algorithm that is executed over the course of an experiment.          standalone, ADO starts with an uninformative prior for each
The framework of ADO is depicted in the shaded area in                individual participant. HADO extends ADO by modeling a
Figure 3. On each trial of the experiment, on the basis of the        higher-level structure across all individuals, which can be
present state of knowledge (prior) about the phenomenon               used as an informative prior for the next, new measurement
under study, which is represented by a statistical model of           session. In the other way around, the parameter estimate of a
data, the optimal design with the highest expected                    new individual helps update the higher-level structure.
information gain is identified. The experiment is then
carried out with the optimal design, and measured outcomes
                                                                  750

Formulation of HADO                                                            For HADO to be adaptive, Bayesian updating for
The implementation of conventional ADO, also a                              posterior distribution is performed recursively on two
component of HADO, requires a statistical model defined as                  different levels. On the individual level, only the lower-level
a parametric family of probability distributions, p(y|θ, d)’s,              parameters θ are updated after each observation during an
which specifies the probability of observing an experimental                experiment. On the upper level, the higher-level parameters
outcome y given a parameter value θ and a design d. A prior                 η are updated at the end of each experiment through HBM.
for θ is assumed at the beginning of the experiment, and                    The estimate of η is used to calculate the prior for the next
after each observation, the prior is updated by Bayes’                      measurement session.
theorem, and then it serves as the prior for the next
experimental trial. For each trial, a design with the largest                                Simulation Experiments
value of a pre-defined utility function is selected. The                    The benefits of HADO were demonstrated in simulated
information-theoretic choice of a utility function is mutual                experiments in the domain of visual perception (an example
information (Cover & Thomas, 1991), which in the current                    used in the Introduction). Using the conventional ADO
context is given by                                                         framework described earlier, Lesmes et al. (2010)
                                                                            introduced an adaptive version of the contrast sensitivity test
  ( )                                                                       called qCSF. Contrast sensitivity, S(f), against spatial
                ( : ),
                             ( )               ( :  )     ( )               frequency f, was modeled using the truncated log-parabola
= ∬ log                   (      | ,    ) ( |         )d      d , (1)
                 ( :   )
                                                                            with four parameters:
where ( : ) is the collection of past measurements made
                                                                                              −         if  <        −
from the first to ( − 1)-th trials, denoted by ( : ) , plus
                                                                              ( )=                                                     (4)
an outcome, ( ) , to be observed in the current, t-th trial
conducted with a candidate design, .                                                          − (log 2)              otherwise,
                                                                                                             /
   To integrate HBM into ADO, a higher-level model of the
parameters ( : | ) is assumed (e.g. a multivariate normal                   where the four parameters are           , the peak sensitivity,
density with parameters η) where : = ( , … , ) is the                              , the peak frequency, , the bandwidth, and δ, the low-
collection of model parameters for all n individuals. The                   frequency truncation level.
joint posterior distribution of the hierarchical model given                   To demonstrate the benefits of HADO, the simulation
all observed data is expressed as                                           study considered four conditions in which simulated
                                                                            subjects were tested for their CSFs by means of four
     (   : , |   :   )∝ (     : |   : ) ( : | ) ( )               (2)       different measurement methods.
                       ∝ [∏       ( | )] ( : | ) ( ),
                                                                            Simulation Design
where ( ) is the prior distribution for the higher-level                    The two most interesting conditions were the ones in which
model’s parameters . If all parameters : and can be                         ADO and HADO were used for stimulus selection. In the
represented on a multidimensional grid and satisfy a certain                first, ADO condition, the qCSF method of Lesmes et al.
condition ( ’s are conditionally independent given ),                       (2010) was applied and served as the existing, state-of-the-
values of ( : , | : ) in Eq. (2) can be easily calculated                   art technique against which, in the second, HADO condition,
by dividing the values on each grid point by the summation                  its hierarchical counterpart developed in the present study
of all such values (i.e., normalization). Then we can obtain                was compared. If the prior information captured in the
the marginal distribution of by integrating Eq. (2) over                    higher-level structure of the hierarchical model can improve
   : as                                                                     the accuracy and efficiency of model estimation, then
                                                                            performance in the HADO condition should be better than
     ( |    : )=∬ (        : , |     : )d  : .                   (3)        that in the ADO (qCSF) condition. Also included for
                                                                            completeness were two other conditions to better understand
The estimates ̂ can be obtained as the expectation ̂ =                      information gain achieved by each of the two components of
∑               | : where G is the number of the grid points                HADO: hierarchical Bayes modeling (HBM) and ADO. To
of . As such, an informative prior for a new participant is                 demonstrate the contribution of HBM alone to information
constructed by plugging                  ̂ in the higher-level              gain, in the third, HBM condition, prior information was
model ( | ̂ ), which substitutes the uninformative prior in                 conveyed through HBM but no optimal stimulus selection
the conventional ADO.1                                                      was performed during measurement (i.e., no ADO). In the
                                                                            fourth, non-adaptive condition, neither prior data nor
                                                                            stimulus selection was utilized, so as to provide a baseline
   1                                                                        performance level against which improvements of the other
     Approximation of the prior in more general cases (e.g., a point
estimate ̂ is considered too restrictive to represent the prior, or the     methods could be assessed.
grid size is too large to manage) is discussed in Kim et al. (under            The hierarchical model in the HADO condition comprised
review).                                                                    two layers. On the individual level, each subject's CSF was
                                                                        751

modeled by the four-parameter, truncated log-parabola                    To prevent idiosyncrasies of the simulation’s probabilistic
described above. On the upper level, the generation of a              nature (due to simulated subjects’ random responses) from
subject's CSF parameters was described by a four-variate              misleading the interpretation of results, ten replications of
Gaussian distribution, along with the usual, normal-inverse-          the 147 leave-one-out experiments were run independently
Wishart prior. While a more refined structure might be                and results were averaged over all individual sessions (i.e.
plausible (e.g., the population is a mixture of heterogeneous         10×147=1470 experiments were conducted in total). All
groups, or CSFs covary with other observed variables), the            required computations for individual-level design
current hypothesis (i.e., individuals are similar to each other       optimization and Bayesian updating (i.e., shaded area in
in the sense that their CSFs are normally distributed) was            Figure 3) were performed on a grid in a fully deterministic
simple and sufficient to show the benefits of HADO.2                  fashion (i.e., no Monte Carlo integration). The posterior
   The ADO (qCSF) condition shared the same individual                inference of the higher-level model (i.e., outside the shaded
data model as specified in the HADO condition, but the                region in Figure 3), also involved no sampling-based
variability among individuals was not accounted for by a              computation. This was possible because the higher-level
higher-level model. Instead, each individual's parameters             model (i.e., Gaussian distribution) allowed for conditional
were given a diffuse, Gaussian prior. The HBM condition               independence between individuals so that the marginal
took the whole hierarchical model from HADO, but the                  posterior distribution in Eq. (3) could be evaluated as
measurement for each individual was made with stimuli                 repeated integrals over individual 's.
randomly drawn from a prespecified set. Finally, the non-
adaptive method was based on the non-hierarchical model in            Results
ADO (qCSF) and used random stimuli for measurement.                   Performance of the four methods of measurement was first
   To increase the realism of the simulation, we used real            evaluated with respect to information gain. The degree of
data collected from 147 adults who underwent CSF                      uncertainty about the current, n-th subject's parameters upon
measurements. The number of measurements obtained from                observing trial 's outcome was measured by the differential
each subject was more than adequate to provide highly                 entropy (extension of the Shannon entropy to the continuous
accurate estimates of their CSFs. These estimates were                case; see Cover & Thomas, 1991). Use of the differential
taken and assumed to be underlying CSFs in this simulation            entropy, which is not bounded in either direction on the real
study.                                                                line, is often justified by choosing a baseline state and
   To compare the four methods, we used a leave-one-out               defining the observed information gain as the difference
paradigm, treating 146 subjects as being previously tested            between two states' entropies. In the present context,
and the remaining subject as a new individual to be                   information gain is defined as
measured subsequently. We further assumed that, in each
simulated measurement session, artificial data are generated              (    ,   )=      (   )−     (    )                        (5)
from an underlying CSF (taken from the left-out subject)
with one of the four methods providing stimuli. This                  where ( ) is the entropy of the baseline belief about
situation represents a particular state in the recursion of           in a prior distribution so that       ( , ) may be interpreted
measurement sessions shown in Figure 3; that is, the session          as the information gain achieved upon trial t during the test
counter is changing from n = 146 to n = 147 to test a new,            of subject n relative to the baseline state of knowledge. For
147th subject. Theoretically, the two-stage updating shown            all the four methods, we took the entropy of the non-
in Figure 3 may be used from the start of a large-scale               informative prior as ( ).
experiment (i.e., from n = 1). However, because a large                  Shown in Figure 4 is the cumulative information gain
sample is needed for the higher-level structure to be                 observed with the four different methods. Each of the four
accurately estimated, HADO can be applied with no                     curves corresponds to information gain (y-axis) in each
significant loss of its benefit in a situation in which there are     simulation condition over 200 trials (x-axis) relative to the
some previously collected data.3                                      non-informative, baseline state (0 on the y-axis). The
                                                                      information gain measures were averaged over all 1,470
   2
     Benefit of using a non-normal, mixture distribution for          individual measurement sessions in each condition.
modeling higher-level structure was also investigated with this          The results demonstrate that the hierarchical adaptive
application example. A non-parametric, kernel density estimation      methodology (HADO) achieves higher information gain
(KDE; Hastie, Tibshirani, & Friedman, 2009) technique was
                                                                      than the conventional adaptive method (ADO). The
employed to capture a highly non-normal, multimodal distribution
on the space of CSF parameters in a simulation setup. Results         contribution of hierarchical modeling is manifested at the
suggested that, with a low-dimensional model such as a CSF            start of each session as a considerable amount of
model, the advantage of using such a mixture distribution is not      information (0.4) in the HADO condition (solid curve) than
significant, producing only slightly higher information gain than
HADO with a normal distribution used as higher-level structure.       particular hierarchical model is robust enough to take advantage of
   3
     Although not presented due to a space limit, an additional       even a small sample of previously collected data. However, the
simulation was conducted to see how this application of HADO          effect of small n may depend on the model employed, suggesting
performs when there is a small accumulation of data (e.g., n = 4,     that this observation would not generalize to all potential HADO
10, 40). The results suggest that the Bayesian estimation of this     applications (Kim et al., under review).
                                                                  752

no information (zero) in the ADO condition (dashed curve).                     exhibiting the lowest RMSE of all methods' from the start to
As expected, this is because HADO benefits from the                            the end of a session. The benefit of the prior information is
mutual informativeness between individual subjects, which                      also apparent in the HBM condition, making the estimates
is captured by the higher-level structure of the hierarchical                  more accurate than with the uninformed, ADO method for
model and makes it possible for the session to begin with                      the initial 40 trials, but the advantage is eclipsed in further
significantly greater information. As the session continues,                   trials by the effect of design optimization in ADO. In sum,
HADO needs 43 trials on average to reach the baseline                          HADO combines the strengths of both ADO and HBM to
performance of the non-adaptive method (dotted, horizontal                     enjoy both the initial boost in performance and faster
line) whereas ADO (qCSF) requires 62 trials. The clear                         decrease in error throughout the experiment.
advantage diminishes as information accumulates further
over the trials since the measure would eventually converge                                   9
to a maximum as data accumulate.                                                                      Peak Sensitivity           HADO
                                                                                              8                                  ADO (qCSF)
                      1.6                                                                     7                                  HBM
                                                                                                                                 Non-Adaptive
                      1.4                                                                     6
                                                                                  RMSE (dB)
                                                                                              5
                      1.2
                                                                                              4
   Information Gain
                       1
                                                                                              3
                      0.8
                                                                                              2
                      0.6                                                                     1
                      0.4                           Non-Adaptive                              0
                                                                                                  0       50            100       150           200
                                                    HBM
                                                                                                                  Trial Number
                      0.2                           ADO (qCSF)
                                                    HADO
                                                                               Figure 5: Accuracy of parameter estimation over
                       0
                            0   50       100        150            200         measurement trials achieved by each of the four
                                     Trial Number                              measurement methods.
Figure 4: Comparison of information gain of the four
experimental design methods for estimation of CSFs.
                                                                                                               Discussion
                                                                               The present study demonstrates how hierarchical Bayes
   The HBM condition (dash-dot curve), which employs the                       modeling (HBM) can be integrated into adaptive design
hierarchical modeling alone and no stimulus selection                          optimization (ADO) to improve the efficiency and accuracy
technique, enjoys the prior information provided by the                        of measurement. The resulting hierarchical adaptive design
hierarchical structure at the start of a session and exhibits                  optimization (HADO) further improves the efficiency of
greater information gain than the ADO method until it                          experiments by not only achieving maximal information
reaches trial 34. However, due to the lack of stimulus                         gain in each experimental trial, but also borrowing
optimization, the speed of information gain is considerably                    information from other experiments. When applied to the
slower, taking 152 trials to attain baseline performance. The                  problem of estimating a contrast sensitivity function (CSF)
non-adaptive approach (dotted curve), with neither prior                       in visual psychophysics, HADO achieved an average
information nor design optimization, shows the lowest level                    decrease in parameter estimation error of 38% (from 4.9 dB
of performance.                                                                to 3.1 dB; see Lesmes et al., 2010, for the measurement
   Information gain analyzed above may be viewed as a                          scale of errors) over conventional ADO, under the scenario
summary statistic, useful for evaluating the measurement                       that a new session could afford to make only 30
methods under comparison. Not surprisingly, we were able                       measurement trials.
to observe the same profile of performance differences in                         Although the simulation study served the purpose of
estimating the CSF parameters. Figure 5 shows the                              demonstrating the benefit of the hierarchical adaptive
comparison of parameter estimation errors for each of the                      methodology, the full potential of HADO should be greater
four methods. Error was quantified in terms of root mean                       than that demonstrated in our particular example. The level
squared error (RMSE; y-axis) from the known, underlying                        of improvement possible with HADO depends on the
parameter value over 200 trials (x-axis). Because we                           sophistication of the hierarchical model itself. In our case,
observed the same trend for all parameters, results for the                    the model was based on a simple hypothesis that a newly
first parameter (peak sensitivity) is shown for simplicity.                    tested individual belongs to the population from which all
   As with the case of information gain, HADO benefits                         other individuals have been drawn. It conveys no further
from the informative prior through the hierarchical model as                   specific information about the likely state of a new
well as the optimal stimuli through design optimization,                       individual (e.g., his or her membership to a sub-population
                                                                               is unknown).
                                                                         753

   There are various situations in which hierarchical              Box, G. F. B., & Hill, W. J. (1967). Discrimination among
modeling can take better advantage of the data-generating            mechanistic models. Technometrics, 9, 57-71.
structure. For example, although modeled behavioral traits         Cavagnaro, D. R., Pitt, M. A., Gonzalez, R., & Myung, J. I.
vary across individuals, they may covary with other                  (2013). Discriminating among probability weighting
variables that can be easily observed, such as demographic           functions using adaptive design optimization. Journal of
information (e.g., age, gender, occupation, etc.) or other           Risk and Uncertainty, 47(3), 255-289.
measurement data (e.g., contrast sensitivity correlates with       Cavagnaro, D. R., Tang, Y., Myung, J. I. & Pitt, M. A.
measures of visual acuity - eye chart test). In this case, a         (2009). Better data with fewer participants and trials:
general, multivariate regression or ANOVA model may be               Improving experimental efficiency with adaptive design
employed as the upper-level structure to utilize such                optimization. In N. A. Taatgen & H. van Rijn (eds.),
auxiliary information to define a more detailed relationship         Austin, TX: Cognitive Science Society.
between individuals. This greater detail in the hierarchical       Comerford, J. P. (1983). Vision evaluation using contrast
model should promote efficient measurement by providing              sensitivity functions. American Journal of Optometry and
more precise information about the state of future                   Physiological Optics, 60, 394–398.
individuals.                                                       Cover, T. M., & Thomas, J. A. (1991). Elements of
   Another situation in which hierarchical modeling would            information theory. Hoboken, New Jersey: John Wiley &
be beneficial is when a measurement is made after some               Sons, Inc.
treatment and it is sensible or even well known that the           DiMattina, C., & Zhang, K. (2008). How optimal stimuli for
follow-up test has a particular direction of change in its           sensory neurons are constrained by network architecture.
outcome (i.e., increase or decrease). Taking this scenario           Neural Computation, 20, 668-708.
one step further, a battery of tests may be assumed to exhibit     Good, I. J. (1965). The estimation of probabilities: An essay
profiles that are characteristic of certain groups of                on modern Bayesian methods. Cambridge, MA: MIT
individuals. The higher-level structure can also be modeled          Press.
(e.g., by an autoregressive model) to account for such             Hastie, T., Tibshirani, R., & Friedman, J. (2009). The
transitional variability in terms of the parameters of the           elements of statistical learning. Springer.
measurement model. With these kinds of structure built in          Kim, W., Pitt, M.A., Lu, Z.-L., Steyvers, M. & Myung, J.I.
the hierarchical model, HADO can be used to infer quickly            (under review). A hierarchical adaptive approach to
the state of new individuals.                                        optimal experimental design.
                                                                   Lee, M. D. (2006). A hierarchical Bayesian model of human
                         Conclusion                                  decision-making on an optimal stopping problem.
Science and society benefit when data collection is efficient        Cognitive Science, 30, 55-580.
with no loss of accuracy. The proposed HADO framework,             Lesmes, L. A., Jeon, S.-T., Lu, Z.-L., & Dosher, B. A.
which judiciously integrates the best features of design             (2006). Bayesian adaptive estimation of threshold versus
optimization and hierarchical modeling, is an exciting new           contrast external noise functions: The quick TvC method.
tool that can significantly improve upon the current state of        Vision Research, 46, 3160-3176.
the art in experimental design, enhancing both measurement         Lesmes, L. A., Lu, Z.-L., Baek, J., & Albright, T. D. (2010).
and inference. This theoretically well-justified and widely          Bayesian adaptive estimation of the contrast sensitivity
applicable experimental tool should help accelerate the pace         function: The quck CSF method. Journal of Vision, 10, 1-
of scientific advancement in behavioral and neural sciences.         21.
                                                                   Lindley, D.V. (1956). On a measure of the information
                                                                     provided by an experiment. Annals of Mathematical
                    Acknowledgments
                                                                     Statistics, 27(4), 986-1005.
This research is supported by National Institute of Health         Miller, F., Dette, H., & Guilbaud, O. (2007). Optimal
Grant R01-MH093838 to J.I.M and M.A.P., as well as                   designs for estimating the interesting part of a dose-effect
National Eye Institute Grant R01-EY021553-01 to Z.-L.L.              curve. Journal of Biopharmaceutical Statistics, 17, 6.
The present conference paper is based largely on Kim et al.        Myung, J. I., Cavagnaro, D. R., & Pitt, M. A. (2013). A
(under review) that has been submitted for journal                   tutorial on adaptive design optimization. Journal of
publication.                                                         Mathematical Psychology, 57, 53-67.
                                                                   Tang, Y., Young, C., Myung, J. I., Pitt, M. A., & Opfer, J.
                         References                                  (2010). Optimal inference and feedback for
Amzal, B., Bois, F. Y., Parent, E., & Robert, C. P. (2006).          representational change. In S. Ohlsson & R. Catrambone
   Bayesian-optimal design via interacting particle systems.         (Eds.), Proceedings of the 32nd annual meeting of the
   Journal of the American Statistical association,                  cognitive science society (p.2572-2577). Austin, TX:
   101(474),773-785.                                                 Cognitive Science Society.
Atkinson, A., & Donev, A. (1992). Optimum experimental
   designs. Oxford University Press.
                                                               754

