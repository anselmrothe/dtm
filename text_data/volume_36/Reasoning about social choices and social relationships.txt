UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reasoning about social choices and social relationships
Permalink
https://escholarship.org/uc/item/7752k71z
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Jern, Alan
Kemp, Charles
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Reasoning about social choices and social relationships
                                       Alan Jern                                      Charles Kemp
                                jern@rose-hulman.edu                                  ckemp@cmu.edu
                    Department of Humanities and Social Sciences                 Department of Psychology
                          Rose-Hulman Institute of Technology                   Carnegie Mellon University
                              Abstract                                    Kemp, 2011). In social settings, however, the chooser’s utility
                                                                          may depend on the utility experienced by others. One way to
   We study inferences about social choices—choices that affect
   people besides the chooser. Social choices depend on the rela-         capture this dependence is to suppose that the chooser’s util-
   tionships between the people involved: for example, whether            ity function is a weighted combination of the utilities directly
   they are friends, strangers, or enemies. We propose that these         experienced by all affected individuals (Wyer, 1969; McClin-
   different social relationships correspond to different ways in
   which the chooser weights another person’s utility relative to         tock, 1972; Griesinger & Livingston, Jr., 1973). We propose
   her own. We describe a probabilistic model of social reasoning         that people represent different social relationships as differ-
   that incorporates this notion of weighted utility, and evaluate it     ent utility weighting functions. We show that combining this
   in an experiment in which participants made inferences about
   others’ social choices. The results support our probabilistic          proposal with the inverse reasoning approach can account for
   model and expose some of the assumptions that people tend to           a wide array of social inferences, including inferences about
   make when reasoning about social choices.                              whether a pair of people are more likely to be friends, ene-
   Keywords: social cognition; social reasoning; folk social psy-         mies, or strangers.
   chology; probabilistic models
                                                                             Our proposal is conceptually related to previous computa-
   People frequently engage in folk psychological reasoning.              tional approaches that have been used to explain how people
We explain and predict other people’s behavior and draw in-               infer social goals like “helping” (Baker, Goodman, & Tenen-
ferences about other people’s thoughts and feelings. This                 baum, 2008; Ullman et al., 2009). These approaches have
reasoning sometimes depends on knowledge of social rela-                  focused on how people reason about sequences of actions
tionships. For example, if you know that Alice and Bob                    that extend through time and space. By contrast, we explore
are friends, you might predict that Alice would be willing                one of the simplest possible settings that supports inferences
to make a financial sacrifice to help Bob, perhaps by offering            about social choices and how such choices are affected by
him a loan. If you know that Alice and Bob are enemies, you               social relationships.
might predict that Alice would not be willing to make a finan-               The next two sections introduce our formal approach in
cial sacrifice to benefit Bob, but she might be willing to make           more detail. We then evaluate our approach in an experiment
a financial sacrifice to harm Bob, perhaps by turning down a              in which participants made several kinds of inferences about
mutually beneficial business opportunity.                                 social choices.
   Alice’s choices above are instances of social choices—
choices that affect people besides the chooser. Her choices                                  A social choice model
each result in a cost to herself, but also a benefit or cost to           We propose that people reason about social choices by invert-
Bob. These examples illustrate how knowledge of the rela-                 ing a simple model of how utilities give rise to social choices.
tionship between two people can inform expectations about                 Consistent with previous approaches (Train, 2009), we as-
the social choices that they will make. Conversely, observing             sume that utilities are additive and that people tend to choose
a social choice may allow us to infer something about the re-             options with greater utilities. With social choices, the notion
lationship between the people involved. Despite the fact that             of utility can be confusing because utility is not necessarily
people commonly reason about social choices and social re-                identical to a direct reward. For example, if Alice’s choice
lationships, there are few formal proposals about how people              can either benefit or harm Bob, Alice’s utility may depend on
perform this sort of reasoning (Haslam, 1994). We suggest in              the effect her choice has on Bob in addition to any benefit
this paper that inferences about social choices and relation-             her choice provides for herself. To alleviate this confusion,
ships can be viewed as a kind of probabilistic reasoning.                 we will refer to the utilities assigned to rewards or payouts
   Previous research has explored how people reason about                 as direct utilities and will use the term “utility” to refer to a
other people’s non-social choices, like choosing which shirt              chooser’s total utility.
to buy. Standard choice models can be used to predict the                    How much utility a chooser assigns to different options in
choices that follow from a given set of preferences, and “in-             a social choice depends on how the chooser weights the direct
verting” these models provides a way to reason backward and               utilities of everyone affected by the choice. Here we assume
infer the preferences that likely motivated an observed choice.           that there is only one other person affected by the choice, but
Several studies have shown that this inverse reasoning ap-                our approach can be straightforwardly extended to include
proach accounts well for experiments that focus on reasoning              any number of people. We will henceforth refer to the chooser
about non-social choices (Lucas et al., 2014; Bergen, Evans,              as Alice and the person affected by the choice as Bob. Let wA
& Tenenbaum, 2010; Jern & Kemp, 2011; Jern, Lucas, &                      be the weight that Alice assigns to her own direct utility and
                                                                      689

let wB be the weight that Alice assigns to Bob’s direct utility.                (a)               Altruistic
                                                                                                  (0,1)
We constrain these weights to sum to 1: wA + wB = 1. When                                   1
wB = 0, Alice does not take Bob’s direct utility into account
                                                                                                             Prosocial
at all. To capture the idea that Alice may either want to help                                               (1/2,1/2)
or harm Bob, we include another parameter γB ∈ {−1, +1}
that specifies the polarity that Alice assigns to Bob’s utility.
                                                                                                        γB = 1
When γB = −1, Alice’s utility increases as Bob’s direct utility                    γB · wB  0
                                                                                                                          Individualistic
                                                                                                                          (1,0)
decreases, and when γB = 1, Alice’s utility increases as Bob’s
direct utility increases. The former case might apply when                                              γB = −1
Alice and Bob are enemies and the latter case might apply                                                    Competitive
when they are friends.                                                                          Sadistic     (1/2,−1/2)
   We can now specify how Alice’s utility is computed. We                                       (0,−1)
                                                                                           −1
will use UA to represent her total utility and uA and uB to rep-                              0                       1
resent direct utilities for Alice and Bob. Consistent with pre-                                         wA
vious research (Wyer, 1969; McClintock, 1972; Griesinger
                                                                                (b)             Altruistic
& Livingston, Jr., 1973), we define Alice’s total utility as a                                  (50,100)
linear combination of direct utilities:                                                   100
                                                                                                                Prosocial
                   UA = wA · uA + γB · wB · uB .                                                                (85,85)
In some cases, Alice will not know Bob’s direct utility be-
fore making a choice. In these cases, Alice’s (possibly false)                                                         Individualistic
beliefs about uB will influence her choices. We therefore as-                    Bob’s     50                          (100,50)
                                                                                 payout
sume that uB represents Alice’s belief about Bob’s direct util-
ity, rather than the true value of Bob’s direct utility.
                                                                                                Sadistic
   We will refer to a particular setting of these parameters as
                                                                                                (50,0)          Competitive
Alice’s social attitude toward Bob. Figure 1a shows all the                                                     (85,15)
                                                                                            0
possible settings of these parameters. The cyan line on the
                                                                                               50                100
top half corresponds to cases in which γB = 1 and the green
line on the bottom half corresponds to cases in which γB =                                      Alice’s payout
−1. Some of these social attitudes are labeled in the figure
using English adjectives. For example, point (0, 1) is labeled       Figure 1: Social attitudes and social choices. (a) The two line
“altruistic” because in this case Alice completely discounts         segments show all possible settings of parameters wA , wB , and
her own direct utility in favor of Bob’s. Figure 1b shows a set      γB . Some settings correspond to the social attitudes indicated
of options along the blue arc that might be available to Alice.      by the labels. (b) A set of options available to Alice. Alice’s
Each option results in a payout to both Alice and Bob. Every         preferred option depends on her social attitude toward Bob.
point along the lines in Figure 1a corresponds uniquely to a         This figure is adapted from Liebrand (1984) and Murphy and
preferred option along the arc in Figure 1b. Some of these           Ackermann (2012).
options are identified by the social attitudes that would lead
Alice to prefer them. For example, if Alice is altruistic, she
will choose the (50, 100) option, which provides the greatest        Table 1 (“Basic relationship model”) summarizes the com-
payout to Bob.                                                       monsense assumptions we make about these relationships. If
   To complete the social choice model, we must specify how          Alice and Bob are friends, we assume that Alice assigns a
Alice selects an option. We will refer to a function that spec-      positive polarity to Bob’s direct utility (i.e, γB = 1). If Alice
ifies how choices are made as a choice function. When mod-           and Bob are enemies, we assume that Alice assigns a nega-
eling the experiment discussed later, we consider two com-           tive polarity to Bob’s direct utility (i.e., γB = −1). Note that
mon choice functions. The first is a utility-maximizing choice       for both friends and enemies, we make no assumption about
function, which specifies that Alice will select the option that     the relative weights Alice assigns to her own and Bob’s direct
maximizes UA . We will call the second a utility-matching            utilities. If Alice and Bob are strangers, we assume that Alice
function because it specifies that Alice will select options         weights her own direct utility more than Bob’s, but we make
probabilistically in proportion to their utilities.                  no assumption about the polarity Alice assigns to Bob’s direct
                                                                     utility.
           Representing social relationships                            We now show how performing probabilistic inference us-
We now show how it is possible to define different social re-        ing the social choice model in the previous section can be
lationships in terms of the social attitude parameters defined       used to account for inferences about social relationships.
in the previous section. In this paper, we focus on three re-        Suppose you observe Alice make a social choice. For ex-
lationships: friends, enemies, and strangers. The left side of       ample, in the experiment described in the next section, we
                                                                 690

                               Basic relationship model    No relationship model        Augmented relationship model
              Relationship         wA and wB     γB            wA and wB       γB          wA and wB                   γB
              Friends                  –           1                –            –          wA < wB                     1
              Strangers             wA > wB        –                –            –          wA > wB                     1
              Enemies                  –        −1                  –            –          wA > wB                   −1
Table 1: Three social relationships defined in terms of the social attitude parameters wA , wB , and γB . This table shows assump-
tions made by three models described in the text. The “–” entries indicate no assumptions.
consider a simple social choice in which Alice chooses a type         the labels above the plots indicate what information was pro-
of candy that will be given to both her and Bob. Let Al-              vided in that condition. In six conditions (Figure 2a.i), par-
ice’s choice be denoted by cA . Using the assumptions just            ticipants inferred Alice’s preference; in six conditions (2a.ii),
described, we can apply Bayes’ rule to compute probabilities          participants inferred Alice’s belief about Bob’s preference;
of each relationship after observing cA :                             in six conditions (2a.iii), participants predicted Alice’s social
                                                                      choice; and in four conditions (2a.iv), participants inferred
          P(Friends|cA ) ∝ P(cA |Friends)P(Friends)                   Alice’s and Bob’s relationship.
                          = P(cA |γB = 1)P(Friends)          (1)
       P(Strangers|cA ) ∝ P(cA |Strangers)P(Strangers)                Model
                          = P(cA |wA > wB )P(Strangers)      (2)      We considered three models of this task. All models assume
        P(Enemies|cA ) ∝ P(cA |Enemies)P(Enemies)                     that Alice is more likely to choose options with greater utility
                                                                      and that the utility she assigns to each option is a weighted
                          = P(cA |γB = −1)P(Enemies)         (3)      function of her and Bob’s direct utilities. The models differ
Computing the likelihood terms in these equations, like               with respect to the assumptions they make about how people
P(cA |γB = 1) in Equation 1, requires integrating over the val-       think about friends, strangers, and enemies. Each model’s
ues  of the other parameters. For example, P(cA |γB = 1) =            assumptions are shown in Table 1.
                                                                         The first model, which we will refer to as the basic re-
R R
  wA wB P(cA |wA , wB , γB = 1)P(wA , wB )dwB dwA . We assume a
uniform prior distribution over the parameters wA , wB , and γB ,     lationship model, makes three assumptions that were previ-
and compute P(cA |wA , wB , γB ) by applying the social choice        ously described and are shown in the left column of Table
model.                                                                1. We call this model the basic relationship model because
                                                                      the few assumptions that it makes seem obligatory in order to
                          Experiment                                  capture commonsense expectations about friends, strangers,
We evaluated our formal approach by comparing its predic-             and enemies.
tions to people’s inferences in an experiment. Our experiment            In order to evaluate whether the assumptions made by the
involved a simple social choice in which Alice chooses be-            basic relationship model are needed to account for people’s
tween two types of candy and the candy she chooses is given           inferences, we considered a baseline model that places uni-
to both her and Bob. Although this choice is simple, it de-           form prior distributions over each model parameter. Although
pends on three factors: Alice’s candy preferences, Alice’s be-        this no relationship model makes no assumptions at all about
liefs about Bob’s candy preferences, and Alice’s social atti-         the differences between the three relationships, it still as-
tude toward Bob. In other words, this simple choice captures          sumes that Alice is more likely to choose options with greater
one important feature of real-life social choices: Alice must         utility. As a result, there are some situations in which the
balance her own interests against Bob’s interests.                    model should make sensible inferences about Alice.
   We provided participants with three of the following four             The third model in Table 1 adds three assumptions to the
pieces of information and asked them to infer the fourth: (1)         basic relationship model. We will describe this third model
the type of candy Alice likes best, (2) the type of candy Al-         after presenting our data.
ice believes that Bob likes best, (3) Alice’s and Bob’s rela-            All models assume a uniform prior distribution on the three
tionship, and (4) Alice’s choice of candy—either Candy 1 or           relationships, meaning that all three types of relationships are
Candy 2. Alice and Bob can each prefer either Candy 1 or              initially judged to be equally probable. This assumption is
Candy 2, Alice can choose Candy 1 or Candy 2, and we con-             unlikely to be true in general, but the cover story of our ex-
sidered three possible relationships between Alice and Bob:           periment suggested that, in the context of the experiment, the
friends, strangers, and enemies. Eliminating one of the four          three types of relationships were equally common. We as-
pieces of information and enumerating all possible values of          sumed that Alice assigns a generally positive utility to each
the remaining pieces of information results in 22 distinct in-        type of candy. To be consistent with previous research (Lucas
ference problems, each of which constituted an experimental           et al., 2014; Jern et al., 2011), both models also assume nor-
condition. These conditions are shown in Figure 2a, where             mal prior distributions over utilities (ui ∼ N (2, 4)), but the
                                                                  691

models make nearly identical predictions given other distri-           • Relationship: How likely is it that Alice and Bob are . . .
butional assumptions (e.g., ui ∼ Uniform(0, 10)). We gen-                  (1) Friends? (2) Strangers? (3) Enemies?
erated one set of predictions for each model using a utility-
maximizing choice function and one set of predictions using            Participants answered each question using a slider that
a utility-matching choice function.                                    spanned from 0 (very unlikely) to 100 (very likely).
Method                                                                 Results
Participants 80 participants were recruited from the Ama-              Model predictions The information provided about Alice
zon Mechanical Turk website. They were paid for their par-             was encoded in the models as follows. Alice’s preference
ticipation.                                                            was captured by placing a constraint on her direct utilities.
                                                                       For example, if Alice preferred Candy 1, the models assumed
Design We used a mixed design in which each participant                that u1A > u2A , where the subscript indicates the person and the
completed all of the conditions for one type of inference. That        superscript indicates the candy. Similarly, if Alice believed
is, each participant completed all of the conditions in one row        that Bob preferred Candy 1, the models assumed that u1B > u2B .
of Figure 2a. Participants were randomly assigned to infer-                The model predictions were computed by conditioning on
ence type and completed the conditions in a random order.              the provided information. For example, in one condition, the
Procedure The experiment was completed online. Each                    provided information stated that Alice prefers Candy 1, Alice
condition appeared on a separate page. Participants were first         believes that Bob prefers Candy 2, and Alice chose Candy 2.
told that a group of researchers had conducted a study to see          The probability that Alice and Bob are friends can therefore
how people in different relationships make choices that af-            be computed as follows:
fect others. They were told that the study involved pairs of
people and that some of these pairs of people were friends,                P(Friends|u1A > u2A , u1B < u2B , cA = 2) ∝
some were strangers, and some were enemies. Finally, they                          P(cA = 2|Friends, u1A > u2A , u1B < u2B )P(Friends).
were told that the choices in the study were about two differ-
ent types of candy, Candy 1 and Candy 2, and that all of the           The first term on the right-hand side of the equa-
people in the experiment had been allowed to try both types            tion can be expanded by applying the model’s def-
of candy before making any choices.                                    inition of the friends relationship and then applying
   In each condition, participants were presented with three           the appropriate choice function.               Predictions in the
of the following four pieces of information about one pair of          preference inference conditions were similarly generated
people in the fictional study.                                         by computing P(u1A > u2A |Relationship, Bob’s preference, cA )
                                                                       for each condition.           Predictions in the belief infer-
• Alice and Bob are [friends/strangers/enemies].                       ence conditions were generated by computing P(u1B >
• Alice was asked which type of candy she liked best. Alice            u2B |Relationship, Alice’s preference, cA ), and predictions in
   liked [Candy 1/Candy 2] best.                                       the choice prediction conditions were generated by comput-
• Alice was asked which type of candy she thought Bob liked            ing P(cA |Relationship, Alice’s preference, Bob’s preference).
   best. Alice thought that Bob liked [Candy 1/Candy 2] best.          We generated 200,000 samples from the appropriate distribu-
• Alice was asked to pick a candy that would be given to both          tion in each condition by importance sampling with samples
   Alice and Bob. Alice picked [Candy 1/Candy 2].                      drawn from the corresponding prior distributions.
The information in brackets depended on the condition.                 Human judgments Participants’ ratings for each condition
Whether Alice liked Candy 1 or Candy 2 best was random-                were normalized so that their ratings summed to 1. Figure
ized across participants. The actual names used in the exper-          2a compares ratings for all conditions with the predictions
iment were also randomized.                                            of the utility-matching basic relationship model. These plots
   In the inference phase of each condition, participants re-          suggest that the commonsense assumptions made by the ba-
sponded to one of the following four sets of questions, de-            sic relationship model are sufficient to account for people’s
pending on the inference condition.                                    inferences in most conditions.
                                                                           The overall performance of the basic relationship and no
• Alice’s preference: How likely is it that . . . (1) Alice liked      relationship models is shown in Figures 2b.i and 2b.ii. Figure
   Candy 1 best? (2) Alice liked Candy 2 best?                         2b.i suggests that the basic relationship model predicts peo-
• Alice’s belief: How likely is it that . . . (1) Alice thinks         ple’s quantitative judgments quite well. The model performs
   Bob likes Candy 1 best? (2) Alice thinks Bob likes Candy            significantly better than the no relationship model (z = 3.04,
   2 best?                                                             p < .01), suggesting that participants did distinguish be-
• Social choice: Alice was asked to pick a candy that would            tween friend, stranger, and enemy relationships, and expected
   be given to both Alice and Bob. How likely is it that . . . (1)     these relationships to influence people’s social choices. The
   Alice picked Candy 1 for both Alice and Bob? (2) Alice              utility-maximizing versions of both models performed worse
   picked Candy 2 for both Alice and Bob?                              (r = 0.88 and r = 0.72) than the utility-matching basic rela-
                                                                   692

(a) (i) Infer Alice’s preference                                                                                                       (b) (i)                        Basic relationship
                                                                                                                                                                  1
                                                                                                                                             Mean human ratings
                               Friends          Strangers        Enemies          Friends                Strangers        Enemies
                               B likes 1        B likes 1        B likes 1        B likes 1              B likes 1        B likes 1
                               A chose 1        A chose 1        A chose 1        A chose 2              A chose 2        A chose 2
      P(preference)
                         1
                                                                                                                                                                                        r = 0.91
                        0.5
                                                                                                                                                                                        M SE = 0.013
                         0                                                                                                                                        0
                                   1       2        1       2        1       2        1       2           1       2        1       2                                  0                     1
                                   Candy            Candy            Candy            Candy               Candy             Candy                                         Model probabilities
     (ii) Infer Alice’s belief about Bob’s preference                                                                                       (ii)                          No relationship
                                                                                                                                                                  1
                                                                                                                                             Mean human ratings
                               Friends          Strangers        Enemies          Friends                Strangers        Enemies
                               A likes 1        A likes 1        A likes 1        A likes 1              A likes 1        A likes 1
                               A chose 1        A chose 1        A chose 1        A chose 2              A chose 2        A chose 2
      P(preference)
                         1
                                                                                                                                                                                        r = 0.71
                        0.5
                                                                                                                                                                                        M SE = 0.034
                         0                                                                                                                                        0
                                   1       2        1       2        1       2        1       2           1       2        1       2                                  0                     1
                                   Candy            Candy            Candy            Candy               Candy             Candy                                         Model probabilities
     (iii) Predict Alice’s choice                                                                                                           (iii) Augmented relationship
                                                                                                                                                                  1
                                                                                                                                             Mean human ratings
                               Friends          Strangers        Enemies          Friends                Strangers        Enemies
                               A likes 1        A likes 1        A likes 1        A likes 1              A likes 1        A likes 1
                               B likes 1        B likes 1        B likes 1        B likes 2              B likes 2        B likes 2
                         1
      P(choice)
                                                                                                                                                                                        r = 0.96
                        0.5
                                                                                                                                                                                        M SE = 0.008
                         0                                                                                                                                        0
                                   1       2        1       2        1       2        1       2           1       2        1       2                                  0                     1
                                   Candy            Candy            Candy            Candy               Candy             Candy                                         Model probabilities
     (iv) Infer Alice’s and Bob’s relationship                                                                                              (iv)                               Fitted
                                                                                                                                                                  1
                                                                                                                                             Mean human ratings
                               A likes 1        A likes 1        A likes 1        A likes 1
                               B likes 1        B likes 1        B likes 2        B likes 2                   Mean human ratings
                               A chose 1        A chose 2        A chose 1        A chose 2
      P(relationship)
                         1                                                                                    Basic relationship
                                                                                                              model predictions                                                         r = 0.96
                        0.5
                                                                                                                                                                                        M SE = 0.008
                         0                                                                                                                                        0
                               F       S   E    F       S   E    F       S   E    F       S   E                                                                       0                     1
                              Relationship     Relationship     Relationship     Relationship                                                                             Model probabilities
Figure 2: Experiment results and model predictions. (a) Comparison between the utility-matching basic relationship model
predictions and mean human ratings. Each row shows results for one type of inference. The labels at the top of each plot
indicate the information that the model and participants were provided with. In the last row, F = friends, S = strangers,
and E = enemies. The error bars for the mean human ratings indicate standard errors of the mean. The conditions in boxes
motivated the augmented relationship model discussed in the text. (b) Overall performance of the four models discussed in the
text. Predictions are for utility-matching choice functions in all cases. The gray lines in the plots indicate perfect correspondence
between the model predictions and human ratings. MSE = mean squared error.
tionship model. Therefore, we will not discuss utility maxi-                                            Bob likes Candy 1 best. The model predicts that it is equally
mization any further.                                                                                   probable that Alice will choose Candy 1 and Candy 2 because
   Despite the overall accuracy of the basic relationship                                               the model does not make any assumptions about whose direct
model, people’s inferences in several conditions, indicated by                                          utility Alice will weight more heavily. Alice might weight her
boxes in Figure 2a, suggest that people made some additional                                            own direct utility more heavily and choose Candy 1, or she
assumptions that are not captured by the model. For example,                                            might weight Bob’s direct utility more heavily and choose
consider the condition in Figure 2a.iii in which Alice and Bob                                          Candy 2 because the pair are enemies. By contrast, partic-
are enemies, Alice likes Candy 1 best, and Alice believes that                                          ipants judged it more likely that Alice would choose Candy
                                                                                                  693

1, consistent with an expectation that Alice tends to weight          tionally, social choices are often influenced by social norms
her own direct utility more heavily. The other highlighted            and other factors that go beyond the direct costs and benefits
conditions in Figure 2a suggest that people expected Alice            to everyone affected. An important goal for research in both
to weight Bob’s direct utility more than her own when they            cognitive science and social cognition is to develop a general
were friends, and expected Alice to assign a positive polarity        computational account of folk social psychology that applies
to Bob’s direct utility when they were strangers. These ex-           to situations like these. Our work suggests that utility weight-
pectations are broadly consistent with how people in differ-          ing functions and probabilistic inference are two principles
ent relationships actually make social choices (Loewenstein,          that can contribute to such an account.
Thompson, & Bazerman, 1989). We therefore considered an               Acknowledgments This work was supported by the Pittsburgh
additional model that captures these expectations.                    Life Sciences Greenhouse Opportunity Fund, NSF Grant CDI-
                                                                      0835797, and NIMH Training Grant T32MH019983.
The augmented relationship model The third column of
Table 1 adds the three assumptions just described to the three                                  References
assumptions of the basic relationship model. We refer to the          Baker, C. L., Goodman, N. D., & Tenenbaum, J. B. (2008).
resulting model as the augmented relationship model.                     Theory-based social goal inference. In Proceedings of the
    The overall performance of the augmented relationship                30th Annual Conference of the Cognitive Science Society.
model (with a utility-matching choice function) is shown in           Bergen, L., Evans, O. R., & Tenenbaum, J. B. (2010). Learn-
Figure 2b.iii. The model predicts participants’ judgments                ing structured preferences. In Proceedings of the 32nd An-
(r = 0.96) significantly better than the utility-matching ba-            nual Conference of the Cognitive Science Society.
sic relationship model (z = 1.98, p < .05). Although not              Griesinger, D. W., & Livingston, Jr., J. W. (1973). Toward a
shown, the model also captures the qualitative effects in the            model of interpersonal motivation in experimental games.
highlighted conditions in Figure 2a that the basic relationship          Behavioral Science, 18(3), 173–188.
model was unable to capture.                                          Haslam, N. (1994). Mental representation of social relation-
    To obtain an upper bound on model performance, we also               ships: Dimensions, laws, or categories? Journal of Person-
considered a model in which all of the social attitude param-            ality and Social Psychology, 67(4), 575–584.
eters were fit to the data. For each relationship, we fit the pa-     Jern, A., & Kemp, C. (2011). Decision factors that support
rameters wA , wB , and γB . We generated model predictions for           preference learning. In Proceedings of the 33rd Annual
every combination of parameters, with direct utility weights             Conference of the Cognitive Science Society.
varying in increments of 0.1, and fit the predictions to the          Jern, A., Lucas, C. G., & Kemp, C. (2011). Evaluating the
complete set of mean participant ratings. We chose the val-              inverse decision-making approach to preference learning.
ues of the parameters that produced the largest correlation              In Advances in Neural Information Processing Systems 24.
coefficient between model predictions and mean participant            Liebrand, W. B. G. (1984). The effect of social motives,
ratings. The overall performance of the fitted relationship              communication and group size on behavior in an N-person
model is shown in Figure 2b.iv. As the figure shows, the                 multi-stage mixed-motive game. European Journal of So-
fitted model offers virtually no performance gains over the              cial Psychology, 14(3), 239–264.
augmented relationship model, suggesting that the relation-           Loewenstein, G. F., Thompson, L., & Bazerman, M. H.
ship assumptions made by the augmented relationship model                (1989). Social utility and decision making in interpersonal
are sufficient to capture people’s inferences in our task.               contexts. Journal of Personality and Social Psychology,
                                                                         57(3), 426–441.
                         Conclusion                                   Lucas, C. G., Griffiths, T. L., Xu, F., Fawcett, C., Gopnik,
Our data support the idea that different social relationships            A., Kushnir, T., et al. (2014). Child as econometrician:
correspond to different ways of weighting utility functions.             A rational model of preference understanding in children.
Three commonsense assumptions about the nature of these                  PLOS ONE, 9(3), e92160.
weights for different relationships allowed us to predict peo-        McClintock, C. G. (1972). Social motivation—a set of propo-
ples social inferences in a large number of cases fairly accu-           sitions. Behavioral Science, 17(5), 438–454.
rately. Our experimental results also revealed three additional       Murphy, R. O., & Ackermann, K. A. (2012). A review of mea-
assumptions that people seem to make about how friends,                  surement methods for social preferences. (Working paper)
strangers, and enemies will behave toward one another.                Train, K. (2009). Discrete choice models with simulation
    This paper focused on one of the simplest examples of folk           (2nd ed.). New York, NY: Cambridge University Press.
social psychology: reasoning about a choice that affects one          Ullman, T. D., Baker, C. L., Macindoe, O., Evans, O., Good-
person in addition to the chooser. Future research should ex-            man, N. D., & Tenenbaum, J. B. (2009). Help or hinder:
plore how people reason about more complex social situa-                 Bayesian models of social goal inference. In Advances in
tions. For example, situations in which two people simulta-              Neural Information Processing Systems 22.
neously make social choices that affect one another introduce         Wyer, R. S. (1969). Prediction of behavior in two-person
a recursive aspect to the social decision-making process that            games. Journal of Personality and Social Psychology,
is not captured by the present version of our model. Addi-               13(3), 222–238.
                                                                  694

