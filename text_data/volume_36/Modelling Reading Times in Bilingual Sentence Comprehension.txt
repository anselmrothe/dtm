UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modelling Reading Times in Bilingual Sentence Comprehension
Permalink
https://escholarship.org/uc/item/02b2t6hn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Frank, Stefan
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                 Modelling Reading Times in Bilingual Sentence Comprehension
                                                  Stefan L. Frank (s.frank@let.ru.nl)
                            Centre for Language Studies, Radboud University Nijmegen, The Netherlands
                               Abstract                                  example of such a bilingual RNN, trained on two artificial
                                                                         miniature languages that were modelled on French and En-
   Relatively little is known about the interaction between a bilin-
   gual’s two languages beyond the word level. This paper inves-         glish. Since the current objective is to accurately estimate sur-
   tigates the issue by comparing word reading times (RTs) in            prisal values for words from experimental stimuli or naturally
   both L1 and L2 to quantitative predictions by statistical lan-        occurring sentences, an RNN implementation is required that
   guage models. Recurrent neural networks are trained on either
   a Dutch corpus, an English corpus, or the two corpora com-            allows for training on large corpora of natural text. The highly
   bined (i.e., the bilingual network treats the two languages as        efficient implementation by Mikolov, Deoras, Povey, Burget,
   one). Next, estimates of word surprisal by the three models are       and Černocký (2011) is well suited to this purpose.
   compared to RTs by native Dutch speakers on L1 Dutch and L2
   English sentences. The monolingual Dutch model accounts for              Three RNNs were trained: one on a Dutch corpus, one
   RTs on Dutch better than the bilingual model. In contrast, the        on an English corpus, and one on the two corpora com-
   bilingual model outperforms the monolingual English model             bined. Hence, there are two monolingual networks (hence-
   on English RTs. These findings suggest that sentence compre-
   hension in L1 is not much affected by L2 knowledge, whereas           forth, RNNDutch and RNNEnglish ) and one bilingual network
   L2 reading does show interference from L1.                            (RNNbi ). Dutch training data came from a part of the Corpus
   Keywords: Bilingualism; sentence comprehension; recurrent             of Web (Schäfer & Bildhauer, 2012; 5.8M sentences, 107M
   neural networks; word surprisal; word reading time                    word tokens, 314K word types) and English data was taken
                                                                         from the British National Corpus (4.5M sentences, 87M word
                           Introduction                                  tokens, 182K word types). The three RNNs are architec-
Reading time (RT) effects on interlingual homographs and                 turally identical, except for their number of input and out-
cognates have revealed that L1 knowledge affects L2 reading              put nodes which must match the number of word types in the
(Duyck, Van Assche, Drieghe, & Hartsuiker, 2007) and, vice               training corpus. Hence, the only thing that makes a network
versa, L2 knowledge affects L1 reading (Van Assche, Duyck,               Dutch, English, or bilingual is the language(s) it is trained on.
Hartsuiker, & Diependaele, 2009). However, whether these                    The RNNs embody two extreme views on bilingual pro-
effects are modulated by sentence context (rather than be-               cessing: The monolingual models allow no effect of the other
ing merely lexical phenomena) is still controversial (Libben             language whatsoever, whereas the bilingual model treats the
& Titone, 2009; Van Assche, Drieghe, Duyck, Welvaert, &                  two languages as one. Most likely, bilingual sentence com-
Hartsuiker, 2011).                                                       prehension falls somewhere in between these two poles. Fit-
   RT on a word depends, among other things, on the word’s               ting surprisal to RT should reveal which of the two extreme
occurrence probability given the sentence so far. More pre-              positions is most like bilingual reading. To the extent that
cisely, a positive correlation has been found between RT and             bilinguals are affected by the language not currently being
the negative logarithm of word probability, a value know as              used, surprisal estimates by RNNbi should fit the RT data bet-
the word’s surprisal (Fernandez Monsalve et al., 2012; Smith             ter than surprisals from a monolingual RNN.
& Levy, 2013). Word surprisal can be estimated by statisti-
cal language models that are trained on large text corpora. So                            Results and conclusion
far, such work has only made use of models that process a                Surprisal values were obtained on each word of the 56 filler
single language (predominantly English) but if a bilingual’s             (i.e., non-target) sentences from a study by Frank, Trompe-
two languages influence each other during reading, bilingual             naars, and Vasishth (2014), who collected self-paced RTs
(as opposed to monolingual) language models may provide a                from 46 native Dutch speakers tested in either Dutch (N = 24)
more accurate account of bilingual reading behaviour.                    or English (N = 22). RNNDutch processed Dutch sentences,
                                                                         RNNEnglish processed English, and RNNbi processed both,
      Modelling bilingual sentence processing                            yielding four sets of surprisal estimates. A significant amount
When recurrent neural networks (RNNs) are applied as sta-                of variance in RTs was accounted for by each set of surprisals
tistical language models, their surprisal estimates regularly            (all p < .0001 in a linear mixed-effects regression analysis)
outperform those from other model types in predicting RTs                over and above word length and word log-frequency.
(Frank & Bod, 2011; Frank & Thompson, 2012) as well as                      The main question of interest is whether the monolingual
N400 size (Frank, Otten, Galli, & Vigliocco, 2013). More-                RNNs’ surprisals fit the data better or worse than surprisal
over, RNNs provide a straightforward account of how two                  from RNNbi . Hence, we compare the fit to RTs of two re-
languages may be combined into a single system, as the net-              gression models that differ only in the source of their sur-
work’s hidden layer can be activated by word input from ei-              prisal values: one includes surprisal estimates by a monolin-
ther language without receiving any (explicit) information               gual RNN (i.e., RNNDutch for Dutch; RNNEnglish for English)
about language identity. French (1998) presents an early                 and the other takes RNNbi ’s surprisals (on either Dutch or
                                                                     1860

                                                                    Fernandez Monsalve, I., Frank, S. L., & Vigliocco, G. (2012).
Table 1: Model comparison results for monolingual versus
                                                                      Lexical surprisal as a general predictor of reading time. In
bilingual RNN. Du. = Dutch; Eng. = English.
                                                                      Proceedings of the 13th Conference of the European Chap-
                  Participants                                        ter of the Association for Computational Linguistics (pp.
    Lang.      N    L1     L2            BF        P(Hmono )          398–408). Avignon, France: ACL.
    Du.       24    Du.    Eng.      23.2              .96          Frank, S. L., & Bod, R. (2011). Insensitivity of the human
    Eng.      22    Du.    Eng.       2.7×10−3         .00            sentence-processing system to hierarchical structure. Psy-
    Eng.      20    Eng. none         6.9 × 104       1.00            chological Science, 22, 829–834.
    Eng.      20    Eng. mixed       27.1              .96          Frank, S. L., Monsalve, I. F., Thompson, R. L., & Vigliocco,
                                                                      G. (2013). Reading time data for evaluating broad-
                                                                      coverage models of English sentence processing. Behavior
                                                                      Research Methods, 45, 1182–1190.
English sentences). This is a comparison between two non-           Frank, S. L., Otten, L. J., Galli, G., & Vigliocco, G. (2013).
nested regression models, for which we take the approach ad-          Word surprisal predicts N400 amplitude during reading. In
vocated by Wagenmakers (2007): The difference between the             Proceedings of the 51st Annual Meeting of the Association
two models’ Bayesian Information Criterion gives rise to an           for Computational Linguistics (pp. 878–883). Sofia, Bul-
estimate of Bayes Factor (BF) for the comparison between              garia: ACL.
the two hypotheses (i.e., Hmono versus Hbi : the monolin-           Frank, S. L., & Thompson, R. L. (2012). Early effects of word
gual/bilingual RNN fits the data best). Assuming equal prior          surprisal on pupil size during reading. In Proceedings of the
probabilities of Hmono and Hbi , BF is then used to obtain the        34th Annual Conference of the Cognitive Science Society
probability of Hmono (P(Hmono ), or, equivalently, 1 − P(Hbi )).      (pp. 1554–1559). Austin, TX: Cognitive Science Society.
   The first two rows of Table 1 show the estimated BF as well      Frank, S. L., Trompenaars, T., & Vasishth, S. (2014). Cross-
as P(Hmono ) for the comparison between RNNbi and either              linguistic differences in processing double-embedded rel-
RNNDutch (for RTs on Dutch sentences) or RNNEnglish (for              ative clauses: Working-memory constraints or language
English). The RTs on L1 Dutch are predicted more accurately           statistics? Manuscript submitted for publication.
by RNNDutch than by RNNbi , whereas data on L2 English              French, R. M. (1998). A simple recurrent network model
are predicted more accurately by RNNbi than by RNNEnglish .           of bilingual memory. In Proceedings of the 20th Annual
This suggests that the Dutch native participants are not much         Conference of the Cognitive Science Society (pp. 368–373).
affected by their L2 English when reading in Dutch, whereas           Mahwah, NJ: Erlbaum.
their L1 does affect their reading process in English.              Libben, M. R., & Titone, D. A. (2009). Bilingual lexical
   If the results for English really do reflect successful RNN        access in context: evidence from eye movements during
modelling of L1 intrusion in L2 reading, then RNNEnglish              reading. Journal of Experimental Psychology: Learning,
should outperform RNNbi when fitting RTs from participants            Memory, and Cognition, 35, 381–390.
who do not speak Dutch. The UCL corpus (Frank, Mon-                 Mikolov, T., Deoras, A., Povey, D., Burget, L., & Černocký,
salve, Thompson, & Vigliocco, 2013) provides eye-tracking             J. (2011). Strategies for training large scale neural network
data of native English speakers (with no knowledge of Dutch)          language models. In IEEE Workshop on Automatic Speech
reading 205 sentences that were randomly selected from un-            Recognition and Understanding (pp. 196–201).
published novels. The bottom two rows of Table 1 show               Schäfer, R., & Bildhauer, F. (2012). Building large corpora
the results for monolingual and bilingual participants sep-           from the web using a new efficient tool chain. In Proceed-
arately. As expected, both groups’ RTs were predicted                 ings of the 8th International Conference on Language Re-
more accurately by RNNEnglish than by RNNbi . Hence, the              sources and Evaluation (pp. 486–493). Istanbul: ELRA.
Dutch/English bilingual RNN’s success appears to depend on          Smith, N. J., & Levy, R. (2013). The effect of word pre-
the data coming from Dutch/English bilingual readers.                 dictability on reading time is logarithmic. Cognition, 128,
   This paper presented the first statistical language model          302–319.
that can process natural sentences from two different lan-          Van Assche, E., Drieghe, D., Duyck, W., Welvaert, M., &
guages. A comparison between its word surprisal esti-                 Hartsuiker, R. J. (2011). The influence of semantic con-
mates and human RT measures provides evidence that L1                 straints on bilingual word recognition during sentence read-
knowledge affects L2 comprehension beyond the word level,             ing. Journal of Memory and Language, 64, 88–107.
whereas the reverse may not be the case.                            Van Assche, E., Duyck, W., Hartsuiker, R. J., & Diependaele,
                                                                      K. (2009). Does bilingualism change native-language read-
                          References                                  ing? Cognate effects in a sentence context. Psychological
Duyck, W., Van Assche, E., Drieghe, D., & Hartsuiker, R. J.           Science, 20, 923–927.
  (2007). Visual word recognition by bilinguals in a sentence       Wagenmakers, E.-J. (2007). A practical solution to the perva-
  context: Evidence for nonselective access. Journal of Ex-           sive problems of p values. Psychonomic Bulletin & Review,
  perimental Psychology: Language, Memory, and Cogni-                 14, 779–804.
  tion, 33, 663-679.
                                                                1861

