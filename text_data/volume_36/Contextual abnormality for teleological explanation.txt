UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Contextual abnormality for teleological explanation
Permalink
https://escholarship.org/uc/item/0826x171
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Varga, Alexandra
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                            Contextual abnormality for teleological explanation
                                 Alexandra Varga (Alexandra.Varga@psychol.uni-giessen.de)
                               Experimental Psychology and Cognitive Science, Justus-Liebig Universität
                                                                Giessen, Germany
                               Abstract                                   on the features that recommend it for modelling teleologi-
   How can we make sense of observed instrumental actions that            cal reasoning for action explanation. Upon wrapping up, I
   are on a first glance bizarre, i.e., different from what “I myself     emphasize the potential of closed-world reasoning about ab-
   would have done”? In an attempt to answer this question, the           normalities to provide a conducive conceptual framework in
   paper sets forth a two-staged reasoning procedure for teleolog-
   ical action explanation: goal assignment, and backward plan-           cognitive science, and end with a related methodological up-
   ning. Closed-world assumptions about abnormalities frame               shot.
   reasoning to a manageable format under limited processing ca-
   pacities. Non-default instrumental actions may be explained
   with respect to a goal hypothesis by encountering an abnor-                    Teleological reasoning about actions
   mality in the action context. The proposed procedure can be
   modelled in logic programming, and thereby subserve empiri-            Goals are a peculiar kind of action effects that motivate agents
   cal research on the more generic topic of of defeasible reason-        to plan their actions. Because reasons for action are grounded
   ing.                                                                   in agents’ prior motivations, goals fulfill an explanatory role.
   Keywords: teleological reasoning; action explanation; closed-          Inasmuch as goals are motivational factors for action perfor-
   world assumption; abnormality.
                                                                          mance, they also focus the explanatory processing of other
                Introduction and road map                                 agents’ actions. If a goal g gives agent X reasons for doing
                                                                          a, then g explains X’s a-ing in context c. This means that an
I propose a reasoning procedure that fosters the explanation              observer agent Y may use the goal in order to make sense of
of intentional instrumental actions, i.e., actions meant by an            X’s action performance. The human propensity for teleolog-
agent to achieve a particular goal in the context of perfor-              ical explanation is empirically well-documented in the psy-
mance. My grounding assumption is that the two mirror-                    chological literature (Csibra & Gergely, 2007; Lombrozo &
ing phenomena of planning one’s own performance of instru-                Carey, 2006).
mental actions, and understanding those performed by other
                                                                             Teleological reasoning is intrinsically linked with the fea-
agents, are underpinned by inferential processes. Planning
                                                                          tures of the situation where it is applied. The goal status
and explaining actions are instances of high-level cognition.
                                                                          is hypothetical because goal inference is an inverse prob-
The assumption is supported by empirical evidence, e.g., in
                                                                          lem (Csibra & Gergely, 2007): contextual information does
the developmental literature (Gergely, Bekkering, & Király,
                                                                          not deductively recommend a single solution. The choice
2002; Király, Csibra, & Gergely, 2013), as well as in adult
                                                                          of means fit for goal achievement is also guided by contex-
studies (Brass, Schmitt, Spengler, & Gergely, 2007; Hickok,
                                                                          tual features. For example, depending on whether the road is
2009). My locus of concern is the use of teleological reason-
                                                                          frosty or not, I may choose to cycle or to walk to university
ing for interpreting goal-directed actions. The distinctiveness
                                                                          on a Monday morning. Relatedly, action explanation with re-
of the proposed mechanism resides in the fact that it is use-
                                                                          spect to the agent’s reason for action is context dependent too.
ful for real agents in real time to make sense of atypical in-
                                                                          I might interpret my colleague, a convinced cyclist, walking
strumental actions, i.e., of alternatives to the default ways of
                                                                          to university in a different manner on a warm day of spring
achieving goals.
                                                                          than on a freezing cold day.
   It has been shown recently (Varga, 2013) that the use of
teleological reasoning for imitative learning from observa-                  Agents’ teleological inferences are flexible. The context-
tions by human agents as young as 14-month-old, i.e., the                 relative hierarchy of means and ends makes teleological rea-
results of Gergely et al. (2002), can be modeled in the non-              soning an epitome of hypothetical defeasible reasoning; it
monotonic formal system of constraint logic programming                   is a form of ‘explanationist abduction’ (Gabbay & Woods,
(Lambalgen & Hamm, 2005). The account of teleological                     2005). Its conclusions are open to revision as new infor-
reasoning set forth in this paper lays the ground for computa-            mation becomes available. For this and other reasons (see
tional models of human explanatory practices.                             Pollock, 1995; Kowalski, 2011; McCarthy & Hayes, 1969),
   I start with introducing some distinctive features of goal-            goal-centered reasoning is remarkably complex from a com-
centered reasoning in the service of teleological explanation             putational point of view.
of actions, which reveal its considerable computational com-              Closed-world assumptions in teleological reasoning.
plexity. I go on to present the proposal for a realistic proce-           Taking into account cognitive economy presumptions (Chater
dure by which human agents with limited cognitive capaci-                 & Vitanyi, 2003; Gigerenzer, Todd, & ABC group, 1999),
ties may succeed, i.e., reasoning with closed-world assump-               according to which reasoners tend to invest a minimal cogni-
tions. In the next Section I describe the reasoning steps. I              tive effort for a maximally advantageous outcome, the com-
then briefly present constraint logic programming, focusing               putational complexity may be dealt with in real time by as-
                                                                      1664

sumptions that help to ‘frame’ (McCarthy & Hayes, 1969)                       action rules are features of a context, say c1 , which make ab-
the inferential scope. One such assumption is that unless pos-                normality conditions obtain, and thereby override the appli-
itive information is available, no abnormality occurs in the                  cation of the closed-world assumption to c1 . The action rule
context1 . This is the closed-world assumption for reasoning                  may be revised for c1 , and prescribe performance of an action
about abnormalities CWAab (Stenning & Lambalgen, 2008).                       a1 , a1 6= a, in order to g. For the corresponding case of action
It calls for the formation of the minimal, simplest possible                  explanation, positive evidence of an exception p1 in context
interpretation of the context to be explained.                                c1 would justify performance of a1 instead of a in order to g.
   Attached to the CWAab is a disclaimer based on the rea-
soners’ commonsense background knowledge, i.e., a set of                                           The reasoning steps
conditions specifying the kind of positive evidence that may                  Let us begin with a simple example of two agents, an actor
constitute abnormality. At the psychological level, the set of                and an observer, in an action context. It will serve to illustrate
abnormality conditions can be said to be ‘at the back of the                  the reasoning steps.
reasoner’s mind’. The set is the result of interaction between                   Imagine a Dutch university, where the bike is the default
working memory and long-term memory, under limitations                        means of transport to work. X works there as a researcher.
imposed by the capacity of the former. The whys and where-                    One day her colleague Y sees her walking towards the Uni-
fores of such relations are depicted in detail in J. R. Ander-                versity not long before the regular arrival time. How can Y
son’s (1983) prominent model of human thinking, ACT-R.                        make sense of X walking? The action is prima facie not un-
   The set of abnormality conditions is Σ = {p1 , . . . , pn },               derstood, and it calls for explanation.
where IF p1 THEN ab,. . . , IF pn THEN ab. The states of                         The reasoning involved in teleological explanation of ac-
the world represented by p1 , . . . , pn are explicit evidence of             tions is roughly two-staged: formation of a goal conjecture,
abnormality. p1 . . . pn are hierarchically ordered based on the              followed by testing its explanatory capacity in the current
likelihood of overriding the assumption. n is potentially in-                 context.
finite, because so is the cardinality of the set of logical pos-
                                                                              (1) Goal hypothesis formation. In the first step, the ob-
sibilities; in principle, there could be gremlins, fairies, the
                                                                              server Y conjectures a goal of the instrumental action a per-
laws of gravity may stop holding, etc. Some of these abnor-
                                                                              formed by X.
mal cases however are more realistic than gremlins. They
                                                                                 Given that goals are conceptualized as a kind of action ef-
are exceptional contextual features that may actually prevent
                                                                              fects, observations are first causally individuated. Organiz-
the smooth, habitual running of a process. The set of condi-
                                                                              ing observations along means – ends hierarchies supervenes
tions considered depends on various factors, such as the im-
                                                                              on setting up a causal model (Lambalgen & Hamm, 2005)
portance of a satisfactory explanation, the degree of certainty
                                                                              of the current context. Empirical research supports this pro-
that counts as satisfactory, or the amount of time available for
                                                                              posal; the causal individuation of events appears to be a quasi-
computations.
                                                                              automatic processing mode. From very early infancy events
   In contexts where there is evidence of any of p1 . . . pn , the
                                                                              are perceived as forming cause – effect sequences. This is
assumption is justifiably overridden. For instance, a broken
                                                                              evidenced by empirical findings, e.g., 6 – 7 month-old in-
right elbow could define an abnormal context for a right-
                                                                              fants dishabituate to causal sequences of motion events af-
handed person. It is crucial for the current purposes to note
                                                                              ter having been familiarized with situations in which spatio-
that her using the left hand to sign a petition would be ex-
                                                                              temporal contiguity (presumably the crucial cue for causal
plained by observation of p1 = ‘broken hand’ in a context
                                                                              relations) between events is disrupted (Saxe & Carey, 2006).
where the rule ‘IF p1 THEN ab’ is active. It goes with-
                                                                                 In our working example, X’s walking is perceived as the
out saying that abnormality conditions are checked by rea-
                                                                              cause of gradual minimization of the distance to university,
soners only if teleological inferences produce unsatisfactory
                                                                              which eventually results in arrival at the office3 – a = ‘walk-
outcomes under the assumption that nothing abnormal is the
                                                                              ing’.
case. Otherwise the CWAab would be self-defeating.
                                                                                 The causal model of the current situation, relevant bits of
   Under this view of teleological closed-world reasoning, hu-
                                                                              background knowledge, and other observable cues for goal
man agents’ instrumental actions can be represented in action
                                                                              attribution, such as:
rules that connect a goal to an ordered sequence of actions in
a particular context. They read as “In order to g in context c                 · the number of effects per cause (potential multifinality) and
do a2 , unless something abnormal is the case”. The CWAab is                     of causes per effect (potential equifinality),
captured by the ‘unless’ proviso. Under the assumption that
                                                                               · the availability and salience of action effects,
nothing abnormal is the case, a is a default action. The pro-
viso makes explicit that the rule may not be applicable in a                   · the agent’s (emotional) reaction to the effects,
different context where exceptions do occur. Exceptions to
                                                                              constitute the database for further computations. The com-
    1 ‘Positive information of abnormality’ may refer to current ob-          putational complexity of goal hypothesis formation depends
servation, or consequences derived from it by forward reasoning.
    2 For simplicity I will henceforth use the singular ‘action’ for ‘or-         3 This is an instance of perceiving continuous causation
dered sequence of actions’.                                                   (Lambalgen & Hamm, 2005).
                                                                          1665

on which of these elements are available, and on their consis-              something abnormal is the case”. The ‘unless’ proviso al-
tency (or lack of). Given the database, Y establishes a goal                lows that additional contextual information modify the action
hypothesis g that presumably calls for the observed agent’s                 b prescribed by backward reasoning for goal achievement. A
action a in context c. In the current example, Y’s knowledge                non-default action may be prescribed for the same g in an
that it is a working day, that the path on which he sees X                  abnormal context.
walking leads to university, and that X works for the univer-                  Planning with CWAab is a rather automatic reasoning pro-
sity, plausibly leads to assigning X’s action a the goal to come            cedure, e.g., it can be implemented in a spreading activation
to university.                                                              network (Stenning & Lambalgen, 2008). A passive, unsu-
   Clearly goal assignment is often much more complicated                   pervised process like spreading activation is essential granted
that this, e.g., in contexts of unsuccessful or unfulfilled ac-             the size of potentially relevant long-term memory. In the
tions, multifinality, equifinality (Baker, Tenenbaum, & Saxe,               case of habitual goals that pertain to the reasoner’s procedu-
2009; Csibra & Gergely, 2007; Luo & Baillargeon, 2005;                      ral knowledge (e.g., get to work, write a paper, make cof-
Paulus & Király, 2013), but a comprehensive mechanism for                  fee), offline planning details activation of an action response
goal inference is beyond the scope of this paper. This example              most strongly associated with the goal (e.g., mount on the
is sufficient to grasp the structure of the reasoning process.              bike, turn on the computer, turn on the stove). The use of the
                                                                            CWAab for planning is the crucial element that justifies call-
(2) Testing the explanatory potential of the goal hypoth-
                                                                            ing this process inferential. Low-level action – effect associ-
esis. Because goal assignment is hypothetical, the explana-
                                                                            ation processes do not allow the kind of flexibility, and thus
tory function of the goal requires confirmation. The uncer-
                                                                            contextual adjustment of actions to goals, that closed-world
tainty with respect to fulfilling the function is even higher in
                                                                            planning does.
the case of unusual or atypical actions. And it is precisely
such actions that usually trigger explanatory processes.                       The observer’s own action rule is compared with observa-
                                                                            tions; the output is either match or mismatch.
   I propose offline plan simulation as a method for hypoth-
esis testing. The procedure is offline because the result of                   The case of match, i.e., a = b, is rather trivial. The fact that
planning is not overt action, rather an action representation to            the observed agent did what the observer would have done
be compared with observations.                                              to attain the hypothesized goal confirms the hypothesis and
                                                                            its explanatory function. In fact, the word ‘explanation’ may
   Reasoning amounts to computing a sequence of actions for
                                                                            appear as a misnomer here, since the teleological structure of
the goal g, in an attempt to answer the question “what would I
                                                                            observations is self-evident. Nothing calls for what we nor-
have done in order to g?”. This gives voice to the widespread
                                                                            mally mean by explanation – a deliberative, consciously en-
human tendency to use own behavior as a standard for under-
                                                                            gaged process. However inferential and automatic processing
standing the actions of other agents, when the observer can
                                                                            need not be seen as contrasting modes; as mentioned above,
resonate either with the behavior itself, or with its conjec-
                                                                            closed-world reasoning instantiates both (Stenning & Lam-
tured goal. In this sense, it follows the guiding idea behind
                                                                            balgen, 2008).
simulationist approaches to action understanding (Gallese &
Goldman, 1998; Zentgraf, Munzert, Bischoff, & Newman-                          The more interesting and explanatorily substantial case is
Norlund, 2011). The crucial difference lies in the fact that the            when observations conflict with the output of offline plan-
proposed account is inference-driven.                                       ning, i.e., a 6= b. At this point, the assigned goal does not
   The inferential strategy for planning is backward closed-                fulfill the expected explanatory function. Computations pro-
world reasoning (Lambalgen & Hamm, 2005), from the goal                     ceed stepwise. The goal hypothesis is not canceled immedi-
g to actions4 . The input for reasoning is the goal, and the                ately. Cognitive economy, or the least effort principle, rec-
expected output is a temporally ordered sequence of actions                 ommends a computationally less expensive conflict resolu-
whose performance achieves the goal, unless something ab-                   tion procedure first, i.e., retry explanation in light of the same
normal is the case in the context.                                          goal.
   The output is represented in the format of action rules in-                 The working example instantiates this case. Let us spell
troduced above. The action in the rule is a default action                  out the two mismatching action rules.
(Mueller, 2006), i.e., what the observer would have done in
                                                                            Default: In order to come to university use the bike in con-
order to g in a context where nothing abnormal is the case.
                                                                               text c unless something abnormal is the case.
Defaults are typical actions5 . The action rule computed by
the observer in offline planning is “In order to g do b unless              Observation: In order to come to university walk in context
    4 The                                                                      c1 unless something abnormal is the case.
            backward direction of reasoning overlaps with the goal-to-
action inferences in teleological action interpretation, as described
by Csibra and Gergely (2007). In a discussion of deontic conditional           In Y’s simulation of X’s plan for the goal “come to uni-
reasoning, Beller (2008) applies it to inferences from the action side      versity”, the CWAab prescribes the default use of the bike in
to the condition side of deontic rules.
    5 It is worth noting that although there may of course be individu-     a normal context c. Further contextual analysis of the ob-
ally specific defaults (e.g., my own special way of typically making        served c1 may provide evidence for abnormality. This calls
coffee), most are shared across communities.                                for checking whether CWAab does indeed hold in c1 . Sup-
                                                                        1666

 pose that X’s default rule comes with the following hierarchy           In what follows I focus on the appropriateness of CLP seman-
 of abnormality conditions:                                              tics for modelling teleological reasoning. NAF is a weaker
                                                                         form of negation than the one in classical logic; the negation
1. IF wind is too strong THEN ab,                                        of a sentence is true whenever there is no evidence for the
2. IF there is snow or frost on the way THEN ab,                         truth of the (positive) sentence. In Section Closed-world as-
3. IF bike has flat tire THEN ab,                                        sumptions in teleological reasoning I introduced the CWAab
                                                                         by saying that it is applicable as a constraint on reasoning
4. . . .                                                                 in the absence of positive evidence of exceptional cases that
 They are scanned from the most likely in descending order.              constitute abnormalities. Therefore formalization in terms of
 Suppose that the whole story takes place in a warm sunny day.           NAF is appropriate.
 It is thus easy to reject (1) and (2) – the conditions’ truth value        Furthermore it is worth noting that the notion of model
 is 0. Then X encounters (3). He has no positive information             construction7 in formal semantics is tantamount to the psy-
 about the state of his colleague’s tires. However, he does not          chological notion of interpretation. Action explanation pro-
 know that it is false either. The truth state of condition (3) is       ceeds via the construction of models that fit observations and
 u (uncertain), but it may evolve towards either 0 or 16 . At this       relevant bits of background knowledge, taking seriously the
 point the CWAab may be justifiably overridden, and thereby              constraints of cognitive economy. Formal model construc-
 the unusual instrumental action may be explained by the as-             tion had thus better be uniformly and efficiently computable
 signed goal. Suppose that Y finally enters the office and starts        in real time. The weak notion of negation, NAF, fares well in
 complaining about the poor quality of bike tires nowadays.              this respect (Etzioni, Golden, & Weld, 1997). It allows com-
 This indicates that the antecedent of condition (3) holds (its          putations to be performed in minimal models. Such minimal
 truth value is 1), thus something abnormal is the case, thus c1         models are ‘closed worlds’. Minimal model semantics is a
 where the bizarre action takes place is an abnormal context             useful modelling device because of its approximation of prin-
 with respect to the assigned goal. X’s walking to university            ciples of least effort, as expressed in the CWAab . A minimal
 on a warm sunny day is then contextually explained by g in              model may be (minimally) extended to cover abnormalities
 light of the abnormality for which positive information about           in the face of positive evidence.
 the flat tire provides evidence. The minimal teleological in-              Lambalgen and Hamm (2005) have argued for the use of a
 terpretation is extended to include the abnormality.                    three-valued Kleene semantics for CLP as a modelling instru-
     If the scan of abnormality conditions provides no evidence          ment for cognitive phenomena. Kleene semantics has three
 of relevant exceptions to the default action rule for the goal          possible truth values: 1 for ‘true’, 0 for ‘false’, and u for ‘un-
 g, the goal conjecture is dropped. The teleological structure           certain’. What is special about the Kleene’s u is that it is not
 of the context of observation is recomputed from step (1). A            a degree of truth intermediary between 0 and 1. Rather u is
 different goal g1 is assigned to the observed action, and its           undecided and can evolve toward 0 or 1 as a computational
 explanatory function is verified along the lines of (2). The            upshot. This fits nicely with the potential indeterminacy of
 process is thus recursive.                                              truth value of the conditions for abnormality with respect to
                                                                         action rules (such as was the case in the working example).
           Potential for formal implementation                              At the level of syntactic operations, CLP has the capac-
 The logical notion that corresponds to psychological flexibil-          ity to capture the use of abnormality conditions in teleolog-
 ity is non-monotonicity (Mueller, 2006; Stenning & Lambal-              ical reasoning by representing them as integrity constraints
 gen, 2008). It means that validly derived conclusions may               (Kowalski & Sadri, 2009; Reiter, 1988). Integrity constraints
 become false when new premises are added to the database.               impose local norms on computations, in the form of obliga-
 A non-monotonic formal system is needed as a computational              tions or prohibitions. They are expressed in conditional form;
 format for the flexible, context adaptive reasoning that I pro-         they call upon, or prohibit, certain computational movements,
 posed to subserve action explanation. Throughout the paper I            ensuring that the database satisfies the conditions expressed in
 described these processes as a form of closed-world teleolog-           the consequent of the conditional. For the case of abnormality
 ical reasoning. The computational logic system of constraint            conditions, when evidence of exceptions becomes available,
 logic programming (CLP) provides a suitable framework to                the database must be updated with abnormalities. This affects
 capture goal-centered reasoning with closed-world assump-               further computations, to which the closed-world assumption
 tions. The technical background for the description of CLP              no longer applies.
 below is taken mainly from Lambalgen and Hamm (2005).                      The semantics of the conditional in integrity constraints is
     Negation as failure (NAF) is the basic formal manifestation         a matter of ongoing debate in the computer science and AI
 of closed-world reasoning; it can be encountered at the levels          literature (Godfrey, Grant, Gryz, & Minker, 1998; Kowal-
 of the CLP’s semantics, syntax, and consequence relation. An            ski, 2011). For the current purpose of modelling teleological
 exhaustive description of CLP exceeds the present purpose.              reasoning for explanation, I propose that the ‘IF exception
      6 This is Kleene’s three-valued semantics. More on this in the         7 The term ‘model’ is used here as ‘semantic model’, not to be
 next Section.                                                           confounded with its homonymous meaning of ‘formal theory’.
                                                                     1667

. . . THEN ab’ expression of abnormality conditions should          nitive limitations, and that the chosen formalism is well able
be monotonic. An abnormality that is validly inferred from          to capture the kind of processing required by these limita-
positive evidence of an exceptional condition cannot be after-      tions, the proposal is likely to subserve the construction of a
wards withdrawn; ‘exceptions to exceptions’ are not accepted        realistic process model for action explanation9 . Furthermore
by the formalism thus construed8 . This possibility would           such a model is likely to inform the intricacies of abductive
be too permissive with respect to the flexibility of reasoning      reasoning at a descriptive level (Gabbay & Woods, 2005).
about actions, to the point that it could be detrimental to the         Non-monotonic reasoning has a larger scope of applicabil-
desired efficiency of reasoning under real time constraints.        ity in human cognition than teleological reasoning for expla-
     Finally, the cognitive relevance of CLP has been shown         nation. The intrinsic role of modelling to provide theoretical
in a variety of domains. It has been used to construct a            generalizations does not need further arguments. Therefore a
formal cognitive semantics of tensed speech (Lambalgen &            computational model of closed-world reasoning about abnor-
Hamm, 2005) and thereby applied to discourse interpretation         malities may also prove useful for empirical investigations
(R. Baggio, Lambalgen, & Hagoort, 2008), or to formalize            of related cognitive phenomena in the psychology of reason-
conditional reasoning tasks which facilitated the derivation        ing, e.g., reasoning with counterexamples. In the subfield of
of predictions with respect to autistic subjects’ performance       legal reasoning, for example, research is currently underway
on those tasks (Pijnacker et al., 2009; Pijnacker, Geurts, Lam-     (Gazzo-Castañeda & Knauff, n.d.) regarding the conditions in
balgen, Buitelaar, & Hagoort, 2010). For instance Pijnacker         which exculpatory circumstances are accepted as counterex-
et al. (2009) have shown that different reasoning patterns be-      amples to legal rules. Conceptualizing counterexamples as
tween people with autism and normal controls are to be ex-          abnormalities with respect to typical cases where rules ap-
pected upon abstracting the logical form of the task using          ply, supplemented by a principled manner of establishing hi-
such logical formalization methods. The hypotheses gen-             erarchies of abnormality conditions, is likely to be beneficial
erated by CLP formal models have been confirmed in be-              by yielding finer-grained empirical predictions. The factors
havioral and neural studies. Furthermore CLP has been               presumed to influence the cardinality of the set of abnormal-
conducive to appealing implementations in neural networks           ities conditions (e.g., the importance of a satisfactory expla-
(Stenning & Lambalgen, 2008).                                       nation, or the amount of time available for computations), for
                                                                    instance, may be manipulated in the experimental design.
       Conclusions: wrapping up and further on                          Apart from its intrinsic interest, this proposal also has
I proposed that, upon establishing a causal model of actions in     methodological implications. It is commonly assumed that
an observed context, agents explain actions via goal-centered       logical modelling has been superseded by probabilistic tech-
inferences. First, a goal hypothesis is formed; in so doing,        niques; more specifically, Bayesian models give the most
the agent constructs a minimal teleological model of obser-         prominent accounts of action understanding (Baker, Tenen-
vations. The expectation is that the goal explains the ob-          baum, & Saxe, 2006; Baker et al., 2009). There are
served sequence of actions. Second, an attempt is made to           close structural connections between logic programming and
corroborate the explanatory role of the hypothesis. This is         Bayesian models. However the latter are high-level norma-
done by computing a plan that answers the question ‘what            tive accounts; their profile makes them unsuitable for process
would I have done in order to achieve this goal?’. The of-          models of mental processes that involve fast-changing con-
fline planning is constrained by closed-world assumptions.          ceptual vocabularies (G. Baggio, Stenning, & Lambalgen, in
When observations mismatch what the observer would have             press). The rejection of logics as modelling tools in psychol-
done, actions are not explained by the assigned goal. The           ogy and cognitive science, in favor of probability, is prema-
flexible use of closed-world assumptions can foster explana-        ture.
tory computations without having to re-compute the teleolog-
ical structure ‘from scratch’ (i.e., engage in recursion start-                           Acknowledgments
ing from goal attribution anew, and attempting to validate the      This work has been supported by the DFG grant KN 465/11-1
secondary goal conjecture). Although different from what            to Markus Knauff. I wish to thank Keith Stenning for insight-
the observer would have normally done, an observed action           ful discussions that helped writing this paper.
may be explained by the initial goal assigned to it if the con-
text of performance turns out to be abnormal. Consequently,                                     References
the observer engages in further contextual analysis, by going
through the abnormality conditions and checking for positive        Anderson, J. R. (1983). The architecture of cognition. Mah-
evidence that at least one of those obtains. The bottom line           wah, New Jersey: Lawrence Erlbaum Associates.
is that finding contextual abnormality supports efficient tele-     Baggio, G., Stenning, K., & Lambalgen, M. van. (in press).
ological explanation of non-default instrumental actions.              The Cognitive Interface. In M. Aloni & P. Dekker (Eds.),
     The proposed reasoning strategies can be formalized in             9A   further argument along these lines that is worth developing
CLP. Given that at all points I took into consideration cog-        is that the functioning of production systems such as ACT-R closely
                                                                    resembles the procedural mechanisms of logic programming, which
      8 This is a form of regress argument.                         are most congenial to its practical use (Kowalski & Sadri, 2009).
                                                                1668

  Cambridge Handbook of Formal Semantics. Cambridge:                 Kowalski, R., & Sadri, F. (2009). Integrating logic program-
  Cambridge University Press.                                          ming and production systems in abductive logic program-
Baggio, R., Lambalgen, M. van, & Hagoort, P. (2008). Com-              ming agents. In A. Polleres & T. Swift (Eds.), Web reason-
  puting and recomputing discourse models: An ERP study.               ing and rule systems (Vol. 5837, pp. 1–23). Springer Berlin
  Journal of Memory and Language, 59, 36–53.                           Heidelberg.
Baker, C. L., Tenenbaum, J., & Saxe, R. (2006). Bayesian             Lambalgen, M. van, & Hamm, F. (2005). The Proper Treat-
  models of human action understanding. In Advances in                 ment of Events. Malden: Blackwell Publishing.
  neural information processing systems (Vol. 18). MIT               Lombrozo, T., & Carey, S. (2006). Functional explanation
  Press.                                                               and the function of explanation. Cognition, 99(2), 167–
Baker, C. L., Tenenbaum, J., & Saxe, R. (2009). Action                 204.
  understanding as inverse planning. Cognition, 113(3), 329–         Luo, Y., & Baillargeon, R. (2005). Can a self-propelled box
  349.                                                                 have a goal?: Psychological reasoning in 5-month-old in-
Beller, S. (2008). Deontic norms, deontic reasoning, and               fants. Psychological Science, 16(8), 601–608.
  deontic conditionals. Thinking & Reasoning, 14(4), 305–            McCarthy, J., & Hayes, P. (1969). Some philosophi-
  341.                                                                 cal problems from the standpoint of artificial intelligence.
Brass, M., Schmitt, R., Spengler, S., & Gergely, G. (2007).            In B. Meltzer & D. Michie (Eds.), Machine Intelligence
  Investigating action understanding: Inferential processes            (Vol. 4, pp. 463–502). Edinburgh University Press.
  versus action simulation. Current Biology, 17(24), 2117–           Mueller, E. (2006). Commonsense Reasoning. San Francisco,
  2121.                                                                CA: Morgan Kaufmann Publishers.
Chater, N., & Vitanyi, P. (2003). Simplicity: a unifying prin-       Paulus, M., & Király, I. (2013). Early rationality in action
  ciple in cognitive science? Trends in Cognitive Sciences,            perception and production? a theoretical exposition. Jour-
  7(1), 19–22.                                                         nal of Experimental Child Psychology, 116(2), 407–414.
Csibra, G., & Gergely, G. (2007). ‘Obsessed with goals’:             Pijnacker, J., Geurts, B., Lambalgen, M. van, Buitelaar, J.,
  Functions and mechanisms of teleological interpretation of           & Hagoort, P. (2010). Reasoning with exceptions: An
  actions in humans. Acta Psychologica, 124(1), 60–78.                 event-related brain potentials study. Journal of Cognitive
Etzioni, O., Golden, K., & Weld, D. (1997). Sound and                  Neuroscience, 23(2), 471–480.
  efficient closed-world reasoning for planning. Artificial In-      Pijnacker, J., Geurts, B., Lambalgen, M. van, Kan, C., Buite-
  telligence, 89(1–2), 113–148.                                        laar, J., & Hagoort, P. (2009). Defeasible reasoning in high-
                                                                       functioning adults with autism: Evidence for impaired ex-
Gabbay, D. M., & Woods, J. (2005). A practical logic of
                                                                       ception handling. Neuropsychologia, 47(644–651).
  cognitive systems (Vol. 2). Oxford, UK: Elsevier Ltd.
                                                                     Pollock, J. (1995). Cognitive Carpentry: A Blueprint for
Gallese, V., & Goldman, A. (1998). Mirror neurons and
                                                                       How to Build a Person. MA, USA: MIT Press Cambridge.
  the simulation theory of mind-reading. Trends in Cognitive
                                                                     Reiter, R. (1988). On integrity constraints. In Proceedings
  Sciences, 2(12), 493–501.
                                                                       of the 2nd conference on Theoretical Aspects of Reasoning
Gazzo-Castañeda, E. L., & Knauff, M. (n.d.). Defeasibil-
                                                                       about Knowledge, TARK’88 (pp. 97–111). San Francisco,
  ity and the role of counterexamples in reasoning with legal
                                                                       CA, USA: Morgan Kaufmann Publishers.
  conditionals. Submitted for publication.
                                                                     Saxe, R., & Carey, S. (2006). The perception of causality in
Gergely, G., Bekkering, H., & Király, I. (2002). Rational             infancy. Acta Psychologica, 123(1-2), 144–165.
  imitation in preverbal infants. Nature, 415, 755.                  Schueler, G. (2003). Reasons and purposes: Human rational-
Gigerenzer, G., Todd, P. M., & ABC group the. (1999). Sim-             ity and the teleological explanation of action. New York,
  ple heuristics that make us smart. New York: Oxford Uni-             NY: Oxford University Press Inc.
  versity Press.                                                     Stenning, K., & Lambalgen, M. van. (2008). Human Rea-
Godfrey, P., Grant, J., Gryz, J., & Minker, J. (1998). Integrity       soning and Cognitive Science. Bradford Book, The MIT
  constraints: Semantics and applications. In J. Chomicki              Press, Cambridge, Massachussets.
  & G. Saake (Eds.), Logics for Databases and Information            Varga, A. (2013). A formal model of infants’ acquisition of
  Systems (Vol. 436, pp. 265–306). Springer US.                        practical knowledge from observation. Doctoral disserta-
Hickok, G. (2009). Eight problems for the mirror neuron the-           tion, Department of Philosophy, Central European Univer-
  ory of action understanding in monkeys and humans. Jour-             sity, Budapest.
  nal of Cognitive Neuroscience, 21(7), 1229–1243.                   Zentgraf, K., Munzert, J., Bischoff, M., & Newman-Norlund,
Király, I., Csibra, G., & Gergely, G. (2013). Beyond ratio-           R. (2011). Simulation during observation of human actions
  nal imitation: Learning arbitrary means actions from com-            – theories, empirical studies, applications. Vision Research,
  municative demonstrations. Journal of Experimental Child             51, 827–835.
  Psychology, 116(2), 471–486.
Kowalski, R. (2011). Computational logic and human think-
  ing: How to be artificially intelligent. New York: Cam-
  bridge University Press.
                                                                 1669

