UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Constructing Hierarchical Concepts via Analogical Generalization
Permalink
https://escholarship.org/uc/item/6hv175t4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Liang, Chen
Forbus, Ken
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                        Constructing Hierarchical Concepts via Analogical Generalization
                                      Chen Liang (chenliang2013@u.northwestern.edu)
                                        Kenneth D. Forbus (forbus@northwestern.edu)
                             Qualitative Reasoning Group, Northwestern University, 2133 Sheridan Road
                                                         Evanston, IL, 60208 USA
                              Abstract                                  hierarchical concepts. Next we describe three experiments,
                                                                        providing evidence that it can produce results that are
   Learning hierarchical concepts is a central problem in
   cognitive science. This paper explores the Nearest-Merge             compatible with human judgments, and with a prior
   algorithm for creating hierarchical clusters that can handle         Bayesian simulation on a data set for which no human data
   both feature-based and relational information, building on the       is available. We close with related and future work.
   SAGE model of analogical generalization. We describe its
   results on three data sets, showing that it provides reasonable                                Background
   fits with human data and comparable results to Bayesian
   models.                                                              We assume Gentner’s (1983) structure-mapping theory.
                                                                        Our model is built upon the Sequential Analogical
   Keywords: Analogy, concept           learning,   computational
                                                                        Generalization Engine (SAGE; McLure et al. 2010), which
   modeling, hierarchical clustering
                                                                        in turn uses the Structure-Mapping Engine (Falkenhainer et
                                                                        al 1989) for analogical comparison and MAC/FAC (Forbus
                          Introduction
                                                                        et al 1995) for analogical retrieval. Thus we start with
How concepts are formed and organized is a central                      SME, since it is the most fundamental. SME takes as input
question in cognitive science. It has been argued that people           two structured representations, a base and target, and
group examples into categories to maximize within-category              produces one or more mappings. Each mapping provides a
similarity and minimize between-category similarity                     set of correspondences (i.e. what goes with what), a
(Mervis & Rosch, 1981). One important feature of                        structural evaluation score which provides an overall
categories is that they are not isolated from each other.               estimate of match quality, and candidate inferences. We
Instead, people tend to organize the categories into a                  refer to the similarity score of a mapping as
hierarchy or taxonomy (Collins & Quillian, 1969; Murphy                 NSIM(base,target), which is normalized to [0,1] by dividing
& Lassaline, 1997).                                                     the raw score by the mean of the self-scores of the base and
   Most models of hierarchical category learning focus on               target 1 . Forward candidate inferences go from base to
feature-based representations (e.g. Medin & Schaffer, 1978;             target, reverse candidate inferences go from target to base.
Fischer 1987). Feature-based representations cannot capture             MAC/FAC takes as input a case library, which is a set of
relational thinking, involved in explanation, causal                    structured descriptions, and a probe, which is a structured
reasoning, and planning, which is central to human                      description. It returns one or more approximations to the
cognition (Gentner & Kurtz, 2005). Bayesian models                      most similar case in the case library, using a two-stage
(Kemp et al. 2006; Kemp & Tenenbaum 2008) can create a                  process that enables it to scale to large case libraries. The
variety of structures, including hierarchical structures,               first stage uses a flattened version of the relational structure
although to our knowledge they have not been tested on                  of cases, called content vectors, whose dimensions are
representations involving higher-order relations. Analogical            proportional to the weighted number of occurrences of each
generalization (Kuehne et al. 2000) can handle relational               predicate in a description. The dot product of two content
representations with higher-order relations as well as feature          vectors is an estimate of SME’s structural evaluation score
representations, but currently it does not create hierarchical          for the structured representations, making it a useful coarse
conceptual structures. This paper explores how analogical               filter. Both SME and MAC/FAC have been used to model a
generalization might be extended to model the formation of              variety of psychological phenomena.
hierarchical conceptual structure. The basic insight is that               SAGE maintains, for each concept, a generalization
the numerical similarity score computed via structure-                  context. A generalization context has a trigger, which is
mapping can serve the same roles as vector-based                        used to test whether or not an incoming example should be
operations used in feature-based models of similarity, and              added to it. (An incoming example might satisfy multiple
hence many of the same ideas and insights of those models               triggers, and hence be processed by several generalization
can be extended to handle relational (including higher-order            contexts.) Each generalization context maintains a set of
relational) representations.                                            generalizations and a set of unassimilated examples.
   We begin by summarizing relevant aspects of structure-
mapping and the models that we are building upon. Then                     1
                                                                             The mapped representations are subsets of both base and target,
we describe the Nearest-Merge algorithms for constructing               so its score is lower than either of their self-scores.
                                                                   2561

(Either of these sets might be empty, and both are initially.)     two clusters depends on their cohesiveness scores relative to
Generalizations are also structured representations, but           the similarity score between the two.
associated with their statements are probabilities, based on          Consider two concepts C1 and C2 with cohesiveness
the number of times facts that align with them are found in        scores c1 and c2, with NSIM(C1,C2) = s. If s is smaller than
examples that are part of that generalization.                     c1 and c2, e.g., when we are trying to merge the concepts
   Every time a new example is added, SAGE uses                    “blue whale” and “humpback whale”, we would construct a
MAC/FAC to retrieve up to three examples or                        superordinate “whale” above them; if s is only larger than
generalizations, based on whatever is the most similar to the      one of them, e.g., when we are merging “feline animal” and
new example. If nothing is retrieved, or the similarity to the     “cat”, the more cohesive category “cat” would break into
returned item is less than an assimilation threshold, the new      the other one and becomes a subordinate of it. The situation
example is stored as is. Otherwise, if the returned item is a      where s is larger than or equal to c1 and c2 is rare in
generalization, the new example is assimilated into it. If the     simultaneous clustering, because usually the more similar
returned item is a previously unassimilated example, then          pairs would be merged first. But this might be helpful if we
the two are combined into a new generalization.                    have identical examples, for example e1, e2, e3 and e4, they
   The assimilation process increments frequency counts            would be merged into one concept (e1, e2, e3, e4)
associated with each statement, based on whether or not            containing all four of them instead of creating a two layer
something in the example aligned with it. For a new                hierarchy of them like ((e1, e2) (e3, e4)). The algorithm is
generalization, such facts are always either 1.0 (in both) or      shown in Table 1.
0.5. If, for example, 1 black cat and two grey cats had been           procedure nearestMerge (E, a set of one or more examples)
seen, then P[(primaryObjectColor <GenEnt> Black)] = 1/3.                    if numberOf(E) = 1 then:
Facts whose probabilities drop too low are pruned, for                         return E //a set containing only the root of the
efficiency. Importantly, these generalizations do not have           hierarchy, representing the most general concept
logical variables: When non-identical entities are aligned, as              set maxScore = 0, maxPair = nil
in the cats example, a new arbitrary individual (called                     for each example e ∈ E:
<GenEnt> above) is constructed to stand for the aligned                           mapping m = macfacBest(e, E - e)
individuals, with its characteristics being determined by the                     if NSIM(m) ≥ maxScore then:
set of statements in the generalization that constrain it.                           set maxScore = NSIM(m)
                                                                                     set maxPair = (m.base,m.target)
                                                                             set newConcept =
         Extension to Hierarchical Concepts                                         conceptMerge(maxPair.base,
Our goal is to explore how to extend SAGE to automatically                                        maxPair.target)
construct psychologically plausible hierarchical concepts.                   addSubordinate(maxPair.base, newConcept)
The basic approach is agglomerative hierarchical clustering                  addSubordinate(maxPair.target, newConcept)
(Manning et al. 2008) in which the hierarchy is built                        return
                                                                                 nearestMerge(E – maxPair + newConcept)
bottom-up, by merging pairs of existing clusters. The most
commonly used hierarchical clustering algorithm is average-            procedure conceptMerge (concept1, concept2)
linkage clustering, which constructs a dendrogram by                       set c1 = cohesivenessOf(concept1)
merging two most similar members each time, using the                           c2 = cohesivenessOf(concep2)
mean distance between elements of each cluster as the                           ch1= subordinatesOf(concept1)
distance between them. This method is similar to exemplar                       ch2= subordinatesOf(concept2)
models, in that similarity is measured by the mean of its                      score = NSIM( concept1,concept2)
members, although computational exemplar models (Medin                     if score < c1, c2 then:
& Schaffer, 1978; Nosofsky, 1992) use more elaborate                           newConcept =
combination mechanisms than arithmetic average.                                    createConcept(concept1 ∪ concept2)
   Our approach, starting with SAGE, is more prototype-                    elseif score ≥ c1, c2 then:
based. Each SAGE generalization can be thought of as a                         newConcept = createConcept(ch1 ∪ ch2)
                                                                           elseif c1 > score > c2 then:
prototype for the concept represented by that generalization
                                                                               newConcept = createConcept(concept1 ∪ ch2)
context.
                                                                           elseif c2 > score > c1 then:
                                                                               newConcept = createConcept(ch1 ∪ concept2)
Nearest-Merge Algorithm                                                   return newConcept
   Nearest-Merge algorithm uses the same process as
average-linkage, but the similarity of two clusters is                 Table 1: Nearest-Merge algorithm
computed with the generalizations representing each cluster.
Each cluster has a cohesiveness score which measures the
dispersion of exemplars to the generalization. Dispersion
denotes how stretched or squeezed a distribution is,
calculated here as the average similarity of each exemplar of
a generalization to the generalization. The result of merging
                                                               2562

   It is useful to be able to flatten a hierarchy into natural           work as constraints on the cohesiveness score of natural
clusters, to compare against human clustering results. Note              categories (no bounds are used in Experiment 2 below).
that the cohesiveness score, which estimates the within-
category similarity, increases monotonically as we descend
to lower level, since lower level concepts are more cohesive.                                     Experiments
For a given category, let c be its own cohesiveness score,               We test this clustering algorithm on three datasets. We use
̅ be the average cohesiveness score of its subordinates,             average-linkage, with the distance vector computed from
and let c be the cohesiveness score of its superordinate.           structural similarity and content vector dot products (cosine
We cut the hierarchy at the first category along each branch             similarity), as baselines for comparison.
that satisfies̅  c  c  c . Intuitively, these natural
categories are where the increase of cohesiveness score                  Experiment 1: Animal data set
slows down, which has also been proposed as a criterion for
finding the basic level categories (Mervis & Crisafi, 1982) 2.           We use the data set of 50 mammals collected by Osherson et
This algorithm is shown in Table 2. Human categorization is              al. (1991). Each animal is rated along 85 features, such as
influenced by knowledge and expertise (Murphy, 2004).                    having hooves, a long neck, being a quadruped, and so on.
Experts usually prefer more specific categories, which have              These features are converted to binary values using the
higher cohesiveness scores. In contrast, novices usually                 global mean as the criterion (Kemp et al, 2006). We asked 5
prefer less specific categories with lower cohesiveness                  raters to distribute them into natural categories. Although
scores. In order to have the flexibility to model both novices           the conditions are different, our result corresponds well with
and experts, we added an upper-bound (0.6 when modelling                 Osherson’s. The average number of clusters raters created
                                                                         was 11.4 (SD=3.5), with a minimum of 6 and a maximum of
    procedure flattenHierarchy(H, a hierarchy)                           17, while the average number of clusters in Osherson’s data
        return flatten(getRoot(H))                                       on 30 subjects is 11.5 (SD=3.49) with a minimum of 5 and a
                                                                         maximum of 20.
    procedure flatten(ct, a concept)
         if leaves?(ct) = true
            or cohesivenessOf(ct) ≥ upperBound
         then:
            return ct
         else
            set ̅ =
                   averageCohesiveness(getSubordinate(ct))
                  c =
                    cohesivenessOf(getSuperordinate(ct))
                  c = cohesivenessOf(ct)
             if (̅  c  c  c )
                 and cohesivenessOf(ct) ≥ lowerBound
              then:
                  return ct
              else
                 flatCategories = nil
                 for each s ∈ getSubordinate(ct)                                Figure 1: An example of a hierarchy constructed for ten
                     set flatCategories =                                    animals, with the cohesiveness scores for the generalizations.
                           flatCategories ∪ flatten(s)                           The corresponding flat categories are colored in gray.
                return flatCategories                                       We used our algorithms to compute clusters for this data
                                                                         set, and then calculated the average ARI (adjusted Rand
                    Table 2: Flattening algorithm                        index) between each algorithm’s result and the human-
                                                                         generated clusters. ARI is a commonly used measure of the
novices as in Experiment 1 below) and a lower-bound (0.8                 similarity between two data clusters. It ranges from [-1.0,
when modelling experts as in Experiments 3 below), which                 1.0], with 1.0 for perfect match, close to 0.0 for random
                                                                         clustering and negative values for bad clusters. We use ARI
                                                                         as a proxy for estimating the psychological plausibility of
   2 The                                                                 clusters. We also compare them to the average inter-rater
          natural categories we found share some similarity with
basic level categories, like being preferred in clustering tasks, but
                                                                         ARI, to provide a benchmark. Table 3 describes the results.
the comparison is not clear because in experiment 1, the input
examples are categories instead of individual examples, while in
experiment 2 and 3, the basic level categories are not easy to
define.
                                                                     2563

                  Inter-rater          Nearest-
                                                                    open-domain sketch understanding system. The sketches
                                                                    were created by students taking an undergraduate
                                       Merge
                                                                    geoscience course at Northwestern University. There are 28
  Average ARI     0.3939               0.4014
                                                                    sketches, drawn from three different exercises. The ground
                                                                    truth clusters were provided by one of the authors of these
                  Average-             Average-                     geoscience exercises (Figure 2 illustrates).
                  Linkage(SME)         Linkage(CV)                     Students are asked to identify and label the fault, hanging
                                                                    wall, foot wall, marker beds, and movement along the fault
  Average ARI     0.4011               0.4011                       in the picture by sketching. For example, the sketch in the
                                                                    top left corner of Figure 2 is nearly correct by the exercise’s
                                                                    standards. The marker beds are marked by four black
             Table 3: Results of the animal dataset                 rectangles. The two big blue triangle denotes the foot wall
                                                                    (left) and hanging wall (right), and the black arrows show
  The Nearest-Merge algorithm generates 11 clusters, close          the moving direction of the marker beds.
to the mean of human results (11.4), and average ARI
                                                                       (isa Object-811 GeologicalMarkerBed)
(0.4014) which also corresponds well with inter-rater ARI              (transMotion Object-811 Down)
(0.3939). The average-linkage baseline algorithm requires
manual entry of the desired number of clusters, giving it an           (implies
advantage. The ARI differs little from content vector to                 (and (exceedsQuantInkLeftBound
                                                                                                     Object-809 Object-446)
SME-based average-linkage (0.4011) and Nearest-Merge,                          (exceedsQuantInkRightBound
which is to be expected given that the dataset are purely                                            Object-809 Object-446))
feature-based.                                                           (quantInk-tooWide Object-809 Object-446))
Experiment 2: Political data set                                       Table 5: Examples of higher-order relational statements
This experiment moves one step into relational structure,              The sketches are compared with the standard solution
using a dataset containing first-order relations. The political     provided by the instructor, and turned into relational
dataset, including 14 countries during the cold war, was            statements automatically by CogSketch. Table 5 shows
used by Kemp et al (2006). It included various properties           some of the statements generated from the bottom left
for countries as well as relationships between countries (e.g.      sketch in Figure 2. The statements on the top says that
that China provides Egypt with economic aid).                       Object-811 is a marker bed and it is moving down. The
                                                                    bottom one says that Object-809, the fault identified by the
        Bayesian model                   Nearest-merge              student, exceeds the left and right bound of Object-446, the
 (Brazil Netherlands)            (Brazil Netherlands)               corresponding fault in instructor’s solution, which implies
 (UK USA)                        (UK USA)                           that Object-809 is too wide compared with Object-446.
 (Burma Indonesia Jordan)        (Burma Indonesia) (Jordan)
 (India Israel Egypt)            (India Israel) (Egypt)
 (Cuba Poland USSR China)        (Cuba Poland USSR) (China)
   Table 4: Comparison of clusters generated by Bayesian
             model and Nearest-Merge algorithm
Since no human categorization results are available, we
compare our result with the result from Bayesian model
(Kemp et al, 2006). The clusters found by the Nearest-
Merge algorithm are similar to those found by the Bayesian
approach (ARI = 0.6286). Table 4 shows the
corresponding clusters. Nearest-Merge tends to treat
exceptions like China and Egypt as separate clusters,
resulting in finer-grained clusters. The more inclusive
clustering by Kemp et al. (2006) might result from their
algorithm using a Chinese Restaurant Process, which prefers            Figure 2: Four sketches from the student sketch dataset. The
smaller numbers of clusters.                                            top two are in the same cluster, while the bottom two each
                                                                                         are in their own clusters.
Experiment 3: Student hand-drawn sketches
Finally, we move to more fully structured data, containing
higher-order relations (Table 5). This dataset consists of
fault identification worksheets collected by (Chang &
Forbus, 2013) with CogSketch (Forbus et al. 2011), an
                                                                2564

                                                                    used as a source of priors for such algorithms. A third
                 Average-Linkage        AL        Nearest-
                                                                    approach is statistical relational learning (Getoor & Taskar,
                                                                    2007), for example inductive logic programming
                 (CV)                 (SME)        Merge
                                                                    (Muggleton, 1992) and Markov logic networks (Richardson
   Mean ARI,          0.0769          0.4000      0.6842
                                                                    & Domingos, 2006), which constructs rules via doing
    Exercise 1
                                                                    statistical reasoning over first-order representations. SAGE
                                                                    generalizations can be used to draw new conclusions via
                 AL (CV)                AL       Nearest-           analogical inference, and the probability information it
                                      (SME)       Merge             constructs can be used in statistical reasoning to determine
   Mean ARI,          0.4954          0.3836      0.5946            when generating rules would be productive (Friedman et al
    Exercise 2                                                      2009), although that capability is not used here.
                 AL (CV)                AL        Nearest-                         Conclusions & Future work
                                      (SME)        Merge            This paper explores how analogical generalization can be
   Mean ARI,          0.7037          0.3939      0.7500            extended to model hierarchical concept formation. We
    Exercise 3                                                      show that the Nearest-Merge algorithm can provide
                                                                    psychologically plausible results. Specifically, as the
                  Table 6: Sketch dataset results                   animal data set results indicate, it can produce human-like
As Table 6 indicates, the Nearest-Merge algorithm provides          clusters and hierarchies with the attribute-only
the best correspondence with the expert clusters on all three       representations assumed by research based on feature
exercises. Notice that there is great variability in how well       vectors. As the political data set results indicate, it can
the SME-only and content-vector scores perform. The                 create conceptual structures that are compatible with a prior
difference may depend on whether or not the important               Bayesian simulation, using the same data. As the student
properties are as simple as the existence of an entity of a         sketches data set results indicate, it can produce clusters
particular type, versus whether or not an important                 similar to those generated by an expert, using higher-order
relationship is violated. A content-vector match suffices for       relational information. Thus we think this is a promising
detecting whether or not a marker bed is present in a               approach for modeling how people construct hierarchical
description (leaving out that geological structure turns out to     conceptual structures.
be a common student mistake in the exercises). But                     There are several kinds of future work ahead. First, rarely
detecting that the spatial relationships between two marker         in real life do people have all of the concepts to be
beds is incorrect requires a structural match.                      organized all at once. Human learning is incremental, and
                                                                    we are experimenting with an incremental version of
                                                                    Nearest-Merge.       Robust incremental learning requires
General Discussion                                                  overcoming well-known issues with order bias (Eilo &
To summarize, the Nearest-Merge algorithm results                   Anderson 1984; Wattenmaker 1993; Kuehne et al 2000).
correspond best with human raters, and it produces results          Second, we are exploring better ways to quantitatively
comparable with a prior Bayesian model on the dataset for           measure the similarities and differences in the hierarchies
which human data is not available. The performance of               created by people and our models. Classic statistical
average-linkage with content vector and SME score varies            methods for comparing two hierarchical results (Fowlkes &
on different datasets depending on how much structure               Mallows, 1983) need the value of average similarity
information exists and how important this structure is.             between members for each cluster, which are hard to elicit
                                                                    from human raters, and edit distance metrics are difficult to
                                                                    calculate and score properly for unordered trees. Third, we
                       Related Work                                 plan on exploring how these internal, similarity-based
AI research on conceptual clustering has explored three             criteria interact with linguistic labels, especially when the
approaches. The first, and most widely used, approach is to         linguistic labels occur at multiple levels of abstraction and
define a distance metric and then search for clusters by            cut hierarchical boundaries (dogs and cats are mammals,
optimizing a function of intra-cluster distance and inter-          and goldfish and sharks are fish, but dogs, cats and goldfish
cluster distance (Manning et al. 2008). This approach has           are all pets).
been limited mainly to feature vectors, using vector-based
distance metric. Our technique can be seen as building on
this insight, but by using SME as our model of similarity,
we can handle relations and higher-order relations as well as
attributes. A second approach is to use Bayesian techniques
to produce clusters that maximize predictability and/or
utility (Fisher, 1987; Kemp et al 2008). The probability
information automatically constructed by SAGE could be
                                                                2565

                     Acknowledgments                              McLure, M., Friedman, S., & Forbus, K. (2010). Learning
                                                                    concepts from sketches via analogical generalization and
This research was sponsored by the Socio-Cognitive                  near-misses. Proceedings of the 32nd Annual Conference
Architectures for Adaptable Autonomous Systems Program              of the Cognitive Science Society (CogSci), Portland, OR.
of the Office of Naval Research, N00014-13-1-0470.                Medin, D. L. (1983). Structural principles of categorization.
                                                                    In T. Tighe & B. Shepp (Eds.), Development:
                         References                                 Interactional analyses. Hillsdale , NJ : Erlbaum.
                                                                  Medin, D. L., Goldstone, R. L., & Gentner, D. (1993).
Chang, M. D., & Forbus, K. D. (2013). Clustering Hand-              Respects for similarity. Psychological review, 100(2),
  Drawn Sketches via Analogical Generalization. Twenty-             254.
  Fifth IAAI Conference.                                          Medin, D. L., & Schaffer, M. M. (1978). Context theory of
Collins, A. M., & Quillian, M. R. (1969). Retrieval time            classification learning. Psychological review, 85(3), 207.
  from semantic memory. Journal of verbal learning and            Mervis, C. B., & Crisafi, M. A. (1982). Order of acquisition
  verbal behavior, 8(2), 240-247.                                   of subordinate-, basic-, and superordinate-level
Elio, R., & Anderson, J. R. (1981). The effects of category         categories. Child Development, 258-266.
  generalizations and instance similarity on schema               Mervis, C. B., & Rosch, E. (1981). Categorization of natural
  abstraction. Journal of Experimental Psychology: Human            objects. Annual review of psychology, 32(1), 89-115.
  Learning and Memory, 7(6), 397.                                 Muggleton, S. (1992). Inductive logic programming (Vol.
Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The          38): Morgan Kaufmann.
  structure-mapping engine: Algorithm and examples.               Murphy, G. L. (2004). The big book of concepts: MIT press.
  Artificial intelligence, 41(1), 1-63.                           Murphy, G. L., & Lassaline, M. E. (1997). Hierarchical
Fisher, D. H. (1987). Knowledge acquisition via incremental         structure in concepts and the basic level of categorization.
  conceptual clustering. Machine learning, 2(2), 139-172.         Nosofsky, R. M. (1992). Similarity scaling and cognitive
Forbus, K. D., Gentner, D., & Law, K. (1995). MAC/FAC:              process models. Annual review of psychology, 43(1), 25-
  A model of similarity-based retrieval. Cognitive Science,         53.
  19(2), 141-205.                                                 Osherson, D. N., Stern, J., Wilkie, O., Stob, M., & Smith, E.
Forbus, K. D., Usher, J., Lovett, A., Lockwood, K. and              E. (1991). Default probability. Cognitive Science, 15(2),
  Wetzel, J., 2011. CogSketch: Sketch understanding for             251-269.
  cognitive science research and for education. Topics in         Richardson, M., & Domingos, P. (2006). Markov logic
  Cognitive Science, 3, 648-666. 43.                                networks. Machine learning, 62(1-2), 107-136.
Fowlkes, E. B., & Mallows, C. L. (1983). A method for             Rips, L. J. (1989). Similarity, typicality, and categorization.
  comparing two hierarchical clusterings. Journal of the            Similarity and analogical reasoning, 21-59.
  American statistical association, 78(383), 553-569.             Tanaka, J. W., & Taylor, M. (1991). Object categories and
Friedman, S., Taylor, J., & Forbus, K. (2009). Learning             expertise: Is the basic level in the eye of the beholder?.
  naïve physics models by analogical generalization.                Cognitive psychology, 23(3), 457-482.
  Proceedings of the 2nd international analogy conference.        Wattenmaker, W. D. (1993). Incidental concept learning,
Gentner, D. (1983). Structure-mapping: A theoretical                feature frequency, and correlated properties. Journal of
  framework for analogy. Cognitive Science, 7(2), 155-170.          Experimental Psychology: Learning, Memory, and
Gentner, D., & Kurtz, K. J. (2005). Relational categories.          Cognition, 19(1), 203.
  Categorization inside and outside the lab, 151-175.
Getoor, L., & Taskar, B. (2007). Introduction to statistical
  relational learning: The MIT press.
Hampton, J. A. (1998). Similarity-based categorization and
  fuzziness of natural categories. Cognition, 65(2), 137-165.
Kemp, C., & Tenenbaum, J. B. (2008). The discovery of
  structural form. Proceedings of the National Academy of
  Sciences, 105(31), 10687-10692.
Kemp, C., Tenenbaum, J. B., Griffiths, T. L., Yamada, T., &
  Ueda, N. (2006). Learning systems of concepts with an
  infinite relational model. Proceedings of AAAI.
Kuehne, S., Forbus, K., Gentner, D., & Quinn, B. (2000).
  SEQL: Category learning as progressive abstraction
  using structure mapping. Proceedings of the 22nd Annual
  Meeting of the Cognitive Science Society.
Manning, C. D., Raghavan, P., & Schütze, H. (2008).
  Introduction to information retrieval (Vol. 1): Cambridge
  University Press Cambridge.
                                                              2566

