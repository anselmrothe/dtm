UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Symbolic Reasoning with Bounded Cognitive Resources
Permalink
https://escholarship.org/uc/item/0nc1267p
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Strannegard, Claes
Nizamani, Abdul Rahim
Engstrom, Fredrik
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        Symbolic Reasoning with Bounded Cognitive Resources
                                          Claes Strannegård (claes.strannegard@gu.se)
                      Department of Philosophy, Linguistics and Theory of Science, University of Gothenburg
                        Department of Applied Information Technology, Chalmers University of Technology
                                    Abdul Rahim Nizamani (abdulrahim.nizamani@gu.se)
                             Department of Applied Information Technology, University of Gothenburg
                                           Fredrik Engström (fredrik.engstrom@gu.se)
                      Department of Philosophy, Linguistics and Theory of Science, University of Gothenburg
                                                Olle Häggström (olleh@chalmers.se)
                             Department of Mathematical Sciences, Chalmers University of Technology
                              Abstract                                  between three types of symbolic reasoning: deduction, induc-
                                                                        tion, and abduction. These processes have been described as
   We present a multi-domain computational model for symbolic           methods to draw rational conclusions, generalize from expe-
   reasoning that was designed with the aim of matching human
   performance. The computational model is able to reason by            rience, and make plausible assumptions, respectively (Garcez
   deduction, induction, and abduction. It begins with an arbitrary     & Lamb, 2011).
   theory in a given domain and gradually extends this theory as
   new regularities are learned from positive and negative exam-           There is an extensive body of literature on symbolic rea-
   ples. At the core of the computational model is a cognitive          soning in logic, psychology, computer science, and linguis-
   model with bounded cognitive resources. The combinatorial            tics. In logic, reasoning is studied in the form of formal proofs
   explosion problem, which frequently arises in inductive learn-
   ing, is tackled by searching for solutions inside this cognitive     in proof theory (Troelstra & Schwichtenberg, 2000) and in
   model only. By way of example, we show that the compu-               psychology, reasoning is studied, e.g. in the mental logic and
   tational model can learn elements of two different domains,          mental model traditions (Adler & Rips, 2008).
   namely arithmetic and English grammar.
                                                                           One research field in computer science that studies rea-
   Keywords: symbolic reasoning; bounded resources
                                                                        soning is automatic theorem proving (Robinson & Voronkov,
                                                                        2001). Another field is machine learning, including Bayesian
                          Introduction                                  inference, which considers inferences in a setting where prob-
Artificial intelligence (AI) concerns computer models with              abilistic data are available (Tenenbaum et al., 2011). A
intelligence that ideally matches or exceeds that of humans.            third research field involving reasoning is inductive logic pro-
Strong AI, a.k.a. artificial general intelligence, targets general      gramming (Muggleton & Chen, 2012) and, more generally,
intelligence, whereas weak AI targets domain-specific intel-            inductive program synthesis, where the goal is to develop
ligence. Weak AI has attained enormous success over the                 programs from examples consisting of input-output pairs
last decades, whereas strong AI has yet to be achieved (Wang            (Kitzelmann, 2010). The two main approaches of inductive
& Goertzel, 2012; Kühnberger et al., 2013). The only known             program synthesis are the analytical approach, which uses ex-
cognitive system with general intelligence is the human brain;          amples as a basis for constructing programs, and the generate-
thus, researchers in strong AI are seeking inspiration from             and-test approach, which uses examples for testing purposes
neuroscience and cognitive psychology.                                  only. Analytical techniques include anti-unification and re-
   In this paper, we propose a strong AI model for the case             cursive relation learning. A representative system of the
of symbolic reasoning. The proposed model is able to reason             generate-and-test approach, M AGIC H ASKELLER searches
by induction, deduction, and abduction. The model includes              among Haskell programs that may include higher-order func-
a simplified cognitive model with explicit representations of           tions (Katayama, 2005). The systems FLIP (Ferri-Ramı́rez
several cognitive resources, including declarative and work-            et al., 2001) and ADATE (Olsson, 1998) blend the two ap-
ing memory. Our rationale for including a cognitive model               proaches in an inductive logic programming setting. The sys-
in our model for strong AI is to exploit the limitations of hu-         tem ADATE also uses evolutionary methods to generate pro-
man cognitive resources to decrease the computational com-              grams. A major obstacle to program synthesis on a larger
plexity. This paper constitutes a continuation and generaliza-          scale is the computational complexity of the state-of-the-art
tion of our earlier work on models of deduction and induction           methods (Kitzelmann, 2010).
with bounded resources (Strannegård, Engström, et al., 2013;             Reasoning is also studied in computational linguistics,
Strannegård, Nizamani, et al., 2013).                                  particularly in grammar induction (Clark & Lappin, 2010),
   In this paper, we consider symbolic reasoning, which in-             where classes of languages are learned from positive and neg-
volves discrete signals, in contrast to sub-symbolic reasoning,         ative examples. Computational complexity is a major issue in
which involves analogue signals. Peirce (1958) distinguished            this field as well.
                                                                    1539

   A particular line of research on reasoning can be traced            sively among those solution candidates that use no more cog-
back to Occam’s razor, the principle of preferring simple and          nitive resources than are available. This search strategy can
short explanations in science and everyday life. There are             be combined with any heuristic search algorithm. In this man-
several complexity measures that can be regarded as formal             ner, we may accelerate the search considerably, thus avoiding
versions of Occam’s razor. Some of these, e.g., Kolmogorov             the combinatorial explosion that is associated with many stan-
complexity and Solomonoff complexity, are not computable,              dard AI algorithms.
whereas others, e.g., Levin complexity, are computable (Li                Our computational model also includes a performance
& Vitányi, 2009). Some of the computable versions are ob-             measure for agents that was inspired by the notion of biolog-
tained by combining Kolmogorov complexity with traditional             ical fitness (the ability of an organism to survive and repro-
complexity classes pertaining to the time and space used by            duce). More precisely, we assume that a notion of reward and
Turing machines.                                                       punishment exists in the background, similar to the scheme
   The universal AI model AIXI is based on Solomonoff                  in reinforcement learning models. Thus, each example will
complexity and is therefore not computable in its original             have an associated utility, which may be positive (reward) or
form. However, this model also exists in restricted versions           negative (punishment). We now proceed to define our com-
that are computable and capable of practical problem solving,          putational model formally.
e.g., in game domains (Veness et al., 2011).
                                                                       Definition 1 A language is a set of strings that is generated
   Different aspects of reasoning have been modeled in cog-            by some finite context-free grammar.
nitive architectures, such as Soar (Laird et al., 1987), ACT-
R (Anderson & Lebiere, 1998), CHREST (Gobet & Lane,                       The elements of a language L are called L-terms. Two ex-
2010), and NARS (Wang, 2007). Cognitive architectures                  amples of languages, whose grammars are expressed in the
commonly model computations as rewrite sequences in ab-                Backus-Naur form, are given below.
stract rewrite systems (Bezem et al., 2003). Moreover, they
                                                                       Example 1 Below is a definition of the language Stream,
often include explicit models of cognitive resources, includ-
                                                                       consisting of arbitrary streams of words over a five-word vo-
ing working, sensory, declarative, and procedural memory.
                                                                       cabulary. We use S as the start symbol of grammars.
These cognitive resources are bounded in various ways, e.g.,
                                                                       Word = Alice | Bob | plays | crawls | OK
with respect to capacity, duration, and access time (Kosslyn
                                                                       S = Word | Word S
& Smith, 2006). In particular, working memory can typi-
                                                                          For example, Alice crawls and plays plays are
cally only hold a small number of items, or chunks, and is a
                                                                       Stream-terms.
well-known bottleneck of human problem solving (Toms et
al., 1993).                                                            Example 2 A definition of the language Arith, consisting of
   Cognitive resources are required for computing and learn-           simple arithmetical expressions, is shown below.
ing. According to Piaget, there are two ways of adapting to            Digit = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9
new information: assimilation, in which new pieces of in-              Num = Digit | Num Digit
formation are fitted into existing knowledge structures, and           Var = x | y | z
accommodation, in which the new information pieces cause               Unary = f
new knowledge structures to be formed or old structures to be          Binary = + | g
modified (Piaget, 1937).                                               Chunk = f(0) | f(x) | f(x+1) | g(x,0) |
                                                                               g(x,y) | g(x,y+1)
                  Computational model                                  S = Num | Var | Unary S | Binary S S | Chunk
                                                                          For example, 2+4 and f(x+1) are (pretty-printed) Arith-
Computational models that are used in cognitive psychology
                                                                       terms. Strictly speaking, the syntactic category Chunk is re-
should ideally perform on the human level with respect to
                                                                       dundant here. Our reason for including it nevertheless is to
any performance measure. Thus, the models should perform
                                                                       model memory chunks.
(i) at least on the human level and (ii) at most on the human
level. For AI, however, satisfying (i) is generally sufficient. In     Definition 2 An L-axiom is an expression of the form t  t 0 ,
fact, performing above the human level is only an advantage.           where t and t 0 are L-terms.
Thus, constructing a unilateral cognitive model that satisfies
                                                                       For example, x+y  y+x is an Arith-axiom and
(i) but not necessarily (ii) may be sufficient for the purpose of
                                                                       Alice crawls  OK is a Stream-axiom.
AI and also considerably easier than constructing a psycho-
logically plausible model that satisfies both (i) and (ii).            Definition 3 An L-theory is a finite set of L-axioms.
   Our computational model includes such a unilateral cogni-
                                                                       The purpose of theories is to serve as building blocks of com-
tive model, and our rationale is as follows. Suppose a human
                                                                       putations, as explained below.
(with bounded cognitive resources) can find a solution to a
certain problem. A solution to the problem should then ex-             Definition 4 Suppose that t and t 0 are L-terms such that t 0 is
ist inside a suitable cognitive model of this human (also with         a substring of t. Then, we say that t 0 is a subterm of t and
bounded resources). Thus, we can search for solutions exclu-           write t(t 0 ).
                                                                   1540

Languages may include the syntactic category Var, which                  Example 7 Below is a computation in a simple theory of
specifies the variables of L. For instance, Arith contains the           lists. This computation is expressed in a language similar
variables x, y, and z.                                                   to the Haskell programming language. Intuitively, the com-
Definition 5 An L-substitution is a partial function σ that              putation demonstrates that the result of applying the revers-
maps variables of L to terms of L.                                       ing function rev to the list [6,7] is the list [7,6]. Here,
                                                                         the axiom rev([])  [] states that the result of revers-
For instance, σ = {(x, 2), (y, 3)} is an Arith-substitution. By          ing an empty list [] is again []. The axiom rev(x:xs) 
extension, we will discuss substitutions that map terms to               rev(xs) ++ [x] states that a list that begins with an element
terms. In the same example, we obtain σ(x+y) = 2+3. We                   x and continues with a list xs can be reversed by first revers-
are now ready to define our only computation rule.                       ing xs and then moving x to the end.
Definition 6 Let L be a language, and let T be an L-theory                               rev([6,7])
containing the axiom t 0  t 00 . Additionally, suppose that t(t1 )                                   rev(x:xs)  rev(xs) ++ [x]
                                                                                    rev([7]) ++ [6]
and t(t2 ) are L-terms such that σ(t 0 ) = t1 and σ(t 00 ) = t2 for                                            rev(x:xs)  rev(xs) ++ [x]
                                                                           (rev([]) ++ [7]) ++ [6]
some L-substitution σ. Then, we write                                                                          rev([])  []
                                                                                ([] ++ [7]) ++ [6]
                           t(t1 ) 0                                                                      [] ++ xs  xs
                                   t  t 00                                              [7] ++ [6]
                           t(t2 )                                                                   [x] ++ xs  x:xs
                                                                                            [7,6]
and state that the conclusion (the term below the line) follows          Definition 8 Let t be an L-term. Then, the size of t is defined
from the premise (the term above the line) by T -rewriting.              as the minimum number of leaf nodes in an L-parse tree of t.
Example 3 Suppose that T is a theory in the language Arith,              The size of t might model the load of t on the working mem-
defined in Example 2, and x+y  y+x ∈ T . Then, the follow-              ory.
ing is an application of T -rewriting (with σ as above):
                                                                         Example 8 Let Arith be as defined in Example 2. Then,
                          2+3 x+y  y+x                                  the Arith terms f(x+1), f(x) + 2, and x + 23 have sizes
                          3+2                                            1, 3, and 4, respectively. Note the role played by the syntactic
Definition 7 Let L be a language, and let T be an L-theory. A            category Chunk in this case.
T -computation is a sequence of terms (t0 , . . . ,tn ) such that for
all i ≤ n, ti+1 follows from ti by an application of T -rewriting.       Definition 9 An agent is a tuple (L, T,W, S, D), where
   We will write computations in a vertical style, with the first         - L is a language,
term of the computation on top and the last term at the bottom.
                                                                          - T is an L-theory (declarative memory),
Example 4 Below is a computation in a simple theory of En-
glish grammar. Intuitively, the computation demonstrates that             - W is a natural number (working memory capacity),
the word stream Bob plays is grammatically correct.
                                                                          - S is a natural number (assimilation capacity), and
                  Bob plays
                                plays  crawls
                 Bob crawls                                               - D is a natural number (accommodation capacity).
                                 Bob  Alice
               Alice crawls
                                 Alice crawls  OK                       Definition 10 Let L be a language, and let A = (L, T,W, S, D)
                      OK
Example 5 Below is a computation in a simple theory of                   be an agent. An A-computation is a sequence of L-terms
arithmetic. Intuitively, the computation is a calculation of             (t0 , . . . ,tn ) with
the term (2+4)*(6+1). In fact, all of the axioms used here                - bounded transitions: (t0 , . . . ,tn ) is a T -computation
preserve equality.
                      (2+4)*(6+1)                                         - bounded width: no ti can have a size that exceeds W
                                       2+4  6
                         6*(6+1)                                          - bounded length: n ≤ S.
                                     6+1  7
                           6*7
                                  6*7  42                                  As will be further clarified in Definition 14, this definition
                            42
Example 6 Below is a computation in a simple theory of                   aims to capture those computations that are within reach of
propositional logic. Intuitively, the computation is a proof             an unassisted human with language L, declarative memory
of the tautology (x ⇒ y) ∨ x. In fact, all of the axioms used            T , working memory capacity W , assimilation capacity S, and
here preserve logical equivalence.                                       accommodation capacity D.
     (x => y) || x                                                       Example 9 Let L = Stream, as defined in Example 1 and let
                           (x => y)  (not x || y)                       T consist of all the L-axioms that are used in the computation
  (not x || y) || x
                           x || y  y || x                               of Example 4. Then, A = (L, T, 8, 10, 6) is an agent, and the
  (y || not x) || x
                           (x || y) || z  x || (y || z)                 aforementioned computation is an A-computation.
  y || (not x || x)
                           x || not x  True
        y || True                                                        Observation 1 Let A be an agent.                Then, the set of A-
                      x || True  True
            True                                                         computations is finite.
                                                                     1541

 Definition 11 Let L be a language. An L-item is a triple                                         Results
 (in, out, u) such that in and out are L-terms, and u is an in-       We have developed a program called O CCAM, which is based
 teger (utility). An L-induction problem (IP) is a finite set of      on the Occam function and uses an additional strategy for
 L-items.                                                             generating axioms by replacing terms by variables. The pro-
 This definition is slightly more general than the ordinary def-      gram first applies several filters to the set of candidate theories
 inition of induction problem with positive and negative ex-          and then it evaluates each remaining candidate theory on the
 amples, which is used in inductive logic programming. The            relevant induction problem using resource-bounded compu-
 present definition enables us to treat induction problems as         tations. The program comprises approximately 1,500 lines of
 more fine-grained optimization problems. It may be helpful           code in the functional programming language Haskell.
 to consider utility as rewards (for positive values) and punish-        In this section, we describe two learning processes in
 ments (for negative values). We obtain the ordinary definition       which O CCAM is used for learning regularities from a small
 of induction problem by assigning utilities of +1 and -1 to the      number of positive and negative examples. The agents con-
 positive and negative examples, respectively.                        sidered in this section have the capacity limits W = 8, S = 10,
                                                                      and D = 6. O CCAM finds all the solutions discussed in this
 Definition 12 The performance of an agent A on an L-
                                                                      section in a matter of minutes. The first learning process con-
 induction problem I is the number
                                                                      cerns English grammar and the challenge is to learn which
               Σ{u : (in, out, u) ∈ I and in →A out}.                 sequences of words correspond to grammatically correct sen-
                                                                      tences.
 Here, in →A out means that there is an A-computation from            Example 10 To model the first learning situation, let L =
 in to out. We use the convention that Σ0/ = 0 to ensure that         Stream, as defined in Example 1 and T = 0.        / Also, suppose
 the performance is always defined.                                   the IP consists of the items
 Observation 2 The performance measure is computable.                    (Alice crawls, OK, 1)                                        (1)
    When all parameters are clear from the context, we will              (Alice, OK, -1).                                             (2)
 discuss the performance of theories rather than of agents in
 some cases.                                                          Then, O CCAM returns the theory ∆ consisting of the axiom
 Definition 13 The size of an axiom is the sum of the sizes of           Alice crawls  OK.                                           (3)
 its left and right terms. The size of a theory is the sum of the
 sizes of its axioms.                                                 Item (1) is computable in T + ∆ as follows:
 Definition 14 The Occam function takes as arguments an                                      Alice crawls (3)
 agent A = (L, T,W, S, D) and an L-induction problem I. The                                          OK
 function’s value is an L-theory ∆ of maximum size D, such            However, item (2) is not computable in T + ∆. In fact, there
 that the agent (L, T + ∆,W, S, D) performs optimally on I in         is no axiom in T + ∆ with a left side that matches Alice. A
 the sense that no other agent (L, T + ∆0 ,W, S, D), where ∆0 is      more general way of demonstrating the non-computability of
 at most of size D, performs strictly better on I. Moreover, the      an item in a given theory is to generate all of the computations
 following tiebreakers apply to ∆ in the stated priority order:       of this theory and verify that none of them start and end with
                                                                      the relevant terms. Indeed, this is the manner in which O C -
1. ∆ has the minimum size.                                            CAM works. Therefore, the performance of the agent on IP
                                                                      is 1, which is optimal. Intuitively, the first English sentence
2. ∆ contains the maximum number of variable occurrences.             encountered by the agent was learned by heart.
3. ∆ contains the minimum number of variables.                        Example 11 Let us now assume that the agent continues the
                                                                      learning process with T consisting of the axiom (3) from the
4. ∆ is lexicographically minimal.                                    previous example. Let the IP be given by
 If there is no sufficiently small improvement ∆ over T , then           (Alice plays, OK, 1)                                         (4)
 the Occam function outputs 0.    / Condition 1 aims to capture
                                                                         (Alice, OK, -1).                                             (5)
 Occam’s razor. Condition 2 states a preference of generality
 in the sense that variables are preferred over constants. Con-       Then ∆ consists of the axiom
 dition 3 states that variables should be reused whenever pos-
 sible. Condition 4 ensures that the output is always uniquely           plays  crawls.                                              (6)
 defined.
                                                                      Item (4) is computable in T + ∆ as follows:
 Observation 3 The Occam function is computable.
                                                                                              Alice plays
                                                                                                                 (6)
 This follows since there are only finitely many theories and                                Alice crawls (3)
 associated agent computations to check.                                                             OK
                                                                  1542

Intuitively, the agent does not learn the second grammatical                                     2+3 (17)
sentence that it encounters by heart. Instead, it assumes that                                   3+2
replacing plays by crawls preserves grammatical correct-            However, item (16) is not computable in T +∆, as can be seen
ness.                                                               by inspecting the axioms of T + ∆.
Example 12 We then let T consist of the previously learned          Example 16 Now, the learning process can be continued in
axioms (3) and (6). Let the IP be given by                          a similar manner so that the agent also learns the table entry
   (Bob crawls, OK, 1)                                      (7)     2+2  4 and the associative law (x+y)+z  x+(y+z). Then,
   (Alice, OK, -1).                                         (8)     the agent is ready to learn ordinary multiplication from exam-
                                                                    ples. In fact, suppose that the IP is given by
Then, ∆ consists of the axiom
                                                                       (g(2,1), 2, 1)                                          (18)
   Bob  Alice.                                             (9)
                                                                       (g(2,2), 4, 1)                                          (19)
Item (7) is computable in T + ∆ as follows:                            (g(2,3), 2, -1).                                        (20)
                         Bob crawls (9)
                       Alice crawls (3)                             Then, ∆ consists of the following axioms:
                             OK
Intuitively, the agent draws the conclusion that replacing Bob         g(x,0)  0                                              (21)
by Alice preserves grammatical correctness.
                                                                       g(x,y+1)  g(x,y) + x.                                  (22)
Example 13 We now let T consist of the previously learned
axioms (3), (6), and (9). The IP is then given by                   Thus, in this case, O CCAM finds the ordinary recursive def-
   (Bob plays, OK, 1)                                      (10)     inition of multiplication in terms of addition. Item (19) is
   (Alice, OK, -1).                                        (11)     computable in T + ∆ as follows:
Then, ∆ = 0,  / and item (10) is computable in T + ∆, as in                           g(2,2)
                                                                                                 (22)
Example 12. Intuitively, no learning occurred, as the sentence                       g(2,1)+2
                                                                                                   (22)
can be analyzed with previously learned knowledge.                                (g(2,0)+2)+2
                                                                                                   (x+y)+z  x+(y+z)
   Now let us consider a learning process that concerns ele-                      g(2,0)+(2+2)
                                                                                                   2+2  4
mentary arithmetic and the challenge of learning a theory of                         g(2,0)+4
                                                                                                 (21)
arithmetic from examples.                                                               0+4 (17)
Example 14 Let L = Arith, as defined in Example 2 and                                   4+0 (14)
                                                                                         4
T = 0./ Also, suppose the IP consists of the following items:
   (5+0, 5, 1)                                             (12)     Example 17 Continuing with the theory T that consists of
                                                                    the axioms that the agent has learned thus far, it can now ex-
   (5+1, 5, -1).                                           (13)     trapolate number sequences, such as 8, 11, 14. In fact, let
Then, O CCAM returns the axiom                                      the IP be given by
   x+0  x.                                                (14)        (f(0), 8, 1)                                            (23)
Thus, O CCAM finds the identity axiom for + in this case. Item         (f(1), 11, 1)                                           (24)
(12) is computable in T + ∆ = {x+0  x} with a one-step                (f(2), 14, 1)                                           (25)
computation. However, item (13) is not computable in this              (f(0), 0, -1).                                          (26)
theory, as the theory contains no axiom with a left-hand side
that matches 5+1. Thus, the performance of T + ∆ is 1, which        Then, ∆ is the following theory:
is optimal.
   O CCAM does not output the axioms x  y, x+y  x, or,               f(0)  8                                                (27)
x  5, as each of these axioms enables item (13) to be com-            f(x+1)  f(x) + 3.                                      (28)
putable.
Example 15 We now let T consist of the previously learned           Thus, in this case, O CCAM finds a pattern in the number se-
axiom (14) and consider the IP given by                             quence. Item (25) is computable as follows:
   (2+3, 3+2, 1)                                           (15)                        f(2)
                                                                                                 (28)
   (1+3, 3+2, -1).                                         (16)                      f(1) + 3
                                                                                                     (28)
Then, O CCAM returns the axiom                                                  (f(0) + 3) + 3
                                                                                                     (x+y)+z  x+(y+z)
                                                                                f(0) + (3 + 3)
   x+y  y+x.                                              (17)                                      3+3  6
                                                                                     f(0) + 6
Thus, O CCAM finds the commutativity axiom for + in this                                         (27)
                                                                                       8 + 6
                                                                                               8+6  14
case. Item (15) is computable in T + ∆ as follows:                                       14
                                                                1543

We can now use this function to compute the value of f(3)             Gobet, F., & Lane, P. (2010). The CHREST Architecture of
and thus obtain the next number of the sequence 17. The same            Cognition: the Role of Perception in General Intelligence.
method can be applied to extrapolation and interpolation                In Artificial General Intelligence 2010, Lugano, Switzer-
problems involving arbitrary number sequences. From earlier             land. Atlantis Press.
work, we know that a fixed agent similar to the one consid-           Katayama, S. (2005). Systematic search for lambda expres-
ered in this example can perform above the average human                sions. Trends in functional programming, 6, 111–126.
level with respect to previously unseen IQ tests (Strannegård,       Kitzelmann, E. (2010). Inductive Programming: A Survey of
Nizamani, et al., 2013).                                                Program Synthesis Techniques. In Approaches and Appli-
                                                                        cations of Inductive Programming. Springer.
                        Conclusions                                   Kosslyn, S. M., & Smith, E. E. (2006). Cognitive Psychology:
We have presented a multi-domain computational model for                Mind and Brain. Upper Saddle River, NJ: Prentice-Hall.
symbolic reasoning with bounded cognitive resources that              Kühnberger, K.-U., Rudolph, S., & Wang, P. (2013). Pro-
supports reasoning by deduction, induction, and abduction.              ceedings of the 6th International Conference on Artificial
   The model differs from mainstream models that are used               General Intelligence, Beijing, China (Vol. 7999). Springer.
in logic, computer science, and cognitive psychology by in-           Laird, J., Newell, A., & Rosenbloom, P. (1987). Soar: An Ar-
corporating a unilateral model of human cognition that serves           chitecture for General Intelligence. Artificial Intelligence,
the purpose of reducing the computational complexity, while             33(3), 1–64.
keeping performance at the human level or above. Thus we              Li, M., & Vitányi, P. M. B. (2009). An introduction to Kol-
aim to tackle the combinatorial explosion problem that fre-             mogorov complexity and its applications. Springer.
quently arises in inductive logic programming, automatic the-         Muggleton, S., & Chen, J. (2012). Guest editorial: special is-
orem proving, and grammar induction.                                    sue on Inductive Logic Programming (ILP 2011). Machine
   The model is broad because it can learn entirely new do-             Learning, 1–2.
mains of symbolic reasoning by starting with an empty the-            Olsson, J. R. (1998). The art of writing specifications for the
ory. This was shown for simple versions of English gram-                ADATE automatic programming system. In 3rd Annual
mar and arithmetic. The model also has depth, as it performs            Conference on Genetic Programming (pp. 278–283).
above the average human level on several domains, includ-             Peirce, C. (1958). Collected Papers of Charles Sanders
ing number sequence extrapolation and tautology identifica-             Peirce. Belknap Press of Harvard University Press.
tion. We believe that the computational complexity of the             Piaget, J. (1937). La construction du réel chez l’enfant.
model could be improved considerably by adding some nat-                Delachaux & Niestlé.
ural heuristics. More research is needed to determine the             Robinson, J. A., & Voronkov, A. (2001). Handbook of Auto-
model’s generality, scalability, and sensitivity to training data       mated Reasoning. Elsevier.
variation.                                                            Strannegård, C., Engström, F., Nizamani, A. R., & Rips, L.
                                                                        (2013). Reasoning About Truth in First-Order Logic. Jour-
Acknowledgement                                                         nal of Logic, Language and Information, 1–23.
This research was supported by The Swedish Research Coun-             Strannegård, C., Nizamani, A. R., Sjöberg, A., & Engström,
cil (grant 421-2012-1000).                                              F. (2013). Bounded Kolmogorov complexity based on cog-
                                                                        nitive models. In K. U. Kühnberger, S. Rudolph, & P. Wang
                         References                                     (Eds.), Proceedings of AGI 2013, Beijing, China. Springer.
Adler, J. E., & Rips, L. J. (2008). Reasoning: Studies of Hu-         Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
   man Inference and its Foundations. Cambridge University              N. D. (2011). How to Grow a Mind: Statistics, Structure,
   Press.                                                               and Abstraction. Science, 331(6022), 1279–1285.
Anderson, J. R., & Lebiere, C. (1998). The atomic compo-              Toms, M., Morris, N., & Ward, D. (1993). Working Mem-
   nents of thought. Mahwah, N.J.: Lawrence Erlbaum.                    ory and Conditional Reasoning. The Quarterly Journal of
Bezem, M., Klop, J. W., & de Vrijer, R. (2003). Term Rewrit-            Experimental Psychology, 46(4), 679–699.
   ing Systems. Cambridge University Press.                           Troelstra, A., & Schwichtenberg, H. (2000). Basic Proof
Clark, A., & Lappin, S. (2010). Computational Learning                  Theory. Cambridge University Press.
   Theory and Language Acquisition. Philosophy of linguis-            Veness, J., Ng, K. S., Hutter, M., Uther, W., & Silver, D.
   tics.                                                                (2011). A Monte-Carlo AIXI approximation. Journal of
Ferri-Ramı́rez, C., Hernández-Orallo, J., & Ramı́rez-                  Artificial Intelligence Research, 40(1), 95–142.
   Quintana, M. J. (2001). Incremental Learning of Func-              Wang, P. (2007). From NARS to a Thinking Machine. In
   tional Logic Programs. In Functional and Logic Program-              Proceedings of the 2007 Conference on Artificial General
   ming. Springer.                                                      Intelligence (pp. 75–93). Amsterdam: IOS Press.
Garcez, A. S. d., & Lamb, L. C. (2011). Cognitive Algo-               Wang, P., & Goertzel, B. (2012). Theoretical Foundations of
   rithms and Systems: Reasoning and Knowledge Represen-                Artificial General Intelligence. Atlantis Press.
   tation. In V. Cutsuridis, A. Hussain, & J. G. Taylor (Eds.),
   Perception-Action Cycle. Springer New York.
                                                                  1544

