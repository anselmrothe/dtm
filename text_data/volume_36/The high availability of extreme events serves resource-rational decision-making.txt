UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The high availability of extreme events serves resource-rational decision-making
Permalink
https://escholarship.org/uc/item/5433c2jb
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Lieder, Falk
Hsu, Ming
Griffiths, Thomas L.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

  The high availability of extreme events serves resource-rational decision-making
                                               Falk Lieder (falk.lieder@berkeley.edu)
                          Helen Wills Neuroscience Institute, University of California at Berkeley, CA, USA
                                                Ming Hsu (mhsu@haas.berkeley.edu)
                                 Haas School of Business, University of California at Berkeley, CA, USA
                                        Thomas L. Griffiths (tom griffiths@berkeley.edu)
                                Department of Psychology, University of California at Berkeley, CA, USA
                                Abstract                                            Sampling as a Decision Strategy
                                                                         To evaluate a potential action a, decision makers should in-
   Extreme events come to mind very easily and people over-              tegrate the probabilities P(o|A = a) of possible outcomes
   estimate their probability and overweight them in decision-
   making. In this paper we show that rational use of limited cog-       o with their utilities u(o) into the action’s expected utility
   nitive resources can generate these ’availability biases.’ We hy-     E p(O|A=a) [u(O)] (Von Neumann & Morgenstern, 1944). In
   pothesize that availability helps people to quickly make good         the real-world–unlike in the laboratory–each action has in-
   decisions in very risky situations. Our analysis shows that
   agents who decide by simulating a finite number of possible           finitely many possible outcomes. As a consequence, the ex-
   outcomes (sampling) should over-sample outcomes with ex-              pected utility of action a becomes an integral:
   treme utility. We derive a cognitive strategy with connections
   to fast-and-frugal heuristics, and we experimentally confirm                                              Z
   its prediction that an event’s extremity increases the factor                      E p(O|A=a) [u(O)] =        p(o|a) · u(o) do.        (1)
   by which people overestimate its frequency. Our model also
   explains three context effects in decision-making under risk:
   framing effects, the Allais paradox, and preference reversals.        In the general case, this integral is intractable to compute, but
   Keywords: availability; Bayesian; bounded rationality; cog-
                                                                         it can be approximated by sampling methods (Hammersley &
   nitive biases; heuristics; judgment and decision-making               Handscomb, 1964). Mental simulations of a decision’s poten-
                                                                         tial consequences can be thought of as samples. In fact, there
                                                                         is neural evidence (Fiser, Berkes, Orbán, & Lengyel, 2010)
                           Introduction                                  and behavioral evidence (Vul, Goodman, Griffiths, & Tenen-
People overestimate the probability of extreme events such               baum, 2014; Denison, Bonawitz, Gopnik, & Griffiths, 2013;
as terrorism (Sunstein & Zeckhauser, 2011) and other threats             Griffiths & Tenenbaum, 2006) that the brain handles uncer-
(Lichtenstein, Slovic, Fischhoff, Layman, & Combs, 1978;                 tainty by sampling. For instance, people’s predictions of an
Rothman, Klein, & Weinstein, 1996) and overreact accord-                 uncertain quantity X given partial information y are roughly
ingly (Sunstein & Zeckhauser, 2011). This phenomenon has                 distributed according to the posterior distribution p(X|y) as
been explained by the availability bias (Tversky & Kahne-                if they were sampled from it (Griffiths & Tenenbaum, 2006;
man, 1973) according to which people overestimate the prob-              Vul et al., 2014). These results suggest that people often
ability of events that come to mind very easily.                         use only one or very few samples, and this is what rational
                                                                         agents with finite computational resources (bounded rational
   The availability bias appears irrational, but here we ar-
                                                                         agents) should do (Vul et al., 2014). The evidence for sam-
gue that it reflects the rational use of finite time (resource-
                                                                         pling in human cognition raises the question which sampling
rationality; Lieder, Griffiths, & Goodman, 2013, Griffiths,
                                                                         algorithm(s) are implemented in the brain.
Lieder, & Goodman, in revision). In brief, we hypothesize
that the high availability of extreme events helps decision-                Importance sampling is a popular sampling algorithm in
makers to allocate their finite time towards considering the             computer science and statistics (Hammersley & Handscomb,
most important consequences their decision might have. We                1964; Geweke, 1989), and it has been shown to have connec-
model the strategy that might determine which events come                tions to both neural network (Shi & Griffiths, 2009) and psy-
to mind first and how they influence judgment and decision-              chological process models (Shi, Griffiths, Feldman, & San-
making. Our model explains not only why people overesti-                 born, 2010). Self-normalizing importance sampling estimates
mate the probability of extreme events, but it also explains             the expected value of a function by the weighted average of
three context effects in decision-making under risk.                     the function’s values at points drawn from a distribution q:
   The plan of this paper is as follows: The first section intro-                                              p(x j )
duces the theoretical and empirical background. The second                         X1 , · · · , Xs ∼ q, w j =                             (2)
                                                                                                               q(x j )
section derives a rational model of decision-making in high-                                                             s
risk situations. The third section presents an experiment test-                                       IS       1
                                                                                   E p [ f (X)] ≈ Êq,s  =            · ∑ w j · f (x j ), (3)
ing the model’s predictions for frequency judgment, and the                                                ∑sj=1 w j    j=1
fourth section applies the model to explain context-effects in
decision-making under risk. The final section discusses our              where wi is the weight of the ith sample. With finitely many
results and their implications.                                          samples, this estimate is generally biased. Following Zabaras
                                                                     2567

(2010), we approximate its bias and variance by                                     though the expected utility is about −1000. In conclusion,
                                                                                    under high risk, representative sampling is insufficient for
                           1        p(x)2
                                Z
                  IS
         Bias[Êq,s   ]≈      ·              · (E p [ f (x)] − f (x)) dx     (4)    resource-bounded decision-making.
                           s         q(x)                                              What is the problem with representative sampling and how
                         1
                              Z
                                   p(x)2                                            can it be overcome? Representative sampling fails when it
                 IS
         Var[Êq,s  ]≈      ·              · ( f (x) − E p [X])2 dx          (5)    neglects crucial eventualities. Neglecting some eventuali-
                         s          q(x)
                                                                                    ties is necessary, but particular eventualities are more im-
Importance sampling can be used to approximate the ex-                              portant than others. Intuitively, the importance of potential
pected utility E p(O|A=a) [u(O)] of taking action a and to es-                      outcome oi is determined by |p(oi ) · u(oi )| because neglect-
timate the optimal decision a? = arg maxa E p(O|A=a) [u(O)]:                        ing oi amounts to dropping the addend p(oi ) · u(oi ) from the
                                                                                    expected-utility integral (Equation 1). Thus, intuitively, the
     â? = arg max Ûq,s  IS
                             (a), Ûq,s  IS
                                            (a) ≈ E p(O|a) [u(O)]            (6)    problem of representative sampling can be overcome by con-
                    a
                                  s                                                 sidering outcomes whose importance (|p(oi ) · u(oi )|) is high
        IS              1
     Ûq,s (a) =                ∑    w j · u(o j ),     o1 , · · · , os ∼ q. (7)    and ignoring those whose importance is low.
                    ∑sj=1 w j j=1                                                      Formally, the agent’s goal is to maximize the expected util-
                                                                                    ity of a decision made from only s samples. The utility fore-
Note that importance sampling is a family of algorithms: each
                                                                                    gone by choosing a sub-optimal action can be upper-bounded
importance distribution q yields a different estimator, and two
                                                                                    by the error in a rational agent’s utility estimate. Therefore
estimators may recommend opposite decisions. We thus con-
                                                                                    the agent should minimize the expected squared error of its
sider which distribution q yields the best decisions.
                                                                                    utility estimate,
                                                                                                     which    is the sum of its squared bias and vari-
                                                                                    ance, i.e. E (Ûq,s IS − E[U])2 ] = Bias[Û IS ]2 + Var[Û IS . As
   Which distribution should we sample from?                                                                                      q,s              q,s
                                                                                    the number of samples s increases, the estimate’s squared bias
Intuitively, the rational way to make a decision is to simu-                        decays much faster (O(s−2 )) than its variance (O(s−1 )); see
late consequences o according to one’s best knowledge of the                        Equations 4-5. Therefore, as the number of samples s in-
probability p that they will occur, i.e. q = p:                                     creases, minimizing the estimator’s variance becomes a good
                           1 s                                                      approximation to minimizing its expected squared error.
            ÛsRS (a) =       ∑ u(oi ), o1 , · · · , os ∼ p(O).              (8)       According to variational calculus the variance (Equation 5)
                           s i=1
                                                                                    of the utility estimate in Equation 7 is minimized by
This importance sampling algorithm, which we call represen-
                                                                                                     qvar (o) ∝ p(o) · |u(o) − E p [U]|.               (10)
tative sampling, computes unbiased utility estimates. Yet–
surprisingly– representative sampling is insufficient for mak-                      Interestingly, the optimal sampling distribution overrepre-
ing good decision with very few samples. Consider, for in-                          sents outcomes with large absolute utility, Thus, biased sam-
stance, the choice to play Russian roulette with the popu-                          pling can lead to better decisions. Unfortunately, importance
lar six-round NGant M1895 revolver. Playing the game will                           sampling with qvar is intractable, because it presupposes the
most likely, i.e. with probability p1 = 56 , reward you with a                      expected utility E p [U] that importance sampling is supposed
thrill and a gain in status (u(o1 ) = 1) but kill you otherwise                     to approximate. A priori the expected utility of a prospect
(p2 = 16 , u(o2 ) = −109 ). Ensuring that representative sam-                       whose outcomes may be good or bad is equally likely to be
pling declines a game of Russian roulette at least 99.99% of                        positive or negative. The same is true for choosing action a
the time, would require 51 samples–potentially a very time-                         over action b or vice versa. Therefore, the most principled
consuming computation. Many real-life decisions involve                             guess an agent can make for the expected utility E p [U] in
high risks and are even more challenging, because the prob-                         Equation 10–before computing it–is 0. Thus when the ex-
ability of disaster is orders of magnitude smaller than 61 but                      pected utility is not too far from zero, then the importance
may or may not be large enough to warrant caution. Exam-                            distribution qvar is efficiently approximated by
ples include risky driving, the stock market, and air travel.
For some of these choices (e.g. texting while driving) there                                                q̃(o) ∝ p(o) · |u(o)|.                     (11)
may be a one in a million chance of disaster while all other
outcomes have negligible utilities:                                                 This confirms our intuition and leads to an importance sam-
                                                                                    pling scheme that we call utility-weighted sampling:
    u(od ) = −109 , p(od ) = 10−6 , ∀i 6= d : |u(oi )| ≤ 1                   (9)                                      s
                                                                                             IS            1
                                                                                          Ûq̃,s =                   ∑   sgn (u(o j )) , o j ∼ q̃,     (12)
If people decided based on n representative samples, they                                          ∑sj=1 1/|u(o j )| j=1
would completely ignore the potential disaster with proba-
bility 1 − (1 − 10−6 )n . Thus to have at least a 50% chance                        where sgn(x) is +1 for positive x and −1 for negative x.
of taking the potential disaster into account the agent would                       Utility-weighted sampling is a simple and psychologically
have to generate almost 700 million samples. This is clearly                        plausible strategy for decision-making under uncertainty: It
infeasible; thus one would almost always take this risk even                        generates examples of possible outcomes by an appropriately
                                                                                2568

biased simulation and tallies how many of them are positive.                                                         0.8
                                                                                                                                     avg. estimate (95% CI)
If more than half of the examples for the utility of choosing                                                        0.6
                                                                                                probability
                                                                                                                                     natural statistics
                                                                                                                     0.4
action a over action b are positive, then the agent will prefer
                                                                                                                     0.2
action a; if more than half of them are negative, then the agent                                                      0
                                                                                                                           mundane      stressful        death (all causes)
will prefer action b; otherwise it it will be indifferent.
                                                                                         judged extremity (95% CI)
                                                                                                                     100
   Utility-weighted sampling succeeds where representative
sampling failed. In Russian roulette utility-weighted sam-                                                           50
pling requires only 1 rather than 51 samples to recommend
the correct decision at least 99.99% of the time, because the                                                         0
                                                                                                                           mundane      stressful              lethal
first sample is almost always the most important potential out-                                                                        event type
come, i.e. death. Likewise one single utility-weighted sample
                                                                                  Figure 1: Judged frequency and extremity by event type.
suffices to consider the potential disaster (Equation 9) at least
99.85% of the time, whereas even 700 million representative
samples would miss the disaster almost half of the time. Thus,                ficial statistics.1 The complete experiment can be inspected
utility-weighted sampling would allow people to avoid both                    online.2 Out of 100 participants 17 failed the attention check
disasters even under extreme time pressure. The hypothesis                    (wrong answer on attention-check questions, or mean judged
that people decide by utility-weighted sampling makes two                     extremity of lethal events less than 75%) and were excluded.
predictions that we test in the next two sections:
                                                                              Results and Discussion
1. People overestimate an event’s probability more, the more
                                                                              Consistent with our theory, participants overestimated the fre-
   extreme the event is.
                                                                              quencies of all lethal events (all p < 0.0005) but none of
2. Extreme potential outcomes are over-weighted in decision-                  the mundane events (all p > 0.048 > αSidak = 0.0014, Sidak-
   making, and extremity is context-dependent.                                correction for multiple comparisons). Participants also over-
                                                                              estimated 23 of the 30 stressful life events. Figure 1 shows
 Overestimation of extreme events’ frequencies                                that across event types overestimation gradually increase with
We hypothesize that the mind re-uses utility-weighted sam-                    extremity: Absolute overestimation ( p̂ − p) was significantly
pling (Equation 12) to estimate event frequencies, because                    larger for stressful life events than for mundane events (p <
evolutionary fitness depended on good decisions rather than                   0.01) and even larger for lethal events (p = 0.02). While
accurate statements of probability. We therefore predict that                 our participants’ probability estimates were very accurate for
people’s estimate p̂k of the probability pk = p(ok ) is                       mundane events, their (implicit) estimate of the annual death
                                                                              rate was 25-times higher than its true value. For stressful life
               ∑si=1 wi · 1(oi = ok )           1                             events overestimation and judged extremity are both interme-
       pˆk =            s             , wi =           , oi ∼ q̃.   (13)
                      ∑i=1 iw                |u(o i )|                        diate. This pattern answers the open question whether avail-
                                                                              ability or regressed frequency causes the overestimation of
Since the importance density q̃(o) ∝ p(o) · |u(o)| over-                      extreme events (Hertwig, Pachur, & Kurzenhäuser, 2005): if
represents events proportionally to their extremity |u|, i.e.                 estimates were merely regressive towards a mean frequency,
q̃(o)
 p(o) ∝ |u(o)|, we predict that people’s relative over-estimation             as proposed by Gigerenzer (2008a), then people should un-
 p̂k                                                                          derestimate frequent mundane events, but our participants did
 pk   is a monotonically increasing function of the event’s ex-
tremity |uk |. Formally, the bias (Equation 4) of utility-                    not. Figure 2 shows that the average relative overestimation
weighted probability                                                          of the 37 events increases with their judged extremity (Spear-
                       estimation (Equation 13) implies that                man’s rank correlation ρ = 0.53, p < 0.001). Furthermore, we
 pˆk −pk    1    1
    pk = s − |ui | +C , for some constant C. We tested this                   observed the same effect at the level of individual judgments
prediction with a simple experiment.                                          (Spearman’s rank correlation ρ = 0.28, p < 10−15 ). On aver-
Methods                                                                       age, the extremest event’s frequency (murder, 98% extreme)
                                                                              was overestimated by a factor of 972, whereas the frequency
We recruited 100 participants on Amazon Mechanical Turk.                      of the least extreme event (headache, 20% extreme) was over-
Each participant estimated how many of 1000 randomly se-                      estimated by merely 6% (n.s.). Consistent with this result,
lected American adults had experienced each of 39 events in                   Rothman et al. (1996) found that prevalence is more heavily
2013 and judged the events’ valence (good or bad) and ex-                     overestimated for suicide than for divorce.
tremity (0: neutral – 100: extreme). The 39 events comprised                     In conclusion, the experiment confirmed our theory’s pre-
30 stressful life events from Hobson et al. (1998), four lethal               diction that an event’s extremity increase the relative overesti-
events (suicide, homicide, lethal accidents, and dying from                   mation of its frequency. However, additional experiments are
disease/old age), three more mundane events (going to the
movies, headache, and food-poisoning), and two attention-                        1 Hobson & Delunas (2001),www.cdc.gov/nchs/fastats/deaths.htm,www
                                                                              .mpaa.org/resources/3037b7a4-58a2-4109-8012-58fca3abdf1b.pdf,www.cdc
checks. Overestimation was measured by the ratio of a par-                    .gov/foodborneburden/, Rasmussen, Jensen, Schroll, & Olesen (1991).
ticipant’s estimate over the event’s frequency according to of-                  2 http://sites.google.com/site/falklieder/freq estimation.html
                                                                           2569

                                                             ρ = 0.53, p < 0.001
                                           40
            relative overestimation rank
                                           35
                                           30
                                           25
                                           20
                                           15
                                           10
                                            5
                                            0
                                                0   5   10      15    20     25      30   35   40
                                                             judged extremity rank
Figure 2: Overestimation p̂−p p increases with perceived ex-
tremity (|u|). A cross represents one event’s average ratings.                                         Figure 3: Risk preferences (E[∆Û]) predicted by utility-
                                                                                                       weighted sampling with s = 2.
required to disentangle the effects of extremity and low prob-
ability, because these two factors were anti-correlated. Future
                                                                                                       According to our theory, people simulate ∆U by sampling
work will formally test our model against competing theories                                                                                                       IS ac-
                                                                                                       from q̃(∆u) ∝ |∆u| · p(∆u) and estimate E[∆U] by ∆Ûq̃,s
and investigate whether the effect of an event’s extremity is
                                                                                                       cording to Equation 12. When the bias of this estimate
mediated by how many instances of this event people imagine                                                       IS )) is positive, the agent will fancy the gamble
                                                                                                       (Bias(∆Ûq̃,s
or retrieve from memory (cf. Hertwig et al., 2005).
                                                                                                       (risk-seeking), but when it is negative, the agent will be risk-
                                                                                                       averse. The importance distribution q̃ is proportional to |∆u|.
         Context effects in decision-making
                                                                                                       Therefore the agent will overweight the gain/loss o of the lot-
While our goal was to explain why people overestimate the                                              tery if p(o) is small, because then |u(o) − u(p · o)| > |u(p · o|).
probability of extreme events, utility-weighted sampling also                                          Conversely, the agent will underweight outcome o if p(o) is
predicts that people over-weight certain outcomes in eco-                                              large, because then |u(o) − u(p · o)| < |u(p · o|)). This renders
nomic decisions. To simulate such decisions we model the                                               the agent’s bias positive (risk-seeking) for improbable gains
utility of winning or losing money by the following function                                           and probable losses but negative (risk-aversion) for probable
based on prospect theory (Tversky & Kahneman, 1992):                                                   gains and improbable losses (see Figure 3). Thus our model
                        (                                                                              predicts the fourfold pattern of risk preferences which is used
                          o0.85      , if o ≥ 0                                                        to explain how a person who is so risk-averse that he buys
                u(o) =                          .        (14)
                          −|o|0.95 , if o < 0                                                          insurance can also be so risk-seeking that he plays the lottery.
                                                                                                          Next we show by simulation that a bounded rational agent
When choosing between receiving a high payoff with low
                                                                                                       might indeed make both choices. First, we simulated the de-
probability (risky gamble) or a low payoff with high proba-
                                                                                                       cision whether or not to play the Powerball lottery.3 The jack-
bility (safe gamble), people often prefer the risky gamble in
                                                                                                       pot is at least $40 million, but the odds of winning it are less
one context but the safe gamble in another. This suggests
                                                                                                       than 1:175 million. In brief, people pay $2 to play a gam-
that people’s risk preferences are inconsistent and context-
                                                                                                       ble whose expected value is only $1. We found that utility-
dependent (Tversky & Kahneman, 1992). Utility-weighted
                                                                                                       weighted sampling does, in expectation, fancy the lottery
sampling can explain several such inconsistencies: (i) fram-                                                                                                IS ] ≥ 59.8
                                                                                                       when the number of samples is less than 4 (E[Ûq̃,s
ing effects, (ii) the Allais paradox, and (iii) preference rever-
                                                                                                       for s ≤ 3). If the agent chose based on one sample (cf. Vul
sals. We now consider these in turn.
                                                                                                       et al., in press) and was given the choice twice a week, it
Framing effects on risk attitudes                                                                      would buy about seven lottery tickets per year. This value
                                                                                                       is a lower bound, because it ignores debt and other factors.
Framing outcomes as losses rather than gains can reverse peo-
                                                                                                       Nevertheless, it demonstrates that playing the lottery is com-
ple’s risk preferences (Tversky & Kahneman, 1992): In the
                                                                                                       patible with resource-rational decision-making. Second, we
domain of gains people prefer a lottery (o dollars with proba-
                                                                                                       simulated the decision whether or not to buy insurance. The
bility p) to its expected value (risk seeking) when p < 0.5, but
                                                                                                       magnitude of an insured loss l can be modeled by the Pareto
when p > 0.5 they prefer the expected value (risk-aversion).                                                                           α · x−α−1 , x             9
                                                                                                       distribution (e.g., p(l) = α · xmin          min < x < 10 with
To the contrary, in the domain of losses people are risk seek-
                                                                                                       α = xmin = 1). We found that the bias of utility-weighted
ing for p < 0.5 but risk averse for p > 0.5. This phenomenon
                                                                                                       sampling (Equation 4) would make people overestimate the
is known as the fourfold pattern of risk preferences.
                                                                                                       value of insurance against such a loss by 244   s %, where s is
   Whether or not people should choose the gamble depends
                                                                                                       the number of samples. This resolves the apparent paradox
on the expected value of the utility difference ∆U:
                                                                                                       of being willing to buy both lottery tickets and insurance.
            (
               u(o) − u(p · o) with probability p
     ∆U =                                                  (15)
               −u(p · o)         with probability 1 − p                                                    3 www.calottery.com/play/draw-games/powerball
                                                                                                    2570

                        Table 1: Allais Gambles                                Table 3: Utility-weighted sampling explains preference reversals.
             (o1 , p1 )    (o2 , p2 )       (o3 , p3 )                                  utility of                                       E[U]             IS ]
                                                                                                                                                     E[Ûq̃,2
  L1 (z) :   (z, 0.66)     (2500, 0.33)     (0, 0.01)                                   safer gamble (Ls : $1, p = 0.8)                  0.80        1
  L2 (z) :   (z, 0.66)     (2400, 0.34)                                                 riskier gamble (Lr : $2, p = 0.4)                0.72        1.8
                                                                                        choosing Ls over Lr                              0.079       0.075
  Table 2: Utility-weighted sampling explains the Allais paradox.
              ∆U                      p                q̃      q̃/p
              0                       0.66             0       0              utility function (cf. Equation 14); see Table 3. This illustrates
z = 2400: u(2500) − u(2400)           0.33             0.54    1.6            that utility-weighted sampling weights events differently de-
              −u(2400)                0.01             0.46    46             pending on the problem to be solved.
              0                       0.66 · 0.67       0       0
              −u(2400)                0.67 · 0.34       0.5     2.19
z=0:          u(2500) − u(2400)       0.33 · 0.34       0.01    0.08                                      General Discussion
              u(2500)                 0.33 · 0.66       0.49    2.26
                                                                              Our resource-rational analysis of decision-making in high-
Note: The agent’s simulation yields ∆U = ∆u with probability                  risk situations suggested that people should decide by utility-
q̃(∆u) ∝ p(∆u) · |∆u| where p is ∆u’s objective probability.                  weighted sampling (Equation 12). Utility-weighted sampling
                                                                              explains not only how we are able to make sensible decisions
                                                                              under high risk but also why we overestimate the frequency of
The Allais paradox                                                            extreme events and have inconsistent risk preferences (fram-
In the two gambles L1 (z) and L2 (z) defined in Table 1 the                   ing effects, the Allais paradox, and preference reversals).
chance of winning z dollars is exactly the same. Yet, when z =                   While overestimation was previously explained by ‘avail-
2400 most people prefer L2 over L1 , but when z = 0 the same                  ability’ (Tversky & Kahneman, 1973), our theory specifies
people prefer L1 over L2 . This inconsistency is known as the                 what exactly the availability of events should correspond to–
Allais paradox. Table 2 shows how our theory resolves this                    namely their importance distribution q̃ (Equation 11)–and
paradox: According to the importance distribution q̃ (Equa-                   why this is useful. Inconsistent risk preferences were pre-
tion 11) people overweight the event for which the utility dif-               viously explained by regret (Loomes & Sugden, 1982) or
ference between the two gambles’ outcomes (O1 and O2 ) is                     salience (Bordalo, Gennaioli, & Shleifer, 2012). Like these
largest (∆U = u(O1 ) − u(O2 )). Thus when z = 2400, the most                  explanations our theory assumes an amplified impact of large
over-weighted event is the possibility that gamble L1 yields                  utility differences. While regret theory explains this ampli-
o1 = 0 and gamble L2 yields o2 = 2400 (∆U = −u(2400));                        fication by altered subjective utilities, utility-weighted sam-
consequently the bias is negative and the first gamble ap-                    pling and salience theory explain the amplification by al-
pears inferior to the second (E[∆Ûq̃,2      IS ] = −152). But when
                                                                              tered probability-weighting. Despite this commonality, our
z = 0, then L1 yielding o1 = 2500 and L2 yielding o2 = 0                      account offers three advances over salience theory. First,
(∆U = +u(2500)) becomes the most over-weighted event                          we do not only describe the effect of utility on probability-
making the first gamble appear superior (E[∆Ûq̃,2           IS ] = +4.1).
                                                                              weighting, but we also model the cognitive strategy that gen-
This explains why people’s preferences switch from the sec-                   erates it. Second, our theory reconciles this seemingly ir-
ond to the first gamble as z switches from 2400 to 0.                         rational effect with rational information processing. Con-
                                                                              cretely, the resource-rational basis of the salience of a util-
Preference Reversals                                                          ity difference ∆U = u(O1 ) − u(O2 ) is the relative frequency
When people first price a risky gamble and a safe gamble with                 with which it should be simulated, i.e. the importance dis-
similar expected value and then choose between them, their                    tribution q̃ (∆u) ∝ p (∆u) · |∆u|.4 Third, since our explanation
preferences are inconsistent almost 50% of the time: most                     instantiates a more general theoretical framework–resource-
people price the risky gamble higher than the safe one, but                   rationality–it can be extended to multi-alternative decisions,
many of them nevertheless choose the safer one (Lichtenstein                  decisions from experience, and many other problems.
& Slovic, 1971). Utility-weighted sampling over-estimates                        We have proposed a psychologically plausible cognitive
the expected utility E prisky [u(Orisky )] of high-payoff (risky)             strategy that approximates the normative–but intractable–
lotteries more than for low-payoff (safe) lotteries, because                  decision-rule of expected utility theory in two simple steps:
q̃(o) ∝ |u(o)|. This explains why people price the risky gam-                 (i) generate example outcomes by biased mental simula-
ble higher than the safe one. To choose between two lot-                      tion, and (ii) count how many of them are positive. Inter-
teries our model estimates the expected utility difference,                   estingly, these steps resemble two fast-and-frugal heuristics
i.e. E psafe,risky [u(Osafe ) − u(Orisky )]. In this estimation prob-         (Gigerenzer, 2008b): Biased mental simulation (stochasti-
lem there are 2 × 2 rather than just 2 possible outcomes, and                 cally) considers the most important consequence first–like
the importance of positive outcomes is counterbalanced by                     take-the-best–and binary choices are made by tallying if there
the importance of the negative outcome. As a result, utility-                 are more positive than negative simulated outcomes–as in
weighted sampling’s bias in favor of the riskier option is                    the tallying heuristic. The fact that we derived this strategy
weaker in choice than in pricing: so weak that it is overwrit-
ten by the risk-aversion due to concavity (flattening) of the                     4 This definition satisfies two of Bordalo et al.’s (2012) three axioms of salience.
                                                                          2571

 as a resource-efficient approximation to normative decision-                  Gigerenzer, G. (2008b). Why heuristics work. Perspect. Pschol.
 making (resource-rational analysis) sheds light on why fast-                   Sci., 3(1), 20–29.
                                                                               Gigerenzer, G., & Brighton, H. (2009). Homo heuristicus: Why
 and-frugal heuristics work and how they can be generalized                     biased minds make better inferences. Top. Cogn. Sci., 1(1), 107–
 to harder problems (cf. Lieder, Griffiths, & Goodman, 2013).                   143.
 Future research will also compare the rationality and descrip-                Griffiths, T. L., Lieder, F., & Goodman, N. D. (in review). Levels
                                                                                of analysis between the computational and the algorithmic. Top.
 tive accuracy of heuristics derived by resource-rational anal-                 Cogn. Sci..
 ysis to established heuristics, decision-by-sampling (Stewart,                Griffiths, T. L., & Tenenbaum, J. B. (2006). Optimal predictions in
 Chater, & Brown, 2006), and other models of risky choice                       everyday cognition. Psychol. Sci., 17(9), 767–773.
                                                                               Hammersley, D. C., & Handscomb, J. M. (1964). Monte Carlo
 (Erev et al., 2010). Our theory makes three novel predictions:                 methods. London: Methuen & Co Ltd.
                                                                               Harman, G. (2013). Rationality. In H. LaFollette, J. Deigh, &
1. The probability-weighting function (Tversky & Kahne-                         S. Stroud (Eds.), International Encyclopedia of Ethics. Hoboken:
    man, 1992) depends on the ratio of the outcomes’ utilities.                 Blackwell Publishing Ltd.
                                                                               Hertwig, R., Pachur, T., & Kurzenhäuser, S. (2005). Judgments of
                                                                                risk frequencies: tests of possible cognitive mechanisms. J. Exp.
2. As time pressure or cognitive load increase, people’s risk                   Psychol.-Learn. Mem. Cogn., 31(4), 621.
    preferences become more inconsistent.                                      Hobson, C. J., & Delunas, L. (2001). National norms and life-event
                                                                                frequencies for the revised social readjustment rating scale. Int. J.
3. The more concave a person’s utility function, the less she                   Stress Manag., 8(4), 299–314.
                                                                               Hobson, C. J., Kamen, J., Szostek, J., Nethercut, C. M., Tiedmann,
    will overestimate and over-weight extreme events.                           J. W., & Wojnarowicz, S. (1998). Stressful life events: A revision
                                                                                and update of the social readjustment rating scale. Int. J. Stress
    In conclusion, utility-weighted sampling is a promising ra-                 Manag., 5(1), 1–23.
 tional process model of probability judgment and decision-                    Lichtenstein, S., & Slovic, P. (1971). Reversals of preference be-
                                                                                tween bids and choices in gambling decisions. J. Exp. Psychol.,
 making. This strategy works not despite but because it is                      89(1), 46–55.
 biased (cf. Gigerenzer & Brighton, 2009). Biased minds                        Lichtenstein, S., Slovic, P., Fischhoff, B., Layman, M., & Combs, B.
 can not only make better inferences but also better decisions.                 (1978). Judged frequency of lethal events. J. Exp. Psychol. Hum.
                                                                                Learn. Mem., 4(6), 551.
 However, our results highlight a tension between good in-                     Lieder, F., Goodman, N. D., & Griffiths, T. L. (2013). Reverse-
 ference and good decision-making: Bounded sample-based                         engineering resource-efficient algorithms [Paper presented at
 agents should over-sample extreme events even though this                      NIPS-2013 Workshop Resource-Efficient ML, Lake Tahoe, USA].
                                                                               Lieder, F., Griffiths, T. L., & Goodman, N. D. (2013). Burn-in, bias,
 leads to overestimation (bad inference), and people appear to                  and the rationality of anchoring. In P. Bartlett, F. C. N. Pereira,
 do the same. In more general terms, the human mind should,                     L. Bottou, C. J. C. Burges, & K. Q. Weinberger (Eds.), Adv. neural
 and appears to, sacrifice the rationality of its beliefs (the-                 inf. process. syst. 26. Red Hook: Curran Associates, Inc.
                                                                               Loomes, G., & Sugden, R. (1982). Regret theory: An alternative
 oretical rationality) for the rationality of its actions (prac-                theory of rational choice under uncertainty. Econ. J., 92(368), 805–
 tical rationality, Harman, 2013), because limited computa-                     824.
 tional resources necessitate tradeoffs. Concretely, our anal-                 Rasmussen, B. K., Jensen, R., Schroll, M., & Olesen, J. (1991). Epi-
                                                                                demiology of headache in a general populationa prevalence study.
 ysis suggested that the availability bias is a manifestation                   J. Clin. Epidemiol., 44(11), 1147–1157.
 of resource-rational decision-making. This conclusion sup-                    Rothman, A. J., Klein, W. M., & Weinstein, N. D. (1996). Absolute
 ports the emerging view that cognitive biases are a window on                  and relative biases in estimations of personal risk. J. Appl. Soc.
                                                                                Psychol., 26(14), 1213–1236.
 resource-rational computation rather than a sign of irrational-               Shi, L., & Griffiths, T. (2009). Neural implementation of hierar-
 ity (Lieder, Griffiths, & Goodman, 2013; Lieder, Goodman,                      chical Bayesian inference by importance sampling. In Y. Bengio,
 & Griffiths, 2013). Being biased can be resource-rational.                     D. Schuurmans, J. Lafferty, C. K. I. Williams, & A. Culotta (Eds.),
                                                                                Adv. neural inf. process. syst. 22 (pp. 1669–1677). Red Hook: Cur-
                                                                                ran Associates, Inc.
 Acknowledgments. This work was supported by grant number                      Shi, L., Griffiths, T., Feldman, N., & Sanborn, A. (2010). Exemplar
 N00014-13-1-0341 from the Office of Naval Research and grant                   models as a mechanism for performing Bayesian inference. Psy-
 number RO1 MH098023 from the National Institutes of Health.                    chon. Bull. Rev., 17(4), 443–464.
                                                                               Stewart, N., Chater, N., & Brown, G. D. (2006). Decision by sam-
                                                                                pling. Cogn. Psychol., 53(1), 1–26.
                              References                                       Sunstein, C. R., & Zeckhauser, R. (2011). Overreaction to fearsome
 Bordalo, P., Gennaioli, N., & Shleifer, A. (2012). Salience theory             risks. Environ. Resour. Econ., 48(3), 435–449.
  of choice under risk. Q. J. Econ., 127(3), 1243–1285.                        Tversky, A., & Kahneman, D. (1973). Availability: A heuristic
 Denison, S., Bonawitz, E., Gopnik, A., & Griffiths, T. (2013). Ra-             for judging frequency and probability. Cogn. Psychol., 5(2), 207–
  tional variability in childrens causal inferences: The sampling hy-           232.
  pothesis. Cognition, 126(2), 285–300.                                        Tversky, A., & Kahneman, D. (1992). Advances in prospect theory:
 Erev, I., Ert, E., Roth, A. E., Haruvy, E., Herzog, S. M., Hau, R., . . .      Cumulative representation of uncertainty. J. Risk Uncertain., 5(4),
  Lebiere, C. (2010). A choice prediction competition: Choices from             297–323.
  experience and from description. J. Behav. Decis. Making, 23(1),             Von Neumann, J., & Morgenstern, O. (1944). The theory of games
  15–47.                                                                        and economic behavior. Princeton: Princeton university press.
 Fiser, J., Berkes, P., Orbán, G., & Lengyel, M. (2010). Statistically        Vul, E., Goodman, N. D., Griffiths, T. L., & Tenenbaum, J. B.
  optimal perception and learning: from behavior to neural represen-            (2014). One and done? Optimal decisions from very few samples.
  tations. Trends Cogn. Sci., 14(3), 119–130.                                   Cognitive Sci., 1–39.
 Geweke, J. (1989). Bayesian inference in econometric models using             Zabaras, N. (2010). Importance sampling (Tech. Rep.). Cornell
  Monte Carlo integration. Econometrica, 57(6), 1317–1339.                      University. Retrieved from http://mpdc.mae.cornell.edu/
 Gigerenzer, G. (2008a). Rationality for mortals: How people cope               Courses/UQ/ImportanceSampling.pdf
  with uncertainty. Oxford University Press.
                                                                           2572

