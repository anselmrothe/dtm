UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Statistical Unpredictability of F0 Trajectories as a Cue to Sentence Stress
Permalink
https://escholarship.org/uc/item/1f2626mj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Kakouros, Sofoklis
Rasanen, Okko Jihannes
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                     Powered by the California Digital Library
                                                                       University of California

           Statistical Unpredictability of F0 Trajectories as a Cue to Sentence Stress
                                          Sofoklis Kakouros (sofoklis.kakouros@aalto.fi)
                                    Department of Signal Processing and Acoustics, Aalto University,
                                                       PO Box 13000, AALTO, Finland
                                               Okko Räsänen (okko.rasanen@aalto.fi)
                                    Department of Signal Processing and Acoustics, Aalto University,
                                                       PO Box 13000, AALTO, Finland
                                Abstract                                  poses the question of learnability versus innateness of stress
                                                                          perception: If stress perception is innate, it is likely that
   This paper introduces a hypothesis that the perceived sentence
   stress in speech is related to the unpredictability of prosodic        there are universal physical characteristics that define
   features, thereby capturing attention of the listener. In order to     stressed words with respect to unstressed ones. On the other
   study this idea, a computational model was designed that               hand, if stress perception is learned, the relevant question is
   learns the statistical structure of temporal F0 trajectories from      then what is actually learned from the signals, how it is
   continuous speech data without supervision using n-gram                learned, and how does this learning of prosody relate to the
   statistics. When the model output is compared to human                 other aspects of speech perception. The problem regarding
   perception of stress on a set of novel utterances, the low-            the nativist (or “hard-wired”) approach is that it has
   probability points of the F0 trajectories show high correlation        difficulties in explaining the differences in stress use across
   with the moments of subjective perception of stress. The
                                                                          languages, talkers, and speaking styles. On the other hand,
   result gives support to the idea that perceptual attention and
   unpredictability of sensory stimulus are mutually connected,           perceptual learning of stress cannot be based on explicit
   and suggests that stress perception can be learned with similar        instruction since, at least according to the knowledge of the
   statistical learning mechanisms that are considered to play a          authors, language learners rarely receive feedback for their
   central role in early word segmentation.                               supra-segmental perceptual processing of language.
                                                                             The role of learning in stress perception is especially
   Keywords: sentence stress; prosody; pitch; attention;
   statistical learning                                                   relevant in the context of language acquisition research. For
                                                                          example, word-level stress patterns are known to be relevant
                            Introduction                                  for early word segmentation (Endress & Hauser, 2010;
                                                                          Jusczyk, Cutler & Redanz, 1993; Peters, 1983; Thiessen,
Sentence stress is a universal property of speech where a                 Hill & Saffran, 2005). Similarly, it can be hypothesized that
word or multiple words of an utterance are given a special                one role of sentence stress in infant-directed speech (IDS) is
emphasis in the message in order to facilitate the listener’s             to provide attentional cues to the child regarding the
perception and draw attention to these aspects of the content             important content words in the message (Fernald & Mazzie,
(e.g., Cutler & Foss, 1977). It is widely accepted that stress            1991). For example, focus on specific words may facilitate
is correlated with prosodic features such as pitch, loudness,             cross-situational learning between acoustic word forms and
and timing (Imoto et al., 2002; Cutler & Foss, 1977; see also             their referents by constraining the number of relevant
Cutler, Dahan & Donselaar, 1997, for a review). Also, the                 candidate words in the present utterance.
acoustic correlates of stress seem to be relatively universal                 As for the computational modeling of stress detection
across languages although the specific realizations of stress             and perception, previous approaches have primarily focused
patterns may vary substantially from one language to                      on supervised learning of the relationship between prosodic
another with respect to the underlying linguistic content                 (acoustic) features and the stressed and/or non-stressed units
(Endress & Hauser, 2010). The characteristics of prosody                  of speech (Chaolei, Jia & Shanhong, 2007; Imoto, Dantsuji
and prominence are also similar in infant-directed speech                 & Kawahara, 2000; Imoto et al., 2002; Lai et al., 2006;
(IDS) and adult-directed speech (ADS), although the                       Minematsu et al., 2002; Ringerval et al., 2011; Rosenberg &
prosodic modulation is typically exaggerated in the IDS and               Hirchberg, 2009). For example, Imoto et al. (2002)
the stressed words in IDS may exhibit more systematic                     proposed a two-stage model where a weighted combination
relative positioning in the utterance in comparison to the                of F0, signal power, and Mel-frequency cepstral coefficients
ADS (Endress & Hauser, 2010; Ferguson, 1964; Fernald &                    (MFCCs) are used in a hidden-Markov model (HMM) to
Mazzie, 1991; Grieser & Kuhl, 1988; Remick, 1976).                        determine the presence or absence of stress in a word,
    However, despite the well documented findings on                      followed by a more close evaluation of the stress level.
acoustic and linguistic characteristics of stress, it is not well         Another approach was presented by Minematsu et al. (2002)
understood why listeners pay attention to these specific                  who proposed a technique for modeling stressed and
aspects of the acoustic signal and, on the other hand, how                unstressed syllables in speech by analyzing the relative
the variability in the stress patterns across different                   differences of acoustic features between consecutive
languages are related to the perceptual processing. This also             syllables. These differences were then used to determine
                                                                      1246

whether a specific syllable is characterized as stressed or                                          Material
unstressed. They also used supervised HMM training to
                                                                     The CAREGIVER Y2 UK corpus (Altosaar et al., 2010)
learn the associations between the acoustic features and
                                                                     was used in the study. The style of speech in CAREGIVER
human-made stress annotation. Finally, an approach
                                                                     is enacted IDS spoken in continuous UK English,
combining the acoustical features with the linguistic
                                                                     simulating a situation where a caregiver is talking to a child
properties of the utterances was proposed by Lai et al.
                                                                     regarding a number of important objects and events in a
(2006). Their method utilizes three layers of classifiers
                                                                     shared interaction scene, but recorded in high-quality within
where the first two layers assign stress labels to content
                                                                     a noise-free anechoic room. In addition to a set of 50 unique
words and unstressed labels to function words while the
                                                                     keywords, the speech material contains a number of verbs
third classifier performs stress labeling based on the
                                                                     and function words used in the surrounding carrier
acoustic features of the utterance. In all of the above studies,
                                                                     sentences, yielding a total vocabulary of 80 words. The
the stress is detected in terms of presence of specific
                                                                     vocabulary is statistically balanced over the keywords so
acoustic features, their differences between subsequent
                                                                     that the predictive relationships between keywords and
linguistic units, or in terms of linguistic content of the
                                                                     keyword pairs (e.g., an adjective and a noun) are minimized.
signal, and the connection between these cues and presence
                                                                     The talkers were not separately instructed on the use of
of stress is learned in a supervised manner using machine
                                                                     prosody or stress beyond that they were asked to read the
learning algorithms.
                                                                     text prompts, paired with visual stimuli, as they would talk
     In contrast to the supervised approaches, sentence level
                                                                     to their own children (see Altosaar et al., 2010, for details).
stress can also be examined from purely unsupervised point
                                                                        In overall, CAREGIVER UK Y2 contains 2397 sentences
of view. More specifically, we put forward a hypothesis that
                                                                     from each main talker. A subset of 300 unique utterances
the statistical unpredictability of the prosodic features is the
                                                                     were chosen for the listening tests from one male and
main carrier of stress in speech. Therefore no supervised
                                                                     female talker (Speakers 3 and 4), yielding a total of 600
associative learning is required. The idea is inspired by the
                                                                     utterances. All single-word utterances were excluded from
cognitive foundations of attention where the primary role of
                                                                     the data, leading to an average of 5.9 words per sentence.
the attentional system is to select novel or otherwise
                                                                     This set of utterances is referred to as the test set, as it was
significant information from the environment (Broadbent,
                                                                     also used to probe the performance of the studied statistical
1958; Treisman, 1964). In other words, attention can be
                                                                     F0 model (see the Methods section).
seen as a mechanism for allocating active sensory- and
                                                                        As for the training of the statistical model, 2000 sentences
learning resources for input that is not anticipated by our
                                                                     per talker were used (i.e., 4000 in total). None of these
existing predictions regarding the state of the surrounding
                                                                     training set sentences were present in the above test set.
world. It also seems that the the human brain is wired to
react to expectations and their violations in the sensory input          Input      (i)           (ii)         (iii)
(see Itti & Baldi, 2009, and references therein).                        utterance
                                                                                   Pre-processing      Pitch   Normalization
                                                                                                    Estimation
     In the given framework, potential points of stress in
                                                                                                                               (v)
speech can be hypothesized to be the points where the                                                          (iv)
                                                                                                                                    Model
                                                                                                                Quantization
prosodic features deviate from their expected outcomes in                                                                          Training
the given context. These deviations can be actively
controlled by the talker who is relatively free to choose the                                                   Probabilities       Model
suprasegmental acoustic parameters as a function of position
in the utterance while the listener can only rely on the                                                             P(F0 , t)
previously learned a priori expectations for these                                 Figure 1: Overview of the proposed model.
parameters. Importantly, the listener’s expectations can be
learned from exposure to speech without any supervision,                                             Methods
i.e., without access to a ground truth on the degree of stress
in the heard words. Instead, a statistical model of the typical      The study of the statistical learning hypothesis in stress
behavior of the prosodic features is sufficient, and it is now       perception requires: 1) the collection of a reference
widely accepted that human infants and adult are sensitive           annotation representing human perception of stress in the
to regularities in the sensory input (e.g., Romberg &                test set, and 2) a computational model that can learn the
Saffran, 2010, and references therein).                              statistical regularities of the F0 trajectories from the training
     In the current work, we study the statistical learning          data and then evaluate the points of unpredictability on the
hypothesis by modeling the fundamental frequency contours            same data that human listeners were exposed to.
of continuous speech and comparing the model output to
human perception of sentence stress in the same utterances.
                                                                     Stress Annotation
More specifically, we test whether the regions of low-               In order to create a reference annotation of sentence stress
probability in the F0 contours match with the human stress,          against which the model could be tested, an annotation tool
showing that there is substantial correlation between the            with a graphical user interface (GUI) was created for
two.                                                                 MATLAB. The GUI plays each utterance through
                                                                     headphones, displays the list of spoken words in a
                                                                 1247

temporally ordered list on a computer screen, and then                                0.4
                                                                     amplitude
                                                                                      0.2
prompts the user to choose the words that were perceived as                             0
stressed using a computer mouse as the controller. For each                          −0.2
                                                                                     −0.4
utterance, the test subject can select zero or more words as                            0.6        0.8   1   1.2   1.4       1.6    1.8   2    2.2    2.4
stressed. The test subject can also listen to each sentence as                              1
many times as he/she wishes.                                                 N             0.8
                                                                         F0
   The listening tests were performed in a sound-isolated                                  0.6
listening booth using Sennheiser HD650 headphones fed                                      0.4
                                                                                             0.6   0.8   1   1.2   1.4       1.6    1.8   2    2.2    2.4
through Motu Ultralink MK3 audio interface. The listeners                                   0
were able to take a break any time between the utterances.
                                                                             F0 log−prob
                                                                                           −1
   Annotation data for the current study were collected from
a total of thirteen test subjects (7 male, 6 female) from the                              −2
age range of 20-30 years. Nine of the participants were L1                                  0.6    0.8   1   1.2   1.4       1.6    1.8   2    2.2    2.4
                                                                                            0
Finnish speakers, one British English, one Greek, one
                                                                         word prob
Russian and one Spanish. English and Swedish represented                             −20
the majority of the L2 and L3 languages among the                                    −40
listeners. Despite the various L1 and L2 combinations, each                                 0.6    0.8   1   1.2   1.4        1.6   1.8   2    2.2    2.4
                                                                                                                         time (s)
listener was considered as experienced English user. On
                                                                     Figure 2: Example output of the algorithm for the utterance
average, the task took approximately 1.5 hours per listener.
                                                                     “Daddy looks at the dirty car”, with the word “dirty”
                                                                     annotated as stressed by the majority of the annotators. Top
Statistical Model of Prosodic Trajectories
                                                                     panel: The original signal waveform. Second panel: The
The overall aim was to build an unsupervised statistical             normalized F0N contour. Third panel: The corresponding 4-
model of the temporal evolution of the F0 trajectories based         gram log-probabilities (with 3-point median filtering for
on the training set of utterances and then to detect word            improved visual clarity). Bottom panel: Cumulative word
stress in terms of the unpredictability of the F0 during the         log-probabilities across the entire word duration. Vertical
test set. The overall model consists of the following steps:         lines denote word boundaries.
(i) signal pre-processing, (ii) F0 estimation, (iii) F0
normalization, (iv) F0 quantization, and (v) n-gram                  As for the statistical modeling of the temporal evolution of
parameter estimation (during training) or n-gram probability         the discretized F0 values, standard n-grams were chosen for
computation (during testing; see Figure 1).                          the purpose due to their computational simplicity and ease
   In the pre-processing step, the speech data were                  of interpretation. The analysis was limited to n-gram orders
downsampled from 44.1 kHz to 8 kHz. Then the F0                      of n = 2, 3 and 4, where bi-grams (n = 2) correspond to the
estimation and voicing detection was performed for each              shortest temporally ordered segments available while the
utterance using the YAAPT-algorithm (Zahorian & Hu,                  four-grams (n = 4) are the longest recurring sequences for
2008). “Filler” F0 contours for unvoiced segments were               which probabilities can be reliably estimated from the data.
generated by linear interpolation from the surrounding                  The probabilities for the n-grams were computed using
voiced F0 values. This was done in order to ensure temporal          the maximum-likelihood estimator, i.e., using the relative
continuity of the data without introducing any new                   frequencies of the n-tuples occurring in the training set.
information to the signal that could cue stress or absence of
stress in the signals (see Fig. 2, second panel).                                                                    C(F0i , F0i −1 ,, F0i − N +1 ) (2)
   In order to ensure F0 comparability across different              P(F0i | F0i −1 ,, F0i − N +1 ) =
                                                                                                                       C(F0i −1 ,, F0i − N +1 )
utterances and the two talkers, the original absolute
frequency F0 contours were normalized according to
                                                                                      P"(F0, t) = log(P(F0 t | F0 t −1 ,, F0 t − N +1 ))            (3)
                        F0(t) − min(F0)                   €
          F0 N (t) =                                (1)              In the equations, C denotes the frequency counts of the
                       max(F0) − min(F0)                             discrete F0 n-tuples in the training data and F0 refers to the
                                                              €
                                                                     discretized F0 values in the range 1–32.
where min(F0) and max(F0) refer to the minimum and                       During the test phase, steps (i)-(iv) were the same as in
maximum of the F0 during the given utterance, effectively            the training. The probability curve of the F0 as a function of
€
scaling the F0N between 0 and 1 (see Imoto et al., 2002).            time (Figure 2, third panel) was computed for each utterance
  Finally, in order to enable probabilistic modeling of the          using the Eq. (3). Then the logarithm of the probabilities
normalized F0 contours, the F0N were quantized into 32               was taken to avoid numerical instability. Also, in order to
discrete amplitude levels that were estimated using the k-           avoid log(0) for previously unseen F0 contours, zero
means algorithm with a random sampling initialization. The           probability contours were floored to P’ = log(0.00001).
number of levels was selected as a compromise between the                In order to simulate the listening test task of choosing N
best possible approximation of the F0 contours without               stressed words out of the M possibilities in each sentence,
ending up with too sparse statistics for the different levels.       the instantaneous F0 probabilities were converted into word-
                                                                  1248

specific probability scores S(w) by simply summing the log-       words thereby leading to lower overall probabilities (cf., Eq.
probabilities of the F0 trajectory over the duration of each      (4)). Duration baseline therefore also provides indirect
word (Figure 2, bottom).                                          evidence of the role of duration in stress perception, as the
                     t2                                           duration cannot be directly represented as a signal feature in
          S(w) =    ∑ P"(F0, t)                       (4)         the current type of temporal model. Both baselines were
                   t =t1                                          computed across 50 iterations of random sampling.
where t1 and t2 are the known word boundaries in time.
    Finally, the stress hypotheses for words were generated                                  Results
from
 €     the word scores by choosing the words wy that had
their overall score S(wy) below a threshold ri. The ri was        Annotation Analysis
defined dynamically according to
                                                                  The set of 600 test signals were stress annotated by thirteen
              r i = µ i - σ iλ                        (5)         separate annotators. The overall Fleiss kappa across all
                                                                  annotators was κ = 0.4, which translates into mean
i.e., as λ standard deviations σi from the mean µi of the         agreement rate of 85.7% for individual word tokens. On
scores across all words in the same utterance i. Value of the     average, a total of 23.6% (±5.6%) of all words were
free parameter λ was varied in the experiments in order to        considered as stressed. As for the pair-wise agreements
                                                                  between annotators, the average agreement was κ = 0.39
observe the behavior of the model as a function of the
detection threshold. It should be noted that the use of a         with a standard deviation of 0.12, a minimum of κ = 0.12,
global fixed threshold across all utterances was also studied     and a maximum of κ = 0.65. This indicates that there is
and it was found to lead to similar performance with Eq. (5).     notable variation across the annotators, some of the listeners
                                                                  sharing a very similar perception of stress across a large
Evaluation                                                        number of utterances while some others have very different
                                                                  view on what is stressed or not. The average agreement of
In order to measure inter-annotator agreement rate in the
                                                                  0.4 is significantly above chance level and is at the
listening test and in order to compare model output to the
                                                                  boundary of “fair” and “moderate” agreement on the Landis
human annotations, the standard Fleiss kappa (Fleiss, 1971)
                                                                  & Koch (1977) scale. It is also the same agreement rate
measure was used. In essence, the Fleiss kappa measures the
                                                                  observed in two other studies of prominence perception
degree of agreement between two or more annotators on a
                                                                  using American English (Mo, Cole & Lee, 2008; You,
nominal scale κ ∈ [-1,1]. It takes into account the
                                                                  2012). In overall, the results from the listening tests confirm
underlying distribution of the ratings, yielding κ = 0 if the
                                                                  that the sentence-level prominence is not a clear unanimous
number of agreements is equal to what is expected based on        phenomenon, but more like a fuzzy continuum from
chance-level co-occurrences in the data. In the current           unstressed to stressed words. Still, there is a systematic
study, the Fleiss kappa was measured on a word-level, i.e.,       tendency among listeners to perceive specific parts of the
each word occurring in the test set was considered as a           signals as stressed (more detailed analysis of the listening
binary decision between non-stressed and stressed. The            test data is beyond the scope of the current paper).
overall agreement rate across all words in the test set were
used as the primary evaluation measure. As for the listening      Model Simulations
test data, we measured the overall kappa value across all
thirteen annotators and the pair-wise kappas for each             The statistical model of F0 was evaluated for a number of
possible pair of annotators. In order to evaluate the model,      detection thresholds by varying the parameter λ of Eq. (5).
the stress hypotheses of the model were compared in a pair-       The overall results with the model can be seen in Figure 3
wise manner with the markings of all individual annotators        where the result is averaged across the three studied n-gram
and the average across all model-annotator-pairs was              orders (n = 2, 3, 4). All results are pooled across the male
computed.                                                         and female talker of the test set. The best correspondence to
    In order to understand chance-level performance in the        manually annotated stress words is obtained for a threshold
task, two different random baseline results were also             of 1/2 standard deviations below average F0 probability
generated. In the basic baseline, each word was randomly          during the word, leading to mean pair-wise agreement of κ
assigned as either stressed or unstressed with the constraint     = 0.39 with the annotators. For the individual n-gram orders,
that each utterance receives the same number of stress            the agreements are κ = 0.41, 0.40, and 0.38 for the bi-, tri-,
words as hypothesized by the model with a given detection         and four-grams, respectively.
threshold λ. In the so-called duration baseline, the process         As can be observed from Figure 3, the average statistical
was otherwise similar but, instead of sampling from a             model agreement with the behavioral data is basically equal
uniform distribution, the probability of a word being             to the inter-rater agreement level and significantly above
assigned as stressed was linearly proportional to the             both chance-level performances. As expected, the uniformly
duration of the word. The duration baseline represents the        sampled random baseline achieves κ = 0.00. In contrast, the
performance achieved by simply integrating random signal          duration baseline reaches a slight agreement of κ = 0.16.
(random probabilities) across the word lengths with longer
                                                              1249

                   0.5
                   0.4                                                                 0.6
                                                                                       0.5
                   0.3
                                                                                       0.4
                                                                           agreement
                   0.2
      agreement
                                                                                       0.3
                   0.1
                                                                                       0.2
                    0                                                                  0.1
                  −0.1                                                                  0
                                                                                             1   2   3   4   5   6  7    8   9   10 11 12 13
                                                                                                                 annotator
                  −0.2
                     −1   −0.5      0               0.5   1   1.5
                                        threshold
                                                                       Figure 4: Pair-wise agreement rates between the model
                                                                       output and each individual annotator. The result is the mean
Figure 3: Pair-wise Fleiss kappa between the model output              and SD of the three evaluated n-gram orders. Green bars at
and the human listeners as a function of detection threshold           the bottom show the duration-baseline agreement levels.
λ. The blue solid line shows the mean and standard
deviation of model performance across n-grams orders n =               example, infant’s capability for word segmentation has been
2, 3, and 4. The black dashed line shows the basic chance              discussed in the context of statistical learning of transitional
level performance and the red dashed line at the middle                probabilities (TPs) between linguistic units such as phones
shows the chance-level performance when the word                       or syllables (see Romberg & Saffran, 2010, for a review).
durations are taken into account. The red and black                    However, it is known that prosody also helps in word
horizontal dashed lines indicate the overall and mean pair-            segmentation (e.g., Johnson & Jusczyk, 2001), with the
wise kappas across the annotators, respectively.                       statistical learning and prosody perception being treated as
                                                                       two distinct mechanisms. However, the current work
Figure 4 shows the pair-wise agreement of the model output             suggests that a statistical learning mechanism could account
with each annotator together with the corresponding                    for the sensitivity to both types of cues with the only
duration baselines. As can be observed, the notable variation          difference in the acoustic features that are being learned. In
between annotators is also evident in the model output                 the TP-based word segmentation, the focus is on the
comparisons, the model agreeing with annotator 11 with                 statistical structure of linguistically relevant features such as
above κ = 0.6 using tri-grams while agreement with                     formant frequencies or the overall spectrum of speech (see
annotator 8 is only slightly above κ = 0.2.                            Räsänen, 2011, 2012). In contrast, the perception of prosody
  In general, the current results provide strong support to            may be driven by the statistical structure of the
the statistical learning hypothesis as the agreement rate of           suprasegmental features with the degree of predictability in
the algorithm with human listeners is comparable to that of            the prosody modulating the attentional focus of the listener.
any human listener.                                                       However, more work is needed to consolidate the current
                                                                       findings. First of all, the experiment should be extended to
                                 Conclusions                           adult-directed speech in order to see whether the findings
In this work, we formulated a hypothesis that the perception           persist, although the acoustic features of prominence in
of sentence stress in speech is related to the unpredictability        ADS and IDS should be similar but simply of different
of the acoustic correlates of prosody. This is in contrast to          magnitude (e.g., Song, Demuth & Morgan, 2010). Also, it is
the classical approach where stress is defined in relation to          currently unknown how much exposure is needed to form
specific configurations of acoustic feature values and                 the expectations for the prosodic trajectories (e.g., short-
assuming that the listener knows this relationship in                  term vs. long-term memory), and whether these expectations
advance. The unpredictability hypothesis was tested by                 generalize across talkers and across communicative
modeling the temporal evolution of fundamental frequency               contexts. In addition, we have so far considered only one of
with a simple unsupervised statistical model. The model                the acoustic correlates of prosodic features, namely F0.
marks words as prominent if the F0 trajectory during them              Other features such as loudness (energy), spectral tilt, or the
is unlikely given the earlier learned expectations. As a               full wide-band spectrum of the signal should be investigated
result, the model shows high agreement with human                      using the same approach. These studies are beyond the
perception on the same task and thereby provides the first             scope of the current paper but will be addressed in the future
evidence to the idea that stress perception can be learned             work.
from statistical regularities of speech.
   The idea of learning supra-segmental linguistic cues from                                         Acknowledgements
statistical regularities has interesting parallels to the ongoing      This research was funded by the Data to Intelligence (D2I)
research      in     early     language      acquisition.     For      project of Tekes and by the Academy of Finland.
                                                                    1250

                        References                              Landis, J. R., & Koch, G. G. (1977). The measurement of
                                                                  observer agreement of categorical data. Biometrics, 33,
Altosaar, T., ten Bosch, L., Aimetti, G., Koniaris, C.,
                                                                  159–174.
   Demuynck, K., & van den Heuvel, H. (2010). A Speech
                                                                Minematsu, N., Kobashikawa, S., Hirose, K., & Erickson,
   Corpus     for    Modeling      Language     Acquisition:
                                                                  D. (2002). Acoustic Modeling of Sentence Stress Using
   CAREGIVER. Proceedings of the International
                                                                  Differential Features Between Syllables for English
   Conference on Language Resources and Evaluation
                                                                  Rhythm Learning System Development. Seventh
   (LREC), Malta, pp. 1062–1068.
                                                                  International Conference on Spoken Language
Broadbent, D. E. (1958). Perception and Communication.
                                                                  Processing (ICSLP’2002), pp. 745–748.
   New York: Pergamon.
                                                                Mo, Y., Cole, J., & Lee, E-K. (2008). Naïve listeners’
Chaolei, L., Jia, L., & Shanhong, X. (2007). English
                                                                  prominence and boundary perception. Proc. 4th Speech
   Sentence Stress Detection System Based on HMM
                                                                  Prosody, Campinas, Brazil, pp. 735–738.
   framework. Applied Mathematics and Computation, 185,
                                                                Peters, A. M. (1983). The Units of Language Acquisition.
   759–768.
                                                                  Cambridge: Cambridge University Press.
Cutler, A., & Foss, D. J., (1977). On the Role of Sentence
                                                                Remick, H., (1976). Maternal speech to children during
   Stress in Sentence Processing. Language and Speech, 20,
                                                                  language acquisition. In W. von Raffler-Engel & Y.
   1–10.
                                                                  Lebrun (Eds.), Baby talk and infant speech (pp. 223–233).
Cutler, A., Dahan, D., & van Donselaar, W. (1997). Prosody
                                                                  Amsterdam: Swets & Zeitlinger.
   in the comprehension of spoken language: A literature
                                                                Ringeval, F., Demouy, J., Szaszák, G., Chetouani, M.,
   review. Language and Speech, 40, 141–201.
                                                                  Robel, L., Xavier, J., Cohen, D., & Plaza, M. (2011).
Endress, A. D., & Hauser, M. D. (2010). Word
                                                                  Automatic Intonation Recognition for the Prosodic
   Segmentation with Universal Prosodic Cues. Cognitive
                                                                  Assessment of Language-Impaired Children. IEEE
   Psychology, 61, 177–199.
                                                                  Transactions on Audio, Speech, and Language
Ferguson, C. A. (1964). Baby talk in six languages.
                                                                  Processing, 19, 1328–1342.
   American Anthropologist, 66, 103–114.
                                                                Romberg, A. R., & Saffran, J. R. (2010). Statistical learning
Fernald, A., & Mazzie, C. (1991). Prosody and Focus in
                                                                  and language acquisition. Wiley Interdisciplinary Review
   Speech to Infants and Adults. Developmental Psychology,
                                                                  of Cognitive Science, 1, 906–914.
   27, 209–221.
                                                                Rosenberg, A., & Hirschberg J. (2009). Detecting Pitch
Fleiss, J. L. (1971). Measuring norminal scale agreement
                                                                  Accents at the Word, Syllable and Vowel Level. Human
   among many raters. Psychological Bulletin, 76, 378–382.
                                                                  Language Technology Conference of the North American
Grieser, D. L., & Kuhl, P. K., (1988). Maternal Speech to
                                                                  Chapter of the ACL, Boulder, Colorado, pp. 81–84.
   Infants in a Tonal Language: Support for Unviersal
                                                                Räsänen, O. (2011). A computational model of word
   Prosodic Features in Motherese. Developmental
                                                                  segmentation from continuous speech using transitional
   Psychology, 24, 14–20.
                                                                  probabilities of atomic acoustic events. Cognition, 120,
Imoto, K., Dantsuji, M., & Kawahara, T. (2000). Modelling
                                                                  149–176.
   of the Perception of English Sentence Stress for
                                                                Räsänen, O. (2012). Computational modeling of phonetic
   Computer-Assisted Language Learning. Proceedings of
                                                                  and lexical learning in early language acquisition: existing
   Interspeech, Beijing, China, pp. 175–178.
                                                                  models and future directions. Speech Communication, 54,
Imoto, K., Tsubota, Y., Raux, A., Kawahara, T., and
                                                                  975–997.
   Dantsuji, M. (2002). Modeling and Automatic Detection
                                                                Song, J.Y., Demuth, K., & Morgan, J. (2010). Effects of the
   of English Sentence Stress for Computer-Assisted English
                                                                  acoustic properties of infant-directed speech on infant
   Prosody Learning System. Seventh International
                                                                  word recognition. Journal of the Acoustical Society of
   Conference on Spoken Language Processing, pp. 749–
                                                                  America, 128, 389–400.
   752.
                                                                Thiessen E. D., Hill, E. A., & Saffran, J. R. (2005). Infant-
Itti, L., & Baldi, P. (2009). Bayesian Surprise Attracts
                                                                  Directed Speech Facilitates Word Segmentation. Infancy,
   Human Attention. Vision Research, 49, 1295–1306.
                                                                  7, 53–71.
Johnson, E. K., & Jusczyk, P. W. (2001). Word
                                                                Treisman, A. M. (1964). The effect of irrelevant material on
   segmentation by 8-month-olds: When speech cues count
                                                                  the efficiency of selective listening. The American
   more than statistics. Journal of Memory and Language,
                                                                  Journal of Psychology, 77, 533–546.
   44, 548–567.
                                                                Zahorian, S. A., & Hu, H. (2008). A spectral/temporal
Jusczyk, P. W., Cutler, A., & Redanz, N. (1993). Infants’
                                                                  method for robust fundamental frequency tracking.
   Preference for the Predominant Stress Patterns of English
                                                                  Journal of the Acoustical Society of America, 123, 4559–
   Words. Child Development, 64, 675–687.
                                                                  4571.
Lai, M., Chen, Y., Chu, M., Zhao, Y., & Hu, F. (2006). A
                                                                You, H-J. (2012). Determining prominence and prosodic
   Hierarchical Approach to Automatic Stress Detection in
                                                                  boundaries in Korean by non-expert rapid prosody
   English Sentences. International Conference on
                                                                  transcription. Proc. 6th Speech Prosody, Shanghai, China.
   Acoustics, Speech and Signal Processing (ICASSP’2006),
   Toulouse, France, pp. 753–756.
                                                            1251

