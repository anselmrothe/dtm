UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How perceived distractor distance influences reference production: Effects of perceptual
grouping in 2D and 3D scenes
Permalink
https://escholarship.org/uc/item/2cs9r4bs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Koolen, Ruud
Houben, Eugene
Huntjens, Jan
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

               How perceived distractor distance influences reference production:
                             Effects of perceptual grouping in 2D and 3D scenes
                                       Ruud Koolen (r.m.f.koolen@tilburguniversity.edu)
                                              Eugène Houben (eugene@eyetractive.nl)
                                                  Jan Huntjens (jan@eyetractive.nl)
                                     Emiel Krahmer (e.j.krahmer@tilburguniversity.edu)
                  Tilburg Center for Cognition and Communication (TiCC), Tilburg University, The Netherlands
                              Abstract                                  reflect human referential behavior, but is also at the heart of
   This study explored two factors that might have an impact on
                                                                        computational models for Referring Expression Generation.
   how participants perceive distance between objects in a visual       Such models, most notably the Incremental Algorithm (Dale
   scene: perceptual grouping and presentation mode (2D versus          & Reiter, 1995), typically seek attributes with which a target
   3D). More specifically, we examined how these factors affect         object can be distinguished from its surrounding distractors,
   language production, asking if they cause speakers to include        aiming to collect a set of attributes with which any distractor
   a redundant color attribute in their descriptions of objects. We     that is present in the scene is ruled out (Van Deemter, Gatt,
   expected speakers to use more redundant color attributes             Van Gompel, & Krahmer, 2012).
   when distractor objects are perceptually close. Our findings
   revealed effects of perceptual grouping, with speakers indeed           So what would a description of the target object in Figure
   using color more often when all objects in a scene were in the       1 look like? The target’s type is probably mentioned because
   same perceptual group as compared to when this was not the           it is necessary for a proper noun phrase (Levelt, 1989). Also
   case. An effect of presentation mode (whether scenes were            size is likely to be included, to rule out the large bowl. What
   presented in 2D or in 3D) was only partially borne out by the        else? The speaker may also add color, following the general
   data. Implications of our results for computational models of        preference to mention this attribute (e.g., Pechmann, 1989),
   reference production are discussed.
                                                                        or because the speaker is triggered by the different colors of
   Keywords: Reference production; overspecification; 2D and            the objects present in the visual scene (Koolen, Goudbeek &
   3D scene processing; perceptual grouping; artificial agents.         Krahmer, 2013a). In any case, adding color would cause the
                                                                        description to be overspecified, since it is not necessary for
                          Introduction                                  unique identification: mentioning type and size (“the small
                                                                        bowl”) rules out all possible distractors.
Definite object descriptions (such as “the red chair”) are an
                                                                           If color variation can trigger a speaker to use a redundant
important part of everyday communication, where speakers
                                                                        color attribute, this implies that the distractors in a particular
often produce them to identify objects in the physical world
                                                                        scene largely determine the process of content selection. For
around them. To serve this identification goal, descriptions
                                                                        the case of Figure 1, it might well be that the speaker would
have to be unambiguous, and must contain a set of attributes
                                                                        only add color if she were to regard all objects in the scene
that jointly exclude the distractor objects with which the
                                                                        as relevant distractors (uttering “the small green bowl” as a
listener might confuse the target object that is being referred
                                                                        final description). However, there are reasons to believe that
to. For example, imagine that a speaker wants to describe
                                                                        speakers tend to ignore certain distractors (Koolen, Krahmer
the object that is pointed at with an arrow in Figure 1.
                                                                        & Swerts, 2013b), and only consider the objects that are into
                                                                        their focus of attention (Beun & Cremers, 1998). This may
                                                                        cause the speaker to leave out color in her description of the
                                                                        target in Figure 1: if she were to restrict her focus space to,
                                                                        say, the two bowls (thereby ignoring the yellow plate), she
                                                                        would probably be less prone to redundantly use color in her
                                                                        description.
                                                                           What determines whether the yellow plate (or any object
                                                                        in general) is in the speaker’s focus of attention? Intuitively,
                                                                        physical distance plays a role here: the distant distractor (the
                                                                        plate) might well be ignored, while the closest one (the large
               Figure 1: An example visual scene.                       bowl) might actually be considered a relevant distractor. In
                                                                        recent empirical research, some evidence has been found for
   Solving the referential task here requires content selection:        this suggestion (e.g., Clarke, Elsner & Rohde, 2013), though
the speaker must decide on the attributes that she includes in          other papers suggest a more nuanced picture (e.g., Koolen et
order to distinguish the bowl from any distractor object that           al., 2013b).
is present in the scene (such as the other bowl, the plate and             In the current paper, we explore two possible factors that
the chairs). This notion of content selection does not only             may influence perceived distractor distance (i.e., perceptual
                                                                    2507

grouping, and 2D vs. 3D presentation mode), and examine               size, occlusion, and perspective) to perceive distance and
how they influence language production.                               depth. Previous work on visual perception has shown that
                                                                      people usually have no difficulty in understanding the three-
Perceptual grouping                                                   dimensional nature of 2D images (Saxena, Sun, & Ng,
The first factor we expect to affect how speakers perceive            2008). However, at least for children, it has also been shown
distance between objects in a scene is perceptual grouping.           that binocular depth and perception is more accurate than
This phenomenon is part of the Gestalt laws of perception             monocular depth perception (Granrud, Yonas, & Petterson,
(originally introduced by Wertheimer in 1923), and can be             1984), and that 3D scenes are rated higher on naturalness
defined as people’s ability to organize the visual world they         than 2D scenes (Seuntiëns et al., 2005).
perceive in meaningful groups (Palmer, 1992). Among other               The above literature suggests that people are better able to
things, people use this ability to create groups of objects, for      accurately perceive distance between objects in 3D than in
example when using an expression such as “the silverware              2D visual scenes. Therefore, we hypothesize that the mode
on the counter”. Thórisson (1994) explains that all kinds of          of presentation may also affect speakers in determining the
factors can cause people to perceive objects as groups. The           set of relevant distractors for a given scene. For example, in
most important factors are proximity (where objects that are          Figure 1, the plate might be considered a relevant distractor
close together share a group) and similarity (where objects           in 2D, but not in 3D, since speakers might perceive the
that are similar in shape, color, orientation or function are         distance between the target bowl and the plate as bigger in
perceived as a group). Palmer (1992) mentions the principle           the latter case.
of common region, which holds that objects that are located
together in a common region of space are usually perceived            The current study
as a group (e.g., if they lie within an enclosing contour, such       We performed a reference production experiment, where we
as a table surface).                                                  presented participants with scenes like the one displayed in
  The question is to what extent perceptual grouping guides           Figure 1, and asked them to produce a unique description of
speakers in restricting the set of relevant distractor objects in     a target referent. Crucially, the scenes were set up in such a
a given scene. Our study provides systematic manipulations            way that color was never needed to identify the target. This
of grouping to test this. We hypothesize that objects that are        allowed us to take the proportional use of redundant color
in the same perceptual group as the target are more likely to         attributes as our dependent variable (following recent work
be in the speakers’ focus of attention (in the sense of Beun          by Koolen et al. (2013b)).
and Cremers, 1998), and are therefore considered a relevant              We used two presentation modes to present the stimuli to
distractor. Along similar lines, we expect the opposite to be         the participants (2D and 3D), and applied a manipulation of
true for objects that are in a different group as compared to         perceptual grouping by systematically placing one distractor
the target. Following these expectations, speakers would not          (that always had a different color as compared to the target)
consider the yellow plate a relevant distractor in Figure 1,          either in the same region as the target, or in a different one.
since it is part of a different region of space (the sideboard)       Third, we replicated a factor that has already been shown to
than the target (which is placed on the table). Thus, in cases        determine speakers’ composition of the distractor set, which
such as these, it is less likely that speakers redundantly use        is related to distractor type (Koolen et al., submitted).
color than when both the target and the distractor are in the            We expect, as explained above, that speakers use color
same perceptual group.                                                more often in the same group condition than in the different
                                                                      group condition. Secondly, we expect speakers to use color
Presentation mode: 2D vs. 3D scenes                                   more often in 2D than in 3D scenes, because speakers may
The second factor we expect to affect people’s perception of          rely on a bigger distractor set in the former case (due to their
distractor distance relates to how visual scenes are presented        poorer estimations of distance).
to them. In perceiving depth information, people mainly rely
on binocular depth cues that can only be perceived with two                                    Experiment
eyes (Loomis, 2001). For the perception of distance between
objects, stereopsis is an important binocular cue. Stereopsis         Method
holds that people view the world from two different angles            Participants Forty-eight undergraduate students (33 female,
(one for each eye), which delivers them with two images of            mean age: 21.6 years) from Tilburg University took part in
a situation. The difference between these two images allows           the experiment for course credit. All were native speakers of
the viewer to perceive distance between objects: if an object         Dutch, the language of the experiment.
is far away, this difference is relatively small, but it is bigger
for close objects. Also artificial 3D presentation techniques         Materials The stimulus materials were near-photorealistic
use two images, thus relying on stereopsis as well.                   visual scenes, modeled and rendered in Maxon’s Cinema 4D
  As far as we are aware, most (if not all) previous work on          (a 3D modeling software package1). There were 98 trials in
reference production used flat 2D images (i.e., drawings or           total, all following the same basic set-up: participants saw a
realistic photographs) as stimulus material. For such images,
viewers depend solely on monocular cues (such as relative             1
                                                                        See http://www.maxon.net/ for downloads and more information.
                                                                  2508

     Figure 2: Examples of critical trials (in 2D). The left scenes are trials in the same group condition, while the right scenes
 are trials in the different group condition. The upper scenes are trials in the different type condition, while the lower ones are
        trials in the same type condition. Note that the trials were presented to the participants on a big television screen.
picture of a living room that contained a dinner table and a          Crucially, the physical distance between the target and the
sideboard (plus some clutter objects to make the scenes look          second distractor was the same in the two conditions.
realistic). The table and the sideboard formed two surfaces              The second manipulation was related to the type of the
on which objects were positioned: one target object and two           second distractor in the scene: this could either be different
distractor objects were present in every scene. The target            or the same as the target’s type. For example, in Figure 2,
object always occurred at the left side of the table (from the        the second distractor (the plate) has a different type than the
participants’ point of view), and had one distractor placed           target (the bowl) in the upper two trials, while all relevant
next to it (either left or right). This distractor had the same       objects are of the same type in the lower trials. Note also
type and color as the target (meaning that it could only be           that mentioning a target’s type and size was sufficient to
ruled out by means of its size). Each scene also contained a          distinguish the target in all four scenes, implying that the
second distractor – always in a different color as compared           use of color would always result in overspecification. This
to the target – by means of which two principal factors in            applied to all scenes used in the experiment.
the design were manipulated (related to perceptual grouping              The experiment consisted of ninety-eight trials, sixteen of
and type). We explain these in more detail below, as well as          which were critical trials. As said, with regard to the critical
a third factor (manipulating presentation mode).                      trials, all scenes had the same basic set-up, but four different
   Firstly, there was a manipulation of perceptual grouping.          sets of objects were used as target and distractor objects. In
This factor was manipulated as follows: in half of the trials,        Figure 2, trials for one of these sets are depicted (with bowls
the second distractor and the target object were in the same          and a plate). With regard to the other sets, we made sure that
group (meaning that they were both positioned on the table),          they all consisted of food-related objects (such as mugs and
while they were in a different group in the other half of the         cutting boards) that can reasonably be found on a sideboard
trials (with the target placed on the table, and the distractor       or a dinner table in a living room. The scenes for these sets
on the sideboard). Example scenes for these two conditions            of objects were manipulated in a 2 (perceptual grouping) x
can be found in Figure 2. The left scenes represent the same          2 (type) design, which resulted in four within conditions as
group condition: in these scenes, all objects are on the table.       described above: one scene in which the second distractor
The right scenes represent the different group condition: the         object shared a group with the target, but not its type; one in
target object (the small bowl) is again on the table, while the       which the distractor shared its group and its type with the
second distractor (i.e., the plate in the upper picture, and the      target object; one in which the distractor neither shared a
yellow bowl in the lower picture) is placed on the sideboard.         group, nor its type with the target; and one in which the
                                                                 2509

distractor did not share its group with the target, but did          were presented as still images at 120 Hz, resulting in 60 Hz
share its type. The similar first distractor was added to make       per eye. In both conditions, participants were shown a short
sure that mentioning type and color was never sufficient to          introduction movie (a fragment from the ‘Shreck’ or ‘Ice
distinguish the target.                                              Age’ movies), so that they could get accustomed to the TV
   Besides the factors perceptual grouping and type, which           and the glasses.
were both manipulated within participants, we also included             There were two versions of the experiment in terms of
one between factor, related to presentation mode (2D / 3D).          trial order: we made one block of trials in a fixed random
Participants were randomly assigned to either the 2D or the          order (which was presented to half of the participants), and a
3D condition. In the 2D condition, the trials were presented         second block containing the same trials but in reverse order
to the participants as flat 2D images (i.e. regular photos). As      (which was presented to the other half of the participants).
we have explained in the introduction section of this paper,         The trials were set as slides, and presented using Keynote.
for 2D images, a viewer depends solely on monocular cues             No transitions or black screens were used; when a trial was
to perceive depth information (and distance between objects          completed, the transition to the next trial was instant. The
in particular). In the 3D condition, the trials were presented       participants could take as much time as needed to provide a
as 3D images, where speakers could rely on both monocular            description for every target object, and their descriptions
and binocular depth cues to perceive depth information. The          were recorded with a voice recorder. The listener – who was
visual scenes in the 2D condition were rendered in the same          a confederate of the experimenter – sat behind a laptop (out
way as those in the 3D condition, but the image for the left         of the speaker’s sight), and clicked objects he thought the
eye was 100% identical to that for the right eye, eliminating        speaker was referring to. Each time the listener had done
depth differences. This means that the 2D and 3D scenes did          this, the next trial appeared. The speaker’s instructions told
neither differ in terms of the objects that were visible, nor in     that the listener did not see the stimuli in the same way as
the positioning of these objects in the scenes. Moreover, the        the participants, and that the positioning of the objects was
stimuli as a whole had the same size in the two conditions.          different. This eliminated the use of location information as
   The experiment had eighty-two fillers, all following the          an identifying target attribute, avoiding descriptions such as
setup of the critical trials, with all kinds of objects placed on    “The bowl at the right side of the table”. The listener never
a table and a sideboard. Again, one of the objects served as         asked clarification questions, to make sure that the speakers
the target and was described by the participants, with the           produced initial target descriptions.
crucial difference that the objects in the filler scenes did not
differ in terms of their color. In this way, the speakers were       Design and statistical analysis The experiment had a 2 x 2
discouraged from using color when describing the fillers.            x 2 design with two within participants factors2: perceptual
                                                                     grouping (levels: same, different) and distractor type
Procedure The experiment took place in an office room at             (levels: same, different), and one between participants
Tilburg University, and participants took part one at a time.        factor: presentation mode (levels: 2D, 3D). The dependent
The running time for one experiment was approximately 15             variable was the proportional use of redundant color
minutes. After participants had entered the room, they were          attributes. As described above, we ensured that participants
randomly assigned to the 2D or 3D condition (there were 24           never needed color to distinguish the target referent from its
speakers in both conditions). Thereafter, they were asked to         distractors: mentioning a target’s size ruled out the first
sit down and read an instruction manual. It was explained to         relevant distractor, while adding the target’s type eliminated
the participants that they would be presented with scenes in         the second relevant distractor. Thus, if speakers used color
which one of the objects was marked with an arrow. This              anyway, this inevitably resulted in overspecification.
target had to be described in such a way that a listener could          Our statistical procedure consisted of Repeated Measures
distinguish it from the other objects that were present in the       ANOVAs: one on the participant means (F1) and one on the
scene. Once participants were done reading the instructions,         item means (F2). To generalize over participants and items
they were given the opportunity to ask questions.                    simultaneously, we also calculated MinF’; we only regarded
  The participants (all acting as speakers in the experiment)        effects as reliable if F1, F2, and MinF’ were all significant.
were seated in front of a large 3D television, while wearing         To compensate for departures from normality, we applied a
3D glasses. This was done regardless of the condition they           standard arcsin transformation to the proportions before we
were assigned to, to eliminate differences in the procedure.         ran the ANOVAs. For the sake of readability, we report the
In the 2D condition, the television displayed flat 2D images         untransformed proportions in the results section.
of the stimuli. In the 3D condition, the TV used ‘active’ 3D
technology to display the trials: it synchronized with the 3D        2
glasses by means of infrared signals, and used electronic              Besides the factors mentioned here, the design also contained a
                                                                     replication of one of the factors reported in Koolen, Krahmer, and
shutters to separate images through the participant’s right
                                                                     Swerts (2013b), related to physical distractor distance. For this
and left eye. The three-dimensional input was configured as          factor, there were trials that either had a close or a distant second
side-by side: both eyes would view an image with a source            distractor object (which were in both cases positioned on the table
resolution of 960 by 1080 pixels, presented on an LCD                surface). In line with Koolen et al., there were no differences in the
panel with a resolution of 1920 by 1080 pixels. The scenes           proportional use of color for these two conditions. Due to lack of
                                                                     space, we do not report on these results in the paper.
                                                                 2510

Results
A total of 768 descriptions were produced in the experiment
for the critical trials. These were all fully distinguishing, and
speakers mentioned a redundant color attribute in 66,0% of
the cases. The order in which the trials were presented to the
participants (regular vs. reversed) had no effect on the use of
color, and is therefore not further analyzed below.
Results for presentation mode We first examined whether
the way in which the trials were presented to the participants
(i.e., in 2D or in 3D) had an effect on the redundant use of
color. The results show that the presentation mode to some
extent affected the use of the redundant attribute color, but               Figure 3: The proportional use of color (plus standard
this effect was only significant by items (F1(1,46) = 2.73, p =           deviations) for the 2D and 3D conditions as a function of
.11, ŋp2 = .06; F2(1,12) = 39.71, p < .001, ŋp2 = .77; minF’(1,52)                the same group and different group stimuli.
= 2.55, p = .11). This means that the speakers in the 2D
condition (M = .75, SE = .07) included color more often                                          Discussion
than speakers in the 3D condition (M = .57, SE = .07), but             In the current paper, we studied how the perceived distance
that we did not find a reliable effect for presentation mode.          between objects in a scene affects speakers’ production of
                                                                       definite object descriptions, and, in particular, to what extent
Results for perceptual grouping The second factor that we              it causes them to include redundant color attributes in such
expected to have an effect on the redundant use of color was           descriptions. Firstly, we replicated the effect of distractor
perceptual grouping. The results indeed showed an effect of            type, reported earlier by Koolen et al. (submitted): we found
grouping on the redundant use of color (F1(1,46) = 7.81, p =           speakers to use color more often when a target object and a
.008, ŋp2 = .15; F2(1,12) = 9.02, p = .01, ŋp2 = .43; minF’(1,41)      differently colored distractor were of the same type (e.g.,
= 4.18, p < .05). More specifically, as predicted, we found            two bowls) as compared to when they had different types.
higher proportions of color use in the same group condition            These findings suggest that an object is more likely to be
(M = .69, SE = .05) than in the different group condition (M           considered a relevant distractor if it shares its type with the
= .62, SE = .05). Overall, this means that our speakers were           target (as compared to when this is not the case).
more likely to include color in scenes where all objects were             Our findings did not reveal reliable effects of presentation
positioned on the table, as compared to the scenes in which            mode (2D vs. 3D) on redundant color use. We hypothesized
the second distractor was placed on another surface (i.e., the         that it is more difficult for people to accurately perceive the
sideboard).                                                            distance between a target object and a given distractor in 2D
   Further inspection of the data suggests that this effect of         scenes rather than in a 3D version of the same scenes, since
perceptual grouping was stronger for 3D stimuli rather than            in a 3D presentation mode, speakers can use both monocular
2D stimuli. As visualized in Figure 3, in the case of the 2D           and binocular cues for depth perception (Loomis, 2001). We
stimuli, there was hardly a numerical difference between the           indeed found a numerical difference (in terms of redundant
same group condition (M = .76, SE = .08) and the different             color use) between the conditions in the expected direction,
group condition (M = .74, SE = .07), while this difference             but this difference only reached significance by items. One
was bigger for the 3D stimuli (same group condition: M =               explanation for this could be related to the way in which we
.63, SE = .08; different group condition: M = .52, SE = .07).          manipulated distance between objects in the scenes: this was
However, this interaction between perceptual grouping and              done horizontally, on the X-axis. It may be that the effect of
presentation mode only reached significance by participants            presentation mode is stronger when distance is manipulated
(F1(1,46) = 4.61, p = .04, ŋp2 = .09; F2(1,12) = 2.97, p = .11, ŋp2    along the depth (Z) axis, or along the X-axis and the Z-axis
= .20; minF’(1,29) = 1.80, p = .19). Therefore, this interaction       at the same time. Arguably, in the latter cases, the difference
was not statistically reliable.                                        between actual and perceived distance may be interpreted as
                                                                       bigger in 3D than in 2D. In future research, we plan to study
Results for distractor type Thirdly, we aimed to replicate             if this is indeed the case.
the effect of type (reported on by Koolen et al. (submitted))             With regard to our manipulation of perceptual grouping,
expecting the type of the second distractor to have an effect          we were able to confirm our expectations. We hypothesized
on redundant color use. Distractor type indeed had an effect           that objects that are in the same region of space as the target
on the redundant use of color (F1(1,46) = 6.88, p = .01, ŋp2 =         are more likely to be considered as a relevant distractor than
.13; F2(1,12) = 9.09, p = .01, ŋp2 = .43; minF’(1,44) = 3.91, p =      objects in a different region of space (in the sense of Palmer,
.05). This means that speakers more often used color when              1992). To test this, we systematically placed one distractor
the distractor’s type was the same as the target’s type (M =           (the one with the different color) either in the same region as
.69, SE = .05) as compared to when its type was different              the target, or in a different one (keeping the actual distance
(M = .63, SE = .06).                                                   between the objects the same). Participants used color more
                                                                   2511

often in the same group condition than in the different group         Casasanto, D. (2008). Similarity and proximity: when does
condition, which suggests that the differently colored object           close in space mean close in mind? Memory & Cognition,
was more likely to be in a speakers’ focus of attention (Beun           36 (6), 1047-1056.
& Cremers, 1998) in the former case. Along the lines of               Clarke, A., Elsner, M., & Rohde, H. (2013). Where’s Wally:
Palmer (1992), our findings imply that speakers indeed tend             the influence of visual salience on referring expression
to perceive objects around them in groups, and that this                generation. Frontiers in Psychology, 4, article 329.
tendency guides them in determining the distractor set when           Dale, R., & Reiter, E. (1995). Computational interpretations
describing objects in a scene. In future research, we plan to           of the Gricean maxims in the generation of referring
validate this suggestion by collecting eye-tracking data, and           expressions. Cognitive Science, 18, 233-263.
to extend the results reported on here with manipulations of          Granrud, C., Yonas, A., & Pettersen, L. (1984). A
grouping other than region of space, such as proximity and              comparison of monocular and binocular depth perception
similarity (see also Casasanto, 2008). Furthermore, also the            in 5- and 7-year-old infants. Journal of Experimental
interaction between grouping and presentation mode would                Child Psychology, 38 (1), 19-32.
be worth exploring in future research: although it seemed to          Koolen, R., Goudbeek, M., & Krahmer, E. (2013a). The
be the case that the effect of grouping was practically absent          effect of scene variation on the redundant use of color.
in 2D and strong in 3D, this interaction was only significant           Cognitive Science, 37 (2), 395-411.
in F1, but not in F2 and MinF’ (and therefore not reliable).          Koolen, R., Krahmer, E., & Swerts, M. (2013b). The impact
   The finding that people rely on perceptual grouping when             of bottom-up and top-down saliency cues on reference
determining the set of distractors for a scene has interesting          production. In Proceedings of the 35th annual meeting of
implications for current computational models in the field of           the Cognitive Science Society (CogSci), 817-822. Berlin,
Referring Expression Generation (REG), most notably Dale                Germany.
and Reiter’s (1995) Incremental Algorithm (IA). As noted in           Koolen, R., Krahmer, E., & Swerts, M. (submitted). How
the introduction, such models are artificial agents that aim to         distractor objects trigger referential overspecification:
generate distinguishing descriptions of objects, and compute            testing the effects of visual clutter and distance.
a set of attributes that rules out all distractors in a given         Krahmer, E., & Theune, M. (2002). Efficient context-
scene. However, for their IA, Dale and Reiter (1995, p. 236)            sensitive generation of referring expressions. In: K. van
define the distractor set as “the set of entities that the hearer       Deemter, & R. Kibble (Eds.). Information sharing:
is currently assumed to be attending to”. This means that the           givenness and newness in language processing (pp. 223-
IA normally includes any object that is present in a scene in           264). CSLI Publications, Stanford.
the distractor set, following many other algorithms in the            Levelt, W. (1989). Speaking: from intention to articulation.
field. However, while Krahmer and Theune (2002) show                    MIT Press, Cambridge/London.
that the distractor set that REG algorithms use may change            Loomis, J. (2001). Looking down is looking up. Nature, 414
during a discourse, our findings for perceptual grouping                (6860), 155-156.
suggest that the region in which objects occur should be              Palmer, S. (1992). Common region: a new principle of
taken into account as well: objects that do not share their             perceptual grouping. Cognitive Psychology, 24 (3), 436-
region with the target should not always be considered.                 447.
                                                                      Pechmann, T. (1989). Incremental speech production and
                         Conclusion                                     referential overspecification. Linguistics, 27, 89-110.
This paper explored the impact of perceptual grouping and             Saxena, A., Sun, M., & Ng, A. (2008). Make3D: depth
presentation mode (2D versus 3D) on how people perceive                 perception from a single still image. In Proceedings of the
distance between objects in a visual scene when referring to            23rd AAAI conference on artificial intelligence, 1571-
objects. The results showed an effect of perceptual grouping            1576. Chicago, Illinois, USA.
on the redundant use of color, implying that objects that are         Seuntiëns, P., Heynderickx, I., IJsselstein, W., Avoort, P.,
in the same region of space as the target are more likely to            Berentsen, J., Dalm, I., …, Oosting, W. (2005). Viewing
be considered a relevant distractor than objects that are in a          experience and naturalness of 3D images. In Optics East,
different region. Our manipulation of presentation mode did             Boston, Massachusetts, USA.
not reveal reliable effects on redundant color use.                   Thórisson, K. (1994). Simulated perceptual grouping: an
                                                                        application to human-computer interaction. Proceedings
                                                                        of the 16th annual conference of the Cognitive Science
                    Acknowledgments                                     Society (CogSci), 876-881. Atlanta, Georgia, USA.
We thank Fons Maes, Hans Westerbeek, Martijn Goudbeek,                Van Deemter, K., Gatt, A., Van Gompel, R., & Krahmer, E.
and Jorrig Vogels for their comments on an earlier draft.               (2012). Toward a computational psycholinguistics of
                                                                        reference production. Topics in Cognitive Science, 4 (2),
                         References                                     166-183.
Beun, R.J., & Cremers, A. (1998). Object reference in a               Wertheimer, M. (1923). Untersuchungen zur Lehre von der
   shared domain of conversations. Pragmatics & Cognition,              Gestalt. Psychologische Forschung, 4, 301-350.
   6 (1/2), 121-152.
                                                                  2512

