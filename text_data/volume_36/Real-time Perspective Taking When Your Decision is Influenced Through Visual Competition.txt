UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Real-time Perspective Taking: When Your Decision is Influenced Through Visual Competition

Permalink
https://escholarship.org/uc/item/8w10f0k6

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Greenwood, Michelle
Spivey, Michael

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Real-time Perspective Taking: When Your Decision is Influenced Through Visual
Competition
Michelle D. Greenwood (mgreenwood@ucmerced.edu)

Cognitive and Information Sciences, 5200 North Lake Road
Merced, CA 95348 USA
Michael J. Spivey (spivey@ucmerced.edu)

Cognitive and Information Sciences, 5200 North Lake Road
Merced, CA 95348 USA
Abstract
People often tacitly assume an egocentric perspective when
describing spatial scenes, and then use ambiguous
descriptions (e.g., “The bottle is on the left.”). However,
they can also take an alternative perspective, for instance
referencing an agent that is present in the scene to reduce
ambiguity (e.g., “The bottle is on your right.”). In this
experiment, participants viewed a computer screen that
contained a photograph of a basket on a table. Participants
were given ambiguous spatial relationship directions for
placing the objects (trials) in the scene (e.g., “Place the X to
the right of the basket.”). The goal was to determine, through
mousetracking, how often people choose an other-centric
perspective, and if they chose an egocentric perspective did
they consider other viewpoints. Results showed that the
visual input (conditions) influenced the initiation times and
maximum deviation of an egocentric response when a person
was present in the scene compared to when a person was
absent.
Keywords: perspective taking; viewpoint; affordances;
other-centric

Introduction
In everyday conversation, spatial descriptions are
ubiquitous. People often have to explain where they are in
physical space, including their position relative to other
people or objects. Sometimes these descriptions are
ambiguous. For example, imagine that Bob and Julie are
sitting on opposite ends of a table, and two coffee cups are
placed on the table. Bob says to Julie, “The cup on the
right is mine.” Which cup is Bob referring to? The cup on
Bob’s right, or the cup on Julie’s right? The answer
depends on perspective.
People often take an egocentric perspective when
describing a spatial scene (Piaget & Inhelder, 1956; Pick &
Lockman, 1981; Shelton & McNamara, 1997). However,
they can also choose another perspective by adopting the
viewpoint of another person or object (e.g., “The dent is on
the car’s front left fender”, “A mosquito is on your right
shoulder”). Object anchoring is one way people take an
other-centric perspective. They use a particular object or
person to describe the location of another object or person
(e.g., “Mary is on John’s right”) (Schober, 1993; see also
Borghi, Glenberg, & Kaschak, 2004). They can also vary

2298

intonation patterns or use gesture (Clark, 1996). In recent
years, many researchers have argued that the egocentric
perspective is the default mechanism in conversation
(Hanna, & Tanenhaus 2004; Horton & Keysar, 1996;
Keysar, Barr, Balin & Brauner, 2000; Tversky, Lee &
Mainwaring, 1999; Nadig & Sedivy, 2002). Critically,
however, there are circumstances that give rise to an othercentric perspective (Tversky & Hard, 2009).
A considerable amount of psycholinguistic literature has
treated the egocentric perspective in language processing
as a default mode that is enforced by the cognitive
architecture of the language processing system (Epley,
Keysar, Van Boven, & Gilovich, 2004; Horton & Keysar,
1996; Keysar et al., 2000). In that account, factors that
might encourage an accommodation of another’s
perspective come into play during a second stage of
processing after an initial egocentric anchoring point has
been assumed. An alternative approach has been to treat
egocentric biases and “other” centric biases as competing
against one another simultaneously and on equal footing
(Hanna & Tanenhaus, 2004; Hanna, Tanenhaus, &
Trueswell, 2003; Nadig & Sedivy, 2002).
Much research shows a preference for egocentric
perspective in viewing scenes, but little is known about
how or why this occurs. Tversky and Hard (2009) began to
explore these questions in a novel study using photographs.
Participants viewed pictures of objects (water bottle or
book) and explained where the objects were in relation to
one another. If a person also appeared in the picture (facing
the participant), participants occasionally accommodated
that person’s perspective and chose it over their own.
Tversky and Hard also manipulated the question to
highlight action in the scene, which yielded interesting
differences, such as increased other-centric perspective
taking. Their findings provide an excellent foundation for
exploring the role of viewpoint in spatial descriptions.
Choosing another’s perspective when describing a
spatial scene seems like a natural way to help achieve
mutual understanding when another person is present. But
to what extent does this generalize? Previous work
(Greenwood, Matlock, Matthews, & Spivey, 2010, 2011,
& 2013) suggests participants sometimes take a
perspective other than their own when there are

affordances present in the visual scene that allow them to
take advantage of the affordances to produce that other
centric response. This arises from nothing more than a hint
of volitional agency. In one study, participants take the
other perspective of a toy robot that does not actually
afford the task but participants still assume the perspective
of the toy robot because the language and visual input still
hint at the toy robot being the volitional agent (Greenwood,
Matlock, Matthews, & Spivey, 2011). Another experiment
using the same paradigm showed participants taking the
other perspective more often when the visual scene
included an empty chair across the table from the
participant. Once again, participants produce other centric
responses because of a hint of volitional agency when no
agent exists (Greenwood, Matlock, Matthews, & Spivey,
2011). They also showed that in social settings, such as
committee participation, individuals took the perspective
of a stranger in the scene more often than they do their
friends’. They suggest that participants take the stranger’s
perspective in an effort to find common ground amongst
the committee members. They also manipulated verb
agency and found that a greater number of other centric
responses are elicited when action in the scene is
highlighted (Greenwood, Matlock, Matthews, & Spivey,
2010, 2011, & 2013).
The other studies participants were given a free
response task and used off line measures where
participants typically chose one perspective as their
response. The following experiment used online measures
and allowed participants to decide between one of two
possible perspectives. In this experiment we used
MouseTracker (Freeman & Ambady, 2010; Freeman, Dale,
& Farmer, 2011) in an effort to determine the spatial
attraction in real-time of the possible choices. Using the
mouse-tracking method, constraining the possible
perspectives available in the spatial scene to two, and by
varying the visual input participants would see we devised
the following experiment. From previous work (Tversky &
Hard, 2009) we knew that when a person was present
individuals are more likely to take the perspective of that
person. In this online version we wanted to determine
through the trajectories of their responses, the differences
in reaction times and maximum deviation if we could
replicate that finding but also find pointers to attraction
toward the other response even if they ultimately choose
the egocentric response. We predicted that when there was
a person present in the scene, people would more often
take the perspective of that person. In addition, we
predicted that when participants were in the “person
present” condition their maximum deviation would be
greater for those taking their own perspective due to the
visual competition of the person in the scene there would
be attraction toward the “other” perspective. In terms of
initiation latency we hypothesized that participants would
be slower to initiate their reaction time if they were in the
“person absent” condition and choosing their own
perspective because of the ambiguous nature of the

2299

instructions and the competition of another perspective
would inhibit their decision-making process. We also
predicted that their overall reaction time would be slower
in the “person absent” condition and choosing the other
perspective. We predicted this because when an individual
chooses the other perspective and there is no person that
they are placing the object in front of (but beside the
basket) it might take longer to decide where placement of
the object should be located. Although this was not
something that could be measured in the offline versions
this was something we considered when designing this
online version.

Experiment
Using MouseTracker (Freeman & Ambady, 2009), we
examined how participants would respond to an online task
of moving objects on a screen when directions were
spatially ambiguous. We tracked participants’ computer
mouse movements while making decisions to get a graded
measure of thought output over time. We were interested in
both participants’ final responses, but also attraction
toward alternative responses as well.

Method
Participants were given instructions to place objects, using
a computer mouse, on either the right or the left side of a
basket displayed on a computer screen (we also used inside
the basket as filler trials). Participants were never told
which side should be right or left. Although the task never
changed during the experiment and neither did the
condition participants could assume an egocentric
perspective on trial one and assume an “other” centric
perspective on trial two. The potential to switch
perspectives from trial to trial existed. Assuming
participants took an egocentric perspective, when asked to
place objects to the right of the basket, right would be
located on the right side of the computer screen. If
participants took an “other” perspective, placing an object
to the right of the basket would mean that the object was
placed on the left side of the computer screen. Trials
always began with the mouse curser in the same location at
the bottom of the screen in a small box that was labeled
“start.” When the individual would left click on the start
location the trial began and the mouse pointer would turn
into the object they were being instructed to place in or by
the basket on the screen. The trial would end once they
released the left mouse button and dropped the object to
their desired location. Then, the next trial would begin and
they would repeat this sequence until they placed all the
trial objects on the right, left or inside the basket.

Participants
Fifty-seven individuals (37 females, 1 declined to answer)
between the ages of 18-32 from the University of
California, Merced participated in this experiment. They
were given course credit for their participation.

Materials
An Apple iMac (Apple, Inc., 1997-2014) running
Microsoft Windows 7 (Microsoft Corporation, 2001-2014)
and MouseTracker (Freeman & Ambady, 2010) software
was used in this experiment. Photographs of the objects
and the backgrounds used for the experiment were taken
with a Sony (Sony Corporation, 1946-2014) digital
camera. The female voice used for each of the trials was
recorded using Praat (Boersma & Weenink, 2014).

Procedure
Participants were brought into the lab to perform the task
individually. After consenting to participate research
assistants explained the task and sat them at the computer
station. Instructions on how to proceed were displayed on
the computer. Participants were given several practice
trials and then continued on to experimental trials. The first
screen was written directions for the participant explaining
how to partake in the trial but as they proceeded to the
trials the instructions were given verbally through a
female-recorded voice. The female voice was in an effort
to counterbalance the male photo that participants would
view in Condition 2 as shown in Figure 2. Critically, we
did not want participants to believe the instructions were
coming from the person in the photo. Participants were
instructed to “place the object [listed in Table 1] to [the
right], [the left] or [inside] the basket.” There were twenty
different objects (see Table 1) and each object was
presented three different times, once for right, once for left
and once for inside. Each object, and the direction that the
object was to be placed, were randomized for each
participant. Each participant was also randomly placed in
one of two conditions: Condition 1 contained a table, on
which a basket was placed; Condition 2 was similar to
condition 1 except it included a person sitting behind the
table facing the participant.

Figure 1: Condition 1 background.

2300

Figure 2: Condition 2 background.
Table 1: Each object is an individual trial, repeated for
“left,” “right,” and “inside,” and randomized for each
participant.
Objects
(alphabetically)
Apple
Berries
Bowl
Candle
Candy
Chips
Clip
Cup
Gum
Keys

Objects
(continued)
Matches
Mug
Nuts
Orange
Pizza
Pliers
Roll
Salt
Scissors
Tape

Results
The data were coded using MouseTracker Analyzer
(Freeman & Ambady, 2009). Technically, there were no
right or wrong answers in this task, due to the ambiguous
nature of the questions. However, we coded the responses
such that individuals would take an egocentric perspective.
From the 57 participants we collected 2280 critical trials
(right or left) and discarded 63 total trials due to the
incompletion of the trial. We hypothesized that those
individuals in Condition 2 would be more likely to take an
“other” perspective more often than those in Condition 1.
We hypothesized that initiation latency would be slower
for egocentric perspectives in the “person absent”
condition. We also hypothesized that reaction times would
be faster for egocentric perspectives in the “person absent”
condition. Our last prediction was that maximum deviation
would also show a pattern of attraction toward the other
perspective when another person was present even when
they chose the egocentric perspective. We ran an item
analysis to rule out the possibility that a particular object
could potentially drive a specific perspective. This was not
the case; all items were used in both perspectives and were
used on average about 14% of the time. This result is
consistent with the overall finding that individuals chose
the other perspective about 10% of the time when there

was a person in the scene compared to 2% when there was
no person in the scene, Welch's t-test, t(395.22) = 14.9, p <
.001. The 95% confidence interval for the effect of
perspective on condition is between 1.5 and 1.2 percent.
We also analyzed initiation latency, reaction times and
maximum deviation to examine our hypotheses. However,
we began with replicating former findings, when
individuals saw Condition 2, as shown in Figure 2,
participants took the other perspective more often than they
did in Condition 1, as reported in this regression, b = 1.53,
t(2215) = 139.93, p < .001. Perspective also explained a
significant proportion of variance in the condition the
participant was randomly assigned, R2 = .49, F = (1, 2215)
= 137.9, p = .001. When individuals saw another person
facing them in the scene, as shown in Figure 2, regardless
of which perspective they chose, initiation times were
about the same, (egocentric: M = 1470.30, SD = 1273.72;
other centric: M = 1527.30, SD = 1205.65). However,
when there was no person facing them as shown in Figure
1, people were much slower to initiate an egocentric
response but much faster to initiate an other person
response (M = 2018.16, SD = 1184.28; M = 1255.43, SD =
1348.32). This was confirmed significant by Welch’s t-test,
t(41.33) = 3.3, p < .001, as shown in Figure 3.

Figure 4: Reaction time by Condition for
Egocentric vs. Exocentric responses.
The maximum deviation had an interesting pattern; there is
more curvature toward the egocentric response in
Condition 2 (“person present”) than there is for the “other”
perspective even though as reported earlier more people
are taking that perspective than in the “person absent”
condition. However, that pattern is reversed in Condition 1
as reported in this regression, b = .085, t(2214) = 8.86, p <
.001. Maximum deviation also explained a significant
proportion of variance in the perspective the participant
chose, R2 = .14, F = (2, 2214) = 9.4, p = .001.

Figure 3: Initial Latency by Condition for
Egocentric vs. Exocentric responses.
For overall reaction time, in the Condition 1 as shown in
Figure 1, participants were slower when choosing the other
perspective compared to when they chose their own
perspective (M = 4165.18, SD = 685.93; M = 3775.36, SD
= 812.23). Again, this was confirmed significant by
Welch’s t-test, t(43.29) = -3.5, p < .001. The 95%
confidence interval for the effect of perspective on reaction
time is between -614.3 and -165.3 percent.

2301

Figure 5: Maximum Deviation by Condition
for Egocentric vs. Exocentric responses.

Discussion
Using computer mouse trajectories we compared initiation
latency, reaction times, and maximum deviation
trajectories of the competing biases in two unique
conditions (other person present/other person absent). In
this experiment the language processing necessary to
complete the task is exactly the same but we find that with
a slightly different visual input we get a significantly
different result. The findings showed the distinctly
different initiation latency, overall reaction time, and
maximum deviation patterns that emerged. The initiation
latency pattern for individuals in the condition where the
visual scene contained a person was about the same
regardless of the perspective participant’s took and in this
condition we see an increase in participants taking the
“other” perspective. Yet in the “person absent” condition
we see less people taking the other perspective; individuals
are much slower to initiate the egocentric response and
much faster to initiate the other perspective. Overall
reaction times are also faster for the other centric response
in Condition 2 when a person is facing them. For
maximum deviation we also see an interesting pattern for
egocentric and other centric responses. In Condition 1 the
maximum deviation is less for the other perspective than it
is for the egocentric response. However, in the Condition 2
we see that pattern reversed and participants’ maximum
deviation for the egocentric response is greater than the
other centric response. These results seem to suggest that
even when participants are taking the egocentric
perspective they are also considering taking the other
perspective. This finding also seems to dispute the default
account of processing that involves a second stage of
accommodation. It seems to support the competing biases
account where two perspectives are on equal footing. This
experiment gives us a glimpse into the time course of
perspective competition as it unfolds over time.

Acknowledgments
Thanks to all the research assistants that helped with taking
photographs, MouseTracker experiment coding, and
interacting with participants: Norma Cardona, Cynthia
Carlson, James Greenwood, Caleb Henke, Vandana
Koppula, Courtney Griffin-Oliver, Elaine Lai, David
Sparks, and Monica Yanez. There was an extra amount of
work done by the following research assistants: Yaasha
Ephraim, Jesse Falke, Morgan Fleming, Fatima Panes, and
Zachary Tosi. Special thanks to Dr. Eric Chiu for his
tireless help with statistical analysis. Also special thanks to
Janelle Szary for all her beautiful work of voice recordings
on over sixty object references.

References
Apple Incorporated. (1997-2014). iMac (21.5 inch)
[Computer hardware]. Cupertino, CA: Apple, Inc.

2302

Apple Incorporated. (2006-2014). Boot Camp (4.0) Boot
Camp is a multi boot utility included with Apple
Inc.'s OS X that assists users in installing Microsoft
Windows
operating
systems on Intel-based
Macintosh computers. [Computer utility] Cupertino, CA:
Apple, Inc.
Boersma, P. & Weenink, D. (2014) Praat: doing phonetics
by
computer
[Computer
program].
Version 5.3.51, retrieved 2 June 2014 from
http://www.praat.org/.
Borghi, A. M., Glenberg, A. M., & Kaschak, M. P. (2004).
Putting words in perspective. Memory & Cognition,
32(6), 863-873.
Clark, H. H. (1996). Using language. Cambridge; UK:
Cambridge University Press.
Epley, N., Keysar, B., Van Boven, L., & Gilovich, T.
(2004). Perspective taking as egocentric anchoring and
adjustment. Journal of Personality and Social
Psychology, 87(3), 327.
Freeman, J. B., Dale, R., & Farmer, T.A. (2011). Hand in
motion reveals mind in motion. Frontiers in Psychology,
2, 59.
Freeman, J. B., Ambady, N. (2010). MouseTracker:
Software for studying real-time mental processing using
a computer mouse-tracking method. Behavior Research
Methods, 42, 226-241.
Gibson, J. J. (1979). The ecological approach to visual
perception. Boston: Houghton Mifflin.
Greenwood, M. G., Matthews, J. L., Spivey, M. J.,
Matlock, T. (2013). Taking someone else's perspective:
When body "position" is more important than body
"presence". The 35th Annual Meeting of the Cognitive
Science Society. Berlin, Germany.
Greenwood, M. D., Matlock, T., Spivey, M. J., &
Matthews, J. L. (2011). Looking at the social dynamics
of viewpoint. The 33rd Annual Conference of Cognitive
Science Society. Boston, MA.
Greenwood, M. D., Matlock, T., Spivey, M. J., &
Matthews, J. L. (2010). Am I a robot? How verb agency
and agent depiction influence perspective in visual
scenes. The 32nd Annual Conference of Cognitive
Science Society. Portland, OR.
Hanna, J. E., & Tanenhaus, M. K. (2004). Pragmatic
effects on reference resolution in a collaborative task:
evidence from eye movements. Cognitive Science, 28(1),
105-115.
Hanna, J. E., Tanenhaus, M. K., & Trueswell, J. C. (2003).
The effects of common ground and perspective on
domains of referential interpretation. Journal of Memory
and Language, 49(1), 43-61.
Horton, W. S., & Keysar, B. (1996). When do speakers
take into account common ground? Cognition, 59(1), 91117.
Keysar, B., Barr, D. J., Balin, J. A., & Brauner, J. S.
(2000). Taking perspective in conversation: The role of
mutual knowledge in comprehension. Psychological
Science, 11(1), 32 -38.

Microsoft Corporation. (2001-2014). Microsoft Windows 7
(7.0) Windows 7 is an operating system produced
by Microsoft for use on personal computers, including
home and business desktops, laptops, netbooks, tablet
PCs, and media center PCs. Redmond, WA: Microsoft.
Nadig, A.S., & Sedivy, J.C. (2002). Evidence of
perspective-taking constraints in children's on-line
reference resolution. Psychological Science, 13, 329336.
Piaget, J., & Inhelder, B. (1956). The child’s conception of
space. London: Routledge and Kegan Paul.
Pick, H. L. J., & Lockman, J. J. (1981). From frames of
reference to spatial representations. In L. S. Liben, A. H.
Patterson, & N. Newcombe (Eds.), Spatial
representation and behavior across the life span : theory
and application, Developmental psychology series. New
York: Academic Press.
Schober, M.F. (1993). Spatial perspective-taking in
conversation. Cognition, 47, 1-24.
Shelton, A.L., & McNamara, T.P. (1997). Multiple views
of spatial memory, Psychonomic Bulletin & Review, 4,
102-106.
Sony Corporation. (1946-2014). Sony Electronics [digital
camera]. San Diego, CA: Sony Electronics.
Tversky, B., & Hard, B.M. (2009). Embodied and
disembodied cognition: Spatial perspective-taking.
Cognition, 110, 124-129.
Tversky, B., Lee, P., & Mainwaring, S. (1999). Why do
speakers mix perspectives? Spatial Cognition and
Computation, 1, 399-412.

2303

