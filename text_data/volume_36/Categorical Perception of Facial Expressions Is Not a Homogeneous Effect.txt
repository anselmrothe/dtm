UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Categorical Perception of Facial Expressions Is Not a Homogeneous Effect
Permalink
https://escholarship.org/uc/item/0rs79692
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Korolkova, Olga
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

         Categorical Perception of Facial Expressions Is Not a Homogeneous Effect
                                            Olga A. Korolkova (olga.a.kor@gmail.com)
               Moscow State University of Psychology and Education, 29 Sretenka Street, Moscow, 127051 Russia
                       Moscow Institute of Psychoanalysis, 34 Kutuzovsky Avenue, Moscow, 119334 Russia
                              Abstract                                 1992), and later also on gray-scale images (Calder et al.,
                                                                       1996; de Gelder et al., 1997; Young et al., 1997). Its specific
   We studied the categorical perception on transitions between
   seven basic emotional facial expressions and explored the           aspects were revealed in children (Cheal, Rutherford, 2011;
   influencing factors. In Experiment 1, participants performed a      Kotsoni et al., 2001), in patients with amygdala damage
   multiple-choice emotion labeling task while observing basic         (Adolphs et al., 1999), schizophrenia (Kee et al., 2006) and
   or morphed (blended between a pair of basic emotions) facial        autism spectrum disorders (Teunisse, de Gelder, 2001).
   expressions. In Experiment 2, other participants completed          Although, several studies did not show the CP (Fiorentini,
   AB-X discrimination task. They observed pairs of images             Viviani, 2009; Schiano et al., 2004) or reported the factors
   adjacent in a morphing continuum, and matched the test
   image to one of the pair. The results of Experiment 1 revealed
                                                                       reducing this effect (namely, verbal interference: Roberson,
   influence of emotional context, formed by the presented             Davidoff, 2000; Roberson et al., 2007).
   expressions, on perception of surprise, anger, disgust, and            The concept of CP implies that there is a number of
   neutral face. The “categorical field” of morphed expressions        discrete emotional categories with qualitative differences
   includes not only the two relevant emotions (morphing basis)        between each other, and that each entity of facial emotion
   but a number of additional ones. Based on the data of               can be placed by an observer into one of these alternative
   Experiment 1, we selected the pairs of stimuli crossing the         emotional categories. Another way of describing emotion
   categorical boundary, and pairs falling within the category, to
   predict the discriminability obtained it the Experiment 2. A        and facial expression are continuous spatial models, where
   generalized linear mixed model was fitted to the data. We           the perceived differences between faces are measured as
   show the main effect of within/between category pair, type of       distances in a face-space (Valentine, 1991), or the diversity
   continuum and continuum/category interaction on the                 of emotions is located in a multi-dimensional space with the
   probability of correct discrimination. Overall, our results         axes corresponding to physiological properties such as
   showed the categorical perception, but its strength depends on      arousal, sleepiness or valence (Russell, 1980). A possible
   particular pair of emotional categories.
                                                                       solution of the long-standing debate between categorical
   Keywords: face, facial expression, emotions, categorical            (discrete) and dimensional (continuous) understanding of
   perception, generalized linear model.                               emotion and face perception is by incorporating the both
                                                                       notions into consolidated hierarchical model of higher-level
                          Introduction                                 categorical system that interacts with low-level perceptual,
When we want to test whether the perception of a particular            non-categorical one (e.g., Fujimura et al., 2012; Roberson et
class of objects is categorical, we generally compare the              al., 2010).
ability to perceive physical differences in pairs of objects              In line with the discrete emotions theory, at least seven
belonging to the same and to different categories. Assuming            basic emotions, universal among cultures, were revealed by
that these differences are equal, the enhanced                         P. Ekman (Ekman, Friesen, 1976), and 21 emotional
discriminability in cross-boundary pairs compared to                   continua, representing transitions from one basic emotion to
within-category pairs reflects the categorical perception              another, can be constructed between each pair of emotions
(CP). If categories do not influence the discriminability, we          to test the categorical perception hypothesis. Although, the
refer to continuously perceived differences.                           majority of the facial expressions CP studies explored the
   The classic experimental paradigm for testing the CP was            perception and differentiation of face images belonging to
proposed by Liberman et al. (1957) in the studies on                   only a few of these emotional continua. In particular, CP has
phonemes perception. It included an identification (labeling)          been shown on continua between happiness and six other
task aimed at defining the boundary between categories, and            emotional expressions, but results on CP of happiness /
a discrimination task, in which subjects were asked to                 surprise and happiness / sadness are controversial (see
differentiate objects in both cross-boundary and within-               Calder et al., 1996; de Gelder et al., 1997; Etcoff, Magee,
category pairs.                                                        1992). The continua most frequently used in studies are
   Since then, the CP has been extensively studied on a                those between anger, sadness, fear and happiness. Though,
variety of objects, including facial emotional expressions             even on these expressions, the results are ambiguous and do
(Calder et al., 1996; Cheal, Rutherford, 2011; Etcoff, Magee,          not always show the CP (Calder et al., 1996; de Gelder et
1992; Fugate, 2013; de Gelder et al., 1997; Herba et al., 2007;        al., 1997; Fiorentini, Viviani, 2009). Other continua were
McCullough, Emmorey, 2009; Roberson et al., 2007;                      rarely included in the stimuli for discrimination task, and for
Roberson, Davidoff, 2000; Suzuki et al., 2005; Teunisse, de            8 out of 21 continua, no experimental data is available.
Gelder, 2001; Young et al., 1997; etc.). CP has been shown                An extensive study of facial expressions CP was
first on faces presented as linear drawings (Etcoff, Magee,            conducted by Young et al. (1997) and included all possible
                                                                   767

21 continua between pairs of seven basic emotions, but only            Twenty-one emotional continua were divided into seven
in the labeling (alternative forced-choice) task. In the study      stimuli sets so that each set included three separate
of expression discrimination, 6 continua (happiness / surprise      transitions organized into a meta-continuum in the form:
/ fear / sadness / disgust / anger / happiness) were used, and      Emotion1→Emotion2→Emotion3→Emotion4, where “→”
significant low to moderate correlations were found between         stands for sequence of 4 intermediate morphs. The inner
the discrimination results and the predicted discriminability       structure of these “meta-continua” is similar to the structure
which was based on identification task results.                     of the transitions used in earlier studies, for example,
   Thus, the results obtained up to date, suggest that the CP       between artificial phonemes /ba/, /da/ and /ga/ in the study
can vary in its degree depending on a particular continuum          by Liberman et al. (1957), where the stimuli with linear
between pair of basic emotional expressions. However, this          change in voice onset time were perceived as a sequence of
issue has not been the primary focus of any research yet. To        distinct phonetic categories. In our study, each of the seven
investigate, whether CP depends on the type of emotional            meta-continua served as stimuli in two separate
continua, and in what continua the CP does not appear at all,       experimental series.
we constructed 21 morphing transitions between all pairs of
7 basic emotional facial expressions and carried out two            Experiment 1: Identification
experiments, identification and discrimination tasks, using         Participants were 138 university students (median age 21
the whole range of the basic emotional expressions. The             years, range 18 to 53 years; 41 males) with normal or
procedure of identification task was changed compared to            corrected-to-normal vision. They participated in the study
the study by Young et al. (1997) to extend the previously           for credits. Each subject performed the identification task
obtained results. The discrimination task procedure was also        with one of the seven stimuli sets, thus, 18 to 23 subjects
slightly modified, and the stimuli range was substantially          worked with each set.
broadened to include all transitions between basic emotions.
   To analyze the results, we propose using a generalized           Procedure Each of 16 images from a meta-continuum was
linear mixed model, which is generalization of logistic             presented using PXLab software (Irtel, 2007) to a subject
regression and allows to correctly modeling categorical data        for 3 seconds in the center of 85 Hz CRT display (visual
dependence on various predictors. Mixed logistic regression         angle of 6.7°×9.3°), followed by invitation to choose one or
(multi-level logit modeling) is preferred method of analysis        several out of seven basic emotions that were expressed on
over traditional ANOVA (Jaeger, 2008) as it allows                  the face. Each image was presented twice; the order of
accounting for multiple fixed and random effects                    presentation was randomized. The trial sequence is shown
simultaneously. This method of discrimination data analysis         on Figure 1, a. The participants were not instructed to
can be helpful in revealing the influence of continua type, as      answer as quickly as possible, but to be attentive to the
well as any other significant predictors of the CP.                 images presented to them and to give accurate responses.
                               Method
The aims of the present study were to explore the CP of
facial expressions and the factors that influence the
discriminability of morphed faces from the same or different
emotional categories, and to fit a model to our data.
Stimuli
We used computer morphing to obtain equal distance
transitions between seven basic emotions of actor JJ
(Ekman, Friesen, 1976), as proposed by P. Ekman:
happiness, surprise, fear, sadness, disgust, anger, and neutral
face. Before applying the morphing procedure, the gray-
scale images (245×350 pixels) were corrected for mean
brightness, size and rotation. Then up to 300 reference
points were placed onto each image, and 21 morphing                       Figure 1: a) Identification task trial. Sixteen images
continua were produced for each pair of the initial images.             belonging to one of meta-continua were presented in
We then hid all non-facial features of the images under a             random order, each image twice. The task was to match
black mask, and selected two basic and 4 morphed images                     one or several emotion labels to the presented
(20%, 40%, 60% and 80% impact of one of the two basic                     expression; b) Discrimination task trial. A pair of
emotions) from each continuum, so that the formal                      adjacent images from a meta-continuum was presented
differences between the adjacent images remained the same.            side-by-side, preceded by fixation cross. Then they were
We estimated the inter-image differences as dot products of             masked by black-and-white noise pattern, and the test
vectors composed of the two images’ pixels brightness                  image appeared, equal to one of the pair. The task was
levels.                                                                      to match the test image to one from the pair.
                                                                768

Experiment 2: Discrimination                                                                       As same basic expressions were included into several
Participants were 140 university students (median age 20                                        stimuli sets, we are able to assess possible influences of the
years, range 17 to 47 years; 40 males) with normal or                                           overall emotional context to their perception and
corrected-to-normal vision, none of them performed the                                          identification. Using Fisher’s exact test, we compared the
identification task. Twenty of the subjects worked with each                                    labeling proportions for the same images presented in
of 7 stimuli sets, similarly to the identification task.                                        different settings. The identification of happy, sad, and
                                                                                                feared expressions in different contexts did not change. The
Procedure We used AB-X discrimination task to estimate                                          surprise expression was significantly more frequently
the perceived differences between images of facial                                              labeled as fear when presented in absence of fear expression
expressions. Sixteen stimuli from a meta-continuum were                                         in the experiment series (Fisher’s exact test p < 0.04). The
organized in 15 pairs of adjacent images. In each trial, a                                      same pattern was observed for anger expression labeled as
fixation cross was presented for 600 ms, followed by the                                        surprise or fear without these two expressions in the
stimuli pair simultaneously presented side-by-side for 1500                                     emotional context (Fisher’s exact test p < 0.04). In the same
ms (each image occupied visual angle of 6.7°×9.3°, the                                          manner, disgust expression was confused with anger and
distance between them was 2.3°), and a black-and-white                                          sadness (Fisher’s exact test p < 0.039), and neutral
noise pattern (400 ms, 17.5°×9.3°). After that, the test                                        expression – with happiness and disgust (Fisher’s exact test
stimulus, being one of the pair, appeared in the center of the                                  p < 0.042).
screen for 1500 ms, and the subject was prompted to answer                                         Next, we analyzed the emotional labeling of intermediate
using the keyboard, which of the two images in the pair                                         morphs, depending on their position in a particular
corresponded to the test stimulus. Each pair of images was                                      continuum. In several continua, intermediate images were
presented 20 times in four possible orders of stimuli in the                                    mainly identified as one of the two basic emotions
AB-X triad. The trial sequence is shown on Figure 1, b. All                                     corresponding to those that form the continuum. Morphs
300 trials in the discrimination task were randomized. A                                        were labeled as other emotions in less than 20% of trials.
short training was provided before the main experiment to                                       This was true for happiness / surprise, sadness / neutral,
allow subjects to familiarize with the task. Images from the                                    surprise / fear, disgust / happiness, sadness / disgust, neutral /
training series were not shown in the following experiment.                                     surprise, surprise / disgust, and neutral / happiness continua.
The simultaneous presentation of the AB pair allows                                             In all of them, the categorical boundary is defined as the
reducing the known sequence, or memory, effects, namely,                                        point of cross of two emotion functions. In the other
better performance for sequentially presented stimuli ABB                                       continua, the intermediate morphs in the center of
compared to ABA.                                                                                continuum were identified as other emotions in up to 40%
                                                                                                of trials. Intermediate fear / sadness and sadness / anger
                                                      Results                                   morphs were confused with disgust; fear / disgust morphs –
                                                                                                with sadness, and neutral / fear ones – with surprise. As this
Emotions identification                                                                         occurs in the absence of the “misidentified” emotions in the
                                                                                                overall context, we determined the categorical boundary in
The results of the Experiment 1 are proportions of choosing                                     such continua as the point of crossing for the two relevant
each of seven emotion labels as matching the presented                                          emotion functions.
expressions (see Figure 2).
proportions of identification
                                    Figure 2: Identification task results. The proportions of choosing each of seven emotion labels are plotted against
                                stimuli from seven meta-continua. Basic, non-morphed, images are indicated with labels: ha – happiness; fe – fear; di –
                                  disgust; ne – neutral; an – anger; su – surprise; sa – sadness. Intermediate, morphed, images are placed between the
                                                              corresponding basic ones. Panels are organized by stimuli sets.
                                                                                          769

Discrimination of facial expressions
The results obtained from the Experiment 2 are
dichotomous correct / incorrect discriminations. We fit a
generalized linear mixed model to the data, using R (R Core
Team, 2013) package lme4 (Bates, 2010; Bates et al., 2013).
   The input data for fitting the model has the following
structure. The Response variable comprises two levels
(correct / incorrect). The covariates, possibly influencing the
response, include Category (3 levels: pair of stimuli
crossing the boundary; those containing one basic (non-
                                                                                     probability of correct discrimination
morphed) image and one 20% morph, both being within the
same category; intermediate within-category pairs including
only morphs), Continuum types (21 levels), arranged in
stimuli Sets (7 levels), Age, Sex and unique ID of
participants, unique index of stimuli Pair across all continua
(105 levels), and the Order of images in an AB-X trial (4
levels). The levels of Category covariate were determined
on the basis of the Experiment 1 results. We consider a pair
of images as crossing the categorical boundary if in the
identification task, the emotion identification functions cross
between these two images or at one of them. All the other
pairs, except for those including a non-morphed emotion,
are considered intermediate. We excluded the intermediate
pairs from the further analysis and compared only cross-
boundary and basic pairs. Thus, the remaining dataset
consisted of 27600 observations.
   We started fitting the model from including all covariates:
Category, Continuum, Category × Continuum interaction
and Sex as fixed factors; stimuli Order and Set, and
participants’ ID and Age as random effects. Then we refitted
the model in several steps, each time excluding one of the
factors. The initial and refitted models were compared using
likelihood ratio test (LRT) statistic, –2 (l1–l0), where l1 and
l0 are maximized log-likelihood of the compared models                       Figure 3: Probability of correct discrimination in pairs
with (l1) and without (l0) the factor excluded. To assess,                 of images that cross the categorical boundary (between)
whether the contribution of a factor is significant to fitting                  and include basic emotion image (within). The
the model, we use χ2 test with degrees of freedom equal to                 probabilities are computed using the fixed effects of the
the number of levels of the excluded parameter.                                  fitted model. The continua are named by the
   The random effects of stimuli Set [Pearson’s χ2(1) = 0, p =               corresponding basic emotions: Ha – happiness; Fe –
0.996; SD = 0.000015] and participants’ Age [χ2(1) = 0, p =                    fear; Di – disgust; Ne – neutral; An – anger; Su –
1; SD = 0.00011] in the initial model did not change                                         surprise; Sa – sadness.
significantly the model fit, but excluding Order [χ2(1) =
67.403, p < 0.001; SD = 0.118], and participants’ ID [χ2(1)                                                                  Discussion
= 280.72, p < 0.001; SD = 0.301], resulted in considerably
                                                                        The two experiments described in the present paper
lower fit.
                                                                        accounted for categorical perception of emotional facial
   The fixed effect of participants’ Sex did not contribute to
                                                                        expressions. This phenomenon has been of interest for many
the model’s fit [χ2(1) = 0.0004, p = 0.984], so we excluded it
                                                                        researchers over the last 20 years, but the issue whether we
as not influencing the result. The fixed effects of Category
                                                                        perceive emotions categorically or continuously is not fully
[χ2(1) = 224.2, p < 0.001], Continuum [χ2(20) = 279.02, p <
                                                                        resolved yet. In our study, we tested the hypothesis of CP
0.001], and Category × Continuum interaction [χ2(20) =
                                                                        dependence on emotion continua type. We implemented
94.953, p < 0.001] were highly significant.
                                                                        modified procedures and advanced method of analysis to
   The probabilities of correct discrimination in pairs of
                                                                        our experimental data.
adjacent images, computed from the final model, are
                                                                          In Experiment 1, the multiple-choice labeling task let us
presented on Figure 3. The computed probabilities show
                                                                        to obtain not only matching of the basic and morphed
high correlation with the mean values for raw data [r =
                                                                        images with one most relevant emotion category, but to
0.9998, p < 0.0001], therefore, we can conclude that the final
                                                                        estimate broad “category fields” of facial expressions, and
model describes the discrimination data rather well.
                                                                        therefore, explore the structure of possible systematic
                                                                  770

“misidentifications” of emotional expressions.                      number of additional emotions that form the periphery, with
   The results of the identification task revealed strong           probabilistic identification of the face images with these
context-based effects for expressions of surprise, anger,           emotions. If an expression is far from category center, it can
disgust and neutral face. When we do not present the full           be associated with several adjacent categories. To be so, a
range of the emotions in the same experimental series, these        direct categorical boundary should exist between each pair
four expressions can be “confused” with those not being             of confused categories. The existence of such direct
presented. In classical model (Liberman et al., 1957), the CP       boundaries is to be verified in future research.
is considered to be independent of any contextual                      Based on the results of Experiment 1, we chose the pairs
interference, although, such influences in fact can be              of adjacent stimuli that cross the categorical boundaries, and
prominent. More recently Treisman et al. (1995) proposed a          presented them along with other pairs in parallel AB-X
criterion setting theory, according to which, the subjective        discrimination task in Experiment 2. Compared to other
criterion of signal detection is reset in each new                  studies of facial expressions discrimination, the present one
experimental trial, and, therefore, depends on short-term           included transitions between all possible basic emotions,
influence of the previous trials (the two mechanisms of             and along with substantial amount of individual raw data, it
criterion setting are its stabilization – a shift towards the       allowed us to construct an integral model describing the
stimulus value after each trial, and continuous assessment of       factors that underlie the categorical perception.
signal probability causes shift in opposite direction), as well        In our discrimination data modeling, the influence of
as on long-term overall context influence and individual            stimuli Set (the context effect), though, was not significant.
experience.                                                         Rather, a multi-level logit modeling of the data showed
   Global context effects on perception of objects from             main effects of within- versus between-category position of
different categories and within the same category are also          equidistant stimuli pairs; influence of the type of continua,
incorporated into category adjustment model (Huttenlocher           and the interaction of the two factors, on the proportions of
et al., 2000), in which categories are described in terms of        correct discrimination of the images. We therefore obtained
prototypes theory, and pertinence of each object to each            the categorical perception of facial expressions found
category is probabilistic. According this model, the global         previously in many studies.
aim of an observer is to increase mean accuracy of                     Moreover, according to our results, the CP of facial
judgments by combining the information about a particular           emotional expressions indeed has different intensity,
stimulus with information about its category prototype              depending on the pair of emotional categories being
stored in long-term memory. If the former is incomplete, it         considered. In particular, there were no large differences in
can be partially of entirely substituted by the latter. The         discrimination of within- and between-category expressions
model was tested in experiment with facial expression               in happy / neutral, happy / feared, happy / angry, happy / sad,
differentiation (Roberson et al., 2007). Our identification         surprised / neutral, sad / disgusted, angry / neutral, feared /
data is in line with this model, as our subjects were probably      angry continua. On the contrary, in other continua (happy /
adjusting their judgments to the full range of basic emotion        disgusted, happy / surprised, neutral / disgusted, feared / sad,
categories presented to them as possible labels for the             feared / disgusted, feared / neutral, surprised / sad, surprised /
restricted stimuli set, and, therefore, were more sensitive to,     angry, surprised / feared, surprised / disgusted, sad / angry,
say, subtle disgust cues in ambiguous morphed images                sad / neutral, disgusted / angry) the CP effect is pronounced.
between sadness and anger, if they were not shown the               Possible explanations of such pattern may include: initial
intense disgust expression.                                         difference of particular emotion categories in their affective
   The context adaptation can be avoided if one would               or perceptive power; perception of other, probably non-
present the whole range of facial expressions in the same           emotional, but rather conversational meaning in
experimental series. This paradigm was used in Experiments          intermediate morphed images; or relying on low-level
1 and 2 by Young et al. (1997), with alternative choice of          configural cues of the stimuli (opened or closed mouth,
one out of 6 or 7 basic emotions labels. Though, even in this       morphing artifacts, etc.). Further studies should reveal the
study, pure surprise, sadness / anger and anger / surprise          right one.
morphs were sometimes confused with fear; and fear /                   In conclusion, the present study provided new data of
disgusts morphs – with anger of sadness. Another effect             emotional labeling and discrimination of facial expressions,
revealed in our study is inclusion of additional categories in      contributed to better understanding the categorical
the center of continuum, between the two main categories            perception of emotional faces. We revealed dependence of
(surprise identified in intermediate morphs between neutral         this well-documented and previously considered as
and feared face; disgust – between sadness and anger or             homogeneous effect on the type of emotional categories.
between fear and sadness; sadness between fear and                  Finally, we proposed using the “category field” concept to
disgust). It is also similar to Young et al. (1997) results and     describe the results of emotional misidentification and to
cannot be fully explained by context adaptation or category         discuss them not as accidental errors of perception, but as
adjustments. We propose to explain this issue using the             systematical “adjustments” or “re-calibration” of categorical
concept of “category field” of facial expression, which             structure of emotions depending on particular context.
include the core emotion – the center of category – and a
                                                                771

                     Acknowledgments                               Kee, K. S., Horan, W. P., Wynn, J. K., Mintz, J., & Green,
                                                                     M. F. (2006). An analysis of categorical perception of
The study was supported by Russian Foundadtion for
                                                                     facial emotion in schizophrenia. Schizophrenia Research,
Humanities, project № 12-36-01257a2 “Features of
                                                                     87, 228–237.
perception and perceptual space of facial expressions” to
                                                                   Kotsoni, E., de Haan, M., & Johnson, M. H. (2001).
Olga A. Korolkova.
                                                                     Categorical perception of facial expressions by 7–month-
                                                                     old infants. Perception, 30, 1115–1125.
                          References                               Liberman, A. M., Harris, K. S., Hoffman, H. S., & Griffith,
Adolphs, R., Tranel, D., Hamann, S., Young, A. W., Calder,           B. C. (1957). The discrimination of speech sounds within
   A. J., Phelps, E. A., Anderson, A., Lee, G. P., & Damasio,        and across phoneme boundaries. Journal of Experimental
   A. R. (1999). Recognition of facial emotion in nine               Psychology, 54 (5), 358–368.
   individuals     with     bilateral    amygdala     damage.      McCullough, S., & Emmorey, K. (2009). Categorical
   Neuropsychologia, 37, 1111–1117.                                  perception of affective and linguistic facial expressions.
Bates, D. M. (2010). lme4: Mixed-effects modeling with R.            Cognition, 110 (2), 208–221.
   Springer.                                                       R Core Team (2013). R: A language and environment for
Bates, D. M., Maechler, M., Bolker, B., & Walker, S.                 statistical computing. R Foundation for Statistical
   (2013). lme4: Linear mixed-effects models using Eigen             Computing, Vienna, Austria. URL: http://www.R-
   and S4. R package version 1.0-5.URL: http://CRAN.R-               project.org/.
   project.org/package=lme4.                                       Roberson, D., & Davidoff, J. (2000). The categorical
Calder, A., Young, A., Perrett, D., Etcoff, N., & Rowland,           perception of colours and facial expressions: The effect of
   D. (1996). Categorical perception of morphed facial               verbal interference. Memory & Cognition, 28, 977–986.
   expressions. Visual Cognition, 3, 81–117.                       Roberson, D., Damjanovic, L. & Kikutani, M. (2010) Show
Cheal, J. L., & Rutherford, M. D. (2011). Categorical                and tell: the role of language in categorizing facial
   perception of emotional facial expressions in                     expression of emotion. Emotion Review. 2, 255–260.
   preschoolers. Journal of Experimental Child Psychology,         Roberson, D., Damjanovic, L., & Pilling, M. (2007).
   110 (3), 434–443.                                                 Categorical Perception of Facial Expressions: Evidence
de Gelder, B., Teunisse, J. P., & Benson, P. J. (1997).              for a 'Category Adjustment' model. Memory & Cognition,
   Categorical perception of facial expressions: categories          35, 1814–1829.
   and their internal structure. Cognition and Emotion, 11, 1,     Russell, J. A. (1980). A circumplex model of affect. Journal
   1–23.                                                             of Personality and Social Psychology, 39, 1161–1178.
Ekman, P., & Friesen, W. V. (1976). Pictures of facial             Schiano, D.J., Ehrlich, S.M., & Sheridan, K. (2004).
   affect. Palo Alto, CA: Consulting Psychologists Press.            Categorical imperative not: facial affect is perceived
Etcoff, N. L., & Magee, J. J. (1992). Categorical perception         continuously. CHI 2004 (pp. 49–56). N.Y.: ACM.
   of facial expressions. Cognition, 44, 281–295.                  Suzuki, A., Shibui, S., & Shigemasu K. (2005).Temporal
Fiorentini, C., & Viviani, P. (2009). Perceiving facial              characteristics of categorical perception of emotional
   expressions. Visual Cognition, 17, 373–411.                       facial expressions. Proceedings of the Twenty-Sixth
Fugate, J. M. B. (2013).Categorical Perception for                   Annual Conference of the Cognitive Science Society (pp.
   Emotional Faces. Emotion Review, 5, 84.                           1303–1308). Hillsdale, NJ: Lawrence Erlbaum
Fujimura, T., Matsuda, Y., Katahira, K., Okada, M., &                Associates.
   Okanoya, K. (2012). Categorical and dimensional                 Teunisse, J. P., & de Gelder, B. (2001).Impaired categorical
   perceptions in decoding emotional facial expressions.             perception of facial expressions in high-functioning
   Cognition & Emotion, 26 (4), 587–601.                             adolescents with autism. Child Neuropsychology, 7 (1),
Herba, C. M., Heining, M., Young. A. W., Browning, M.,               1–14.
   Benson, P. J., Phillips, M. L., & Gray, J. A. (2007).           Treisman, M., Faulkner, A., Naish, P.L., & Rosner, B.S.
   Conscious and nonconscious discrimination of facial               (1995). Voice-onset time and tone-onset time: the role of
   expressions. Visual Cognition, 15, 1, 36–47.                      criterion-setting mechanisms in categorical perception.
Huttenlocher, J., Hedges, L. V., & Vevea, J. L. (2000). Why          The Quarterly Journal of Experimental Psychology A, 48
   do categories affect stimulus judgment? Journal of                (2), 334–366.
   Experimental Psychology: General, 129, 220–241.                 Valentine, T. (1991). A unified account of the effects of
Irtel, H. (2007). PXLab: The Psychological Experiments               distinctiveness, inversion and race in face recognition.
   Laboratory [online]. Version 2.1.11. Mannheim                     Quarterly Journal of Experimental Psychology, 43A,
   (Germany):       University     of     Mannheim.     URL:         161–204.
   http://www.pxlab.de.                                            Young, A., Rowland, D., Calder, A., Etcoff, N., Seth, A., &
Jaeger, T. F. (2008). Categorical data analysis: Away from           Perrett, D. (1997). Facial expression megamix. Cognition,
   ANOVAs (transformation or not) and towards logit mixed            63, 271–313.
   models. Journal of Memory and Language, 59 (4), 434–
   446.
                                                               772

