UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Does the Emotional Modulation of Visual Experience Entail the Cognitive Penetrability or
Emotional Penetrability of Early Vision?
Permalink
https://escholarship.org/uc/item/0j97t3dt
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Author
Raftopoulos, Athanassios
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            Does the Emotional Modulation of Visual Experience Entail the Cognitive
                          Penetrability or Emotional Penetrability of Early Vision?
                                              Athanassios Raftopoulos (raftop@ucy.ac.cy)
                                                            Department of Psychology
                                                               University of Cyprus
                                                                  P.O. Box 20537
                                                               Nicosia 1678, Cyprus
                              Abstract                                       stage of perception. Since perception has two stages, any
I argue that emotive states affect perceptual processing either              adequate discussion about CP should make clear to which
directly or indirectly with latencies that fall within late vision and       stage the claim concerning CP purports to apply, and,
not early vision. These effects differ from the effects of, and are          similarly, any claim concerning the penetration of perception
subserved by different neuronal mechanisms than those that                   by emotional influences should make clear to which stage of
subserve, attentional effects on perception, although the two sorts
of effects may interact. It follows that the emotive effects found
                                                                             visual processing it purports to apply.
in perception do not entail either the cognitive penetrability of                Affective states modulate perceptual processing and affect
early vision or its emotional penetrability.                                 the allocation of processing resources to incoming sensory
                                                                             stimuli. In this sense, they function as attention does and for
                                                                             this reason, the difference between attentional and emotional
                         Introduction                                        mechanisms notwithstanding, many researchers talk of
Discussions on the cognitive impenetrability (CI) of                         ‘emotional attention’. (Vuilleumier 2005) Emotional states
perception almost exclusively concern attentional modulation                 can affect perceptual processing both directly or indirectly.
of perceptual processing. Pylyshyn (1999) argues that                            The indirect effects occur when signals form brain areas
attention does not modulate a stage of visual processing,                    like the OFC (orbitofrontal cortex), and the amygdala that
namely, early vision, which is CI. Late vision, in                           process the emotional aspects of stimuli are transmitted to
contradistinction, is cognitively penetrated (CP). Raftopoulos               parietal and frontal areas and affect the semantic processing of
(2009) reaches the same conclusion based on neuroscientific                  the stimulus that takes place there, as when the valence of a
evidence on the timing of attention. However, even if attention              stimulus speeds up or inhibits object recognition. In this case,
does not signify the CP of early vision, other influences might              the emotional processes co-determine the allocation of
modulate early visual processing. Since emotional states affect              cognitively driven attention and, thus, affect indirectly
perception, is early vision penetrated by emotional states?                  perceptual processing through attentional effects; emotional
Siegel (2006) and Stokes (2012) have argued that affective                   effects modulate attention and, thereby, perception. (Phelps
states affect the phenomenology of perception. A second                      2006) Since, I assume that the earliest effects of cognitively
interesting question is whether emotional effects are                        driven attention modulate perceptual processing at 150 ms
independent of attention, or whether they should be                          after stimulus onset the earliest, and that early vision lasts for
interpreted as attentional phenomena in which emotional                      up to 80-120 ms, I take it that the indirect emotional
stimuli are more attended. (Brown et al. 2010)                               influences on perceptual processing through attentional
    Philosophers usually discuss about the CP of perception as               allocation do not threaten the CI of early vision.
if perception were a unified stage. If they find reason to                       There are also direct emotional effects on perceptual
believe that some perceptual states are CP, they conclude that               processing through top-down transmission of signals from
perception is CP. However, perception is not a homogeneous,                  either the OFC or the amygdala to the visual processing areas,
undifferentiated process. It consists of two main stages,                    signals that are distinct from those generated in parietal and
namely early vision and late vision, of which only the former                frontal areas. Should this be the case, early vision despite its
may be CI. Siegel (2006, 501) acknowledges that it is likely                 CI, would be emotionally penetrated (EP). There is, for
that visual perception has an informationally encapsulated part              example, evidence that irrespective of whether or not a face
that is CI and another part that is influenced by cognitive                  cue directs covert attention, the fear face cue enhances
processing. These two visual parts represent different                       contrast sensitivity. (Phelps and LeDoux 2005) There is also
properties of the environment. For example, object                           evidence for modulation of the P1 waveform at 120 ms after
membership to some category, which according to Siegel is                    stimulus onset by emotional stimuli, a latency that precludes
part of the content of perception, may be represented in the CP              this modulation being the result of top-down cognitive signals
                                                                         1216

but can be accounted for by signals from the amygdala                   mechanisms that filter information before it reaches
affecting directly visual processing.                                   awareness. These mechanisms are not considered to be
    In this paper, I argue that emotive states do not affect            attentional because they occur very early and do not involve
directly early vision but only late vision. In the first section, I     higher brain areas associated with attentional mechanisms
discuss early and late vision, as well as CP and EP. In the             (prefrontal cortex, parietal cortex, etc.)
second section, I discuss the timing of emotional effects to                Second, ‘pre-attentional’ should be construed in relation to
determine whether they affect perceptual processing and, to             cognitively driven attention that affects perceptual processing
the extent that the answer is affirmative, which stage of               directly, the claim being that early vision involves processes
perceptual processing. Given that early vision lasts for 120ms,         that are not affected directly by this sort of attention.
to affect early vision affective affects must be registered             Cognitively driven attention is opposed both to exogenous or
within 120 ms. If they occur later than that and while                  stimulus-driven attention, and to the effects of either spatial or
perceptual processing still lasts, they affect late vision. I           feature/object cueing before stimulus onset. The latter do not
conclude that direct emotional effects are found in late vision         affect in a top-down manner visual processing but just rig up
but not in early vision. Thus, early vision is not EP.                  the feedforward sweep. This phenomenon is referred to as the
                                                                        attentional modulation of spontaneous activity. For example,
               2. Visual Stages, CP, and EP                             attending to a location at which the stimulus will appear may
I assume that perception consists of two stages; early vision           enhance the base-line activation, that is, the spontaneous firing
and late vision. The former is CI, while the latter is CP as far        rates, of the neuronal assemblies tuned to the attended location
as cognitive effects that are mediated by cognitively driven            in specialized extrastriate areas. The same phenomenon is
attention are concerned. Thus, I assume that cognitively driven         found with respect to feature/object-centered attention.
attention does not affect directly early vision.                            Late vision is affected by cognitive effects and, thus,
    Early vision includes both a feed forward sweep (FFS) of            involves higher cognitive areas of the brain (memory etc); late
signal transmission in which signals are transmitted bottom-up          vision involves the global neuronal workspace. (Dehaene et al.
and which lasts, in visual areas for about 100 ms, and a stage          2006) Such effects start at about 150 ms when information
at which lateral and recurrent connections between neurons              concerning the gist of a visual scene, retrieved on the basis of
allow recurrent processing. This sort of recurrent                      low spatial frequency (LSF) information in the parietal cortex
processingLamme (2003) calls it local recurrent processing             in about 130 ms, reenters the extrastriate cortex and facilitates
(LRP)occurs at 80-120 ms, is restricted within visual areas,           the processing of the high spatial frequency information (HSF)
and does not involve signals from cognitive centers. The                leading to faster scene and object identification. (Kihara and
unconscious FFS extracts high-level information that could              Takeda 2010; Peyrin et al. 2010)
lead to categorization, determines the classical receptive field            Let me explain what I mean by CP and CI of early vision.
of neurons and their basic tuning properties, and results in                CP=The CP of early vision is the nomological
some initial feature detection. The representations formed at               possibility that cognitive states can causally affect in a
this stage are restricted to including information regarding the            top-down, direct, on-line way (that is, while the viewer
transducable features of objects, that is, information about                has in her visual field and attends to the same location
spatio-temporal properties, surface properties, viewer-centered             or stimulus, or is prepared to attend to the same stimulus
shape, color, texture, orientation, motion, and affordances, in             when it appears) early vision, in a way that changes the
addition to the representations of objects as bounded, solid                visual contents that are or would be experienced by a
entities that persist in space and time. Parts of this stage’s              viewer or viewers with similar perceptual systems,
contents are at the personal level. By being restricted within              under the same external viewing conditions.
the visual system and by not involving signals from the                 The reference to direct on-line effects purports to insulate a
cognitive areas of the brain, FFS and LRP are CI.                       process that is indirectly affected by cognitive inferences from
    During early vision no cognitively-driven attentional               being construed as CP. The indirect effects include both
effects exist. Neurophysiological evidence for this comes from          cognitively driven spatial and feature/object based attention,
various findings (discussed in Raftopoulos 2009, ch. 2) that            and the preparedness to attend that covers cases in which the
strongly suggest that the first signs of cognitively driven             viewer expects a certain object or feature to appear either at a
attentional effects on visual areas up to V4 occur at about150          certain cued location or somewhere in her visual field. The
ms. Thus, early vision is a pre-attentional stage of visual             former cases are post-early vision effects. The later cases
processing that is CI in the sense that its formation is not            constitute a rigging-up of the FFS and are not instances of CP,
directly affected by signals from cognitive centers. It is in           which is supposed to affect perception on-line. The term of
defining what ‘directly’ means that considerations about                causality ensures that any relation between contents occurs as
attention enter the picture and make necessary some                     a result of the causal influences of cognitive states on
explication of what “pre-attentional’ means.                            perceptual states and contents and is not a matter of
    First, my claim does not entail that there is no selection          coincidence. Finally, the specification of ‘top-down’ ensures
during early vision. There are non-attentional selection                that the operational constraints, which are at play in perception
                                                                    1217

to solve the various problems of underdetermination both of           reciprocal connections to the lateral parietal areas in the dorsal
the distal objects from the retinal image and of the percept          system, where it receives LSF information transmitted through
from the retinal image do not constitute cases of CP because          magnocellular pathways. Using LSF information, the medial
by being hardwired in the perceptual system, they cannot be           OFC extracts the affective context in which the object has
cognitive effects. (Raftopoulos 2009)                                 been experienced in the past and this information is relayed to
    A similar definition applies to EP.                               the dorsal system where it contributes to the determination of
    EP=The EP of early vision is the nomological                      the sketchy gist of the scene or object. The lateral OFC, in its
    possibility that affective states can causally affect in a        turn, has reciprocal connections with inferior temporal areas
    top-down, on-line way (that is, while the viewer has in           of the ventral stream, whence it receives HSF information
    her visual field the same stimulus or is prepared for the         through parvocellular pathways (the pathways that carry
    appearance of the same stimulus) early vision, in a way           detailed information about a visual scene in the ventral
    that changes the visual contents that are or would be             system). Its role is to integrate sensory with affective
    experienced by a viewer or viewers with similar                   information to create a specific representation of the scene or
    perceptual systems, under the same external viewing               object, which eventually leads to conscious experience. Note
    conditions.                                                       that owing to the time delay of the information transmitted
Note that there are some differences from the definition of CP        through parvocellular pathways compared to the information
owing to the fact that, as we shall see, it is likely that            transmitted through magnocellular pathways, information
emotional stimuli can be processed and experienced even               arrives faster at the medial OFC than at the lateral OFC.
when they are outside the focus of attention. As in the case of       (Ashley et al. 2003)
CP, the preparedness purports to cover cases in which a cue               Emotional stimuli, owing to their intrinsic significance,
regarding the valence of an upcoming stimulus may influence           have a competitive advantage relative to neutral stimuli and
the base-line activation of the neurons encoding the stimulus.        are more likely to win the biased competition among stimuli
                                                                      for further processing. However, affecting the biased
               2. Timing Emotional Effects                            competition among stimuli is what attentional effects do too
When the brain receives information, it generates a hypothesis        and, so, the question arises as to the relation between
based on the input and what it knows from the past to guide           emotional and attentional influences on visual processing.
recognition and action. In addition to what it knows, it uses         Evidence shows that both attention to non-emotional stimuli
affective representations, that is, prior experiences of how the      and emotional stimuli per se can boost neural responses
input had influenced internal bodily sensations. In determining       (Vuilleumier et al. 2004; Shupp et al. 2003). This suggests that
the meaning of the incoming stimulus, the brain employs               the net result of both attentional and motivational modulation
representations of the affective impact of the stimulus to form       of the visual cortex is very similar. Since emotional effects,
affective predictions. These predictions are made within ms           like attentional effects, enhance perceptual processing, they
and do not occur as a separate step after the object is               are sometimes referred to as ‘emotional attention’.
identified; rather they assist in object identification. There is     (Vuilleumier 2005) However, the neuronal pathways
substantial evidence that the OFC, which is the centerpiece of        responsible for attentional and emotional effects are likely
the neuronal workspace that realizes affective responses, plays       different, since, among other things, differences in size and
an important role in forming the predictions that support             duration of the time courses of semantic and emotional
object recognition. (Barr 2009)                                       processing and their influences on the visual cortex have been
    Activation of the OFC owing to bottom-up signals is               observed. (Attar et al. 2010; Vuilleumier 2005; Vuilleumier
observed between 80-130 ms. (Bar 2009) This activity is               and Driver 2007) Another reason for being skeptical of the
driven by LSF information and, hence, magnocellular visual            view that the same mechanism underlies attentional and
input. A second wave of activity in the OFC is registered at          emotional effects is that there is mixed evidence concerning
200 to 450 ms, probably reflecting the refinement and                 whether unattended emotional stimuli (fearful faces) are
elaboration of the initial hypothesis. There is evidence that the     processed. Williams et al. 2005 argue that although
brain uses LSF information to make an initial prediction about        differential amygdala responses to fearful versus happy facial
the gist of a visual scene or object, that is, to form a              expressions are tuned by mechanisms of attention, the
hypothesis regarding the class to which the scene/object              amygdala gives preference to potentially threatening stimuli
belongs. This hypothesis is tested and details are filled using       under conditions of inattention. Moreover, the influence of
HSF information in the visual brain and information from              selective attention on amygdala activity depends on the
visual working memory. (Johnson and Olshausen 2005;                   valence of the facial expression. Bishop et al. 2007, on the
Kihara and Takeda 2010; Peyrin et al. 2010)                           other hand, argue that affective modulation of the BOLD
    Barrett and Bar (2009) argue that the medial OFC directs          signals occurs only when the task demands low attention.
the body to prepare a physical response to the input, while the           Studies in humans (Olofsson et al. 2008; Vuilleumier and
lateral parts of OFC are integrating the sensory feedback from        Driver 2007) show that emotional vs. neutral faces processing
the bodily states with sensory cues. The medial OFC has               produces a higher amplitude of VEP (visual evoked potentials)
                                                                  1218

and an enhancement of the P1 ERP component at about 120                they may reflect the functioning of an early selective attention
ms. P1 originates in extrastriate areas and is considered to be        mechanism that does not depend on valence categorization but
the hallmark of the effects of exogenous spatial attention on          on motivational relevance and which facilitates processing of
visual processing, that is, the effects of the automatic orienting     stimuli with high motivational relevance. (Shupp et al. 2004)
response to a location where sudden stimulation has occurred.              Emotional effects are found at long latencies as well
This entails that the emotion-related modulation of the visual         (>300ms), probably reflecting the impact of emotional signals
cortex arises prior to the processing stages associated with           to the processing of sensory information in fronto-parietal
fine-grained face perception indexed by the N170 component             areas. Both P3 and the following positive slow wave relate to
for face recognition. This reinforces the view that emotional          the elevated ERP positivity caused by the emotional
affects are prior to, and help in determining, the categorization      modulation of P3 and of the slow wave, and by the valence
of the stimuli, and that they can collaborate with attentional         value and arousal level of the stimulus (valence influences
effects by enhancing the processing of spatially relevant and          P3b but not P3a, while arousal influences both).
emotionally significant stimuli. The early latency precludes                In general, valence effects are found predominantly for
this modulation being the result of top-down cognitive signals.        early and middle-range ERP components, probably reflecting
Neither can the modulation be accounted for by signals from            the role of emotional intrinsic value of the stimulus for
the amygdala because the amygdala in humans processes the              stimulus selection. Arousal effects, that is, a positive shift in
emotional content of facial expressions at 140-170 ms after            the ERP waveforms, are found for middle-range and late
stimulus onset (Conty et al. 2012), or at 200 ms (Pessoa &             components and constitute the primary affective influence at
Adolphs 2010). Despite its early latency, the P1’s modulation          these latencies (Olofsson et al. 2008). They probably reflect
by emotion occurs when early vision is almost over (120 ms).           the allocation of processing resources to the selected stimuli.
    The N170 is also modulated by emotional content and this               The discrepancies found in studies comparing emotional
modulation occurs at about the same time that amygdala start           with attentional effects are probably caused by the fact that in
processing the emotional content of face expressions. (Conty           the various experiments there were different manipulations of
et al. 2012) EEG studies that manipulate attentional and               the kind of attention involved (spatial vs. object-based
emotional facial expressions orthogonally (Holmes et al.               attention). In ERP studies when non-spatial attentional
2003) show that emotional effects start modulating face                manipulations were applied (pictures of fearful faces and
processing at the fusiform gyrus closely following the N170            houses were superimposed so that spatial attention could be
face specific component. Thus, the emotional modulation of             controlled and object-based attention could be manipulated) a
the extrastriate cortex takes place prior to task-related              sustained positivity in response to fearful faces emerged at
attentional selection and prior to the full processing of faces in     about 160 ms in the fusiform gyrus, which was not affected by
the cortex. This is also an indication that emotional effects          attentional manipulations. (Santos et al. 2008) Similar results
enhance or inhibit the processes that lead to object                   suggesting that emotion-related modulation occurs even when
recognition.                                                           emotional stimuli were not task relevant have been found with
    ERP results on affective processing show also an early             SSVEP studies. (Muller et al. 2008)
posterior negativity (EPN) at about 200-300 ms for arousing                To disentangle this issue, Attar et al. (2010) examined not
vs. neutral pictures, which involves both fronto-central and           the time course of emotional processing of stimuli per se but
temporo-occipital sites and which is thought to index                  its effects on attentional resource allocation in a primary task
‘motivated attention’. The motivated attention selects                 with respect to which the emotional stimuli functioned as
affectively arousing stimuli for further processing on the basis       distractors. Their findings suggest that highly arousing
of perceptual features. Furthermore, other findings show that          emotional pictures consume much more processing resources
the affective amplitude modulation persists for a prolonged            than neutral pictures over a prolonged period of time, which
period of time, which entails that emotionally arousing stimuli        means that emotional distractors receive prioritized processing
receive enhanced encoding even when they had to be ignored             despite severe resource limitations. This effect, however, is of
by being task irrelevant. (Olofsson et al. 2008) Around the            relatively small size when compared to the effects of general
same time (200-300 ms), stimulus valence has been shown to             picture processing on task-related activity, where irrelevant
elicit a decreased N2 negativity (unpleasant compared to               whole pictures without any emotional value that act as
pleasant stimuli). Since at 200-300 ms latencies stimulus              distractors have a detrimental effect on task related activity.
discrimination and response selection are thought to occur,            More importantly for this paper, however, Attar et al (2010)
affective visual stimuli may influence neural activation before        found, at the behavioral level, significant decreases in target
response stages. (Carretie et al. 2004)                                detection rates when emotional compared to neutral pictures
    The negativity biases of ERP waveforms at these latencies          were concurrently presented in the background. At the
may reflect rapid activity by amygdala processing of aversive          neuronal level, the effect was accompanied by a stronger
information and the transmission of this information to fronto-        decrease of SSVEP amplitudes directed to a primary task for
parietal areas where it modulates the allocation of attention so       emotional relative to neutral pictures. The earliest onset for the
that unpleasant stimuli may receive priority processing. Or,           affective deflective amplitude was at 270 ms. According to
                                                                   1219

our knowledge about the neural sites at which SSVEP signals           impaired owing to parietal damage in spatial neglect. fMRI
are generated, the deflection observed stems from sources in          studies with patients show enhanced fusiform activity for
early visual areas. (Andersen et al. 2012) Attar’s et al (2010)       fearful faces compared to neutral faces even when the faces
work also shows that the presence of a challenging primary            were neglected. (Vuilleumier et al. 2004) fMRI studies show
task that limits the availability of processing resources does        that amygdala feedback to the fusiform area influences visual
not eliminate the observed emotion-induced reduction of               cortex additively to the modulation of the same area by
SSVEP amplitudes, which suggests that the effects of                  attention (in this case attention and emotion cooperate). Thus,
emotional distractors are not contingent on top-down                  even though emotional states produce activations analogous to
attentional control. Note that the SSVEP findings accord well         those of attention, the fact that they enhance the representation
to the findings on the timing of the emotional effects on visual      of emotionally task-irrelevant stimuli means that these effects
processing found in the various ERP studies discussed above.          are probably realized by different neural pathways.
    The discussion thus far shows both attentional and                        Emotional and attentional effects can also compete.
emotional effects on visual processing from brain areas other         Emotional modulation of distractors enhances the responses of
than the visual cortex. However, the brain regions and neural         the neurons encoding them. This increases the competition
pathways involved in emotional and attentional influences             with the targets by reducing the responses of the neurons
seem to be different. For example, amygdala is involved in            encoding them. Emotional signals, however, may be
emotional modulation of perceptual processing, whereas the            suppressed by high perceptual competition where spatial
FEF and other parietal regions are involved in the modulation         attention filters out very early most of the distractors. (Lavie
of perceptual processing by spatial attention. Amygdala is            2005) Finally, amygdala’s influence can persist in conditions
well poised to modulate perception because it receives sensory        where cortical responses are reduced, contributing, thus, to the
inputs from all modalities and sends signals to many cortical         amplification of cortical processing when sensory inputs are
and subcortical regions that can potentially influence                insufficient. (Vuilleumier 2005)
perception. Amygdala is sensitive both to coarse LSF                      Emotional effects act separately from attentional effects
information that travels fast in the brain and to slow HSF            and provide an additional bias to the processes of sensory
information. This way an initial appraisal of emotional               representations that lead to the selection of some among the
significance based on a limited amount of information may             items in the input, either adding to or competing with
proceed quicker than the elaborate and time consuming                 attention. The competition that emotional effects pose to
processing associated with conscious awareness of a stimulus.         attention is advantageous for an organism since unexpected
    This may explain why ERPs to fearful expressions in face          events that have a particular emotional value can be detected,
selective neurons in monkeys are registered very early (50-100        and influence behavioral responses, independently of the
ms after the initial selective activity), while the fine encoding     organism’s current attentional loads.
of faces that relies on the slower traveling HSF information
starts at 170ms as indexed by the specifically related to face-                                 Conclusion
processing N170.                                                      Between 80 and 170 ms after stimulus onset an emotional
    Concerning the relation between affective and attentional         effect is found in emotion sensitive areas like the OFC and the
effects, one can make the following general remarks. The              amygdala owing to bottom-up sensory signals. At 120 ms
amygdala responds to fearful expressions independent of               emotional influences start modulating perceptual processing in
attentional modulation. The amygdala can reinforce the                extrastriate cortex and at about 170 ms the processing of face
representation of fearful faces in fusiform cortex, an influence      selective neurons is affected by emotional signals. At 270 ms
that is disrupted when the amygdala is damaged. (Vuileumier           SSVEP signals are registered in early visual areas, driven by
et al. 2004) Recordings of face-selective neurons in monkeys          top-down emotional signals. In this latency, an EPN and
(Sugase et al. 1999) suggest that the amygdala modulates              perhaps a N2 effect due to affective modulation is found.
perceptual processing 50-100 ms after the initial face-selective      Information concerning the emotional significance of visual
activity. Since the monkey amygdala neurons respond to                stimuli reenters visual areas at about 120 ms the earliest, and
threatening face expressions between 120-250 ms (Pessoa &             continues for up to 1000 ms. Thus, the earliest affective
Adolphs 2010), the earliest modulation of face selective              influences reach visual areas at such latencies that fall outside
neurons by amygdala signals starts at about 170 ms, in                the duration of early vision; they affect only late vision.
accordance with Holmes et al (2008) findings. The amygdala
activity probably reflects coarse-grained global processing of
the input, while the affective modulation of face processing
                                                                                              References
reflects affective information contributing to a more fine-           Andersen, S., Muller, M., & Hillyard, S. (2012). Tracking the
grained representation of faces at later latencies with a delay           allocation of attention in visual scenes with SSEVP. In M.
of 50 ms compared to global processing.                                   I. Posner (ed.), Cognitive Neuroscience of Attention. New
    Emotional enhancement of the responses of neurons in                  York, N.Y: Guilford Press.
visual areas of the brain can operate even when attention is          Ashley, V., Vuilleumier, P., & Swick, D. (2003). Effects of
                                                                          orbitofrontal lesions on the recognition of emotional faces
                                                                  1220

   expressions. Paper presented at the Cognitive                        biological significance. Nature Reviews Neuroscience, 11,
   Neuroscience Society Meeting.                                        773-783
Attar, C. H., Andersen, S., & Muller, M. M. (2010). Time             Peyrin, C., Michel. C. M., Schwartz, S., Thut, G., Seghier, M.,
   course of affective bias in visual attention: convergent             Landis, Th., Marendaz, Ch., &Vuilleumier, P. (2010). The
   evidence from steady-state visual evoked potentials and              neural processes and timing of top-down processes during
   behavioral data. NeuroImage, 53, 1326-1333.                          coarse-to-fine categorization of visual scenes: a combined
Barr, M. (2009). The proactive brain: memory for predictions.           fMRI and ERP study. Journal of Cognitive Neuroscience,
   Philosophical Transactions of the Royal Society, Biology,            22(12), 2678-2780.
   364, 1235-1243.                                                   Phelps, E. A. (2006). Emotion and cognition. Annual Review
Barrett, L. F., & Bar, M. (2009). See it with feeling: affective        of Psychology, 57, 27-73.
   predictions during object perception. Philosophical               Phelps, E. A., & LeDoux, J. E. (2005). Contributions of the
   Transactions of the Royal Society,, 364, 1325-1334.                  amygdala to emotion processing: from animal models to
Bishop, S.J., Jenkins, R., Lawrence, A. D. (2007). Neural               human behavior. Neuron 48, 175-187.
   processing of fearful faces: effects of anxiety are gated by      Pylyshyn, Z. (1999). Is vision continuous with cognition?
   perceptual capacity limitations. Cerebral Cortex, 17, 1595-          Behavioral and Brain Sciences, 22, 341-423.
   1603.                                                             Raftopoulos, A. (2009). Cognition and Perception: How do
Brown, Ch., El-Deredy, W., & Blanhette, I. (2010).                      Psychology and the Neural Sciences inform Philosophy.
   Attentional modulation of visual-evoked potentials by                Cambridge, MA: The MIT Press.
   threat: investigating the effect of evolutionary relevance.       Raftopoulos, A. (forthcoming). The cognitive impenetrability
   Brain and Cognition, 74, 281-287.                                    of perception and theory-ladenness. Journal of General
Carretie, L., Merecado, F., Hinosoja, J. A., Loeches, M., &             Philosophy of Science.
   Sotillo, M. (2004). Valence-related vigilance biases in           Santos, I. M., Iglesias, J., Olivares, E. I., Young, A. W.
   anxiety studied through event-related potentials. Journal of         (2008). Differential effects of object-based attention on
   Affective Disorders, 78, 119-130.                                    evoked potentials to fearful and disgusted faces.
Conty, L., Dezecache, G., Hugueville, L., & Grezes, J. (2012).          Neurophysiologia, 46, 1468-1479.
   Early binding of gaze, gesture, and emotion: neural time          Shupp, H. T., Junghoffer, M., Weike, A. J., & Hamm, A. O.
   course and correlates. Neuroimage, 28, 4531-4539.                    (2004). Emotional facilitation of sensory processing in the
Dehaene, S., Changeux, J-P., Naccache, L. Sackur, J., &                 visual cortex. Psychophysiology, 41, 441-449.
   Sergent, C. (2006). Conscious, preconscious, and                  Siegel, S. (2006). Which properties are represented in
   subliminal processing: a testable taxonomy. Trends in                perception? In T. S. Gendler & J. Hawthorne (eds.),
   Cognitive Science, 10(5), 204-211.                                   Perceptual Experience. Oxford: Oxford University Press.
Holmes, A., Vuilleumier, P., & Eimer, M. (2003). The                 Stokes, D. (2012). Perceiving and desiring: a new look at the
   processing of emotional facial expression is gated by                cognitive penetrability of experience. Philosophical
   spatial attention: evidence from event-related brain                 Studies, 158 (3), 479-92.
   potentials. Brain Research, 16, 174-184.                          Sugase, Y., Yamane, S., Ueno, S., & Kawano, K. Global and
Johnson, J. S. & Olshausen, B. A. (2005) The earliest EEG               fine information coded by single neurons in the temporal
   signatures of object recognition in a cued-target task are           visual cortex. Nature, 400(6747), 869-873.
   postesensory. Journal of Vision, 5, 299-312.                      Vuilleumier, P. (2005). How brains beware: neural
Kihara, K., & Takeda, Y. (2010). Time course of the                     mechanisms of emotional attention. Trends in Cognitive
   integration of spatial frequency-based information in                Science, 19(12), 585-595.
   natural scenes. Vision Research, 50, 2158-2162.                   Vuilleumier, P., Richardson, M., Armony, J., Driver, J., &
Lamme, V. A. F. (2003). Why visual attention and awareness              Dolan, R. J. (2004). Distant influences of amygdala lesion
   are different. Trends in Cognitive Sciences, 7 (1), 12-18.           on visual cortical activation during emotional face
Lavie, N. (2005). Distracted and confused? selective attention          processing. Nature Neuroscience, 7, 1271-1278.
   under load. Trends in Cognitive Science, 9, 75-82.                Vuilleumier, P. & Driver, J. (2007). Modulation of visual
Muller, M. M., Andersen, S. K., & Keil, A. (2008). Time                 processing by attention and emotion: windows on causal
   course of competition for visual processing resources                interactions between human brain regions. Philosophical
   between emotional pictures and foreground task. Cerebral             Transactions of the Royal Society, Biology, 362, 837-855.
   Cortex, 18, 1892-1899.                                            Williams, M. A., McGlone, F., Abbott, D. F., & Mattingley,
Olofsson, J. K., Nordin, S., Sequeira, H., & Polich, J. (2008).         J. B. (2005). Differential amygdala responses to happy
   Affective picture processing: an integrative review of ERP           and fearful facial expressions depend on selective
   findings. Biological Psychology, 77, 247-265.                        attention. Neuroimage, 24, 417-425.
Pessoa, L. & Adolphs, R. (2010). Emotion processing and the
   amygdala: from a 'low road' to 'many roads' of evaluating
                                                                 1221

