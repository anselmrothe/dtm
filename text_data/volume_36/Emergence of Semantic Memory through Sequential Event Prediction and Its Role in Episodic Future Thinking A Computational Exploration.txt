UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Emergence of Semantic Memory through Sequential Event Prediction and Its Role in
Episodic Future Thinking: A Computational Exploration
Permalink
https://escholarship.org/uc/item/2hk7640k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Ito, Yuichi
Ueno, Taiji
Kitagami, Shinji
et al.
Publication Date
2014-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

            Emergence of Semantic Memory through Sequential Event Prediction
          and Its Role in Episodic Future Thinking: A Computational Exploration
         Yuichi Ito (ito.yuichi@nagoya-u.jp)                                         Taiji Ueno (taijiueno7@gmail.com)
  Shinji Kitagami (kitagami@cc.nagoya-u.ac.jp)                               Jun Kawaguchi (kawaguchijun@nagoya-u.jp)
                     Department of Psychology, Graduate School of Environmental Studies, Nagoya University,
                                     Furo-cho, Chikusa-ku, Nagoya City, Aichi 4648601, JAPAN
                             Abstract                                   precedes retrieval of time-specific episodic information. The
                                                                        role of semantic memory is also supported by
  This study aimed to clarify the mechanism underlying
  episodic future thinking, which refers to the ability to              neuropsychological data from patients with semantic
  generate prospective events in a specific time/location/context.      dementia (SD) (Irish et al., 2012). These patients are
  Given that episodic future thinking involves generating               impaired on tasks that probe conceptual knowledge of
  predictions in a plausible order from previous internal               things (words, object, etc.), but their episodic memory
  predictions, we hypothesized that knowledge of sequential             (especially, about recent events) are relatively preserved
  event prediction should underlie episodic future thinking. A          (Irish et al., 2011). Irish et al. (2012) revealed that their
  parallel-distributed processing model was trained to predict
  the next event in the training sequence. After training, the
                                                                        episodic future thoughts lacked details relevant to the events
  model used the acquired knowledge to repeatedly self-                 cued by investigators. For example, when asked to talk
  generate event sequences (i.e., the model predicts the next           about a future dinner, an SD patient might suddenly change
  event, and this prediction then forms the input of the next trial     topic and talk about his wife or past events. In other words,
  which in turn will trigger the next prediction). The resultant        SD patients’ future simulations tend to transgress the
  event sequences captured the episodic future thinking of              boundary of the contexts cued by investigators. However, it
  normal participants and that of neurological patients when the        has yet to be clarified why and how these different types of
  model was lesioned. Moreover, the nature of knowledge
  acquired after training for sequential prediction of external         representations contribute to the simulation of future events.
  events reflected that of episodic memory, schema-like                 An implemented computational model is a useful approach
  knowledge and semantic memory, all of which have been                 on this issue (e.g., Botvinick & Plaut, 2004; Elman, 1990).
  found to contribute to episodic future thinking by past studies.         Any computational modelling of a complex higher-order
  Keywords: episodic future thinking; semantic memory;                  cognitive function requires a set of working assumptions
  parallel distributed processing model; sequential prediction          and simplifications. It is noteworthy that simulation of
                                                                        future events involves the self-generation of successive
                         Introduction                                   internal event predictions. Taking a simulation of tomorrow
                                                                        morning as an example, one might first envision waking up
We can mentally simulate future events that are likely to
                                                                        in your bedroom, followed by an image of a next plausible
happen in a specific time and place (e.g., “We’ll go to that
                                                                        event such as leaving the room, and finally one might
Indian restaurant for lunch. Upon arrival, a young waiter
                                                                        imagine washing his/her face. In other words, our working
will say hello and show us to our table”). This cognitive
                                                                        assumption is that mental simulation requires a mechanism
function is termed episodic future thinking (e.g., Schacter,
                                                                        that allows sequential prediction of an event after the
Addis & Buckner, 2008), and past studies have investigated
                                                                        previously self-generated event in a plausible order.
the role of various types of knowledge within this mental
                                                                        Interestingly, a seminal work of Rumelhart et al. (1986)
simulation process. These include episodic memory
                                                                        mentioned this idea more than a quarter-century ago:
(Hassabis et al., 2007), autobiographical memory
(D’Argembeau & Mathy, 2011), schema/schemata                              Now, suppose that the world events did not happen. It would
representations (general knowledge database about a                       be possible to take the output of the mental model and replace
location/context where a mental simulation is projected)                  the stimulus inputs from the world with inputs from our model
(Berntsen & Bohn, 2010), semantic memory 1 (Irish et al.,                 of the world. In this case, we could expect that we could "run
2012), and so on. For example, D’Argembeau and Mathy                      a mental simulation" and imagine the events that would take
(2011) argued that construction of future event                           place in the world when we performed a particular action.
representations typically involves gradual conversion from
general to more specific information such that access to                Sequential predictions and various knowledge
general knowledge (autobiographic memory, and schema)                   Once we formulate a mental simulation of future events in
                                                                        terms of sequential predictions (NB. We do not mean
  1
                                                                        episodic future thinking is equal to sequential predictions),
     In literature, general knowledge of an event (i.e.,                then we can explain why the experimental studies above
schema/script) and semantic memory of an event are sometimes
used as synonymously and/or the latter is the source of the former
                                                                        found correlations between episodic future thinking and
(Berntsen & Bohn, 2010; Schacter et al., 2008).                         various types of knowledge (episodic memory,
                                                                    660

autobiographic memory, schema-like representations, &
semantic memory) because these are closely relevant to
each other. First, an ability to self-generate a sequence of
predictions is acquired as a consequence of daily
unconscious activities. The external world continuously
provides an event, and one implicitly predicts what follows
next on the basis of what has happened so far (i.e., the past,
especially recent episodes). Thus, our sequential prediction
ability is based on our episodic memory (/autobiographic
memory). Secondly, in a parallel-distributed processing
(PDP) framework, general knowledge about a location/
context (schema/script) comes out as an emergent property,               Figure 1: Three-layer simple-recurrent network. The
not built-in, through the act of sequential predictions of                    number of units are shown in parentheses.
event sequences (Botvinick & Plaut, 2004; Schapiro et al.,
2013; Rumelhart, et al., 1986). Specifically, a system does         for sequential prediction of external events underlies
not need to access a stored “thing” or an isolable database         episodic future thinking, then the model’s self-generation of
about general knowledge of a location/context when it is            internal event predictions should capture the episodic future
interpreting the environment in order to predict what would         thinking of healthy participants. Thus, (D) the trained model
come next. Rather, such a scheme-like behavior emerges in           should be able to self-generate a stable event sequencein the
a system only by adjusting the connection strength among            cued context. In contrast, if the computation of hidden layer
neuron-like processing units so that the system’s function is       activations is distorted (virtual ‘lesioning’), then (E)
tailored to the statistical structure of the event sequences.       semantically-similar items would not be represented in a
Finally, one may argue that such emergent knowledge                 similar manner, thereby mimicking the degraded conceptual
underpinning sequential prediction (i.e., knowledge about           knowledge seen in SD patients. (F) Such a lesioned model
what is likely to come next) is part of semantic knowledge          should find it difficult to self-generate event sequences in a
about the ongoing event sequence.                                   specific context as real SD patients do. Importantly, like SD
  Taken together, one may not need to build-in separable            patients, a lesioned model should still show (G) a higher
knowledge structures to simulate episodic future thinking.          level of familiarity on recent episodes.
Instead, this study aimed (1) to train a model on the
sequential prediction of external event sequences (i.e., the                                   Method
model receives an external event input, and is asked to
predict the next external event input), and (2) to then allow       Model Architecture, Task and Representations
the trained model to use this acquired knowledge for the            Figure 1 shows the architecture of the model. The units in
self-generation of internal event predictions to simulate           the two peripheral layers (input/output layers) were fully
episodic future thinking (i.e., the model predicts the next         connected via units in the hidden layer in a feedforward
event upon a event cue, and this prediction then forms the          manner. The activities in the hidden/output layers were fed
input of the next trial which in turn will trigger the next         back to the hidden layer at the next event through the (self-)
prediction). The specific predictions are as follows. After         recurrent connections. These recurrent connections enabled
training, the nature of the acquired knowledge for external         the model to gain ‘memory’ about past sequences (see
event predictions should reflect the characteristics of             Botvinick & Plaut, 2004; Elman, 1990). The input layer was
episodic memory, schema-like representations, and semantic          divided into six sub-layers to represent each one of six
memory. Thus, (A) the model should show a higher level of           elements of an event in a localist manner (see Table 1). For
familiarity on the recently experienced/trained events than         example, the units in each layer denoted: Time = [time1,
the remote episodes (i.e., episodic memory). Also, during           time2, time3], Location = [home, school, university, office,
sequential predictions of external events, (B) the model            town], Context = [dining, cooking, studying, working,
should be able to ‘interpret’ the context (e.g., now dining) of     cleaning, watching films], Item = [glass, knife, …etc.],
the current sequences (i.e., schema-like behavior). Related         Action = [take/grasp, place, bring into mouth, …etc.]. Given
to this, one would say knowledge about what is likely to            that the task was to predict the next input (e.g., Elman,
happen after a given event is part of semantic memory of            1990), the output layer was organized in the same way,
that event. Thus, (C) the acquired representations (i.e.,           except for the absence of the Time layer (in reality, we do
hidden layer activations) should mirror the structure of            not predict what the next Time is). Note, importantly, we
semantic memory, such that semantically-similar events              assume that context label is not what is explicitly given
should be represented more similarly. After demonstrating           from the external world (Rumelhart, et al., 1986). Therefore,
the nature of the knowledge acquired for sequential                 units in the Context input layer did not receive any external
predictions of external events, the model was allowed to use        input (these are written here so that the creation of the event
this knowledge for self-generation of internal event                sequences is clearer). This means that the model was never
predictions (its own output is the next input). If knowledge        explicitly informed of the context label. On the other hand,
                                                                661

                            Table 1: Examples of the training sequences generated by cellular automata.
                        Input (target of the previous trial) localist patterns
  Event no.                                                                                                    Events in English
                 Time     Location Context*        Subject         Item        Action
      1                    school      dining          I           fork          take                 I take a fork during dining at school.
      2                    school      dining          I           fork         stick                I stick a fork during dining at school.
      3                    school      dining          I           fork bring to mouth       I bring a fork to my mouth during dining at school.
      4                    school      dining          I           fork        place**               I place a fork during dining at school.
      5                    school      dining      friend A        glass         take               A' takes a glass during dining at school.
      6                    school      dining      friend A        glass bring to mouth     A' brings a glass to his mouth during dining at school.
      7                    school      dining      friend A        glass       place**             A' places a glass during dining at school.
      8                    school     cleaning         I           cup          wash               I wash a glass during cleaning at school.
               chilhood
      9                    school     cleaning         I           cup         place**             I place a glass during cleaning at school.
               (Time1)
     10                    school     cleaning     friend B       towel         wipe           B' wipes with a towel during cleaning at school.
     …                        …          …            …          …             …                                      …
      i                     school    cleaning         I        cup        place**                  I place a pen during studying at school.
    i +1                     home     cooking          I         oil        open                       I open oil during cooking at home.
     i+ 2                    home     cooking          I         oil         pour                      I pour oil during cooking at home.
     i+ 3                    home     cooking          I         oil       place**                     I place oil during cooking at home.
     i+ 4                    home     cooking          I        knife         cut                 I cut with a knife during cooking at home.
     …                        …          …            …          …             …                                      …
50,000,001 adolescence      college   studying    classmate F    pen          write             F' writes with a pen during studying at college.
     …       (Time2)          …          …            …          …             …                                      …
100,000,001 adulthood        office   working     colleague H    PC           type                  H' types texts into the PC at the office
     …       (Time3)          …          …            …          …             …                                      …
Note . *      Context input was not given to the network, but the output layer was required to switch 'ON' the correct Context unit.
Note . **     Once all the action lists were used up for each item, Action 'place' was taken. Then, from the next trial, Item information changed,
              and simultaneously, Location/Context/Subject information changed/unchanged probabilistically (see main text).
the units in the Context output layer received a target signal                asterisks in Table 1 denote examples of the timing when
(i.e., the context label of the next input). This means that the              these probabilistic changes of information were made.
model was required to interpret the context of the current                    When the cellular automata decided to change each piece of
event based on the other pieces of information available.                     information, then the next piece of information was
Finally, a small amount of Gaussian noise (range = 0.2) was                   randomly selected from the possible lists (see Tables 2, 3)
added to the input activations to reflect sampling variability.               such that the event sequence was as realistic as possible. For
                                                                              example, Cooking context never occurred in Town; a
Structure of Event Sequence                                                   frying-pan never appeared during Working, etc.
The event sequences in the real world are not random but                      Additionally, once an Item changed to another, the same
follow certain statistical constraints. For example, a waiter                 Item was never selected until two other Items were selected.
is unlikely to pour wine before opening the bottle at a                       Finally, in order to simulate the recency effect on episodic
restaurant. Also, we are likely to bring a fork to our mouth                  memory (see Prediction A, above), the whole training
after sticking it into food. Then, we place the fork down and                 sequence (300 million trials) was divided into three: The
grasp the glass of water, and so on. The event sequences for                  first 50 million trials were labeled as Time1 (Childhood),
training were generated by cellular automata with similar                     the next 50 million trials were Time2 (Adolescence), and
statistical constraints to those within the real world. Table 1               finally the last 200 million trials were Time3 (Adulthood).
shows the examples. The following statistical constraints                     As shown in Table 2, there was time-specific
were applied to the training sequence. Suppose the first                      Location/Subject information (e.g., ‘school’ was specific in
event occurred (Event 1, in Table 1). Then, the following                     Time1). The input patterns with such time-specific
several events (Events 2-3) were generated with the same                      information were later used to probe the model’s episodic
Time/Location/Context(not-presented)/Subject/Item infor-                      memory (see Figure 2 in Results and Discussion).
mation but with different Action information (randomly
selected from the plausible Action lists for that Item, see                   Training
Table 3). Once every possible action was selected without                     In each trial, 64 units in the input layer were hard-clamped
replacement, then ‘place’ Action was taken (see Event 4), at                  to their input values, and the activation spread in a
which point Item information of the next trial always                         feedforward manner. The error derivative was calculated
(100%) changed, and simultaneously the other pieces of                        (cross-entropy), and the weight was adjusted (back-
information changed probabilistically. Specifically, Subject                  propagation). A weight decay of 1E-9 was set. A learning
information changed with a probability of 70%. And, if                        rate of 0.41 was set, and was gradually reduced to 0.01 by
Subject changed, Context information changed with a                           0.02 per every 10 million trials. An error derivative was set
probability of 30%. Then, if Context changed, Location                        to zero if the target-output difference was less than 0.1.
information changed with a probability of 30%. The double
                                                                        662

 Table 2: Possible Contexts/Subjects in each Time/Location                                 Table 3: Examples of possible Items/Action in each Context
Location Time        Context lists    Subject lists (and Time each Subject appears)           Context                      Item lists (and Action lists in each Item)
                 cleaning, studying,  I                                                                      glass (take/grasp, wash*, place), frying-pan (take/grasp,
  home     1-3     dining, cooking,                                                           cleaning
                                                                                                             wash*, place), handkerchief (take/grasp, wash*, place), etc.
                   watching films
                                                                                                             glass (take/grasp, bring to a mouth*, place),
                 cleaning, studying,  I, friend A (Time 1),                                    dining
  school    1                                                                                                handkerchief (take/grasp, wipe mouth*, place), etc.
                        dining        friend B (Time 1), friend C* (Time 1)
                 cleaning, studying,  I, friend A (Time 2), classmate D (Time 2),                            frying-pan (take/grasp, shake/toss*, place),
 college    2                                                                                 cooking
                        dining        classmate E (Time2), classmate F* (Time2)                              knife (take/grasp, cut, place) etc.
                 cleaning, working,   I, classmate D (Time 3),                                               pen (take/grasp, write, place),
  office    3                                                                                 studying
                        dining        colleague G (Time3), colleague H* (Time3)                              note (take/grasp, write, flip, look, place), etc.
                                      I, friend A (Time 1, 2, & 3),
                        dining,                                                                              handout/document (take/grasp, write, flip, read, place),
   town    1-3                        friend B (Time 1), classmate D (Time 2 & 3),            working
                   watching films                                                                            PC (type, read) etc.
                                      classmate E (Time 2), colleague G (Time 3)
 Note. * Friend C (Time 1), classmate F (Time 2), & colleague H (Time 3) are both                            TV (watch), cinema screen (watch),
                                                                                            watching films
         time-/location-specific Subjects. Thus, any events with these Subjects were                         popcorn (take/grasp, bring to mouth, place), etc.
         time-specific, which were used to probe the episodic memory (see main text).               Note . Full lists of Items and associated Actions in each
                                                                                                             Context/Location are available from authors upon request.
                                                                                                    Note . * These actions are the examples of Context-specific actions
                       Results and Discussion                                                                (i.e., one does not wash handkerchief during dining).
Accuracy in Sequential Prediction Task                                                    information available (e.g., Item, Action). Such a schema-
The task was not deterministic but probabilistic, such that                               like behavior can be visualized by multi-dimensional scaling
the model was not able to predict the next event with                                     analysis on the hidden layer activation patterns (Schapiro et
absolute certainty. Elman (1990) evaluated the performance                                al., 2013). As shown in Figure 3, the trials during the same
of such a task in terms of the cosine of the angle between                                context were clustered together and separated from other
the output vector and the target likelihood vector. The latter                            trials (different context). Thus, as found with previous PDP
referred to the probability of each output unit to receive a                              models, general knowledge to interpret the outer world (i.e.,
target signal of 1.0 for a given input pattern. We were able                              schema) does not need to be built-in, but rather comes out as
to determine these probabilities from the training corpus,                                an emergent property (Rumelhart et al., 1986).
resulting in a mean cosine value collapsed over all the trials
of 0.95 (SD = 0.01). Thus, the model successfully acquired                                Emergence of Semantic Memory (Prediction C)
the statistical structure underlining the event sequences.                                Acquisition of knowledge for sequential prediction means
                                                                                          that the model knows what is likely to come next in a
Familiarity in Past Episodes (Prediction A)                                               certain event. One would say such knowledge is part of
Knowledge for sequential prediction of events should be                                   semantic memory of an event. If so, semantically similar
acquired on the basis of past episodes (episodic memory). If                              Items shouldbe similarly represented in the hidden layer.
the model has acquired episodic memory, then recently                                     During training, each Item was presented with some realistic
experienced patterns (Time3) should be more familiar than                                 constraints (e.g.,glass appeared only in Cooking/Cleaning,
remote ones (Time1). Plaut (1997) measured the unit’s                                     and its plausible Action lists were take/grasp, stick, wash,
polarity for an input pattern and took it as an index of that                             etc. See Table 3). Therefore, if the model acquired semantic
input pattern’s familiarity. Figure 2 the distribution of the                             kno wledge as an emergent property of sequential
polarity values (taken from the output layer) for the time-                               predictions, then semantically similar items in the real world
specific trials (see Method). The polarity distribution of the                            (glass, cup, etc.) should be represented as similar patterns.
most recent events (Time3) was higher than those of
Time1/Time2, showing a recency effect.
Schema-like behavior (Prediction B)
The present model did not receive a context label (input)
during training, but was trained to interpret the context of
the current event sequences from the other pieces of
                                                                                              Figure 3: Multidimensional scaling 3D plot of the hidden
                                                                                                  layer activations underlying the model’s context
                                                                                                   ‘interpretation’, and 2D-projections to improve
   Figure 2: Distribution of the polarity values in the output                                 visualization. The colors of the plots denote the input
                  layer units for time-specific events.                                                  context label (not given to the network).
                                                                                      663

   Figure 4: Cluster analysis of the hidden layer activations
 for each Item. Abbreviations used for labelling the clusters:
  D = dining, S/W = studying/working, Cl = cleaning, Co =
 Cooking. Percentages in parentheses denote the ratio of the
    Items that are correctly classified into four categories.
The hidden layer activation vectors for all the trials of an
Item were averaged (collapsing over the other pieces of
information) to form the representative vector of that Item,
                                                                        Figure 5: Survival plots of the Context output during
and we conducted a cluster analysis on those representative
                                                                       internal predictions against the number of predictions by
vectors of 29 Items. The left third of Figure 4 (intact model)
                                                                        (a) Intact, (b) milder, (c) mild, & (d) severe SD models.
shows the resultant dendrogram. If we draw aclustering
criterion line as shown in Figure 4a (red holizontal line),
                                                                    prediction underlies episodic future thinking, then our
then the data were represented by four clusters, and each
                                                                    model should simulate an impaired behavior as well. To
cluster was interpreted to represent Items for Dining,
                                                                    simulate different levels of severity, different levels (SD =
Studying/Working, Cleaning, and Cooking, respectively.
                                                                    0.01, 0.1, & 0.5, respectively) of noise were added to the
Thus, the hidden layer activities captured the semantic
                                                                    recurrent connection (e.g., Botvinick & Plaut, 2004).
similarities of Items in the real world, which was a signature
of emergent semantic memory.
                                                                    Degradation of Semantic Memory (Prediction E) SD
                                                                    patients exhibit more degraded semantic memory as the
Episodic Future Thinking (Prediction D)
                                                                    disease progresses. Figure 4b and 4c shows the results of the
The analyses so far revealed that the model acquired                same cluster analysis as before on the data from the
knowledge for sequential prediction of external events, and         damaged models. Although there were four semantic
this knowledge captured the nature of episodic memory,              categories to classify Items in the intact model (Figure 4a)
schema-like representations, and semantic memory of Items.          such categories got more blurry as the amount of the noise
Next, we tested if this knowledge underlied simulation of           increased. Moreover, the distance (y-axis height) between
future events. First, the model was presented with an event         items within a category also got shorter. This means the
pattern (e.g. Colleague H brought a cup to his mouth during         semantically-similar items became undiscriminable from
dining at the office) as a cue just like in a human experiment.     each other. Thus, semantic memory of the damaged model
Once the model predicted the next event, this output vector         was degraded as observed in real patients (Irish et al., 2012).
was converted to binary in a ‘winner-takes-all’ manner,. and
was hard-clamped to the input layer at the next trial (e.g., if     Episodic Future Thinking (Prediction F) Next, the
Glass output unit had the highest activation value among the        damaged models were tested on their ability to self-generate
Item units, then the corresponding input unit was clamped to        a sequence of internal event predictions. Three levels of
1.0 at the next trial). This cycle was repeated 300 times.          severity were simulated (Figures 5b, 5c, and 5d). As the
Figure 5a (Intact model) plotted the Context output of the          noise level increased, context information in the self-
self-generated internal predictions (a holizontal line means a      generated sequence shifted more frequently from the cued
stable internal prediction sequence within the same context).       event (dining). Thus, like real SD patients, the damaged
After training, the self-generated sequence in the intact           model could not maintain the internal event predictions in a
model was stable in the same context as the cued                    specific context. Moreover, context information generated
information, mirroring the episodic future thinking of              was incongruent with location (e.g., watching films in the
normal participants (Irish et al, 2012).                            Office, which never occurred during training).
Simulating Semantic Dementia                                        Relatively Intact Episodic Memory (Prediction G) Figure
SD patients’ future simulations tended to deviate from the          6a and 6b show the impact of lesioning on the distribution
cued context (Irish et al., 2012). If knowledge for sequential      of the polarity (familiarity) values for the time-specific
                                                                664

                                                                    Finally, a tempting idea is that episodic future thinking
                                                                  can screen different types of neulogical patients given the
                                                                  relationship between semantics and context-coherent event
                                                                  predictions we demonstrated. At this point, we should be
                                                                  cautious because it requires a detailed error analysis, but this
                                                                  would be an intial step towards such a clinical contribution.
                                                                                      Acknowledgments
                                                                  This study was supported by Grant-in-Aid for Challenging
                                                                  Exploratory Research (23653224) to J. Kawaguchi, and for
                                                                  JSPS Fellows (24008998) to Y. Ito.
                                                                                           References
  Figure 6: Distribution of the polarity values in the output
                                                                  Botvinick, M., & Plaut, D. C. (2004). Doing without schema
    layer units for time-specific events of damaged models
                                                                     hierarchies: a recurrent connectionist approach to normal
                                                                     and impaired routine sequential action. Psychological
events. Like real SD patients (Irish et al., 2011), the
                                                                     review, 111(2), 395–429.
familiarity (polarity) of the recent events (Time3) remained
                                                                  Berntsen, D., & Bohn, A. (2010). Remembering and
high when the noise range was small (mild SD). However,
                                                                     forecasting: The relation between autobiographical
such a recency effect disappeared for the severe model
                                                                     memory and episodic future thinking. Memory &
(Figure 6b). Taken together, these patterns replicated the
                                                                     cognition, 38(3), 265–278.
dissociation between degraded semantic memory and
                                                                  D’Argembeau, A., & Mathy, A. (2011). Tracking the
relatively intact episodic memory (especially for recent
                                                                     construction of episodic future thoughts. Journal of
events) found in real SD patients (Irish et al., 2011). Thus,
                                                                     experimental psychology: General, 140(2), 258–271.
impaired episodic future thinking in SD patients can be
                                                                  Elman, J. L. (1990). Finding structure in time. Cognitive
attributed to degradation of semantic memory.
                                                                     Science, 14(2), 179–211.
                                                                  Hassabis, D., Kumaran, D., Vann, S. D., & Maguire, E. A.
               Summary and Conclusion                                (2007). Patients with hippocampal amnesia cannot
  Episodic future thinking involves the successive self-             imagine new experiences. Proceedings of the National
generation of internal event predictions. The present model          Academy of Sciences of the United States of America,
acquired knowledge that captured the characteristics of              104(5), 1726–1731.
episodic memory, schema-like representation (to interpret         Irish, M., Hornberger, M., Lah, S., Miller, L., Pengas, G.,
context) and semantic memory through sequential                      Nestor, P. J., Hodges, J. R., Piguet, O. (2011). Profiles of
prediction of external events. The model used such                   recent autobiographical memory retrieval in semantic
knowledge to conduct a self-generation of internal event             dementia, behavioural-variant frontotemporal dementia,
predictions. The resultant sequences mirrored the episodic           and Alzheimer’s disease. Neuropsychologia, 49(9), 2694–
future thinking of healthy people. In contrast, a damaged            2702.
model mimicked the profile of SD patients, and it had a           Irish, M., Addis, D. R., Hodges, J. R., & Piguet, O. (2012).
difficulty in self-generating internal event predictions in a        Exploring the content and quality of episodic future
steady context. These findings suggest that semantic                 simulations in semantic dementia. Neuropsychologia,
memory contributes to episodic future thinking so that               50(14), 3488–3495.
temporally extended event sequences settle into a steady          Plaut, D. C. (1997). Structure and Function in the Lexical
state within a cued context. An isolable knowledge structure         System: Insights from Distributed Models of Word
(e.g., schema) does not need to be built-in, but rather such         Reading and Lexical Decision. Language and Cognitive
knowledge emerges from daily sequential prediction.                  Processes, 12(5/6), 765–806.
Another implication from this model is that event and object      Rumelhart, D. E., & McClelland J. L., & the PDP Research
knowlege do not require different subsystems, but could be           Group     (1986)     Parallel    distributed    processing:
represented in a multidimensional space of a single hidden           Explorations in the microstructure of cognition (Vol. 2).
layer. This is consitstent with Schapiro et al. (2013) who           Cambridge, MA: MIT Press
argued the similar computational principles for object            Schacter, D. L., Addis, D. R., & Buckner, R. L. (2008).
semantics and event knowledge. Note before that we do not            Episodic simulation of future events: concepts, data, and
mean a one-to-one correspondence between event                       applications. Annals of the New York Academy of
knowledge and episodic memory, and therefore this does               Sciences, 1124, 39–60.
not mean a single-system account for episodic memory and          Schapiro, A. C., Rogers, T. T., Cordova, N. I., Turk-Browne,
semantic memory, neither. Further insight on this issue              N. B., & Botvinick, M. (2013). Neural representations of
would be gleaned by extending this model into other                  events arise from temporal community structure. Nature
episodic/semantic tasks.                                             neuroscience, 16(4), 486–492.
                                                              665

