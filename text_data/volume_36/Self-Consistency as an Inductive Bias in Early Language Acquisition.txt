UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Self-Consistency as an Inductive Bias in Early Language Acquisition
Permalink
https://escholarship.org/uc/item/6g70d1t7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Fourtassi, Abdellah
Dunbar, Ewan
Dupoux, Emmanuel
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

             Self-Consistency as an Inductive Bias in Early Language Acquisition
                                       Abdellah Fourtassi (abdellah.fourtassi@gmail.com)
                                                     Ewan Dunbar (emd@umd.edu)
                                       Emmanuel Dupoux (emmanuel.dupoux@gmail.com)
                            Laboratoire de Sciences Cognitives et Psycholinguistique, ENS/EHESS/CNRS
                                                              Paris 75005, France
                               Abstract                                   other (neighboring) words. This can be seen as guiding the
   In this paper we introduce an inductive bias for language acqui-       learner towards a more “semantically coherent” lexicon. We
   sition under a view where learning of the various levels of lin-       show, using English and Japanese corpora, that the SC-score
   guistic structure takes place interactively. The bias encourages       picks out the correct (ideal) inventory and word boundaries.
   the learner to choose sound systems that lead to more “seman-
   tically coherent” lexicons. We quantify this coherence using           We also show that, although the SC-score has some free pa-
   an intrinsic and unsupervised measure of predictiveness called         rameters, it is largely independent of the way these parameters
   “self-consistency.” We found self-consistency to be optimal un-        are set.
   der the true phonemic inventory and the correct word segmen-
   tation in English and Japanese.                                           The paper is organized as follows. We begin by setting the
   Keywords: Language acquisition, inductive bias, phonemes,              framework of our experiment (modeling of phonetic varia-
   word segmentation, semantics.                                          tion, word segmentation, and semantics). Then, we introduce
                                                                          our learning bias, the SC-score, and explain how it links these
                           Introduction                                   different levels of representation in a coherent and intuitive
In learning their native language, infants need to make sense             fashion. Next, we present the results of our simulations on
of the sounds they are hearing. For the segmental inventory,              two different speech corpora in English and Japanese.
they need to decide how much of the detail present in the
signal matters, and how much of the detail they should ig-                                       The framework
nore. The inventories that human lexicons make use of are                 In order to acquire language, infants must undo various kinds
somewhere in between maximally coarse and maximally fine-                 of sub-phonemic variation present in the phonetics, segment
grained. For word segmentation, learners need to decide what              words from continuous utterances, and assign meaning to
to take as a lexical unit of speech: this could in principle be           these words. In this section, we explain how phonetic inven-
anywhere from a single segment up to an entire utterance, but,            tories, word segmentation, and semantics are operationalized
in reality, the result is somewhere in between.                           in this study.
   Whether learning is seen from a nativist or empiricist per-
spective, it cannot happen without some kind of learning bias             Corpora
(whether domain specific or domain general) which delimits
the hypothesis space, however broadly, and favors one repre-              We use two speech corpora: the Buckeye Speech corpus (Pitt,
sentation over another, however weakly (see Pearl and Gold-               Johnson, Hume, Kiesling, & Raymond, 2005), which consists
water (in press) for a review).                                           of 40 hours of spontaneous conversations with 40 speakers
   In this paper we propose a novel learning bias and show that           of American English, and the core of the Corpus of Spon-
it aids in picking out the right level of granularity for both the        taneous Japanese (Maekawa, Koiso, Furui, & Isahara, 2000)
segmental inventory and lexical segmentation. It makes use                which consists of 45 hours of recorded spontaneous conversa-
of the synergy between different levels of representation (in-            tions and public speeches in different fields, ranging from en-
ventory, lexicon, semantics). It takes a systemic approach to             gineering to humanities. Following Boruta (2012), we use an
language acquisition, whereby infants are understood as try-              inventory of 25 phonemes for transcribing Japanese. For En-
ing to build and optimize a coherent system with compatible               glish, we use the phonemic transcription of Pitt et al. (2005),
levels of representation.                                                 which consists of a set of 45 phonemes. We take these phone-
   Recent developmental studies have indeed begun to sug-                 mic transcriptions to give the ideal lexical inventories for the
gest that infants start learning both the sound system and the            two languages.
lexicon of their native language at the same time, around 6
                                                                          Phonetic variation
months (see Gervain and Mehler (2010) for a review). This
paper proposes that these two levels crucially interact in learn-         We generate alternate inventories for English and Japanese by
ing.                                                                      modifying the phonetic transcription of each corpus, starting
   The bias towards global coherence is coded by a measure                from the ideal (i.e., phonemic) transcription.
we call the self-consistency score (SC-score). It is used to                 To generate inventories smaller than the true inventory, we
evaluate a phonetic inventory and a word segmentation, as a               collapse the segments into 9 natural classes: stops, fricatives,
function of the predictiveness of the lexicon they induce. The            affricates, nasals, liquids, glides, high vowels, mid vowels and
lexicon should be one in which words are highly predictive of             low vowels; then, into 4 coarser-grained classes: obstruents,
                                                                      469

nasals, sonorants and vowels; and, finally, into only two seg-        chunks in the input, and uses them to parse novel utterances.
mental categories: consonants and vowels. We then rewrite             Ngon et al. (2013) have shown that infants indeed recognize
the corpus transcription using each of these alternate invento-       highly frequent n-grams (both words and non-words).
ries.                                                                    For this study, we use state-of-the-art algorithms from each
   To generate inventories larger than the true inventory (i.e.,      of these two families. On the boundary detection side, we use
with a finer grain than the phoneme), we use the same logic           the Diphone-Based Segmentation (DiBS: Daland and Pier-
as in Peperkamp, Le Calvez, Nadal, and Dupoux (2006) and              rehumbert, 2011); from the lexicon building side, we use
Martin, Peperkamp, and Dupoux (2013), and consider contex-            an Adaptor Grammar with a Unigram Model (AG: Johnson,
tual allophones. That is, a given segment is split into possibly      Griffiths & Goldwater, 2007). The input to these models con-
several allophones as a function of its left and/or right context     sists of a phonetic transcription of the corpus, with boundaries
as in Figure 1.                                                       between words eliminated (we vary this transcription to cor-
                                                                      respond to the different candidate inventories in both experi-
                                                                     ments below). The models try to reconstruct the boundaries,
                   [χ] before a voiceless consonant                   following their respective strategies.
         /ʁ/ →
                   [ʁ] elsewhere                                         For the evaluation, we use the same measures as Brent
                                                                      (1999) and Goldwater (2006), namely token Precision (P),
                                                                      Recall (R) and F-score (F). Precision is defined as the num-
           Figure 1: Allophonic variation of French /ʁ/
                                                                      ber of correct word tokens found, out of all tokens posited.
                                                                      Recall is the number of correct word tokens found, out of all
   In order to generate these allophones in a phonetically con-       tokens in the ideal segmentation. The F-score is defined as
trolled fashion, we follow Fourtassi, Schatz, Varadarajan, and        the harmonic mean of Precision and Recall:
Dupoux (2014) in using Hidden Markov Models (HMM).
   We convert the raw speech waveform of the corpora into                                             2∗P ∗R
                                                                                               F =
successive vectors of Mel Frequency Cepstrum Coefficients                                              P +R
(MFCC), computed over 25 ms windows, using a period of
10 ms (the windows overlap). We use 12 MFCC coefficients,             Semantics
plus the energy, plus the first and second order derivatives,         We use as the semantic representation of a word its frequency
yielding 39 dimensions per frame. Each state is modeled by            distribution over different documents (contexts). This sim-
a mixture of 17 diagonal Gaussians.                                   plified way of assigning meaning to words is known as Dis-
   The HMM training starts with one three-state model per             tributional Semantics. The idea can be traced back to Harris
(true) phoneme. Then, each phoneme model is cloned into               (1954): the meaning of a word can be inferred in part from its
context-dependent triphone models, for each context in which          context. For us, this is more than a simplifying assumption.
the phoneme actually occurs (for example, the phoneme /ɑ/             The SC-score we propose below uses only this contextual rep-
occurs in the context [d–ɑ–g] as in the word /dɑg/ (“dog”).           resentation. It is usable by a learner who has no referential
The triphone models were then retrained on only the relevant          semantic knowledge.
subset of the data, corresponding to the given triphone. Fi-             We chose one of the simplest and most commonly used dis-
nally, these detailed models were clustered back into artifi-         tributional semantic models, Latent Semantic Analysis (LSA:
cial inventories of various sizes (from 2 to 8 times the size of      Landauer & Dumais, 1997). The LSA algorithm takes as in-
the phonemic inventory) using a linguistic feature-based deci-        put a matrix consisting of rows representing word types and
sion tree. The HMM states of linguistically similar triphones         columns representing contexts in which tokens of the word
were tied together so as to maximize the likelihood of the data       type occur. A context is defined as a fixed number of utter-
(Young et al., 2006).                                                 ances. Singular value decomposition (a kind of matrix factor-
                                                                      ization) is used to extract a compact representation, in which
Word segmentation                                                     words and contexts can be represented as vectors smaller than
In the word segmentation literature, we can distinguish two           the original matrix (we call this reduced size the semantic di-
major types of algorithms, modeling two strategies infants            mension of the model). The cosine of the angle between vec-
might use to segment words from continuous speech. The                tors in the resulting space is used to measure the semantic sim-
first is boundary detection using transition probabilities (TP)       ilarity between words. Two words have a high semantic simi-
between pairs of phones. For example, the sequence [pd] oc-           larity if they have similar distributions, i.e., if they co-occur in
curs almost nowhere in the English lexicon, so the TP of [p]          most contexts. The model has two parameters: the dimension
and [d] is very low; [pd] thus likely signals a word boundary.        of the semantic space, and the number of utterances taken as
Empirical studies have shown that infants can use TP statistics       defining the context of a given word form.
in word segmentation (Saffran, Aslin, & Newport, 1996).
   The second strategy is lexicon building. Unlike the previ-                         The self-consistency score
ous strategy, where words are obtained as a mere byproduct            In this section, we introduce the self-consistency score. It
of boundaries, this strategy looks explicitly for reoccurring         takes as input a representation of the lexicon, including dis-
                                                                  470

                                 Figure 2: A schematic description of the SC-score computation
tributional semantic information, and outputs a score that re-        detection techniques, it is possible to use the distribution of
flects the global contextual informativity of the lexicon.            cosine distances across the entire list of word pairs to compute
                                                                      a Receiver Operating Characteristic curve (Fawcett, 2006),
Representation of the lexicon                                         from which one derives the area under the curve. The result-
The representation of the lexicon varies along two dimen-             ing score can be interpreted as the probability that, given two
sions: first, the segmentation that defines it. For example,          pairs of words, of which one is a pseudo-synonym pair, the
the utterance “the doggie is eating” (represented here ortho-         pairs are correctly identified based on cosine distance. This
graphically for readability) can lead to the following lexicons       is the SC-score. A value of 0.5 represents pure chance, and a
(among others): {the, dog, -ie, is, eat, -ing}, {the, doggie, is,     value of 1 represents perfect performance.
eating} (under the ideal segmentation) or {thedoggie, iseat-             When we split the tokens of a lexical item in two variants
ing}. Depending on the segmentation strategy, we may end              at random, these two variants (pseudo-synonyms) should still
up with an oversegmented or undersegmented lexicon (or a              have roughly the same distributions, leading to a high dis-
mix of both). Second, the segmental inventory on which it             tributional semantic similarity. The more consistent the dis-
is based. For example, the lexical item “cat” can have the            tribution, the higher the similarity between the two pseudo-
following representations: /CVC/, /kæt/, or /k2 æ1 t3 /. De-          synonyms, and the easier it gets to distinguish them from ran-
pending on how fine-grained the inventory is, some represen-          dom pairs. Intuitively, if a lexicon is coherent, it will have the
tations will be underspecified and some will be “overspeci-           property that it supports predicting a word from other words
fied.” In Experiment 1, we examine how these two dimen-               in its context.
sions interact.                                                          In Experiment 2, we examine how the SC-score allows us
                                                                      to select the optimal representation of the lexicon.
How the score is computed
Suppose we have a representation of the lexicon, i.e., a com-                       Experiments and discussion
bination of an inventory and a segmentation. Each item is, in
                                                                      Experiment 1: Interaction between variation and
addition, endowed with a distributional information (a vector
representing frequencies over contexts) as explained above.           segmentation
The self-consistency score operates at the distributional se-         As a prelude to our test of the SC-score, (Experiment 2), we
mantic level and examines the extent to which the distribution        explore how the sound inventory influences the outcome of
of items over different contexts is consistent. It is illustrated     the segmentation strategies, in order to check whether the gen-
schematically in Figure 2, and it is computed as follows.             eral strategy is valid. We want to see whether optimizing one
   First, for each representation, we generate a pseudo-              part of the representation can lead to better results for another
synonym corpus, (PS-corpus), where each word is randomly              part. In Figure 3, we show the token F-scores under differ-
replaced by one of two lexical variants. For example, the             ent inventories. The F-score is computed by comparing the
word dog is replaced in the PS-corpus by dog1 or dog2 . In            segmentation under a given inventory with the ideal segmen-
the derived corpus, each word that occurs at least twice is du-       tation under the same inventory. It shows that both segmenta-
plicated, and each variant appears with roughly half of the           tion strategies are optimal for the phonemic inventory. Their
frequency of the original word.                                       performance drops for both finer- and coarser-grained inven-
   Second, we perform a same–different task: a pair of words          tories.
is selected at random from the derived corpus, and the task              The token F-score, however, penalizes over- and under-
is to decide whether the two are variants of each other or not        segmentation equally. In order to explore the kind of errors
based (only) on their cosine distances. Using standard signal         made by the segmentation algorithm, we compared the bound-
                                                                  471

ary precision (number of correct boundaries found, out of all                          the phonetic level. However, the information about the seg-
boundaries posited) and recall (the number of correct bound-                           mentation performance was based on the comparison with the
aries found, out of all boundaries in the ideal segmentation).                         ideal segmentation. In this experiment, we go a step further
If the precision is higher than the recall, then the algorithm                         in our reasoning: we test whether moving to a higher level of
has a tendency to under-segment; if precision is lower than re-                        representation can offer an unsupervised alternative.
call, the algorithm has a tendency to oversegment (Goldwater,                             Each representation of the lexicon corresponds to a corpus
2006). To give an intuitive sense of why this is the case, con-                        transcribed with a phonetic inventory and segmented using
sider the segmentation of the utterance: /ðə dɑg/ (“the dog”).                         one of the segmentation algorithms. To evaluate a represen-
The extreme oversegmentation corresponds to the case where                             tation, we generate a PS-corpus (as described in the previous
the algorithm considers there to be a boundary between each                            section) and apply the LSA model to derive the distributional
pair of phones: /ð ə d ɑ g/. The boundary precision of this seg-                       semantic space, in which each word is represented by a vec-
mentation is very low, and the boundary recall is maximal.                             tor corresponding to the distribution of its tokens over the rel-
                                                                                       evant dimensions (which could be seen as topics). Next, we
                                                                                       derive the matrix of distributional semantic distances between
                               Eng                         Jap
                                                                                       all pairs of words in the lexicon. Finally we compute the
 Tokens Fscore
                   0.5
                   0.4                                                                 SC-score based on this matrix (Figure 2). The LSA was per-
                   0.3                                                                 formed using the software Gensim (Řehůřek & Sojka, 2010).
                   0.2
                   0.1                                                                    Note that the SC-score depends on the LSA parameters:
                   0.0
                                     0                           0
                                                                                       the size of the context and the dimensions of the semantic
                         10   25                      10   25
                              45   10                      45    10   seg              space. We thus test the robustness of the score when we vary
                                          Variation
                                                                            AG         these parameters. For each representation of the lexicon, we
                                                                            DiBS
                                                                                       compute different SC-scores for values of context size rang-
                               Eng                         Jap
 Bound. Prec−Rec
                   1.0                                                                 ing from 10 and 100 utterances, and for semantic space di-
                   0.5
                                                                                       mensions ranging from 10 to 200 dimensions (Fourtassi and
                                                                                       Dupoux (2013) showed that the performance of LSA tends to
                   0.0
                                                                                       level out after about 200 dimensions).
             −0.5
                                     0                            0
                                                                                          In addition to DiBS and AG, we consider a random segmen-
                         10   25
                                     10               10   25
                                                                 10
                              45                           45
                                                                                       tation and the ideal (gold) segmentation as controls. Figure 4
                                          Variation
                                                                                       shows the SC-score as a function of the inventory and the seg-
                                                                                       mentation. For a given segmentation, the score peaks around
                              Figure 3: Segmentation scores                            the phonemic inventory of the language (45 in English and 25
                                                                                       in Japanese). The absence of such a peak in the random seg-
   We show in Figure 3 the difference between precision and                            mentation demonstrates that the result is not a mere artifact of
recall (precision − recall) as a function of the level of phonetic                     the way the phonetic inventories were generated, but, rather,
variation. We find an interesting interaction between variation                        a consequence of the way this variation affects the semantic
and segmentation strategy. Variation seems to cause the AG to                          representation of the lexicon.
undersegment less and less in the range of variation that we are                          When the inventory is small, the lexicon is less consistent,
considering, and the general pattern points towards overseg-                           since it has more homophones. In an inventory composed of
mentation with more variation. For DiBS, on the other hand,                            coarse-grained natural classes, two words that have orthogo-
the pattern moves from oversegmentation to undersegmenta-                              nal semantics, like /kæt/ and /bæg/, will be treated as tokens of
tion as soon as the inventory becomes finer than the phonemic                          the same type, since all the consonants belong to the class of
representation. The reason for the first pattern is that larger                        stops. This type will not have a consistent distribution, since
inventories increase the number of word forms, which each                              it occurs in contexts that are not necessarily semantically re-
occur, therefore, with lower frequency. Consequently, the lex-                         lated. The smaller the inventory is, the more homophones
icon building algorithm will posit as “words” smaller chunks,                          will be created, and the less informative word-level context
which still occur with reasonable frequency. As for the second                         will be.
pattern, for a given pair of phones, the boundary probability                             Larger inventories increase the number of types, which
drops as the inventory size increases. Consequently, many                              therefore occur with lower frequency. This makes the con-
pairs that would otherwise be above the boundary threshold,                            textual representation less informative. The case of extreme
will drop below it, leading to undersegmentation for DiBS.                             variation leads to a token/type ratio inferior to 3 in the English
                                                                                       corpus (compared to 30 in the phonemic inventory) and a ra-
Experiment 2: Evaluation of the lexicon                                                tio inferior to 6 in the Japanese corpus (as compared to 33 in
representations                                                                        the phonemic inventory). Ratios of this order of magnitude
In the previous experiment, we showed that the quality of the                          are evidently not sufficient to build a predictive lexicon.
lexicon can be used to choose the right amount of variation at                            For a given inventory, the SC-score distinguishes between
                                                                                 472

                                       Eng                                               Jap
                                                             0.8                                                    Seg
     Self Consistency
                        0.7
                                                                                                                          AG
                                                             0.7                                                          DiBS
                                                                                                                          Gold
                        0.6
                                                                                                                          Rand
                                                             0.6
                        0.5
                              2   10   25   45   20                  2              10      25   45         20
                                                    0                                                          0
                                                        Variation
Figure 4: Self-consistency scores across different phonetic inventories and different word segmentations. The points show the
mean score over different parameter settings. The lines are smoothed interpolations (local regressions) through the means. The
                                         grey band shows a 95% confidence interval.
random, ideal, and intermediate-quality segmentations. Note              ideal-size as a fixed effect, and with segmentation model and
that we obtain this result without making use of the ideal seg-          language as random effects (intercepts and slopes) gives an
mentation as in Experiment 1. For random segmentation the                estimated increase of 0.200 (logit scale) for ideal-sized ver-
reason is apparent: the distribution of a type across contexts           sus next-coarser (p = 5 × 10−5 ); of 0.168 for ideal-sized
will clearly not be consistent. The reason the ideal segmen-             versus next-finer (p = 5 × 10−10 ); and 0.350 for ideal-sized
tation leads to a better score as compared to the output of              versus all other runs (mean, N = 10000; geometric mean
the segmentation algorithms is that oversegmentation and un-             p = 3 × 10−8 ). Similarly, we confirm improvements for
dersegmentation both change the token/type ratio. The ex-                AG versus random segmentation (0.896, p < 2 × 10−16 );
treme case of undersegmentation corresponds to taking each               DiBS versus random (0.728, p < 2 × 10−16 ); gold ver-
utterance as a word; the chances of a whole utterance being              sus AG (0.412, p < 2 × 10−16 ); gold versus DiBS (0.527,
repeated enough times to lead to an informative and consis-              p < 2 × 10−16 ).
tent distribution are very small. Conversely, the extreme case              Thus, the SC-score enables us to select the right represen-
of oversegmentation corresponds to taking each phone as a                tation (for instance, the size of the segmental inventory and
word. As in the case of extreme homophony, this leads to                 the size of the lexicon) without any hyperparameter tuning.
a very small lexicon with technically an uninformative (flat)
distributional over contexts.                                                                     Conclusion
   Figure 4 also indicates that the utility of the SC-score in           We have introduced a learning bias that provides a potential
picking out the best representation for the lexicon is largely           guide for infants during language acquisition. The SC-score is
independent of the parameter settings (the confidence bands              not a learning algorithm: it does not account for how a repre-
are over runs with different parameter settings). Statistical            sentation is built. Here, learning is stated statically, abstract-
tests confirm this. For the inventory size, three (general-              ing away from the actual learning procedure, as in the “eval-
ized) linear models confirm that the ideal (phonemic) inven-             uation measure” approach to language acquisition (Chomsky,
tory is the peak: the ideal inventory runs versus the next most          1965). Thus it should be seen as an inductive bias in that it
coarse-grained inventory (9 categories, for both English and             provides a criterion for ranking different candidate represen-
Japanese); ideal inventory versus the next most fine-grained             tations. The simplifying assumption being made here is that
inventory (100 for English, 50 for Japanese); and the ideal in-          all the representations are consistent with the data from the
ventory runs versus all the other runs (in that case, refitting          infant’s perspective. As such, the SC-score corresponds to a
the model many times, undersampling the non-ideal runs uni-              “prior probability” in the Bayesian framework (Jaynes, 2003),
formly each time to get balance in the two groups). A general-           operating in a space of hypotheses, where a hypothesis is de-
ized linear model (logit link) on SC-score with ideal-size/non-          fined as a representation of the lexicon (as defined in section
                                                                   473

2) associated with a distribution over contexts.                     Gervain, J., & Mehler, J. (2010). Speech perception and lan-
   The philosophy of the bias is that infants are learning and         guage acquisition in the first year of life. Annual review of
optimizing an entire system, rather than optimizing different          psychology, 61, 191–218.
sub-levels in isolation. Thus, a representation at one level is      Goldwater, S. (2006). Nonparametric bayesian models of lex-
constrained by the extent to which it is compatible with other         ical acquisition (Unpublished doctoral dissertation). Brown
levels, like pieces of a puzzle.                                       University.
   We assume that language acquisition is driven by the need         Harris, Z. (1954). Distributional structure. Word, 10(23),
to make sense of the input, the selection pressure coming from         146–162.
the process of extracting meaning. The quality of a repre-           Jaynes, E. T. (2003). Probability theory: The logic of science.
sentation is measured by the informativeness of context when           Cambridge University Press.
that representation is used. We have operationalized this us-        Johnson, M., Griffiths, T. L., & Goldwater, S. (2007). Adap-
ing a measure we call self-consistency, which applies to the           tor grammars: a framework for specifying compositional
lexicon. We found our method to disfavor both over-fine and            nonparametric bayesian models. In B. Sch”olkopf, J. Platt,
over-coarse hypotheses, based, strikingly, on a purely intrin-         & T. Hoffman (Eds.), Advances in neural information pro-
sic criterion having nothing to do with phonology per se. We           cessing systems 19 (pp. 641–648). Cambridge, MA: MIT
found optimal SC-scores for the true phonemic inventories              Press.
and the ideal word segmentations of two typologically dif-           Landauer, T. K., & Dumais, S. T. (1997). A solution to Plato’s
ferent languages: English and Japanese. We also found the              problem: The latent semantic analysis theory of the acqui-
SC-score to be independent of the parameter setting to a large         sition, induction, and representation of knowledge. Psycho-
extent, and to operate with minimal, if any, external supervi-         logical Review, 104, 211–240.
sion.                                                                Maekawa, K., Koiso, H., Furui, S., & Isahara, H. (2000).
                                                                       Spontaneous speech corpus of japanese. In LREC. Athens,
                    Acknowledgments                                    Greece: European Language Resources Association.
                                                                     Martin, A., Peperkamp, S., & Dupoux, E. (2013). Learning
This work was supported in part by the European Research               phonemes with a proto-lexicon. Cognitive Science, 37(1),
Council (ERC-2011-AdG-295810 BOOTPHON), the Agence                     103-124.
Nationale pour la Recherche (ANR-10-LABX-0087 IEC,                   Ngon, C., Martin, A., Dupoux, E., Dominique, C., Dutat,
ANR-10-IDEX-0001-02 PSL*), the Fondation de France, the                M., & Peperkamp, S. (2013). (non)words, (non)words,
Ecole de Neurosciences de Paris, and the Région Ile de France          (non)words: evidence for a protolexicon during the first
(DIM cerveau et pensée).                                               year of life. Developmental Science, 16(1), 24–34.
                                                                     Pearl, L., & Goldwater, S. (in press). Statistical learning,
                          References                                   inductive bias, and bayesian inference in language acquisi-
                                                                       tion. In J. Lidz (Ed.), Oxford handbook of developmental
Boruta, L. (2012). Indicateurs d’allophonie et de phonémic-            linguistics. Oxford University Press.
   ité (Doctoral dissertation). Université Paris-Diderot - Paris     Peperkamp, S., Le Calvez, R., Nadal, J.-P., & Dupoux, E.
   VII.                                                                (2006). The acquisition of allophonic rules: Statistical
Brent, M. R. (1999). An efficient, probabilistically sound             learning with linguistic constraints. Cognition, 101(3),
   algorithm for segmentation and word discovery. Machine              B31–B41.
   Learning, 34(1-3), 71-105.                                        Pitt, M. A., Johnson, K., Hume, E., Kiesling, S., & Ray-
Chomsky, N. (1965). Aspects of the theory of syntax. Cam-              mond, W. D. (2005). The buckeye corpus of conversational
   bridge, MA: MIT Press.                                              speech: labeling conventions and a test of transcriber relia-
Daland, R., & Pierrehumbert, J. B. (2011). Learning diphone-           bility. Speech Communication, 45(1), 89-95.
   based segmentation. Cognitive Science, 35(1), 119-155.            Řehůřek, R., & Sojka, P. (2010, May 22). Software Frame-
Fawcett, T. (2006). An introduction to ROC analysis. Pattern           work for Topic Modelling with Large Corpora. In Proceed-
   Recogn. Lett., 27(8), 861–874.                                      ings of the LREC 2010 Workshop on New Challenges for
Fourtassi, A., & Dupoux, E. (2013). A corpus-based eval-               NLP Frameworks (pp. 45–50). Valletta, Malta: ELRA.
   uation method for distributional semantic models. In 51st         Saffran, J., Aslin, R., & Newport, E. (1996). Statisti-
   Annual Meeting of the Association for Computational Lin-            cal learning by 8-month-old infants. Science, 274(5294),
   guistics Proceedings of the Student Research Workshop (pp.          1926–1928.
   165–171). Sofia, Bulgaria: Association for Computational          Young, S. J., Kershaw, D., Odell, J., Ollason, D., Valtchev,
   Linguistics.                                                        V., & Woodland, P. (2006). The HTK Book Version 3.4.
Fourtassi, A., Schatz, T., Varadarajan, B., & Dupoux, E.               Cambridge University Press.
   (2014). Exploring the Relative Role of Bottom-up and Top-
   down Information in Phoneme Learning. In Proceedings of
   the 52nd Annual Meeting of the Association for Computa-
   tional Linguistics.
                                                                 474

