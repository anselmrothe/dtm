UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Asking for Help from a Gendered Robot
Permalink
https://escholarship.org/uc/item/3w70h4t9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Alexander, Emma
Bank, Caroline
Yang, Jie Jessica
et al.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                      Asking for Help from a Gendered Robot
                 Emma Alexander, Caroline Bank, Jie Jessica Yang, Bradley Hayes, Brian Scassellati
                                             Department of Computer Science, Yale University
                                                    51 Prospect St, New Haven, CT 06511
                     {caroline.bank,emma.alexander,jiejessica.yang,bradley.h.hayes,brian.scassellati}@yale.edu
                               Abstract                                  (Lattner, Meyer, & Friederici, 2005; Decasper & Prescott,
                                                                         1984).
   This project investigates the effects of gender in a human-robot         After interacting with a robot, people will often bring up
   collaboration interaction. In the experiment, participants com-
   pleted four Sudoku-like puzzles with a robot from which they          comments on robot gender unprompted, demonstrating that
   could verbally elicit help. The robot was given the gendered          its strength as a social cue is still highly relevant (Carpenter et
   characteristics of a gendered computer generated voice and ei-        al., 2009). In another study, participants used more complex
   ther the name Charlotte (female condition) or Charley (male
   condition). Contrary to expectations from psychology, male            language when describing the stereotypically female domain
   participants asked the robot for help more frequently regardless      of relationships to a female robot than a male robot (Powers
   of its assigned gender. Participants of both genders reported         et al., 2005). Men have also been shown to be more will-
   feeling more comfortable with a robot assigned the other gen-
   der and preferred the male robot’s help. Findings indicate            ing to make donations when asked by a female robot (Siegel,
   that gender effects can be generated in human-robot collab-           Breazeal, & Norton, 2009). This study also demonstrated that
   oration through relatively unobtrusive gendering methods and          after the interaction, participants saw robots of the other gen-
   that they may not align with predictions from psychology.
                                                                         der as more credible, trustworthy, and engaging, indicating
                                                                         an other-gender preference in the case of a robot asking a
                           Background                                    human for a help. It has been found that in particular situ-
Gender effects are present and well-studied in human-human               ations, people prefer interaction with an other-gender robot
interaction and collaboration. When presented with the de-               (Park, Kim, & del Pobil, 2011) and will consider a robot dis-
scription of a potential helper, men have been seen to be more           playing other-gender characteristics more attractive, interest-
likely to seek help from a woman than from a man (Nadler,                ing, and trustworthy than one displaying same-gender char-
Maler, & Friedman, 1984). On the other hand, mixed-gender                acteristics (Siegel et al., 2009). In many studies, gender was
groups working on collaborative computer-based tasks ex-                 conferred to the robot using only a single, relatively subtle
hibit less collaborative behavior (Collazos, Guerrero, Llana,            cue: a gendered name and introduction (Nomura & Takagi,
& Oetzel, 2002) and lower performance (Underwood, Mc-                    2011), voice modulation (Siegel et al., 2009), a combination
Caffrey, & Underwood, 1990) than same-sex groups in iden-                of the two (Crowelly, Villanoy, Scheutzz, & Schermerhornz,
tical circumstances. Women were also more likely to seek                 2009), or voice modulation accompanied by variation in lip
help in general (Nadler et al., 1984). Women and men also                color (Powers et al., 2005). These results indicate that even
show differences in asking for help from attractive versus               with limited gender cues behavioral responses can be elicited
unattractive members of the same or different gender (Nadler,            from humans by robotic stimulus. This study explores the
Shapira, & Ben-Itzhak, 1982). These effects also carry over              shaping of perceptions within the specific case of a human
to perceived helpfulness: Menzel and Carrell (1999) found a              seeking help from a gendered robot collaborator.
strongly mediated but nonetheless significant effect on per-
ceived learning where students believed they learned more                                            Methods
when taught by a professor of the same gender.                           To study gender effects on human-robot collaboration we de-
   Existing literature suggests that helpfulness is not the only         signed a 2x2 study on robot and participant gender. Robot
quality that people perceive through a lens of gender. In                gender was assigned with a name/pronoun cue and a voice
1968, Rosenkrantz et al found that over 75% of participants              cue. Past studies have shown that these cues alone are suffi-
of both genders associated a number of attributes to one gen-            ciently strong to elicit a gender response. Changes in appear-
der or the other. In particular, participants associated compe-          ance were avoided as they could confound results. We picked
tence, dominance, independence, and logic with males, and                a puzzle-based task because it provided a way for the robot
emotion, subjectiveness, submission, and tact with females               to contribute to the participant’s success while allowing the
(1968). These stereotypes were reaffirmed in a survey by                 variety of interaction to be limited, ensuring that participants
Hosoda and Stone (2000). Biernat and Kobrynowicz found                   shared a standard experience. The puzzle chosen was sudoku,
that these biases can affect other behavior, as subjects that            with the numbers 1-9 replaced with the letters A-I so that both
were asked to evaluate candidates in a mock job interview                analytical and verbal skills would be indicated and the robot
setting rated woman and minorities against a lower standard              perception would not be affected by stereotypes of numeri-
for baseline competence but more stringent standards for high            cal intelligence. Participants were given four puzzles in or-
levels of competence (1997; 2010). Even gendered voices                  der of increasing difficulty to control for differences in their
with no other stimuli evoke different responses in the brain             previous experience with the activity. Each puzzle was in-
                                                                     2333

                        (a) Sample puzzle, unsolved                                 (b) Sample puzzle, solved
                            Figure 1: An example of the puzzles participants were to solve with the robot.
tentionally allotted a shorter time period than was needed for         Participants each completed four puzzles with the robot.
completion to encourage interaction with the robot. During          Each trial (puzzle) was limited to five minutes, and partic-
each puzzle, researchers tallied the number of help requests        ipants were told to begin and end work upon verbal cues
from each participant. Additionally, participants were asked        from the robot. The starting cue was “Hi, my name is
to rate the robot on a number of qualities (trustworthiness,        Charley/Charlotte. Let’s work together” for the first puzzle
intelligence, etc.) to further characterize the interaction.        and “I have received the puzzle. Let’s get started” for the re-
                                                                    maining three puzzles. The robot was remotely operated by
Hypotheses                                                          the experimenter based on audio monitoring of the interac-
• H1 Women would ask more questions of the robot than               tion. For responding to participant queries, the experimenter
   men, regardless of robot gender.                                 was able to select from the following phrases:
• H2 Participants of both genders would ask more questions          • I think so
   of a robot assigned the opposite gender.
                                                                    • I don’t think so
Procedure
                                                                    • There is/are [number] minutes remaining
Participants were presented with an entrance survey and a
warm-up puzzle as an introduction to the task. They were told
by the experimenter that the purpose of the study was to aid        • I think there is a [letter] in square [coordinates]
development of robots for use in human-robot collaboration
in puzzle solving. They were then introduced to the robot and       If the participant asked a question that could not be answered
told that it had been developed to collaborate with humans on       with one of these phrases, the robot would respond with “I
the task. Participants were informed that the robot could not       don’t know how to answer that”. The robot also automati-
see, but that it could speak and hear and that the experimenter     cally informed the participant when one minute remained in
would be “downloading” the puzzle to the robot.                     each trial, and at the end of each trial with the phrase “time is
                                                                    up”. Before speaking, the robot moved its body down, tilted
   The task used in this experiment was a set of Sudoku puz-
                                                                    forward, and paused for two seconds to emulate thinking. At
zles over the letters A through I instead of the conventional
                                                                    the end of each trial, the experimenter returned and adminis-
numbers 1 through 9. The puzzle is a 9x9 grid into which
                                                                    tered a brief survey.
each of the letters must be placed so that each letter appears
in every row, column, and 3x3 square once. The grid’s rows
                                                                    Participants
were labelled with the letters A through I and its columns
were numbered 1 through 9. This system was explained to             The 48 participants used in this study were members of the
the participants as a way to communicate with the robot, for        Yale community (24 female and 24 male). Data were col-
example referring to the upper-left cell in a puzzle as “square     lected over a 12-week period. Participants were compensated
A1.”                                                                for their time with entry into a gift card lottery.
                                                                2334

                         (a) Keepon Pro robot                                          (b) Experimental setup
                         Figure 2: The robot platform and experimental environment used in our study.
Robot
                                                                         Participant Gender     Robot Gender      Mean      SD
The robot used in this study was a Keepon, seen in Figure 2a.            F                      F                 -2.958    1.994
Keepon is a small, yellow robot that has previously been used                                   M                 -4.25     1.994
to study human-robot interaction (Kozima, Michalowski, &                 M                      F                 -5.333    1.994
Nakagawa, 2009). The robot sits on a stationary platform and                                    M                 1.083     1.994
has four degrees of freedom allowing it to rotate on the plat-
form, tilt backwards and forwards, lean sideways, and bounce
up and down. It has cameras in its eyes and a microphone in          Table 1: Difference between participants’ estimated number
its nose.                                                            of requests and actual number of requests on the first puzzle
Conditions
                                                                     7-point Likert-scale questions in addition to several free-
Each participant was randomly assigned to either the female
                                                                     response questions.
or male robot experimental group upon arrival. This, plus
participant gender, created four experimental groups: male-
participant/female-robot (M/F), female-participant/female-
                                                                                                 Results
robot (F/F), male-participant/male-robot (M/M), and female-          Data were collected from 48 participants, 12 in each condi-
participant/male-robot (F/M). The experimenter referred to           tion. Participant scores were calculated by totaling the num-
the robot as “Charlotte” in the female robot conditions and          ber of correctly placed letters in each puzzle at the end of the
as “Charley” in the male robot conditions. This name change          trial time. There was no significant effect of either participant
was reflected in the experimental surveys, which also referred       gender (F(1,44) = .023, p = 0.881) or robot gender (F(1,44) =
to the robot by the appropriate gendered pronoun. The gen-           1.479, p = .230) on this measure of task performance. A two-
dering was reinforced by the choice of the robot’s computer          way analysis of variance found a borderline significant effect
generated voice: Mac OS X’s “Vicki” for the female robot             of participant gender on the number of successful interactions
and “Alex” for the male robot.                                       (F(1,44) = 3.263, p = .078, Female participants: M = 58.125,
                                                                     sd = 5.725, Male participants: M = 72.750, sd = 5.725) and
Measures                                                             a significant effect of gender on the number of failed interac-
The experimenter operating the robot recorded the number             tions(F(1,43) = 6.836, p=.012, Female participants: M = .750,
of successful and failed interactions between the participants       sd = .304, Male participants: M = 1.875, sd = .304) initiated
and the robot. Failed interactions were defined as any inci-         with the robot. In the exit survey, participants were asked
dents of participants asking questions that necessitated the “I      for an estimate of how many times they asked the robot for
don’t know how to answer that” response, with successful in-         help during each puzzle. There was a borderline significant
teractions defined as any other incidents of participants asking     participant gender-robot gender interaction on the difference
questions. The puzzles were also scored and recorded. The            between this measure and the actual number of requests for
surveys completed after the first, second, and third puzzles         the first puzzle. A summary of this result can be found in
contained five 7-point Likert-scale questions on the robot’s         Table 1. The participant gender effect on number of inter-
perceived intelligence, competence, helpfulness, trustworthi-        actions may have resulted in a different experience for male
ness, and likability. The fourth survey contained seventeen          participants versus female participants. To account for this
                                                                 2335

                  7                                                                                                                    1
                                                               Female Robot                                                                                                      Female Robot
                                                                                     Proportion of Correctly Gendered Pronoun Usage
                                                               Male Robot                                                             0.9
                  6                                                                                                                                                              Male Robot
                                                                                                                                      0.8
                  5                                                                                                                   0.7
                                                                                                                                      0.6
                  4
        Comfort
                                                                                                                                      0.5
                  3
                                                                                                                                      0.4
                  2                                                                                                                   0.3
                                                                                                                                      0.2
                  1
                                                                                                                                      0.1
                  0                                                                                                                    0
                          Male                        Female                                                                                Male                        Female
                                 Participant Gender                                                                                                Participant Gender
                      (a) Adjusted mean ratings of comfort.                     (b) Adjusted mean proportion of correctly-gendered pronoun use.
Figure 3: The above are plots of adjusted means calculated by performing analyses of covariance using total successful inter-
actions and total failed interactions as covariates
difference, all further analysis was performed controlling for                                                                                         Discussion
both measures. An analysis of covariance with robot gender
and participant gender and between-subjects with the number                      In this experiment, participants were asked to engage in puz-
of failed interactions and number of successful interactions as                  zle solving with a characteristically gendered robot. It re-
covariates found a significant interaction between participant                   mains unclear whether the results found were driven by a
and robot gender interaction on ratings of comfort with the                      gender bias or by reactions to the specific ways the robot’s
robot (F(1,42) = 6.590, p = .014). Mean ratings of comfort                       gender was manipulated. It is possible, for instance, that the
by both groups of participants were higher for the robot of                      differences found were differing reactions to the computer-
the opposite gender - a plot of adjusted means can be found                      generated voices chosen. Furthermore, previous research has
in Figure 3a. A further analysis of covariance found a that                      found that people tend to identify robots as either genderless
participants rated their preference for working with the robot                   or male (Shin & Kim, 2007). It must be noted that age and
over a human partner as higher for the male robot than for the                   culture differences may make Shin’s result inapplicable to the
remale robot (F(1,42) = 12.347, p = .001, Female robot: ad-                      demographic targeted here since his participants were Korean
justed mean = 3.657, sd = .373, Male robot: adjusted mean =                      schoolchildren rather than American young adults. However,
5.412, sd = .373). In the exit survey, participants were asked                   in the absence of a comparable study performed at an Amer-
to give answers to five free response questions, four of which                   ican university this result is the closest we have to a charac-
pertained to their feelings towards the robot. These responses                   terization of robot gender assumption. Then we expect that
were scored for gendered pronoun usage. The generic pro-                         if a participant identifying a robot as male was confronted by
nouns it and its were scored as ‘non-gendered’, she and her                      the female voice and naming given to Charlotte, it is possi-
were scored as ‘correctly-gendered’ for participants who in-                     ble that the dissonance between their perception of the robot
teracted with Charlotte and ‘cross-gendered’ for participants                    and its gendered characteristics may have made the robot a
who interacted with Charley. He and him were scored as                           less desirable partner. This effect may have been particu-
‘cross-gendered’ for participants who interacted with Char-                      larly present for male participants who worked with the fe-
lotte and ‘correctly-gendered’ for participants who interacted                   male robot, who on average referred to the female robot as
with Charley. Only a single participant (in the ‘M/F’ con-                       ‘it’ more frequently in proportion to gendered pronouns than
dition) used cross-gendered pronouns. However, there was                         men with a male robot or women with either robot gender.
a borderline significant interaction of robot gender and par-                       Contrary to our first hypothesis (H1), male participants ini-
ticipant gender on the proportion of total pronouns used that                    tiated more interactions with the robot than female partici-
were ‘correctly-gendered’. A plot of the adjusted means can                      pants. This stands in contrast with previous research in psy-
be found in Figure 3b.                                                           chology that has found men less willing to ask humans for
                                                                                 help. Results from psychology support the notion that men
                                                                                 are more comfortable with novel technology than women are,
                                                                                 an effect that has been confirmed in the domain of human-
                                                                                 robot interaction (Carpenter et al., 2009). This may have in-
                                                                              2336

fluenced their willingness to ask the robot for assistance. At       in what way the female robot was perceived as comparatively
the same time, female participants rated themselves as liking        less desirable. There were no significant effects of robot gen-
the robot of both genders at a higher level than male partic-        der on the related ratings of liking and the robot’s ability
ipants at a borderline significant level(F(1,42) = 3.466, p =        to solve the puzzle. Further study is required to determine
.070, Female participants: M = 5.726, sd = .280, Male par-           whether this preference was due to the robot’s perceived so-
ticipants: M = 4.941, sd = .280). This may have been be-             cial abilities, task-solving abilities, or other factors.
cause while male participants felt more comfortable asking
for assistance, this asking inspired negative feelings towards                                 Conclusion
the robot. It is also possible that within the framework of          In this experiment we presented participants with a series of
the experiment, the interactions were not perceived as asking        puzzle-based tasks and a robot partner to assist them. This
for help. One participant referred to the robot as an “answer        robot was assigned a gender through seemingly unobtrusive
key” either because of the nature of the questions asked or          cues: name and voice modulation. Contrary to expectations
a lack of agency attributed to the robot. If participants saw        based on psychological literature, male participants engaged
themselves as using the robot rather than interacting with it,       in more help-seeking interactions with the robot than did fe-
we would expect the results from the human-robot interaction         male participants, perhaps because of the effectiveness of
literature to dominate the effects predicted from collaboration      the help, which has been shown to influence men’s technol-
psychology.                                                          ogy usage more than that of women(Venkatesh & Morris,
   Contrary to our second hypothesis (H2), we did not find           2000). Also in contrast with psychology literature, we did
that participants were more likely to ask for help from a robot      not find that participants asked more questions of a robot of
assigned the opposite gender. However, participants interact-        the other gender, but participants did report that they were
ing with a robot of the opposite gender on average rated the         more comfortable with the robot in that case. Participants
robot as making them feel more comfortable. This comfort             of both gender reported a preference for working with the
may have stemmed from a number of different aspects of the           male robot, though it is unclear if this is an effect of gen-
interaction. Given that the participants were prompted to ask        der or the specifics of how the robots were gendered. Over-
the robot for help, this result might reflect their comfort in       all, these results indicate that human-robot interactions can
seeking assistance from the robot. This would support previ-         be significantly affected by fairly subtle gender cues, and that
ous research that found men to be more willing to ask for help       these effects may not be reliably predictable from studies of
from women and vice versa, and with studies that show more           human-human interactions. Because our results more closely
positive interactions with robots of the other gender (Siegel        mirrored those from other kinds of human-robot interactions
et al., 2009; Park et al., 2011; Powers et al., 2005). It is         than those of human collaborations, we suspect that a task
also possible that participants were more comfortable with           with expanded opportunity for collaboration, which was re-
the different computer voice, or simply from interacting with        quested by many participants, may foster interactions which
a different-gendered robot.                                          more closely match psychological results. However, the re-
   Both of our hypotheses, based on previous study of human-         quired range of possible interactions would make it difficult
human collaboration, were incorrect. Our results were, how-          to ensure standardization or even similarity of participant ex-
ever, supported by studies of non-collaborative human-robot          perience.
interaction, which suggests that the type of the interaction is
less important than the type of interactive partner. On the                                Acknowledgments
other hand, psychological effects may have played a role in          This work is supported by NSF grants 1139078 and 1117801,
the perception of the interaction. This could explain why            and Office of Naval Research grant #N00014-12-1-0822. We
men underestimated the number of questions they had asked            thank the anonymous reviewers for their helpful comments.
the female robot and overestimated the number of requests
to the male robot. This means that within the domain of                                        References
each interaction, psychology literature cannot predictably be        Biernat, M., Fuegen, K., & Kobrynowicz, D. (2010). Shifting
applied to gendered interactions with robots and when mul-              standards and the evaluation of competence: Complexity in
tiple social factors are involved, as in this experiment, the           gender-based judgment and decision making. Personality
behaviors and perceptions of participants must be measured              and Social Psychology Bulletin, 36(7), 855-868.
rather than inferred from previous studies. Further research         Biernat, M., & Kobrynowicz, D. (1997). Gender- and race-
is needed to elucidate and confirm the gender characteristics           based standards of competence: Lower minimum standards
that evoke different reactions, and the social dynamics that            but higher ability standards for devalued groups. Journal of
underlie those differences.                                             Personal and Social Psychology, 72(3), 544-557.
   To complicate this picture, participants rated the male robot     Carpenter, J., Davis, J. M., Erwin-Stewart, N., Lee, T. R.,
more highly than the female robot for their agreement to the            Bransford, J. D., & Vye, N. (2009). Gender representation
statement “I would prefer working with Charlotte/Charley                and humanoid robots designed for domestic use. Interna-
over a human partner for this task.” However, it is unclear             tional Journal of Social Robotics, 1(3), 261–265.
                                                                 2337

Collazos, C., Guerrero, L. A., Llana, M., & Oetzel, J. (2002).       man interactive communication, 2007. ro-man 2007. the
  Gender: An influence factor in the collaborative work pro-         16th ieee international symposium on (p. 1040 -1045). doi:
  cess. Proceedings of the 4th International Conference on           10.1109/ROMAN.2007.4415235
  New Educational Environment (ICNEE 2002), 7-10.                  Siegel, M., Breazeal, C., & Norton, M. (2009, oct.). Persua-
Crowelly, C., Villanoy, M., Scheutzz, M., & Schermerhornz,           sive robotics: The influence of robot gender on human be-
  P. (2009). Gendered voice and robot entities: perceptions          havior. In Intelligent robots and systems, 2009. iros 2009.
  and reactions of male and female subjects. In Intelligent          ieee/rsj international conference on (p. 2563 -2568). doi:
  robots and systems, 2009. iros 2009. ieee/rsj international        10.1109/IROS.2009.5354116
  conference on (pp. 3735–3741).                                   Underwood, G., McCaffrey, M., & Underwood, J. (1990).
Decasper, A. J., & Prescott, P. A. (1984). Human newborns’           Gender differences in a cooperative computer-based lan-
  perception of male voices: Preference, discrimination, and         guage task. Educational Research, 32(1), 44-49.
  reinforcing value. Developmental Psychobiology, 17(5),           Venkatesh, V., & Morris, M. G. (2000). Why don’t men
  481-491.                                                           ever stop to ask for directions? gender, social influence,
Hosoda, M., & Stone, D. L. (2000). Current gender stereo-            and their role in technology acceptance and usage behavior.
  types and their evaluative content. Perceptual and Motor           MIS Quarterly, 24(1), 115-139.
  Skills, 90, 1283-1294.
Kozima, H., Michalowski, M. P., & Nakagawa, C. (2009).
  Keepon. International Journal of Social Robotics, 1(1), 3–
  18.
Lattner, S., Meyer, M. E., & Friederici, A. D. (2005). Voice
  perception: Sex, pitch, and the right hemisphere. Human
  Brain Mapping, 24(1), 11-20.
Menzel, K. E., & Carrell, L. J. (1999). The impact of gender
  and immediacy on willingness to talk and perceived learn-
  ing. Communication Education, 48(1), 31-40.
Nadler, A., Maler, S., & Friedman, A. (1984). Effects of
  helper’s sex, subjects’ androgyny, and self-evaluation on
  males’ and female’s willingness to seek and receive help.
  Sex Roles, 10(5-6), 327-339.
Nadler, A., Shapira, R., & Ben-Itzhak, S. (1982). Good looks
  may help: Effects of helper’s physical attractiveness and
  sex of helper on males’ and females’ help-seeking behav-
  ior. Journal of Personality and Social Psychology, 42(1),
  90-99.
Nomura, T., & Takagi, S. (2011). Exploring effects of ed-
  ucational backgrounds and gender in human-robot interac-
  tion. In User science and engineering (i-user), 2011 inter-
  national conference on (p. 24-29).
Park, E., Kim, K. J., & del Pobil, A. P. (2011, May). The ef-
  fects of robot’s body gesture and gender in human-robot
  interaction. In Proc. 2011 iasted international confer-
  ence on internet and multimedia systems and applications
  (ieee/hci). Washington, DC, USA.
Powers, A., Kramer, A., Lim, S., Kuo, J., lai Lee, S., &
  Kiesler, S. (2005, aug.). Eliciting information from peo-
  ple with a gendered humanoid robot. In Robot and human
  interactive communication, 2005. roman 2005. ieee inter-
  national workshop on (p. 158 - 163). doi: 10.1109/RO-
  MAN.2005.1513773
Rosenkrantz, P., Vogel, S., Bee, H., Broverman, I., & Brover-
  man, D. M. (1968). Sex-role stereotypes and self-concepts
  in college students. Journal of Consulting and Clinical
  Psychology, 32(3), 287-295.
Shin, N., & Kim, S. (2007, aug.). Learning about, from,
  and with robots: Students’ perspectives. In Robot and hu-
                                                               2338

