UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning a Motor Grammar of Iconic Gestures
Permalink
https://escholarship.org/uc/item/9kh3j9zr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Sadghipour, Amir
Kopp, Stefan
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                 Learning a Motor Grammar of Iconic Gestures
                                         Amir Sadeghipour (sadeghipour@uni-bielefeld.de)
                                            Stefan Kopp (skopp@techfak.uni-bielefeld.de)
                      Faculty of Technology, Center of Excellence ‘Cognitive Interaction Technology’ (CITEC),
                                   Bielefeld University, P.O. Box 100 131, D-33501 Bielefeld, Germany
                                Abstract                               mapped onto motor goals that are then refined into structured
   In this paper, we present a computational investigation into        motor programs and on to motor primitives (Mussa-Ivaldi
   the compositionality of iconic gestures by trying to learn a        & Solla, 2004). In line with this view, Flash and Hochner
   motor grammar. We propose a grammar formalism that learns           (2005) argued that our motor repertoire can be spanned by
   (1) the salient, invariant features of single movement segments
   (motor primitives) and (2) the hierarchical organization of         combining motor primitives according to syntactic rules. As
   these segments in complex gesturing. The formalism is               the motor system is also involved in the perception of ges-
   applied to a dataset of natural iconic gestures. The extracted      tures (Montgomery, Isenberg, & Haxby, 2007), this hierar-
   structure reveals compositional patterns of iconic gesturing.
                                                                       chical structure of motor knowledge should also guide the
   Keywords: gesture; motor program; probabilistic grammar             interpretation of communicative gestures. Against this back-
                                                                       ground, the question is (1) whether and how a compositional
                           Introduction                                and hierarchical motor structure can be identified in gestu-
An integral part of our communicative ability is to gesture, i.e.      ral movement and (2) how this may guide the comprehension
to perform expressive bodily actions as (part of) an utterance.        and production of iconic gestures with their global semiosis.
Gesturing has received much interest during the last decades                                                                                                 Wrists'
                                                                                    Performing way 1: Drawing with an index finger
and work in (Psycho-)Linguistics, Cognitive Psychology and                      size=big; projection=(x,y); repetition=1; start-position=low; v=fast; ...
                                                                                                                                                           movement
                                                                                                                                                          trajectories
Human-Computer Interaction has provided many models of
gesture production (e.g. Kopp, Bergmann, and Kahl (2013))
or gesture recognition (see Mitra and Acharya (2007) for
a survey). Most of these models focus either on the higher
cognitive processes (e.g., of multimodal conceptualization or               size=medium; projection=(x,z); repetition=2; start-position=high; v=slow;…
speech-gesture formulation) or on low-level vision-based per-
ception and recognition. Little is known about the sensory-               ...                                                              ...
motor representations that underlie and possibly shape those
cognitive processes during perception, interpretation and pro-
                                                                                                                       t
duction of gestural behavior.                                                                                                                                Wrists'
                                                                              Performing way 2: Drawing with two hands synchronously
   We focus on natural iconic gestures, which are sponta-                   size=big; projection=(x,y); repetition=1; direction=bottom-up; v=medium; ...
                                                                                                                                                           movement
                                                                                                                                                          trajectories
neously and extemporaneously performed in communication
to refer to objects or events by depicting visual-spatial as-
pects. As illustrated in Figure 1, spontaneous iconic gestur-
ing exhibits a very large variability even when performed for
the same object. Extracting the communicative significance                 size=medium; projection=(x,y); repetition=1; direction=top-down; v=slow; …
of an iconic gesture thus involves (at least) two steps: (1) an
iconic mapping of physical movement onto visuospatial im-
agery (e.g. a circular trajectory onto aspects of “roundness”,
“size”, or “orientation”); (2) a referential mapping of this im-
agery onto concrete objects or events (e.g. the specific round
window being referred to). Here we are concerned with the              Figure 1: Different iconic gestures performed for a virtual 3D
first iconic mapping only and we want to understand how                sphere, along with the respective wrist trajectories.
movements are used to create gestural imagery.
   Classically, iconic gestures are assumed to have no linguis-           In this paper we present a computational investigation into
tic structure with a composition of primitives. Rather, Mc-            the compositionality of iconic gesturing by trying to learn
Neill (2000) has argued for a “global semiosis” of such ges-           a “motor grammar” of iconic gestures. After discussing rel-
ticulations, holding that the meanings of ‘parts’ of a gesture         evant work, we propose a hybrid grammar-based approach
are determined by the meaning of the whole (and not the other          that statistically identifies low-level feature-based regularities
way around as in language). On the other hand, it is widely ac-        (“symbolization process”) and integrates this with searching
knowledged that the motor system is organized hierarchically           for their compositional organization in high-level syntactic
(Hamilton & Grafton, 2007), such that given intentions are             rules. Then, we discuss results from an application of this
                                                                   1341

formalism to a dataset of natural iconic gesture trajectories.        grammatical structure on top of them (see, e.g., Guerra-Filho
We show how movement features that are characteristic of              and Aloimonos (2007) for the use of “action morphemes”).
the iconic mapping are determined by their position within            The challenge here is that we cannot make such an assump-
syntactic structure while, the other way around, terminals and        tion for gesture. Instead we need to ground the learning of
syntactic rules emerge from these recurring low-level move-           hierarchical motor structure in the lowest levels of single fea-
ment features. It is demonstrated that this two-way interac-          ture values, such that structural-syntactic patterns of gestures
tion of two levels of analysis (identifying primitives and find-      and low-level statistical regularities that may constitute build-
ing compositions) allows for carving out a motor grammar of           ing blocks are extracted at the same time. To this end, we
iconic gesture trajectories.                                          adopt an idea that can be traced back to the 80’s, where Tsai
                                                                      and Fu (Tsai & Fu, 1980) proposed grammars that integrate
           Background and Related Work                                statistical consideration into syntactic pattern analysis. How-
                                                                      ever, many applied grammar formalisms in behavior analysis
One motivation behind the present work is to develop a cogni-         have treated these separately with a first step of statistical seg-
tive model of the sensorimotor processes involved in the pro-         mentation and symbolization, usually using Hidden Markov
duction and perception of meaningful nonverbal behaviors, in          Models (Chen, Georganas, & Petriu, 2008; Ivanov & Bobick,
particular communicative gesture. Previously, we proposed a           2000) to learn a finite set of symbols as terminals, and af-
hierarchical model of sensorimotor knowledge of hand ges-             terwards extraction of longer range structures using grammar
tures that consists of three levels of abstraction (Sadeghipour       formalisms such as SCFG.
& Kopp, 2011): motor commands (MC) controlling segments
of a movement trajectory (corresponding to motor primi-                                 Feature-Based Stochastic Context-Free
tives), motor programs (MP) representing complete gesture                                            Grammar
performances, and motor schemas (MS) capturing the vari-
ant and invariant features of the gesture performances that           We propose Feature-based Stochastic Context-Free Gram-
can be employed to fulfill certain communicative functions.           mars (FSCFG) to unify statistical (feature-based) and syn-
Accounting for a dual-use of this motor knowledge for both            tactic (structure-based) processing in a hybrid framework.
perception and production of gestures, we have proposed an            It aims to learn not only rule-based syntactic compositions
algorithm for Bayesian belief propagation in-between those            of terminals but also the statistical relations in underlying
levels and have utilized it to enable resonance-based percep-         features spaces that form them. Here, we explain briefly
tion, generation and imitation with an embodied virtual agent.        how an FSCFG is learned from given sample sequences; see
                                                                      Sadeghipour and Kopp (2014) for more details.
   The investigation presented here originally aimed to pro-
vide a representation for motor schemas that group individual
gestural performances (e.g. of “wiping”) together and extract                                                                                              S
                                                                                           SCFG represenation
the essence of a certain “gesture class” according to the rele-                            Rules         Probabilities
                                                                          Syntactic
                                                                                                                                            NT1           NT2    NT3
vant features for its iconic mapping. This links to recent de-                          S    NT1 NT2 NT3      [1]
                                                                                        NT1    NT11 NT12      [.5]
bates about the analogies between the deeper hierarchical or-                           NT1    t1             [.5]
                                                                                        NT11    t21           [1]           t1              NT11         NT12   t3     t4
ganization of human action and the syntax of language (Pastra                           NT12    t22           [1]
                                                                                        NT2    t3             [1]
& Aloimonos, 2012) as well as possible common underlying                                NT3    t4             [1]                           t21          t22
neural bases (Mussa-Ivaldi & Bizzi, 2000). Indeed, recursive
organization of motor primitives can be found in the repre-                                                                      wF
sentation of different motor knowledge in the human brain
                                                                          Statistical
(Mussa-Ivaldi & Bizzi, 2000; Flash & Hochner, 2005).                                         Feature sets:                   F1             F2     ...    Fl
                                                                                                                       wf
   Grammar-based formalisms have been applied for the
computer-based recognition of nonverbal behavior (Hong,                                      Features:            f1        f2        ...    fn
Turk, & Huang, 2000) or complex activities (Ryoo & Aggar-
wal, 2006; Kitani, Sato, & Sugimoto, 2006). To deal with un-
certainty due to noisy sensors or vision, such approaches have        Figure 2: Hybrid model of FSCFG, where terminal symbols
been extended to include probabilities. Stochastic Context-           in the syntactic structure serve as interface to the statistical
Free Grammars (SCFG) (Stolcke, 1994) where applied for                feature-based representations.
vision-based hand gesture recognition (Ivanov & Bobick,
2000) or activity recognition during a Tower of Hanoi task               As illustrated in Figure 2, FSCFG extend the syntactic rules
(Minnen, Essa, & Starner, 2003) based on predefined gram-             of SCFG to feature-based representation of terminals. In this
mars. Only few approaches have attempted to learn prob-               way, a terminal is not an atomic symbol anymore, but it is
abilistic grammars for activity recognition in domains like           represented as a prototype of a cluster of samples in an n-
gymnastic exercises, traffic events or multi-agent interactions       dimensional feature space. Thereby, the impact of the i-th
(Kitani et al., 2006; Zhang, Tan, & Huang, 2011). All of them         sample (or feature set) to a terminal is given by wFi ; and
presume a set of clear-cut morphemes and then built up a              the importance of the i-th feature for each terminal is given
                                                                   1342

by w fi . Learning these statistical regularities between features       deviation of the feature f in all the feature sets of its terminal.
and feature sets, the terminals emerge as prototypes of an in-           In other words, the higher the variance of a feature within a
tegrated symbolization process. This allows us to compute the            terminal is, the less it contributes to the parsing of that termi-
similarity between two symbols (or terminals) as the distance            nal. That means, during parsing, each lexical non-terminal is
in an n-dimensional feature space. Hence, while parsing, the             most sensitive to its most stable features. In this way, FSCFG
match between a terminal against an input symbol is not a                distinguishes between variant and invariant features of each
binary decision but computed probabilistically.                          terminal, depending on its incorporated feature sets which in
                                                                         turn depend on the structure of the syntactic rules.
Learning the structure and parameters
Learning an FSCFG refers to optimizing both its structure                Dealing with uncertain input
(i.e. the set of rules), and the values of its parameters (i.e. P        During grammar learning and parsing, uncertainty in the in-
of each rule, wF and w f for each terminal).                             put data may lead to deletion errors when an expected symbol
   In order to find the optimal set of rules, first an initial set       is missing in the input stream, insertion errors when sym-
is generated and used to parse the given input strings. For              bols occurr spuriously, or substitution errors when a symbol
each given input symbol, a terminal with a single feature set            is parsed through a wrong terminal. Since FSCFG can parse
is generated and a start rule is added that comprises the en-            any symbol by any terminal through feature-based parsing,
tire given string. Upon initialization, the structure is gener-          the substitution error is handled implicitly. To deal with the
alized through applying the merge and chunk operators: The               insertion and deletion errors during parsing, we introduce two
merge operator merge(X1 , X2 ) = Y replaces all occurrences              new special symbols: skip and ε. skip is a special terminal
of the non-terminals X1 and X2 with a new non-terminal Y .               with no feature set that handles insertion errors. The proba-
The chunk operator chunk(X1 ... Xk ) = Y replaces all occur-             bilistic similarity between skip and any given symbol is set to
rences of the ordered sequence of the non-terminals X1 ... Xk            a small value, so that the skip terminal will only then be used
with a single new non-terminal Y . These operators simplify              when otherwise the parsing would fail. On the other hand, ε
the grammar through decreasing its Description Length (DL)               is an empty terminal which is produced alternatively by each
(Rissanen, 1983), which is proportional to the number of bits            lexical rule with a small probability. Parsing a symbol with ε
needed to store the grammar’s rules. The loss measure during             means to ignore the symbol. From parsing to structure learn-
this process is the negative logarithm of the Bayesian poste-            ing, deletion and insertion errors exchange their roles as cause
rior parsing probability. The likelihood term, which indicates           and effect. Correspondingly, using these error handling sym-
how well the given samples fit the learned model, is set to the          bols, the FSCFG framework considers both hypotheses that
parsing probability of the samples, and the prior probability            either the learned grammar structure is incorrect or the given
of a grammar is set to its DL. Using this Bayesian loss mea-             input string is noisy. However, after providing enough train-
sure, the grammar structure is modified towards a trade-off              ing data, noisy rules will be used less for parsing and they
between simplicity and fitting of the model to the given data.           will end up with very low probability.
   The parameters of an FSCFG are learned and optimized
during both learning the structure and parsing new strings.                                              Results
The probability of each rule, P, is determined from how often            Data analysis
the rule is invoked in parsing, normalized by the sum of all in-         We have collected a dataset of 1739 gestures performed by
vocations of rules with the same left-hand side non-terminal.            29 participants to refer to 20 different 3D objects (3D Iconic
Computing the weight of each feature set of a terminal, wF ,             Gesture Dataset; 3DIG1 ). Since we aim for investigating the
employs a counter normalized by the sum of its values in each            iconic mapping of gestures onto abstract forms such as round
terminal. Initially, each terminal consists of a single feature          or rectangular, we used only the gesture performances which
set with its counter set to one, yielding t={(F1 , wF1 = 1)}.            were performed for ten simple geometrical shapes (see Fig. 5,
This representation of a terminal is adapted in two cases: (1)           bottom, for objects and Fig. 1 for gesture examples).
During parsing, when a terminal parses a symbol, the fea-                   A data analysis revealed four major representation tech-
ture set of the symbol is added to the terminal. In this way,            niques to perform iconic gestures: (1) Drawing the 3D or
parsing reshapes the terminals of a grammar towards the fea-             2D contour of the object in the air. (2) Enacting an action
tures of the parsed symbols. (2) During structure learning,              on an imaginary object. (3) Static posturing depicts the form
when merging two lexical non-terminals merge(X1 , X2 ) = Y               of an object with held hands. (4) Dynamic posturing refers
with X1 ⇒ t1 and X2 ⇒ t2 , the right-hand side terminals are             to a drawing movement with expressive static hand postures.
merged together yielding a new rule of the form Y ⇒ t, where             As shown in Figure 3, most of the gestures are performed
t={(F1 , 21 ), (F2 , 12 )}. These extensions of feature sets yield an    through drawing or dynamic posturing, where the wrist move-
integrated symbolization process in which incremental clus-              ment trajectories bear the main contribution to the depiction.
tering during both learning and parsing may result in different          To define and represent motor primitives, we hence focused
symbols depending on their syntactical roles in grammar.                 on the wrist trajectories, which also can be easily captured
   The weights of features, w f , are set for each terminal indi-
vidually. w f is defined inversely proportional to the standard              1 http://projects.ict.usc.edu/3dig
                                                                     1343

                                                         Applied representational techniques per object set
                        Applied representational techniques Drawing per object set
                     Applied representational techniques per subjectDynamic
                                                                     for simpleposturing
                                                                               objects
      1.2
                                 Drawing                           Static posturing
                                 Dynamic posturing                 Enacting                              Table 2: Feature-based statistical variabilities of gestures.
    100%1
                                 Static posturing
      0.8
     80%
                            1    Enacting                                                               Feature-based     An example of variation
                                                                                                        variability
  1
      0.6
     60%                                                                                                Direction         Drawing while moving a hand to left or to right.
                                                                                                        Velocity          Moving a hand fast or slow.
      0.4
     40%
                                                                                                        Size              Drawing a small or a big circle.
      0.2
     20%
                                                                                                        Position          Gesturing in front of head or chest.
                         0.8
                                                                                                        Projection        Drawing a horizontal or vertical projection.
0.8     0
           1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
                                                                                                        Form              Making a curved movement or a straight one.
        Figure 3: Different techniques used by each participant.
                         0.6
                                                                                                      their hands during non-communicative parts faster than in
                                                                                                      other parts.
0.6
    through low-cost motion tracking systems (in contrast to hand                                     Data preparation
    shapes).
                                                                                                      In order to learn FSCFG models of the recorded gestures,
                                                                                                      the first step is to segment the movement trajectories into a
                         0.4
          Table 1: Structural syntactic variabilities of gestures.                                    sequence of sub-movements which correspond to individual
0.4                                                                                                   motor primitives (motor commands in our proposed hierar-
      Structural          An example of variation                                                     chy of motor knowledge, encoded here as feature-based sym-
      variability
      Degree of           Drawing a 3D shape or a 2D projection.                                      bols of the FSCFG). These motor primitives are demarcated
      simplification                                                                                  by drops of movement velocity along hand movement trajec-
                         0.2
      Ordering            First, referring to the triangle shape of a cone                            tories. This segmentation results in short curved or straight
0.2                       and then to its circular bottom, or vise versa.                             movement segments, and a gesture is defined as a string of
      Repetition          Drawing a part once, twice or three times.                                  these segments or symbols. We extracted the following 18
      Handedness          Drawing a circle with one hand or both hands.                               feature dimensions to describe each segment:
                            0
                                                  simple objects
                                                                                                      •   A vector from the start position to its end (3 dimensions)
                                                                                                  complex objects
        We learn the hierarchical motor knowledge as a single                                         •   Weight and hight of the bounding box (2 dimensions)
  0
    FSCFG model   simplefrom
                         objectsthe different gesture performances        complex objects in the      •   Normal vector of the trajectory’s plain (3 dimensions)
    data. Based on our analysis, two types of variabilities need to                                   •   Direction of concavity (3 dimensions)
    be accounted for. Table 1 reports the most prominent struc-                                       •   Average movement velocity (1 dimension)
    tural (or syntactic) variabilities, which can lead to very differ-                                •   Start timestamp (1 dimension)
    ent gestures performed for the same object (i.e. with similar                                     •   Five samples of the movement trajectory, after normalizing
    iconic mapping). These variabilities concern segments of a                                            its position, size and orientation (5 dimensions)
    gesture performance. Below this level of variation, the sta-
    tistical variabilities concern the instantaneous level of spa-                                    Learned motor grammar
    tiotemporal features (Table 2). At this level, features can be                                    In order to learn an FSCFG from observed gestures, the first
    invariant or variant with respect to a specific part of a ges-                                    observation is incorporated through generating new rules.
    ture, to the referred object, or to the used representational                                     Then, each further gesture performance is first tried to be
    technique. For instance, a curved trajectory for round objects                                    parsed. If the parsing probability is too low, new rules are
    is a characteristic and invariant feature, whereas the move-                                      added to the grammar to incorporate the performance. After
    ment direction of drawing is irrelevant to its iconic mapping                                     each incorporation, the structure of the FSCFG is optimized
    and thus a variant feature. Our FSCFG framework needs to                                          (see Learning the structure and parameters) to achieve a gen-
    cope with both kinds of variabilities while generalizing over                                     eralized sparse representation of the observed gestures.
    different gestures, separating different gesture performances                                         Figure 4 shows an FSCFG, learned from 211 drawing ges-
    and determining variant and invariant features of each part of                                    tures. The grammar consists of seven start rules, whereby
    a gesture.                                                                                        each provides an abstract representation of all gestures with
        Another challenging structural variation of gestures fol-                                     similar iconic mapping. Each start rule is associated with
    lows from their temporal anatomy. Kendon (1972) divided                                           a set of rules, which represent different ways of perform-
    a gesture performance in three main phases of preparation,                                        ing the same iconic mapping with left hand and right hand
    stroke and retraction, whereby only the stroke phase is the                                       movement, respectively. Each of these rules consists of non-
    communicative, expressive part. However, even during this                                         terminals, each producing a terminal that represents a seg-
    stroke phase, parts of a movement might not be communica-                                         ment of the wrist movement trajectory. Correspondingly, each
    tive (e.g. when moving the hand to continue drawing from a                                        terminal is represented statistically, as a set of weighted fea-
    different position). We observed that the participants moved                                      ture sets (through wF ), and each feature set is represented by
                                                                                                 1344

                                                                                                                                                                                                                                      0.7                              2
                                                                                                                                                                                                                                                                                                2
0.5 P wf
  0.5
                                                           54
                                                                                                                               S => L26 R27 (30)[0.22]                                                                                0.6
 0.45
                                                     NT53 => t45                                                                L26 => MG46 NT5 NT6 NT7 NT8 (17)[0.77]
                                                                                                                                                                                                                                      0.5
                                                                                                                                                                                                                                                                   3
                                                                                                                                                                                                                                                                                      3
0.4
                                                                                                                                                                                                                                      0.4
  0.4                                                                                                                                                                                                                             Y
 0.35
                                                                                                                                L26 => NT17 NT18 NT19 NT20 (1)[0.04]                                                                  0.3
                                                                                                                                                                                                                                      0.2
0.3 .31
                                                                                                                                L26 => NT18 (1)[0.04]
  0.3
                                                                                                                                                                                                                                      0.1
 0.25
                                                                                                                                                                                                                                       0                  1 −0.2                                          1 0.3
                                                                                                                                L26 => NT5 NT6 NT7 NT8 (3)[0.14]
                                                                                                                                                                                                                                            −0.4   −0.3                −0.1       0       0.1       0.2           0.4
0.2
  0.2
                                                                                                                                                                                                                                                                              X
 0.15                    .21
0.1
  0.1
                                         .12          .11
                                                                            .13                                                 R27 => NT10 NT11 NT12 NT13 NT14 NT15(1)[0.04]              S=>L26 R27   S=>L31 R37 S=>L54 R54                 S=>L57 R61                                                                S=>L70 R76 S=>L83 R88 S=>L97 R102
                                                                                              .08
 0.05
    0
          Form           Direction       Concavity   Start−End              Size              Start time
                                                                                                                .04
                                                                                                                Velocity   f    R27 => R27 SK106 (13)[0.59]
         Form Dir. Conc. S.-E. Size Time Vel.                                                                                   R27 => NT22 NT23 NT24 NT25 (6)[0.27]
                                                      46
0.5 wF
   0.5
                                                                                                                                R27 => NT25 (1)[0.04]                                                                                  Motor Schemas
0.40.4                                                                                                                          R27 => NT12 (1)[0.04]
0.30.3
                                                                                                                               S => L31 R37 (17)[0.12]
0.20.2
                                                                                                                                L31 => NT27 NT28 NT29 NT30 (16)[0.94]
                                                                                                                                L31 => NT28 (1)[0.06]
0.1
                                                                                                                                R37 => NT32 NT33 NT34 NT35 NT36 (15)[0.75]
   0.1
    0
             1       2         3         4       5    6             7       8        9          10         11       F           R37 => R37 SK39 (1)[0.05]                                                                             Motor Programs
         P                                                 53
0.5            wf                                                                                                               R37 => NT32 NT33 NT35 NT36 (3)[0.15]
  0.5
 0.45
                                                     NT54 => t46
0.4 .44
  0.4
 0.35
                                                                                                                                R37 => R37 SK45 (1)[0.05]
0.3
  0.3
                                                                                                                               S => L54 R54 (3)[0.022]
                                                                                                                                L54 => MG46 NT41 (1)[0.33]
 0.25
0.2
  0.2
 0.15
                         .16
                                                                                                                                L54 => NT46 NT47 NT48 (2)[0.67]
0.1                                                                     .13
                                                                                                                                R54 => NT43 NT44 (1)[0.33]
  0.1
                                         .08          .07                                     .09
                                                                                                                                                                                                                                  Motor Commands
 0.05
                                                                                                                .03        f
   0
          Form           Direction       Concavity
         Form Dir. Conc. S.-E. Size Time Vel.
                                                     Start−End              Size          Start time            Velocity
                                                                                                                                R54 => NT50 NT51 NT52 (2)[0.67]
                                                                                                                               S => L57 R61 (46)[0.34]
                                                      46
0.5 wF
   0.5
                                                                                                                                L57 => NT53 NT54 NT55 NT56 NT57 (2)[0.04]
0.4
                                                                                                                                L57 => NT53 NT54 NT56 NT57 (6)[0.12]
   0.4
0.30.3
                                                                                                                                L57 => NT53 NT54 NT57 (40)[0.83]
0.20.2
                                                                                                                                R61 => NT58 NT59 NT60 (46)[1.0]
0.10.1                                                                                                                         S => L70 R76 (14)[0.10]
    0
            1        2         3         4       5    6             7       8        9          10         11       F           L70 => NT64 NT65 NT66 NT67 NT68 NT69(5)[0.31]          Trapezoid   Cone      Cube   Cylinder Ellipsoid                                        Sphere                                        Egg       Parallel   Rectangular   Pyramid
0.5 P wf
  0.5
                                                           57
                                                                                                                                L70 => NT64 NT65 NT66 NT67 NT69 (7)[0.44]                                                                                                                                                            trapezoid      box
 0.45
0.4
  0.4
                                                     NT57 => t49                                                                L70 => NT64 NT65 NT66 NT69 (4)[0.25]
 0.35
                                                                                                                                R76 => NT71 NT72 NT73 NT74 NT75 (10)[0.37]
0.3 .32
  0.3
 0.25                                                                                                                           R76 => R76 SK77 (12)[0.44]
0.2
  0.2
 0.15
0.1
                         .21                                                                                                    R76 => NT71 NT73 NT74 NT75 (5)[0.18]
                                                                                                                               S => L83 R88 (10)[0.07]
                                                                                                                                                                                   Figure 5: Resulting motor grammar as a hierarchical motor
                                         .12          .12
  0.1
                                                                        .11
 0.05
   0
          Form           Direction       Concavity
         Form Dir. Conc. S.-E. Size Time Vel.
                                                     Start−End              Size
                                                                                              .08
                                                                                              Start time
                                                                                                                .04
                                                                                                                Velocity   f    L83 => NT79 NT80 NT81 NT82 (10)[0.91]              knowledge, where gestural movements with similar iconic
                                                     49                                                                         L83 => L83 SK91 (1)[0.091]
0.5 wF
   0.5
                                                                                                                                R88 => NT84 NT85 NT86 NT87 (8)[0.88]               mappings are grouped into the same schemas.
0.40.4
                                                                                                                                R88 => NT87 (1)[0.11]
0.30.3                                                                                                                         S => L97 R102 (17)[0.12]
0.20.2
                                                                                                                                L97 => NT93 NT94 NT95 NT96 (14)[0.93]
                                                                                                                                L97 => NT94 (1)[0.07]
0.10.1
                                                                                                                                R102 => NT98 NT99 NT100 NT101 (15)[0.94]
    0
           1     2         3         4       5   6    7         8       9       10       11       12       13       F           R102 => NT99 (1)[0.06]                                Figure 5 illustrates how the learned FSCFG can serve as
                                                                                                                                                                                   a compositional/hierarchical representation of motor knowl-
                                                                                                                                                                                   edge, which is learned from observed gesture performances.
Figure 4: Motor grammar learned from 211 gesture perfor-                                                                                                                           For this purpose, we consider each start rule equivalent to a
mances (lexical rules omitted) along with the weights of the                                                                                                                       motor schema and each motor program is represented through
features and feature sets of three terminals used in one spe-                                                                                                                      a pair of hand-specific rules (or a single one in the case of one-
cific rule.                                                                                                                                                                        handed performances). Each motor command is represented
                                                                                                                                                                                   through a terminal (or equivalently its producing lexical non-
18 features which are weighted through w f .                                                                                                                                       terminal). In Figure 5, the nodes at the bottom represent the
   Figure 4 shows the weighting of the terminals in a spe-                                                                                                                         individual gestures, with performances for different objects
cific rule representing the movement of the left hand while                                                                                                                        shown in different colors. Each of the outgoing connections
drawing a semicircle. The terminal produced by NT53 and                                                                                                                            from each gesture represents one of its movement segments
NT57 represent preparation and retraction phase of gestures                                                                                                                        which is then associated with the motor command, whose lex-
respectively, and NT54 represents the actual stroke phase with                                                                                                                     ical rule is invoked for parsing that segment. Each outgoing
a drawing intention behind it. A significant difference be-                                                                                                                        connection, from commands to programs up to the start rules
tween this phase and the neighbouring ones is the importance                                                                                                                       as schemas, represents a gesture performance.
of the form features, indicated by the relative difference be-                                                                                                                        As shown, gestures for the same or similar objects get as-
tween their weigths (blue bar) and those of the other features.                                                                                                                    sociated with the same start rules. For example, since draw-
Apparently, form features are the most invariant for the stroke                                                                                                                    ing gestures depict a rough silhouette of the referred ob-
phase of drawing gestures for round shapes. On the other                                                                                                                           ject and subtle distinctions are ignored, gestures for sphere,
hand, in NT53 and NT57, features such as direction, start-end                                                                                                                      ellipsoid and egg are clustered into a single start rule for
positions and concavity gain more importance. This is due                                                                                                                          “round” objects. This automatic generalization can be viewed
to their low variance as preparation and retraction phases are                                                                                                                     as capturing the essence of depicting the corresponding iconic
fast movements in specific directions.                                                                                                                                             mapping (e.g. a general motor schema for depicting round
   While w f determines how characteristic each feature for                                                                                                                        shapes). Likewise, the gestures for cone and trapezoid are also
the feature sets of each terminal is, wF (given as gray bars in                                                                                                                    parsed by the same start rule, but then get differentiated at the
Fig. 4) specifies the importance of each feature set itself to its                                                                                                                 motor program level as different performances.
terminal. Few highly weighted feature sets (such as for NT53                                                                                                                          Finally, to demonstrate the important ability of FSCFG to
and NT54) indicate a prototypical movement segment for that                                                                                                                        also produce new gesture performances, the top row of Figure
part of the gesture. In contrast, several equally weighted fea-                                                                                                                    5 shows a generated prototypical gesture (as wrist trajecto-
ture sets represent a part of a gesture with a high variability.                                                                                                                   ries) for each motor schema. This shows that the proposed
For instance, NT57 covers different retraction movements and                                                                                                                       FSCFG cannot only be used to learn compositional motor
thus possesses no prototypical movement trajectory.                                                                                                                                knowledge at different levels of abstraction from highly var-
                                                                                                                                                                                1345

ied gesture performances, but it can also be used to generate           Report No. 376). Tokyo, Japan: IEICE - The Institute of
prototypes of the learned gestures, e.g. in a humanoid virtual          Electronics, Information and Communication Engineers.
agent or robot. Furthermore, learned FSCFGs can also be ap-           Kopp, S., Bergmann, K., & Kahl, S. (2013). A spreading-
plied as discriminative models to recognize hand gestures, as           activation model of the semantic coordination of speech
we presented and discussed in (Sadeghipour & Kopp, 2014).               and gesture. In (pp. 823–828). Cognitive Science Society.
                                                                      McNeill, D. (2000). Language and gesture (Vol. 2). Cam-
                         Conclusion                                     bridge University Press.
The goal of the present work is to investigate the structures         Minnen, D., Essa, I., & Starner, T. (2003). Expectation gram-
of iconic gesturing at a level of movement features that af-            mars: leveraging high-level expectations for activity recog-
fords a motor grammar. To deal with the lack of clear-cut               nition. In Computer vision and pattern recognition, ieee
symbolic units in gesture, we proposed the framework of                 conference on, (Vol. 2, pp. 626–632).
FSCFG, which combines feature-based representation (incl.             Mitra, S., & Acharya, T. (2007). Gesture recognition: A sur-
symbolization) with syntactical rule-based organization. That           vey. IEEE Transactions on Systems Man and Cybernetics
is, grammar-like structure is built on local, statistically iden-       Part C-Applications and Reviews, 37(3), 311-324.
tified primitives. Applied to natural iconic gesture trajecto-        Montgomery, K. J., Isenberg, N., & Haxby, J. V. (2007).
ries, the resulting grammar organizes motor knowledge hier-             Communicative hand gestures and object-directed hand
archically across the levels of motor commands, programs,               movements activated the mirror neuron system. Social
schemas. The well-known phasal organization of gesture is               Cognitive and Affective Neuroscience, 2(2), 114-122.
reified and, crucially, structures become visible that may            Mussa-Ivaldi, F. A., & Bizzi, E. (2000). Motor learn-
fulfill independent depictive functions. This elevates motor            ing through the combination of primitives. Philosophical
knowledge to a level of structural organization, where signif-          transactions of the Royal Society of London. Series B, Bio-
icant invariant features of iconic mapping are identified that          logical sciences, 355(1404), 1755–1769.
can provide first hints for a motor-meaning interface in com-         Mussa-Ivaldi, F. A., & Solla, S. A. (2004). Neural primitives
municative bodily behavior.                                             for motion control. IEEE Journal of Oceanic Engineering,
                                                                        29(3), 640-650.
                                                                      Pastra, K., & Aloimonos, Y. (2012). The minimalist grammar
Acknowledgements This research is supported by the                      of action. Philosophical transactions of the Royal Society
Deutsche Forschungsgemeinschaft (DFG) in the Center of                  of London. Biological sciences, 367(1585), 103–117.
Excellence EXC 277 in ‘Cognitive Interaction Technology’.             Rissanen, J. (1983). A universal prior for integers and estima-
                                                                        tion by minimum description length. Annals of Statistics,
                          References
                                                                        11(2), 416–431.
Chen, Q., Georganas, N. D., & Petriu, E. (2008). Hand ges-            Ryoo, M. S., & Aggarwal, J. (2006). Recognition of compos-
   ture recognition using haar-like features and a stochastic           ite human activities through context-free grammar based
   context-free grammar. Instrumentation and Measurement,               representation. In Computer vision and pattern recogni-
   IEEE Transactions on, 57(8), 1562–1571.                              tion, 2006 ieee computer society conference on (Vol. 2, pp.
Flash, T., & Hochner, B. (2005). Motor primitives in verte-             1709–1718).
   brates and invertebrates. Current Opinion in Neurobiology,         Sadeghipour, A., & Kopp, S. (2011). Embodied gesture pro-
   15(6), 660–666.                                                      cessing: Motor-based integration of perception and action
Guerra-Filho, G., & Aloimonos, Y. (2007). A language for                in social artificial agents. Cognitive Computation, 3, 419–
   human action. Computer, 40(5), 42–51.                                435.
Hamilton, A., & Grafton, S. (2007). The motor hierarchy:              Sadeghipour, A., & Kopp, S. (2014). A hybrid grammar-
   From kinematics to goals and intentions. In Attention and            based approach for learning and recognizing natural hand
   performance. Oxford University Press.                                gestures. In Proceedings of the 28th AAAI conference on
Hong, P., Turk, M., & Huang, T. S. (2000). Gesture mod-                 artificial intelligence. (in press).
   eling and recognition using finite state machines. In Au-          Stolcke, A. (1994). Bayesian Learning of Probabilistic Lan-
   tomatic face and gesture recognition, 2000. proceedings.             guage Models. Unpublished doctoral dissertation, Univer-
   fourth ieee international conference on (pp. 410–415).               sity of California at Berkeley, Berkeley, CA.
Ivanov, Y., & Bobick, A. (2000). Recognition of visual activ-         Tsai, W. H., & Fu, K. S. (1980). Attributed grammar - a
   ities and interactions by stochastic parsing. Pattern Analy-         tool for combining syntactic and statistical approaches to
   sis and Machine Intelligence, IEEE Transactions on, 22(8),           pattern-recognition. IEEE Transactions on Systems Man
   852–872.                                                             and Cybernetics, 10(12), 873–885.
Kendon, A. (1972). Some relationships between body motion             Zhang, Z., Tan, T., & Huang, K. (2011). An extended gram-
   and speech. In A. Siegman & B. Pope (Eds.), Studies in               mar system for learning and recognizing complex visual
   dyadic communication. New York: Pergamon Press.                      events. Pattern Analysis and Machine Intelligence, IEEE
Kitani, K. M., Sato, Y., & Sugimoto, A. (2006). An mdl ap-              Transactions on, 33(2), 240–255.
   proach to learning activity grammars (Vol. 106; Technical
                                                                  1346

