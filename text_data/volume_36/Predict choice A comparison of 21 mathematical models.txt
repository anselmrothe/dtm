UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Predict choice: A comparison of 21 mathematical models
Permalink
https://escholarship.org/uc/item/23f5053p
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)
Authors
Schulz, Eric
Speekenbrink, Maarten
Shanks, David R.
Publication Date
2014-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              Predict choice: A comparison of 21 mathematical models
                                        Eric Schulz (eric.schulz@cs.ucl.ac.uk)
                   Department of Computer Science, University College London, London WC1E 6BT
    Maarten Speekenbrink (m.speekenbrink@ucl.ac.uk) and David R. Shanks (d.shanks@ucl.ac.uk)
               Cognitive, Perceptual and Brain Sciences, University College London, London WC1H 0AP
                          Abstract                               applied to a somewhat artificial data set. The paper
   How should we choose a model that predicts human              at hand puts the aforementioned performance-flexibility
   choices? Two important factors in this choice are a           trade off to a test in the potentially more interesting area
   model’s predictive power and a model’s flexibility. In        of human choices. In doing so, we will introduce an em-
   this paper, we compare these aspects of models in a
   large set of models applied to an experiment in which         pirical measurement of a model’s flexibility based on its
   participants chose between brands of fictitious chocolate     ability to recover and predict data generated by other
   bars and a quasi-experiment predicting movies’ gross          models. Furthermore, we will use this flexibility mea-
   revenue. We show that there is a trade-off between flex-
   ibility and predictive power, but that this trade-off ap-     surement to rank and compare the 21 models’ perfor-
   pears to lie more towards the “flexible” side than what       mance in predicting human choices in a two-alternative
   was previously thought.                                       forced-choice task, and predicting movies’ gross revenue
   Keywords: Choices; Forecasting; Overfitting.
                                                                 and a different key variable. We conclude that, even
                       Introduction                              though there clearly is a trade-off between flexibility and
Choosing a good model to predict choices is an important         predictive performance, the point at which more flexibil-
task for both researchers of decision making and statis-         ity diminishes predictive performance is at a higher level
ticians. One crucial debate within this area concerns the        of flexibility than was previously expected.
flexibility of the model used to predict human choices.
On the one hand, there is the belief that more flexible                      Assessing model flexibility
models should be preferred as they potentially capture
the underlying psychological phenomenon well. Propo-             To shed more light on the debate about various degrees
nents of this approach try to show how more flexible             of flexibility and performance, one needs to introduce a
models can outperform simpler models in many differ-             reliable measurement of flexibility. Different measure-
ent predictive tasks (Chater et al., 2003). On the other         ments have been suggested, such as Kolmogorov com-
hand, there are researchers who argue that models which          plexity (Chater & Vitányi, 2003) and a model’s degrees
are too flexible tend to overfit the data, capturing unim-       of freedom. The flexibility measure proposed here is de-
portant noise in the training set which results in sub-          fined in terms of the average ability of a model to capture
optimal generalization to the test set. One example for          and predict observations that have been generated from
overfitting is that by increasing the degrees of a poly-         a different model. Importantly, the generating model has
nomial regression to capture the average temperature of          itself been fitted to a random set of data, and the best
one year, one will reach a point where the models’ predic-       fitting parameters are then used to generate the learning
tive performance for the next year goes down (Gigerenzer         and test sets. We used randomly generated data sets for
& Brighton, 2009). Both sides at least implicitly assume         the initial model fits in order to not bias the final recov-
that if a Model A makes more correct predictions than            ery result in any systematic direction. While we could
a Model B, Model A somehow captures the underlying               have used real world data sets for this initial simulation
process better than Model B, an assumption that can              stage, our main concern was to assess a model’s ability to
be argued against from various points (Salmon, 1971).            recover data generated by different models, and not their
However, given an equal amount of evidence for both              ability to recover systematic characteristics of particular
Model A and Model B, it is common practice to accept as          data sets. The averaged overall predictive performance
better the model that makes more accurate experimental           then is rank-transformed as an indicator for a model’s
predictions. In the past, researchers such as Gigerenzer         relative flexibility within the set of models under con-
& Brighton (2009) showed that in tasks such as predict-          sideration. The models used here and their performance
ing city sizes or professors’ salary, simple models can          and obtained flexibility ranks are presented in Table 11 .
outperform more sophisticated models such as Multiple               In more detail, we obtained the relative flexibility mea-
Regression or Naive Bayesian Classifiers. Later, Chater          sure as follows. We first generated 100 values for four
et al. (2003) showed that other models such as Decision          independent variables Xj by sampling each value inde-
Trees or Feedforward Networks can perform at least as            pendently from a Normal distribution with a mean of
well as simple models such as Take The Best. How-
                                                                     1
ever, both studies only used a limited amount of models                All models were fitted using Matlab R2011B.
                                                             2889

µ = 0 and a standard deviation of σ = 2.5, i.e.                        model’s complexity Wagenmakers et al. (2004). As com-
                                                                       plexity is normally defined as rather being model-specific
     Xij ∼ N (0, 6.25),    i = 1, . . . , 100, j = 1, . . . , 4 (1)
                                                                       and our flexibilty measurement is a combination of the
We used a normal distribution for the initial simulation               situation and the model, complexity is not the same as
as the variables in the actual tasks were generated by                 predictive accuracy a priori. Flexible models can be not
a normal distribution as well. Of course, the choice of                very complex and vice versa Spiegelhalter et al. (2002).
this initial distribution is rather artificial, but we believe         We have chosen to use random data at the first simu-
that a normal distribution is more likely (as for example              lation stage to avoid systematic biases in the flexibility
compared to a uniform distribution) to represent the ac-               comparison. This of course means that some of the orig-
tual distributions in the data sets later on. In addition,             inal model fits are very weak, a behavior that can be
values of a dependent variable Y were generated as inde-               changed in future studies to see whether more system-
pendent draws from a Bernoulli distribution with a prob-               atic relations at that stage might shift the measurement
ability of p = .5, i.e. Yi ∼ Bern(p = 0.5), i = 1, . . . , 100.        into a different direction.
A given model was then fitted to this data set of 100                  In general, our flexibility measurement is a first attempt
observations. The fitted model was used to generate 2                  to quantify flexibility in the psychological domain and
new data sets of 100 observations each by drawing new                  the resulting ranking seems to be prima facie plausible.
values of the independent variables according to Equa-                 Additionally, our experiments show that it can be used
tion 1 and then generating new values of the dependent                 to produce reliable and reproducible results.
variable as the model prediction for these values of the
independent variable. One of these new data sets was                          Experiment 1: Choices over time
treated as a learning set and the other was used as a test             The first experiment confronted participants with two-
set. An alternative model was then fitted to the learn-                alternative forced choices between fictitious chocolate
ing set and used to predict the dependent variable in the              bars that were described on 4 different scales. The de-
test set. This procedure was repeated 100 times for ev-                scriptions of these scales were generated from a pilot
ery possible model-model combination and the average                   study (n = 21, bars= 12), where participants had to
number of correct predictions over these 100 replications              describe real chocolate bars on 30 different scales. The
was calculated at the end. For a set of 21 models, this                evaluations then were entered into a factor analysis with-
means that every model produced 21 averaged values of                  out rotation, forcing the total number of factors to be
how well it recovered and predicted all the other mod-                 equal to 4. The resulting factor structure explained 82%
els (including the model itself2 ). These 21 values were               of the variance and from each resulting dimension one
then averaged across each model to get an overall mea-                 scale was chosen so that all the 4 scales were slightly
surement of a model’s flexibility. This measurement was                positively correlated with each other3 . The final scales
rank-transformed to obtain relative flexibility values (for            were described as “Design”, “Calories”, “Crunchiness”
the question at hand, the exact differences do not matter              and “Richness of Taste”. The main experiment was pro-
as much as the fact that one model is more flexible than               grammed in HTML and hosted online on the Unipark
another). The ranked values are an unbiased estimate of                survey platform. Participants were recruited via uni-
each model’s position in the whole population of models,               versity email lists. Within the experiment, participants
reflecting the probability that a randomly chosen model                were presented with pairs of fictitious chocolate bars that
is less flexible.                                                      were described by a value on the aforementioned scales.
   We acknowledge that our proposed flexibility measure-               Their task was to choose which of the two bars they
ment can only be seen as an approximation to the de                    would prefer. The values describing the bars were gener-
facto flexibility of a given model as it only checks for               ated at random to be distributed as N (5, 6.25) between
the ability to recover structure within a limited domain.              the range of 0 and 10. As such, participants revealed
In addition, it can be argued that including more mod-                 how they integrate the presented information in order to
els that are either more or less flexible could change the             make a final choice between chocolate bars. Participants
ranking completely; a concern that we tried to address                 were randomly assigned to one of five inter-correlations
by including a set of models that –in our opinion– can                 between the dimensions, r ∈ {0, 0.2, 0.4, 0.6, 0.8}. Differ-
be seen as representative for models that are normally                 ent levels of inter-correlation were used in order to make
used within standard data mining tasks. Our set up fits                the results more generalizable across different choice en-
into the more common set up of model mimicry in that                   vironments. The experiment was spread over 6 days;
models that are able to mimic the behavior of a large                  participants were presented with 50 pairs of chocolate
set of different models tend to have a higher flexibil-                bars on the first day, and 20 pairs of chocolate bars on
ity score. However, it is not completely the same as a                 each of the following days. Different time-points were
    2                                                                     3
      One of our earlier questions was about specificity. The               We wanted the factors to be slightly correlated to allow
ability to capture data well that was produced by the same             for a range of different inter-correlations in the actual exper-
model class.                                                           iment.
                                                                   2890

                  Table 1: Model description, flexibility performance and assigned rank value
Model                                Description                                Performance   Rank Score
Coin Flip                            No fitting involved, assumes that each         50.0%        0.00
                                     possible outcome is equally likely
Pick cue at random                   Picks one of the 4 predictors at random        59.2%        0.05
                                     and predicts that the item with a higher
                                     value wins
Tallying                             Unit weight strategy, sums up all the          70.5%        0.10
                                     values of the cues per item and predicts
                                     that the item with the higher sum wins
Minimalist                           Take The Best-algorithm with ran-              71.9%        0.15
                                     domly determined cue order
Biased Coin                          Calculates the mean of the dependent           73.4%        0.20
                                     variable and flips a coin with p(y) =
                                     µ(Ylearning sample )
Response Bias                        Calculates the mean of the independent         73.8%        0.25
                                     variable and predicts that all values will
                                     be what the majority of the items were
                                     in the learning sample
Context Model                        Uses the weighted distance to every win        74.1%        0.30
                                     and loss for predictions
Take The Best                        Standard Take The Best (Gigerenzer &           75.9%        0.35
                                     Goldstein, 1999)
Nearest Neighbour                    Predicts that the same is going to hap-        76.7%        0.40
                                     pen as in the most similar case in the
                                     learning sample
Classification Trees                 Builds a classification tree to classify       78.7%        0.45
                                     items
Linear Discriminant Analysis         Draws a linear function within the di-         82.2%        0.50
                                     mensions to separate losses from wins
Logistic Regression                  Standard Logistic Regression                   82.7%        0.55
Cascade Network                      Neuronal Network with cascade back-            82.9%        0.60
                                     wards propagation, MSE-learning, 5
                                     neurons
Multi-Adaptive Regression Splines    Non-parametric regression that uses a          83.9%        0.65
                                     weighted sum of linear basis functions
Naive Bayesian Classifier            Estimates the conditional probability          84.4%        0.70
                                     to win or lose given the data to classify
                                     items, assumption of no covariance
Generalized Regression Network       Uses a Radial function to approximate          85.2%        0.75
                                     the underlying data structure
Polynomial Logistic                  Polynomial regression with up to 3 de-         85.8%        0.80
                                     grees of freedom, determined by AIC
Pattern Recognition Network          Network with a Tansig backward prop-           85.9%        0.85
                                     agation and MSE training function
Support Vector Machine               Support Vector classifier with a linear        86.8%        0.90
                                     Kernel
Random Forest                        Ensemble classifier based on decision          87.2%        0.95
                                     trees, prediction is the mode of the out-
                                     puts of all trees
Feed Forward Network                 Unsupervised Net with 2 layers, num-           89.2%        1.00
                                     ber of knots determined by cross-
                                     validation of training set
                                                       2891

used in order to asses to what extent participants’ pref-
                                                                                                            Table 2: Estimates of the different polynomials within
erences are consistent over a (relatively short) period
                                                                                                            the generalized linear regression. ∗ = best model.
of time. 15 participants (µage = 24.5, σage = 1.4, 7
females) participated in the study and received a real                                                                          Form           AIC
chocolate bar as a reward.                                                                                                      Linear         7392.9
  After the experiment was completed, each of the 21                                                                            Quadratic      7367.2
models in Table 1 was fitted to the first 50 choices of                                                                         Cubic          7351.2∗
each participant individually by calculating the differ-                                                                        Quartic        7352.7
ences between the corresponding scales4 and treating the
choices as binary. Afterwards, every model was used to
predict the following 100 choices and the percentage of                                                     bic form was found to be the best according to Akaike’s
correct predictions for every day was calculated. Based                                                     “An Information Criterion” (AIC; Akaike (1974)). This
on the argument above, we hypothesized the following:                                                       means that the final model is of the form presented in
1. More flexible models will, on average, perform better                                                    Equation 1.
   than less complex models.                                                                                             f (x) = β0 + β1 x + β2 x2 + β3 x3             (2)
2. There is a point after which an increase in flexibility                                                  The estimated parameters for this model are presented in
   will reduce predictive performance.                                                                      Table 3, alongside their standard errors. From the cubic
Results and discussion
The predictive performance of the models is shown in                                                        Table 3: Parameters estimates of the best fitting gener-
Figure 1. The overall correlation between flexibility and                                                   alized polynomial linear regression model in Experiment
                                                                                                            1.
                        Figure 1: Bar chart of model performance                                                                         βi    σ(βi )
                                                                                                                                 β0    -0.04   0.01
                                                       Model performance                                                         β1    0.71    0.08
                                                                                                                                 β2    -0.59   0.11
                   20
                                                                                                                                 β3    -1.88   0.44
                                                   ●
                               ●                       ●
                                                                                                            regression model, it is straightforward to calculate the
                   15                        ●         ●                                                    flexibility value with maximum predictive performance5
                               ●
                                                                                                            as follows:
 Performance
                                                                                                                        f (x) = −0.04 + 0.71x − 0.59x2 − 1.88x3
                   10                                                                    ●
                                                                                                                      d
                                                                                                                        f (x) = 0.71 − 1.18x − 5.64x2
                                                                                                                     dx
                                                                                                                  d
                                                                                                                    f (xmax ) = 0 → xmax = 0.77
                   5                                                                                             dx
                                                   ●
                                         ●                                                                  Thus, the maximum point is at a normalized relative
                               ●
                                                                         ●
                                                                         ●
                                                                                               ●
                                                                                               ●
                                                                                                            flexibility level of about 0.776 . The model closest to
                   0                                                                                        this point is the generalized regression network, which
                                                                                                            is also the model that performs best overall with an
                           0       0.1       0.2       0.3   0.4   0.5       0.6   0.7   0.8   0.9   1      average of 80% correct predictions. Interestingly, the
                                                             Complexity rank                                Minimalist heuristic performed surprisingly well in the
                                                                                                            task too, which could indicate that the way participants
                                                                                                            integrated information might have changed over time.
performance was r = 0.53, p < 0.01. This significant                                                        However, when we explored this possibility, we did not
positive correlation means that, on average, more flex-                                                     find an effect of time on model performance; this may
ible models indeed performed better than less flexible                                                      be because the time period was relatively short.
models. In order to check for a potential turning point,                                                       Summarizing Experiment 1, more flexible models seem
we analyzed the data by using a generalized polynomial                                                      to perform better on average, but there is a flexibility-
regression with a logit link function and mean-centering                                                    performance trade-off, which occurs in our experiments
the complexity (the resulting scale of flexibility was be-                                                     5
tween -0.5 and 0.5). As can be seen in Table 2, the Cu-                                                          The point after which more flexibility starts reducing the
                                                                                                            predictive performance of the model.
               4                                                                                               6                 d2
                   Resembling the same structure as in the rank generation.                                      Checking that dx  2 f (x) < 0, which is true in our case
                                                                                                         2892

 at a normalized relative rank of 0.77. This is further to-
                                                                 Table 5: Parameters estimates of the best fitting gener-
 wards the side of flexibility than those proposing simple
                                                                 alized polynomial linear regression model in Experiment
 heuristics may have expected. As this experiment con-
                                                                 2.
 tained a limited number of subjects, and choices were
 made between fictitious products, we sought to replicate                                    βi    σ(βi )
 these findings with a different data set.                                             β0  -0.49   0.05
                                                                                       β1    0.9   0.21
     Experiment 2: Movies’ gross revenue                                               β2   -3.3   0.31
 The second (quasi-)experiment had a similar design as
 the first experiment, but this time we used publicly avail-
 able data from the internet on movies’ gross revenue               Again, it is possible to calculate the point of max-
 (how much money a given movie made whilst running               imum performance (where increasing flexibility further
 in the cinemas). Notice that this can still be seen as a        reduces predictive performance) through the following
 choice scenario, where a movie with a higher gross rev-         calculations:
 enue was preferred by more people than a movie with
 a lower gross revenue. As predictors of revenue, we in-                            f (x) = −0.49 + 0.9x − 3.3x3
 cluded the costs of the movie, the number of google hits                         d
 received, its IMDB-score, as well as the number of likes                           f (x) = 0.9 − 9.9x2
                                                                                 dx
 on facebook (as of July 2011). All the models were fitted                    d
 to 80 randomly-drawn pairs of movies from the IMDB                             f (xmax ) = 0 → xmax = 0.8
                                                                             dx
 Top 100 of the year 2000 and used to predict 20 randomly
 drawn pairs from the Top 100 of each of the following           The maximum point thus lies roughly at the same point
 years between 2001 and 2010 (100 predictions in total).         as in Experiment 1.
 The proportion of correct predictions for each model and           Experiment 2 tried to replicate the overall findings
 year were calculated as before. The hypotheses tested in        from Experiment 1 within a different setting. Again,
 Experiment 2 were as follows:                                   we found a trade-off between flexibility and predictive
                                                                 performance and the optimal level of flexibility was close
1. There will be again a trade-off between flexibility and       to that found in Experiment 1. However, this time the
    predictive accuracy.                                         Random Forest algorithm (flexibility=0.95) performed
                                                                 best overall, even though the fitted model showed the
2. The point of this trade-off will be close to the point        smooth maximum to be at around 0.8. Interestingly,
    found in Experiment 1.                                       for this data, the Minimalist heuristic only achieved a
 Results and Discussion                                          performance predicting 60% of the choices correctly.
                                                                    While one could argue that predicting a movies’ gross
 Replicating the findings of Experiment 1, flexibility was       revenue is not a very psychological problem in itself, or
 again positively correlated with overall performance,           that variables such as facebook likes or IMDB scores
 r = 0.71, p < 0.01. A similar logistic regression anal-         are directly caused by how many people watch a movie,
 ysis as before, where predictive success is regressed on        so that this is more a problem of backwards prediction,
 model flexibility, revealed a cubic polynomial without          the data analysed here closely resembles those used in
 the quadratic term as the best model. The final form            similar studies of model performance. Importantly, the
                                                                 replication of the flexibility-performance trade-off tells
 Table 4: Estimates of the different polynomials within          us that there seems to be some truth behind the fact
 the generalized linear regression. ∗ = best model.              that more flexible models do not always lead to better
                                                                 predictive performance.
          Form                               AIC
          Linear                             918.4                                General Discussion
          Quadratic                          920.4               In two experiments we found a flexibility-performance
          Cubic                              914.4               trade-off that occurred at an assigned relative rank value
          Cubic (without quadratic term)     912.4∗              of about 0.8. This result nicely brings together both
                                                                 opinions mentioned in the introduction, according to
 of this model is presented in Equation 3 and the param-         which either more flexibility or more simplicity should
 eter estimates are presented in Table 5, alongside their        be preferred. At least according to our findings, there
 standard errors.                                                exists a point where more flexibility reduces a model’s
                                                                 predictive performance, but this points occurs rather far
                  f (x) = β0 + β1 x + β2 x3             (3)      on our generated scale. This means that –in some sense–
                                                                 both sides of the argument seem to be right (and wrong).
                                                             2893

On the one hand, flexible models should not always be            other models. For example, modelling changing environ-
preferred if one wants to make good predictions, as there        ments between the learning and the test set could give
is a point at which increasing flexibility reduces predic-       us a better understanding of the driving forces behind a
tive performance. But the point where flexibility starts         model’s performance. By doing so, one could then cata-
penalizing predictive performance lies more towards the          logue the specific attributes of environments that lead to
flexible side than what some might have expected. For            a superior performance of a certain model class. Another
example, all of the included simple heuristics were far          step could be to model even more realistic scenarios with
less flexible than the optimal level of flexibility.             our approach. Modelling real choice scenarios could shed
                                                                 more light on the flexibility required to make good pre-
   To our knowledge, we compared more mathematical               dictions in naturalistic situations.
models of choice than ever before in a single study. In             Only by focusing on real psychological phenomena as
addition, we proposed a relative flexibility measure that        well as using computationally rigorous approaches can
was useful to investigate the trade-off between flexibil-        we actually try to answer the question of how we as
ity and predictive performance. The paper at hand can            scientists should actually predict human behavior, but
be seen as a first attempt to capture real psychological         this choice is up to us.
choices with a large set of different models, whereas past
work has mainly focused on rather artificial data sets                             Acknowledgments
such as city sizes or professors’ salaries (e.g., Gigerenzer     This work was supported by a DAAD grant and by the
& Goldstein, 1999; Chater & Vitányi, 2003). Of course,          UK Centre for Doctoral Training in Financial Comput-
there are limitations to the interpretation of our findings.     ing & Analytics
First of all, our focus was on the flexibility-performance
trade-off, whereas some might argue that the real trade-                                References
off is between complexity and performance. Model sim-            Akaike, H. (1974). A new look at the statistical model
plicity is an ambiguous concept. For example, if a heuris-          identification. Automatic Control, IEEE Transactions
tic had happened to be the best within our simulations,             on, 19 (6), 716–723.
then the heuristic would have been assigned the high-            Chater, N., Oaksford, M., Nakisa, R., & Redington, M.
est flexibility rank, even though one might not consider            (2003). Fast, frugal, and rational: How rational norms
heuristics as very complex models. But whether a model              explain behavior. Organizational behavior and human
is intuitively “simple” is, loosely put, language depen-            decision processes, 90 (1), 63–86.
dent (Speekenbrink, 2003). While we admit a model’s              Chater, N., & Vitányi, P. (2003). Simplicity: a unifying
ability to recover data generated by other models is not            principle in cognitive science? Trends in cognitive
a direct indication of a model’s complexity, flexibility as         sciences, 7 (1), 19–22.
defined here captures one of the main reasons why overly         Gigerenzer, G., & Brighton, H. (2009). Homo heuristi-
complex models have poor predictive performance: their              cus: Why biased minds make better inferences. Topics
ability to fit random noise in a training set. Additionally,        in Cognitive Science, 1 (1), 107–143.
recovery ability has been used to show superior model            Gigerenzer, G., & Goldstein, D. G. (1999). Betting on
performance in the literature before (Pitt & Myung,                 one good reason: take the best and its relatives. Sim-
2002). Another problem is that rank-transforming flex-              ple Heuristics that Make Us Smart. Oxford University
ibility values allows for only relative positioning. In-            Press, New York , (pp. 75–95).
troducing many even more complicated models would                Pitt, M. A., & Myung, I. J. (2002). When a good fit can
arbitrarily push the rankings towards 0 and the found               be bad. Trends in cognitive sciences, 6 (10), 421–425.
trade-off point might have been closer to the less flexi-
                                                                 Salmon, W. C. (1971). Statistical explanation and sta-
ble side. A main reason for rank-transforming the values
                                                                    tistical relevance. University of Pittsburgh Press.
is to make them less task-dependent. The finding that
the optimal trade-off point is relatively more towards the       Speekenbrink, M. (2003). The hierarchical theory of jus-
more flexible side remains, even if we used the actual per-         tification and statistical model selection. In New De-
centages of correct predictions Our proposed method to              velopments in Psychometrics, (pp. 331–338). Springer.
assess model flexibility involved fitting models to a test       Spiegelhalter, D. J., Best, N. G., Carlin, B. P., & Van
data set generating by pairing random values of a de-               Der Linde, A. (2002). Bayesian measures of model
pendent variable (e.g., choices) to plausible values of the         complexity and fit. Journal of the Royal Statistical So-
independent variables (e.g., product dimensions). This is           ciety: Series B (Statistical Methodology), 64 (4), 583–
similar to using permutation methods in non-parametric              639.
statistics. In future work, we plan to explore this link         Wagenmakers, E.-J., Ratcliff, R., Gomez, P., & Iver-
further. Another future step could include simulations              son, G. J. (2004). Assessing model mimicry using the
of different environments in order to find out the nec-             parametric bootstrap. Journal of Mathematical Psy-
essary conditions for less flexible models to outperform            chology, 48 (1), 28–50.
                                                             2894

