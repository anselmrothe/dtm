UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Heuristics for Choosing Features to Represent Stimuli
Permalink
https://escholarship.org/uc/item/029646z4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Zeigenfuse, Matthew
Lee, Michael
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                           Heuristics for Choosing Features to Represent Stimuli
                                              Matthew D. Zeigenfuse (mzeigenf@uci.edu)
                                                     Michael D. Lee (mdlee@uci.edu)
                                    Department of Cognitive Sciences, University of California, Irvine
                                                             Irvine, CA 92697 USA
                               Abstract                                    another. We use these heuristics to begin answering the ques-
                                                                           tion of specifying what properties of a feature cause people
   In this paper, we compare three heuristic methods for choosing
   which of a set of features to use to represent a domain of stim-        to represent it.
   uli when we know the categories to which those stimuli belong.
   Our methods are based on three measures of category differen-               Representation and Basic-Level Categories
   tiation: cue validity, category validity, and their product, collo-
   cation. In a comparison of their ability to predict human simi-         Our heuristics are based on measures of category differenti-
   larity ratings in the Leuven Natural Concept Database, we find          ation that have been proposed to explain basic-level catego-
   collocation to have the best performance, suggesting people             rization. Basic-level phenomenology refers to people’s pref-
   use both cue and category validities in choosing which features
   to represent.                                                           erence to categorize objects at a particular level in a cate-
   Keywords: Feature representation; basic-level categorization;           gory hierarchy, known as the basic level. Key finds are ob-
   similarity judgment.                                                    jects are categorized into basic-level categories more quickly
                                                                           than sub- or super-ordinate categories, basic level objects are
                           Introduction                                    named faster, objects are described preferentially with ba-
Of all the aspects of their world that could be represented,               sic level names, more features are listed at the basic level
which do people actually choose? Imagine you are standing                  than at the superordinate level, basic level names are learned
in front of a black dog named “Rover” with a small white                   before names at other levels, and basic level names tend to
patch of hair under its left eye. Which of its features do you             be shorter (Rosch, Mervis, Gray, Johnson, & Boyes-Braem,
choose to represent: its tail and four paws, its name, “Rover”,            1976). These results suggest an intimate relationship between
and the spot under its eye? The last two of these may be useful            an object’s basic-level category and its mental representation.
for a representation of this particular dog, but are probably              Category-Based Measures
less useful to representing dogs as whole. Conversely, the first
                                                                           Category Differentiation Given a feature representation,
two may be useful for representing dogs, but are probably less
                                                                           many theories of basic-level categorization score potential
useful for distinguishing Rover.
                                                                           categorizations of the concepts in a domain through the infor-
   One method of learning about which aspects of a particular
                                                                           mation its categories give about the features of category mem-
set of concepts people represent is the feature generation task
                                                                           bers and vice-versa. Examples include, cue validity (Rosch
(Rosch & Mervis, 1975). Often in this task people are asked
                                                                           et al., 1976), category validity, collocation (Jones, 1983), fea-
generate a fixed number of features for each exemplar in a
                                                                           ture predictability (Corter & Gluck, 1992), category statis-
domain. In some cases, additional participants are asked to
                                                                           tical density (Kloos & Sloutsky, 2006), and strategy length
rate whether an exemplar has a feature for each combination
                                                                           and internal practicability (SLIP: Gosselin & Schyns, 2001).
of features and exemplars in a domain (Deyne et al., 2008).
                                                                           Inverting this logic, given a set of categories, we can score
This leads to a large number of features describing each ex-
                                                                           features on their usefulness in providing information about
emplar; however, not all of these features will be important to
                                                                           which of the set of categories a concept belongs to, the infor-
a person’s representation.
                                                                           mation knowing a concepts category provides about whether
   Zeigenfuse and Lee (2008, 2010) provide a computational-
                                                                           it has the feature, or a mixture of the two.
level (Marr, 1982) approach to the problem. Similar to the
theory of second-order isomorphism in perception (e.g. Shep-               Usefulness Measures The heuristics described here for
ard & Chipman, 1970), they argue that people represent those               choosing feature representations are based on three measures
features that determine the similarity between objects and de-             of feature usefulness. Suppose we have a domain of cat-
velop a model to infer which features are important using sim-             egories {c1 , . . . , cM }. Let f be an arbitrary feature. The
ilarity judgments. Unfortunately, their method does not of-                first heuristic is maximum cue validity, which we define as
fer a psychological rationale for why one feature is important             max1≤ j≤M p(c j | f ). The quantity p(c j | f ) is known in the lit-
vis-à-vis an unimportant one, since it is more of a statistical           erature as the cue validity of feature f (implicitly, with re-
solution than an account of feature importance.                            spect to category c j ). Psychologically, it expresses how well
   This paper expands upon the computational approach of                   having a feature predicts whether a stimulus belongs to a par-
Zeigenfuse and Lee (2008, 2010) by exploring psychologi-                   ticular category.
cal theories of what makes a feature important. To this end,                  We also look at maximum category validity, defined as
we propose heuristic methods for choosing important features               max1≤ j≤M p( f |c j ). Here p( f |c j ) is often referred to as the
based on how well a feature distinguishes categories from one              category validity f (again, implicitly, with respect to category
                                                                       1565

c j ). It expresses how well belonging to a category predicts               made of metal” and low frequency features such as “stands in
whether a stimulus has a particular feature.                                the crib at Christmas” and “stored in the cellar”.
    Finally,     we     look       at  maximum          collocation,           Domain similarity judgments are pair-wise similarity judg-
max1≤ j≤M p(c j | f )p( f |c j ). The quantity p(c j | f )p( f |c j ) is    ments collected between exemplars in a set of consisting five
known as the collocation of feature f and category c j . This               exemplars from each of the categories in a domain. This re-
measure has previously been applied by Jones (1983) in                      sults in sets of twenty-five exemplars for the animals domain
his feature possession score account of category basicness.                 and sets of thirty exemplars for the artifacts domain. Two dis-
Here it is applied as a measure that integrates both cue and                tinct sets of exemplars were chosen for each domain, resulting
category validity.                                                          four sets of domain similarity judgments.
Alternative Measures                                                                             Feature Selection Measures
We supplement the usefulness heuristics by two additional
                                                                            Starting with a set of features that we wish to select a feature
heuristics, included as baselines. The first of these is based
                                                                            representation from (such as the 765 animal or 1295 artifact
around a measure we term feature prevalence, defined to be
                                                                            features in the Leuven sets), each heuristic chooses a feature
the proportion of exemplars in a domain which possess a
                                                                            representation using a two step process. First, the useful-
given feature. The purpose of this heuristic is to compare the
                                                                            ness of each feature is computed under a particular useful-
usefulness heuristics to a simple heuristic using only base-
                                                                            ness measure. Then, we select those features whose useful-
rate information. The second is a “random” heuristic, which
                                                                            ness is above a pre-defined threshold. For example, suppose
simply selects subsets of features at random. This heuristic is
                                                                            we wish to use the collocation heuristic to choose among the
intended to illustrate how our usefulness heuristics compare
                                                                            seven features representing the exemplars of the three cate-
to an arbitrarily chosen heuristic for selecting features.
                                                                            gories in Table 1. First, we would compute the maximum
    The remainder of the paper compares the five heuristics
                                                                            collocation over categories for each of the features (shown in
using human similarity judgments. We procede as follows.
                                                                            the “Colloc.” column of Table 1). Then, we would select all
First, we describe the data on which the heuristics will be
                                                                            those features for which the maximum collocation over the
compared, the Leuven Natural Concept Database (Deyne et
                                                                            categories was above our threshold. In this example, were
al., 2008), a collection of normative data for semantic con-
                                                                            the threshold one-half, we would select features 1, 2, and 3.
cepts. We then present the selection heuristics and how the
                                                                            The same procedure can be used with the benchmark impor-
representations chosen are used to generate similarity judg-
                                                                            tance measure of Zeigenfuse and Lee (2008, 2010) to select a
ments. Next, we show the results of applying the heuristics
                                                                            representation.
to the Leuven database. We close by discussing what these
                                                                               The features selected by these heuristics to generate sim-
results tell us about the features people choose to represent
                                                                            ilarities according to a common features model (Shepard
stimuli and the difference between natural and artificial kinds.
                                                                            & Arabie, 1979). Suppose we have a set of features
        The Leuven Natural Concept Database                                 { f 1 , . . . , f K } from which we have selected a set of useful
                                                                            features indexed by U ⊆ {1, . . . , K}. The common features
The Leuven Natural Concept Database (Deyne et al., 2008)
                                                                            model says that similarity between concepts i and j is
contains normative data for semantic concepts falling into one
of two domains, animals and artifacts. These data consist
of typicality ratings, goodness ratings, goodness rank orders,
                                                                                                       si j = c + ∑ wk fki fk j ,         (1)
                                                                                                                  k∈U
generalization frequencies, exemplar associative strengths,
category associative strengths, estimated ages of acquisition,              where c is the universal similarity and wk is the salience of
word frequencies, familiarity ratings, imageability, and pair-              feature fk .
wise similarity ratings for concepts within a single category                  The remainder of the section is devoted to discussing for
as well as exemplar-by-feature matrices and pairwise simi-                  the benchmark and other heuristics in greater detail. In the
larity ratings between a subset of the exemplars in a domain                first subsection, we summarize the benchmark measure of
spread across its categories.                                               importance. In the second, we provide a rationales for each
    In our comparisons we make use of the exemplar-                         of the three category-based usefulness measures. In the final
by-feature matrices and domain similarity ratings. The                      subsection, we provide rationales for the two baseline heuris-
exemplar-by-feature matrices describe the exemplars of a do-                tics.
main in terms of a number of participant-generated features.
For the animals domain, 129 exemplars, split among the cat-                 Benchmark
egories birds, fish, insects, mammals, and reptiles, are de-                The Zeigenfuse and Lee (2008, 2010) method for learning
scribed in terms of 765 features. For the artifacts domain,                 which of a set of features people use to represent stimuli is
166 exemplars, split among the categories clothing, kitchen                 based upon latent variable selection. In this framework, those
utensils, musical instruments, tools, vehicles, and weapons,                features that are included in a concept’s representation are
are described in terms of 1295 features. These features in-                 termed “important” features. For each feature, they define a
clude both high frequency features such as “is a bird” and “is              variable zk indicating whether feature f k is used in similarity
                                                                        1566

                                Category 1              Category 2                    Category 3                  Cue   Cat.   Colloc.
        Feature 1           •    • • •         •                                                                   1     1        1
        Feature 2           •    • • •         •        •                                                         5/6    1       5/6
        Feature 3           •    • • •                                                                             1    4/5      4/5
        Feature 4                    •                                                                             1    1/5      1/5
        Feature 5           • • • •            •        •          •                    •   •     •    •          5/11   1      5/11
        Feature 6           • • • •            •                           •     •      •   •     •    •    •     5/12   1      5/12
        Feature 7                                           •              •                •                     2/3   1/3     4/21
                             Table 1: Representative features illustrating behavior of the usefulness measures.
judgments. Then, the similarity between concepts i and j is                 the category validity of f k with respect to category c j is
then                                                                        p( f k |c j ) = n jk /q j and the maximum category validity is the
                                   K                                        maximum of n jk /q j taken over j. Returning to Table 1, we
                       si j = c + ∑ zk wk fki fk j .                 (2)    see that features whose category validity is high (Features 1,
                                  k=1
                                                                            2, 5, and 6) are possessed by most of the exemplars in at least
    To learn which features are included in the representation,             one category.
Zeigenfuse and Lee (2008, 2010) develop a Bayesian model
                                                                            Maximum Collocation Maximum collocation is a measure
and sample from the marginal posterior over the zk using
                                                                            of how simultaneous concentrated in and diffuse across a cat-
Markov Chain Monte Carlo (MCMC). In this framework, a
                                                                            egory a feature is. Using the terminology of the previous sec-
feature’s importance is the marginal posterior probability the
                                                                            tions, the collocation of a feature f k with respect to category
feature is represented. They found that a small number of
                                                                            c j is (n jk /rk )(n jk /q j ). Maximum collocation is the maxi-
important features are able to fit similarity almost as well as
                                                                            mum of this quantity taken over j.
using all features.
                                                                                Features with high collocation are possessed by most ex-
Usefulness Measures                                                         emplars within a category and few outside it, as illustrated by
                                                                            the architypical Feature 1 in Table 1. Alternatively, Features 4
Different measures of usefulness correspond to different as-
                                                                            and 6 show why it is necessary for both of these to be true.
sumptions about what aspects of the environment lead a per-
                                                                            Those features possessed by only a small fraction of exem-
son to represent a particular feature. In the opening exam-
                                                                            plars within a single category will have high cue validity but
ple, the small white spot under the dog’s eye and its name,
                                                                            low category validity (Feature 4). Those features possessed
“Rover”, may be useful for representing the family dog, but
                                                                            by most exemplars in more than one category will have high
are probably not useful for representing dogs generally. This
                                                                            category validity but low cue validity (Feature 6).
section outlines the psychological theories of feature impor-
tance embodied by each of the usefulness heuristics.                        Alternative Measures
Maximum Cue Validity Maximum cue validity measures                          The two baselines used here are intended to show both how
how concentrated a feature is in a single category. Formally,               well our usefulness heuristics performed against heuristics
let rk be the total number of objects with a particular feature             embodying contrasting assumptions. The first of these is
 fk and let n jk be the number of objects with the feature in cate-         based on the base rate of a feature across stimuli, which we
gory c j . The cue validity of f k is then p(c j | f k ) = n jk /rk and     refer to as feature prevalence. For feature f k , the prevalence
the maximum cue validity is the maximum of n jk /rk taken                   is p( f k ) = rk /K, where rk is as defined in the previous sec-
over j.                                                                     tion. This shows that the ability of a feature to distinguish
    As illustrated by example features Table 1, maximum cue                 among categories does not affect its importance.
validity is large when most of the exemplars possessing a fea-                  The random heuristic provides a different sort of foil for
ture belong to the same category (Features 1 – 4), though                   the usefulness heuristics. Many methods other than those in-
this need not be a large number of exemplars (Feature 4). To                cluded here could be imagined for selecting a sets of features.
see why, note that maximum cue validity is large if and only                By selecting features at random, it allows us to compare the
if there exists a category for which n jk is nearly rk . Since              predictions of our heuristics to those an arbitrary method of
nlk ≤ rk − n jk for l 6= j, rk − n jk must be small and few exem-           choosing features.
plars with fk can belong to cl .
Maximum Category Validity Category validity measures                                               Method Comparison
how diffuse a feature is within a particular category. As with              Here we describe a comparison of maximum cue validity,
maximum cue validity, let n jk be the number of exemplars                   maximum category validity, and maximum collocation to
in category c j with feature f k , and define a new quantity q j            each other as well as the benchmark and baselines using the
to be the total number of exemplars belonging to c j . Then,                Leuven Natural Concept Database (Deyne et al., 2008). In
                                                                        1567

the first section, we enumerate the procedure used to fit the          that percentage of features. Alternatively, a heuristic whose
domain similarity data. In the second, we present the results          correlation is below the lower limit of the area fits worse than
of this procedure for each of the heuristics.                          95 percent of heuristics at that percentage of features.
                                                                           Regardless of data set, the orders produced by the
Procedure                                                              Zeigenfuse and Lee (2008, 2010) measure is always able to
The fit procedures begins with the exemplar-by-feature ma-             fit the similarities in the top 5 percent of ordering, justifying
trices. Before applying any of the heuristics we filter out all        its use a benchmark. The orders produced by feature preva-
features possessed by zero, one, or all of the 25 or 30 ex-            lence nearly always perform worse than those generated by
emplars included in the domain similarity comparisons. Fea-            the other measures, often in the worst 5 percent of all orders.
tures possessed by one exemplar or fewer will not be used              On the whole, cue validity, category validity, and collocation
in any similarity comparisons, since fki fk j = 0 for all dis-         perform middling to well, rarely performing worse than fea-
tinct stimuli i and j. Features possessed by all exemplars             ture prevalence.
will be used in every similarity comparison, so they can be                For the animals data sets, cue validity outperforms category
included in the constant term c in Equation (2). Addition-             validity for small numbers of features (less than around 20
ally, we find all groups of features possessed by exactly the          percent), category validity outperforms cue validity for larger
same set of exemplars, and combine these into a single fea-            numbers of features, and collocation is always commensurate
ture. Suppose f k and f l are features possessed by exactly            to the best of these. For very small (less than around 10 per-
the same set of exemplars. Then, fki = fli for all i and               cent) numbers of features, cue validity performs better than
wk fki fk j + wl fli fl j = (wk + wl ) fki fk j .                      the benchmark; however, for larger numbers of features its
    After pre-processing, for the benchmark and all of the             performance is at best mediocre. After a slow start, category
heuristics except the random heuristic, we compute its cor-            validity performs in the top 5 percent of orderings for larger
responding measure using all of the exemplars in the domain,           numbers of features. Collocation always performs near the
not just those included in the domain similarity judgments.            benchmark and is nearly always in the top 5 percent of order-
The features are then sorted in order of decreasing value on           ings.
these measures. Starting with only the top two features, we                For the artifacts data sets, cue validity still performs bet-
fit the common features model to the domain similarity judg-           ter than category validity for very small (less than 10 per-
ments using non-negative least squares and compute the cor-            cent) numbers of features, after which category validity per-
relation between the fitted similarities and the actual similari-      forms better than cue validity. As with animals, collocation
ties. We repeat this process with the top three features, the top      performs near or better than the best of these two measures.
four features, etc. To apply this procedure with the maximum           Category validity and collocation nearly always perform be-
collocation heuristic to the features in Table 1, we first com-        tween the 5th and 95th quantiles of heuristics; however, for
pute the values in the collocation column. We then order the           larger numbers of features (around 20 percent in the first set
features in order of decreasing collocation, which in this case        and around 40 percent in the second), cue validity performs
is 1, 2, 3, 5, 6, 4, 7. We first fit the model with features 1 and     in the bottom 5 percent of orderings.
2, then 1, 2, and 3, followed by 1, 2, 3, and 5, etc. Finally,             Overall, these results suggest that both cue and category
for the random heuristic, we generated 100 random feature              validity contain information about a feature’s importance.
orders and apply this procedure to each of the orders.                 Collocation always performs about the same as the best of cue
                                                                       and category validity, indicating that it tracks the best aspects
Results
                                                                       of the two measures. This suggests that early on collocation
Figure 1 shows the correlation between observed and those              is dominated by features with high cue validity, but later it is
fitted using the first x percent of features ordered by either         dominated by category validity.
cue validity, category validity, collocation, prevalence, or the
benchmark. For example, on the collocation line (shown as a                                        Discussion
solid line) the correlation at a percentile rank of 20 percent is
the correlation between the observed values and those fitted           Cue and Category Validity
using the first 20 percent of features ordered by collocation.         The major result of the previous section is that both cue
The smaller pane in the lower right-hand corner is a blowup            and category validity seem to be important to choosing
of the lines in rectangular region extending from 0 − 20 in            which of a set of features makes a good representation.
percentile rank and from 0.6 − 1 in correlation.                       Murphy (1982) suggests why this may be the case: cue
    The gray shaded area shows 95% confidence intervals for            validity cannot pick out basic-level categories because it
the correlation between the values fitted using first x percent        can only increase for more inclusive categories. Consider
of features chosen by the random heuristic and the observed            the hierarchy of categories animal, bird, duck, in which
values. These orders give an estimate of how difficult the             bird is the basic-level category, and suppose we wish to
similarity data are to fit with a heuristic choosing x percent of      compute the cue validity of the feature “has wings”. Let
the available features. A heuristic whose correlation is above         rwings be the number of things with wings and nducks,wings ,
the upper limit of the area fits better 95 percent of heuristics at    nbirds,wings , and nanimals,wings be the number of ducks, birds,
                                                                   1568

                                           1.0                                                           1.0
                                           0.8                                                           0.8
                                                           1.0                                                           1.0
                 Animals     Correlation                                                   Correlation
                                           0.6                                                           0.6
                                           0.4             0.8                                           0.4             0.8
                                           0.2                                                           0.2
                                                           0.6                                                           0.6
                                           0.0                    0        10        20                  0.0                    0        10        20    Heuristic
                                                 0    20     40       60        80   100                       0    20     40       60        80   100       Collocation
                                                     % of Features                                                 % of Features
                                                                                                                                                             Benchmark
                                                                                                                                                             Cue
                                           1.0                                                           1.0                                                 Category
                                                                                                                                                             Prevalence
                                           0.8                                                           0.8
                                                           1.0                                                           1.0
                 Artifacts   Correlation                                                   Correlation
                                           0.6                                                           0.6
                                           0.4             0.8                                           0.4             0.8
                                           0.2                                                           0.2
                                                           0.6                                                           0.6
                                           0.0                    0        10        20                  0.0                    0        10        20
                                                 0    20     40       60        80   100                       0    20     40       60        80   100
                                                     % of Features                                                 % of Features
Figure 1: Model fit by the percent of features used for each of the four sets of domain similarities in the Leuven data set. The
benchmark, three category-based heuristics, and feature prevalence baseline are shown as lines. In the legend, “collocation”
corresponds to the maximum collocation heuristic, “benchmark” to the benchmark, “cue” to maximum cue validity, “category”
to maximum category validity, and “prevalence” to feature prevalence. The gray area shows a 95% confidence interval for the
fit of the random heuristic. The panels in the lower righthand corner of each of the plots enlarges the rectangular region from
0 − 20 in percent of features and from 0.6 − 1 in correlation in the main plots.
and animals with wings.             Since ducks are birds and                                              Natural Versus Artificial Kinds
birds are animals, nducks,wings ≤ nbirds,wings ≤ nanimals,wings , so                                       A final point worth mentioning is the difference in perfor-
nducks,wings /rwings ≤ nbirds,wings /rwings ≤ nanimals,wings /rwings .                                     mance of the heuristics on data sets containing natural kinds
But the n·,wings /rwings is just the cue validity of “has wings”,                                          versus those containing artificial kinds. Numerous authors
illustrating why, in settling on basic-level categories, people                                            have suggested that natural and artificial kinds are represented
must be sensitive to more information than just cue valid-                                                 in fundamentally different ways (e.g. Keil, 1989). Results of
ity. Since similarity is assumed to reflect representation, this                                           Zeigenfuse and Lee (2010) support this theory, finding the ra-
should be reflected in measures used to select representations.                                            tio between the probability two stimuli within the same cate-
   Along these lines, Tenenbaum and Griffiths (2001) offer                                                 gory have a feature and the probability two arbitrarily chosen
a fuller explanation for why both cue and category validities                                              stimuli have a feature is larger for natural kinds than artificial
should be important to choosing good representations. They                                                 ones.
argue that people generalize properties to novel instances                                                    Here we find a similar result: for animals data sets colloca-
only in the smallest set of instances consistent with known                                                tion nearly always performs in the top 5 percent of heuristics,
examples, a theory known as the “size principle”, and further                                              whereas for artifacts data sets, collocation performs about as
that similarity is the degree to which the consequences of be-                                             well as an arbitrary heuristic. In theory this difference could
ing one object generalize to another. By this logic, choosing                                              come from either differences in the types of features repre-
features on the basis of cue validity will lead to categories                                              sented or the ability of the common features model to fit sim-
which are overly restrictive and choosing features on the basis                                            ilarity judgments among exemplars of that domain. The latter
of category validity will lead to categories which are overly                                              seems unlikely, however, given that the benchmark performs
broad. Appropriate generalization, then, requires taking both                                              well for all four data sets it seems a common features similar-
types of information into account. Thus, we would expect a                                                 ity model is able to fit the data well.
heuristic that does this, like collocation, to choose better rep-                                             This, then, suggests that the difference in fits comes from
resentations than heuristics that do not.                                                                  differences in the types of features people choose to repre-
                                                                                                1569

sent. Among animals, people prefer features that are closely             these regularities can be uncovered by investigating the rela-
tied to a particular basic category. Among artifacts, they seem          tionship between categories and features.
to prefer a different strategy, representing features for multi-
ple levels in a category hierarchy or selecting features using                                    References
different criteria.                                                      Corter, J. E., & Gluck, M. A. (1992). Examining basic cate-
                                                                            gories: Feature predictability and information. Pyscholog-
Extensions                                                                  ical Bulletin, 111, 291-303.
                                                                         Deyne, S. D., Verheyen, S., Ameel, E., Vanpaemel, W., Dry,
A detailed explanation of this difference may requires exten-
                                                                            M., & Voorspoels, W. (2008). Exemplar by feature applica-
sions addressing one of both of these sources. The first of
                                                                            bility matrices and other Dutch normative data for semantic
these begins from the recognition that the source of the appar-
                                                                            concepts. Behavior Research Methods, 40(4), 1030-1048.
ent distinction between natural and artificial kinds may stem
                                                                         Gosselin, F., & Schyns, P. G. (2001). Why do we SLIP to
not from an actual difference but from an incorrect choice of
                                                                            the basic level? Computational constraints and their imple-
selection heuristic. Thus, it makes sense to look at heuris-
                                                                            mentation. Psychological Review, 108(4), 735-758.
tics based on additional measures of category differentiation.
                                                                         Jones, G. V. (1983). Identifying basic categories. Psycholog-
The second supposes choosing just those features associated
                                                                            ical Bulletin, 94, 423-428.
with basic-level category structure is not sufficient for select-
                                                                         Keil, F. (1989). Concepts, kinds, and cognitive development.
ing good feature representations.
                                                                            Cambridge, MA: MIT Press.
Additional Heuristics In order to explore the first of these             Kloos, H., & Sloutsky, V. M. (2006). What’s behind differ-
extensions, we could develop heuristics based on different                  ent kinds of kinds: Effects of statistical density on learning
measures, both those that have been proposed in the basic-                  and representation of categories. Journal of Experimental
level literature and outside it. Such measures could include                Psychology: General, 137(1), 52-72.
the category likelihood ratio (Zeigenfuse & Lee, 2010), the              Markman, A. B., & Gentner, D. (1993). Structural alignment
mutual information between a category and a feature SLIP                    during similarity comparisons. Cognitive Psychology, 25,
(Gosselin & Schyns, 2001). These last of these differs from                 431-467.
the first two in that, in the first, each feature affects the quality    Marr, D. (1982). Vision: A computational approach. San
of a categorization independent of all other included, whereas              Francisco: Freeman & Company.
in the second two the effect of adding a new feature depends             Murphy, G. L. (1982). Cue validity and levels of categoriza-
upon the features already included.                                         tion. Psychological Bulletin, 91(1), 174-177.
Category Hierarchies The second extension allows the                     Rosch, E., & Mervis, C. B. (1975). Family resemblances:
method to deal with category hierarchies. The importance                    Studies in the internal structure of categories. Cognitive
of structured representation in understanding human judg-                   Psychology, 7, 573-605.
ments of similarity has been illustrated by many authors (e.g.           Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., &
Markman & Gentner, 1993). Understanding how such struc-                     Boyes-Braem, P. (1976). Basic objects in natural cate-
tured representations influence those features represented is               gories. Cognitive Psychology, 8, 352-382.
a crucial step towards bringing these models into contact                Shepard, R. N., & Arabie, P. (1979). Additive clustering:
with feature-based models such as Tversky’s contrast model                  Representations of similarities as combinations of discrete
(Tversky, 1977). One potential method for acheiving this                    overlapping properties. Psychological Review, 86(2), 87-
would be to compute the collocation, or other measure, at                   123.
each level in a category hierarchy and to use a weighted com-            Shepard, R. N., & Chipman, S. (1970). Second-order isomor-
bination of the collocations as the selection criterion.                    phism of internal representations: Shapes of states. Cogni-
                                                                            tive Psychology, 1, 1-17.
                           Conclusion                                    Tenenbaum, J. B., & Griffiths, T. L. (2001). Generalization,
                                                                            similarity, and Bayesian inference. Behavioral and Brain
In this paper, we have presented three heuristic methods for                Sciences, 24(4), 629-640.
choosing a feature representation based on measures of cat-              Tversky, A. (1977). Features of similarity. Psychological
egory differentiation. We find these heuristics to fit human                Review, 84, 327-352.
data better than heuristics that do not take this information            Zeigenfuse, M. D., & Lee, M. D. (2008). Finding feature
into accounts, acheiving very good fits for natural kinds and               representations of stimuli: Combining feature generation
above average fits for artificial kinds. Moreover, our results              and similarity judgment tasks. In V. Sloutsky, B. Love,
suggest both how concentrated in a particular category a fea-               & K. McRae (Eds.), Proceedings of the 30th annual con-
ture is and how diffuse it is across exemplars in that category             ference of the cognitive science society (p. 1825-1830).
are important factors in whether a feature is represented as                Austin, TX: Cognitive Science Society.
well as supporting a distinction between natural and artifi-             Zeigenfuse, M. D., & Lee, M. D. (2010). Finding the features
cial kinds. Though much still needs to be done, this work                   that represent stimuli. Acta Psychologica, 133, 283-295.
suggests people choose features in a systematic way and that
                                                                     1570

