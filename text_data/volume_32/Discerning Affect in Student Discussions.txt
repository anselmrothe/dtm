UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Discerning Affect in Student Discussions
Permalink
https://escholarship.org/uc/item/9tg4362n
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Kim, Jihie
Shaw, Erin
Wyner, Saul
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                     Discerning Affect in Student Discussions
                              Jihie Kim, Erin Shaw, Saul Wyner, Taehwan Kim, and Jia Li
                                                            (jihie@isi.edu)
                                 University of Southern California/ Information Sciences Institute
                                                    Marina del Rey, CA 90292 USA
                            Abstract                                    We describe the first stages of the development of
  Students’ emotions and attitudes are discernible in
                                                                        practical classification for emotion acts and explore the
  messages posted to online question and answer boards.                 potential    of     sentiment-based     student    profiling.
  Understanding student sentiment may help instructors                  Specifically, in this paper, we do the following:
  identify students with potential course issues, optimize              1. Identify categories of affect exhibited in an online
  help-seeking, and potentially improve student achievement,                 student discussion in an undergraduate CS course.
  as well as identify both positive and negative actions by
  instructors and provide them with valuable feedback.                  2. Examine the frequency of affect in the corpus by
  Towards this end, we present a set of context-independent                  gender, role and types of participants.
  emotion acts that were used by students in a university-              3. Examine the influence of affect in instructor
  level computer science course to express certainty and                     messages on student responses (discerned by affect).
  uncertainty, frustration, and politeness in an online Q&A             4. Examine the correlation between affect and type of
  board and develop viable classification approaches. To                     thread (resolved or unresolved).
  explore the potential of sentiment-based profiling, we
                                                                        5. Illustrate of how emotion acts can be used in
  present a heuristic-driven analysis of thread resolution and
  detail future research.                                                    assessing and predicting student discussion outcome.
                                                                        6. Describe our approach to and initial results of
   Keywords: student online discussions, discourse analysis.                 automatically classifying three categories of affect.
                        Introduction                                              Identifying Categories of Affect
Online discussion boards are widely used in higher                      It is extremely difficult to devise a category of affect
education, extending the availability of instructors,                   labels given the gradations and subtlety of the way
assistants, and materials to students beyond the traditional            feelings and emotions are expressed in language. It is not
classroom. Students use discussion forums to collaborate,               surprising then that there is no general agreement on how
exchange information, and seek answers to problems from                 to label affective content and that instead there exist a
their instructors and classmates. Discussion board use is               number of different labeling schemes for different
generally associated with improved academic perfor-                     domains (Ordelman and Heylen, 2005). However,
mance and greater student satisfaction (Kumrow, 2005;                   previous work suggests that at least some affective
Newman and Schwager, 1995).                                             content can be identified and selected for, independent of
    Previous work on analyzing student discussions has                  context.     For     example,     acknowledgements        are
been based on rhetorical speech acts, course topics, and                recognizable by the presence of common politeness
problem tasks (Kim et al., 2007; McLaren et al., 2007).                 phrases (Brown & Levinson, 1987), and may be used to
Classification systems for these features enable                        indicate resolution in Q&A discussion; and certainty
researchers to automatically identify student problems.                 categorization was shown to assist in distinguishing
Similarly, understanding student affect may help                        between editorial and news writing (Rubin et al., 2006),
instructors identify students with potential course issues,             and may be used to distinguish questions and answers by
optimize help-seeking, and potentially improve student                  the presence and absence of student confidence.
achievement. In addition, by examining the results of                     Identifying a set of categories was an iterative process,
different instructor-student interactions in terms of affect,           and there were three criteria for selection: a) category
instructors could potentially receive valuable feedback                 examples had to be well represented in the corpus, b)
about their online interactions.                                        researchers had to agree on the categories, and c)
  In this paper we present a set of dialogue features, or               categories had to be relevant to student learning. Selection
emotion acts (EAs), analogous to Speech Acts (Searle,                   was originally motivated by the desire to identify
1969), that characterize student sentiment with respect to              students’ self-efficacy and attitudes, although these
1) frustration and tension, 2) high and low certainty                   categories were too abstract to be practical. We examined
(confidence) and 3) politeness. These sentiments were                   discourse that indicated confidence, interest and mastery,
exhibited in student discourse within a question and                    and also, urgency, understanding and technicality. Our
answer (Q&A) board in an undergraduate Computer                         final categories were high and low certainty (confidence),
Science course. A discussion corpus consisting of 1,030                 tension/frustration, and politeness.
student posts was manually tagged with the emotion acts.
                                                                  2344

Tension (kappa: 0.74)                                                        Examples
Instructor Judgments: Possible student issues with class attendance,         If you really want to do this; I stated in class on at least 2
judgment or choices                                                          occasions
Student Judgments: Possible student issues with questioner or target         Result of this sucks; Wow… That was..
Frustration (kappa: 0.92)                                                    Examples
Repetitious Actions, Continual Actions: Descriptions of continuous           A lot (15+ times); Never seems to end; High rate of
actions without real progress                                                redundancy; Another can of worms
Large Quantities: Descriptions of overwhelming amounts of work and Zillions of references; Super-huge; Simply gargantuan;
other material                                                               Monstrous, super-verbose
Difficulty/Impassability, Material Denigration: Statements of explicit
                                                                             Serious disk quota problems; Severe annoyances; A pain to fix;
difficulty in either solution or understanding of issues, as well as
                                                                             Makes it really hard
frustration about the material itself
Self-Denigration/Lack of Confidence: Declarations of a personal belief I have spent FAR too long; …I’m stumped; Longer than they
in a lack of ability on the part of the poster                               should have
High Certainty (kappa: 0.80)                                                 Examples
Specificity of Question/Answer: Specific phrasing that concisely
                                                                             The only way; I found the answer; It only appears
explains through examples and pre-conditions
Ease of Understanding/Completeness: Emphasis of the simplicity or            The trick is; Just wait till; Will be simple; All you need to do
completeness of a solution or question                                       is
Necessity: Specifically stating that the presented solution is required,     Must be able to; Vitally important task;
or in the case of a question, its importance                                 Must have something; You will
Logical Presentation: A method of presenting a proposition, solution,
                                                                             I assume that; Granted,; Likewise,; On the other hand,
or question that makes it a logical proposal
Low Certainty (kappa: 0.95)                                                  Examples
Vagueness in Question/Answer: Statements that imply only general or
                                                                             What is wrong?; If I understand; Seems to me; Read it
surface understanding of the material at hand by stating personal
                                                                             somewhere
understandings over factual presentation
Lack of Understanding: Statements that clearly state a lack of
                                                                             I am still confused; Not sure if I understand; I follow most; I’m
understanding; differs from other Speech Acts as it implies a
                                                                             not sure
continuing lack, rather than an individual issue
Optional Nature: Statements indicating a not strongly recommended or Should be compiled from the network directory; You might
vital issue, solution, or question                                           try; …maybe I’ll try making; What is wrong?
Weakened Presentation: Phrases that weaken or justify logical                Correct me if I am wrong; Apparently; I am guessing that is the
proposal statements                                                          way; As far I know
Politeness categories                                                        Examples
Positive (kappa: 0.99): Language strategies used according to formal
cultural rules to avoid losing face. Commonly identified as typical          Thanks; Okay thanks; Good luck with your project
polite speech
Negative (kappa: 0.99): Dealing with a face-threatening act, by              I was wondering if; Thought I’d throw this out there; Get this
lightening the request or response into a less pressing, informal status.    cleared up early; Just a head’s up,
Bald on record (kappa: 0.84): Dealing with a face-threatening
                                                                             I question the; don’t bzero anything; Change it to this; Do we?
situation by ignoring or emphasizing the consequences of the threat
Off record (kappa: 0.82): Attempting to change the request or
                                                                             Has anyone else had this problem; What would do; Asking for
response into a non-face-threatening statement, i.e., by generalizing a
                                                                             answers directly is way easier
query to a rather than asking for direct help
                                            Table 1. Categories of affect – description and examples.
The final categories had high agreement among the                              subculture language use. This necessitated a high level of
research team, and thus had potential for use in an                            selectivity and repeatability in all annotations, as well as
automatic classification system.                                               reliance on specific patterns of distinct phrases and
Annotation Methodology                                                         grammar from within the corpus rather than whole
                                                                               statements.
Annotating affect involved identifying those speech                                Table 1 lists and describes the final EA categories. A
fragments that reliably indicated an identified emotion act                    dataset of 1,030 messages in 210 threads from an
in a repeatable fashion throughout the corpus of student                       Operating Systems course was analyzed. Several
discussion board posts. This was complicated by the                            iterations were performed until we minimized ambiguity
highly irregular nature of the message content, which was                      among the categories and finalized clear EA definitions.
characterized by frequent misspellings and grammar and                         For inter-annotator agreement, we compared two
syntactical errors, stemming from common parlance,                             annotators’ data on 322 messages in 30 discussion
simple carelessness, and Computer Science student                              threads. For the current categories, the kappa values are
                                                                       2345

greater than 0.7. Some Politeness EAs show very high                                 student frustration and low certainty can follow the
agreement ratios since the annotators consider them very                             instructor’s expression of low certainty.
clear and there are only small numbers of cases.                                          While these results show many interesting possible
    The labeling process consisted of EA classification as                           relationships between expressed emotion acts and topic
well as the marking up of contextual information within                              success, the clear and immediate indication shows that
the message content. The markup included information                                 emotion acts can show distinctions between different
about the type of response (question/query or                                        types of posts and threads, which prove their potential
answer/statement) and the role of the author (student,                               usefulness as a profiling mechanism.
instructor, or TA).
                                                                                        Table 2. Distribution of Emotion Acts among participants.
Affect Frequency by Type of Participants                                                                        Percent Emotion Acts found in messages:
The final frequency distribution of emotion acts for
                                                                                      Emotion Act                                      Male            Female                Instruct-
messages posted by different participants within the                                                            Total
                                                                                                                                      Student          Student                  or
dataset is shown in Table 2. Of interest are the high                                                          (N=1179)
                                                                                                                                     (N=782)           (N=62)                (N=300)
occurrences of low certainty and the relatively high
                                                                                     Tension                    2%                      1%               0%                    6%
frequency of frustration. Female students seemed to
present less frustration than male students. Also, females                           Frustration                14%                    19%               9%                    2%
present more positive politeness in their messages. As                               Certainty_High             32%                    31%              36%                    35%
expected, the instructor’s messages show high confidence.                            Certainty_Low              20%                    26%              27%                    4%
Among politeness categories, the instructor presents more                            Politeness_Pos             13%                    15%              55%                    0%
bold-on-record politeness (BOR) than students.                                       Politeness_Neg             13%                    18%               3%                    3%
   We also looked at the presence of emotion acts among
                                                                                     Politeness_OFF             5%                     6%               11%                           0%
high and low frequency contributors. Figure 1 shows the
distribution of different emotion acts for seven groups of                           Politeness_BOR             10%                    8%               11%                           16%
contributors. As can be predicted from the distribution in
Table 2, confidence and polite acts dominate. For the
students who post many messages, the number of other
emotion acts increases, especially confidence, but also
frustration and negative politeness.
Influence of Instructor Affect on Students
The course instructor participated in discussions in many
ways; he provided answers directly, gave alternative
perspectives, supported student ideas, and elaborated on
student answers. It is useful to analyze the influence of
the instructor on student dialogue.
     In Table 3, we consider what happens when an
instructor exhibits emotion. It appears that students tend
to express more emotion themselves (certainty,
frustration, negative politeness) after an instructor shows
emotion. Students appear to express high certainty when                                 Figure 1: Distribution of Emotion Acts in infrequent and
they respond to an instructor’s high certainty. Similarly,                                       frequent discussion board contributors.
                                         Table 3: Students’ EAs following an instructor EAs.
                  Following
                                                                                                                        Polite_Pos
                                                                Frustration             High_Cert                                                       Polite_OFF       Polite_BOR
                 Student EAs              #
     Instructor EAs                               Tension                                           Low_Cert                              Polite_Neg
                                                  0              31                    60                44             22               35                    6                  12
     Tension                        19            0          2                             4          6                  1                1                    1                   2
     Frustration                     7            0          2                             2          1                  1                2                    0                   0
     High_Certainty                107            0         16 (15%)                 33 (31%)       23 (21%)            5               20(19%)                 3                  9
     Low_Certainty                  12            0         5 (42%)                   3 (25%)        4 (33%)            2               4 (33%)                 0                  0
     Politeness_Pos                  1            0         1                              0           1                 0                   1                       0                0
     Politeness_Neg                 11            0         1                              2           1                12                   2                       1                0
     Politeness_OFF                  0            0         0                              0           0                0                    0                       0                0
     Politeness_BOR                 49            0         4                         16 (33%)         8                1                    5                       1                1
                                                                              2346

                                   Emotion Act Percentage (%) From Each Group
                                           Certainty Level                                                       Politeness
                                                                          Frus-      Tensio
   Subset for Analysis (N)                                                                     Bald-On-                            Off-
                                 High      Low       Med        N/A      tration       n                   Positive    Negative
                                                                                                Record                            Record
  All Posts            (1030)    49.03     13.50       3.79     33.69       24.27      2.72        19.71      17.38         24.66    6.89
  All Resolved         (916)     50.11     12.99       3.17     33.73       23.47      2.84        19.43      17.36         23.91    6.33
                                                                                                                                     11.4
  All Unresolved       (114)     40.35     17.54       8.77     33.33       30.70      1.75        21.93      17.54         30.70
                                                                                                                                        0
  Resolved Answers     (645)     56.12     10.23       2.95     30.70       18.60      3.72        22.79      11.16         20.31    2.02
  Unresolved Answers   (79)      43.04     10.13       8.86     37.97       25.32      1.27        29.11      13.92         32.91    6.33
                                                                                                                                     16.6
  Resolved Questions   (271)     35.79     19.56       3.69     40.96       35.06      0.74        11.44      32.10         32.47
                                                                                                                                        1
  Unresolved                                                                                                                         22.8
                       (35)      34.29     34.29       8.57     22.86       42.86      2.86         5.71      25.71         25.71
  Questions                                                                                                                             6
  Resolved Inst. Ans.  (233)     62.66      2.58       0.43     34.33        5.58      8.58        35.19       3.00          7.30    0.43
  Unresolved
                       (25)      48.00      0.00       8.00     44.00        0.00      4.00        44.00       8.00         16.00    0.00
  Inst. Ans.
  Resolved                                                                                                                           20.0
                       (180)     33.89     17.78       2.22     46.11       33.33      0.56        13.89      37.22         32.78
  First Posts                                                                                                                           0
  Unresolved                                                                                                                         23.3
                       (30)      43.33     16.67       3.33     36.67       50.00      0.00        23.33      36.67         40.00
  First Posts                                                                                                                           3
  Resolved
                       (180)     45.56     16.11       4.44     33.89       17.22      2.22        17.22      26.11         24.44    5.00
  Final Posts
  Unresolved
                       (30)      26.67     13.33       3.33     56.67       20.00      0.00        30.00       6.67         13.33    6.67
  Final Posts
                            Table 5. The distribution of relevant emotion acts in resolved vs. unresolved threads.
                                                                           closely conform to their intrinsic impressions of
               Affect Patterns in Threads                                  “resolved” threads. Those threads that were not
While sentiment-based discussion analysis is a significant                 considered resolved were classified as an “unresolved”.
development, emotion acts represent only the lowest level                  This revealed 180 resolved, and 30 unresolved threads.
of potential analysis of student message content. With                        After this classification, both resolved and unresolved
consistent and functional emotion acts, posters, posts, and                threads were further broken-down into relevant subsets
entire threads can be analyzed in terms of repeatable EA                   for EA analysis. The analysis was based upon a simple
profiles. As a proof of concept, we wished to develop an                   presence test for specific EAs, and the percentage of posts
independent heuristic to classify threads with a                           within the subset that contained that emotion act.
hypothetically robust emotional distinction, and examine                   Certainty, however, as the most common emotion act,
the resulting EA profile for such a distinction.                           was instead calculated as a level, defined by containing
     We chose the concept of resolved and unresolved                       over 75% of a specific type of either high or low certainty
discussion threads, where resolved threads contain a final                 emotion acts. If the ratio was less than 75%, it was
                                                                           designated as medium certainty. While rudimentary, this
solution or demonstrable ratification of issues, as well as a
                                                                           examines the potential for more rigorous profiling, by
beneficial discussion, and open threads are those for
                                                                           revealing any obvious difference among threads.
which initial questions are not satisfied or which have                       The results show a clear distinction between resolved
unresolved issues. The ultimate goal is to identify patterns               and unresolved threads. Distinctions were noted when
of affective states that help to discern students who may                  there existed at 10% or above difference from resolved vs.
require further assistance, and topics that may require                    unresolved versions of the chosen subset.
further clarification. Towards this goal, we experimented                     Within the certainty measures, high certainty is shown
with several classification measures based upon observed                   to strongly influence the resolution of a thread with
trends in annotated threads. To fulfill the need for a                     respect to answers, while having little effect on questions.
conclusion, we focused on threads that concluded with an                   However, in initial posts, high certainty seems to counter-
answer, or an acknowledgement of thanks for a provided                     indicate resolution. In contrast, low certainty seems to
solution. To ensure a basic level of back-and-forth                        have minimal effect, except in the case of questions, in
pedagogic discourse we included only the subset of                         which it is strongly represented in unresolved questions.
threads that also contained equal numbers of or more                       A lack of certainty (both high and low) also strongly
answer/statement posts. The generated results by these                     differentiates resolved and unresolved questions and
criteria were examined by the annotators and found to                      initial posts, while it shows the inverse in final posts.
                                                                   2347

   In terms of frustration and politeness, frustration is           manually-annotated training data, the result is not yet at a
unsurprisingly well-represented in unresolved posts,                level where it can be immediately applied in a functional
though most notably in initial posts. Bald-on-record                setting. However, we strongly expect these results to
politeness shows strongly in unresolved instructor                  improve as more training data becomes available.
answers, original posts, and final posts. Positive
politeness is seen greatly in resolved questions and final                                      Test Data Results
posts, while negative politeness is greater in resolved final            Emotion Act         Precision      Recall      F-Score
posts. Off-record politeness shows little effect overall.                High Certainty      0.68           0.64        0.65
                                                                         Low Certainty       0.80           0.83        0.81
           Automatic Affect Classification                               Frustration         0.73           0.75        0.73
For automatic classification of emotion acts, we followed                     Table 4. Automatic classification test results for
                                                                                        certainty and frustration.
a similar approach that was previously applied to identify
speech acts in student discussions (Kim et al., 2009). We
focused on certainty and frustration because they are most                                Related Work
relevant to student performance. The annotated discussion
threads were first pre-processed: Because student                   Our work builds on prior research on spoken dialogue
discussions are informal and noisy with respect to                  analysis including dialogue acts (Searle 1969; Hirschberg
grammar, syntax and punctuation, our model fixes                    and Litman 1993; Samuel 2000; Graesser et. al., 2001;
common typos, transforms informal words to formal                   Kim et al., 2009), rhetoric analysis (Mann and Thomson,
words, and converts apostrophes to their original forms. It         1988), and surface cue words analysis (Hirschberg and
replaces some typical words and phrases with fixed                  Litman 1993; Samuel 2000). There have also been
keywords; for instance, programming code fragments are              Dialogue Acts modeling approaches for automatic tagging
replaced with by CODE, and contractions such as “I’m”               and recognition of conversational speech (Stolcke et al.,
and “You’re” were replaced with “I am” and “You are”.               2000) and related work in corpus linguistics where
The features used include:                                          machine learning techniques have been used to find
 F1: Cue phrase and their position in the post                      conversational patterns in spoken transcripts of dialogue
 We used n-gram features including unigrams (1 word),               corpus (Shawar and Atwell, 2005). Although spoken
 bigrams (two word sequence), trigram (three word                   dialogue is different from message-based conversation in
 sequence) and two separate unigrams. We also use position          online discussion boards, they are closely related to our
 in the post as in the first part, last part or elsewhere.          thread analysis work, and we plan to investigate potential
 Beginning sentences can have different meanings than those         use of conversation patterns in spoken dialogue in
 in subsequent sentences. For example, “Thank you” in the           threaded discussions.
 beginning sentence position may be an expression of                  Carvalho and Cohen (2005) present a dependency-
 gratitude for previous information, while “thank you” in the       network based collective classification method to classify
 last sentence may indicate only politeness.                        email speech acts. However, estimated speech act labeling
 F2: Message position in the thread: Indicates if the post is       between messages is not sufficient for assessing
 the first post, last post or one of the other posts.               contributor roles or identifying help needed by the
 F3: The emotion acts of the previous message: EAs in the           participants. We included other features like participant
 previous message that the current message is replying to.          profiles. Also our corpus consists of less informal student
 F4: Poster class: Defined as either a student or instructor.       discussions rather than messages among project
 F5: Poster change: Checks if the current poster is the same
                                                                    participants, which tend to be more technically coherent.
 as the previous.
                                                                      Requests and commitments of email exchange are
 F6: Post length: Categorizes the post as Short (1-5 words),
 Medium(6-30 words), or Long (>30 words).
                                                                    analyzed in (Lampert et al., 2008). As in their analysis,
                                                                    we have a higher kappa value for questions than answers,
    Given all combination of features F1-F6, we used                and some sources of ambiguity in human annotations such
Information Gain (Yang and Pedersen, 1997) to prune the             as different forms of answers also appear in our data.
feature space and select features. For each Emotion Act,
                                                                    However, student discussions tend to focus on problem
we sorted all features (lexical and non-lexical) by
                                                                    solving rather than task request and commitment as in
Information Gain and used the top N (=200) features.
                                                                    project management applications, and their data show
    We used the Support Vector Machine of Chang and
Lin (2001). We did a 5-fold cross validation in the                 different types of ambiguity due to the different nature of
training. RBF (Radial Basis Function) was used as the               participant interests.
kernel function. We performed a grid search to get the                There has also been work on non-traditional, qualitative
best parameter (C and gamma) in training and applied                assessment of instructional discourse (Boyer et al., 2008;
them to the test corpus. With the training data of 159              Graesser et al., 2005; McLaren et al., 2007), and results
threads and the test data of 52 threads, the initial                have been used to find features for critical thinking and
classification result is shown in Table 4.                          level of understanding. Similar approaches for classifying
    The initial results indicate that the EA classification is      speech acts were investigated in Ravi and Kim (2007).
feasible. Due to the relatively small set size of available         This work captures features that are relevant to analyzing
                                                               2348

noisy student discussion threads and supports a full                    Craggs R., and Wood M. (2004). A Categorical Annotation Scheme
automatic analysis of student discussions instead of                       for Emotion in the Linguistic Content of Dialogue. Affective
                                                                           Dialogue Systems, Elsevier, 89-100.
manual generation of thread analysis rules. Earlier work                D'Mello, S., Dowell, N., and Graesser (2009). A.: Cohesion
on annotating emotion in dialogue focused on polarity                      Relationships in Tutorial Dialogue as Predictors of Affective
(positive or negative) and intensity (Craggs and Wood,                     States. Proceedings of the AI in Education Conference.
2004) but is less useful for analyzing student discussions.             Feng, D., Kim, J., Shaw, E., and Hovy, E. (2006), Towards
   Finally, there have been studies of student affective                   Modeling Threaded Discussions through Ontology-based
states in tutorial dialogue, including boredom, confusion,                 Analysis, Proceedings of National Conference on Artificial
surprise and frustration. These were analyzed and                          Intelligence.
                                                                        Graesser, A. C., Olney, A., Ventura, M., Jackson, G. T., (2005).
captured using dialogue states with linguistic features                    “AutoTutor's Coverage of Expectations during Tutorial
such as cohesion measures (D’Mello et al., 2009). Our                      Dialogue.” Proceedings of the FLAIRS Conference.
work focuses on ‘threaded’ discussions, and is potentially              Graesser, A., VanLehn, K., Rosé, C., Jordan, P., Harter, D. (2001).
useful for analyzing student discussion outcome.                           Intelligent Tutoring Systems with Conversational Dialogue. AI
                                                                           Magazine, 22(4).
               Summary and Future Work                                  Hirschberg, J. and Litman, D. (1993). Empirical Studies on the Dis-
                                                                           ambiguation of Cue Phrases, Computational Linguistics, 19(3).
As the distinctions between resolved and unresolved                     Kim, J., Kim, T. and Li, J. (2009). Identifying Student Online
threads show that profiling and automatic identification                   Discussions with Unanswered Questions, Proceedings of the
by affect is fully possible, it is important to look forward               International Conference on Knowledge Capture.
toward methods and directions of higher-level                           Kim, J., Shaw, E. Chern, G. and Herbert, R. (2007) Novel tools for
interpretation. The procedure used in investigating closure                assessing student discussions: Modeling threads and participant
is only for broad proof-of-concept, rather than developing                 roles using speech act and course topic analysis, Proceedings of
                                                                           the AI in Education Conference.
specific profile criteria for automatic categorization. As              Kumrow, D. (2005). Student Self-Regulatory Resource Man-
such, future development in profiling will require specific                agement Strategies and Academic Achievement in a Web-based
categories, defined by interactions within posts between                   Hybrid Graduate Nursing Course. Education and Technology,
differing affect in a repeatable manner. This can reveal                   Editor(s): T.C. Montgomerie, J.R. Parker, ICET.
information about important qualities of posts, threads,                Lampert, A., Dale, R., and Paris, C. (2008). The Nature of Requests
and students.                                                              and Commitments in Email Messages”, AAAI workshop on
      We have described an important first step towards the                Enhanced Messaging.
identification and use of emotion acts for instructional                Mann, W.C. and Thompson, S.A., (1988). Rhetorical structure
                                                                           theory: towards a functional theory of text organization. Text: An
analysis of student discussions: We have identified                        Interdisciplinary Journal for the Study of Text, 8 (3)
common acts used by students within a course discussion                 McLaren, B. et al., Using Machine Learning Techniques to Analyze
board, developed a promising classification approach, and                  and Support Mediation of Student E-Discussions, Proceedings of
have shown that these acts are significant within the                      the AI in Education Conference.
corpus through an investigation of resolved/unresolved                  Newman, R. and Schwager, M. (1995). Students’ Help Seeking
threads. There are many research avenues to explore. In                    During Problem Solving: Effects of Grade, Goal, and Prior
combination with existing metrics based on rhetorical                      Achievement. American Educational Research Journal, v32 n2.
speech acts, contribution quantity and technical depth, the             Ordelman, R. and Heylen, D. (2005). Annotation of Emotions in
new measures will assist instructors and researchers in                    meetings in the AMI project.
                                                                        Ravi, S., Kim, J. (2007) Profiling Student Interactions in Threaded
understanding how students learn. This study
                                                                           Discussions with Speech Act Classifiers, Proceedings of the AI in
complements prior work on speech acts and discussion                       Education Conference.
topics (Carvalho & Cohen 2005; Feng et al., 2006; Kim et                Rubin, V., Liddy E., and Kando, N. (2006). Certainty Identification
al. 2007).                                                                 in Texts: Categorization Model and Manual Tagging Results. In
                                                                           Computing Attitude and Affect in Text: Theory and Applications.
                          References                                    Samuel, K., (2000) An Investigation of Dialogue Act Tagging using
Boyer, K., Phillips, R., Wallis M., Vouk M., Lester, J., Learner           Transformation-Based Learning, PhD Thesis.
   Characteristics and Feedback in Tutorial Dialogue (2008), ACL        Searle, J., (1969). Speech Acts. Cambridge: Cambridge Univ. Press.
   workshop on Innovative Use of NLP for Building Educational           Shawar, B. A. and Atwell, E. (2005). Using corpora in machine-
   Applications.                                                           learning chatbot systems. International Journal of Corpus
Brown, P. and Levinson, S.C. 1987. Politeness: Some universals in          Linguistics, V10.
   language usage. Cambridge: Cambridge University Press.               Stolcke, A., Coccaro, N. Bates, R., Taylor, P., Van Ess-Dykema, C.,
Carvalho, V.R. and Cohen, W.W., (2005). On the collective                  Ries, K., Shriberg, E., Jurafsky,D., Martin,R., Meteer,M., (2000).
   classification of email speech acts, Proceedings of the SIGIR           Dialogue act modeling for automatic tagging and recognition of
   Conference.                                                             conversational speech, Computational Linguistics, v.26 n.3.
Chang, C. and Lin, C. (2001). LIBSVM: a library for support vector
   machines.
                                                                   2349

