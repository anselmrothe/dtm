UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A critique of multi-voxel pattern analysis
Permalink
https://escholarship.org/uc/item/4914w4rs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Anderson, Michael
Oates, Tim
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                      A critique of multi-voxel pattern analysis
                                    Michael L. Anderson (michael.anderson@fandm.edu)
                                       Department of Psychology, Franklin & Marshall College
                                                        Lancaster, PA 17604 USA
                                                  Tim Oates (oates@cs.umbc.edu)
                            Department of Computer Science, University of Maryland, Baltimore County
                                                       Baltimore, MD 21250 USA
                              Abstract                                 “localizable task-specific representations of freely chosen
                                                                       intentions” (Haynes at al., 2007), and the regions of the
   Multi-voxel pattern analysis (MVPA) is a popular analytical
   technique in neuroscience that involves identifying patterns in
                                                                       brain that “contain information” (Preston et al., 2008)
   fMRI BOLD signal data that are predictive of task conditions.       relevant to the cognitive or perceptual task under
   But the technique is also frequently used to make inferences        investigation.
   about the regions of the brain that are most important to the          To put it bluntly, however, such inferences are at best
   tasks in question, and our analysis shows that this is a            misleading and at worst entirely unwarranted. The issues
   mistake. MVPA does not provide a reliable guide to what             dovetail with, but are distinct from, the more general
   information is being used by the brain during cognitive tasks,      concerns about the unreliability of “reverse inference” from
   nor where that information is. This is due in part to inherent      neuroimaging data (Poldrack, 2006), and have significant
   run to run variability in the decision space generated by the       implications both for how we ought to interpret some of the
   classifier, but there are also several other issues, discussed      many papers already published, and for how the field
   here, that make inference from the characteristics of the
   learned models to relevant brain activity deeply problematic.
                                                                       applies this technique in the future.
   These issues have significant implications both for many               Of course, not every MVPA study is governed by the
   papers already published, and for how the field uses this           logic that we will criticize here. For instance, Mitchell et al.
   technique in the future.                                            (2008) take something like the opposite approach, and see if
                                                                       they can predict the pattern of brain activity that will be
   Keywords: neuroscience, machine learning, inference,                caused by listening to novel words. Here the point of the
   philosophical issues.
                                                                       study is not to discover which brain regions are responsible
                                                                       for understanding; rather, they are testing the hypothesis that
                          Introduction                                 meanings of words are based on sets of “semantic features”
Multi-voxel pattern analysis (MVPA) is an increasingly                 that can be inferred from word co-occurrence in language
popular analytical technique in neuroscience. MVPA                     corpora. McDuff, Frankel & Norman (2009) are likewise
involves searching through the Blood Oxygenation Level                 focused on hypothesis testing, in their case about the
Dependent (BOLD) signal data produced in fMRI                          characteristics of targeted memory retrieval. We think that
experiments to identify patterns that are highly predictive of         MVPA has a very promising future both as a diagnostic
task conditions. To illustrate, consider a simple experiment           tool, and as a useful dependent variable—in part because the
in which participants are asked to view pictures representing          technique is sensitive to contingencies beyond classical
various object categories (e.g. faces, houses, chairs, shoes,          single-voxel effects—but that for the reasons outlined in this
etc.). One early MVPA study showed it was possible to                  paper it is a very poor tool for reliably localizing
determine, by looking only at BOLD data, which class of                information or identifying cognitive states.
object an experimental participant was viewing when that
data was collected (Haxby et al., 2001). The technique has                            Information and the brain
since been used to predict the orientation of lines being              There are three general ways in which information could
viewed by a participant (Haynes & Rees, 2005), to                      inhere in the BOLD signal. First, the information could be
differentiate between lying and truth-telling (Davatzikos et           non-local, that is, carried by irreducibly relational features
al., 2005), and to predict which action a participant was              of the signal like regional co-variance. We might expect this
about to take (Haynes et al., 2007), among many other                  to occur when large-scale neural synchrony is the relevant
things (see Pereira, Mitchell & Botvinick, 2009; Norman et             aspect of brain activity (Varela, et al., 2001; Gross et al.,
al., 2006; Haynes & Rees, 2006 for reviews of the technique            2004). Second, it could be local and distributed, that is, the
and its applications).                                                 information could be carried by the activity of individual
   This is indeed impressive, and we expect that MVPA will             voxels, and the information-carrying voxels could be spread
have many important experimental and diagnostic                        throughout the brain. We might expect this for cognitive
applications (Lao et al., 2004). It has become commonplace             processes that require the cooperation of many different
to make certain inferences about the way differences in                brain regions. Third, the information could be local and
BOLD signal patterns correspond to differences in mental               concentrated, that is, carried by individual voxels that are
states. For instance, by finding the set of voxels that are            grouped together in one or a few clumps. This might
most predictive of a certain task outcome, studies have                happen when the work done by local neural circuits is most
claimed to discover the “cognitive states associated with              important to the cognitive task(s) in question. In this essay,
perception of tools and dwellings” (Shinkareva et al., 2008),          we will consider the performance of MVPA in all three
                                                                   1511

ssituations, and discuss whatt can, and cannnot, be inferrred                        which there nevertheeless is also relevant local innformation,
 from
 f      features of o the learned modelm                 c
                                               in each case.                         distribuuted across manny voxels.
                                                                                             o analysis off the performannce of MVPA with local,
                                                                                        For our
 Local,
 L          distrib  buted inform     mation                                         distribuuted information, we gennerated 20 seets of 80
 C
 Consider the problem of differentiatinng between the                       t        “scans””—that is, 20 datasets, eachh containing 400 instances
 following
 f              two patterns
                      p          of hyppothetical voxeel-level activatiion           of eachh pattern typee. Patterns were    w      corruptedd with 5%
 data,
 d      each pressented with tw       wo versions of the same patteern               noise——a 5% chance for each voxell that it will bee in a state
 tyype (see Figurre 1). In this simple  s       example each of the 25               inconsiistent with the pattern. For each  e              w used 40
                                                                                                                                     dataset, we
 “
 “voxels”     can be b in one of tw    wo states (activve or inactive,, if                                    t
                                                                                     of the 80 scans for training        and 400 for test, andd classified
 you
 y      like). Supppose “brain scans” like these had beeen                           them using a Support Vectoor Machine. Because
 o
 observed      durinng an experimeent in which participants
                                                         p                weere      classifiication accuraccy roughly trackks the relative proportion
 asked
 a        to classiify pictures ass “living” or “non-living”.
                                                          “                   If     of patteern versions, ouur scans contaiined a 4:1 ratioo of pattern
 thhese judgmentts reliably corrresponded to the          t two patternns,           versionns within eacch type, and classificationn accuracy
 r
 respectively,      coould we use MVPA M         to read the mind of the    t        averageed 80%.
 p
 participants?                                                                          Thuss, our hypothetical experimennt would have produced p         a
                                                                                     solid predictive success; we wouldd be able to teell, 80% of
                                                                                     the tim
                                                                                           me, which task condition
                                                                                                               c           the participant
                                                                                                                               p            wass in just by
                                                                                     lookingg at the fMRI data. But whaat, if anything, would we
                                                                                     be permmitted to concluude about the locall     neural coonditions—
                                                                                     represeentations, infformation conntent, activitty, etc.—
         Pattern typee 1, version 1               Pattern type 1, version 2
                                                                                                             d
                                                                                     contributing to the differences           c
                                                                                                                            in cognitive  taskss (thinking
                                                                                     about or o judging the difference between b         livingg vs. non-
                                                                                     living things)?
                                                                                             t
                                                                                        Althoough any of thhe input compoonents could coontribute to
                                                                                     the preediction breakiing one way or      o the other inn an given
                                                                                     case (aand it needn’tt be the sam        me componentss for each
         Pattern typee 2, version 1               Pattern type 2, version 2          instance), in practice there can be a small numberr of voxels
             Figure 1: Simple patterrns for use in MV     VPA test                   that coontribute most to the classifi    fier performancce because
                                                                                     they (liiterally) carry the
                                                                                                              t most weighht—that is, theey have the
 N
 Now, when thee ratio of patterrn versions wiithin each patteern                     highestt values of wi. In linear MVPA,   M        this sett of highly
 tyype is 1:1, every voxel is in        n both of its possible
                                                         p           states in       weighteed voxels is coonsidered the “m    most informatiive”.
 e
 every   task conddition. That is:: no voxel is byy itself predictiive                  Figurre 2 shows a map of the voxels that were           w     most
 o any cognittive state, and thus in thhis condition all
 of                                                                                  informaative for distinnguishing between pattern typpes 1 and 2
 innformation is non-local. In          n this conditioon linear MVP        PA       in datasset 1.
 cannot
 c         distinguuish between th      hese two patterns; it is blindd to
 non-local
 n              inforrmation (Kamittani & Tong, 2005;    2        Normann et
 al.
 a 2006). For linear classifieers, since the evvidence providded
 b each voxell is integrated
 by                                    d separately, linear
                                                         l         MVPA is
 s
 successful      onlyy when there are individuall voxels that are           a
                                                                                        Figurre 2: Most inform
                                                                                                             mative voxels forr an MVPA classsification
 s
 sensitive     to thee difference between
                                       b          classes. In general, a
 (binary) linear classifier overr an input space of dimensionn n
                                                                                     What is  i the proper interpretation of these resuults in the
 loooks like this:
                                                                                     contextt of MVPA? These T        are the voxels
                                                                                                                              v       that, hadd they been
                                                                                     in a diffferent state, would have beenn most likely too cause the
                  preediction        siggn b          w      x
                                                                                     classifiier to place the pattern in the other class. Buut consider
                                                                                     the folllowing inferennce, an inferencce of similar structure
                                                                                                                                               s         to
 where the ith weight
 w                  w         is wi andd the ith compoonent of the inpput
                                                                                     those being
                                                                                             b       made inn the MVPA literature:
                                                                                                                               l           if thhe state of
 vector
 v         (the listt of numbers th      hat describe thhe patterns to be
                                                                                     these voxels
                                                                                            v        had been different in the right way—       —and note
 c
 classified)     is xi and the bias value
                                        v      is b. If the
                                                          t sum abovee is
                                                                                     this piccture providess no informatioon about whaat the right
 positive,
 p           the instance is classified one way;; if it is negativve,
                                                                                     way iss—the brain would have been in the relevantly
 thhe instance is classified
                      c            the other
                                       o      way.
                                                                                     differennt state (or thhe participant would
                                                                                                                               w       have been
                                                                                                                                              b      in the
    However, manipulating
                    m                  th
                                        he version raatio changes the       t
                                                                                     differennt cognitive sttate). This infference does not    n follow,
 situation
 s            from one in which no voxel is more         m       informatiive
                                                                                     becausee if covariancce is the cruccial cognitivelly relevant
 thhan any other—    —a situation in    n which linear classifiers faill—
                                                                                     propertty of the activitty here, then alla the other voxxels would
 too one in whicch there is ind         deed a set of voxels,
                                                          v          scatterred
                                                                                     also bee different wheen the brain/participant is inn the other
 thhrough the patterns,
                     p            that are informattive about claass
                                                                                     state: thhey will be covvarying with a different set of   o partners.
 membership.
 m                    That
                      T is to say, although theree is still non-loccal
                                                                                     And, evven if covariaance is not the crucial property—if the
 innformation in the patterns—       —and it is arguaable that the noon-
                                                                                     relevannt informationn is the locall information—         —it seems
 loocal co-variancce structure is the crucial, rellevant distinctiion
                                                                                     pretty clear
                                                                                              c     that it isnn’t all or onlyy the voxels in the “most
 b
 between      these patterns—the initial test sittuation is one in
                                                                                 1512

innformative” seet that would need    n      to be in a different statee to      and training K times on a rotating K-1   K of the parttitions. We
tuurn one patternn into the otherr.                                              performmed 10-fold crross validationn on our 20 traaining sets,
    Likewise, coonsider a similaar inference (vversions of whiich                and fouund similar variability in thee set of most innformative
c also easilyy be found in the literature):: the informatiion
can                                                                              voxels in each fold. The mean num       mber of inclusioons among
contained
c              in thhese voxels is the informatioon crucial to the       t       the top 10 most highlyy weighted voxxels was 4 (SD    D 2.83). 23
difference
d               betwween the cogniitive states under investigatiion              of the voxels were among the 100 most highlyy weighted
(jjudging living vs. non-living       g things). This inference is allso         voxels in at least one fold.
unwarranted,
u                  foor similar reaso   ons. For one strong
                                                        s       possibillity
is that the relevvant informatio        on is carried by
                                                       b the covariannce         Non-loocal informaation
s
structure    of thee patterns, and     d this non-locaal informationn is         So, thaat seems to be the situation whenw     informatiion is local
n contained in
not                 i the set of “m   most informativve” voxels. And  A          and disstributed. Whhat about whenn the only infoormation is
e
even   if the locaal information is     i what is relevvant here, we canc        non-loccal, that is, whhen the ratio off pattern versioons is 1:1?
s from the reesults above th
see                                    hat the set of most
                                                        m      informatiive      It turnss out it is poossible to classsify these pattterns with
voxels
v        does nott consist of all or only the vooxels carrying the       t       100% accuracy, appplying MVPA using a suppport-vector
relevant
r          inform  mation.                                                       machinne with a polyynomial kernell of degree two. Can we
    The uncertaiinty of inferen         nces about brrain or cognitiive          concludde anything in this case abouut the neural coonditions—
s
states   based onn which voxells are most higghly weightedd is                   represeentations, inforrmation, activiity, etc.—contrributing to
d
driven    home even e       more strrongly when one     o looks at the   t       the diffferences in coggnitive tasks?
s
stability   of the set of highly weighted voxeels over multipple                    One is of course tem  mpted to simplly dismiss the possibility.
                                                                                                                                         p
trrials of the saame task. Fig         gure 3 shows the most highhly             In our examples everry voxel is in both  b   of its posssible states
weighted
w            voxells from the first three datasetss.                             in everry task condittion. That iss: no voxel iss by itself
                                                                                 predictiive of any coggnitive state, and a thus no innference to
                                                                                 the speecial status of activity
                                                                                                          a        in anyy voxel could possibly
                                                                                                                                        p          be
                                                                                 supportted by the predictive suuccess of MV             VPA. Yet
                                                                                 researchers do extracct “most inforrmative” voxell sets even
                                                                                 when using
                                                                                          u       polynom mial kernels (e.g. Davatzikkos et al.,
          Figure 3: 3 Most informattive voxels for thhree different              2005), so it is wise to consider the matter
                                                                                                                          m      more carrefully.
                              classificcation runs                                  In linnear classifierss identifying most
                                                                                                                        m important voxels for
                                                                                 the classsifier is easy——the features in i the decisionn space that
O
Obviously, the highly weighted voxels varyy from run to ruun.                    have thhe highest weights are the most m     important,, and these
T get a better quantitative handle on thee stability of the
To                                                                       t       features have a 1:1 correspondencee with componnents of the
highly
h        weighted voxel set, we      w counted the number of tim       mes       input vector,
                                                                                         v         that is, with the vooxel values fed into the
e
each    voxel waas among the top 10 most highly          h       weighteed.      classifiier. But non‐llinear SVMs use “kernel functions”,
                                                                                                                                         f
O
Overall,   every voxel was in this     t set at leastt twice, and noone          wherebby a vector inpput is projecteed into a kernnel‐specific
more
m                    t
        than 12 times.         24 vox  xels were in thhe set betweenn 6          high‐diimensional spaace, and the im   mportance of eaach feature
and
a      12 times,, and 22 bettween 6 and 10 times. The                  T         is deterrmined in thatt space. The orriginal space for f a given
characteristics
c                      of the classification model    m          can vaary       vector x has one dimeension for eachh component of     o the input
considerably,
c                     driven in paart by noise in the trainiing                  vector, and the vallue of that feature—its
                                                                                                                          f            poosition on
innstances, but alsoa by the facct that the algorrithm needs onnly               dimenssion i—is just xi. In contrastt, a polynomial kernel of
find
f      some of the   t features th    hat discriminatte between som      me      degree 2 (K2) projectss the input vecctor into a spacce having a
innstances of the    t    patterns somes       of the time. It is not   n                                 u
                                                                                 dimenssion for each unique        (unordered) pair of features in
guaranteed
g               to find
                    f                 r
                          all of the relevant    differeentiating featurres,     the vecctor, and the value of eachh of those features—its
nor
n the best. The      T conclusion       n seems obvioous, but is worth           positionn on dimensionns (i,j)—is xi * xj.
s
stating   clearly: when any vox         xel can make it into the “moost             Thuss, the K2 classiffier over an inpput space of diimension n
innformative” seet, and many voxels    v        are morre or less equaally       looks more
                                                                                        m      like this:
liikely to end up    u there, this should make us a bit uneaasy
a
about    their acttual informativeness. If theere is somethiing                             prediction       sign b            ,
                                                                                                                        ,
stable
s         to the cognitive sttates differenttiating the taask
conditions,
c                thee set of most informative
                                       i              vooxels is certainnly      In factt, we can gett exactly thiss situation byy manually
                                                                                 projectiing our input vectors into the polynomiaal space—
n tracking it, nor can it therrefore be a reliiable indicator of
not
                                                                                 turningg them in this case from n‐ddimensional vectors into
thhe location of the cognitively       y relevant inforrmation.
                                                                                 n+((n2‐n)/2)
                                                                                         ‐       dimensioonal vectors— —and using linnear SVMs
    In should be noted that cro      oss-validation doesd     not alleviaate     to classsify them. Thhis procedure will produce the same
thhis issue. Crooss-validation consistsc         of a faamily of methoods        decision surface as using
                                                                                                         u      K2 in thee original spacce, but will
d
designed     to preevent over-fittiing of the moddel to what couuld              allow us to directlly inspect the resulting weights    w          to
be
b an unusuaally biased saample. Typicaally, it involvves                         determiine which featuures were mostt important.
b
building    multipple models based on multiplee partitions of the        t          Howwever, given thhe nature of noon‐linear SVM     Ms, relating
s
sample,    and avveraging resullts over the raange of differeent                 features to individuaal components of the input vectors is
partitions
p             (Pereeira et al., 2009    9). For instance, K-fold cross-          inherenntly problematiic. For note thhat what gets weighted
                                                                                                                                        w          in
v
validation     invoolves splitting the training data   d     into K parrts,      the deecision functioon is the prooduct of each pair of
                                                                             1513

components. So, if a given product turns out to be important           Given the high degree of variability in the features
to the classifier, shall we attribute this importance to just       considered most important, it seems certain that the set of
one of the components, or to both? Either decision seems            frequently informative components (voxels) is likewise
likely to give misleading results. Nevertheless, for the sake       unstable. To confirm this, we generated 500 training sets of
of the discussion, let’s adopt the simple rule that when a          the 10x10 patterns, and, following the procedure above,
given feature is highly weighted, both components (voxels)          found the top 500 most important features for each set.
will be counted as “informative”. Given this, we can                Then, we counted the number of times each individual
examine the frequency with which voxels are informative,            component of the input vector was included in a pair that
and track the voxels that are frequently informative.               was in this important feature set. On average, each
   To test this procedure when using K2, we generated 40,           component was included in the set 10.00 times (SD 0.39).
10x10 versions of the standard patterns from Figure 1, 20 of        No component averaged fewer than 9 inclusions, or more
each pattern type, with a 1:1 ratio of versions, and a noise        than 11.00. Once again, if there is some stable difference
level of 5%. We projected each of these patterns into the           between the cognitive states in the two task conditions, the
5,050‐dimensional feature space of K2, and trained a linear         set of most informative voxels is certainly not tracking it,
SVM on the set. Then we found the top 500 highest                   nor can it therefore be a reliable indicator of the location of
weighted features, and projected these back onto the 10x10          the cognitively relevant information.
pattern following the rule above. Now, it is perfectly                 Admittedly, this example was based on a very simple rule
legitimate to make the following inference from this                for mapping features in the multi-dimensional space to
procedure: the highly weighted voxels are the ones that, had        components of the original vector, and it is true that more
they been in a different state, would have been most likely         sophisticated procedures for uncovering the most
to cause the classifier to place the pattern in the other class.    informative components have been developed (Davatzikos
The trouble is, the weighting is often taken to tell us             et al., 2005; Lao et al., 2004). But insofar as these
something about the relative importance of each voxel to the        techniques still depend in one way or another on identifying
intrinsic difference between the patterns (and to the               the most highly weighted features in a multi-dimensional
underlying cognitive states), and no such inference is              space, and insofar as this set is not determinate for a given
warranted in this case.                                             classification task, then the results of such analyses need to
   First, there is a basic problem of interpretation given that     be interpreted with extreme caution.
the important features are in fact products of two voxels—             Before moving on with the remainder of the analysis, it is
so, every time a voxel is deemed informative, it has a              worth pausing to summarize the findings. In the case where
partner with which it was important, and the set itself gives       there is local information relevant to distinguishing patterns,
no information about the distribution of these partners.            linear MVPA does not reliably find it; and in the case where
Second, it is clear in this case (because there is no local         there is relevant non-local information, carried for instance
information) that the relevant information differentiating          by covariance patterns, linear MVPA cannot find it, and
between the patterns is non-local, carried in the covariance        non-linear MVPA models can make it look as if they were
structure of the pattern, and this information is not contained     using local information. More importantly, having
in the set of frequently informative voxels. Third, the most        discovered some features whose state matters most to the
highly-weighted features are not those that contain the most        classification decision is not the same as having discovered
information. As in the linear case, they are the features that      the brain regions whose activity matters most (or even
contained sufficient information to drive the classifier on a       relatively more) to the participant (or her brain). Indeed,
given set of training examples. Fourth and finally, as should       these two sorts of information need have no regular
not be surprising, the set of informative features and              correspondence to one another; one need not track, be a
informative voxels is highly unstable in this case, as well.        reliable indicator of, or be otherwise instructive about the
   To explore the stability of the set of important features        nature, scope or location of the other.
when using K2, we generated 10x10 versions of the standard
patterns above, creating 100 sets of 40 (20 of each pattern)        Local, concentrated information
with a noise level of 5%. We projected each of these                How is this disconnect possible? Consider first an example
patterns into the 5,050‐dimensional feature space of K2, and        from the MVPA literature meant to showcase the power of
trained a linear SVM on each of the 100 sets. From each of          the technique. Haynes and Rees (2005) were able to use
these 100 sets, we extracted the top 500 most important             MVPA to correctly identify the orientation of visually-
features. Doing a pair‐wise comparison of the most                  presented lines, even when the stimuli were presented
important features from each set revealed that, on average,         briefly and masked so that the participant did not
only 101.08 (SD 16.94) of these features (20.21%) were              consciously perceive them. That is an intriguing result, and
common between each pair. Moreover, the common features             may tell us something interesting about the operation of V1
varied from pair to pair. Doing a 5‐wise comparison of the          (the ROI they used to make the predictions). But note the
most important features sets reveals an average of just 0.81        broader implication for the method: since the participants
(SD 1.09) of the features (0.16%) are shared across all five        cannot judge the orientation of the lines, they cannot be in
sets. Note that despite the instability of the “most                whatever cognitive state gives the ability to judge the
informative” feature sets, classification accuracy in all cases     orientation of the lines. Thus, MVPA can be used to infer
was 100%.                                                           features of the task environment from characteristics of the
                                                                1514

BOLD signal, without being a reliable indicator of the               polynomial kernel of degree two. In the latter space, the
cognitive state of the participant.                                  feature corresponding to f19 * f20 had an average weight of
   Now consider extending the experiment in the following            3.64. The remaining 209 features had average weights in the
straightforward way: while the visual stimulus is being              range (0.05, 0.10). In the former case, the average weights
shown (and masked), experimenters play an auditory tone              for features f1 through f5 were 1.92, 1.94, 1.94, 1.93, and
from which the participant could reliably infer the                  1.94. The remaining 15 features had average weights in the
orientation of the line. If, as seems likely in this particular      range (0.03, 0.10). Clearly, the choice of kernel can have a
case, the most informative voxels for the pattern classifier         dramatic impact on which features are deemed important
would remain in V1, this outcome would provide a clear               and, in the case of MVPA, which voxels are implicated in
instance in which the information used by the participant            various cognitive tasks.
and the information used by the classifier would not have               Thus, although much of this paper was spent detailing the
the expected relation.                                               worrying instability and potential deceptiveness of the most
   But is such an outcome really possible? In fact, this             informative voxel set when information is non-local or
hypothetical example points in the direction of a well-              distributed, the fact is that even if MVPA were perfectly
known fact about the way classification algorithms perform.          reliable at the task of finding the most informative features
Numerous theoretical results and a tremendous amount of              in a data set, the inference from this to the brain activity
empirical evidence in machine learning demonstrate that              most important determining the outcome in given task
there is no universally best learning algorithm (Wolpert,            would remain fairly weak. This is because inference from
1996). Every algorithm has a bias that is appropriate for            most informative features to most important activity
some problems and inappropriate for others. This is true for         apparently relies on the unwarranted additional assumption
the brain, and the same is true of kernels. There is no              that the pattern classification algorithm and the brain are
universally best kernel, and changing from one kernel to             classifying on a relevantly similar basis. While of course no
another can lead to large changes in the learned decision            one claims that the success of MVPA shows that the brain is
surface and thus to changes in what features in the data set         implementing an identical classifier, the issue is that the
seem to be important.                                                hypothesis space is different for different classifiers, and so
   The relevance of this problem for MVPA is that a                  different information will be relevant to each. What is
particular set of stimuli may elicit different patterns of           relevant in the brain, and what is relevant to classifying an
activity, call them pattern A and pattern B, in different parts      image of the brain, need not bear much relation.
of the brain, and one kernel may be able to detect pattern A
but not pattern B, whereas another kernel may be able to                                      Conclusion
detect pattern B but not pattern A. Thus, when relating              There are very many challenges to the task of reliably
“most informative features” to “most important activity”,            relating the features (of the BOLD signal) most important to
the area of the brain implicated in the experiment will              classification success to the features (of brain activity) most
change depending on which kernel is used.                            important to cognitive states/outcomes.           By way of
   To make this concrete, consider two patterns with 20              summation, consider this general list of possible ways in
binary features (f1 - f20) in which for every instance of the        which these features might fail to relate as expected.
first (positive) pattern the following two conditions hold:             (1) The highly informative elements of the pattern as
                                                                     discerned by MVPA are distributed in the brain in such a
(a) Either f19 = 1 and f20 = −1, or f19 = −1 and f20 = 1             way that the brain is anatomically or functionally incapable
(b) The sum of the first 5 bits is less than or equal to zero        of integrating the information. If people are nevertheless
                                                                     capable of making the relevant discrimination, it must have
For every instance of the second (negative) pattern, the             been on the basis of different information.
following two conditions hold:                                          (2) There may well be classes of stimuli that differ in
                                                                     ways undetectable to subjects (under any presentation
(a) Either f19 = 1 and f20 = 1, or f19 = −1 and f20 = −1             condition, conscious or otherwise), but which nevertheless
(b) The sum of the first 5 bits is greater than zero                 create patterns in the BOLD signal allowing for successful
                                                                     classification by MVPA. Consider in this regard an
The values of the other bits are chosen uniformly at random          experiment run by Hung et al. (2005). Macaques passively
from {−1, 1}. Condition (a) is the logical exclusive or              viewed picture stimuli in eight different categories while
(XOR) function on bits 19 and 20 and is easily learned by            undergoing direct recording of neural activity using
the polynomial kernel of degree two (the class label is              microelectrode arrays. Hung et al. were able to successfully
−sign(f19 * f20)) but is impossible to learn with a linear           classify the stimuli with a linear SVM taking the multi-unit
kernel. Condition (b) is easily learned with a linear kernel         activity as input. But here the macaques did not—indeed, in
(the class label is 1 if f1+f2+f3+f4+f5 ≤ 0 and is -1 otherwise),    all likelihood could not—classify the stimuli, because they
but is extremely difficult for the polynomial kernel of              had not been trained to do so. In this case, the SVM might
degree two because it has access to individual feature fi only       have been making distinctions that the (untrained) macaques
as fi * fi which is 1 regardless of the value of fi.                 were not.
   We created 100 datasets based on the above rules and                 (3) Stimuli may differ along more than one dimension,
trained an SVM with a linear kernel on both the original             both of which lead to differences in the BOLD signal.
feature space and the feature space constructed for the              MVPA classification could rely on patterns relating to one
                                                                 1515

dimension, while participants use information relating to the        Neuroscience, 7:523-34.
other. That is, even when there is information in the BOLD         Haynes, J.-D. & Rees, G. (2005). Predicting the orientation
signal that is theoretically accessible by (or that is tracking      of invisible stimuli from activity in human primary visual
information accessible by) the participant, this may not be          cortex. Nature Neuroscience, 8(5): 686-91.
the information that is being used by the participant.             Haynes, J.-D., Sakai, K., Rees, G., Gilbert, S., Frith, C. &
   (4) The MVPA classifier may be using a kernel that is             Passingham, R.E. (2007). Reading hidden intentions in
significantly different from what is implemented in the              the human brain. Current Biology, 17: 232-28.
brain. As we saw, classifiers with different kernels trained       Hung, C.P., Kreiman, G., Poggio, T. & DiCarlo, J.J. (2005).
on the very same data will extract different features, and           Fast readout of object identity from macaque inferior
thus come to different decisions about which features (and           temporal cortex. Science, 310: 863-6.
which elements of the input vectors) are most important.           Kamitani, Y. & Tong, F. (2005). Decoding the visual and
   (5) Since there will always be a set of highly informative        subjective contents of the human brain. Nature
voxels produced by the MVPA classifier, the existence of             Neuroscience, 8(5): 679-85.
such a set won’t tell us whether the relevant information in       Kay, K.N., Naselaris, T., Prenger, R.J. & Gallant, J.L.
the brain is local and concentrated, local and distributed,          (2008). Identifying natural images from human brain
non-local, or some combination of these.                             activity. Nature, 452: 352-6.
   The discussion also raises a much more general issue. As        Lao, Z., Shen, D., Xue, Z., Karacali, B., Resnick, S. &
we noted at the outset, MVPA offers an exciting new way to           Davatzikos, C. (2004). Morphological classification of
investigate the operation of the brain, by looking at the            brains via high-dimensional shape transformation and
predictive value of (typically widely) distributed patterns of       machine learning methods. NeuroImage, 21 (1): 46-57.
activity. The problematic inferences generally come in the         McDuff, S.G.R., Frankel, H.C. & Norman, K.A. (2009).
attempt to reduce such patterns to local features of brain           Multivoxel pattern analysis reveals increased memory
activity. But if the best predictor of cognitive states is not       targeting and reduced use of retrieved details during
the location of an activated region, but rather the patterns of      single-agenda source monitoring.              Journal of
cooperation and coactivation between them—as the success             Neuroscience, 29(2):508-516.
of MVPA might be said to indicate, and as has been argued          Mitchell, T.M., Shinkareva, S.V., Carlson, A., Chang, K.-
for independent reasons (Anderson, 2008; Sporns, et al.,             M., Malave, V.L., Mason, R.A. & Just, M.A. (2008).
2004; Uttal, 2001)—then perhaps it is time to pay more               Predicting human brain activity associated with the
heed to the patterns than to the partners. We are just               meanings of nouns. Science, 320: 1191-5.
beginning to develop the tools to make such an investigation       Norman, K.A., Polyn, S.M., Detre, G.J. & Haxby, J.V.
fruitful and rigorous—including not only MVPA but other              (2006). Beyond mind-reading: Milti-voxel pattern
forms of statistical pattern analysis, machine learning, graph       analysis of fMRI data. TRENDS in Cognitive Sciences,
theory, etc.—and it seems a shame instead to use these tools         10(9): 424-30.
in the service of localization projects for which they are         Pereira, F., Mitchell, T., Botvinick, M. M. (2009). Machine
ultimately ill-suited. New tools often come with the                 learning classifiers and fMRI: a tutorial overview.
opportunity to re-consider the strengths of theoretical              NeuroImage, 45: S199-S209.
perspectives and paradigms, and these are offering a chance        Poldrack, R.A. (2006). Can cognitive processes be inferred
to look beyond localization, to what other perspectives on           from neuroimaging data? Trends in Cognitive Sciences,
brain organization might have to offer.                              2006; 10(2): 59-63.
                                                                   Preston, T.J., Li, S., Kourti, Z. & Welchman, A.E. (2008).
                           References                                Multivoxel pattern selectivity for perceptually relevant
Anderson, M. (2008). Circuit sharing and the                         binocular disparities in the human brain. The Journal of
   implementation of intelligent systems. Connection                 Neuroscience, 28(44): 11315-27.
   Science, 20(4): 239-51.                                         Shinkareva, S.V., Mason, R.A., Malave, V.L., Wang, W.,
Davatzikos, C., Ruparel, K., Fan, Y., Shen, D., Acharyya,            Mitchell, T.M. & Just, M.A. (2008). Using fMRI brain
   M., Loughead, J., Gur, R. & Langleben, D.D. (2005).               activation to identify cognitive states associated with
   Classifying spatial patterns of brain activity with machine       perception of tools and dwellings. PLOS One, 3(1):
   learning methods: Application to lie detection.                   e1394. doi:10.137/journal.pone.0001394
   NeuroImage, 28(3): 663-68.                                      Sporns, O., Chialvo, D., Kaiser, M. & Hilgetag, C.C.
Gross, J., Schmitz, F., Schnitzler, I., Kessler, K., Shapiro,        (2004). Organization, development and function of
   K., Hommel, B & , Schnitzler, A. (2004). Modulation of            complex brain networks. Trends in Cognitive Sciences, 8:
   long-range neural synchrony reflects temporal limitations         418-425.
   of visual attention in humans. Proceedings of the National      Uttal, W. (2001). The New Phrenology. Cambridge: MIT
   Academy of Sciences-USA, 101(35): 13050-13055                     Press.
Haxby, J.V., Gobbini, M. I., Furey, M.L., Ishai, A.,               Varela, F., Lachaux J.P., Rodriguez E. & Martinerie J.
   Schouten, J.L. & Pietrini, P. (2001). Distributed and             (2001). The brainweb: phase synchronization and large-
   overlapping representations of faces and objects in ventral       scale integration. Nature Rev. Neuroscience, 2(4): 229-39.
   temporal cortex. Science, 293: 2425-30.                         Wolpert, D. (1996). The lack of a priori distinctions
Haynes, J-D. & Rees, G. (2006). Deconding mental states              between learning algorithms. Neural Computation, 8(7):
   from brain activity in humans. Nature Reviews                     1341-1390.
                                                               1516

