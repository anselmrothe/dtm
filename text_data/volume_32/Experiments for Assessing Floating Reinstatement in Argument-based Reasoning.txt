UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Experiments for Assessing Floating Reinstatement in Argument-based Reasoning
Permalink
https://escholarship.org/uc/item/7xh5r3fr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Rahwan, Iyad
Bonnefon, Jean-Francois
Iqbal Madakkatel, Mohammed
et al.
Publication Date
2010-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

 Experiments for Assessing Floating Reinstatement in Argument-based Reasoning
                                                                 Iyad Rahwan
                              1 Masdar  Institute of Science & Technology, 2 MIT, 3 University of Edinburgh
                                                         Jean-François Bonnefon
                                                     CNRS and Université de Toulouse
                                       Mohammed Iqbal Madakkatel, Ruqiyabi Naz Awan
                                                          British University in Dubai
                                                               Sherief Abdallah
                                          1 British University in Dubai, 2 University of Edinburgh
                               Abstract                                          Textual argument:
   Various Artificial Intelligence semantics have been developed                   A: Tweety flies because it is a bird.
   to predict when an argument can be accepted, depending on                       B: Tweety does not fly, because it is a penguin.
   the abstract structure of its defeaters and defenders. These                    C: The observation that Tweety is a penguin is not reliable.
   semantics can make conflicting predictions, as in the situa-
   tion known as floating reinstatement. We argue that the de-                    Graphical structure:
   bate about which semantics makes the correct prediction can
   be informed by the collection of experimental data about the
   way human reasoners handle these critical cases. The data we                         A             B                C
   report show that floating reinstatement yields comparable ef-
   fects to that of simple reinstatement, thus supporting preferred
   semantics over grounded semantics. Besides their theoreti-                       Figure 1: Defeat structure with reinstatement
   cal value for validating and inspiring argumentation semantics,
   these results have applied value for developing artificial agents
   meant to argue with people.
                                                                          to), and accept A (since every objection to it has been de-
   Keywords: Argumentation; Semantics; Nonmonotonic rea-                  feated). When there are cycles, different semantics may pre-
   soning; Behavioural Experiment;
                                                                          scribe different results.
                                                                             These semantics typically come from a normative perspec-
                           Introduction                                   tive, which relies on intuition and ad hoc hypothetical exam-
Argumentation has become a very fertile area of research                  ples as to what constitutes correct reasoning. We will argue
in Artificial Intelligence (Rahwan & Simari, 2009), where                 that there are limits to relying solely on this approach, and
a highly influential framework for studying argumentation-                we will advocate the use of psychological experiments as a
based reasoning was introduced by Dung (1995). An argu-                   methodological tool for informing and validating intuitions
mentation framework is simply a pair AF = hA , *i where                   about argumentation-based reasoning.
A is a set of arguments and *⊆ A × A is a defeat relation                    In this paper, we apply this experimental method to the
between arguments. This approach abstracts away from the                  problem of floating reinstatement. We will show that psycho-
origin of individual arguments and their internal structures,             logical experiments can help to evaluate these various seman-
and focuses instead on the defeat relationship between them.              tics, and can provide unique insights even when all formal
   Figure 1 shows an example textual argument and its cor-                semantics are in agreement. Not only can these insights in-
responding graph structure. This structure is the canonical               form current and future semantics, but they are relevant to the
example for the notion of reinstatement. In particular, while             design of software agents that can argue persuasively with
argument A is defeated by argument B, the presence of C re-               humans, or provide reliable support to human evaluation of
instates A since C undermines A’s only defeater.1                         arguments (e.g., on top of argument diagramming tools).
   Given an argument framework (or graph), a semantics as-
signs a status to each argument. Classically, we distinguish                     Abstract Argumentation Frameworks
between arguments that are accepted and those that are not                This section contains technical background only, whose out-
(Dung, 1995). In some cases, all semantics agree on the re-               line is the following. Figure 1 displays the canonical graph of
sult. For example, in Figure 1, all classical argumentation               simple reinstatement, whereas Figure 2 displays the canonical
semantics agree that we should accept C (for lack of any                  graph of floating reinstatement. The main question is, in both
counter-argument), reject B (because there is a good reason               cases, whether A can be accepted. For simple reinstatement,
    1 While many notions of defeat exist, here we adopt the simple        A is accepted by preferred as well as grounded semantics (to
notion of undercutting: the defeater’s conclusion explicitly negates      be defined below). For floating reinstatement, A is not ac-
the defeated argument’s premise.                                          cepted by grounded semantics, but is accepted by preferred
                                                                      453

                                                                                       A               B                C
                  C
                                                                       Figure 3: Single (complete, grounded, and preferred) exten-
                                     B             A                   sion in simple reinstatement. Accepted arguments are shaded.
                                                                             C                               C
                  D
                                                                                         B          A                     B         A
                                                                             D                               D
Figure 2: The canonical graph of defeat and floating reinstate-
ment. Argument A is defeated by B, which is itself defeated            Figure 4: The two (complete, preferred) extensions in floating
by C as well as D, although C and D are mutual defeaters.              reinstatement. Accepted arguments are shaded.
semantics. Additionally, preferred semantics also accept C                We now define the characteristic function of an argumen-
and D in the (formally defined) ‘credulous’ sense, but not in          tation framework.
the ‘sceptical’ sense.                                                 Definition 4 (Characteristic function). Let AF = hA , *i be
   We now lay bare the technical background required to ar-            an argumentation framework. The characteristic function of
rive at these conclusions. We begin with Dung’s (1995) ab-             AF is FAF : 2A → 2A such that, given S ⊆ A , we have FAF (S)
stract definition of an argumentation framework.                       = {α ∈ A | S defends α}.
Definition 1 (Argumentation framework). An argumentation                  Applied to an argument set S, the characteristic function re-
framework is a pair AF = hA , *i where A is a set of argu-             turns the set of all arguments defended by S. Because we are
ments and *⊆ A × A is a defeat relation. An argument α                 only dealing in this article with one argumentation framework
defeats an argument β iff (α, β) ∈*, also written α * β.               at a time, we will use the notation F instead of FAF .
   The directed graphs displayed in Figures 1 and 2 will be               We now turn to various so-called extensions that can char-
our running examples all through the article. The critical is-         acterise the collective acceptability of a set of arguments. Es-
sue with these examples is whether argument A can be ac-               sentially, these extensions provide different possible ways to
cepted in spite of being defeated by argument B.                       group self-defending arguments together. These extensions
   For a given set S of arguments, S+ is the set of arguments          will be used subsequently to define the argument evaluation
that are defeated by the arguments in S. Formally, S+ = {β ∈           criteria that we study empirically in this paper.
A | α * β for α ∈ S}. Conversely, for a given argument α,              Definition 5 (Complete/grounded/preferred extensions). Let
the set α− is the set of all arguments that defeat α. Formally,        S be a conflict-free set of arguments in framework hA , *i.
α− = {β ∈ A | β * α}.
                                                                       • S is a complete extension iff S = F (S).
Definition 2 (Conflict-freedom). Let hA , *i be an argu-
mentation framework and let S ⊆ A . S is conflict-free iff             • S is a grounded extension iff it is the minimal complete ex-
S ∩ S+ = 0./                                                              tension with respect to set inclusion.
   In other terms, a set of arguments is conflict free if and only     • S is a preferred extension iff it is a maximal complete ex-
if no argument in that set defeats another.                               tension with respect to set inclusion.
Definition 3 (Defence). Let hA , *i be an argumentation                   S is a complete extension if and only if all arguments de-
framework, let S ⊆ A , and let α ∈ A . S defends α if and              fended by S are also in S (that is, if S is a fixed point of the
only if α− ⊆ S+ . We also say that argument α is acceptable            operator F ). There may be more than one complete exten-
with respect to S.                                                     sion, each corresponding to a particular consistent and self-
   In other terms, a set of arguments defends a given argument         defending viewpoint.
if and only if it defeats all its defeaters.                           Example 2. In the graph displayed in Figure 1, the set {C}
Example 1. In the graph displayed in Figure 1, the set {A,C}           is not a complete extension, because it defends A without in-
is conflict free, but the set {A, B} is not, and neither is the        cluding it. The set {B} is not a complete extension because
set {B,C}. Because the set {C} defeats all the defeaters of            it includes B without defending it against C –see Figure 3.
A, we can say that the set {C} defends argument A. In the              The only complete extension is {A,C}. The graph displayed
graph displayed in Figure 2, the only conflict-free sets (apart        in Figure 2 has two complete extensions, {A,C} and {A, D}
from trivial ones containing single arguments) are {A,C} and           –see Figure 4.
{A, D}. Either one of the sets {C}, {D}, or {C, D}, defends               A grounded extension contains all the arguments in the
A against all its defeaters.                                           graph that are not defeated, as well as all the arguments
                                                                   454

which are defended directly or indirectly by non-defeated ar-                        What Validates a Semantics?
guments. This can be seen as a non-committal view (charac-             As established above, different semantics can have different
terised by the least fixed point of F ). As such, there always         takes on which arguments can be accepted within a given ar-
exists a unique grounded extension.                                    gumentation framework. The question then arises of evaluat-
Example 3. The graph in Figure 1 has only one complete                 ing the different claims made by different semantics.
extension, {A,C}, which is also its grounded extension. The               Most semantics for argumentation-based reasoning in Arti-
graph in Figure 2 has two complete extensions {A,C} and                ficial Intelligence are based on intuition as to what constitutes
{A, D}, but none of this is the grounded extension, because            correct reasoning. This intuition is informed by specific (hy-
there is no node in the graph that is initially undefeated. In         pothetical or real) argumentation scenarios in which a par-
that case, the grounded extension is the empty set.                    ticular semantics draws the desired intuitive answer. This
   A preferred extension is a bolder, more committed position          example-based approach (to borrow a term from Baroni &
that cannot be extended (by accepting more arguments) with-            Giacomin, 2007) is problematic, since one can often construct
out causing inconsistency. Thus a preferred extension can be           other examples with the same logical structure, in which
thought of as a maximal consistent set of hypotheses. There            the proposed semantics draws counter-intuitive conclusions.
may be multiple preferred extensions, and the grounded ex-             For example, Horty (2002) famously devoted a whole paper
tension is included in all of them.                                    to demonstrate counter-intuitive results with floating conclu-
                                                                       sions in default reasoning. Baroni and Giacomin (2007) made
Example 4. The graph in Figure 1 has only one complete
                                                                       a compelling case for the limitations of the example-based ap-
extension, {A,C}, which is also a preferred extension. The
                                                                       proach, noting that even in relatively simple examples, there
graph displayed in Figure 2 has two complete extensions
                                                                       might not be a consensual intuition on what should be the
{A,C} and {A, D}, and both qualify as preferred extensions.
                                                                       correct conclusion. In parallel, Prakken (2002) observed that
   Now we can define the status of an individual argument              intuitions about given examples were helpful for generating
within the graph, that is, we can define criteria for accepting        new investigations, but less helpful as critical tests between
or not each individual argument. The main question in this             different semantics.
paper is whether people evaluate a reinstated argument scep-              To overcome the limitations of the example-based ap-
tically or credulously in accordance with the definition below.        proach, a number of authors recently advocated a more
Definition 6 (Argument status). Let hA , *i be an argumen-             systematic, axiomatic, principle-based approach. In this
tation framework, and E1 , . . . , En its extensions under a given     approach, alternative semantics are evaluated by analysing
semantics. Let α ∈ A and i = 1, . . . , n.                             whether they satisfy certain principles, or quality postulates.
                                                                       Such postulates include the reinstatement criterion, accord-
• α is accepted in the sceptical sense iff α ∈ Ei , ∀Ei .              ing to which an argument must be included in any extension
                                                                       that reinstates it, and directionality criterion which requires
• α is accepted in the credulous sense iff ∃Ei where α ∈ Ei .
                                                                       that an argument’s status should only be affected by the sta-
• α is rejected iff @Ei such that α ∈ Ei .                             tus of its defeaters (Baroni & Giacomin, 2007).
                                                                          The principle-based approach provides a significant im-
   Under the grounded semantics, any argument that belongs             provement over the basic example-based approach, since it
to the unique grounded extension is accepted both in the cred-         enables claims that transcend individual examples and char-
ulous and the sceptical sense, and any argument that does not          acterise semantics more generally. The source of the gen-
belong to the unique grounded extension is rejected. Under             eral postulates, however, is still the researcher’s intuition as
the preferred semantics, an argument is sceptically accepted           to what correct reasoning ought to be. In sum, most of the ex-
if it belongs to all preferred extensions; but it can also be          tent validation of various argumentation semantics, example-
credulously accepted if it belongs to at least one preferred ex-       based or principle-based, relies on normative claims based on
tension. If an argument is neither sceptically nor credulously         intuition. We now suggest that this normative-intuitive per-
accepted, it is rejected.                                              spective could be adequately complemented with descriptive,
Example 5. The graph displayed in Figure 1 has only one                experimental evidence about how people actually reason from
complete extension, {A,C}, which is grounded as well as pre-           conflicting arguments.
ferred. As a consequence, arguments A and C are accepted
by grounded as well as preferred semantics, both in the cred-                     The Experiment-based Approach
ulous and sceptical sense. The graph displayed in Figure 2             There is a growing concern within the Artificial Intelligence
has an empty grounded extension, which means that no argu-             community that logicians and computer scientists ought to
ment should be accepted under a grounded semantics. Under              give serious attention to cognitive plausibility when assess-
a preferred semantics, though, two extensions are identified,          ing formal models of reasoning, argumentation and decision-
{A,C} and {A, D}. From these extensions, only A can be                 making. For example, Benthem (2008) strongly supports the
accepted in a sceptical sense, but A, C, and D can all be ac-          rise of a new psychologism in logic at large, arguing that al-
cepted in a credulous sense.                                           though logicians and computer scientists have tended to go by
                                                                   455

intuition and anecdotal evidence, formal theories can be mod-              simple reinstatement? (A ‘yes’ to both questions would go
ified under pressure from evidence obtained though careful                 against the predictions of grounded semantics.) If so, does
experimental design.                                                       the effectiveness of floating reinstatement require that partic-
   Pelletier and Elio (2005) also argued extensively for the               ipants manifest a preference for either C over D or D over C?
importance of experimental data when formalizing default                   (A ‘yes’ would provide support to the predictions of credu-
and inheritance reasoning, arguing that default reasoning is               lous preferred semantics, a ‘no’ would provide support to the
particularly psychologistic in that it is defined by what peo-             predictions of sceptical preferred semantics.)
ple do. Their own results have been complemented by a dy-
namic experimental literature consisting of controlled tests                                           Method
of human default reasoning (e.g., Bonnefon, Da Silva Neves,                Fourty-seven participants were randomly approached in of-
Dubois, & Prade, 2008; Ford & Billington, 2000; Pfeifer &                  fices, shopping malls, and open spaces in Dubai. Partici-
Kleiter, 2009).                                                            pants read an introduction to the task, informing them that the
   Finally, and in close relation to the problems of simple and            purpose of the experiment was to collect information about
floating reinstatement that we have introduced in the previous             how people thought, that the task included no trick question,
section, Horty (2002) implicitly appealed to descriptive vali-             and that they simply had to mark the answer that they felt
dation when highlighting the issues that floating conclusions              correct. They were randomly assigned to two experimental
raise for sceptical semantics:                                             groups corresponding to simple and floating reinstatement,
   There is a vivid practical difference between the two skepti-           respectively, then solved 12 problems, following a 3-level, 4-
   cal alternatives. [. . . ] Which alternative is correct? I have not     measure within-participant design.
   done a formal survey, but most of the people to whom I have                The 3-level independent variable was the Pattern of the
   presented this example are suspicious of the floating conclu-
   sion (p.64).                                                            problem (Base, Defeated, Reinstated). In the Base pattern,
                                                                           participants were only presented with argument A; in the De-
We believe that the field of computational argumentation can               feated pattern, participants were presented with arguments A
indeed benefit from the same kind of formal surveys that have              and B; finally, in the Reinstated pattern, participants were pre-
been conducted in the field of default reasoning, and that                 sented with the three arguments A, B, and C (in the simple
have been generally called for in Artificial Intelligence. To              reinstatement group) or with the four arguments A, B, C, and
our knowledge, only very few articles have explicitly sought               D (in the floating reinstatement group).
to inform formal models of argumentation with experimental                    The linguistic contents of arguments A, B, C, and D were
evidence, and these experimental data have only been col-                  taken from four different argument sets (see Appendix). All
lected in relation to the specific issue of argumentation-based            participants saw each argument set in its Base, Defeated, and
decision making (e.g., Dubois, Fargier, & Bonnefon, 2008).                 Reinstated versions. The order of argument sets within the
What we offer in this article is an experimental investigation             questionnaire was counterbalanced across participants (two
of the basic issue of how people reason from the complex ar-               different orders), but the order of Pattern within each argu-
gument structure corresponding to floating reinstatement, and              ment set was fixed across the experiment. Participants had to
whether one of the current available semantics can capture                 answer every problem, in the order they appeared in the ques-
their reasoning.                                                           tionnaire, without looking at the next problem in the ques-
   Recently, we conducted experiments on the simple rein-                  tionnaire. For each problem, participants had to assess the
statement structure, across a varied set of linguistic contents            conclusion of argument A, using a 7-point scale anchored at
(Madakkatel, Rahwan, Bonnefon, Awan, & Abdallah, 2009).                    certainly false and certainly true.
Our study revealed that participants reasoned in a way that re-               In addition, participants rated their understanding of each
flected the formal notions of defeat and reinstatement: Their              problem (‘How clearly did you understand the problem?’) on
confidence in an argument A decreased when it was attacked                 a 7-point scale anchored at Not at all and Completely. Lastly,
by an argument B, but bounced back up when B itself was at-                participants in the floating reinstatement group answered the
tacked by a third argument C. These findings are in agreement              following question about the four reinstated problems: Do
with grounded as well as preferred semantics (and others).                 you think that (i) C is a better argument than D, (ii) D is a
What neither semantics could predict, though, is the finding               better argument than C, or (iii) C and D are about equally
that the recovery of argument A was not complete when rein-                good?
stated by argument C: Confidence in A in presence of B and
C did not raise back to its former level, when A was presented                                         Results
alone.                                                                     Figure 5 displays the average confidence in the conclusion
   Our present study offers an experimental comparison of                  of A, as a function of Pattern and Type of reinstatement, av-
the simple reinstatement structure to the more complex struc-              eraged across the contents and participants. The visual in-
ture known as floating reinstatement, shown in Figure 2.The                spection of Figure 5 already suggests that the results are very
present study seeks to answer the following questions: Does                similar for the two groups. This preliminary intuition was
floating reinstatement restore the confidence in the conclu-               confirmed by the results of a mixed-design analysis of vari-
sion of argument A, and does it do so to the same extent as                ance, using the confidence in the conclusion as a dependent
                                                                       456

                                                                                                                    ever, a regression analysis seeking to predict acceptance of
                                                 Standard                             Floating                      reinstated arguments on the basis of problem understanding,
 Confidence in the conclusion (1−7)
                                                                                                                    Type of reinstatement (dummy coded, 1 for floating), and
                                      5
                                                                                                                    the interaction term between these two predictors, failed to
                                      4
                                                                                                                    find any significant effect. The interaction term in particular
                                                                                                                    achieved a standardized β of .19, non-reliably different from
                                      3                                                                             zero, t = 0.32, p = .75.
                                                                                                                       The effectiveness of floating reinstatement does not ap-
                                          Base   Defeated   Reinstated         Base   Defeated   Reinstated         pear to result from the subjects manifesting a preference for
                                                                     Pattern
                                                                                                                    one of the mutually defeated arguments. We conducted four
                                                                                                                    repeated-measure analyses of variance, one for each argu-
Figure 5: Reinstatement is as effective in its floating form                                                        ment set, with conclusion acceptance as a dependent vari-
as in its simple form. Confidence in the conclusion of an                                                           able, pattern as a 2-level predictor (Defeated, Reinstated), and
argument decreases when the argument is defeated, and is                                                            preference as a dummy coded between-group variable (0 for
then imperfectly restored when its defeater is itself defeated,                                                     subjects who said the two mutually defeating arguments were
whether by a single argument (simple reinstatement) or by                                                           equally good, 1 otherwise). The interaction term between pat-
two mutually defeating arguments (floating reinstatement).                                                          tern and preference did not achieve statistical significance in
                                                                                                                    any of the four analyses, all Fs in the 0.5 − 1.5 range, all ps
                                                                                                                    in the .23 − .48 range.
variable, pattern as a 3-level within-subject predictor (Base,
Defeated, Reinstated), the type of reinstatement as a 2-level                                                                               Discussion
between-group variable (Simple, Floating), and four mea-
                                                                                                                    We applied the experimental approach to understand how
sures corresponding to the four linguistic contents.
                                                                                                                    people deal with floating reinstatement in argument-based
   The multivariate test detected a significant effect of Pattern,                                                  reasoning, a case that has puzzled theoreticians for many
F(8, 38) = 6.1, p < .001, η2p = .56. It did not, however, detect                                                    years. Our results suggest that, empirically speaking, floating
a significant main effect of Type of reinstatement F(4, 42) <                                                       reinstatement works exactly as well as simple reinstatement.
1, p = .79, η2p = .04, nor a significant interaction between                                                        Participants’ confidence in an argument A decreased when it
Pattern and Type, F(8, 38) = 1.2, p = .32, η2p = .20.                                                               was attacked by an argument B, but bounced back up when
   The overall effect of Pattern reflected a successful defeat                                                      B itself was attacked by two mutually defeating arguments
followed by a successful reinstatement. As shown by con-                                                            C and D. These results clearly speak in favour of preferred
trast analysis, confidence ratings in the Defeated condition                                                        semantics. Results also suggest that the sceptical version of
were significantly lower than ratings in the Base condition,                                                        preferred semantics might be more cognitively plausible than
F(1, 45) = 34.9, p < .001, η2p = .44, and this difference                                                           the credulous version, since the effect of floating reinstate-
was not moderated by the Type of reinstatement (there is                                                            ment was not dependent on participants showing a preference
indeed no reason that it should be), F(1, 45) < 1, p = .67,                                                         for one of the two mutually defeating arguments. This ques-
η2p < .01. The confidence ratings in the Reinstated condi-                                                          tion is not yet settled, though, since the data do not make it
tion were significantly greater than in the Defeated condi-                                                         clear whether participants would be willing to commit to ac-
tion, F(1, 45) = 13.7, p < .001, η2p = .23, and this difference                                                     cepting one of the mutually defeating arguments C and D.
(more interestingly this time) was not moderated by the Type                                                        This aspect requires further investigation.
of reinstatement, F(1, 45) < 1, p = .60, η2p < .01. Just as in                                                         Besides their theoretical value, our results also have ap-
our earlier study (Madakkatel et al., 2009), reinstatement is                                                       plied value for developing agents that are meant to argue
not perfect, as ratings in the Reinstated condition remain sig-                                                     with human users. We already know that artificial agents
nificantly lower than in the Base condition, F(1, 45) = 9.0,                                                        can achieve better negotiation results with human users when
p < .01, η2p = .17. Again, there is no evidence whatsoever of                                                       they do not play normative equilibrium strategies, but rather
a moderation by Type of reinstatement, F(1, 45) < 1, p = .92,                                                       adopt boundedly rational strategies inspired from human be-
η2p < .01.                                                                                                          havioural data (Lin, Kraus, Wilkenfeld, & Barry, 2008). Gen-
   So far, results suggest that floating reinstatement has an                                                       erally speaking, we may expect that artificial agents may sim-
effect that is identical to classic reinstatement. We further                                                       ilarly be more successful when arguing with human users, if
note that although subjects found the floating reinstatement                                                        they can anticipate human reactions to various abstract argu-
problems slightly harder to understand than the simple rein-                                                        mentation frameworks. With that goal in mind, our results
statement problems, this difference appeared to play no role                                                        suggest that artificial agents may be better off avoiding dis-
in the ratings they gave for their confidence in the conclusion.                                                    cussion that may reveal a defeater, even if the agent has a
The average understanding rating was 4.6 (SD = 1.1) for sim-                                                        counter-argument to that defeater; but should be ready to use
ple reinstatement problems, compared to 4.0 (SD = 0.9) for                                                          floating reinstatement as well as simple reinstatement in order
floating reinstatement problems, t(45) = 2.0, p = .05. How-                                                         to neutralise a defeater raised by the human user. These kinds
                                                                                                              457

of heuristics can be incorporated into a decision-theoretic          Capon, S. Parsons, & H. Prakken (Eds.), The uses of com-
model of a persuasive agent that interacts with users using          putational argumentation: Papers from the aaai fall sym-
natural language (e.g. to promote a healthy diet (Mazzotta,          posium. AAAI Press. (Technical Report FS-09-06)
Rosis, & Carofiglio, 2007). Going beyond our specific re-          Mazzotta, I., Rosis, F. de, & Carofiglio, V. (2007). Portia:
sults, by building up a corpus of argument structures and how        A user-adapted persuasion system in the healthy-eating do-
they are evaluated, it may be possible to use machine learning       main. IEEE Intelligent Systems, 22(6), 42-51.
techniques to build models that predict how people will react      Pelletier, F. J., & Elio, R. (2005). The case for psychologism
to novel argument structures.                                        in default and inheritance reasoning. Synthese, 146(1-2),
   Independently of our specific results, we hope to have con-       7-35.
vinced the reader that the wealth of scientific methodology        Pfeifer, N., & Kleiter, G. D. (2009). Framing human in-
from psychology can give a new perspective on the problems           ference by coherence based probability logic. Journal of
raised when formalising argumentation and developing argu-           Applied Logic, 7, 206–217.
ment evaluation semantics. We hope that our claims and find-       Prakken, H. (2002). Intuitions and the modelling of de-
ings can prompt researchers working on the computational             feasible reasoning: some case studies. In S. Benferhat &
modelling of argument to explore new avenues of investi-             E. Giunchiglia (Eds.), Proceedings of the 9th international
gation inspired by, and validated against, empirical evidence        workshop on non-monotonic reasoning (p. 91102).
from psychology and cognitive science.                             Rahwan, I., & Simari, G. R. (Eds.). (2009). Argumentation
   We also hope to have excited cognitive scientists about           in artificial intelligence. Springer.
the growing literature on formal models of argumentation.
These models, and their associated normative properties, have
                                                                                              Materials
great potential in complementing existing research on human        Argument Set 1
reasoning, and providing conceptual means for dealing with         (A) Cody does not fly. Therefore, Cody is unable to escape by fly-
                                                                       ing.
highly complex inference structures.
                                                                   (B) Cody is a bird. Therefore, Cody flies.
                          References                               (C) Cody is a rabbit. Therefore, Cody is not a bird.
Baroni, P., & Giacomin, M. (2007). On principle-based eval-        (D) Cody is a cat. Therefore, Cody is not a bird.
   uation of extension-based argumentation semantics. Artifi-
                                                                   Argument Set 2
   cial Intelligence, 171(10–15), 675–700.                         (A) Smith does not follow American spelling. Therefore, Smith
Benthem, J. van. (2008). Logic and reasoning: do the facts             writes ‘colour’ instead of ‘color’.
   matter? Studia Logica, 88(1), 67-84.                            (B) Smith speaks American English. Therefore, Smith follows
Bonnefon, J. F., Da Silva Neves, R. M., Dubois, D., & Prade,           American spelling.
   H. (2008). Predicting causality ascriptions from back-
                                                                   (C) Smith was born and brought up in England. Therefore, does
   ground knowledge: Model and experimental validation. In-            not speak American English.
   ternational Journal of Approximate Reasoning, 48, 752–
                                                                   (D) Smith was born and brought up in Australia. Therefore, does
   765.                                                                not speak American English .
Dubois, D., Fargier, H., & Bonnefon, J. F. (2008). On
   the qualitative comparison of decisions having positive and     Argument Set 3
   negative features. Journal of Artificial Intelligence Re-       (A) The car did not slow down. Therefore, the car approached the
                                                                       signal at the same speed or higher.
   search, 32, 385–417.
Dung, P. M. (1995). On the acceptability of arguments              (B) Louis applied the brake. Therefore, the car slowed down.
   and its fundamental role in nonmonotonic reasoning, logic       (C) Louis applied the accelerator instead. Therefore, Louis did not
   programming and n-person games. Artificial Intelligence,            apply the brake.
   77(2), 321–358.                                                 (D) Louis applied the clutch instead. Therefore, Louis did not apply
Ford, M., & Billington, D. (2000). Strategies in human                 the brake.
   nonmonotonic reasoning. Computational Intelligence, 16,         Argument Set 4
   446–468.                                                        (A) Stephen is not guilty. Therefore, Stephen is to be free from
Horty, J. F. (2002). Skepticism and floating conclusions.              conviction.
   Artificial Intelligence, 135(1-2), 55-72.                       (B) Stephen was seen at the crime scene at the time of the crime.
Lin, R., Kraus, S., Wilkenfeld, J., & Barry, J. (2008). Nego-          Therefore, Stephen is guilty.
   tiating with bounded rational agents in environments with       (C) Stephen was having dinner with his family at the time of crime.
   incomplete information using an automated agent. Artifi-            Therefore, Stephen was not seen at the crime scene at the time
   cial Intelligence, (accepted).                                      of the crime.
Madakkatel, M. I., Rahwan, I., Bonnefon, J.-F., Awan, R. N.,       (D) Stephen was watching football with his friends in the stadium
   & Abdallah, S. (2009). Formal argumentation and hu-                 at the time of the crime. Therefore, Stephen was not seen at the
                                                                       crime at the time of the crime.
   man reasoning: The case of reinstatement. In T. Bench-
                                                               458

