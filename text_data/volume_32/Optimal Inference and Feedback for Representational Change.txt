UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Optimal Inference and Feedback for Representational Change
Permalink
https://escholarship.org/uc/item/9162v55j
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Tang, Yun
Young, Christopher J.
Myung, Jay I.
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                  Optimal Inference and Feedback for Representational Change
                                                  Yun Tang (tang.162@osu.edu)
                                       Department of Psychology, The Ohio State University,
                                              1835 Neil Ave, Columbus, OH 43210 USA
                                        Christopher J. Young (young.1202@osu.edu)
                                               Jay I. Myung (myung.1@osu.edu)
                                                  Mark A. Pitt (pitt.2@osu.edu)
                                                John E. Opfer (opfer.7@osu.edu)
                             Abstract                                (Siegler & Mu, 2008) and delayed in cultures that lack
  Knowledge representations are central to many cognitive
                                                                     formal schooling (Dehaene, Izard, Spelke, & Pica, 2008).
  processes, and how these representations change is a central       Recent evidence also suggests that this representational shift
  issue in learning and cognitive development. Here we               can be induced in situ by providing examples (Izard &
  developed and implemented a Bayesian inferential procedure         Dehaene 2007; Opfer & Siegler, 2007). That is, feedback on
  to detect and elucidate representational change in numerical       a few key numbers that are highly discrepant between
  estimation. The proposed procedure of an adaptive numerical        logarithmic and linear functions causes rapid and broad
  experiment both infers a learner's representation and predicts     adoption of linear representations (Opfer & Siegler, 2007).
  the feedback that is likely to induce representational change.
  We provide an application of this procedure using simulated
                                                                        Ideally feedback should take into account a child's current
  subjects and demonstrate its effectiveness in inferring            and target representational states. To do so, one must first
  representational state and inducing change.                        infer, from a few noisy examples, the model that best
                                                                     describes the child's perception of numerical magnitude.
   Keywords: representational shift; numerical estimation;
   adaptive experiment; Bayesian inference.
                                                                     This inference may be viewed as a model selection problem
                                                                     in which candidate models are evaluated and compared for
                         Introduction                                their ability to capture the regularities underlying the data
                                                                     (Pitt & Myung, 2002). With the underlying representation
Knowledge representations play a large role in cognitive             having been inferred, one is now in a position to determine
processes such as learning, memory, and problem-solving              feedback that is most likely to induce representational
(Markman, 1999), and a central problem in cognitive                  changes in learners. This latter perspective proposes
development concerns how representations change with age             hypotheses for the ideal training regimen; feedback given to
and experience (Carey, 1985; Dixon & Bangert, 2002;                  a child will be the most effective when it maximally
Siegler & Opfer, 2003).              A striking example of           discriminates between a logarithmic and linear
representational change occurs in developing numerical               representation while tracking the learner's current
magnitude representations. These representational changes            representation. These ideas can be formalized in a statistical
are apparent across a wide range of tasks where numbers are          framework, which is described in detail in a later section.
quantified along a range, whether by categorizing numbers            This formal approach should have benefits to the theoretical
by magnitude (Opfer & Thompson, 2008), estimating                    questions that motivate research on the shift in numerical
numerosity (Booth & Siegler, 2006), measurements (Booth              estimation, i.e. what is the path and source of change in
& Siegler, 2006), or positions of numbers on number lines            numerical estimation abilities? We will be able to measure
(Dehaene, Izard, Spelke, Pica 2008; Siegler & Opfer, 2003).          more precisely what about a child's representation changes
  Studies on development of numerical representations                to and what types of feedback are most likely to elicit it.
typically find that young children initially estimate                The fruits of this approach could lead to the introduction of
numerical magnitudes to increase logarithmically with                more effective teaching and training regimens.
actual value before later learning the decimal system                   In the present paper we propose a procedure that both (1)
(Siegler & Opfer 2003, Booth & Siegler 2004; Opfer &                 adaptively infers a learner's most likely representation and
Thompson 2007). This change is interesting theoretically             (2) predicts the feedback that will most likely induce
because the logarithmic representation is implicit in speeded        representational shifts through what we call a cognitive
magnitude comparisons (Moyer & Landauer, 1967) and                   tutor. We will demonstrate how this procedure is performed
generation of random numbers (Banks & Hill, 1974) despite            using computer simulations with information drawn from
explicit judgments of numerical magnitude. This shift is             previous experimental data. We will also show the
also widespread across cultures, occurring relatively early in       advantages of this procedure over traditional training studies
cultures that emphasize children's mathematical education            in efficiency and the likelihood of inducing change.
                                                                 2572

   Given our present focus on simulations of the above                analysis. It is adaptive in that it tailors the test procedure to
procedure, the purpose of this simulation study is three-fold.        individual state from trial to trial. Consequently, it obtains
First, before implementation in experimental settings, it is          sufficient evidence to make inference within the fewest
necessary to run simulations to check the performance and             possible trials.
accuracy of the method. Second, simulations could                                                             Adaptive Tutoring
demonstrate the advantages of the cognitive tutor over the
traditional paradigm. Finally, we are able to generate                        Adaptive Inference
hypothesis for later experiments from simulation results. We
use the topic of numerical estimation as a running example,
and then discuss the potential to transfer the technology to                     Pre-Test Session             Post-Test Session
other domains.
          Adaptive Numerical Experiment
For representational shift problems, specifically in the
domain of numerical representation, we propose an adaptive
numerical experiment which infers the representation and
performs the role of cognitive tutor. The procedure takes a                                                    Feedback Session
perspective of model selection and distinguishes between
the following models:
              yi  axi  b  ei (i  1,...,n)                 (1)     Figure 1: General structure of adaptive numerical
              yi  a log xi  b  ei (i  1,...,n)            (2)     experiment consisting of the adaptive inference and the
where x denotes the presented stimuli, y denotes the                  adaptive tutoring processes.
perceived numerical magnitude, and e is a normally
distributed error with mean 0 and standard deviation σ.
                                                                                                                                 EXPERIMENT
   In the experiment, we follow the paradigm used in Opfer
and Siegler (2007), which shows the importance of                                     y1             y2          …            yT
choosing feedback. The same Number-Line Task is used as
the numerical estimation task in our experiment. In each
experiment trial, the child is shown a number between 0-100
or 0-1000 and is asked to estimate its position on a line.               s0                 s1            s2                      sT
   The experiment is split into three sessions, as illustrated in
                                                                                                                                 INFERENCES
Figure 1, and mirrors previous number line studies. In the
pre-test session (Session 1), the Number-Line Task is
performed to infer the child’s existing representation model;
each trial children are shown a number and asked to                             x1                x2           …         xT
estimate its corresponding position on a line. Next in the                                                                           DESIGNS
feedback session (Session 2), children respond as in pre-test,        Figure 2: Flowchart of ADO process including repeated
but after each response are shown the (correct) linear                sessions of design optimization (designs), data collection
position of each number. The post-test session (Session 3) is         (experiment), and model updating (inferences).
similar to the pre-test session, which examines whether any
shift occurred in the child’s representation model, with no
feedback provided.
   The proposed adaptive numerical experiment applies the
Adaptive Design Optimization (ADO) method and
reorganizes the three sessions into two processes, the
adaptive inference and the adaptive tutoring. In what
follows we define the two processes and describe how ADO
works and how it is incorporated into the processes.
Adaptive Inference Process
The adaptive inference process (AIP) takes place in the
pre-test session and infers a child's most likely
representation model (e.g. linear). It conducts a series of
                                                                      Figure 3: A typical curve of model probability change in
experiment trials and presents the numerical stimuli
                                                                      ADO experiments.
sequentially. Within each trial, the observed response is
analyzed and the next stimulus is provided based on the
                                                                  2573

   The adaptive choice of numerical stimuli is formally done        retains a logarithmic model or changes to an undesired
via experiment design optimization methods, where the               linear model (e.g. a linear model with slope smaller than .5),
numerical stimuli are the designs of interest. The idea of          the feedback and post-test sessions are repeated until the
design optimization in this task is to find a numerical             child has acquired the target model. Generally speaking,
stimulus that is the most informative in distinguishing             adaptive inference is also performed within the adaptive
among alternative representational formats (i.e., logarithmic       tutoring process.
vs. linear). This method of adaptive design optimization               The adaptive tutoring process starts from the information
(ADO) is developed and performed in a Bayesian                      sT obtained at the end of the adaptive inference process. In
framework (Myung & Pitt, 2009). In ADO, design                      determining the numbers to be used for teaching, our
optimization (designs), data collection (experiment), and           assumption is that the most informative feedback stimuli for
model updating (inferences) are repeatedly performed, as            the child lie in the region where the target model and the
illustrated in the flowchart in Figure 2. In the process, x         child's current representation model have the largest
denotes the numeric value presented to the child and is the         discrepancy. The target model is assumed as a fixed, correct
design variable to be optimized. The symbol y denotes the           model. Hence, we are not adapting to the child’s
child's response, and s denotes the current inference about         representation states, but are optimizing to the difference
the child's underlying representation state, such as the            between the child’s current status and the target model.
relative likelihood of candidate models and their parameters,       Formally, we are maximizing the informativeness of the
which are formally defined later. The numbers the child sees        feedback stimulus described as the discrepancy between its
in the session are updated trial by trial along the experiment.     true value and its value in the child's representation. The
   The ADO process is performed as follows. At the                  child is tested with the optimal feedback and is corrected
beginning, the experimenter has some prior information s0           with the true position. Then the experimenter obtains the
about the child’s model, from which the initial number x1 is        updated information about the child's numerical
drawn and the response y1 is observed. With s0 and y1, the          representation model using the same process as in AIP. The
posterior s1 is obtained by Bayes theorem. For the next trial,      updated information can be used to find the next optimal
s1 serves as the prior and the above process is repeated. The       feedback stimulus, if necessary. The process runs back and
process continues until the model information sT after T            forth until the child has shown acquisition of the target
trials meets certain stopping criterion. Such an adaptive           model by giving accurate linear responses to the numerical
approach bases the later designs upon previous experimental         stimuli. In all, the adaptive tutoring process tailors to the
results and makes better use of individual data. Hence, it is       child's learning progress and provides a way to combine
more efficient compared to the traditional manner of using          optimal teaching and progress verification.
the same designs for every individual. Figure 3 shows a
typical curve of model probability obtained from an ADO             Bayesian Framework of Design Optimization
simulation. It indicates that the predicted model probability       In this section, we provide a brief description of the ADO
of the true underlying model reaches as high as .9 within           framework implemented in this paper. For fuller technical
four trials. To summarize, ADO-embedded adaptive                    details and applications, the reader is directed to Myung and
inference process could find the optimal designs (i.e.              Pitt (2009) and Cavagnaro, Myung, Pitt and Kujala (2010).
numerical values to estimate) that tailor to individual state,      In ADO, each experimental design is assigned a utility
thus could permit efficient inference from the results.             describing the value of a hypothetical experiment with that
                                                                    design. It is analogous to choosing among a set of gambles
Adaptive Tutoring Process                                           whose payoff is determined by the risks and rewards of each
After inferring the child’s representation model through            type of gamble. The set of all possible designs that could be
AIP, we may know that the child uses some undesired                 used in a given experiment consist of the design space
logarithmic or linear model. The next concern is to find            (Amzal, Bois, Parent, & Robert, 2006; Pitt & Myung,
appropriate feedback stimuli that will be most likely to            submitted). The goal of ADO is to search the entire design
induce representational shift. For this purpose, we combine         space and find the most informative design(s).
the feedback session and the post-test session to form what            The problem of design optimization is formally expressed
we call the adaptive tutoring process (ATP). Design                 as finding an optimal design d* over the design space,
optimization methods are also applied in ATP. In the                which maximizes the expected utility function U(d). U(d)
feedback session, the choice of the feedback stimuli is             typically takes into consideration of all unknown but
optimized in order to teach the child most effectively. For         possible conditions. If multiple models are plausible for
this purpose, we make the assumption that the effectiveness         describing the underlying process in an experiment, U(d)
of the design is determined by the maximum discrepancy              could be defined as:
between the child's model and the target model (e.g., an                      K
                                                                    U (d )   p(mi )  u (d , mi ,  mi , y) p( y |  mi , d ) p( mi )dyd mi
accurate line yi  xi ). After the optimal feedback stimulus                 i 1                                                                (3)
is found and provided to the child, ATP moves to the post-             In the above equation, mi (i = {1, …, K}) is one of K
test session. The post-test session infers the child's model        models under consideration, d is a design, y is the outcome
again and checks if he has changed the model. If the child          of an experiment with design d under model m, θm is the
                                                                2574

parameter of model m, and finally, u(d, θm, y) is the “local”                           In order to run the simulations, we first chose the priors
utility function of deign d, parameter θm and experimental                           on the basis of previous experiment data and experts'
outcome y. In general, U(d) represents the expected value of                         beliefs, so that the priors covered a reasonable range of
local utility functions in which the expectation is taken over                       numerical representation models. Several data sets (e.g.
all possible models and their parameters and over all                                Opfer & Siegler, 2007, Siegler & Opfer, 2003) were fitted
possible experimental observations given the models and                              and the parameter ranges of the models were obtained.
parameters.                                                                          Uniform priors over the parameter ranges were then used for
   In adaptive design optimization, the optimization of U(d)                         intercept, slope, and error variance. Figure 4 shows a sample
is repeated over a series of experimental stages. At each                            of possible models under the priors, in which the linear
stage, the model and parameter priors, p(m) and p(θm), are                           models and logarithmic models are mixed with each other.
updated upon the specific outcome observed in an actual                              It also suggests the difficulty of depicting intuitive designs
experiment carried out with the optimal design d*. This                              for distinguishing between the two sets of models.
updating is performed via Bayes rule and Bayes factor                                   The simulation first implemented the pre-test session with
calculation (Gelman, Carlin, Stern & Rubin, 2004).                                   the above priors. The data-generating model, which was
                                                                                     assumed to be the child's true model in the simulations, took
                                                    Simulations                      the following logarithmic form:
                                                                                               yi  0.21 log xi  0.75  ei , ei ~ N (0,0.0052 )
Pre-test Simulations and Results                                                        Within each simulation, we ran 10 trials (number of trials
In this section, we describe the computer simulations that                           fixed for convenience purposes) of the Number-Line Task
demonstrate the performance and advantages of the adaptive                           in the pre-test session. Results showed that after 6 trials, we
numeric estimation experiment. The purpose of conducting                             had already obtained sufficient evidence to conclude that the
simulations is to guarantee that the processes work as                               logarithmic model was over 90% likely to be the data-
expected, as well as to show the efficiency of the                                   generating model. Meanwhile, we also narrowed down the
methodology.                                                                         range of model parameters as shown in the prediction
                                                                                     density scatter plot in Figure 5. The darkness of each dot
                                                                                     indicates the probabilities of a response y given the
                                                                                     presented number x. Figure 5 shows that the predictions
                                                                                     from possible linear models are more widely spread than the
                                                                                     predictions from possible logarithmic models. It suggests
                                                                                     that the predictions from the logarithmic model posteriors
                                                                                     are highly concentrated and have higher probabilities, which
                                                                                     provides strong evidence that the true model takes a
                                                                                     logarithmic form.
                                                                                     Feedback and Post-test Simulations
                                                                                     After the pre-test session, we simulated the adaptive
Figure 4: Sample curves of linear (black solid lines) and                            tutoring process. The first step was to choose an optimal
logarithmic (red dashed curves) models randomly generated                            feedback stimulus that maximized the discrepancy between
from the priors.                                                                     the target model and what we knew about the child’s
                                     1
                                                                                     existing model. Formally, the utility of the feedback design
                                                                                     accounted for the prediction probabilities of both models, as
                                    0.8
         Position Estimation (yi)
                                                                                     well as the parameter range of both models. For the specific
                                                                                     simulated learner, the optimal feedback design was found at
                                    0.6
                                                                                     x = 0.354. That is, the child would be most “surprised” for
                                                                                     this stimulus when he sees the difference between his
                                    0.4
                                                                                     response and the correct answer. Figure 6 shows the
                                                                                     location of the optimal feedback and its relationship with
                                    0.2
                                                                                     the child’s model and the target model.
                                                                                       To simulate the post-test session, we needed to assume a
                                     0
                                          0   0.2     0.4      0.6      0.8   1      learning mechanism that caused the representational shift
                                               Actual Numerical Value (xi)           and generated the post-test experiment results. An intuitive
Figure 5: Prediction density scatter plot of linear and                              assumption was a conservative learning mechanism in
logarithmic model predictions at the end of the pre-test. The                        which a child learner made the smallest change to
darkness of each dot indicates the probabilities of a response                       accommodate the feedback. Suppose the child could change
y given the presented number x. Black dots indicate the                              to any models within the range of the priors. Among these
highest probabilities and the yellow dots indicate the lowest                        models, there were a subset of linear models and a subset of
probabilities.                                                                       logarithmic models that were consistent with the learned
                                                                                  2575

feedback. A conservative learner would estimate the amount              The post-test session simulation started from the same
of overall discrepancy between these candidate models and            priors used for the pre-test session (shown in Figure 4). It
the current model and choose the one that has the smallest           was because the data-generating model had changed and the
discrepancy. That is, the conservative learning mechanism            posterior information from the pre-test session was no
assumed the child to be an ideal learner. To demonstrate             longer valid. For convenience purpose, we simulated 5 trials
another plausible mechanism, we also assumed a less ideal            of Number-Line Task in the post-test session. For the
learner, the model-conservative learner. The model-                  conservative learner, there was sufficient evidence to
conservative learning mechanism assumed that the child               conclude that linear model was over 90% likely to be the
only considered a subset of logarithmic models that were             data-generating model after 4 trials. For the model-
consistent with the learned feedback and chose one that              conservative learner, it took 5 trials. The range of parameter
required the smallest change from the previous model. In             estimates for the data-generating model was also narrowed
both mechanisms, the winning model was used as the data-             down at the end of the post-test session. Hence, results from
generating model for the post-test session. Figure 7 shows           the post-test simulations showed that the post-test session
representational shifts of the two hypothesized learners.            made quick and reliable inferences about the new data-
After learning the optimal feedback, the conservative                generating model.
learner changes to a linear model yi  0.758  xi  0.086  ei ,        In general, simulation results of the pre-test, feedback,
and the model-conservative learner changes to another                and post-test sessions demonstrated the validity and the
logarithmic model yi  0.218  log xi  0.580  ei . The two         efficiency of the adaptive numerical experiment. We further
                                                                     discuss its practical applications and theoretical implications
models intersect at the point of optimal feedback because            in the next section.
they both accommodate the feedback.
                                                                                              Discussion
                                                                     Previous feedback studies have demonstrated that providing
                                                                     children with data that is incommensurate with their current
                                                                     numerical representation can promote a representational
                                                                     shift. In the current paper we improved upon this design
                                                                     using an adaptive design optimization procedure to perform
                                                                     an adaptive-inference, adaptive-tutoring process. This
                                                                     process infers the most likely dominant numerical
                                                                     representation and provides the optimal feedback to elicit a
                                                                     shift to an accurate linear representation. We simulated this
                                                                     process for a logarithmic learner using parameters from
                                                                     previous empirical experiments. Finally we predicted the
Figure 6: Optimal feedback for the simulated learner                 learner's updated numerical representation based on two
indicated by the square at x = 0.354. The prediction density         possible learning mechanisms.
scatter plot shows the inference of the child’s representation          We established the plausibility of the algorithm for the
at the end of the pre-test session. The dotted line shows the        problem at hand.         The adaptive design optimization
target model ( yi  xi ).                                            procedure was able to infer the data generating function in
                                                                     each simulation by optimizing across the design space. The
                                                                     procedure was more efficient than traditional feedback
                                                                     studies in inferring the simulated child’s representational
                                                                     state in a few trials. This efficiency in turn suggests that a
                                                                     shorter pre-test phase is less likely to reinforce the learner's
                                                                     initial representation. Shorter testing and feedback phases
                                                                     also provide obvious benefits to both experimentation and
                                                                     real world application for testing children; fewer trials
                                                                     reduce the overall attentional costs to children and thereby
                                                                     reduce the influence of attention-related noise in their
                                                                     responses.
                                                                        The adaptive tutoring process also proved useful in
                                                                     determining optimal feedback. Feedback points have
Figure 7: Predicted representational shift to the linear model       previously been chosen to maximize the discrepancy
(solid line) and the logarithmic model (dashed curve) caused         between an ideal logarithmic and linear function (Opfer &
by the two learning mechanisms. Both models intersect with           Siegler, 2007), while our cognitive tutor chooses
the target model at the feedback (the square).                       personalized feedback based on the individual learner's most
                                                                     likely logarithmic or linear representation. This generates
                                                                     very informative results about the ideal feedback points.
                                                                 2576

The magnitudes chosen by the adaptive tutor are                                           References
approximately 30% of the range for a simulated learner
                                                                  Amzal, B., Bois, F. Y., Parent, E., & Robert, C. P. (2006).
based on the parameters of children from previous studies.
                                                                    Bayesian-optimal design via interacting particle systems.
They are near to the previously chosen points (15% of the
                                                                    Journal of the American Statistical Association, 101(474),
range), but are clearly not the same. These optimal
                                                                    773-785.
feedback points may prove to vary widely in actual children,
                                                                  Banks, W. & Hill, D. (1974). The apparent magnitude of
highlighting the need for the adaptive tutoring process to
                                                                    number scaled by random production. Journal of
control for individual differences in representations.
                                                                    Experimental Psychology, 102(2), 353-376.
   The adaptive numeric estimation experiment clearly needs
                                                                  Carey, S. (1985). Conceptual change in childhood.
to be run on children to determine its external validity,
                                                                    Cambridge, MA: MIT Press.
which we plan to carry out. Nevertheless, we were able to
                                                                  Cavagnaro, D. R., Myung, J. I., Pitt, M. A., & Kujala, J. V.
use the adaptive experiment to accurately infer the
                                                                    (2010). Adaptive design optimization: A mutual
representational state of a simulated learner. A byproduct of
                                                                    information-based approach to model discrimination in
this process was the implementation of two potential
                                                                    cognitive science. Neural Computation, 22(4), 887-905.
learning mechanisms to test the end-state representation of
                                                                  Dehaene, S., Izard, V., Spelke, E., & Pica, P. (2008). Log or
the simulated learner.        The conservative and model-
                                                                    linear? Distinct intuitions of the number scale in Western
conservative learning mechanisms were used to produce
                                                                    and Amazonian Indigene Cultures. Science, 320, 1217-
quantitative predictions. A conservative model that uses
                                                                    1220.
optimal feedback to adjust parameters and the model form
                                                                  Dixon, J., & Bangert, A. (2002). The prehistory of
with the least amount of change showed a shift to a more
                                                                    discovery: Precursors of representational change in
accurate linear function with parameters near to the ideal
                                                                    solving gear        system problems.         Developmental
model. The model-conservative mechanism resulted in a
                                                                    Psychology, 38(6), 918-933.
preserved logarithmic function with an overall decrease in
                                                                  Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B.
the model parameters.
                                                                    (2004). Bayesian data analysis. (2nd ed.). Boca Raton, FL:
   If these results can be extended to children, they would
                                                                    Champan and Hall/CRC.
support a perspective that learner will behave as a modeler
                                                                  Kruschke, J. (1996). Dimensional relevance shifts in
and update his dominant representation with ideal feedback.
                                                                    category learning. Connection Science, 8(2), 225-247.
We might then further test whether the child learner is
                                                                  Marcus, G. (1995). The acquisition of the English past tense
engaging in Bayesian learning; specifically whether the
                                                                    in children and multilayered connectionist networks.
different learning mechanisms can be seen as a variation in
                                                                    Cognition, 56, 271-279.
the learner's likelihood ratio. Conservative learning asserts
                                                                  Markman, A. B. (1999). Knowledge representation.
equal likelihood to the representations, while model-
                                                                    Mahwah, NJ: Lawrence Erlbaum Associates.
conservative learning gives weight only to the dominant
                                                                  Moyer, R. & Landauer, T. (1967). Time required for
representation. These may be plausible mechanisms of
                                                                    judgments of numerical inequality. Nature, 215, 1519-
cognitive change based on culture and the strength of each
                                                                    1521.
representation, with emphasis on mathematical education
                                                                  Myung, J. I. & Pitt, M. A. (2009). Optimal experimental
directly affecting the learner's likelihood ratio of a linear
                                                                    design for model discrimination. Psychological Review,
representation.
                                                                    116(3), 499-518.
   Adaptive inference of the probability that a learner is
                                                                  Opfer, J. & Siegler, R. (2007). Representational change and
linear or logarithmic in representation and an adaptive tutor
                                                                    children’s numerical estimation. Cognitive Psychology,
function that maximizes the effect of feedback are necessary
                                                                    55, 169-195.
to understand the learner's representation which might apply
                                                                  Opfer, J. & Thompson, C. (2008). The trouble with transfer:
to many types of representations in diverse areas. The
                                                                    Insights from microgenetic changes in the representation
process could easily be extended to similar numerical
                                                                    of numerical magnitude. Child Development, 79(3), 788-
estimation tasks that use a variety of presented numerical
                                                                    804.
stimuli to determine perceived magnitude. It is possible to
                                                                  Pitt, M. A. & Myung, I. (2002). When a good fit can be bad.
extend this design to other areas in which representational
                                                                    Trends in Cognitive Sciences, 6, 421-425.
shifts are seen, whether to determine children's past tense
                                                                  Pitt, M. A. & Myung, J. I. (submitted). Designing a better
verb use and predict errors in overgeneralization (Marcus,
                                                                    experiment. Manuscript submitted for publication.
1995) or function learning to predict attention to relevant
                                                                  Siegler, R. & Mu, Y. (2008). Chinese children excel on
cues (Kruschke 1996). The adaptive design optimization
                                                                    novel mathematics problems even before elementary
procedure is of obvious use as a means of better modeling
                                                                    school. Psychological Science, 19(8), 759-763.
the learner and refining training.
                                                                  Siegler, R. & Opfer, J. (2003). The development of
                                                                    numerical      estimation:     evidence     for    multiple
                     Acknowledgment                                 representations of numerical quantity. Psychological
This research is supported in part by the NIH Grant R01-            Science, 14 (3), 237-43.
MH57472 to JIM and MAP.
                                                              2577

