UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Interactivity During Spoken Word Recognition: Evidence from Bimodal Bilinguals
Permalink
https://escholarship.org/uc/item/5kw0n2g7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Shook, Anthony
Marian, Viorica
Publication Date
2010-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

            Interactivity During Spoken Word Recognition: Evidence from Bimodal Bilinguals
                                        Anthony Shook (a-shook@northwestern.edu)
                           Department of Communication Sciences and Disorders, 2240 Campus Drive
                                                       Evanston, IL 60208 USA
                                        Viorica Marian (v-marian@northwestern.edu)
                           Department of Communication Sciences and Disorders, 2240 Campus Drive
                                                       Evanston, IL 60208 USA
                             Abstract                                 simultaneously activated. This effect appears to be bottom-
                                                                      up in nature – as auditory input enters the language system,
   We explore the role of top-down information in language            it non-selectively activates lexical items in both languages
   processing by investigating parallel language activation in        based on structural overlap. Critically, a dual-language
   bimodal bilinguals, who are fluent users of a spoken and a         bottom-up pathway cannot exist in bimodal bilinguals, as
   signed language. In an eye-tracking study, bimodal bilinguals
                                                                      their languages do not utilize the same structural input. The
   showed activation of their signed language while receiving
   input in English only. Since spoken and signed languages do        cross-modal nature of bimodal bilingualism therefore allows
   not share structure, the results suggest that linguistic           for the direct investigation of top-down mechanisms in
   information can be readily transmitted across modalities, and      isolation.
   that parallel language activation can be driven by top-down           If bimodal bilinguals co-activate their two languages in
   processes.                                                         the absence of form overlap, it would suggest that language
   Keywords: bilingualism; ASL; language co-activation; top-          co-activation can be driven by top-down information, and
   down processing; eye-tracking; visual world paradigm               would require a system capable of activating the non-target
                                                                      language via top-down or lateral connections. Models that
                         Introduction                                 consider exclusively bottom-up information for lexical
The architecture of the language system is determined by              activation or selection (such as the Shortlist Model, Norris,
the way that information flows among levels of processing.            1994) are unlikely to be able to explain this result, as they
Language processing may involve both bottom-up/feed-                  limit activation to items that exist in the same modality as
forward and top-down/feed-back mechanisms (Rapp &                     the target. Therefore, a bimodal bilingual, when faced with
Goldrick, 2000; Navarette & Costa; 2009). However,                    single-modality input (e.g., spoken English), should not
exclusively feed-forward systems may also be capable of               activate the signed language.
explaining language processing without the aid of feed-back              However, recent research indicates that bimodal
mechanisms (Hagoort & Levelt, 2009; Levelt, Roelofs, &                bilinguals do co-activate their languages. For example,
Meyers, 1999; McQueen, Jesse, & Norris, 2009; Norris,                 hearing ASL-English bilinguals produce speech and signs
1994). Proponents of language systems that recruit top-               simultaneously (Emmorey, Borinstein, Thompson, &
down mechanisms face the difficulty of separating the                 Gollan, 2008), deaf ASL-English bilinguals show
impact of top-down information from that of bottom-up                 interference from sign-language while processing written-
information. When both forms of information are present, it           English (Villwock, Wilkinson, Bailey, Kroll, Morford, &
is difficult to disentangle the unique contributions each may         Piñar, 2009), and late-learning Dutch-Sign Language of the
make to language processing. To understand the role of top-           Netherlands bilinguals show interference from English
down mechanisms during language processing, the                       while processing SLN signs (Van Hell, Ormel, van der
influence of top-down pathways must be measured in                    Loop, & Hermans, 2009). In addition to clarifying the role
isolation. One possible way of limiting the impact of                 of top-down mechanisms in language processing, language
bottom-up information is by investigating language                    co-activation in bimodal bilinguals would suggest that
processing in bimodal bilinguals.                                     linguistic information is readily transmitted across
   Unlike unimodal bilinguals, who use two spoken                     modalities, such that two unrelated languages can be
languages, bimodal bilinguals are fluent in a spoken and a            activated simultaneously, even when phonological
signed language. Research on unimodal bilinguals has                  information from one of the two languages is absent.
revealed non-selective language effects, wherein unimodal                The current study used an adapted visual world paradigm
bilinguals activate both of their languages in parallel               to examine parallel language processing in normal-hearing,
(Blumenfeld & Marian, 2007; Marian & Spivey, 2003;                    ASL-English bilinguals. Investigating whether languages
Weber & Cutler, 2004). For example, when a Russian-                   that do not share modality are co-activated in bimodal
English bilingual hears the English word “marker,” she will           bilinguals can provide insight into the influence of top-down
also make eye movements to items that are phonologically              mechanisms on language processing and the architecture of
similar in the non-target language (e.g., Russian) such as            the language system in general, as well as reveal the extent
“marka” (stamp), suggesting that her Russian is                       to which linguistic information is modality independent.
                                                                  790

                            Method
Participants
Twenty-six participants were tested (thirteen ASL-English
bilinguals, Mage=33.2, SD=11.8 and thirteen English
monolinguals, Mage=23.9, SD=9.8). An additional five
participants were not included in the analysis – three due to
failure to display sufficient proficiency in ASL, and two due
to technical error with the eye-tracker. All participants
completed the Peabody Picture Vocabulary Test (PPVT-III;
Dunn & Dunn, 1997) to assess their English vocabulary
skill. No differences were found between bilinguals
(M=108.2, SD=9.9) and monolinguals (M=111.8, SD=9.4;
t(24)=0.96, p=.35).        Information on the participants’
language background was obtained via the Language
Experience and Proficiency Questionnaire (LEAP-Q;
Marian, Blumenfeld, & Kaushanskaya, 2007). On a scale of
1-10, where 10 means “fluent,” bilinguals rated their ASL
abilities at 8.5 for production, and 8.8 for comprehension,
indicating a high degree of ASL proficiency.              All
participants reported normal hearing and vision.
                                                                        Figure 1: Example of a Competitor Trial.
Materials                                                               Participants eye-movements were recorded while
Twenty-two minimal sign pairs were developed by choosing                they were instructed in English to “click on the
two signs that matched on three of four ASL-phonological                cheese.” At the same time, a phonologically related
parameters – handshape, location in space, motion, and                  competitor in ASL (“paper”) was present in the
orientation of the palm (Brentari, 1998). These sign pairs              display.
represented the target and competitor items in our
competitor condition. For example, the signs for “cheese”         for a look, 0 for no look) and duration of looks (percent of
and “paper” overlapped in handshape, location, and palm           time per trial spent looking at an item). There were twenty-
orientation, but differed in the motion of the sign. Target       two competitor trials, containing a target, a competitor item
and competitor signs did not differ significantly in English      that overlapped with the target in ASL phonology, and two
word frequency [t(38)=-1.654, p=.106] (obtained from the          fillers (Fig. 1). Every competitor trial had a corresponding
SubtLexus database; Brysbaert & New, 2009). In addition,          control trial, in which the content and location of the target
twenty-two control items and 110 filler items were chosen         item and two filler items were identical, but where the
based on their lack of phonological overlap to the target in      phonologically-overlapping competitor item found in the
both ASL and English. Control items were used in place of         competitor trial was replaced with an unrelated control item.
competitor items in the control condition. Control signs          This allowed for the comparison of looks to a specific
also did not differ from target signs in English word             location in the display as a function of the presence or
frequency [t(38)=-1.027, p=.311]. In the experiment, each         absence of a phonological competitor. There were also
item was represented by a black and white line drawing. In        forty-four filler trials, containing a target and three
each condition, four black and white drawings were                phonologically unrelated items.
displayed on a computer screen in the corners of a 3x3 grid.
The words were recorded at 44.1 Khz, 32 bits by a female,         Procedure
monolingual speaker of English, in sentence context as the        After informed consent was obtained, participants viewed a
final word in the phrase “click on the _____.” Recordings         video clip displaying the experimental instructions in ASL
were normalized such that the carrier phrase was of equal         performed by a native signer of ASL. Following the
length for all target sentences, and the onset of the target      instructions, participants were fitted with an ISCAN eye-
word always occurred at 600 ms post onset of the sentence.        tracker to measure the location of their gaze during the eye-
Recordings were amplitude-normalized.                             tracking portion of the experiment. Instructions were again
                                                                  provided, in both written and spoken English, followed by
Design                                                            five practice trials meant to familiarize participants with the
The current study used a 2x2 Mixed design, with group             task. Auditory stimuli were presented over headphones and
(bilingual, monolingual) as a between-subjects factor, and        appeared synchronously with picture stimuli. Participants
condition (competitor, control) as a within-subjects factor.      were told that they would hear instructions to choose a
The dependent variables include the proportion of looks (1        specific object in the visual display, and should click on the
                                                                  object that best represents the target word. Participants’ eye-
                                                              791

movements were recorded. After the eye-tracking portion of           measures ANOVAs were performed on each individual
the experiment, all participants completed the PPVT and the          window, with time (1, 2, 3) and condition (competitor,
LEAP-Q. In addition, bilingual participants were presented           control) as within-subjects factors. Significant effects of
with a list of words and asked to provide the American Sign          condition were found in each of the four 100 ms time
Language translations.        Bilinguals provided correct            windows between 0 ms (word onset) and 400 ms, between
translations for 95.2% of the words (M=62.8/66, SD=2.5).             1000 and 1100 ms, and between 1300 and 1400 ms (all
                                                                     ps<0.05); in all cases, bilinguals showed more looks to
                           Results                                   competitor items than control items. Similar analyses
                                                                     performed on the monolingual activation curves revealed no
Frequency of Looks
We measured both the proportion and duration of looks to
competitor and control items. Bilinguals looked more at
competitor items than at control items, and looked more at                                                1
                                                                                                                                            Competitor
competitor items than monolingual participants. Repeated                                                 0.9                                Control
measures Analyses of Variance (ANOVAs) revealed a
significant Group x Condition interaction for both the                                                   0.8                    *
                                                                       Proportion of Looks (%)
proportion [F(1,24)=27.284, p<0.001; Fig. 2] and duration
[F(1,24)= 23.285, p<0.001; Fig. 3] of looks. Bilinguals
looked at competitor items more than at control items
                                                                                                         0.7
                                                                                                                       *
                                                                                                         0.6
[t(12)=7.62, p<0.001] and for a longer period of time
[t(12)=5.925, p<0.001], signifying that bilinguals activated                                             0.5
phonologically     related    competitors      more     than                                             0.4
phonologically unrelated controls. No differences were
found in the monolingual group for either the proportion                                                 0.3
[t(12)=-0.95, p=0.362] or duration [t(12)=-0.16, p=0.87] of
looks. Bilinguals also looked at competitor items more than                                              0.2
monolinguals [t(24)=5.58, p<0.001] and for a longer period                                               0.1
of time [t(24)=3.512, p<.01], while both groups looked at
control items equally [proportion=t(24)=1.18, p=0.248;                                                    0
duration=t(24)=-.73, p=0.47], verifying that bilinguals                                                             Bilingual           Monolingual
activated phonologically related items more than
monolinguals. Means and standard errors are illustrated in
Table 1.
                                                                                                               Figure 2. Proportion of Looks (%)
  Table 1: Means and Standard Errors of the Proportion and
                 Duration of Looks (%).                                                                  0.2
                                                                                                                                            Competitor
                   Proportion (%)        Duration (%)
                                                                                                                                *           Control
                                                                       Percent Time Spent Looking (%)
                  Comp. Control         Comp. Control
                                                                                                        0.15
   Bilingual
                   66.9
                   (2.8)
                              51.6
                              (3.5)
                                         12.9
                                         (0.8)
                                                    7.7
                                                   (0.6)                                                               *
                   42.9       45.5        8.5       8.6
  Monolingual                                                                                            0.1
                   (3.2)      (3.8)      (0.9)     (1.0)
Time Course                                                                                             0.05
Analysis of the bilingual time-course was consistent with
the overall looks analysis, with bilinguals looking at
competitors more than at control items. In contrast,
monolinguals looked at competitor and control items                                                       0
equally across time. The activation curves were divided                                                             Bilingual           Monolingual
into 100 ms windows, beginning with the time window
between -600 and -500 ms (which signified the first 100 ms
after the onset of the picture), and ending with the window
between 1900 and 2000 ms. Three-by-two repeated-                                                                Figure 3. Duration of Looks (%)
                                                               792

                                                                   Monolinguals
                          1
                                                                                                                            Target
                        0.9                                                                                                 Competitor
                        0.8                                                                                                 Control
  Proportion of Looks
                        0.7
                                  Target Word Onset
                        0.6
                        0.5
                        0.4
                        0.3
                        0.2
                        0.1
                          0   2000
                              1900
                              1800
                              1700
                              1600
                              1500
                              1400
                              1300
                              1200
                              1100
                              1000
                              900
                              800
                              700
                              600
                              500
                              400
                              300
                              200
                              100
                              0
                              -100
                              -200
                              -300
                              -400
                              -500
                              -600
                                                                     Bilinguals
                          1                                                                                                  Target
                        0.9                                 *                                    *            *              Competitor
                        0.8                                                                                                  Control
  Proportion of Looks
                        0.7        Target Word Onset
                        0.6
                        0.5
                        0.4
                        0.3
                        0.2
                        0.1
                          0   2000
                              1900
                              1800
                              1700
                              1600
                              1500
                              1400
                              1300
                              1200
                              1100
                              1000
                              900
                              800
                              700
                              600
                              500
                              400
                              300
                              200
                              100
                              0
                              -100
                              -200
                              -300
                              -400
                              -500
                              -600
                                                                     Time (ms)
                              Figure 4. Time-course data for Monolingual (top) and Bilingual (bottom) participants, showing activation
                              curves for proportion of looks to target, competitor, and control items across time. The negative 600 time
                              point represents onset of the picture stimulus, and the 0 time point represents onset of the target word.
                              Shaded areas indicate windows where looks to competitor and control items differed at p<0.05
significant effects of Condition for the monolingual group in                     earlier target or competitor fixations. If there was a higher
any time window (all ps > 0.1), suggesting that                                   proportion of late-window looks when the early window
monolinguals did not look more at competitor items than                           contained a look to either the target or competitor than when
controls (see Figure 4).                                                          it did not, it would suggest that late-window activation was
  It is possible that the effect seen in the late windows                         due to residual activation from the early window. However,
(1000-1100 ms and 1300-1400 ms) is a product of residual                          both instances showed the same proportion of looks,
activation from the early window. To ensure that the late-                        t(12)=1.04, p=.377, suggesting that the results seen in the
window effects were not due to lingering activation from the                      late-windows are not due to previous activation in the early-
early window, the proportion of late-window looks to                              window.
competitors with a look to targets or competitors in the
early-window was compared to late-window looks without
                                                                            793

                         Discussion                                   is still a product of top-down processes – the linguistic input
                                                                      should activate English only. However, bimodal bilinguals
The results of the current experiment provide evidence for a
                                                                      clearly activate their ASL during the task.
modality-independent language system that utilizes top-
                                                                         Coactivation may also occur via lateral links between
down pathways during processing by revealing parallel
                                                                      translation equivalents. As an English word is presented, it
language activation in bimodal bilinguals. Specifically,
                                                                      may activate its ASL translation via direct excitatory
bilinguals looked more to items with ASL translation
                                                                      connections at the lexical level, which may in turn activate
equivalents that overlapped phonologically with the target
                                                                      phonologically similar ASL items. While this account does
item than to items with translation equivalents that did not
                                                                      not involve top-down processes, it is also not exclusively
overlap, suggesting that phonologically overlapping
                                                                      bottom-up, and requires a system capable of interaction
competitor items were more activated than unrelated
                                                                      across languages, within a single level of processing.
controls. In turn, monolinguals looked at competitor items
                                                                      However, the strength of within-level translational
and unrelated control items equally. This pattern was found
                                                                      connections in bimodal bilinguals is unclear. For instance,
in the overall looks analysis and in the duration of looks
                                                                      bimodal bilinguals do not show enhanced performance on
analyses, as well as within specific time windows during
                                                                      executive control tasks, which has been found in unimodal
processing. The results suggest that even though the
                                                                      bilinguals. Emmorey, Luk, Pyers, and Bialystok (2008)
bilingual participants received no ASL input, they
                                                                      suggest that since a bimodal bilingual’s two languages
nevertheless activated their sign-language during the
                                                                      utilize separate modalities, they do not compete to the same
experiment.
                                                                      extent as two spoken languages. Therefore there is less
   The finding that bimodal bilinguals coactivate their
                                                                      need for executive control of the non-target language in
languages indicates that lexical items from two distinct
                                                                      bimodal bilinguals. One could argue that the lack of
languages do not require surface-level overlap in order to be
                                                                      competition between a spoken and a signed language may
simultaneously activated. Previous studies on unimodal
                                                                      indicate that bimodal bilinguals do not develop cross-
bilinguals have relied on bottom-up information as the force
                                                                      linguistic connections in the same manner as unimodal
behind parallel language activation – words activate
                                                                      bilinguals. It is not yet clear whether the connections
phonologically similar words, regardless of language. If
                                                                      between translation equivalents, or the way in which they
parallel activation is driven purely by overlap at the
                                                                      are processed, are similar in unimodal and bimodal
phonological level, then the bimodal participants should not
                                                                      bilinguals.
have shown cross-linguistic activation. Instead, the
                                                                         Regardless of whether parallel activation in bimodal
connection between ASL and English likely exists at the
                                                                      bilinguals is due to top-down effects or lateral connections
semantic level, since the two languages do not share
                                                                      at the lexical level, it is clear that the processes that underlie
phonological or lexical items. Semantic representations,
                                                                      language coactivation in bimodal bilinguals differ from
once activated, appear to be able to feed back to the lexical
                                                                      those of unimodal bilinguals.             While coactivation in
levels of both signed and spoken languages, resulting in
                                                                      unimodal bilinguals relies more on phonological overlap
parallel activation.
                                                                      across two languages, no such overlap exists within the
   However, the mechanisms that underlie parallel
                                                                      processing architecture of bimodal bilinguals. Therefore,
processing in bimodal bilinguals are unclear. Examination
                                                                      the finding that bimodal bilinguals coactivate their
of the time-course showed that at the moment of the onset of
                                                                      languages implies a system where top-down or lateral
the target word, competitor items were activated more than
                                                                      processes are capable of governing cross- linguistic
control items in the bilingual group. If the target word has
                                                                      activation.     Our results also indicate that language
yet to be presented in full, how is it possible that bilinguals
                                                                      information may be readily transmitted across modalities,
would show increased activation of competitor items? Prior
                                                                      such that two highly unrelated languages can be activated
to onset of the word, bilinguals view the display containing
                                                                      simultaneously. Thus, the language system should be
all four images for 600 ms. Bilinguals may automatically
                                                                      considered modality-independent and able to process
activate the corresponding semantic concepts due to visual
                                                                      linguistic information equally, regardless of whether it is
input. This activation can feed back ASL lexical levels and
                                                                      auditory or sensorimotor in nature.
activate phonologically similar lexical items.               The
                                                                          Moreover, there is reason to believe that a system of this
phonologically related items may then continually activate
                                                                      nature is not unique to bimodal bilinguals, and may provide
one another until target selection occurs.
                                                                      a window into more general language processing.
   The process of top-down activation of the non-target
                                                                      Unimodal bilinguals and monolinguals have shown robust
language in bimodal bilinguals can also be initiated by
                                                                      cross-modal effects as well (for a review, see Marian, 2009),
linguistic input. The initial semantic representation could be
                                                                      and semantic-competition effects from eye-tracking provide
activated by the incoming English target word, rather than
                                                                      evidence for rapid and highly robust lexical-semantic
by visual stimuli. When the semantic representation is
                                                                      interaction (Huettig & Altmann, 2005; Yee & Sedivy,
activated, it feeds back to the lexical representations in both
                                                                      2006). In addition, when bimodal bilinguals produce code-
English and ASL, thereby activating phonologically similar
                                                                      blends, they do so in the same fashion as unimodal
ASL signs and their corresponding semantic representations.
                                                                      bilinguals would code-switch, with the added benefit of
It is important to note that in this account, parallel activation
                                                                  794

being able to produce speech and signs in tandem,                Huettig, F., & Altmann, G. T. M. (2005). Word meaning
suggesting similarities in the underlying mechanisms of            and the control of eye fixation: semantic competitor
production for unimodal and bimodal bilinguals (Emmorey            effects and the visual world paradigm. Cognition, 96,
et al., 2008). It is possible that the top-down pathways           B23–B32.
utilized by bimodal bilinguals are present in unimodal           Levelt, W. J. M., Roelofs, A., & Meyer, A. S. (1999). A
bilinguals and monolinguals as well, but are overshadowed          theory of lexical access in speech production. Behavioral
by more immediate bottom-up effects.                               and Brain Sciences, 22, 1-75.
   The results of the current study indicate that bimodal
                                                                 Marian, V., Blumenfeld, H., & Kaushanskaya, M. (2007).
bilinguals activate both of their languages simultaneously
                                                                   The language experience and proficiency questionnaire
via a cross-linguistic lexical-semantic loop where top-down
                                                                   (LEAP-Q): Assessing language profiles in bilinguals and
information from the conceptual level feeds back to lower
                                                                   multilinguals. Journal of Speech, Language, and Hearing
levels of processing in both languages, regardless of
                                                                   Research, 50(4), 940-967.
modality. The results have further implications for the
architecture and processing dynamics of the language             Marian, V. & Spivey, M. (2003b). Competing activation in
system, bilingual and monolingual alike, suggesting that           bilingual language processing: Within- and between-
language information can be freely accessed across                 language competition.       Bilingualism: Language and
modalities, and that top-down mechanisms can have a                Cognition, 6(2), 97-115.
strong influence on language processing.                         McQueen, J. M., Jesse, A., & Norris, D. (2009). No lexical-
                                                                   prelexical feedback during speech perception or: Is it time
                   Acknowledgments                                 to stop playing those Christmas tapes? Journal of
                                                                   Memory and Language, 61(1), 1-18.
This research was funded in part by grants NICHD                 Navarette, E., & Costa, A. (2009). The naming of gender-
1R03HD046952 and NSF BCS-0418495 to the second                     marked pronouns supports interactivity in models of
author. The authors would like to acknowledge Dr.                  lexical access. Psicológica, 30, 301-321.
Margarita Kaushanskaya, Dr. Henrike Blumenfeld, Caroline         Norris, D. (1994). Shortlist: A connectionist model of
Engstler, Scott Schroeder, James Bartolotti, Michelle              continuous speech recognition. Cognition, 52(3), 189-
Masbaum, and Rucha Mehta for their contributions to this           234.
project.
                                                                 Rapp, B., & Goldrick, M. (2000). Discreteness and
                                                                   interactivity in spoken word production. Psychological
                                                                   Review, 107(3), 460-499.
References                                                       Van Hell, J. G., Ormel, E., van der Loop, J., & Hermans, D.
Blumenfeld, H., & Marian, V. (2007). Constraints on                (2009). Cross-language interaction in unimodal and
   parallel activation in bilingual spoken language                bimodal bilinguals. Paper presented at the 16th
   processing: Examining proficiency and lexical status            Conference of the European Society for Cognitive
   using eye-tracking. Language and Cognitive Processes,           Psychology. Cracow, Poland, September 2-5.
   22(5), 633-660.                                               Villwock, A., Wilkinson, E., Bailey, R., Kroll, J., Morford,
Brentari, D. (1998). A Prosodic Model of Sign Language             J., & Piñar, P. (2009). Cross-language lexical activation
   Phonology. MIT Press.                                           in deaf bilinguals: Does English print activate ASL signs?
Brysbaert, M., & New, B. (2009). Moving beyond Kucera              Presented at The International Symposium on
   and Francis: A critical evaluation of current word              Bilingualism 7. Utrecht, NL.
   frequency norms and the introduction of a new and             Weber, A., & Cutler, A. (2004). Lexical competition in non-
   improved word frequency measure for American English.           native spoken- word recognition. Journal of Memory and
   Behavioral Research Methods, 41(4), 977-990.                    Language, 50, 1-25.
Dunn, L. M. & Dunn, L. M. (1997). Peabody Picture                Yee, E. & Sedivy, J. (2006). Eye movements reveal
   Vocabulary Test, Third Edition. Circle Pine, MN:                transient semantic activation during spoken word
   American Guidance Service.                                      recognition. Journal of Experimental Psychology:
Emmorey, K., Borinstein, H.B., Thompson, R., & Gollan,             Learning, Memory and Cognition, 32, 1-14.
   T.H. (2008). Bimodal bilingualism.          Bilingualism:
   Language and Cognition, 11(1), 43-61.
Emmorey, K., Luk, G., Pyers, J. E., & Bialystok, E. (2008).
   The source of enhanced cognitive control in bilinguals:
   Evidence from bimodal bilinguals.          Psychological
   Science, 19(12), 1201-1206.
Hagoort, P., & Levelt, W. J. M. (2009). The speaking brain.
   Science, 326(5951), 372-373.
                                                             795

