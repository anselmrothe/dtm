UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual and Task characteristics may explain hemispheric asymmetry in visual word
recognition
Permalink
https://escholarship.org/uc/item/0tm6w1z6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Cheung, Kloser Chee Fung
Hsiao, Janet Hui-wen
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                  Visual and Task characteristics may explain
                             hemispheric asymmetry in visual word recognition
                                          Kloser Chee Fung Cheung (kloser@hku.hk)
                                             Janet Hui-wen Hsiao (jhsiao@hku.hk)
                                         Department of Psychology, University of Hong Kong
                                       604 Knowles Building, Pokfulam Road, Hong Kong SAR
                             Abstract                                    Nevertheless, this claim has been challenged by at least
                                                                      one counter example, that is, the recognition of Chinese
   Previous studies proposed that the left hemisphere (LH)
   lateralization in English word recognition is because of the       characters. In contrast to the RVF/LH advantage in the
   LH superiority in language processing. Nevertheless, Chinese       recognition of English words, the recognition of Chinese
   character recognition has been shown to be more bilateral or       characters, a logographic writing system, has been shown to
   right hemisphere (RH) lateralized and thus is a counter            have a left visual field/right hemisphere (LVF/RH)
   example of this claim. Through computational modeling, here        advantage in orthographic processing, demonstrated in
   we show that at least two factors other than language              tachistoscopic recognition tasks (e.g., Tzeng et al., 1979;
   lateralization may influence hemispheric asymmetry in visual
   word recognition: (1) Visual similarity among words, which
                                                                      Cheng & Yang, 1989). In addition, Hsiao and Cottrell (2009)
   can be influenced by the ratio between the alphabet size and       showed a left side bias effect in Chinese character
   the lexicon size and the visual similarity among letters: We       perception in Chinese readers (experts), but not in non-
   show that the more similar the words are in the lexicon, the       Chinese readers (novices). This left side bias effect also
   more high spatial frequency (HSF) information is required to       suggests the RH involvement in Chinese character
   distinguish them, and this leads to more LH lateralization (2)     processing.
   The requirement to decompose a word into letters in order to          As for phonological processing in Chinese character
   map them to corresponding phonemes in pronunciation: We
   show that letter identity mapping requires more HSF                recognition, Weekes and Zhang (1999) reported
   information than word identity mapping, and alphabetic             phonological priming effects on the recognition of phonetic
   reading requires more HSF information than logographic             compounds (i.e. characters with a phonetic radical that has
   reading; this leads to more LH lateralization in alphabetic        information about character pronunciation) when the
   languages. These two visual and task characteristic factors        characters were presented in the RVF/LH but not in the
   alone may explain differences in lateralization between            LVF/RH; this effect was not observed in integrated
   English word and Chinese character recognition, without
                                                                      characters (i.e. characters that do not have a phonetic radical;
   assuming the influence from language lateralization.
                                                                      Weekes, Chen, & Lin, 1998). Thus, research on Chinese
   Keywords: visual word recognition, hemispheric asymmetry,          character recognition has exhibited a LVF/RH advantage for
   computational modeling                                             orthographic processing, and a RVF/LH advantage for
                                                                      phonological processing, especially for phonetic compounds.
                          Introduction                                ERP and fMRI studies of Chinese character recognition
                                                                      have also shown a more bilateral or RH-lateralized
Lateralization in visual word recognition                             activation in the visual system than those of English word
                                                                      recognition (e.g., Tan et al., 2000; Liu & Perfetti, 2003),
Words, which surround us ever since our childhood, have               which is consistent with the behavioral data.
been extensively studied in the research on visual                       The RH advantage in Chinese character recognition has
recognition. Previous studies have consistently shown a left          been argued to reflect the RH superiority in handling
hemisphere (LH) lateralization effect in visual word                  holistic pattern recognition (Tzeng et al., 1979).
recognition in alphabetic languages such as English. A                Nevertheless, findings in later studies do not support this
classical right visual field (RVF)/LH advantage in reading            claim. For example, Cheng and Yang (1989) showed no
English words (or words in alphabetic languages) has been             laterality effect in the recognition of non-characters and
demonstrated first in tachistoscopic recognition (e.g.,               pseudo-characters, suggesting that this RH advantage may
Bryden & Rainey, 1963) and consistently reported in other             be related to lexical knowledge of Chinese characters or
word recognition tasks, such as word naming (Brysbaert &              learning experience. Also, in contrast to Tzeng et al.‟s claim,
d‟Ydewalle, 1990) and lexical decision tasks (Faust,                  Hsiao and Cottrell (2009) showed a reduced holistic
Babkoff, & Kravetz, 1995). Data from fMRI studies have                processing effect in Chinese readers compared with non-
shown a region inside the left fusiform area (Visual Word             Chinese readers. Thus, it remains unclear why Chinese
Form Area, VWFA) responding selectively to words (e.g.,               character recognition and English word recognition involve
McCandliss, Cohen, & Dehaene, 2003). ERP studies also                 different hemisphere lateralization.
show that words elicit a larger N170 in the LH than strings
of symbols (e.g., Maurer, Brandeis, & Dehaene, 2005). This            Hemispheric processing model
RVF/LH advantage in visual word recognition in alphabetic
languages has been argued to be because of the LH                     In order to investigate why Chinese character and English
lateralization in language processing (e.g., Voyer, 1996).            word      recognition     involve     different   hemispheric
                                                                  1441

lateralization, here we adopt a computational approach,
aiming to examine potential factors that may influence
hemispheric asymmetry in visual word recognition, since
computational modeling approaches enable us to have better
control over variables.
   Anatomical evidence shows that our visual field is
initially split along the vertical midline, and the two visual
hemifields are initially contralaterally projected to different
hemispheres. In order to examine at which processing stage
this split information converges, Hsiao, Shieh, and Cottrell
(2008) conducted a hemispheric modeling study of face
recognition, aiming to account for the left side bias effect in
face perception. They proposed three models with different                 Figure 2: Hsiao et al.‟s hemispheric processing
timing of convergence: early, intermediate and late                        model (2008)
convergence models (Figure 1). They showed that both the
intermediate and late convergence models are able to
account for the left side bias effect in face perception,           Visual and task characteristics of a writing system
whereas the early convergence model fails to show the               Here we test the hypothesis that differences in visual and
effect.                                                             task characteristics of a writing system alone are able to
   Hsiao et al.‟s hemispheric processing model (2008)               account for differences in hemispheric lateralization in
incorporates several known observations about visual                visual word recognition in different languages. We
anatomy and neural computation: Gabor responses are used            hypothesize that at least two factors other than language
over the input images to simulate neural responses of cells         lateralization may influence hemispheric lateralization in
in the early visual system (Lades et al., 1993); Principal          visual word recognition:
Component Analysis (PCA), a biologically plausible linear
compression technique (Sanger, 1989), is used to simulate           (1) Visual similarity among words in the lexicon:
possible information extraction processes beyond the early          The more similar the words look visually in the lexicon, the
visual system. This PCA representation then is used as the          more high spatial frequency (HSF) information is required
input to a two-layer neural network (Figure 2).                     to recognize them; this leads to more LH lateralization. We
   In addition, the model implements a theory of                    hypothesize that at least two factors may influence visual
hemispheric asymmetry in perception, Double Filtering by            similarity among words in the lexicon:
Frequency theory (DFF, Ivry & Robertson, 1998). The DFF             (i) Number of letters shared among words in the lexicon:
theory argues that information coming into the brain goes           The more letters are shared among words in the lexicon, the
through two frequency filtering stages: The first stage             more similar the words look visually in the lexicon. This
involves attentional selection of a task-relevant frequency         factor is influenced by the ratio between the alphabet size
range. At the second stage, the LH amplifies high frequency         (i.e. the number of letters in the alphabet) and the lexicon
information, while the RH amplifies low frequency                   size (i.e. the number of words in the lexicon); that is, given a
information. This differential frequency bias in the two            fixed lexicon size, the smaller the alphabet size is, the more
hemispheres is implemented in the model by using two                number of letters may be shared among the words in the
sigmoid weighting functions to assign different weights to          lexicon, and thus the more similar the words look visually in
the Gabor responses in the two hemispheres (Figure 2).              the lexicon.
   Here we apply Hsiao et al.‟s hemispheric processing              (ii) Similarity among letters in the alphabet: The more
model (2008) to the modeling of visual word recognition, in         similar the letters in the alphabet look visually, the more
order to examine whether visual and task characteristics            similar the words look visually in the lexicon. This factor
alone are able to account for the differences in hemispheric        may be influenced by the number of letters in the alphabet;
lateralization in different languages, without assuming the         that is, given a fixed representational space for all possible
influence of language processing being LH-lateralized. We           letters, when we gradually increase the number of letters in
introduce our hypothesis below.                                     the alphabet, it becomes more likely that some letters will
                                                                    look similar to each other (i.e. closer to each other in the
                                                                    space).
                                                                       According to these two factors, we predict that with a
                                                                    fixed lexicon size, when we gradually increase the alphabet
                                                                    size, the model will first exhibit more and more low spatial
                                                                    frequency (LSF) reliance since the words will share fewer
                                                                    and fewer common letters (factor (i)); when the letters in the
                                                                    alphabet start to look visually similar to each other because
      Figure 1: Hemispheric models with different
                                                                    of the alphabet size increase, the model will start to exhibit
      timing of convergence (Hsiao et al., 2008)
                                                                    reduced LSF reliance (factor (ii)). In other words, we expect
                                                                1442

that there will be an inverted-U-shaped curve in LSF                  condition.
reliance/RH lateralization in the model when we gradually
increase the alphabet size given a fixed lexicon size.
(2) The requirement to decompose a word into
letters in order to map them into corresponding
phonemes in pronunciation
Maurer and McCandliss (2007) proposed the phonological
mapping hypothesis to account for the difference in ERP
N170 lateralization between faces and words: N170 has
been found to be larger in the RH compared with the LH in
face recognition, whereas in the recognition of English
words, it has been found to be larger in the LH compared
with the RH. They argued that given phonological processes
                                                                            Figure 3: Images used in the current study: (a)
are typically left-lateralized (e.g., Price et al., 1997; Rumsey
                                                                            palindrome English pseudo-words; (b) Korean
et al., 1997), specialized processing of visual words in
                                                                            pseudo-characters (from left to right, vertical
visual brain areas also becomes left-lateralized. Accordingly,
                                                                            structure, top heavy structure, and bottom heavy
the LH lateralization of N170 may be specifically related to
                                                                            structure); (c) & (d) Left and right damaged
the influence of grapheme-phoneme conversion established
                                                                            images of the English pseudo-words and the
during learning to read. According to this hypothesis, this
                                                                            Korean pseudo-characters
phonological modulation should be less pronounced in
logographic scripts such Chinese (Maurer & McCandliss,
2007).                                                                            Modeling Method and Results
   In contrast to the phonological mapping hypothesis, here           To test our hypotheses, we applied the intermediate
we hypothesize that the LH lateralization in English word             convergence model proposed by Hsiao et al. (2008) to
recognition is due to the requirement to decompose a word             visual word recognition. In the model, the input word
into letters, without assuming phonological processes being           images were first filtered with a rigid grid of overlapping
left-lateralized. We test this hypothesis through two                 2D Gabor filters (Daugman, 1985) to obtain Gabor
simulations. In the first simulation, we contrast two                 responses. At each grid, we used Gabor filters of eight
mapping tasks using the same stimuli: word identity                   orientations and a fixed number of scales. The number of
mapping and letter identity mapping. In the word identity             scales used depended on the task-relevant frequency range,
mapping task, the model learns to distinguish different               which was determined according to the smaller dimension
words, whereas in the letter identity mapping task, the               of the images; the highest frequency scale did not exceed
model learns to identify the constituent letter in each letter        the smaller dimension of the images (following Hsiao et al.,
position of an input word. We expect that the letter identity         2008). In the current simulation, the dimensions of the two
mapping task will require more HSF information (i.e. LH               types of images used were 35 x 100 for the English pseudo-
lateralization) compared with the word identity mapping               words and 70 x 80 for the Korean pseudo-characters (see
task1.                                                                Figure 3); thus the number of scales for English pseudo-
   In the second simulation, instead of mapping word image            word images was five (25 = 32 < 35, and 26 = 64 > 35) and
input to either word or letter identities, we model visual            that for Korean pseudo-character images was six (26 = 64 <
word recognition more realistically by mapping them to                70, and 27 = 128 > 70). We applied the Gabor filters to a
pronunciations. We use an artificial lexicon with Korean-             5x18 grid of points on each English pseudo-word image,
character-like pseudo-characters as the orthography. Two              and to a 12x14 grid of points on each Korean pseudo-
pronunciation conditions are created: in the alphabetic               character image. So each English pseudo-word image was
reading condition, each component (letter) of a character             transformed into a vector of size 3600 (5x18 sample points
maps to a consonant or vowel in pronunciation                         x 8 orientation x 5 scales) while each Korean pseudo-
systematically, whereas in the logographic reading condition,         character image was transformed into a vectors of size 8064
each character maps to a pronunciation randomly without a             (12x14 sample points x 8 orientations x 6 scales).
systematic      relationship     between its orthographic                After obtaining the Gabor magnitudes, two conditions
components (letters) and the phonemes in pronunciation.               were created: the baseline condition and the biased
We expect that the alphabetic reading condition will require          condition. In the baseline condition (the control condition),
more HSF information (i.e. more LH lateralization)                    Gabor responses in different scales were given equal
compared          with       the       logographic        reading     weights (i.e. no frequency bias), while in the biased
                                                                      condition, we implemented the second stage of the DFF
                                                                      theory by using a sigmoidal weighting function to bias the
   1
     Note that we reported some pilot data in Hsiao & Cottrell        Gabor responses on the left half word (RH) to LSFs, and
(2009b). Compared with Hsiao & Cottrell (2009b), here we have         those on the right half word (LH) to HSFs (Figure 2). The
revised the hypotheses and modeling methods, and presented            perceptual representation of each of the left and right half
brand-new and more complete simulations.
                                                                  1443

words was compressed by PCA into a 50-element                        lateralization changed when we gradually increased the
representation each (100 elements in total, following Hsiao          alphabet size.
et al., 2008) 2. This PCA representation then was used as the           In the datasets, we used 8 different fonts for each word,
input to a two layer neural network, as shown in Figure 2            with 4 of them used as the training data, and the other 4
(see Hsiao et al., 2008, for more simulation details).               used as the testing data (counterbalanced across the
   We trained our neural network model to recognize the              simulations). Thus, in both the training and testing datasets,
input images until the performance on the training set               each word had 4 images of different fonts.
reached 100% accuracy. The training algorithm was
gradient descent with an adaptive learning rate. To test
hemispheric asymmetry effects, in contrast to the previous
hemispheric models of face and word recognition (e.g.,
Hsiao et al., 2008, Hsiao & Cottrell, 2009b), here we did not
use “chimeric images” (Figure 3(a) & (b)) as a way to give
noise to one side of the stimulus in order to test the model‟s
reliance on either the left or right half of the representation.
A potential problem in using this kind of chimeric images
for words is some letters may have a similar shape as their
mirror images (such as „o‟ and „m‟ in the English alphabet),
while others do not; thus these letters will give non-uniform
noise distribution over the mirror-image sides of the
chimeric words. Here we avoided this problem by using
                                                                            Figure 4: RH/LSF preference in the models trained
damaged images (Figure 3(c) & (d).) It was made by setting
                                                                            with lexicons with different alphabet sizes in the
one half of the PCA representation to zero, so that when
                                                                            word identity mapping task (*p<0.01; **p<0.001;
mapping these damaged images to their identities, only one
                                                                            ***p<<0.001).
of the visual hemifields was used for recognition. The left
side bias effect thus was measured as the difference between
                                                                        The results are shown in Figure 4. The RH/LSF
the accuracy of recognizing a right-side-damaged word
                                                                     preference was defined as the difference in the left side bias
(carrying LSF/RH information only) as the original word
                                                                     effect between the biased condition and the baseline
and the accuracy of recognizing a left-side-damaged word
                                                                     condition; it reflected how much the model preferred the
(carrying HSF/LH information only) as the original word.
                                                                     RH/LSF-biased representation over the LH/HSF-biased
                                                                     representation compared with the control condition when no
Visual similarity among words in the lexicon:
                                                                     frequency bias was applied (Hsiao et al., 2008). As shown in
We first used images of six-letter English pseudo-words to           Figure 4, when the alphabet size was small (e.g., „a‟ to „c‟),
examine how visual similarity among words in the lexicon             the model had low RH/LSF preference. When we increased
influences lateralization in visual word recognition. To             the alphabetic size, the RH/LSF preferences became
counterbalance the information carried in the two visual             stronger, and then decreased after the peak at around „a-g‟
fields, we used palindrome pseudo-words as the stimuli (e.g.,        (i.e., an inverted-U shape in Figure 4).
Figure 3(a)). We created artificial lexicons with an                    Thus, the results showed that, when gradually increasing
increasing alphabet size (a-c, a-e, a-g…), and trained the           the alphabetic size of the lexicon, the visual similarity
model to learn each lexicon 50 times. In each of the 50              among words decreased, and the model relied more on LSFs
simulations, 26 palindrome words were chosen randomly                to distinguish the words. But when the alphabetic size kept
from all possible combinations of letters in the alphabet to         increasing, more and more letters with similar shapes were
form the artificial lexicon. In the model, each output node          used in the alphabet (e.g., „c‟ and „o‟, „b‟ and „h‟, „m‟ and
corresponded to a word identity.                                     „n‟), and the visual similarity among words in the lexicon
   In the first lexicon with letters from „a‟ to „c‟, there were     increased; as the result, the model required more HSFs to
27 possible combinations: aaaaaa, aabbaa, aaccaa, abaaba,            distinguish the words.
abbbba… The randomly chosen 26 words thus looked very
similar to one another. When we increased the alphabet size          The requirement to decompose a word into letters
to include „a‟ to „e‟, the number of combinations became
                                                                     When reading words in alphabetic languages, the readers
125, and the randomly chosen 26 words became more
                                                                     have to decompose the visual input of a word into its
dissimilar visually to one another (i.e. the similarity among
                                                                     constituent letters/graphemes and map them to the
words decreased). In other words, the larger the alphabet
                                                                     corresponding phonemes. This decomposition may require
size was, the lower the visual similarities among words in
                                                                     details of the word image and thus rely more on the HSF
the lexicon were. Here we examined how the model‟s
                                                                     information. Here we examined lateralization effects in a
                                                                     letter identity mapping task using the English pseudo-words.
   2                                                                 Instead of learning to map word images to word identities,
     In a separate simulation, we found that using 100 components
                                                                     the model was trained to map a word image to its
each made the representation noisier and deteriorated the model‟s
performance.                                                         constituent letter identities. The output layer of the model
                                                                 1444

was divided into 3 parts corresponding to the first 3 letter         Figure 7 shows the results. As shown in the figure, the
positions in a word (the end 3 letters were the same as the       RH/LSF preference in the logographic reading condition
first 3 since they were palindrome words). The number of          was always stronger than that in the alphabetic reading
nodes in each part was equal to the alphabetic size (see          condition. This result suggests logographic reading requires
Figure 5).                                                        more LSF information compared with alphabetic reading,
                                                                  and is consistent with the visual word recognition literature
                                                                  showing a more RH lateralization in reading logographic
                                                                  languages such as Chinese compared with alphabetic
                                                                  languages such as English.
   Figure 5: Output layers of the letter-position identity
   mapping task (Hsiao & Cottrell, 2009b).
                                                                        Figure 7: RH/LSF preference in the Korean
                                                                        pseudo-character       reading    task    (*p<0.01;
                                                                        **p<0.001; ***p<<0.001).
      Figure 6: RH/LSF preference in the letter identity
      mapping task (in red) in the models trained with                           Conclusion and Discussion
      lexicons of different alphabet sizes, compared with         Visual word recognition in alphabetic languages such as
      the word identity mapping task (in blue; *p<0.01;           English has been reported to be LH lateralized, and argued
      **p<0.001; ***p<<0.001).                                    to be due to the LH lateralization of language processes.
                                                                  Nevertheless, a RH/LVF advantage has been reported in
   Figure 6 shows the results. The results showed that            orthographic processing of Chinese character recognition. In
compared with the word identity mapping task, the letter          this study, by applying the hemispheric processing model
identity mapping task required more LH/ HSF information.          (Hsiao et al., 2008) to visual word recognition, we examined
In addition, in the letter identity task, as the alphabet size    whether visual and task characteristics alone are able to
increased, the model relied more on LH/HSF information.           account for differences in hemispheric lateralization in
   In another simulation, we used artificial lexicons with        different languages without assuming the influence from
Korean-character-like pseudo-characters to examine                language processing being LH-lateralized.
hemispheric asymmetry effects in recognizing square-shape            We first showed that visual similarity among words in the
characters, and more importantly, to examine hemispheric          lexicon can influence lateralization in visual word
processing difference between logographic and alphabetic          recognition. We used artificial lexicons with the same
language reading. In this examination, we modeled visual          number of words and word length, but with different
word recognition more realistically by mapping each word          alphabetic sizes, and trained the model to map word image
input into its pronunciation with a consonant-vowel-              input to their word identities. The results showed an
consonant structure.                                              inverted- U -pattern (Figure 4): When the alphabet size
   In the datasets, there were also 8 different fonts for each    increases, the model initially relies more and more on the
Korean-character-like pseudo-character. Each character            RH/LSF information, because words in the lexicon share
consisted of three Korean-alphabet-like letters, arranging in     fewer and fewer common letters and the visual similarity
three different structures: vertical, top-heavy, and bottom-      among words in the lexicon decreases. Nevertheless, with
heavy (Figure 3(b)). The frequency of each letter appearing       further increase of the alphabet size, the model‟s RH/LSF
in either side of the characters in the lexicon was balanced.     reliance starts to decrease, because of the increase of visual
In the alphabetic reading condition, each letter                  similarity among letters in the alphabet.
systematically mapped to either a vowel or a consonant in            We then showed that the requirement to decompose a
pronunciation, whereas in the logographic reading condition,      word in to its constituent letters can also influence
each character mapped to a randomly assigned                      lateralization in visual word recognition. We used the same
pronunciation without a systematic letter-phoneme mapping.        artificial lexicons but trained the model to perform a letter-
                                                                  identity mapping task instead of the word identity mapping
                                                              1445

task. The results showed that decomposition of words into         Hsiao, J. H. & Cottrell, G. W. (2009). Not all expertise is
letters requires more HSF information and thus results in              holistic, but it may be leftist: The case of Chinese
more LH lateralization. In addition, we used Korean                    character recognition. Psychological Science.
pseudo-characters to examine lateralization differences           Hsiao, J. H. & Cottrell, G. W. (2009b). What is the cause of
between logographical reading and alphabetic reading. The              left hemisphere lateralization of English visual word
results showed that logographical reading requires more                recognition? Pre-existing language lateralization, or
LSF information compared with alphabetic reading, and                  task characteristics? Proceedings of the Thirty-First
thus results in more RH-lateralization.                                Annual Conference of the Cognitive Science Society.
   The two factors related to visual and task characteristics     Hsiao, J. H., Shieh, D., & Cottrell, G. W. (2008).
of a writing system we proposed here are able to account for           Convergence of the visual filed split: hemispheric
the lateralization differences between English word and                modeling of face and object recognition. Journal of
Chinese character recognition. Compared with Chinese,                  Cognitive Neuroscience, 20(12), 2298-2307.
words in the English lexicon may look more similar to one         Ivry, R. & Robertson, L. C. (1998). The Two Sides of
other, because of the smaller alphabet size (only 26 letters)          Perception. Cambridge: MIT Press.
and a much larger lexicon size (more than 20,000 words). In       Lades, M., Vorbruggen, J. C., Buhmann, J., Lange, J., von
contrast, Chinese has a smaller lexicon size (about 4500               der Malsburg, C., Wurtz, R. P., & Konen, W. (1993).
characters for a native speaker), but a much larger                    Distortion invariant object recognition in the dynamic
“alphabet” (i.e., more than 1000 stroke patterns). In addition,        link architecture. IEEE Transaction on Computers, 42,
English is an alphabetic language whereas Chinese is a                 300-311.
logographic language. Chinese logographic reading may             Liu, Y. & Perfetti, C. A. (2003). The Time course of brain
require more LSF information that leads to more RH-                    activity in reading English and Chinese: An ERP study
lateralization compared with English alphabetic reading,               of Chinese bilinguals. Human Brain Mapping, 18, 167-
since logographic reading does not require a decomposition             175.
of words into letters in order to map them to corresponding       Maurer U., Brandeis, D., & McCandliss, B. (2005). Fast,
phonemes.                                                              visual specialization for reading in English revealed by
   In summary, here we show that visual and task                       the topography of the N170 ERP response. Behavioral
characteristics of a writing system alone may account for              & Brain Functions, 1(1), 13.
lateralization differences in visual word recognition in          Maurer U., & McCandliss, D. (2007). The Development of
different languages. Specifically, they are (1) visual                 visual experticse for words: the contribution of
similarity among words in the lexicon, and (2) the                     electrophysiology. In E.L. Grigorenke & A. Naples
requirement to decompose a word into letters for performing            (Eds.). Single-Word Reading: Cognitive, behavioral
grapheme-phoneme conversion during learning to read.                   and biological perspectives. Mahwah, NJ: Lawrence
                                                                       Erlbaum Associates.
                   Acknowledgement                                McCandliss, B. D., Cohen, L., & Dehaene, S. (2003). The
We are grateful to the HKU Seed Funding Program for                    visual word form area: expertise for reading in the
Basic Research(project #10400471 to J.H. Hsiao) and the                fusiform gyrus. Trends in Cognitive Sciences, 7, 293-
Research Grant Council of Hong Kong (project code: HKU                 299.
744509H to J.H. Hsiao).                                           Sanger, T. (1989). An optimality principle for unsupervised
                                                                       learning. In Touretzky, D. (ed) Advances in Neural
                                                                       Information Processing Systems, vol. 1, pp. 11-19, San
                         References                                    Mateo: Morgan Kaufmann.
Bryden, M. P. & Rainey, C. A. (1963). Left-right                  Tan, L. H., Spinks, J. A., Gao, J. H., Liu, H. L., Perfetti, C.
      differences in tachistoscopic recognition. Journal of            A., Xiong, J., et al. (2000). Brain activation in the
      Experimental Psychology, 66, 568-571.                            processing of Chinese characters and words: A
Brysbaert, M. & d‟Ydewalle, G. (1990). Tachistoscopic                  functional MRI study. Human Brain Mapping, 10, 16-
      presentation of verbal stimuli for assessing cerebral            27.
      dominance: Reliability data and some practical              Tzeng, O. J. L., Hung, D. L., Cotton, B., & Wang, S. Y.
      recommendation. Neuropsychologia, 28, 443-455.                   (1979). Visual lateralization effect in reading Chinese
Cheng, C. M. & Yang, M. J. (1989). Lateralization in the               characters. Nature (London), 282, 499-501.
      visual perception of Chinese characters and words.          Voyer, D. (1996). On the magnitude of laterality effects and
      Brain and Language, 36, 669-689.                                 sex differences in functional literalities. Laterality, 1,
Daugman, J. G. (1985). Uncertainty relation for resolution             51-83.
      in space, spatial frequency, and orientation optimized      Weekes, B. S. & Zhang, B. Y. (1999). Chinese character
      by two dimensional visual cortical filters. Journal of           recognition in the left and right visual fields. Brain &
      the Optical Society of America A, 2, 1160-1169.                  Cognition, 40, 269-272.
Faust, M., Babkoff, H., & Kravetz, S. (1995). Linguistic          Weekes, B. S., Chen, M. J., & Lin, Y. B., (1998).
      process in the two cerebral hemispheres: Implications            Orthographic Phonological and semantic priming of
      for modularity vs. interactionism. Journal of Clinical           Chinese character recognition. Reading and Writing,
      and Experimental Neuropsychology, 17, 171-192.                   10 (3-5), 201-222.
                                                              1446

