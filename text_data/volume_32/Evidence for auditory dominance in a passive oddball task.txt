UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Evidence for auditory dominance in a passive oddball task
Permalink
https://escholarship.org/uc/item/9gg173d6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Robinson, Chris
Ahmar, Nayef
Sloutsky, Vladimir
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   Evidence for auditory dominance in a passive oddball task
                                     Christopher W. Robinson (robinson.777@osu.edu)
                                                       Center for Cognitive Science
                                                         The Ohio State University
                                           208F Ohio Stadium East, 1961 Tuttle Park Place
                                                       Columbus, OH 43210, USA
                                                 Nayef Ahmar (ahmar.1@osu.edu)
                                                       Center for Cognitive Science
                                                         The Ohio State University
                                           208F Ohio Stadium East, 1961 Tuttle Park Place
                                                       Columbus, OH 43210, USA
                                         Vladimir M. Sloutsky (sloutsky.1@osu.edu)
                                                       Center for Cognitive Science
                                                         The Ohio State University
                                           208C Ohio Stadium East, 1961 Tuttle Park Place
                                                       Columbus, OH 43210, USA
                            Abstract                                        information to one sensory modality interferes with
                                                                            learning in a second modality. These modality
  Simultaneous presentation of auditory and visual input can
  often lead to visual dominance. Most studies supporting                   dominance effects can occur on detection tasks and
  visual dominance often require participants to make an                    on more complex discrimination tasks, with auditory
  explicit response, therefore, it is unclear if visual input disrupt       input often attenuating visual processing in young
  encoding/discrimination of auditory input or results in a                 children (Sloutsky & Napolitano, 2003; Robinson &
  response bias. The current study begins to address this issue             Sloutsky, 2004) and visual input often attenuating
  by examining how multimodal presentation affects                          auditory processing in adults (Colavita, 1974;
  discrimination of auditory and visual stimuli, while using a              Colavita & Weisberg, 1979).
  passive oddball task that does not require an explicit response.             Support for visual dominance in adults comes from
  Participants in the current study ably discriminated auditory
                                                                            a long history of research examining how multimodal
  and visual stimuli in all unimodal and multimodal conditions.
  Furthermore, there was no evidence that visual stimuli                    stimuli affect the detection of auditory and visual
  attenuated auditory processing. Rather, multimodal                        input (Colavita, 1974; Colavita & Weisberg, 1979;
  presentation sped up auditory processing (shorter latency of              Klein, 1977; Posner, Nissen, & Klein, 1976; see also
  P300) and slowed down visual processing (longer latency of                Sinnett, Spence, & Soto-Faraco, 2007; Spence,
  P300). These findings are consistent with research examining              Shore, & Klein, 2001, for reviews). For example, in a
  modality dominance in young children and suggest that visual              classic study Colavita (1974) presented adults with a
  dominance effects may be restricted to tasks that require an              tone, a light, or the tone and light paired together.
  explicit response.                                                        Participants had to press one button when they heard
                                                                            the tone and a different button when they saw the
  Keywords:         Attention,        Cross-modal         Processing,
  Electroencephalograph (EEG), Neurophysiology, Psychology.                 light. While participants were accurate when the tone
                                                                            and light were presented unimodally, they often
                        Introduction                                        responded to the visual stimulus when the stimuli
                                                                            were paired together, with many adults failing to
Most of our experiences are multimodal in nature. The                       detect the auditory stimulus. This finding has been
objects and events that we encounter in the environment                     replicated using a variety of stimuli and procedures,
can be seen, touched, heard, and smelled. The fact that                     with little evidence demonstrating that auditory input
the brain can integrate this knowledge into a coherent                      attenuates visual processing in adults (see Sinnett,
experience is amazing given that each modality                              Spence, & Soto-Faraco, 2007 for a review).
simultaneously receives different types of input, and this                     There appears to be an attentional component
information is processed, at least in the early stages of                   underlying visual dominance (Posner, Nissen, &
processing, by dedicated sensory systems.                                   Klein, 1976). In particular, the underlying idea is that
  While multimodal presentation can sometimes facilitate                    the auditory and visual modalities share the same
learning, there are many occasions when presenting                          pool of attentional resources. While auditory stimuli
                                                                      2644

automatically engage attention, visual stimuli often have         (Mertens & Polich, 1997; Wronka, Kaiser, &
poor alerting abilities. To compensate for the poor               Coenen, 2008).
alerting ability of visual input, adults endogenously direct         Thus, to the best of our knowledge this is the first
attention to visual stimuli. This increased attention to the      study to use a passive oddball task to examine how
visual modality comes with a cost – attenuated auditory           multimodal presentation affects auditory and visual
processing.                                                       processing. If visual stimuli interfere with the
   While there is much support for visual dominance, it is        encoding and/or discrimination of auditory stimuli,
important to note that this support primarily comes from          then the latency of P300 should occur later in the
studies examining response latencies and response                 multimodal condition than in the unimodal condition.
accuracies. Therefore, it is possible that visual input have      However, if visual stimuli only affect the response,
no effect on encoding or discrimination of auditory               then no effects should be found or auditory input may
stimuli. Rather, these effects may stem solely from visual        attenuate visual processing (auditory dominance).
input dominating the response. The current study begins
to address this issue by examining processing of auditory,                              Methods
visual, and multimodal stimuli in a task that does not
require an explicit response.                                     Participants
   Participants in the current study were presented with a        Thirty-nine undergraduate students from The Ohio
passive oddball task where they were presented with               State University (23 men and 16 women, M = 19.5
auditory, visual, or multimodal stimuli. Event Related            years, SD = 3.9 years) participated in this experiment
Potentials (ERPs) were recorded as adults passively               for course credit. Prior to the experiment all
attended to frequent stimuli (standard) and infrequent            participants gave informed consent and provided
stimuli (oddballs). The signature pattern of discrimination       basic personal information (handedness, age, medical
is a P300. P300 is a positive component with a peak               history). All participants had normal hearing and
latency occurring between 300-800 ms after stimulus               normal (or corrected to normal) vision.
onset and is strongest over the temporal, parietal, and
fronto-central regions (see Polich & Criado, 2006 for a
review). The amplitude of P300 is larger for novel or
                                                                  Stimuli
infrequent stimuli (Sutton, Braren, Zubin, & John, 1965),         The stimuli and cover story were designed for young
and the latency of P300 can be used as a measure of               children. The visual stimuli consisted of six novel
processing time (Kutas, McCarthy, & Donchin, 1977). In            creatures that were created in PowerPoint and
particular, experimental manipulations that affect the            exported as 400 x 400 pixel jpeg images (see Figure
processing leading up to classification and responding            1 for examples).
should affect the latency of P300. The same underlying
idea is guiding the current research: multimodal                                         AUD2
                                                                                              **     **
                                                                                                        AUD2
facilitation and interference should manifest themselves
by affecting the latency (and possibly amplitude) of P300.                       *                    *  AUD1
   Previous studies have used oddball tasks to examine                                    AUD1
unimodal and multimodal processing and to examine
effects of response on ERP components. However, these
                                                                                           AUD1           AUD1
procedures differed from the ones reported here in several
important ways. First, ERP studies that have directly
                                                                        Time
compared unimodal and multimodal conditions either                                          AUD1             AUD1
focused on early ERP components associated with
stimulus detection or they required participants to make a
                                                                               Unimodal     Unimodal    Multimodal
response to oddballs (e.g., Brown, Clarke, & Barry, 2007;                        Visual     Auditory
Fort, Delpuech, Pernier, & Giard, 2002; Giard &
Peronnet, 1999; Vidal, Giard, Roux, Barthelemy, &                 Figure 1: Example of stimuli and overview of the
Bruneau, 2008). In contrast, the current study focused            visual, auditory, and multimodal conditions. Note:
exclusively on discrimination of standards and oddballs           “*” denotes visual oddball and “**” denotes auditory
(P300), and participants did not make an explicit response        oddball.
to these stimuli. Second, the studies that have examined
the effects of explicit response on oddball tasks were not           Visual stimuli were presented centrally on a Dell
interested in modality dominance, thus, they did not              17” LCD monitor for 480 ms. The interstimulus
examine discrimination of the same auditory and visual            interval (ISI) randomly varied from 1000 ms - 1520
stimuli when presented unimodally and multimodally                ms. Auditory stimuli were also 480 ms in duration,
                                                                  with a 1000 ms - 1520 ms ISI. The auditory stimuli
                                                             2645

were dynamic sounds that changed in pitch and amplitude          the other creatures. In the auditory condition they
across time. The sounds were created in CoolEdit 2000 by         were told that they would hear the sounds of
using preset functions (e.g., DTMF signal, out of control,       creatures eating vegetables and cookies, and in the
etc.). Stimuli in the multimodal condition were                  multimodal condition they were told that they would
constructed by pairing the auditory and visual stimuli           see creatures and hear the sounds that they make
together (see Figure 1 and Table 1). Thus, the same              while eating vegetables and cookies.
stimuli were used in the unimodal and multimodal
conditions, therefore, any differences found between these                         Unimodal     Unimodal    Multimodal
conditions cannot be accounted for by properties of the                            Auditory       Visual
                                                                     Standard      A1 (280)      V1 (280)   A1V1 (560)
unimodal stimuli.
                                                                   Oddballs (A)     A2 (16)                  A2V1 (16)
Procedure                                                                           A3 (16)                  A3V1 (16)
                                                                                    A4 (16)                  A4V1 (16)
Three different oddball tasks were used (see Figure 1 and                           A5 (16)                  A5V1 (16)
Table 1), and task order was pseudo-randomized for each            Oddballs (V)                  V2 (16)     A1V2 (16)
participant. Approximately half of the participants were                                         V3 (16)     A1V3 (16)
presented with the unimodal oddball tasks (order of                                              V4 (16)     A1V4 (16)
auditory and visual was randomized for each participant),                                        V5 (16)     A1V5 (16)
and then they participated in the multimodal task. The                Novel         A6 (16)      V6 (16)     A6V6 (16)
remaining participants were presented with the
multimodal task, followed by the two unimodal tasks              Table 1. Overview of stimuli and tasks (frequency of
(order randomized for each participant). The multimodal          each stimulus).
task took approximately 40 minutes, and each unimodal
task took approximately 20 minutes.                                 Participants were presented with a warm up task
    As can be seen in Table 1, each task consisted of one        where they were given 10 standards and 3 novels.
standard (presented approximately 80% of the time), four         ERPs from the warm up task were not included in the
oddballs (each presented approximately 4% of the time),          final data. Feedback was provided throughout the
and one novel (presented approximately 4% of the time).          entire experiment. Feedback was provided if
Participants were instructed to press a button every time        participants: (a) responded to a standard or oddball or
they saw/heard the novel, and to not respond to the              (b) failed to respond to a novel. All data were
standards and oddballs (see cover story). The novel trials       recorded with eyes open and participants in the
were presented to keep participants engaged, and ERPs            unimodal auditory condition were asked to fixate on
from these trials were discarded. Four oddballs were used        a square taped to the top of the LCD monitor.
to keep the task interesting for participants and to
maintain a low probability of oddballs (each oddball was
only presented 4% of the time). In each of the unimodal          Recording Conditions and Data Acquisition
conditions there were four oddballs, and in the                  Experiments were conducted in a sound-attenuated,
multimodal condition, there were eight oddballs (four            illuminated, and well-ventilated presentation chamber
auditory and four visual). To examine how multimodal             which housed a Dell 17” monitor, two Polk
stimuli affect auditory processing, we compared auditory         PLKRC65I wall mount speakers, and a response pad.
oddballs in the silent condition (e.g., A2, A3, etc.) with       In the experimenter room, a Dell Optiplex 755
the same auditory oddballs in the multimodal condition           computer with E-prime software v.2.0.8.22 was used
(e.g., A2V1, A3V1, etc.). To examine how multimodal              to present stimuli to participants, and a Harman
stimuli affect visual processing, we compared visual             Kardon AVR-154 receiver was used to amplify the
oddballs in the silent condition (e.g., V2, V3, etc.) with       sounds. Timing tests were conducted to ensure that
the same visual oddballs in the multimodal condition             auditory and visual stimuli were presented
(e.g., A1V2, A1V3, etc.).                                        simultaneously. Offsets between trigger registration
    Prior to each task participants were told a short cover      and stimuli presentation were measured for unimodal
story. For example, in the unimodal visual task,                 and multimodal conditions and were adjusted during
participants were told: You are going to see creatures           analysis. A PowerPC G5 Mac with Netstation
from a far away place. Most of the creatures that you will       software was used to record and store ERP data.
see eat vegetables. However sometimes you will see this              ElectroEncephalography (EEG) brain activity was
creature (novel was presented). This creature eats               recorded using a 128-channel HydroCel Geodesic
cookies. In this game you have to press a button every           Sensor Net (Electrical Geodesics, Inc., Eugene, OR).
time you see this creature that eats cookies (novel was          Scalp-electrode impedances were kept below 50
presented). Do not press any buttons when you see any of         kOhms. All channels were referenced to Cz during
                                                            2646

acquisition. EEG was recorded using a 0.1 to 100 Hz                  (standards vs. oddball) as a repeated measure. The
band-pass filter (3 dB attenuation), amplified at a gain of          same analyses were conducted in the four conditions
1000, sampled at a rate of 250 Hz, and digitized with a              (i.e., Unimodal Auditory, Unimodal Visual,
24-bit A/D converter.                                                Multimodal Auditory, and Multimodal Visual). All
                                                                     ANOVAs were significant, Fs > 20, ps < .0001.
Data analysis
                                                                                                  Unimodal Auditory                      Multimodal Auditory
Participants ably discriminated novels in all of the
conditions (proportion of hits to novels – proportion of
false alarms to standards + oddballs > .99). Because
auditory and visual components both changed on novel                                                                        Standard
                                                                                                                            Oddball
trials and participants made a response, it is unclear if                                                                   Difference
ERP waveforms reflect auditory discrimination, visual                                              Unimodal Visual                        Multimodal Visual
                                                                         Microvolt
discrimination, or the response. Therefore, data from                                5
novel trials were not included in any of the analyses.                               0    t
    ERPs to standards and oddballs were processed using                              -5
Netstation waveform tool. EEGs were band-passed                                               0     200 400 600       800
between 0.1 Hz and 30 Hz and segmented between 100                                                    Time(ms)
ms pre-stimulus onset and 1000ms post stimulus onset.
ERPs were referenced with respect to the average of all              Figure 2. ERP waveforms for Standards and Oddballs
channels after correcting for bad trials using neighboring           across conditions. Solid line represents difference
channels. Trials were then baseline corrected with respect           waves (Oddball – Standard).
to the 100 ms pre-stimulus and then exported to Matlab.
    Initially, we looked at 8 different scalp regions, each            To examine the effects of visual input on auditory
comprising of 6 or 7 channels from the 10/20 system                  discrimination, we compared the auditory difference
representing: F3, F4, P3, P4, T3, T4, Pz, and Oz.                    waveform in the multimodal condition to the auditory
However, in the current study we focused exclusively on              difference waveform in the unimodal condition (see
Pz; the region that provided the best measure of                     Figure 3a). A one-way AVOVA revealed that mean
discrimination in all conditions (see Figure 2). In each of          amplitude between 250-650 ms did not differ
the unimodal conditions, participants provided two ERP               between the unimodal and multimodal conditions.
waveforms (one for the standard and one for the oddball).            We also examined how the presence of auditory input
To equate the number of standards and oddballs, we                   affected visual discrimination by comparing the
randomly picked and averaged 64 of the 280 standards                 visual difference waveform in the multimodal
and we averaged across the four different oddballs. In the           condition to the visual difference waveform in the
multimodal condition, adults provided a waveform for the             unimodal condition (see Figure 3b). As in the
standard, a waveform for auditory oddballs, and a                    auditory conditions, mean amplitude did not differ
waveform for visual oddballs (see Table 1).                          between the unimodal and multimodal conditions.
                                                                       To statistically find and quantify any significant
              Results and Discussion                                 displacement of P300 between unimodal and
                                                                     multimodal conditions, we computed the fractional
A reliable P300 was found at Pz, P3, and P4, however, as             area latency. In particular, for a predefined window,
mentioned above, discrimination was most pronounced at               we measured the area under the curve, and then we
Pz. Thus, analyses reported below focus on Pz between                found the latency that divided that area into two equal
250-650 ms after stimulus onset. Waveforms for the                   parts (see Hansen & Hillyard, 1980). Using this
unimodal conditions are presented on the left side of                measure for a window between 250 ms and 650 ms,
Figure 2 and waveforms for the multimodal conditions are             we found that multimodal presentation sped up
presented on the right side of Figure 2. As can be seen in           auditory discrimination by 26ms and slowed down
Figure 2, participants ably discriminated auditory and               visual discrimination by 12 ms.
visual stimuli when presented unimodally and                           However, as can be seen in Figure 3a, there are
multimodally. Mean averages were computed for each                   multiple peaks in both auditory conditions that could
participant. For example, to assess discrimination of the            be the result of multiple underlying components.
auditory stimuli in the unimodal auditory condition, we              Therefore, we ran sliding windows of 200 ms, 300
computed a mean average for the standard (between 250-               ms, and 400 ms for each participant’s data covering
650 ms) and a mean average for the oddball (between                  the whole time range of interest (250ms to 650ms).
250-650 ms) for each participant. These means were then              That is, for each window length, centered at a time
submitted to a one-way ANOVA with trial type                         sample, we computed the 50% area latency for both
                                                              2647

the multimodal difference waveform and for the unimodal                   latency of the visual P300 and shortening the latency
difference waveform. We then calculated a difference                      of the auditory P300.
wave (Difference Multimodal – Difference Unimodal) to
denote the displacement. We kept doing this while sliding                 a.
the window at 4ms increments. Figure 4a – 4c plot the                                                             Pz - 200 ms window 50% peak
displacement waveforms for the 200 ms, 300 ms, and 400                                             10
                                                                                                                                                Auditory
                                                                                                                                                Visual
ms windows, respectively. Values greater than zero
denote that multimodal presentation increased the latency                                           5
of P300 and values less than zero denote that multimodal
                                                                               Displacement (ms)
presentation shortened the latency of P300.                                                         0
     a.                                                                                             -5
                                        Pz Auditory
                     8
                                                                                                   -10
                     6
                     4                                                                             -15
                                                                                                     250   300   350   400   450    500   550   600      650
                     2                                                                                                 Time Window (ms)
         Microvolt   0
                                                                          b.
                          t                                                                                       Pz - 300 ms window 50% peak
                     -2
                                                                                                   10
                     -4
                     -6                                       UA                                    5
                                                              MA
                     -8                                                                             0
                                                                               Displacement (ms)
                              0   200     400         600   800
                                        Time(ms)
                                                                                                    -5
b.
                                        Pz Visual                                                  -10
                     8
                                                                                                   -15
                     6                                                                                                                          Auditory
                                                                                                   -20                                          Visual
                     4
                                                                                                    250    300   350   400   450    500   550   600      650
                     2
     Microvolt
                                                                                                                       Time Window (ms)
                     0                                                    c.
                         t
                                                                                                                  Pz - 400 ms window 50% peak
                 -2
                 -4                                                                                10
                 -6                                          UV                                     5
                                                             MV
                 -8                                                                                 0
                              0   200     400         600   800
                                                                               Displacement (ms)
                                        Time(ms)
                                                                                                    -5
Figure 3. (a) Difference waves for Unimodal Auditory                                               -10
(UA) and Multimodal Auditory (MA), (b) Difference
                                                                                                   -15
waves for Unimodal Visual (UV) and Multimodal Visual
(MV). All data are averaged across participants.                                                   -20
                                                                                                                                                Auditory
                                                                                                                                                Visual
                                                                                                   -25
  As can be seen in Figures 4a-4c, across all windows,                                              250    300   350   400   450    500   550   600      650
                                                                                                                       Time Window (ms)
multimodal presentation sped up auditory processing and
slowed down visual processing.           ANOVAs were                      Figure 4. Displacement for (a) 200 ms window, (b)
conducted for each window at every 4 ms increment.                        300 ms window, (c) 400 ms window.
Using a window size of 200 ms, auditory and visual
displacement waves differed from 370 ms to 514 ms, ps <                                                          General Discussion
.05. Using a window size of 300 ms, auditory and visual
displacement waves differed from 362 ms to 534 ms, ps <                   The current study used a passive oddball task to
.05. Finally, using a window size of 400 ms, auditory and                 examine the time course of auditory and visual
visual displacement waves differed from 370 ms to 554                     processing when stimuli were presented unimodally
ms, ps < .05. These findings suggest the multimodal                       and multimodally. As can be seen in Figures 2, 3a,
presentation had different effects on auditory and visual                 and 4a-4c, there was no evidence that visual input
processing, with multimodal presentation increasing the                   attenuated discrimination of auditory stimuli. Rather,
                                                                   2648

multimodal presentation appeared to speed up auditory            Hansen, J.C., & Hillyard, S. A. (1980). Endogenous
processing and slow down visual processing. These                  brain potentials associated with selective auditory
findings have important implications for understanding             attention. Electroencephalography and Clinical
the underlying mechanisms and time course of modality              Neurophysiology, 49, 277-290
dominance. In particular, the current findings suggest that      Klein, R. M. (1977). Attention and visual dominance:
some of the effects of visual dominance may stem from              A chronometric analysis. Journal of Experimental
visual input dominating the response. However, future              Psychology: Human Perception & Performance, 3,
research will need to make direct comparisons on tasks             365-378.
that do and do not require explicit responses before any         Kutas, M., McCarthy, G., Donchin, E. (1977).
strong conclusions can be drawn.                                   Augmenting mental chronometry: the P300 as a
   The novelty of the current research is that we examined         measure of stimulus evaluation. Science, 197, 792–
the time course of auditory and visual processing on a             795.
task that did not require an explicit response. The results      Mertens, R., & Polich, J. (1997). P300 from a single-
replicate auditory dominance effects found in young                stimulus paradigm: Passive versus active tasks and
children, with multimodal presentation attenuating visual          stimulus modality. Electroencephalography &
processing, and having no effect or facilitating auditory          Clinical Neurophysiology, 104(6), 488-497.
processing (see Robinson & Sloutsky, 2010 for a review).         Polich, J., & Criado, R. (2006). Neuropsychology
This interaction suggests that effects cannot solely stem          and neuropharmacology of P3a and P3b.
from increased tasks demands, otherwise processing in              International Journal of Psychophysiology, 60(2),
both modalities would have been delayed. Rather, we                172-185.
believe this interaction stems from the dynamics of cross-       Posner, M. I., Nissen, M. J., & Klein, R. M. (1976).
modal processing. According to this account (Robinson &            Visual dominance: An information-processing
Sloutsky, 2010), auditory stimuli quickly engage attention         account of its origins and significance.
and processing of the details of a visual stimulus does not        Psychological Review, 83, 157-171.
begin until the auditory modality releases attention. While      Robinson, C. W., & Sloutsky, V. M. (2004).
this account has received some support in young children,          Auditory dominance and its change in the course of
the finding that auditory input can also slow down visual          development. Child Development, 75, 1387-1401.
processing in adults is novel.                                   Robinson, C. W., & Sloutsky, V. M. (2010).
                                                                   Development of Cross-modal Processing. Wiley
                                                                   Interdisciplinary Reviews: Cognitive Science, 1,
                   Acknowledgments                                 135-141.
This research has been supported by grants from the NSF          Sloutsky, V. M., & Napolitano, A. (2003). Is a
(BCS-0720135), NIH (R01HD056105) and from the US                   picture worth a thousand words? Preference for
Department       of    Education    (R305H050125       and         auditory modality in young children. Child
R305B070407) to Vladimir Sloutsky and from NIH                     Development, 74, 822-833.
(RO3HD055527) to Chris Robinson.                                 Sinnett, S., Spence, C., & Soto-Faraco, S. (2007).
                                                                   Visual dominance and attention: Revisiting the
                        References                                 Colavita effect. Perception & Psychophysics, 69,
                                                                   673–686.
Brown, C.R., Clarke, A.R., & Barry, R.J. (2007).                 Spence, C., Shore, D. I., & Klein, R. M. (2001).
   Auditory processing in an inter-modal oddball task:             Multisensory prior entry. Journal of Experimental
   Effects of a combined auditory/visual standard on               Psychology: General, 130, 799-832.
   auditory target ERPs. International Journal of                Sutton, S., Braren, M., Zubin, J., John, E. (1965).
   Psychophysiology, 65, 122-131.                                  Evoked potential correlates of stimulus uncertainty.
Colavita, F. B. (1974). Human sensory dominance.                   Science, 150, 1187–1188.
   Perception & Psychophysics, 16, 409-412.                      Vidal, J., Giard, M-H., Roux, S., Barthelemy, C., &
Colavita, F. B., & Weisberg, D. (1979). A further                  Bruneau, N. (2008). Cross-modal processing of
   investigation of visual dominance. Perception &                 auditory-visual stimuli in a no-task paradigm: A
   Psychophysics, 25, 345–347.                                     topographic event-related potential study. Clinical
Fort, A., Delpuech, C., Pernier, J., Giard, M.H., (2002).          Neurophysiology, 119(4), 763-771.
   Early auditory–visual interactions in human cortex            Wronka, E., Kaiser, J., & Coenen, A. M. L. (2008).
   during nonredundant target identification. Cogn. Brain          The auditory P3 from passive and active three-
   Res, 14, 20–30.                                                 stimulus oddball paradigm. Acta Neurobiologiae
Giard, M.H., Peronnet, F., 1999. Auditory–visual                   Experimentalis, 68(3), 362-372.
   integration during multimodal object recognition in
   humans: A behavioural and electrophysiological study.
   J. Cogn. Neurosci. 11 (5), 473–494.
                                                            2649

