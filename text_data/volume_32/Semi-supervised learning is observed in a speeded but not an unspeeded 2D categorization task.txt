UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Semi-supervised learning is observed in a speeded but not an unspeeded 2D categorization
task
Permalink
https://escholarship.org/uc/item/8g54r9cm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Rogers, Timothy
Kalish, Charles
Gibson, Bryan
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Semi-supervised learning is observed in a speeded but
                                   not an unspeeded 2D categorization task
             Timothy T. Rogers, Charles Kalish, Bryan R. Gibson, Joseph Harrison and Xiaojin Zhu
                                         Departments of Psychology and Computer Science
                                                   University of Wisconsin-Madison
                                                      Madison, WI 53706 USA
                            Abstract                                 unlabeled data has been a topic of considerable investigation
                                                                     in machine learning, where it has been formally shown that,
  Recent empirical studies of semi-supervised category
  learning—where learners only occasionally receive                  for some kinds of learning problems, a learner can converge
  information about a given item’s category membership—have          much more quickly on an accurate representation of the
  yielded contradictory results, with some studies showing           category structure by combining labeled and unlabeled
  strong effects of unlabeled experience and others little or no     observations (Chapelle, Zien, and Scholkopf, 2006; Zhu and
  effect. We report two experiments designed to help understand      Goldberg, 2009). In cognitive psychology, the empirical
  this heterogeneity. In both, participants performed a
  two-category classification task with novel stimuli varying        question of how experience with both labeled and unlabeled
  along two psychologically separable dimensions. In                 items might influence category learning has rarely been
  semi-supervised conditions, participants categorized and           studied. Some well-known computational approaches to
  received feedback on 32 “labeled” items intermixed with a          category learning suggest ways in which labeled and
  large number of “unlabeled” items. In the supervised-only          unlabeled observations might combine to influence
  condition, participants viewed the same labeled trials
  intermixed with a large number of filler trials. Without time      knowledge of category structure (e.g. Nosofsky, 1986;
  pressure participants learned the task equally well in both        Schyns, 1991; Love et al. 2004), but these ideas have not
  conditions. When required to respond very rapidly, however,        been linked to the formal analyses offered by machine
  participants performed substantially better in the                 learning and have not been a focus of much empirical work.
  semi-supervised condition. The discrepant results may indicate            We are aware of only two studies designed to assess
  a role for selective attention in human semi-supervised
  learning.                                                          whether category learning is influenced by unlabeled
                                                                     experiences, and these come to opposing conclusions. On the
  Keywords: semantic interference, visual lexical decision,          positive side, Zhu and colleagues (2007) studied
  dual-task, single-system view                                      performance in a 1-dimensional 2-category learning task.
                                                                     After learning a category boundary with a small amount of
                         Introduction                                supervised training (ie training with corrective feedback),
      Most theoretical and computational approaches to               participants subsequently classified a large number of items
human category learning consider fully supervised learning:          with no feedback. These “unlabeled” items were sampled
for every training experience, the learner has access to a           from a bimodal distribution with a trough that was displaced
representation of the stimulus and to the true category label        to one side or the other of the original learned category
(e.g. Nosofsky, 1986; Kruschke, 1992; Gluck and Bower,               boundary. The authors found that, following the unlabeled
1988; Anderson, 1991 and many others). Fully unsupervised            experience, participants shifted their mental category
approaches—where the learner never has access to the true            boundary toward the trough of the unlabeled distribution.
category label but must learn to group items into categories         This finding suggests that people expect category boundaries
on the basis of their similarity—are less common but have            to align with low-density regions in the unlabeled feature
also appeared in the literature (e.g. Fried and Holyoak, 1984).      space, and use unlabeled observations to adjust their
Neither approach seems fully adequate, however, for                  representations of category structure accordingly.
explaining human categorization. Although a great deal of                 In contrast, Vandist and colleagues (2009) studied a
natural experience is unsupervised—we continually                    binary classification task with stimuli that varied in two
encounter objects in the world without a “teacher” telling us        psychologically separable dimensions (the orientation and
what kind of things they are—we also certainly get a                 spatial frequency of Gabor patches). Participants viewed a
nontrivial amount of “labeled” experience, where a                   number of labeled examples intermixed either with
recognized authority provides the true class label either            additional unlabeled examples or with unrelated filler items.
directly in an explicit teaching scenario or indirectly through      Unlabeled items were sampled from a bimodal distribution in
use of the label in communication. Human category learning           which the trough aligned with the true category boundary.
may, therefore, involve combining both labeled and                   The authors found no difference in the rate of learning or
unlabeled sources of information—that is, human category             overall performance between these conditions—suggesting
learning may be semi-supervised.                                     that the unlabeled items provided no overall benefit in
     The question of how best to combine labeled and                 learning the category structure, even though the distribution
                                                                 2320

of these items was consistent with the to-be-learned              bisected by an oblique line, and varied in radius (ie circle size)
boundary.                                                         and in the precise angle of the bisecting line. Like the
     In this paper we investigate some of the factors that        dimensions employed by Vandist et al. (2009), size and line
might explain the different results obtained by these studies.    orientation      are    two      psychologically      separable
Though both groups focused on semi-supervised learning,           dimensions—that is, it is possible to attend selectively to one
there were several key differences in their experiments: (i)      dimension without processing the other. In our stimuli, circle
Where Vandist et al. used stimuli varying in two                  radius varied from 50 to 120 pixels while line orientation
psychologically separable dimensions, Zhu et al. employed         varied from 0 to 90 degrees (measured from the horizontal).
visually complex shapes varying along a line in a
multidimensional feature space. (ii) Where Vandist et al.
provided participants with many labeled items, Zhu et al.
trained participants with 10 repetitions each of just 2
individual tokens (ie one exemplar of each category). (iii)
Vandist et al. employed a task requiring participants to
integrate two separable dimensions (ie the category boundary
was oblique in the 2D feature space) whereas Zhu et al.
employed a simple 1D category learning task. (iv) Vandist et
al. provided participants with ongoing labeled training
experiences, whereas Zhu et al. performed a short block of
supervised learning followed by a long block of unsupervised
trials. (v) Vandist et al. compared performance in a
semi-supervised condition to performance in a
fully-supervised condition, whereas Zhu et al. compared two
different semi-supervised conditions.                                                  Diameter (pixels)
     Thus there are several potential hypotheses as to why
different results were obtained in the two studies. We report     Figure 1. Example of the distribution of labeled (black)
two experiments designed to narrow the range of possible          and unlabeled (red) items for one participant. Plus signs
hypotheses by capitalizing on the positive characteristics of     show labeled items from Category A, minus signs show
both Zhu et al.’s (2007) and Vandist et al.’s (2009) original     labeled items from Category B.
designs. Like Vandist and colleagues, our experiments (i)
employ stimuli that vary along two obvious and                          Pilot testing with a fully-unsupervised procedure
psychologically separable dimensions, (ii) compare a              showed a general bias for classifying these stimuli according
semi-supervised condition to a matched supervised condition,      to the angle dimension—only 35% of participants made
and (iii) provide participants with ongoing exposure to           unsupervised categorization decisions based on size.
labeled data. Like the experiment described by Zhu et al., (i)    Consequently our experiments involved learning to classify
our stimuli were more object-like, (ii) participants in the       these items according to their size. Items larger than or equal
semi-supervised condition received relatively few labeled         to 85 pixels in radius were designated class A while those
trials (8%), and (iii) the boundary to be learned did not         smaller than 85 pixels were designated class B.
require integration of the two dimensions. In Experiment 1              The experiment included two between-subjects
we show that, under these conditions, people seem relatively      conditions. In the semi-supervised (SS) condition,
insensitive to unlabeled learning experiences. Experiment 2       participants viewed a total of 32 labeled items—items for
then tests a more explicit hypothesis about the conditions        which feedback was provided—sampled from a uniform
under which unlabeled experiences influence performance.          distribution over the space. These were intermixed with 400
                                                                  unlabeled examples sampled from a bimodal distribution that
                      Experiment 1                                was uniform along the angle dimension but had a substantial
                                                                  gap along the size dimension (see Figure 1). Thus the gap in
                                                                  the unlabeled distribution provided a potential cue to
Method                                                            orientation and location of the true category boundary. In the
                                                                  supervised-only (SO) condition, participants viewed the
Participants. 50 undergraduate students from UW-Madison           same 32 labeled items as in the semi-supervised condition. In
participated in Experiment 1 for course credit or monetary        this case, however, these items were intermixed with filler
compensation. All had normal or corrected-to-normal vision.       trials in which participants viewed the word “left” or “right”
                                                                  on the screen and pressed the corresponding mouse button.
Materials and Design. The stimuli were derived from               Labeled trials were ordered so that 8 appeared in each block
classic work by Nosofsky (1986). They consisted of circles        of 100 unlabeled/filler trials. Subjects in the SS and SO
                                                              2321

conditions were yoked so that each SO participant viewed            greater than 66%. The number of learners in each condition
exactly the same labeled items in exactly the same sequence         was comparable (13/25 in the semi-supervised group, 12 /25
and at exactly the same time as a participant in the SS             in the control group), suggesting that the unlabeled items did
condition. Thus the only difference between conditions was          not produce a greater likelihood of learning the correct
whether the trials interspersed among labeled examples              boundary.
consisted of unlabeled examples or of filler. After experience
with the labeled and unlabeled/filler trials, both groups                                                          Experiment 1 all subjects
categorized, without feedback, 36 items forming an
evenly-spaced “grid” in the stimulus space. Performance was                                     1.00
assessed as the mean proportion correct in each successive
block of 8 labeled items and on the unlabeled grid items.                                       0.90
     If participants use the gap in the unlabeled distribution to
                                                                           Proportion correct
form their mental category boundary, their accuracy on the                                      0.80
labeled items should increase more rapidly, and their
performance on the final grid should be better overall, than                                    0.70
participants in the control condition.
                                                                                                0.60
Procedure The experiment was carried out on PCs running
the DMDX software package under Windows XP. The 50                                              0.50                                                 SS
participants were randomly assigned to either the SS or SO                                                                                           SO
condition with 25 participants in each. Participants in both                                    0.40
groups were told that they would view a series of objects and                                          Block1   Block2        Block3      Block4    Grid
that each belonged to one of two categories. Their job was to
learn to classify the objects correctly by pressing one of two
                                                                                                                Experiment 1 grid learners only
buttons on the mouse. Participants in both conditions were
told that they would only occasionally get feedback                                             1.00
indicating whether their choice was correct, but that they
should do their best to categorize all of the items regardless.                                 0.90
Participants in the SO condition were additionally told that
categorization trials would be interspersed with
                                                                       Proportion correct
                                                                                                0.80
button-pressing trials in which they would view the word
“left” or “right” and must press the corresponding mouse                                        0.70
button. The principal dependent measure was the mean
proportion correct for each successive block of 8 labeled
                                                                                                0.60
items and for the 36 unlabeled grid items.
                                                                                                0.50                                                   SS
Results                                                                                                                                                SO
     Figure 2 (top) shows means and standard errors of the                                      0.40
accuracy for each block of 8 labeled items and for the final                                           Block1        Block2            Block3      Block4
unlabeled grid in the two conditions. A repeated measures
ANOVA treating time (each block of 8 labeled items plus             Figure 2. Top: Mean proportion correct for labeled items
final grid) as a within-subjects factor and learning condition      and grid for all participants in Experiment 1. Bottom:
(SS / SO) as a between-subjects factor revealed a significant       Mean proportion correct for labeled items in each block
main effect of time with performance improving overall              across participants who performed above criterion on the
(F(5,192) = 5.36, p < 0.001), but no effect of learning             final grid. Error bars indicate the standard error of the
condition (F(1,48) = 0.29, p = 0.59) and no interaction             mean.
between these (F(4,192) = 0.51, p = 0.73).
     Performance overall was highly variable, with some                  Finally we investigated the effect of time and learning
participants learning fairly well and others not at all. In fact    condition on accuracy for the 4 blocks of labeled items
performance on the final grid was bimodal in both groups,           considering just those participants who performed to
with one subgroup choosing correctly on 67% or more of the          criterion on the grid items. These data are shown in Figure 2
grid trials and the other group at chance. We therefore             (bottom). Though learners in the SS condition appeared to
classified each participant as a “learner” or a “nonlearner”        perform marginally better, this effect was not statistically
based on grid performance, with learners showing accuracy           reliable. A repeated-measures ANOVA showed a reliable
                                                                    main effect of time (F(3,69) = 10.9, p < 0.001) but no effect
                                                                2322

of condition (F(1,23) = 2.2, p = 0.15) and no interaction (F(3,    groups were told that they would need to respond to each
69) = 1.0, p = 0.40).                                              item as rapidly as possible.
     In sum, we obtained no evidence for semi-supervised
learning in this experiment: though unlabeled items were           Procedure Participants were randomly assigned to one of the
selected from a distribution with a prominent gap that aligned     2 conditions, with 25 participants in each group. The
well with the true category boundary, experience with this         procedure was identical to Experiment 1 with the following
distribution did not significantly impact the overall rate of      exceptions. First, each stimulus appeared onscreen for 125ms
learning, the mean accuracy, or the number of participants         and was then replaced by a visual mask composed of hash
who learned successfully.                                          marks. Participants were given 600ms from the onset of the
                                                                   mask to make their response. If the participant did not
                      Experiment 2                                 respond within this window, the computer indicated that the
                                                                   response was too slow. On labeled trials that did not meet
   Consistent with the observations of Vandist and colleagues      deadline, the computer indicated that the response was too
(2009), Experiment 1 showed little effect of unlabeled             slow and also presented the correct category label. In both
experience on category learning. What then accounts for the        conditions, the deadline was imposed on both labeled trials
strong effects of unlabeled experience previously observed         and on unlabeled/filler trials.
by Zhu et al. (2007)? Experiment 2 tested one hypothesis:
perhaps the difference is observed because, in both the
current work and in Vandist et al.’s (2009) experiment, the        Results
stimuli were composed of two psychologically separable                  Trials that did not meet deadline were discarded from the
dimensions. A classic tradition of research in concept             analysis; these included just 5% of trials on average. Thus
attainment has shown that, for such stimuli, people often          most participants were able to respond within the
adopt a “win-stay-lose-shift” strategy (Bruner, Goodnow and        time-window on the majority of trials. For the remaining
Austin, 1956). That is, they formulate a hypothesis about the      trials, we computed the mean accuracy on each successive
relevant dimension for categorization, then make their             block of 8 labeled trials and on the final unlabeled grid.
decision based solely on that dimension until they receive         Results are shown in Figure 3.
evidence that their hypothesis is wrong, at which point they
                                                                                                             Experiment 2 all subjects
shift to a new hypothesis. If feedback is very sparse,
                                                                                           1.00
participants may focus on the dimension they believe to be
relevant to the exclusion of other dimensions. That is,                                                                                     SS
                                                                                                                                            SO
participants may not attend to the competing dimension at all                              0.90
on many trials, and so may be exposed to very little
information about the distribution on this dimension.
                                                                      Proportion correct
                                                                                           0.80
Especially for our stimuli, where pilot studies suggest that
participants are biased to attend to the irrelevant dimension                              0.70
(angle), such strategic/attentional effects might seriously
attenuate any influence of unlabeled experience.                                           0.60
     To test this hypothesis, we conducted a second study
identical to Experiment 1 in all but one respect: in
                                                                                           0.50
Experiment 2, participants were required to respond within a
deadline of 600ms. With this requirement of a very rapid
response, participants have little time to focus their attention                           0.40
                                                                                                  Block1   Block2     Block3     Block4   Grid
on one dimension or the other. Consequently, we predicted
that the distribution of unlabeled examples would have a           Figure 3. Mean proportion correct across all participants
more significant impact on category learning in this               in Experiment 2 for labeled items in each block and grid.
paradigm.                                                          Error bars indicate the standard error of the mean.
Method                                                                In contrast to Experiment 1, participants in the
Participants 50 undergraduate students who did not                 semi-supervised condition showed greater accuracy across
participate in Experiment 1 were recruited for this study in       all blocks and on the final grid. A general linear model
return for course credit. All participants had normal or           treating time (4 successive blocks of 8 labeled items + grid)
corrected-to-normal vision.                                        as a within-subjects factor and learning condition (SS versus
                                                                   SO) as a between-subjects factor revealed reliable main
Materials and Designs The materials and design were                effects of both factors (for time, F(4,192) = 6.8, p < 0.001; for
identical to Experiment 1, except that participants in both        learning condition, F(1,48) = 4.32, p < 0.05) and no
                                                               2323

interaction between them (F(4, 192) = 1.2, p = 0.32).                                                       Discussion
   As previously we also computed the number of                                       In two experiments we assessed whether the ability to learn
participants who performed to a criterion of 67% or better on                      a simple 2D binary classification task is influenced by
the final grid in each condition. In the SS condition, more                        unlabeled experiences. In the first experiment, where
than half the participants exceeded this criterion (13/25)                         participants responded with no time pressure, we observed
whereas less than a third did in the SO condition (8/25).                          little evidence that unlabeled data matter: participants
These odds are different with likelihood p<0.08 according to                       performed equally well, were equally likely to learn, and
a one-tailed test of the log odds ratio.                                           learned equally rapidly regardless of whether they received
                                                                                   unlabeled learning items. In the second experiment, which
                                     Experiment 2 grid learners only
                                                                                   was identical in all respects except that participants were
                     1.00
                                                                           SS      pressured to respond rapidly, we observed a very different
                                                                           SO      pattern: in this case, experience with unlabeled items led to
                     0.90
                                                                                   better overall performance, a greater likelihood of learning to
                                                                                   criterion, and more rapid learning compared with supervised
                                                                                   learning only. Like Vandist et al (2009), we found little
Proportion correct
                     0.80
                                                                                   evidence that unlabeled data influence category learning
                     0.70                                                          when response times were unconstrained. When responses
                                                                                   were speeded, we replicated Zhu et al.’s (2007) finding that
                     0.60                                                          unlabeled data can produce substantial effects. What
                                                                                   accounts for these different patterns?
                                                                                         One possibility concerns the extent to which participants
                     0.50
                                                                                   can selectively attend to only some of the stimulus feature
                                                                                   dimensions. Prior work has shown that, in categorization
                     0.40
                            Block1       Block2         Block3         Block4
                                                                                   tasks where it is possible for participants to form an explicit
                                                                                   categorization rule, learning depends importantly upon
Figure 4. Mean proportion correct in Experiment 2 for                              mechanisms of attention and cognitive control (Ashby and
participants who performed above criterion in the final                            Maddox, 2005). In Zhu et al.’s (2007) work, stimuli varied
grid. Error bars indicate the standard error of the mean.                          along a line in a complex multidimensional feature
                                                                                   space—therefore it was impossible for participants to
   Finally, we again considered mean accuracy over                                 selectively attend to information that was irrelevant to the
successive blocks of labeled items in just the participants                        category learning task. In contrast, in Vandist’s et al.’s (2009)
who performed to criterion according to their grid accuracy.                       work and the current study, stimuli varied in two
In these participants performance was much better in the SS                        psychologically separable dimensions. If participants
than the SO group, with accuracy on labeled items improving                        selectively attended to only one of these, so that
from 50% to 73% for learners in the SS group but not                               distributional information about the unattended dimension
exceeding chance on any block in the SO group. A general                           was not available to the learning system, effects of unlabelled
linear model of these data showed no reliable main effect of                       data might be attenuated or eliminated—producing the null
time or learning condition but these factors did interact                          result in Vandist’s (2009) work and in Experiment 1.
significantly (F(3,60) = 2.8, p < 0.05) . Inspection of Figure 4,                        On this hypothesis, the robust influence of unlabeled
which plots these data, explains the absence of any main                           data in Experiment 2 was observed because participants
effect and the interaction: performance did not improve                            lacked sufficient time to selectively attend to just one feature
significantly at all for the 8 participants in the SO group who                    dimension. If, under speeded conditions, both stimulus
performed above criterion on the final grid, but did improve                       dimensions are fully represented, then the unlabeled
substantially for those participants in the SS group.                              distribution should have a more robust impact on learning.
Consistent       with       these      observations,     oneway                    On this view, it is not the speed of response that matters per
repeated-measures ANOVAS conducted separately for the                              se, but whether or not the learning system has access to all of
two groups showed significantly different accuracy across                          the relevant distributional information. If this account is
blocks for learners in the SS condition (F(3,36) = 4.6, p <                        correct, it predicts that unlabeled data should have a stronger
0.009) but not in the SO condition (F(3,24) = 0.3, p = 0.83).                      effect for multidimensional stimuli where the stimulus
   In sum, when responses were speeded, providing little time                      dimensions are not psychologically separable, even if
for strategic control of attention, participants in the SS                         response times are unconstrained. We leave this prediction to
condition performed more accurately overall, were                                  future work.
marginally more likely to learn to criterion, and learned                                We further note that, because there are many factors that
labeled items more rapidly than participants in the SO                             differentiate Zhu et al’s (2007) study from that of Vandist and
condition.                                                                         colleagues (2009), there remain several additional
                                                                                2324

hypotheses about the difference in their findings. The current         Journal of Experimental Psychology: Learning, Memory
study isolates speed of response as an important mitigating            and Cognition, 10 (2), 234-257.
factor, but other potentially important factors—including the      Gluck, M. A. and Bower, G. H. From conditioning to
orientation of the category boundary in the stimulus space,            category learning: An adaptive network model. Journal
the ratio of labeled to unlabeled examples, and the temporal           of Experimental Psychology: General, 117(3), 227-247.
distribution of labeled examples over the learning
session—should be parametrically explored in future work.          Hall, D. G. and Waxman, S. R., Eds. (2004). Weaving a
     More generally, the question of whether or not people             Lexicon. Cambridge, MA: MIT Press.
make use of unlabeled observations when learning categories        Keil, F. C. (1979). Semantic and Conceptual Development:
has strong implications for theories of human conceptual               An Ontological Perspective. Cambridge, MA: Harvard
knowledge. Many researchers have noted that even young                 University Press.
children are able, with just a handful of learning experiences,
to infer the extension of many category labels (Hall and           Kruschke, J. K. (1992). An exemplar-based connectionist
Waxman, 2004; Keil, 1979; Markman, 1989). Once they                    model of category learning. Psychological Review, 99(1),
reach the right age, most children need hear the word “horse”          22-44.
only once or twice before being able to make a reasonable          Love, B., Medin, D. L. and Gureckis, T. M. (2004).
guess about which objects in the world are horses and which            SUSTAIN: A network model of category learning.
not. This rapid learning from sparse data is sometimes held to         Psychological Review, 111(2), 309-332.
indicate that children bring strong inductive biases to bear on
                                                                   Markman, E. M. (1989) Categorization and Naming in
word-learning (Xu and Tenenbaum, 2007).
                                                                       Children: Cambridge, MA: MIT Press.
     Semi-supervised learning suggests a different
explanation: Maybe children can learn from just a few              Nosofsky, R. (1986). Attention, similarity, and the
labeled examples because they are marrying these sparse                identification-categorization relationship. Journal of
episodes to knowledge gleaned from a vast amount of                    Experimental Psychology: General, 115(1), 39-57.
unsupervised experience. If children assume that category          Schyns, P. G. (1991). A modular neural network model of
labels tend to span relatively dense clusters in a conceptual          concept acquisition. Cognitive Science, 15, 461-508.
feature space, and that category boundaries follow the
low-density valleys in this space, then—to the extent that this    Vandist, K., de Schryver, M. and Rosseel, Y. (2009).
assumption holds—they only need a small number of labeled              Semi-supervised category learning: The impact of
experiences to work out which labels “go with” which                   feedback in learning the information-integration task.
clusters. This explanation frees theories of word-learning             Attention, Perception and Psychophysics, 71(2),
from having to rely too heavily on strong inductive biases to          328-341.
explain rapid word-learning abilities in children.                 Xu, F. and Tenenbaum, J. (2007). Word learning as Bayesian
                                                                       inference. Psychological Review, 114, 245-272.
                   Acknowledgements                                Zhu, X. and Goldberg, A. B. (2009). Introduction to
   This work was supported in part by a grant from the Air             Semi-Supervised Learning. San Rafael: Morgan and
Force Office of Scientific Research (AFOSR project number              Claypool.
FA9550-09-1-0313) and in part by NSF project                       Zhu, X., Rogers, T. T., Qian, R., and Kalish, C. (2007).
IIS-0916038.                                                           Humans perform semi-supervised classification too.
                                                                       Proceedings of AAAI 2007.
                         References
Anderson, J. R. (1991) The adaptive nature of human
     categorization. Psychological Review, 98, 409-429.
Ashby, F. G. and Maddox, W. T. (2005). Human category
     learning. Annual Review of Psychology, 56, 149-178.
Bruner, J. S., Goodnow, J. J. and Austin, G. A. (1956). A
     Study of Thinking. Hoboken NJ: John Wiley and Sons.
Chapelle, O., Zien, A. and Scholkopf, B. (2006).
     Semi-Supervised Learning. Cambridge, MA: MIT Press.
Fried, L. S. and Holyoak, K. J. (1984). Induction of category
     distributions: A framework for classification learning.
                                                               2325

