UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A rational account of perceptual compensation for coarticulation
Permalink
https://escholarship.org/uc/item/0tj7s650
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Sonderegger, Morgan
Yu, Alan
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                A rational account of perceptual compensation for coarticulation
                                        Morgan Sonderegger (morgan@cs.uchicago.edu)
                         Department of Computer Science, University of Chicago, Chicago, IL 60637 USA
                                                   Alan Yu (aclyu@uchicago.edu)
                Phonology Laboratory, Department of Linguistics, University of Chicago, Chicago, IL 60637 USA
                             Abstract                                  natural coarticulated speech. As another example, the percep-
   A model is presented that explains perceptual compensation          tion of a fundamental frequency (f0 ) contour can change as a
   for context as a consequence of listeners optimally categoriz-      function of vowel height (Hombert, 1978; Silverman, 1987)
   ing speech sounds given contextual variation. In using Bayes’       or consonant voicing (Pardo & Fowler, 1997): /i/ is perceived
   rule to pick the most likely category, listeners’ perception of
   speech sounds, which is biased toward the means of phonetic         as lower in pitch relative to an /a/ with the same f0 , presum-
   categories (Feldman & Griffiths, 2007; Feldman, Griffiths, &        ably because high vowels typically have higher f0 than low
   Morgan, 2009), is conditioned by contextual variation. The          vowels.
   effect on the resulting identification curves of varying cate-
   gory frequencies and variances is discussed. A simulation              Listeners’ language-specific experience crucially affects
   case study of compensation for vowel-to-vowel coarticulation        the degree of perceptual compensation. In a study replicated
   shows the predictions of the model closely correspond to hu-        in part below, Beddor, Harnsberger, & Lindemann (2002)
   man perceptual data.
                                                                       found that English and Shona listeners compensate for the
   Keywords: Speech perception; perceptual compensation; ra-
   tional analysis.                                                    coarticulatory effects of V2 on V1 in CV1 CV2 sequences.
                                                                       That is, listeners identified a continuum of synthesized vow-
                         Introduction                                  els between /a/ and /e/ more often as /a/ when the following
A major challenge for models of speech perception is explain-          vowel was /i/ than when the following vowel was /a/. Impor-
ing the effect of context on phonemic identification. Depend-          tantly, they observed that Shona listeners compensate more
ing on their acoustic, phonological, semantic, syntactic, and          for the vowel contexts that triggered larger acoustic influences
even socio-indexical contexts, identical acoustic signals can          in speech production. Compensatory responses can affect lis-
be labeled differently and different acoustic signals can be la-       teners’ rating judgments as well. English listeners are less
beled identically. One of the most investigated types of con-          accurate in judging vowel nasality in nasal than in non-nasal
textual effects stems from phonemes’ phonetic environments.            contexts, with nasal vowels in nasal contexts the most diffi-
Because of coarticulation, a phoneme’s phonetic realization            cult (Beddor & Krakow, 1999; Kawasaki, 1986).
is heavily context-dependent. To understand speech, the lis-              Explanations of PC effects have been advanced from sev-
tener must take into account context-induced coarticulatory            eral theoretical perspectives. Some emphasize the lexical and
effects to recover the intended message. The term perceptual           phonemic content of the context in determining the identifica-
compensation (PC) has often been used to characterize this             tion of the target sound (Elman & McClelland, 1988; Samuel
type of context-induced adjustment in speech perception. For           & Pitt, 2003). Gestural theorists, who assume that listeners
example, the identification of an ambiguous target syllable as         parse the acoustics in terms of its articulatory sources, argue
/da/ or /ga/ is shifted by preceding /ar/ or /al/ contexts (Mann,      that listeners attribute the acoustic properties of a target sound
1980): the same /Ca/ token is less likely to be heard as /ga/ in       to the coarticulatory context rather than to the target (Fowler,
/arCa/ context than in /alCa/ context. This effect has been ar-        1996, 2006). Auditorists attribute context-induced shifts in
gued to result from perceptual reduction of the coarticulatory         category boundaries to general auditory processes such as fre-
fronting effects of /l/ on a following velar consonant: listen-        quency contrast or spectral contrast (Diehl & Kluender, 1989;
ers are compensating for the effect of /l/ on /g/. This paper          Kingston, 1992; Kingston & Diehl, 1995; Lotto & Kluender,
proposes a simple model in which PC effects emerge as an               1998). Such auditory explanations are unavailable for com-
optimal solution to the problem of categorization in the pres-         pensation effects such as vowel-dependent pitch height com-
ence of context-induced variation. In this model, listeners            pensation (Fowler, 2006; Lotto & Holt, 2006). Motivated by
behave as if they are compensating because what is optimal             such cases, Lotto & Holt (2006) suggest that the spectral con-
differs by context.                                                    trast explanation be supplemented with a “general learning”
   PC effects have been observed in many phonetic settings.            mechanism for category formation from correlations between
The fricative /S/ has lower noise frequencies than /s/, and lip        stimulus parameters.
rounding lowers the resonant frequencies of nearby segments.              The generality of PC effects is accentuated by evidence for
Synthetic fricative noises ranging from /S/ to /s/ are more of-        contextual compensation with speech and non-speech sounds
ten identified by English listeners as /s/ when followed by /u/        in human and non-humans (Holt, Lotto, & Kluender, 2000;
than by /a/ (Mann & Repp 1980; see also Mitterer 2006), pre-           Lotto, 2004). For example, when /da/–/ga/ syllables are pre-
sumably because listeners take into account the lowering ef-           ceded by tone glides matching in frequency to the third for-
fect of lip rounding from /u/ on the noise frequencies of /s/ in       mant (F3 ) transition of /al/ or /ar/, listeners’ syllable identi-
                                                                   375

fication responses shifted in the same direction as when tar-       the task listeners perform in the two-alternative forced choice
gets were preceded by real speech (/al/ or /ar/). The same          (2AFC) paradigm commonly used in PC experiments. The
effect was observed even when steady-state tones at the off-        model formalism is adapted from that used by Feldman et al.
set frequency of /al/ or /ar/ F3 were used (Lotto & Kluender,       (2009). We differ in allowing model parameters to change
1998; cf. Viswanathan, Fowler, & Magnuson, 2009) . Lotto,           with context, and focus on different aspects of the model’s
Kluender, & Holt (1997) conditioned four Japanese quails to         predictions.1
exemplars of /da/ and /ga/ syllables. Two birds were trained           The modeled listener hears signal S in context k, and must
to peck a key when presented with good /da/ exemplars and           decide whether it belongs to category c1 or c2 . Listeners in
to not peck when presented with good /ga/ stimuli while two         this model assume S is normally distributed around a target
other quails were trained in the reverse condition (/ga/ posi-      pronunciation T , itself normally distributed around a cate-
tive, /da/ negative). After reaching a preset criterion of 10:1     gory mean, and categorize based on the likelihood that S is
ratio of pecks to positive versus negative stimuli, birds were      an instance of the speaker producing an example from ci in
presented with novel ambiguous CVs preceded by either /al/          context k, with target T . Formally,
or /ar/. All birds displayed a significant shift in peck rates
across the change in preceding liquid. The /da/-positive birds                 T | ci , k ∼ N(µci ,k , σc ),      S | T, ci ∼ N(T, σS )
pecked substantially more for CVs preceded by /ar/, while
                                                                    where µci ,k is the mean of category i mean in context k, σC2
/ga/-positive birds pecked more for CVs preceded by /al/.
                                                                    is the variance in T around the category mean, and σ2S is the
Crucially, both the task and the results were essentially the
                                                                    variance in S around T . We assume for simplicity that σC
same as in Mann (1980)’s experiment with human subjects.
                                                                    and σS are the same for categories 1 and 2. Although we as-
There is thus strong support for a language-independent, au-
                                                                    sume that T is the variable shifting by context, if it is instead
ditory mechanism of compensation.
                                                                    assumed that S shifts by context in a similar way, all results
   In this paper, we develop a computational model of PC ef-        turn out the same.2 It thus does not matter under this analysis
fects using rational analysis of speech perception and produc-      whether contextual variation is in the target pronunciation, T ,
tion. Rational analysis (RA; Anderson, 1990; Marr, 1982;)           or the acoustic signal itself, S.
attempts to explain aspects of cognition as adaptive responses         The probability S comes from category c1 can be calculated
to the environment; its central claim is that much of people’s      with Bayes’ rule:
behavior when performing some cognitive tasks can be under-
stood as optimal, according to some criterion. RA represents                                            P(c1 | k)P(S | c1 , k)
a different type of explanation from existing theories of PC:          P(c1 | S, k) =                                                        (1)
                                                                                          P(c2 | k)P(S | c2 , k) + P(c1 | k)P(S | c1 , k)
instead of explaining the behavioral locus (e.g. gestural pro-
cessing, lexical knowledge, general auditory processes) of PC       P(ci | k) is the probability of category i occurring in context k,
effects, the model presented here gives an account of why PC        i.e. in the lexicon as a whole. The P(S | ci , k) are calculated by
effects occur, as a consequence of listeners optimally solv-        integrating over all possible T , giving a logistic function:
ing the problem of categorization given context-induced vari-
                                                                                                                   f2 b−Sg −1
                                                                                                                              
ation.                                                                                  P(c1 | S, k) = 1 + e                                 (2)
   RA accounts have been developed for visual word recogni-                                                        f1
tion (Norris, 2006), spoken-word recognition (Norris & Mc-          where
Queen, 2008), perceptual magnet effects (Feldman & Grif-                                      2         2
                                                                                         1 µc1 ,k − µc2 ,k               µc1 ,k − µc2 ,k
fiths, 2007; Feldman et al., 2009), and other cognitive do-                        b=                       ,    g=
                                                                                         2 σ2S + σ2c                       σ2S + σ2c
mains, such as vision (Marr, 1982; Yuille & Kersten, 2006)
and manual movement (Trommershäuser, Gepshtein, Mal-               and fi = P(ci | k) is the frequency of category i in context k.
oney, Landy, & Banks, 2005). Our analysis of PC effects                Studies of PC generally focus on locating the crossover
grows out of the rational model of perceptual magnet effects        point, where S is maximally ambiguous between categories,
of Feldman et al. (2007, 2009). While “optimal” can be un-          i.e. S0 (see Fig. 1) such that P(c1 | S0 , k) = P(c2 | S0 , k) = 0.5.
derstood in Bayesian (e.g. Tenenbaum & Griffiths, 2001) or          Solving from (2) gives
maximum likelihood (e.g. Fried & Holyoak, 1984) terms, fol-
                                                                                          µc1 ,k + µc2 ,k        σ2S + σC2          f2
lowing Feldman et al. and other recent rational accounts of                       S0 =                    +                     ln( )        (3)
speech perception (Clayards, Tanenhaus, Aslin, & Jacobs,                                         2            µc1 ,k − µc2 ,k       f1
2008; Norris & McQueen, 2008), we use Bayesian inference                1 Space constraints prevent us from giving detailed derivations
here.                                                               below; these are given by (Feldman et al., 2009).
                                                                        2 Specifically, if we assume compensation is in S, of the form
                            Model                                            T | ci , k ∼ N(µci , σc ),   S | T, ci , k ∼ N(T + ∆i,k , σS ).
Our rational model for PC effects assumes a simple scenario
                                                                    That is, the distribution of T varies by category, but is not affected
where an idealized optimal listener has to categorize some          by context. Given T , the distribution of S has a mean offset from T
signal as one of two phonetic categories; this is analogous to      by an amount ∆i,k , which depends on the context.
                                                                376

                                                                                        ports the results of a simulation study of PC for anticipatory
        1.0                                                                             vowel-to-vowel coarticulation in English.
                                                          ∆1
        0.8
                                                                                                            A Simulation Study
                    Crossover point (S )
                                       0
                                                                                        A modified replication study of Beddor et al. (2002)’s semi-
                                                                                        nal perception and production study of vowel-to-vowel coar-
        0.6
 P(c1 |S,k)
                                                                                        ticulation in English was conducted. The perceptual results
                                                                                        serve as the observed PC responses. These were compared
        0.4                                                                             to responses predicted by the rational model, using parameter
                                                                                        values obtained from two production studies.
        0.2                                                                             Observed perceptual responses
                                                                                        Eighteen native English speakers at the University of Chicago
        0.0
                           ∆2
                                                                                        participated in a perception experiment, consisting of a train-
                      µ2                   S                   µ1                       ing phase followed by a test phase. The training phase was
                                                                                        intended to expose subjects to speech in which each of V1 =/a/
Figure 1: Schematic of a modeled identification curve. µ1 , µ2                          and V1 =/e/ was equally likely to occur in the context of
are category means, S0 is the crossover point, and ∆1 , ∆2 are                          following V2 =/a/ or V2 =/i/, corresponding to f1 = f2 in our
miscategorization probabilities.                                                        model. The test phase asked listeners to classify an ambigu-
                                                                                        ous vowel V1 as /a/ or /e/, in the context of V2 =/a/ or /i/.
                                                                                           In the training phase, listeners heard CV1 CV2 tokens (C
   Perceptual compensation is thus captured in this model in                            =/p/, /t/, or /k/, V = /e/ or /a/, V2 =/a/ or /i/). Tokens were con-
terms of a shift in the crossover point as a function of the                            structed by splicing together CV syllables produced in isola-
context. Note that if it is assumed that f1 = f2 , S0 is sim-                           tion by an adult male speaker of English. A total of thirty-
ply halfway between the category means, while if category                               six tokens were constructed (=3C×2V1 ×3C×2V2 ). Each
frequencies are not equal ( f1 6= f2 ), S0 is shifted.                                  CV1 CV2 token was heard ten times, for a total of 360 to-
   The shape of the identification curve also changes as sys-                           kens, presented in random order. To encourage attention to
tem parameters are changed. Two important properties of the                             the training stimuli, listeners performed a phoneme monitor-
curve, schematized in Fig. 1, are the slope at the crossover                            ing task where they were asked to identify whether or not
point and the misclassification probabilities at the category                           each token contained a medial /t/.
means.                                                                                     In the test phase, listeners performed a 2AFC categoriza-
   The identification curve’s slope at the crossover point is a                         tion task on V1 in bV1 bV2 context, with V1 varying in F1 -
rough measure of the “degree of uncertainty” (Clayards et al.,                          F3 along an 9-step /a-e/ continuum, and V2 =/a/ or /i/. The
2008) of the category boundary:                                                         nine-step continuum was generated using Akustyk (Plichta
                              dP(c1 | S, k)               µc1 ,k − µc2 ,k               & Preston, 2004), an add-on program for vowel analysis in
              slope at S0 =                           =                                 Praat (Boersma & Weenink, 2001), by interpolating the for-
                                  dS           S=S0       4(σ2S + σ2c )
                                                                                        mant values between two syllables (/ba/ and /be/) produced in
The shallower the slope, the greater the uncertainty. The                               isolation.3 The test tokens were then created by splicing to-
slope is steeper when the difference in category means is                               gether each individual continuum syllable with either a /bi/ or
larger relative to category variances. Unlike the crossover                             a /ba/ syllable, also produced in isolation. The same speaker
point’s location, the slope does not change depending on                                produced the speech stimuli used in both the training and test
whether f1 = f2 .                                                                       phases. Each subject heard each test stimulus ten times, for a
   Categorization uncertainty can also be quantified as the                             total of 180 tokens, presented in random order. Subjects were
misclasssification probabilities ∆1 and ∆2 , defined as the                             paid a nominal fee to participate in the studies.
probability a signal S produced at the mean of category i — a                              Fig. 2 shows empirical curves of the proportion of V1 =/a/
“perfect” exemplar from ci — is misclassified. We find                                  responses in V2 =/a/ and V2 =/i/ contexts, as a function of po-
                                                                                        sition on the V1 continuum. Error bars correspond to 95%
                    f1 (µ1 −µ2 )2 −1                           f2 (µ1 −µ2 )2 −1         confidence intervals over individual-subject proportions.
   ∆1 = (1 +           e 2V )                  ∆2 = (1 +          e 2V )
                    f2                                         f1                          The V1 categorization responses (1=/a/) were modeled us-
                                                                                        ing a mixed-effects logistic regression (Baayen, 2008; Jaeger,
where V = σC 2 + σS 2 . The misclassification probabilities de-
crease as the ratio of the difference in category means to the                              3 The F values of the nine steps along the /a-e/ continuum were
                                                                                                   1
variance increases. When f1 > f2 , ∆1 decreases and ∆2 in-                              713Hz, 682Hz, 635Hz, 606Hz, 592Hz, 563Hz, 522Hz, 500Hz, and
creases (and vice versa for f1 < f2 ).                                                  483 Hz. Values for the higher formants were adjusted as well to
                                                                                        create a more natural-sounding continuum. For simplicity, we focus
   To illustrate the adequacy of the proposed model and its                             on the coarticulatory effect on F1 since the context vowels only vary
treatment of perceptual compensation, the next section re-                              in height and not in backness.
                                                                                  377

2008) with VOWEL CONTEXT (/a/ or /i/) and CONTINUUM
                                                                              Table 1: Model parameters obtained from the production
(1–9) as fixed effects, and random effects of SUBJECT and
                                                                              study, where c1 is “V1 =/a/”, c2 is “V1 =/e/.” B=Bark.
BLOCK (test token number) on the intercept. As a measure of
model quality, Nagelkerke’s pseudo-R2 was 0.64, relative to a                                                   V2      µc1      µc2        σC 2 + σS 2
model with only the intercept. There were significant effects                                                   /a/   6.69 B   4.67 B       0.568 B2
of CONTINUUM and VOWEL CONTEXT (p < 0.001), as well                                                             /i/   6.76 B   4.26 B       0.619 B2
as their interaction (p < 0.05) The effect of VOWEL CON -
TEXT was an increase in V1 =/a/ responses for V2 =/i/ com-
pared to V2 =/a/, in agreement with the results of Beddor et al.              taken to be the mean of µc1 (where c1 is “V1 =/a/”) in V2 =/a/
(2002): native English listeners appear to perceptually com-                  and V2 =/i/ contexts.
pensate for the coarticulatory effects of a following vowel.                     Qualitatively, the fit between the experimental and model-
                                                                              predicted curves in Fig. 2 is very good, without fitting any free
Model-predicted perceptual responses                                          model parameters to the production data. Both experimental
To predict expected identification curves using Eqn. 2, we                    and model curves show a rightward shift for V2 =/a/ context,
need the category means of /a/ and /e/ (V1 ) in the context                   and the predicted slope at the crossover point for both pairs of
of following /a/ or /i/ (V2 ), and category variances for V1                  curves are approximately the same.6 However, the quality of
in V2 =/a/ and V2 =/i/ contexts.4 (Recall that we are assum-                  the fit depends on how rational model parameters are derived
ing equal variances of V1 =/a/ and V1 =/i/, given the following               from the production study, and should be interpreted with
context.) Eqn. 2 also includes the relative probability ( f1 / f2 )           caution. For example, category variances (σC2 + σ2S ) would
of V1 =/a/ and V1 =/i/ in each V2 context. We assume that                     be smaller if based on tokens from a single speaker rather
 f1 / f2 = 1 following the training phase.                                    than several speakers, making the slope of the rational model
    The category mean and variance parameters were esti-                      curves steeper.
mated from two production studies. Category means were
based on 40 productions of the form bV1 bV2 (10 for each
combination of V1 ∈{a,e} and V2 ∈{a,i}) by the speaker
whose speech was the basis of the training and test tokens.
Category variances were calculated from productions of ini-                                               0.8
                                                                               Percentage /a/ responses
tial stressed /adV1 CV2 / sequences (V1&2 =/a/, /e/, or /i/ and
C=/p/ or /b/), each repeated ten times in random order, by
                                                                                                          0.6
four male, phonetically-trained native English speakers. No
                                                                                                                                                          v2
subjects who participated in the perception experiment par-                                                                                                    a
ticipated in the production studies as well.                                                              0.4                                                   i
    We thus assumed that during the experiment, subjects
adjusted their expectation of category means to match the
speaker they were hearing, but that their category variances                                              0.2
reflected variation across speakers.5
    For all production data, formant values were measured at
the midpoint of the target V1 . Means and variances were cal-                                                     2        4            6          8
culated over Bark-transformed F1 values for V1 . Variances                                                              Step Number
for V1 when V2 =/a/ were taken to be the mean of the vari-
ances for /aCa/ stimuli and for /eCa/ stimuli. Variances for V1
                                                                              Figure 2: Dashed lines: Proportion of /a/ responses for V2 =/a/
when V2 =/i/ were calculated similarly. The resulting model
                                                                              (right curve) and V2 =/i/ (left curve) contexts, across all sub-
parameters are listed in Table 1.
                                                                              jects. Error bars are 95% confidence intervals, based on
    The predicted identification curves for V2 =/a/ and V2 =/i/
                                                                              individual-subject proportions. Solid lines: Predicted iden-
contexts are given in Fig. 2. For comparison with the experi-
                                                                              tification curves, based on production data. Dotted line:
mental results, Step 1 was taken to be the mean of µc2 (where
                                                                              Crossover point (rate=0.5).
c2 is “V1 =/e/”) in V2 =/a/ and V2 =/i/ contexts, and Step 9 was
     4 Nearey & Hogan (1986) propose two models for deriving iden-
tification curves from production data. Their ‘NAPP’ model is sim-
                                                                                                                          Discussion
ilar to the present model, but is not derived from an RA viewpoint.           We have illustrated a rational model of perceptual compen-
We also map production data to model parameters differently.
     5 Another interpretation of these category variances, suggested          sation effects and shown that, given a simple probabilistic
by a reviewer, is that subjects assume the tokens have category vari-         model for the observed values of an acoustic-phonetic cue
ances typical of a single speaker, but also account for some “noise”
in perception, beyond the variance observed in the production data               6 The correlation between the two sets of curves is very high (r =
of an individual speaker.                                                     0.987, p < 0.001), indicating good qualitative agreement.
                                                                        378

(here, F1 values) associated with a speech sound, it is possible       most notably Ohala (1993), argue that articulatory and per-
to understand perceptual compensation as an idealized ratio-           ceptual factors shape phonological systems through listener
nal listener arriving at an optimal solution based on evidence         misperception-induced sound changes, and that the syn-
from prior experience. In this model, by choosing the most             chronic typology of sound patterns is a consequence of
probable categorization response given the context, based on           the phonologization of such phonetic “precursors” (Barnes,
their knowledge of the probability distribution of the relevant        2006; Blevins, 2004; Blevins & Garrett, 1998, 2004; Kavit-
cue in that context, listeners appear to ‘undo’ the effect of          skaya, 2001; Yu, 2004). That is, sound change occurs when
coarticulation. Different contexts are associated with differ-         listeners mistake as representative of the speaker’s target pro-
ent cue distributions, and hence difference categorization re-         nunciation the effects of the speakers’ production system, the
sponses.                                                               listeners’ own perceptual system, or ambient distortion of the
   Rational models provide a very general expression of the            acoustic stream. However, this account assumes that errors
computational problem being solved when performing some                in perception (i.e. failure to compensate for contextual varia-
cognitive task, and are largely orthogonal to proposed mech-           tion) lead to adjustments in perceptual and production norms.
anisms by which the task is performed. Our model proposes              The fact that perceptual compensation is observed so robustly
an abstract explanation for why PC occurs, but is compatible           in speech raises questions about the feasibility of this type
with a role for different proposed mechanisms for PC effects           of model of sound change. Earlier work has assumed that
via “prior knowledge” encoded in the cue distributions and             failure to compensate for contextually-induced variation oc-
category frequencies. The model assumes that listeners have            curs when listeners do not detect the conditioning context.
different cue distributions for different contexts, but does not       Our model suggests that the relative magnitude of compen-
specify the source of the distributions; it could be that knowl-       sation can be mediated by properties of the language’s lexi-
edge about gestures or general auditory capabilities generate          con (e.g. the relative frequencies of phones) as well as speak-
or underly the distributions. The category frequencies could           ers’ prior experience with the language (e.g. pronunciation
reflect knowledge of lexical or phonotactic probabilities, as          variation). That is, given certain lexical or contextual con-
pointed out by Feldman et al. (2009).                                  ditions, a change in compensatory response may take place
                                                                       even when the conditioning contextual information is accu-
   The model is able to accommodate two types of PC ef-
                                                                       rately perceived.
fects — language-dependent and domain-general — usually
emphasized in opposing accounts of PC. That PC effects are
language-dependent is expected because many coarticulatory
                                                                                                   Conclusion
effects are language-specific. Since language-specific coar-           The model proposed here allows the incorporation of both
ticulatory effects are reflected in acoustic-phonetic cues, lis-       speech-specific and general auditory factors. It proposes that
teners’ categorization responses should mirror the (language-          perceptual compensation effects emerge as a consequence of
specific) probability distributions of the relevant cues. The          an optimal response to the problem of categorization in the
model is general in that it is not restricted to linguistically-       presence of context-induced variation. To be sure, the present
relevant acoustic cues. As long as a non-linguistic acoustic           model is simplistic, and only a first step toward modeling
cue has a probability distribution, the idealized rational lis-        compensatory phenomena in general. Future work will de-
tener (human or non-human) would seem to compensate in                 velop more general models, e.g. with unequal category vari-
the same way as she would if the acoustic cue were linguis-            ances and multiple (>2) categories, and explore their ef-
tic.                                                                   fects on predicted categorization behavior. Nonetheless, the
   Our model predicts that compensation effects could be               present model contributes to the growing number of studies
ameliorated or even reversed via adjustments to the model              that attempt to understand speech perception from a rational-
parameters. In general, an observed PC effect corresponds to           ist point of view (Clayards et al., 2008; Feldman & Griffiths,
different values of S0 (the crossover point) in different con-         2007; Feldman et al., 2009; Norris & McQueen, 2008).
texts, say k1 and k2 . The second term of (3) predicts that S0 in
k1 and S0 in k2 depend on the relative frequencies of c1 and c2
                                                                       Acknowledgments We thank Matt Goldrick and James
in these contexts. Thus, if f2 / f1 differs significantly by con-
                                                                       Kirby for comments on an earlier version of this paper, Max
text, the context-dependent PC effect can be exaggerated, di-
                                                                       Bane for statistics discussion, and Ed King for setting up the
minished, canceled, or even reversed. Failure to compensate
                                                                       experiment. Part of this work was presented at the 2009 Lin-
could therefore occur for sudden change in f2 / f1 for k1 but
                                                                       guistic Society of America meeting. MS is supported by a
not k2 . Since this proposed effect depends on the second term
                                                                       Department of Education GAANN fellowship.
of (3), compensation could also be undone by changes in vari-
ances (σC2 + σ2S ) or category mean differences (µc1 ,k − µc2 ,k )
                                                                                                    References
for k1 versus k2 . We are currently running experiments to test
the predicted effects of category frequency on compensation.           Anderson, J. (1990). The Adaptive Character of Thought. Hillsdale,
                                                                          N.J.: Erlbaum.
   This understanding of PC failure has serious implications           Baayen, R. (2008). Analyzing linguistic data: A practical introduc-
for current theories of sound change. Many researchers,                   tion to statistics using R. Cambridge: CUP.
                                                                   379

Barnes, J. (2006). Strength and weakness at the interface: Positional     Lotto, A. (2004). Perceptual compensation for coarticulation as
   neutralization in phonetics and phonology. Berlin: Mouton de              a general auditory process. In A. Agwuele, W. Warren, & S.-
   Gruyter.                                                                  H. Park (Eds.), Proceedings of the 2003 Texas Linguistics Society
Beddor, P., Harnsberger, J., & Lindemann, S. (2002). Language-               Conference. Somerville, MA: Cascadilla.
   specific patterns of vowel-to-vowel coarticulation: Acoustic           Lotto, A., & Holt, L. (2006). Putting phonetic context effects into
   structures and their perceptual correlates. Journal of Phonetics,         context: A commentary on Fowler (2006). Perception & Psy-
   30(4), 591–627.                                                           chophysics, 68(2), 178–183.
Beddor, P., & Krakow, R. (1999). Perception of coarticulatory             Lotto, A., & Kluender, K. (1998). General contrast effects in speech
   nasalization by speakers of English and Thai: Evidence for par-           perception: effect of preceding liquid on stop consonant identifi-
   tial compensation. Journal of the Acoustical Society of America,          cation. Perception & Psychophysics, 60(4), 602–19.
   106, 2868–2887.                                                        Lotto, A., Kluender, K., & Holt, L. (1997). Perceptual compen-
Blevins, J. (2004). Evolutionary Phonology. Cambridge: CUP.                  sation for coarticulation by Japanese Quail (Coturnix coturnix
                                                                             japonica). Journal of the Acoustical Society of America, 102,
Blevins, J., & Garrett, A. (1998). The origins of consonant-vowel            1134–1140.
   metathesis. Language, 74(3), 508–56.
                                                                          Mann, V. (1980). Influence of preceding liquid on stop-consonant
Blevins, J., & Garrett, A. (2004). The evolution of metathesis. In           perception. Perception & Psychophysics, 28(5), 407–12.
   B. Hayes, R. Kirchner, & D. Steriade (Eds.), Phonetically-based        Mann, V., & Repp,R B. (1980). Influence of vocalic context on per-
   phonology. Cambridge: CUP.                                                ception of the [ ]-[s] distinction. Perception & Psychophysics,
Boersma, P., & Weenink, D. (2001). Praat, a system for doing                 28(3), 213–28.
   phonetics by computer. Glot International, 5(9/10), 341–345.           Marr, D. (1982). Vision. San Francisco: W.H. Freeman.
Clayards, M., Tanenhaus, M., Aslin, R., & Jacobs, R. (2008).              Mitterer, H. (2006). On the causes of compensation for coarticu-
   Perception of speech reflects optimal use of probabilistic speech         lation: Evidence for phonological mediation. Perception & Psy-
   cues. Cognition, 108, 804–809.                                            chophysics, 68(7), 1227–1240.
Diehl, R., & Kluender, K. (1989). On the objects of speech percep-        Nearey, T., & Hogan, J. (1986). Phonological contrast in experimen-
   tion. Ecological Psychology, 1(2), 121–144.                               tal phonetics: Relating distributions of measurements production
Elman, J., & McClelland, J. (1988). Cognitive penetration of the             data to perceptual categorization curves. In J. Ohala & J. Jaeger
   mechanisms of perception: Compensation for coarticulation of              (Eds.), Experimental phonology. Orlando: Academic Press.
   lexically restored phonemes. Journal of Memory & Language,             Norris, D. (2006). The Bayesian reader: Explaining word recog-
   27(2), 143–165.                                                           nition as an optimal Bayesian decision process. Psychological
Feldman, N., & Griffiths, T. (2007). A rational account of the per-          Review, 113(2), 327–57.
   ceptual magnet effect. In D. McNamara & J. Trafton (Eds.), Pro-        Norris, D., & McQueen, J. (2008). Shortlist B: A Bayesian model
   ceedings of the 29th Annual Cognitive Science Society. Austin,            of continuous speech recognition. Psychological Review, 115(2),
   TX: Cognitive Science Society.                                            357–395.
Feldman, N., Griffiths, T., & Morgan, J. (2009). The influence of         Ohala, J. (1993). The phonetics of sound change. In C. Jones
   categories on perception: Explaining the perceptual magnet effect         (Ed.), Historical linguistics: Problems and perspectives. London:
   as optimal statistical inference. Psychological Review, 116(4),           Longman.
   752–782.                                                               Pardo, J., & Fowler, C. (1997). Perceiving the causes of coartic-
Fowler, C. (1996). Listeners do hear sounds, not tongues. Journal            ulatory acoustic variation: consonant voicing and vowel pitch.
   of the Acoustical Society of America, 99, 1730–1741.                      Perception & Psychophysics, 59(7), 1141–52.
                                                                          Plichta, B., & Preston, D. (2004). Akustyk for Praat (Version 1.7.2)
Fowler, C. (2006). Compensation for coarticulation reflects gesture          [Computer software manual]. East Lansing, MI.
   perception, not spectral contrast. Perception & Psychophysics,
   68(2), 161–177.                                                        Samuel, A., & Pitt, M. (2003). Lexical activation (and other factors)
                                                                             can mediate compensation for coarticulation. Journal of Memory
Fried, L., & Holyoak, K. (1984). Induction of category distributions:        & Language, 48(2), 416–434.
   A framework for classification learning. Journal of Experimental
   Psychology: Learning, Memory, & Cognition, 10(2), 234–257.             Silverman, K. (1987). The structure and processing of fundamen-
                                                                             tal frequency contours. Unpublished doctoral dissertation, Cam-
Holt, L., Lotto, A., & Kluender, K. (2000). Neighboring spectral             bridge University.
   content influences vowel identification. Journal of the Acoustical     Tenenbaum, J., & Griffiths, T. (2001). Generalization, similarity,
   Society of America, 108, 710–722.                                         and Bayesian inference. Behavioral & Brain Sciences, 24, 629–
Hombert, J.-M. (1978). Consonant types, vowel quality, and tone. In          640.
   V. Fromkin (Ed.), Tone: a linguistic survey. New York: Academic        Trommershäuser, J., Gepshtein, S., Maloney, L., Landy, M., &
   Press.                                                                    Banks, M. (2005). Optimal compensation for changes in task-
Jaeger, T. (2008). Categorical data analysis: Away from ANOVAs               relevant movement variability. Journal of Neuroscience, 25(31),
   (transformation or not) and towards logit mixed models. Journal           7169–7178.
   of Memory and Language, 59(4), 434–446.                                Viswanathan, N., Fowler, C., & Magnuson, J. (2009). A critical
Kavitskaya, D. (2001). Compensatory Lengthening: Phonetics,                  examination of the spectral contrast account of compensation for
   phonology, diachrony. Unpublished doctoral dissertation, Uni-             coarticulation. Psychonomic Bulletin & Review, 16(1), 74–79.
   versity of California at Berkeley.                                     Yu, A. (2004). Explaining final obstruent voicing in Lezgian: Pho-
Kawasaki, H. (1986). Phonetic explanation for phonological uni-              netics and history. Language, 80(1), 73–97.
   versals: The case of distinctive vowel nasalization. In J. Ohala       Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference:
   & J. Jaeger (Eds.), Experimental phonology. Orlando: Academic             Analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–
   Press.                                                                    308.
Kingston, J. (1992). The phonetic and phonology of perceptually
   motivated articulatory covariation. Language & Speech, 35, 99–
   114.
Kingston, J., & Diehl, R. (1995). Intermediate properties in the per-
   ception of distinctive feature values. In B. Connell & A. Arvaniti
   (Eds.), Phonology and Phonetic Evidence: Papers in Laboratory
   Phonology IV. Cambridge: CUP.
                                                                      380

