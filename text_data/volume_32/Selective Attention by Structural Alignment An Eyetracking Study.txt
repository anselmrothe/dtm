UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Selective Attention by Structural Alignment: An Eyetracking Study
Permalink
https://escholarship.org/uc/item/2w3479gv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Hoffman, Aaron
Love, Bradley
Markman, Arthur
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

               Selective Attention by Structural Alignment: An Eyetracking Study
                                    Aaron B. Hoffman (aaron.hoffman@mail.utexas.edu)
                                        Department of Psychology, 1 University Station A8000
                                                         Austin, Texas 78712-0187
                                         Bradley C. Love (brad_love@mail.utexas.edu)
                                        Department of Psychology, 1 University Station A8000
                                                         Austin, Texas 78712-0187
                                       Arthur B. Markman (markman@psy.utexas.edu)
                                        Department of Psychology, 1 University Station A8000
                                                         Austin, Texas 78712-0187
                             Abstract                                   Colner, & Hoffman, 2009) and in natural scene perception
  A potential determinant of people’s selective attention is
                                                                        (e.g., Hayhoe, Shrivastava, Mruczek, & Pelz, 2003)
  offered by the structural-alignment view of comparison. This          proposes that the information demands of the task are the
  view holds that objects are compared via structured                   biggest influences on what people selectively attend.
  representations that align sets of features that share relational        In the present study we test the idea that yet another
  roles. A central claim of this account is that the comparison         determinant of people’s selective attention is the
  process directs attention towards alignable features. This            comparisons they make. We will first review comparison
  prediction has been supported by offline measures by                  processes and then evidence from Markman and Gentner
  Markman and Gentner (1997), who showed that alignable
  features serve as better cues for recall than nonalignable            (1997) showing that people have better recall when they are
  features. The present study provides the first online test of the     cued by elements from scenes that are part of structural
  structure-alignment theory’s claim that alignability drives           alignment. Then, by replicating Markman and Gentner
  selective attention. Consistent with this, we show that in            (1997) with an eyetracker, we provide an online test of the
  addition to serving as better cues for recall, alignable              idea that structural alignment can drive selective attention.
  differences are attended more than nonalignable differences.
  Within-trial attention dynamics revealed that attention to            Comparison
  alignable differences increases over the course of the
  comparison process.                                                      The ability to compare is an integral part of human
                                                                        cognition. Category membership is determined by the
  Keywords: comparison, alignment, attention, recall, eye
  movements, eye tracking                                               degree of similarity to category representations (Medin &
                                                                        Schaffer, 1978; Nosofsky, 1984). In problem solving,
                         Introduction                                   people find solutions by comparing new problems to
                                                                        previously solved problems (Chi, Feltovich, & Glaser, 1981;
The amount of information that inundates people’s                       Ross, 1987). In episodic memory, probes are compared to
perceptual systems creates a significant challenge. As                  memory traces (Hintzman, 1986). In analogy people
people move through their environment, they are faced with              compare base and target domains. (Falkenhainer, Forbus, &
thousands of decisions about which information they should              Gentner, 1989; Gentner, 1983; Hummel & Holyoak, 1997)
selectively attend and which they should filter out. They                  There have been a few approaches to modeling the
must decide that certain things are worth remembering and               comparison process, including computing distances in
that others are not. How are such decisions made?                       multidimensional space using feature vectors, (Shepard,
  There are a variety of factors that influence selection of            1962) or comparing features using set operations, Tversky
parts of the stimulus stream. Early work examining how                  (1977). And yet to account for human comparison of
people attend to complex visual scenes showed that people               complex stimuli with relational structure, a third approach
will fixate the most informative elements (Buswell, 1935;               has been used. Borrowing from models of analogy
Mackworth & Morandi, 1967; see Henderson &                              (Falkenhainer et al., 1989), the structure-alignment account
Hollingworth, 1999 for review). Subsequent work explored                (Gentner, 1983) represents objects as features inside
people’s tendency to attend to the most perceptually salient            structures of relations. For example, structure-alignment
features (e.g., Henderson, Weeks, & Hollingworth, 1999;                 theory posits that people will encode features (e.g., the
Parkhurst, Law, & Niebur, 2002). Work on schemata and                   people and objects in Figure 1A) as arguments to relational
memory suggests that semantic consistency with a schema                 predicates: smokes(man, cigar) or paints(painter, model).
determines what is later recalled (Bransford & Johnson,                 On this account, significant processing is applied to building
1972; 1973; Brewer & Dupree, 1983; Rummelhart, 1980).                   a representation of the relations between features in a scene
Finally, recent eye tracking work in categorization (Rehder,
                                                                    2755

or object, and into determining which objects match on the         Gentner (1996) showed that when given a choice, subjects
basis of shared roles.                                             were more likely to select scenes with nonalignable
   With structure alignment, a great deal more information is      differences as being more similar to a base scene than
both represented and processed than what is proposed by            scenes with alignable differences. In a second experiment
simpler accounts. Rather than comparing sets of features           they showed that similarity ratings were more affected by
alone, comparisons are made over features and their                variability in alignable differences than by variability in
relations. To accomplish this, objects with the same               nonalignable differences. Markman and Gentner (1993)
relational role in both scenes are placed in correspondence,       showed that people tend to list more alignable differences
while objects with different roles in their respective scenes      than nonalignable differences.
are not.                                                              In another demonstration of the importance of alignable
                                                                   differences, Markman and Gentner (1997) had subjects rate
Alignable Differences and Attention                                the similarity of ten pairs of scenes, like those in Figure 1.
   Structure alignment has the ability to represent and            Later, subjects were either given probes that were part of an
calculate similarity over structured representations.              alignable or nonalignable difference, as in Figure 2. They
However, this ability comes at a processing cost; the              found that on average, subjects recalled 2.35 pieces of
alignment process must build structurally consistent               information when memory probes were part of an alignable
matches that satisfy parallel connectivity and one-to-one          difference versus just 1.3 when the probes were part of a
mapping. Parallel connectivity requires that matching              nonalignable difference. Thus, across a range of studies,
relations have matching arguments. For example, in Figure          people seemed to place more weight on alignable
1A and 1B, if the photographer is aligned with the painter,        differences.
then the man with the backpack is aligned with the model.             The critical implication of these findings is the idea that
One–to-one mapping states that across representations each         structural alignment can be one of the determiners by which
object can be aligned to at most one other object—the boy          people select relevant aspects of their environment. The
with the backpack cannot also be aligned with the man and          most direct test of this idea is an online measure of people’s
the cigar. Thus, the mapping process in structural alignment       selective attention behavior as they make comparisons.
involves more than simple feature comparisons.
   As a result of the more extensive processing involved in        Eyetracking and Selective Attention
structural alignment, three different kinds of output are             It has been well established that eye movements and
produced (Markman & Gentner, 1993). Whereas the                    selective attention are closely linked. For example, Shepard,
feature-based approaches distinguish only between                  Findlay, and Hockey (1986) demonstrated that although
commonalities (matching features) and differences                  attending without making corresponding eye movements is
(mismatching features), structural alignment produces              possible, it is not possible to make an eye movement
commonalities on one hand, and two types of differences.           without shifting attention. Since high quality visual
Differences that are linked to the commonalities, or               information is acquired only from a limited spatial region
alignable differences, and those that are not, nonalignable        surrounding the fovea, we move our eyes three times each
differences. For example, the female figure in Figure 1A is        second through high-velocity saccades to position the fovea
an alignable difference with the boy in Figure 1B. However,        on what seems important.
the man in the chair is a nonalignable difference, since there        It is no surprise then that eye tracking has enjoyed success
is no corresponding object in 1B. Thus, instead of just two        in numerous research areas that appeal to the construct of
kinds information used in the similarity calculation, the          selective attention. For example, Rehder and Hoffman
structural alignment approach has three.                           (2005a) showed that learning a category corresponded to
   The three types of output allow structure alignment to          abrupt shifts in fixations towards relevant information.
make the unique prediction that comparisons will focus             Later, Rehder and Hoffman (2005b) replicated Medin and
people’s attention on alignable differences. There are two         Schaffer’s (1978) 5-4 category structure with an eye tracker
reasons for this. First, it has been shown that people tend to     and found that fixation times to stimulus dimensions
weigh commonalities more heavily than differences in               matched the decisions weight estimated from behavioral
similarity judgments (Tversky, 1977). Since alignable              responses.
differences are a type of commonality (on the basis of the            More recently, researchers have begun to leverage the
relational structure) they should receive more attention.          flexibility that eye movement analysis offers in terms of
   The second reason for additional focus on alignable             experimental design. It is now possible to examine how
differences is that the entire alignment process is geared         attention is allocated across different kinds of tasks (Rehder,
towards building up relational structure. Since alignable          Colner, & Hoffman, 2009) and across different stimuli and
differences are what compose that structure, they should           categories (Blair, Watson, Walshe, & Maj, 2009). The close
receive a significant amount of attention.                         link between attention and eye movements has been shown
   Over the last decade there has been a growing amount of         across a variety of cognitive tasks (see Liversedge &
evidence that alignable differences in fact receive more           Findlay, 2000 and Rayner, 1998 for reviews).
weight than nonalignable differences. Markman and
                                                               2756

   Of course, the key advantage to using eye tracking for the       differences in subjects’ ability to recall particular objects
present purposes is that it provides an online measure of           from the scenes.
what people attend to during the comparison process. While             Materials The stimuli in the current study were based on
recall behavior, verbal protocols, and similarity ratings all       the Markman and Gentner (1997) materials, but were made
point to the conclusion that alignable differences have a           more suitable for eyetracking by (1) removing unnecessary
greater impact than nonalignable differences on comparison,         textures and (2) increasing the distances between objects to
these are all offline measures. Testing recall performance,         more clearly distinguish which were fixated.
for example, occurs well after the comparison process has              Figure 1 shows an example stimulus. As in the original
taken place. Although offline measures can indicate what            study, there were ten sets of picture triads (one base, and
subjects preferred to encode, they can’t tell us about              two comparison pictures). The base picture had two
processing dynamics as they unfold over time.                       relational scenes within it and each comparison picture
   Finally, one of the key claims of structural alignment is        matched one of the relational scenes. For example, Figure
that the comparison process can help people determine what          1A is a base picture. It contains a portrait relation (the artist
information is worth attending to. If in fact alignable             is painting a portrait of the model on the right), and there is
differences do not receive more attention than nonalignable         a burning-dropping relation on the left (the man is dropping
differences, then the validity of this claim is called into         ash from a lit cigar) on the left. Each comparison matched
question. The present study will provide an online test of          one of the relational scenes. For example, Figure 1B
whether people allocate more attention to alignable features        matches the portrait relation, and Figure 1C matches the
than to nonalignable features.                                      base picture on the burning-dropping relation. On a given
                                                                    trial, the base scene and (one of the) comparison scenes are
                         Experiment                                 presented together on screen. Later, one object from each
   The goal of the present experiment is to use eye tracking        relational structure in the base scene was used as a recall
as a source of data to measure how comparison processes             cue. For example, as shown in Figure 2, the painter and the
direct people’s attention to important pieces of information,       man in the chair from Figure lA were used as recall cues.
and how that in turn relates to recall of that information.            The eye tracker was an SMI Eyelink II, which was set to
According to the structural-alignment approach, the process         track one eye at 250 Hz.
of comparison should lead people to attend to alignable over           Procedure Subjects were first fitted and calibrated to the
nonalignable differences. As a result of this boost in
attention, alignable differences should serve as better cues
for recall later on. To test this, we replicated Markman and
Gentner (1997), using an eyetracker to monitor subjects’
attention allocation. Subjects were fit with a head-mounted
eye tracker and we recorded their eye movements to
alignable and nonalignable differences as they rated the
similarity of ten pairs of scenes.
   The main result of interest is whether subjects tend to
allocate a greater amount of attention to alignable
differences than to nonalignable differences. The structure-
alignment approach predicts that subjects’ fixation times
will be greater on average for alignable differences than for
nonalignable differences. Such a finding supports the idea
that comparison via structural alignment helps focus people
on what’s important in the environment.
   We will also examine how attention to alignable
differences unfolds over the comparison process. Such
dynamics will have implications for models of comparison.
Method
Participants Twenty-eight University of Texas students
participated for course credit. They were tested individually
and assigned to a random order of items. For each item, half
                                                                       Figure 1. Example stimuli. Panel A is the base picture. Panels B
of the subjects saw one comparison scene, and half saw the             and C are the two comparison scenes.
other. At the same time, the assignment of aligned and
nonaligned recall cues to each comparison scene was                 eye tracker. Items (i.e., a pairing of a base and one
counterbalanced across subjects. This designed allowed us           comparison scene) appeared on the screen. At their own
to separate out effects of alignability on attention allocation     pace, subjects rated the similarity of the base picture to the
and memory from any specific object-salience effects, or            comparison picture (on a 1-to-9 scale). Before each item
                                                                2757

   Figure 2. Two example recall cues. Depending on the comparison
   picture, either cue can be an alignable or nonalignable difference.
presentation subjects were asked to fixate a small circle in
                                                                              Figure 3. Example heatmap of fixations to an item, averaged over
the center of the monitor. This was used both as a drift                      subjects for one of the ten items, with comparison scenes. In Panel A
correction and as an indication that they were ready for the                  there are more fixations to the man smoking, but in Panel B, there are
next trial. Subjects recorded their rating by typing one of the               more fixations to the painter and model.
corresponding numbers keys on the keyboard.
   After subjects provided the ten ratings they engaged in a               the scenes. However, the heat maps also show that the
reading task for 30 minutes.                                               allocation of attention is very different depending on which
   During the recall phase subjects were presented with one                comparison scene the subjects saw.
of the recall cues. Half of the recall cues were from                         According to structure-alignment theory, more fixations
alignable differences and the other half were from                         should land near the objects that align with the comparison
nonalignable differences. Subjects’ verbal responses were                  picture. For example, the comparison scene in Figure 3A
recorded by a computer microphone.                                         aligns with the man smoking in the left half of the base
                                                                           picture whereas the comparison scene of Figure 3B aligns
Results                                                                    with the portrait relation on the right hand side of the base
Recall We first set out to test whether we replicated the                  image. In fact, the heat maps in Figure 3 show the result
basic finding from the original Markman and Gentner                        predicted by structural alignment. There are more intense
(1997) study that alignable cues yield better recall than                  and concentrated hot spots over the man in the chair in
nonalignable cues with the revised stimuli. Therefore, we                  Figure 3A, and lesser hot spots over the painter and the
examined the effect that alignability had on subjects’ recall              model. The reverse is true for Figure 3B, there are more
of the scenes, by counting the number of pieces of                         intense hot spots over the painter and the model, and weaker
information recalled from the base scene as a function of                  hot spots over the man in the chair. The heat map presented
whether they received an alignable or nonalignable cue                     in Figure 3 provides a clear illustration of how subjects
during recall. The data were first transcribed from the voice              allocate greater attention allocation to alignable differences
recordings and then rated by a single rater. The instructions              in the scene.
to the rater were that each proposition (adjective, noun, or                  Next, we extended the above analysis to all items. For this
verb) about the scene counted as a piece of information.                   purpose we coded fixations according whether they were to
   The average number of correctly recalled pieces of                      an alignable difference or to a nonalignable difference in the
information for the alignable cues (M = 1.8, SD = 1.2) was                 base picture. We then computed the total fixation time for
reliably greater than the number of pieces of information                  alignable differences across all items, for each subject. The
recalled for the nonalignable cues (M = 1.3, SD = 0.92),                   average total fixation time to alignable differences (M =
t(27) = 2.44, p < .05. The analysis was also carried out by                1473, SD = 814) was greater than that for nonalignable
item, and the result was marginally reliable t(19) = 1.84, p =             differences (M = 1272, SD = 690), t(27) = 2.25, p < .05.
.081. Thus, the basic findings found by Markman and                        (Although item analysis was not statistically reliable t(19) =
Gentner were replicated here.                                              1.2, p = .28., seven out of ten of the items showed the effect
   Fixations For our initial analysis, we constructed heat                 in the expected direction). Thus, as structure-alignment
maps of eye fixations to get a sense for where people were                 predicts, subjects allocated more fixation time to alignable
looking while judging picture similarity. Figure 3 shows                   differences as compared to nonalignable differences.
heat maps of fixations superimposed over one of the items,                    The above results showed that overall, the comparison
with both comparison scenes. To construct these heat maps,                 process engaged by subjects in determining the similarity of
each x-y coordinate of the fixations were weighted by their                two images caused them to fixate alignable differences over
total fixation time and summed over all subjects for each                  nonalignable differences. But how does the comparison
item. The weighted fixation coordinates were then                          process direct attention to important features in a scene, and
processed by a Gaussian kernel density estimator, with                     at what point are people drawn to alignable differences?
bandwidth estimation (Jones, Oliphant, & Peterson, 2001).                  Figure 4 shows the probability of fixating alignable
The red spots of the heat map reflect greater average                      differences, nonalignable differences, and to the comparison
amounts of fixation time, and as a result, where subjects                  scene as a function of time, for ten seconds of the trial.
were attending. Overall, and as expected, in both panels of                   To construct Figure 4 we determined, for each 50-ms
Figure 3 fixations were centered directly over the objects in              interval, whether a subject was fixating one of those three
                                                                       2758

                                                                         comparison and base scenes, attention was allocated to the
                                                                         alignable differences, as predicted.
                                                                            Our results have clear implications for cognitive models.
                                                                         First, mechanisms of comparison need to represent
                                                                         relational structure to explain selective attention behavior
                                                                         towards stimuli with any high level of complexity. Standard
                                                                         models in category learning that contain geometric
                                                                         (Kruschke, 1992) or feature-based (Lee & Navarro, 2002)
                                                                         similarity metrics need to be modified to account for
                                                                         people’s ability to represent and attend to relational
                                                                         semantics.
                                                                            Models that already have the ability to represent relations
                                                                         are consistent with the eye tracking results from the present
                                                                         study. For example, Hummel and Holyoak’s, (1997; 2003)
                                                                         LISA and Larkey and Love’s (2003) CAB models look for
                                                                         surface-feature similarities between items and only later try
   Figure 4. Probability of fixating the aligned, nonaligned, and        to match lower- and higher-order relations. Such mapping
   comparison objects in the scene, as a function of time (seconds).     patterns reflect the selective attention behavior of our
                                                                         subjects because subjects required two seconds on average
locations. We then averaged over all trials and subjects to              to focus primarily on alignable differences.
examine attention allocation over the course of the trial.                  That subjects in our experiment attended differentially to
   The figure shows that as expected, subjects showed no                 objects according to their placement in the relational
immediate preference for the alignable or nonalignable                   structure provides a proof of concept for using eye
differences in the base scene. (The initial preference for the           movements for more detailed tests of computational models,
comparison scene in the first 50 ms reflects that the                    including those that already have the ability to represent
comparison scene was a much larger area of interest than                 relational structure. Additional eyetracking data can be
the individual alignable and nonalignable differences, and               collected to constrain the various components, for example,
there’s a greater baseline chance that eye fixations will                by having people make comparisons over objects that with
happen to be there first.)                                               different levels of relations (e.g., higher order versus lower
   Figure 4 then shows that during the next second, there                order), or by manipulating subjects working memory,
was a dramatic increase in fixations to all three locations,             models’ changes in selective attention can be related
but especially to the comparison scene. In fact, after one               changes in selective attention to humans directly.
second, there is a sudden decrease in fixations to the                      One of the most interesting implications for our results is
alignable and nonalignable differences. Fixations then shift             derived from considering the working memory constraints
from the comparison scene to the alignable differences in                of models like CAB and LISA. Working memory functions
the base picture, until fixations to alignable differences               in such models to constrain the types of relations
peak, at around the two-second mark. After this, fixations               considered. With less working memory only lower-order
gradually dropped off for all locations (as more and more                relations or superficial feature matches will be represented
subjects have already responded), with the most fixations                by the model. This predicts that the details of the relational
allocated to the comparison scene. On average, subjects did              structure that people can maintain will also be influenced by
not allocate more fixations to the nonalignable differences at           working memory constraints. As a result, another potential
any point in the trial.                                                  determiner of what people selectively attend to in a scene is
                                                                         their working memory. If their working memory is
                             Discussion                                  compromised, they will not be able to use relational
   Markman and Gentner’s (1997) result that people have                  structure to guide their selective attention. Thus, the present
greater recall performance when cues are part of alignable               data provide clear predictions for future eyetracking studies.
differences replicated in the present study. These results                  The rich source of data provided by eyetracking was able
were consistent with other previous work showing that                    to confirm predictions of structural alignment and shows
alignable differences have a greater impact than                         promise for constraining and developing more detailed
nonalignable differences on people’s comparison behavior.                processing accounts of existing computational models of
   The main contribution here was that we were able to                   comparison. In addition, there are potential future directions
observe the structural alignment process online. The                     for empirical studies that follow from the present work to
predictions for the eyetracking results, that more fixations             explain how it is that people decide what to selectively
should be allocated to the alignable features obtained. The              attend in an information-rich world.
unfolding of attention allocation over the course of the
comparison process also appeared to make sense. As soon
as subjects allocated a significant amount of attention to the
                                                                     2759

                         References                               Mackworth, N. H., & Morandi, A. J. (1967). The gaze
                                                                    selects informative details within pictures. Perception &
Blair, M. R., Watson, M. R., Walshe, R.C., & Maj, F.
                                                                    Psychophysics,2, 547-552.
  (2009). Extremely selective attention: Eye-tracking
                                                                  Markman, A. B. (1997). Constraints on analogical
  studies on dynamic attentional allocation to stimulus
                                                                    inference. Cognitive Science, 21, 373–418.
  features. Journal of Experimental Psychology: Learning,
                                                                  Markman, A. B. & Gentner, D. (1993). Splitting the
  Memory, and Cognition, 35, 1196-1206.
                                                                    differences: A structural alignment view of similarity.
Bransford, J.D., & Johnson, M.K. (1972). Contextual
                                                                    Journalof Memory and Language, 32, 517–535.
  prerequisites for understanding some investigations of
                                                                  Markman, A. B., & Gentner, D. (1996). Commonalities and
  comprehension and recall. Journal of Verbal Learning
                                                                    differences in similarity comparisons. Memory and
  and Verbal Behavior, 11, 717-726.
                                                                    Cognition, 24, 235–249.
Bransford, J.D., & Johnson, M.K. (1973). Considerations of
                                                                  Markman, A. B., & Gentner, D. (1997). The effects of
  some problems of comprehensioin In W.G. Chase (Eds.),
                                                                    alignabilty on memory. Psychological Science, 8, 363-
  Visual information processing (pp. 383-438).
                                                                    367.
Brewer, W. F. , & Dupree, D. A. (1983). Use of plan
                                                                  Medin, D. L., & Schaffer, M. M. (1978). Context theory of
  schemata in the recall and recognition of goal-directed
                                                                    classification learning. Psychological Review, 85, 207-
  actions. Journal of Experimental Psychology: Learning,
                                                                    238.
  Memory, and Cognition, 9, 117–129.
                                                                  Nosofsky, R. M. (1984). Choice, similarity, and the context
Buswell, G. T. (1935). How people look at pictures: A study
                                                                    theory of classification. Journal of Experimental
  of the psychology of perception in art.Chicago: University
                                                                    Psychology: Learning, Memory, & Cognition, 10, 104-
  of Chicago Press.
                                                                    114.
Chi, M. T. H., Feltovich, P. J., & Glaser, R. (1981).
                                                                  Parkhurst, D., Law, K., & Niebur, E. (2002). Modeling the
  Categorization and representation of physics problems by
                                                                    role of salience in the allocation of overt visual attention.
  experts and novices. Cognitive Science, 5, 121-152.
                                                                    Vision Research, 42, 107–123.
Falkenhainer, B., Forbus, K., & Gentner, D. (1989). The
                                                                  Rayner, K. (1998). Eye movements in reading and
  Structure-Mapping Engine: Algorithm and examples.
                                                                    information processing: 20 years of research.
  Artificial Intelligence, 41, 1-63.
                                                                    Psychological Bulletin, 124, 372-422.
Gentner, D. (1983). Structure-mapping: A theoretical
                                                                  Rehder, B., & Hoffman, A. B. (2005a). Eyetracking and
  framework for analogy. Cognitive Science, 7, 155-170
                                                                    selective attention in category learning. Cognitive
Tversky, A. (1977). Features of similarity. Psychological
                                                                    Psychology, 51, 1-41.
  Review, 84, 327–352.
                                                                  Rehder, B., & Hoffman, A. B. (2005b). Thirty-something
Hayhoe, M., Shrivastava, A., Mruczek, R., & Pelz, J.B.
                                                                    categorization results explained: Selective attention,
  (2003). Visual memory and motor planning in a natural
                                                                    eyetracking, and models of category learning. Journal of
  task. Journal of Vision, 3, 46-63.
                                                                    Experimental Psychology: Learning, Memory, and
Henderson, J, M., & Hollingworth, A. (1999). High-level
                                                                    Cognition, 31, 811-829.
  scene perception. Annual Review of Psychology, 50, 243-
                                                                  Rehder, B., Colner, R.M., & Hoffman, A.B. (2009). Feature
  271.
                                                                    inference learning and eyetracking. Journal of Memory &
Henderson, J, M., Weeks, P.A., & Hollingworth, A. (1999).
                                                                    Language, 60, 394-419
  The effects of semantic consistency on eye movements
                                                                  Rumelhart, D.E. (1980). Schemata: The building blocks of
  during scene viewing. JEP: Human Perception and
                                                                    cognition. In R.J. Spiro, B.C. Bruce, & W.F. Brewer
  Performance, 25, 210-228.
                                                                    (Eds.), Theoretical issues in reading comprehension (pp.
Hintzman, D. L. (1986). “Schema abstraction” in a multiple-
                                                                    33-58). Hillsdale, NJ: Erlbaum.
  trace memory model. Psychological Review, 93, 411-428.
                                                                  Shepherd, M., Findlay, J. M., & Hockey, R. J. (1986). The
Hummel, J. E., & Holyoak, K. J. (1997). Distributed
                                                                    relationship between eye movements and spatial attention.
  representations of structure: A theory of analogical access
                                                                    The Quarterly Journal of Experimental Psychology, 38,
  and mapping. Psychological Review, 104, 427–466.
                                                                    475-491.
Jones, E., Oliphant, T., Peterson, P. and others (2001).
                                                                  Shepard, R. N. (1962). The analysis of proximities:
  SciPy. http://www.scipy.org/SciPy.
                                                                    Multidimensional scaling with an unknown distance
Kruschke, J. K. (1992). ALCOVE: An exemplar-based
                                                                    function, I. Psychometrika, 27, 125-140.
  connectionist model of category learning. Psychological
  Review, 99, 22-44.
Larkey, L.B., & Love, B.C. (2003). CAB: Connectionist
  Analogy Builder. Cognitive Science, 27, 781–794.
Liversedge, S. P., & Findlay, J. M. (2000). Saccadic eye
  movements and cognition. Trends in Cognitive Science, 4,
  6-14.
                                                              2760

