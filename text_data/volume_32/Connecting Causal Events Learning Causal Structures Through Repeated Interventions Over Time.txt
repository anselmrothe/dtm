UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Connecting Causal Events: Learning Causal Structures Through Repeated Interventions Over
Time
Permalink
https://escholarship.org/uc/item/6wk5z3xj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Rottman, Benjamin
Keil, Frank
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Connecting Causal Events: Learning Causal Structures Through Repeated
                                                   Interventions Over Time
                                    Benjamin M. Rottman (benjamin.rottman@yale.edu)
                                          Department of Psychology, Yale U., 2 Hillhouse Ave
                                                           New Haven, CT 06520
                                               Frank C. Keil (frank.keil@yale.edu)
                                          Department of Psychology, Yale U., 2 Hillhouse Ave
                                                           New Haven, CT 06520
                               Abstract                                  the temporal strategy may be common if not a default for
   How do we learn causal structures? All current approaches
                                                                         learning causal structures.
   use scenarios in which trials are temporally independent;                In formal statistics we have developed specialized
   however, people often learn about scenarios unfolding over            procedures for independent cases (e.g., between-subjects)
   time. In such cases, people may assume that other variables           and dependent cases (e.g., repeated-measures, time-series).
   don’t change at the same instant as an intervention. In               Analogously, do people use different learning strategies for
   Experiment 1, participants were much more successful at               the two scenarios? In the following sections we detail the
   learning causal structures when this assumption was upheld            different inferences people might make.
   than violated. In Experiment 2, participants were less
   influenced by such temporal information when they believed
   the trials to be temporally independent, but still used the           Interventions with Independent Trials
   temporal strategy to some extent. People seem to be inclined          Consider first one prominent account of how people learn
   to learn causal structures by connecting events over time.            causal structures from interventions when trials are
   Keywords: causal reasoning; causal structures; time                   independent (e.g., Gopnik et al., 2004; Pearl, 2000; Steyvers
                                                                         et al., 2003). According to this model, when you intervene
                          Introduction                                   upon a variable such that you control its state, that variable
                                                                         is assumed to be independent from its other causes, but its
How do our concepts of event units influence how we learn
                                                                         effects are still dependent on that variable. Consider again
causal structures? Despite the surge of research on causal
                                                                         the example of learning the causal relationships between
structure learning, there has been little attention to how
                                                                         employment (E), GPD (G), and consumption (C). Pretend
learners “connect” streams of information over time.
                                                                         that a priori it is possible that any of these factors could
   Existing theories of how people learn causal structures
                                                                         influence or be influenced by any of the other factors. To
have focused on cases with events considered to be
                                                                         learn the causal structure, one could intervene on each of the
independent. For example, suppose we are trying to learn
                                                                         three variables to determine which other variables are
the causal relationships between three economic variables:
                                                                         influenced by (dependent upon) the intervention.
employment,          GDP,       and     consumption.        Existing
                                                                            Suppose that the true causal structure is a chain; E
psychological theories suggest that one looks at the
                                                                         influences G, which influences C; E→G→C. If we could
relationships among the variables across many separate
countries to determine the causal structure. We call this                institute jobs-creation programs in 10 countries, we would
strategy the independent events strategy because the                     expect them to have high G and C. If, hypothetically, we
countries are assumed to be independent.                                 instituted a mass lay-off of government employees, we
   An alternative approach is to pick one country and follow             would expect comparatively low G and low C. These
the three variables over time. We could track whether GDP                opposite interventions demonstrate how G and C are
goes up when employment goes up, etc. We call this                       dependent on E. If we somehow selectively boosted G for10
strategy the dependent events or temporal strategy because               new countries, they would have high C, but the same E as if
the state of each variable is dependent on its prior state.              we decreased G for 10 other countries; C is dependent on G
   Psychologically, the temporal strategy may be pervasive               but E is not. And if we gave 10 countries a boost in C, and
and perhaps a default. As temporal beings we often perform               another 10 countries a decrease in C, the two countries
or witness sequences of actions on one entity. For example,              should have the same E and G; neither is dependent upon C.
a car mechanic or computer technician can repair different                  If instead the true causal structure is a common cause
components until the problem is solved. A psychotherapist                such that E influences both G and C, G←E→C, we would
can attempt to change one person's beliefs, emotions, and                expect a different pattern of (in)dependence. If we increase
behaviors systematically over time. A physician can                      or decrease G, the respective countries would have the same
intervene on heart rate, breathing, and blood pressure to                levels of E and C because they are independent of G.
stabilize a patient. In many real-world situations we do                    This strategy can identify the precise causal structure
interact with causal systems repeatedly over time, and thus              because each causal structure has a different pattern of
                                                                         (in)dependence when the variables are intervened upon.
                                                                     907

Importantly, however, this strategy requires that the                 However, according to the temporal strategy, the two
observations be independent. This strategy does not look at         orders lead to very different inferences because the useful
whether one country's GDP improves after increasing                 condition upholds the stability assumption but the
employment compared to before (a within-subjects design).           misleading condition violates it. The “useful” condition
It only compares the outcome of countries with increased            suggests the X→Y→Z causal structure. Whenever X is
vs. decreased employment.                                           changed, Y and Z also change (e.g. the transition from Trials
                                                                    1 to 2). Whenever Y is changed, Z also changes, but X stays
Repeated Interventions Over Time                                    the same (e.g., Trials 2-3). When Z changes, X and Y stay
In contrast to the case just described, there are many              the same (e.g., Trials 4-5). In contrast, misleading
scenarios in which a person intervenes repeatedly on one            conditions were designed to suggest the presence of links
entity, and states of variables are fairly stable over time         that do not exist. For example, on Trial 2, Z is changed from
(e.g., car mechanic, physician). Consider a case in which we        1 to 0, and X and Y also change to 0, suggesting that Z
repeatedly intervene to increase or decrease E, G, and C            causes X and Y. Additionally, causal links are not consistent.
within the United States. Suppose that the true causal              On Trial 2, Z appears to cause X and Y to change to 0, but
structure is E→G→C, and initially the country is in a               on Trial 3 it does not cause them to change back to 1.
recession and all three variables are low. If we start a jobs-      Finally, the existence of real links is obscured. For example,
creation program, we would expect G, and C to increase              on Trial 5, X is changed from 0 to 1, but Y is already at 1,
compared to before the intervention. Then, suppose that we          obscuring that X influences Y. In sum, the “misleading”
decreased G. We would expect E to stay high, but C to               condition suggests different links from the "useful"
decrease. Finally, suppose that we encouraged consumption.          condition, and does not clearly identify one causal structure.
We would expect E and G to stay the same. In contrast,                We used this order manipulation in two experiments. In
suppose that the true causal structure is G←E→C. Now, if            Experiment 1, we tested whether people do in fact use the
we increase G, we would expect E and C to stay the same,            temporal strategy. In Experiment 2, we tested whether
but we would expect both to change if we intervened on E.           people appropriately switch between the two strategies
   In sum, if we repeatedly intervene on one entity, we             based on the causal scenario.
expect variables that are not influenced by the intervention
to remain constant. If we intervene upon a variable X, and
another variable Y changes from the previous state, it is a
sign that X causes Y. If Y does not change when X is
manipulated, it is a sign that X does not cause Y. These
inferences are intuitive given the assumption that causes are
generally stable and don’t happen to change at the same
moment that another cause is manipulated. This temporal
assumption of “stability” is analogous to the atemporal
assumption that interventions are independent of other
causes (e.g., Pearl, 2000; see also Rottman & Ahn, 2009a).
Testing Whether People Use the Two Strategies
The temporal strategy is very different from the strategy
appropriate for independent observations. Only in the
temporal case are the changes in variables over time
important for learning causal structure and thus the order of
the trials is critical.
   To determine whether people are sensitive to the temporal
information, we created pairs of data that have the same sets
of 24 intervention trials, but with different trial orders. For
example, consider the chain data in Figure 1. There are three
variables (X, Y, and Z) and two possible values (0, and 1).
Bold represents an intervention. For example, on Trial 1 for
the useful chain condition, X was intervened upon and set to
1. Y and Z consequently have the value 1.
   According to the independent trials strategy, both orders
suggest the chain X→Y→Z. When X is intervened and set to
1, Y and Z are also 1. When Y is set at 1, Z is 1, but X can be
either at 0 or 1 because X is not dependent on Y. Finally, if Z
is set to 1, X and Y could both be 0 or 1 because they are            Figure 1: Summary of Data for Two Causal Structures in
independent of Z.                                                                           Experiment 1.
                                                                908

                       Experiment 1                                  assumed the same value. Exogenous variables had a base-
                                                                     rate of .5. For the common effect structure, the effect was on
In Experiment 1, we created a scenario in which one causal
                                                                     if either of the causes was on.
setup is repeatedly intervened upon over time. Thus
                                                                        For the “useful” conditions, the trials were ordered in a
participants would likely think that the temporal information
                                                                     way that upheld the stability assumption explained in the
was relevant. We presented participants with data generated
                                                                     introduction whereas the “misleading” conditions violated
by five causal structures. For each causal structure, there
                                                                     it. Figure 1 displays a summary of the data for the chain and
was a useful and misleading set of data. If participants use
                                                                     common cause scenarios. The data for the other three causal
the temporal strategy, they will learn the causal structures
                                                                     structures can be obtained from the authors.
more accurately in the useful condition.
                                                                        After each scenario, participants selected the causal
Methods                                                              structure that they believed to have generated the pattern of
                                                                     data for the given scenario (e.g., Figure 2c). Participants
Twenty undergraduates completed the study for payment at             selected arrows indicating the direction of the causal
$10 per hour or partial course credit. Participants first read a     relationships between the three light bulbs. For each pair of
cover story about three light bulbs. Participants were told          bulbs (e.g., X and Y), participants chose between “no
that they would be instructed to turn on or off specific lights      relationship; neither light influences the other”, “X→Y; X
and should try to “learn how each light affects the others.”         influences Y”, “X←Y; Y influences X”, or “X↔Y; X and Y
   Next, participants saw 10 scenarios created by crossing
                                                                     both influence each other.” Participants did not receive
the Order of the Data (useful vs. misleading) × Causal
                                                                     feedback of the accuracy of their causal model. Finally,
Structure (chain, X→Y→Z; common cause, Y←X→Z;                        participants started the next scenario.
common effect, X→Z←Y; one link, X→Y, Z is unrelated; no
links, X, Y, and Z, are unrelated). The 10 scenarios were            Results
ordered in a Latin square grouped by causal structure such
                                                                     Accuracy in causal structure inferences was assessed in the
that each scenario appeared first for some participants.
                                                                     following way. For each pair of bulbs, X and Y, X can cause
                                                                     Y or not, and Y can cause X or not. Thus for each pair of
                                                                     bulbs, participants had the possibility of identifying zero,
                                                                     one, or two correct causal relations. Across the three bulbs
                                                                     in a given scenario, participants had the possibility of
                                                                     identifying zero to six correct causal relations.
                                                                        For all of the five causal structures, participants identified
                                                                     more correct causal relations in the useful than misleading
                                                                     conditions ts(19)>8.32, ps<.01 (Figure 3), suggesting that
                                                                     they used the trial order for learning causal structures.
       Figure 2. Example Screenshots from Experiment 1.
   During each scenario, participants saw three light bulbs.
Each bulb was named by a letter, and different letter triads
were used across the 10 scenarios. Initially, all three bulbs
were off. Then participants were instructed to intervene to
turn on or off specific bulbs (e.g., Figure 2a). To intervene,
participants pressed the key associated with the letter for the
given bulb. After the intervention, participants observed the
outcome of the intervention (which bulbs were on or off) for              Figure 3: Mean Accuracy (Std. Errors) in Experiment 1.
2 seconds (e.g., Figure 2b). Then, while the bulbs were still
visible, instructions appeared for the next intervention.               There are two trends in participants’ mistakes. First, in the
   Each scenario had 24 interventions total, 8 per bulb; 4 on        useful chain condition (X→Y→Z), participants had
and 4 off. The data were determined in the following way.            difficulty learning that Y was a mediator between X and Z.
The causal relations were deterministic; when a bulb was             This requires noticing that when Y is manipulated, X has no
intervened upon, all its effects (and all of their effects)
                                                                 909

influence on Z. Eighteen out of the 20 participants thought                 Next, participants saw eight scenarios. Each scenario
that X also caused Z directly, probably because when X was               presented three hormones. “+” and “-” signs denoted the
turned on and off, Z also changed state. Similar findings                results of the hormones, presence and absence respectively.
have been interpreted to suggest that people sequentially                The eight scenarios were created by crossing Number of
learn individual causal links rather than simultaneously                 Amoebas (one vs. many) × Trial Order (useful vs.
learn an entire causal structure (Fernbach & Sloman, 2009).              misleading) × Causal Structure (common cause, Y←X→Z
   Second, in the misleading conditions, participants                    vs. one link, X→Y, Z is unrelated). The design was entirely
frequently correctly identified true causal links, but they              within subjects. The 8 scenarios were ordered in a Latin
also mistakenly thought that other links existed. They often             square such that each scenario appeared first for some
thought that links were bidirectional, even though they were             participants, and the scenarios were grouped by number of
just unidirectional. In the one link and no link conditions,             amoebas. The trial order and causal structure manipulations
they also frequently inferred relationships between variables            were the same as in Experiment 1, so the following
with no causal relations. These inferences resulted in                   paragraphs focus on the number of amoebas manipulation.
participants often misidentifying the majority of the causal
links; the accuracy in all misleading conditions was below
chance responding of 3, all ts(19)>2.4, ps<.03. However,
these inferences make sense according to the temporal
strategy; the misleading orders were designed so that
variables that were not effects of a manipulated variable
frequently change at the same time as the intervention,
suggesting additional causal relationships.
   In sum, the results strongly suggest that participants were
sensitive to the order of the trials and were using the
transitions between trials to infer causal relationships.
                        Experiment 2
In Experiment 1, it was rational for participants to use a
temporal strategy to learn causal structures because
participants observed entities change over time. The purpose
of Experiment 2 was to determine how flexibly people apply
the temporal vs. independent strategies given different
scenarios. We created two scenarios intended to give
maximal cues to participants that the trials were either
independent (analogous to a between subject design) or
dependent (analogous to a within-subjects design). Previous
studies have successfully used such a manipulation
(Rottman & Ahn, 2009b). We then tested whether
participants would infer different causal structures in useful
vs. misleading orders. If participants use the temporal
strategy for the dependent case, they would be more
accurate in the useful than misleading order, as in
Experiment 1. Additionally, if they do not use temporal
information in the independent scenario, they would not
have different levels of accuracy for the two orders.
Methods                                                                        Figure 4: Example Screenshots from Experiment 2.
Sixteen students from the same population participated.                     The one-amoeba condition, analogous to a within-subjects
   Participants first read a cover study story asking them to            design, emphasized the dependent nature of the data. The
pretend that they are assistants in a biology lab studying               one-amoeba procedures were similar to those in Experiment
hormones in amoebas. They would “produce” or “suppress”                  1; participants repeatedly intervened on one amoeba. While
hormones by injecting chemicals into the amoebas and                     the result of the previous intervention was displayed,
“learn how each hormone affects the others.” They were                   participants were instructed to “PRODUCE” or “INHIBIT”
told that the “hormones work immediately… without any
perceivable delay.”1
                                                                         is produced and suppressed twice in a row, then Hormone B would
                                                                         be produced), which some participants reported in pretesting. In
   1
     This statement about no delay was intended to rule out the          both the dependent and independent conditions, the interventions
possibility of second order causal relationships (e.g., if Hormone A     do work immediately after the intervention key is pressed.
                                                                     910

a specific hormone (e.g., Press “y” to PRODUCE hormone                   not simply transfer the temporal strategy from the one-
y; e.g., Figure 4a). After the intervention, participants                amoeba condition; they were more accurate in the useful
observed the result of the intervention for 2 seconds (e.g.,             than misleading many-amoebas conditions even before
Figure 4b). While the results were visible, instructions for             experiencing the one-amoeba scenarios, t(7)=3.21, p=.02.
the next intervention appeared. Additionally, a picture of
one amoeba was present for the entire scenario to emphasize
the repeated interventions on a single entity over time.
   The many-amoebas condition, analogous to a between-
subjects design, emphasized the independent nature of the
data. Participants made 24 interventions on 24 different
amoebas. After the results of a given intervention were
displayed, participants were instructed to “Press the
spacebar to get the next amoeba” (e.g., Figure 4c). When the
spacebar was pressed, a picture of a new amoeba appeared.
Simultaneously, the results of the intervention on the
previous amoeba (“+” and “-” marks) disappeared (e.g.
Figure 4d). We removed the previous results to make it
perceptually difficult to track the changes of the hormones
over time. Two seconds later, the prompt for the next
                                                                            Figure 5: Mean Accuracy (Std. Errors) in Experiment 2.
intervention appeared (e.g., Press “y” to PRODUCE
hormone y in this amoeba). When the intervention key was
                                                                            There are two other important patterns. First, participants
pressed, the hormone results appeared for the current
                                                                         did worse in the many-amoeba than one-amoeba, useful
amoeba (e.g., Figure 4e). All of these modifications were
                                                                         condition, t(15)=2.57, p=.02. This finding makes sense if
intended to signal that the hormones within one amoeba
                                                                         participants were using the temporal strategy less in the
were independent of the hormones within other amoebas.
                                                                         many-amoebas condition. However, according to the
   After each scenario, participants selected the causal
                                                                         independent trials strategies (e.g., Gopnik et al., 2004;
structure that they believed to have generated the data.
                                                                         Steyvers et al., 2003), participants should have been able to
Results                                                                  correctly identify the causal structures in the many-entity
                                                                         conditions. Second, participants were not even above chance
The dependent variable was the same as in Experiment 1 –                 in the many-amoebas, misleading condition, t(15)<1. Yet
the number of correctly identified causal relations per                  again, participants should have been able to identify the
scenario (zero to six).                                                  correct causal structures according to the independent trials
   A 2 (one vs. many amoebas) × 2 (trial order) × 2 (causal              strategy. The low accuracy in both many-amoebas
structure) repeated-measures ANOVA was performed.                        conditions suggests that participants may have difficulty
There was a main effect of trial order; participants correctly           applying such statistical strategies.
identified more causal relationships in the temporally useful               In sum, participants are able to switch between the
than misleading orders, F(1,15)=45.28, p<.01, ηp2=.75                    temporal vs. independent strategies to some extent based on
(Figure 5). However, the most critical result for this                   knowledge of the learning scenario. However, even in the
experiment is a significant interaction between number of                many-amoebas condition, participants used the temporal
amoebas and trial order, F(1,15)=12.61, p<.01, ηp2=.46.2                 information to some extent, suggesting that it is a common
Though there was a large difference between the useful and               strategy for learning causal structures.
misleading orders for the one-amoeba condition, there was a
smaller difference between the many-amoebas conditions,                                     General Discussion
suggesting that participants were less sensitive to the                  In two experiments, we demonstrated that people learn
temporal order of trials in the many-amoebas condition.                  causal structures very well when entities are repeatedly
This finding makes sense if participants believed that the               manipulated over time (i.e. within-subjects or repeated
trials were independent in the many-amoebas condition.                   measures situations). In Experiment 1, participants were
   However, even though participants used the temporal                   much more accurate at learning causal structures when the
strategy less in the many-amoebas condition, they still used             data were ordered to reflect causes that are stable over time
it to some extent; there was still a significant difference              (don’t happen to change at the moment another variable is
between the useful and misleading, many-amoebas                          intervened upon), a plausible real-world assumption. In
conditions, t(15)=3.59, p<.01. Furthermore, participants did             Experiment 2, participants were less sensitive to the
                                                                         temporal order of trials when they were given reason to
   2
     The only other finding was a marginally significant interaction     believe that the trials were independent (i.e. between-
between causal structure and trial order, F(1,15)=4.03, p<=.06,          subjects situation).
ηp2=.21. The difference between the useful and misleading orders
was slightly larger for the common cause than one link conditions.
                                                                     911

Predominance of the Temporal Strategy                                   The use of a temporal strategy can result in very quick
Why did participants in the many-amoebas condition in                and accurate causal structure learning when the trials are
Experiment 2 still make use of the temporal information to           ordered in a temporally useful way. However, applying an
some extent? There are two possible explanations. First,             incorrect causal strategy can result in substantially worse
people may have still thought that the hormones within               performance. For example, applying a more independent
different amoebas were dependent upon one another. (For              events strategy for events that were truly dependent and
example, if all the amoebas were physically adjacent,                ordered in a useful fashion resulted in considerably worse
perhaps hormones could mix across the amoebas.)                      performance than when participants applied the temporal
Alternatively, people might have been able to learn that the         strategy (Experiment 2). One intriguing possibility is that
trials were dependent from the data itself. In reality, in the       applying the temporal strategy when the events are truly
many-amoebas, useful condition, the order was statistically          independent could also likely result in reduced performance.
dependent. For example, exogenous variables (e.g., X in              Elaborating when and how people apply different learning
X→Y→Z) only changed state when X was intervened upon.                strategies for diverse scenarios is an important future aim.
For long periods of time, X stayed the same (e.g., Trials 2-6
in Figure 1, Chain, Useful) even though its baserate is .5.                              Acknowledgments
   However, there is also a second possibility – the temporal        This research was supported by an NSF Graduate Research
strategy is likely simpler than the statistical strategies           Fellowship (Rottman) and NIH grant R37 HD023922
proposed for independent events (e.g., Gopnik et al., 2004;          (Keil). The authors thank Samuel Tepper for programming,
Steyvers et al., 2003). Thus, it is possible that people tend to     and Rachel Litwin and Brianna Sullivan for data collection.
use this strategy even in cases when the independent
strategy is more appropriate. Perhaps the time-based                                          References
strategy serves as a useful heuristic that is often accurate. In     Burns, P., & McCormack, T. (2009). Temporal information
the real world, much of our causal reasoning involves                   and children’s and adults’ causal inferences. Thinking &
manipulating and observing sequences of events unfolding                Reasoning, 15, 167-196.
over time (e.g., a car mechanic repairing different                  Fernback, P. M. & Sloman, S. A. (2009). Causal learning
components until the problem is solved or a physician                   with local computations. Journal of Experimental
manipulating a patient's heart rate, breathing, and blood               Psychology: Learning, Memory, and Cognition. 35, 678-
pressure to stabilize the patient). Given how frequently we             693.
engage in temporal reasoning, it may be hard to ignore               Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E.,
temporal information such as the order of trials in these               Kushnir, T., & Danks, D. (2004). A theory of causal
experiments even when we should for independent events.                 learning in children: Causal maps and bayes nets.
                                                                        Psychological Review, 111(1), 3-32.
Learning Causal Structure from Temporal Delay                        Lagnado, D. A., & Sloman, S. A. (2004). The advantage of
Lagnado and Sloman (2004, 2006; see also Burns &                        timely intervention. Journal of Experimental Psychology:
McCormack, 2009; Meder et al., 2008; White, 2006)                       Learning, Memory and Cognition, 30 (4), 856-876.
showed how people use temporal delays when learning                  Lagnado, D. A., & Sloman, S. A. (2006). Time as a guide to
causal structures. For example, if you intervene upon X, and            cause. Journal of Experimental Psychology: Learning,
then Y appears, and later Z appears, you would likely infer             Memory and Cognition, 32(3), 451-460.
X→Y→Z. This strategy pertains to the time course of how a            Meder, B., Hagmayer, Y., & Waldmann, M. R. (2008).
causal signal propagates through a network and the order in             Inferring interventional predictions from observational
which the reasoner becomes aware of the states of the                   learning data. Psychonomic Bulletin & Review, 15, 75-80.
nodes. This strategy is entirely consistent with the current         Pearl, J. (2000). Causality: Models, reasoning, and
one, and they likely often work in parallel in the real world.          inference. Cambridge Univ Pr.
However, they are distinct. In the current studies, both of the      Rottman, B. M. & Ahn, W. (2009a). Causal Inference when
non-manipulated variables appear simultaneously for all                 Observed and Unobserved Causes Interact. Proceedings
causal structures. Additionally, in the previous studies (e.g.,         of the 31st Annual Conference of the Cognitive Science
Lagnado & Sloman, 2006), the trials were independent and                Society (pp. 1477-1482).
were often randomized.                                               Rottman, B. M. & Ahn, W. (2009b). Causal Learning about
                                                                        Tolerance and Sensitization. Psychonomic Bulletin and
Summary                                                                 Review, 16, 1043-1049.
Overall, people learn causal structures over time quite              Steyvers, M., Tenenbaum, J. B., Wagenmakers, E., & Blum,
fluently and indeed seem biased to assume that this is the              B. (2003). Inferring causal networks from observations
default mode of causal interpretation. Instead of treating              and interventions. Cognitive Science, 27, 453-489.
trials as independent, which has been assumed by many
approaches of causal structure learning, people weave
together information across trials into larger event units.
                                                                 912

