UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning during Intelligent Tutoring: When Do Integrated Visual-Verbal Representations
Improve Student Outcomes?

Permalink
https://escholarship.org/uc/item/5hd6s0gf

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Butcher, Kirsten
Aleven, Vincent

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Learning during Intelligent Tutoring: When Do Integrated Visual-Verbal
Representations Improve Student Outcomes?
Kirsten R. Butcher (kirsten.butcher@utah.edu)
Department of Educational Psychology, University of Utah, 1705 E. Campus Center Drive, MBH 327
Salt Lake City, UT, 84108 USA

Vincent Aleven (aleven@cs.cmu.edu)
Human Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Avenue
Pittsburgh, PA 15213 USA
of integrated visual-verbal representations for learners.
However, they also raise the question of whether learners
should be provided with integrated visual representations or
if it is better to require learners to generate the integrated
representations themselves.
The question of whether or not to provide students with
integrated visual-verbal representations highlights the
assistance dilemma (Koedinger & Aleven, 2007). The
assistance dilemma refers to the difficulty of deciding when
interactive learning environments should provide vs.
withhold information in order to support optimal student
learning. The assistance dilemma reflects a technologybased application of the long-standing instructional concept
of desirable difficulty (e.g., Bjork, 1994). Desirable
difficulty refers to the finding that increasing the difficulty
of a learning activity can improve long-term knowledge
outcomes, even though performance during training may
suffer. Desirable difficulty argues against a common
assumption that optimal learning is facilitated when
instructional materials are designed to ease student
comprehension and increase successful performance. Thus,
a key question for intelligent tutoring systems using visual
representations is: when should intelligent tutoring systems
provide integrated visual-verbal support vs. withhold this
support in order to optimize student learning outcomes?

Abstract
Research has shown that integration of visual and verbal
information sources during learning promotes successful
student outcomes. However, it is unclear whether it is better
to provide students with integrated visual-verbal
representations, or to require them to build such integrated
representations themselves. In a classroom study, three
conditions were used to explore the impact of integrated
visual-verbal representations that emphasized rule-diagram
mappings in geometry. Students viewed highlighted rulediagram mappings during learning, generated these mappings
themselves, or saw only numerical information embedded in
diagrams (control). Students’ problem-solving knowledge
was measured at posttest and delayed posttest. Overall,
students who generated rule-diagram mappings during
intelligent
tutoring
demonstrated
better
long-term
understanding of geometry principles, but effects were only
visible at delayed posttest. Results show that integrated
visual-verbal representations best support deep learning when
they help the learner make connections between features of a
visual representation and relevant domain information, and
student interactions can be an effective method to scaffold
these connections.
Keywords: Intelligent tutoring; Diagrams; Problem solving;
Long-term retention; Visual representations

Introduction
Research in multimedia learning has demonstrated that
adding visual representations to text materials frequently
improves students’ learning outcomes (e.g., Carney &
Levin, 2002). Studies of cognitive processing with
multimedia materials have demonstrated that visual
materials support learning by increasing students’
generation of effective self-explanations during study
(Ainsworth & Loizou, 2003; Butcher, 2006).
However, not all visual representations are equally
effective in supporting learning. Diagrams have been shown
to be more effective when verbal materials (such as textual
labels for diagrams) are integrated directly into the visual
representation (e.g., Hegarty & Just, 1993) before they are
presented to students. Other research has shown that
student-driven integration of visual and verbal materials
supports learning with complex materials and may promote
goal-oriented behaviors during subsequent, self-directed
learning (Bodemer, Ploetzner, Bruchmüller, & Hacker,
2005). Together, these research results suggest clear benefits

Connecting Diagrams to Domain Knowledge
The assistance dilemma and the concept of desirable
difficulty raise the important question of when to provide
vs. withhold integrated visual-verbal representations for
optimal learning. However, a central question is what type
of integrated representation is most beneficial to learners.
Much of the research on integrated visual representations
has made use of visuals that physically embed additional
information into a visual representation. Multimedia
presentations have been shown to support deeper
understanding of instructional materials when they provide
students with diagrams into which textual labels and
definitions have been embedded (e.g., Hegarty & Just,
1993). In geometry, research has shown that students learn
more when they are provided with representations in which
numerical measures have been integrated into diagrams
(Tarmizi & Sweller, 1988) or when they are provided with
color-coded highlighting that links text references (e.g., a

2888

reference to angle ABC) with relevant diagram elements
(Kalyuga, Chandler, & Sweller, 1999). Overall, research
shows clear benefits for integrated visual-verbal
representations during learning. However, integrated visualverbal representations may not, in and of themselves,
prompt learners to make connections to key domain ideas.
Evidence suggests that individuals with deep domain
understanding tend to exhibit strong connections between
domain concepts and visual representations. For example,
experts in geometry use key diagram configurations to cue
relevant geometry knowledge (i.e., theorems and principles)
during problem solving (Koedinger & Anderson, 1990).
During mathematical problem-solving, mathematicians
repeatedly analyze connections between generated visual
representations, changing goals, and the emerging problem
situation (Stylianou, 2002).
Unlike experts, novices do not demonstrate close
connections between visual representations and domain
knowledge during problem solving. In geometry, novices
tend to process diagrams in isolated ways, focusing on
visual features without considering their relationship to
deeper, conceptual aspects of problems (Lovett & Anderson,
1994). Ainsworth (2006) argues that a central cognitive task
in learning with multiple representations is developing an
understanding of the relationship between a visual
representation and relevant domain information.
One way to support novice learning in geometry, then,
may be to scaffold student interactions with visual
representations in a way that improves their understanding
of the relationship between visual features of geometry
problems (i.e., geometry diagrams) and the geometry
principles/rules used in problem solving. In geometry,
problem solving requires that learners connect meaningful
diagram configurations to relevant geometry principles. For
example, in Figures 2 and 3, angle ABC is an interior angle,
same side to angle BCD. Learners should recognize that the
diagram contains two parallel lines (AB, DC) intersected by
a transversal (BC). Angles ABC and BCD are on the
interior of the parallel lines, and on the same side of the
transversal. Thus, they are interior angles, same side and
can be solved using this rule. In this study, we used
highlighted diagram features to demonstrate the mapping
between diagrams and relevant geometry principles in the
domain (see Figures 2 and 3); hereafter, these are referred to
as diagram-domain representations.

Integrated Diagrams in Intelligent Tutoring
In previous research (Butcher & Aleven, 2007, 2008), we
explored the use of interactive visual diagrams as a method
to support the development of integrated visual-verbal
knowledge during intelligent tutoring in geometry. The
research vehicle for this work was the Geometry Cognitive
Tutor, an intelligent tutoring system (ITS) grounded in
cognitive theory that provides multiple forms of support for
student learning by doing: tracking students’ knowledge
development using a model of student competency,
selecting problems for students to complete that match

identified learning needs, structuring problem-solving steps
for students, giving feedback on all student actions, and
providing hints upon student request or when the student
makes repeated errors. Details about Cognitive Tutor
features are available elsewhere (e.g., Anderson, Corbett,
Koedinger, & Pelletier, 1995).
Butcher and Aleven (2007, 2008) varied the site of
student interaction during geometry problem solving in an
intelligent tutoring system: students used either an
interactive diagram or a solutions table version of the
intelligent tutoring system (see Figure 1). Students using the
interactive diagram tutor clicked directly on diagram
elements to enter answers and receive feedback, thus
creating an integrated representation in which numerical
answers were embedded in the visual representation.
Students in the control condition used the solutions table to
enter their answers and receive feedback. Although the
solutions table kept a running record of students’ answers,
numerical values were not integrated directly into the
diagram. Results showed that students who interacted with
the diagrams to develop an integrated representation learned
geometry principles more deeply (as evidenced by transfer
task performance: Butcher & Aleven, 2007) and retained
their problem-solving skills for longer periods of time
(Butcher & Aleven, 2008).

Figure 1: Condition-based differences in interactions with
an intelligent tutor (Butcher & Aleven, 2007, 2008).
Despite the success of these diagram interactions in an
already-successful intelligent tutoring system, there was still
ample room for student improvement at assessment. It is
possible that diagram interaction helped students focus on
relevant visual elements during problem solving, but the
integrated representations that students developed did not
make it clear how diagram elements mapped onto domain
information.
Student Generation of Integrated Representations
Simply providing students with visual representations that
connect diagrams features to domain information may not
be optimal for learning. Research has shown that requiring

2889

students to actively integrate visual and verbal information
(i.e., using a drag-and-drop interface to produce a labeled
diagram) improves learning outcomes and increases the
quality of students’ self-directed learning behaviors
(Bodemer et al., 2005). However, it is unclear whether
interactions that emphasize diagram-domain mappings
during problem-solving practice can improve learning more
than interactions that build integrated visual-verbal
representations (cf., Butcher & Aleven, 2007, 2008).
The purpose of this study was to explore the potential
benefits of providing students with integrated
representations that emphasized the mapping between
diagram elements and domain information during intelligent
tutoring vs. requiring students to generate these integrated
representations. Both conditions were compared to a control
condition in which students interacted with diagrams to
embed numerical information into the diagrams (i.e., student
interactions
created
an
integrated,
visual-verbal
representation that did not emphasize domain connections).

feedback on each highlighted feature in the diagram.
Incorrect highlights turned red on the diagram and in the
accompanying answer area. Correct highlights were kept on
the screen until the problem-solving step was completed.

Method

Figure 2: In-progress student highlighting of diagram for
interior angles, same side rule. Parallel lines and transversal
have been highlighted so far.

Eighty-three students from five 10th grade geometry
classrooms at a vocational school in rural Pennsylvania
participated in the study as part of their normal classroom
curriculum, which included practice with the Geometry
Cognitive Tutor once a week (one 75 min session per week).
Grade-matched triplets of students were identified within
each class, using students’ first semester geometry grades as
a measure of prior knowledge. From every grade-matched
triplet, one student was randomly assigned to each of the
three experimental conditions described below.

Tutor-Highlighting Condition This condition utilized the
same representations as the student-highlighting condition,
but in this case the tutor provided students with the
highlighted diagram-domain representation. Following a
problem-solving error and student identification of a
relevant geometry principle, the tutor automatically
highlighted the diagram. The screen shot in Figure 3 shows
the result of the tutor highlighting; it is important to note
that the final representations in the student- and tutorhighlighting conditions were equivalent, differing only in
whether the student or tutor generated the representation.

Participants

Materials
Student-Highlighting Condition The purpose of the
student highlighting condition was to require student
interactions with the intelligent tutor that generated
integrated diagram-domain representations during problemsolving practice in the Cognitive Tutor. In this condition, if
a student entered an incorrect answer or reason during
practice, s/he was locked out of the numerical answer field
until s/he identified the correct geometry principle needed to
solve the problem-solving step. Once the correct principle
was identified, students highlighted the diagram features
relevant to that principle (see Figure 2). These highlights
created an integrated diagram-domain representation of the
problem situation. As seen in Figure 2, highlighting was
scaffolded by a list of diagram features that appeared after
students entered a correct geometry principle for a problemsolving step. Students were required to highlight each
diagrammatic feature in the list (e.g., for Interior Angles,
Same Side, students were prompted to highlight the parallel
lines, the transversal, and the two relevant angles).
Students highlighted a diagrammatic feature by clicking
directly on it; students could deselect a highlighted feature
by clicking on it again. Students received immediate

Figure 3: Tutor-highlighted diagram following student error
No Highlighting (Control) The control condition was the
successful interactive-diagram version of the Geometry
Cognitive Tutor from Butcher and Aleven (2007). This
condition did not involve any highlighting of visual diagram
features by either students or the intelligent tutoring system.

2890

However, students entered answers directly into the
geometry diagram; this created an integrated visual-verbal
representation in which numerical values were embedded in
the visual diagram.
Assessments Problem-Solving Pre- and Posttest The
problem-solving pre- and posttest consisted of 16 total
items. For each to-be-solved item, students needed to
provide a numerical answer (e.g., 65º) and the geometry
principle that was used to derive the numerical answer (e.g.,
Vertical Angles). The problem-solving posttest was the
same as the pretest, but problems appeared in a different
order. One point was given for each correctly-solved angle
and correctly-identified principle. Due to a technical error
and student absences, data was collected from 68
participants at pretest and from 70 students at posttest.
Delayed Posttest The delayed posttest was given on the
computer, four weeks following the posttest. The delayed
posttest followed the same format as the pre- and posttest,
but with less complex problems. Students received one
point per correctly-solved angle and correctly-identified
geometry principle, for a maximum of 8 points on each
dependent measure. Due to high numbers of student
absences in the week that the delayed posttest was given
(near the end of the school year), 41 students completed the
delayed posttest.

Procedure
Participants were given up to 30 minutes to complete the
pretest during their geometry class. Pretests were delivered
via computer; students were instructed to try their best to
complete the problems, and to take a guess if they were not
sure of an answer. After completing the pretest, students
worked with their assigned tutor version for four weeks
during a 75-minute, weekly computer lab. This computer
lab was a normal part of the students’ geometry classes, and
all students had used non-experimental versions of the
Geometry Cognitive Tutor during previous sessions in the
computer lab. The Geometry Cognitive Tutor used in each
condition did not differ in problem content, the number of
required problems, or the knowledge models used by the
Cognitive Tutor.
One week after completing the study, students were given
up to 45 minutes to complete the posttest during their
geometry computer lab. A delayed posttest was
administered one month following the posttest. Participants
had up to 30 minutes to complete the delayed posttest.

Results and Discussion
Training Performance
In the Geometry Cognitive Tutor, learners provide a
numerical answer and a geometry principle (aka “rule) that
justifies the numerical answer for each problem-solving
step. Log data from student practice with the Geometry
Cognitive Tutor were analyzed to assess performance on the

first answer and geometry rule attempted by a learner for
each problem step during practice. Data were calculated
only for problem steps that were not given in the problem
statement. That is, data were analyzed only for problem
steps in which students needed to apply a geometry
principle in order to calculate a correct answer. Student
progress in the Geometry Cognitive Tutor was self-paced
and, in general, was slower than anticipated by either the
experimenters or the students’ classroom teachers. Because
the intelligent tutoring system requires mastery learning
before students can continue to the next instructional unit,
not all students completed the three instructional units in the
experimental version of Geometry Cognitive Tutor. In total,
72 students produced tutor log data in unit 1 (control: n =
23, tutor-highlighting: n = 25, student-highlighting: n = 24).
Forty-five students reached unit 2 (control: n = 14, tutorhighlighting: n = 16, student-highlighting: n = 15), but only
27 students reached unit 3 (control: n = 10, tutorhighlighting: n = 8, student-highlighting: n = 9).
Due to the drop in student numbers at each instructional
unit, three multivariate analyses of covariance
(MANCOVAs) were used to assess student performance in
each unit of the tutor. Dependent variables were the percent
correct of students’ initial attempts at numerical answers
and geometry rules for each not-given problem-solving step.
Students’ pretest scores on numerical answers and geometry
rules were used as covariates to control for prior knowledge.
As seen in Figure 4, unit 1 data demonstrated no significant
differences in practice performance on numerical answers or
geometry rules (Fs < 1).
100
95
90
85
80
75
70
65
60
55
50
Answers

Rules
Unit 1

Control

Tutor Highlight

Student Highlight

Figure 4: M (and SE) percent correct for answers and
geometry rules in unit 1 during intelligent tutor practice
Unit 2 also failed to show any significant condition
differences in problem-solving performance on answers or
geometry rules (Fs < 1). For the few students who reached
unit 3, students who interacted with the tutor to generate
integrated diagram-domain representations had a slight,
though non-significant, advantage on numerical answers
(F(2, 22) = 2.7, p < .09). However, as seen in Figure 5, there
were no differences in students’ accuracy in using geometry
rules to justify their problem-solving steps during practice.

2891

70.0

100
95
90
85
80
75
70
65
60
55
50

60.0
50.0
40.0
30.0
20.0
10.0
0.0

Answers

Rules

Answers

Unit 3

Control

Posttest
Student Highlight

Tutor Highlight

Rules

Control

Figure 5: M (and SE) percent correct for answers and
geometry rules in unit 3 during intelligent tutor practice

Tutor Highlight

Student Highlight

Figure 6: M (and SE), adjusted for pretest performance, on
posttest numerical answers and geometry rules.

Problem-Solving Performance
Overall, 33 students completed all three assessments
(control: n = 13, tutor-highlighting: n = 11, studenthighlighting: n = 10). Data were analyzed using a repeatedmeasures MANOVA, where test time (pretest, posttest,
delayed posttest) was the repeated factor.
For numerical answers, results showed no test time by
condition interactions (Linear: F < 1; Quadratic: F(2, 31) =
1.48, p > .24). However, as seen in Table 1, students’
performance on geometry principles showed a significant
test time by condition interaction (Linear: F(2, 31) = 4.97, p =
.01, ηp2 = .24; Quadratic: F(2, 31) = 3.28, p = .05, ηp2 = .18).
Students in the student-highlighting condition were best
able to justify their problem-solving steps with geometry
rules at delayed posttest; however, no differences were seen
at the short-term posttest. Figures 6 and 7 show the pattern
of means on the posttest and delayed posttest, respectively,
adjusted for pretest performance.

One month later, at delayed posttest, the data paint a
different picture Although there were no differences in
students’ accuracy in providing numerical answers at
delayed posttest, students who generated integrated
diagram-domain representations during practice were better
able to justify their problem-solving steps with relevant
geometry rules. It is important to note that this advantage
was found even though control students made use of
integrated diagrams with embedded numerical answers.
Moreover, the advantage cannot be attributed to additional
information in the diagram-domain representations, as
students who were provided with these representations by
the tutor did not outperform the control group in correctly
using geometry rules (see Figure 7).
60.0
50.0
40.0

Table 1: M (and SD) percent correct on geometry rules

30.0

Control
TutorHighlighting
StudentHighlighting

Pretest

Posttest

Delayed
Posttest

18.2 (16. 7)

25.5 (14.3)

19.4 (18.0)

11.1 (10.6)

23.2 (21.2)

17.7 (11.4)

12.4 (7.2)

16.3 (13.6)

31.7 (14.2)

20.0
10.0
0.0
Answers

Rules

Delayed Posttest
Control

As seen in Figure 6, there were no significant condition
differences at posttest. If anything, the pattern of results at
posttest was consistent with a disadvantage for students who
highlighted diagrams during practice. Although this may
seem inconsistent with the overall pattern of performance in
unit 3 during intelligent tutoring practice (see Figure 5), one
should remember that not all students taking the posttest
reached unit 3 in the intelligent tutor.

Tutor Highlight

Student Highlight

Figure 7: M (and SE), adjusted for pretest performance, on
delayed posttest numerical answers and geometry rules.
To confirm results obtained from the small group of
students with full assessment data, two additional analyses
were conducted. First, a MANCOVA was used to assess
performance changes for all 68 students with pre- and
posttest data (control: n = 23, tutor-highlighting: n = 24,
student-highlighting: n = 21). Dependent variables were

2892

performance on numerical answers and geometry rules at
posttest; covariates were students’ performance on answers
and rules at pretest. Results were consistent with the small
sample, showing no condition differences for either
numerical answers or geometry rules (Fs < 1). A second,
similar MANCOVA was conducted for all 41 students with
pre- and delayed posttest data (control: n = 14, tutorhighlighting: n = 13, student-highlighting: n = 14). Results
again were consistent with the small sample, showing a
significant advantage of the student-highlighting condition
for geometry rules (F(2, 36) = 4.04, p = .03, ηp2 = .18), but not
numerical answers (F(2, 36) = 1.38, p > .26).

General Discussion
Overall, results show that providing integrated visual-verbal
materials to students during intelligent tutoring does not
improve students’ learning outcomes. However, findings
show that using interactions to build integrated diagramdomain
representations
can
support
long-term
understanding. Students who generated integrated
representations that emphasized diagram-domain mappings
during problem-solving practice showed no performance
advantages in using geometry principles at practice or
posttest, but were best able to apply these principles one
month following instruction.
Results are consistent with the idea that student
interactions can support deep learning with visual
information. However, results also argue that integrated
visual-verbal representations best support deep learning
when they help the learner make connections between
features of the visual representation and relevant domain
information. The current study shows that student
interactions can be an effective method to scaffold these
connections. Findings also demonstrate the importance of
measuring long-term knowledge gains, as student
performance during practice and short-term assessments
may not provide an accurate picture of deep understanding.

Acknowledgments
The authors thank Octav Popescu, Carl Angiolillo, Michael
Nugent, Grace Leonard, and Thomas Bolster for their
contributions. Special thanks to Mark Schoming and
Colleen Conko for assistance in the classroom. This work
was supported in part by the Pittsburgh Science of Learning
Center through funding from the National Science
Foundation (SBE# 0354420, 0836012). The opinions and
conclusions presented here are those of the authors and do
not necessarily reflect the funding agency.

References
Ainsworth, S. (2006). DeFT: A conceptual framework for
considering learning with multiple representations.
Learning & Instruction, 16(3), 183-198.
Ainsworth, S., & Loizou, A. T. (2003). The effects of selfexplaining when learning with text or diagrams. Cognitive
Science, 27, 669-681.

Anderson, J. R., Corbett, A. T., Koedinger, K. R., &
Pelletier, R. (1995). Cognitive tutors: Lessons learned.
Journal of the Learning Sciences, 4(2), 167-207.
Bjork, R. A. (1994). Memory and metamemory
considerations in the training of human beings. In J.
Metcalfe & A. Shimamura (Eds.), Metacognition:
Knowing about knowing (pp. 185-205). Cambridge, MA:
MIT Press.
Bodemer, D., Ploetzner, R., Bruchmüller, K., & Hacker, S.
(2005). Supporting learning with interactive multimedia
through active integration of representations. Instructional
Science, 33, 73-75.
Butcher, K. R. (2006). Learning From Text With Diagrams:
Promoting Mental Model Development and Inference
Generation. Journal of Educational Psychology, 98(1),
182-197.
Butcher, K. R., & Aleven, V. (2007). Integrating visual and
verbal knowledge during classroom learning with
computer tutors. In D. S. McNamara & J. G. Trafton
(Eds.), Proceedings of the 29th Annual Cognitive Science
Society (pp. 137-142). Austin, TX: Cognitive Science
Society.
Butcher, K. R., & Aleven, V. (2008). Diagram interaction
during intelligent tutoring in geometry: Support for
knowledge retention and deep understanding. In B. C.
Love, K. McRae & V. M. Sloutsky (Eds.), Proceedings of
the 30th Annual Conference of the Cognitive Science
Society (pp. 1736-1741). Austin, TX: Cognitive Science
Society.
Carney, R. N., & Levin, J. R. (2002). Pictorial illustrations
still improve students' learning from text. Educational
Psychology Review, 14(1), 5-26.
Hegarty, M., & Just, M. A. (1993). Constructing mental
models of machines from text and diagrams. Journal of
Memory and Language, 32, 717-742.
Kalyuga, S., Chandler, P., & Sweller, J. (1999). Managing
split-attention and redundancy in multimedia instruction.
Applied Cognitive Psychology, 13(4), 351-371
Koedinger, K. R., & Aleven, V. (2007). Exploring the
assistance dilemma in experiments with cognitive tutors.
Educational Psychology Review, 19(3), 239-264.
Koedinger, K. R., & Anderson, J. R. (1990). Abstract
planning and perceptual chunks: Elements of expertise in
geometry. Cognitive Science, 14(4), 511-550.
Lovett, M. C., & Anderson, J. R. (1994). Effects of solving
related proofs on memory and transfer in geometry
problem solving. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 20(2), 366-378.
Stylianou, D. A. (2002). On the interaction of visualization
and analysis: the negotiation of a visual representation in
expert problem solving. Journal of Mathematical
Behavior, 21, 303-317.
Tarmizi, R. A., & Sweller, J. (1988). Guidance during
mathematical problem solving. Journal of Educational
Psychology, 80(4), 424-436.

2893

