UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning and Generalization of Abstract Semantic Relations: Preliminary Investigation of
Bayesian Approaches
Permalink
https://escholarship.org/uc/item/7fx3p7v8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Chen, Dawn
Lu, Hongjing
Holyoak, Keith
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                     Learning and Generalization of Abstract Semantic Relations:
                              Preliminary Investigation of Bayesian Approaches
                                                   Dawn Chen (sdchen@ucla.edu)
                                                         Department of Psychology
                                                 Hongjing Lu (hongjing@ucla.edu)
                                                 Departments of Psychology and Statistics
                                           Keith J. Holyoak (holyoak@lifesci.ucla.edu)
                                                         Department of Psychology
                                                   University of California, Los Angeles
                                                         Los Angeles, CA 90095 USA
                               Abstract                                  lakes, where the former sentence type contains an
                                                                         antonymous pair (Glass, Holyoak & Kossan, 1977),
  A deep problem in cognitive science is to explain the
  acquisition of abstract semantic relations, such as antonymy           suggesting that some sense of antonymy is available prior to
  and synonymy. Are such relations necessarily part of an                any formal instruction about this concept.
  innate representational endowment provided to humans? Or,
  is it possible for a learning system to acquire abstract relations     The Problem of Relation Learning
  from non-relational inputs of realistic complexity (avoiding
                                                                         Regardless of whether abstract relations are learned or
  hand-coding)? We present a series of computational
  experiments using Bayesian methods in an effort to learn and           mature over the course of development, there is no doubt
  generalize abstract semantic relations, using as inputs pairs of       that adults can distinguish among instances of relations such
  specific concepts represented by feature vectors created by            as antonymy versus synonymy. In the present paper we pose
  Latent Semantic Analysis.                                              the following computational problem: Given as inputs a
   Keywords: Bayesian inference; induction; generalization;              modest number of pairs of concepts that instantiate an
   abstract relations; machine learning; LSA                             abstract relation (e.g., day-night and hot-cold, which
                                                                         instantiate antonymy), is it possible to extract a
                           Introduction                                  representation of the abstract relation that may then be used
                                                                         to accurately classify novel instantiations (e.g., valley-
An intelligent human adult can recognize that the concepts
                                                                         mountain)?
day and night are related in much the same way as hot and
                                                                            Most recent connectionist models of relation learning
cold, but not in the same way as day and hour. This ability
                                                                         (e.g., Rogers & McClelland, 2008) have focused on the
to appreciate abstract semantic relations is fundamental to
                                                                         acquisition of small numbers of specific input-output pairs
analogical reasoning, and is arguably a core component of
                                                                         (e.g., “canary” + “can” → “fly”), but have not demonstrated
what is special about the human mind (Penn, Holyoak &
                                                                         the capacity to generalize to novel inputs dissimilar to the
Povinelli, 2007). But how are such abstract relations
                                                                         training items. In contrast, achieving such generalization is
acquired? If they are learned, how this could be achieved is
                                                                         the central aim of our project. Moreover, an important
far from obvious. On the face of it, no perceptual or other
                                                                         constraint we imposed is that inputs to the learning system
features seem to be available to represent such abstract
                                                                         could not be hand-coded, as has been commonplace in the
relations as antonymy, synonymy, or superordination.
                                                                         literature on computational models of analogy and relation
Almost by default, it might be assumed that abstract
                                                                         learning. For example, Doumas, Hummel, and Sandhofer
relations must be innate (Fodor, 1975).
                                                                         (2008) showed how structured relations corresponding to
  Research on cognitive development has clearly
                                                                         relative adjectives such as bigger-than can be extracted by
established the phenomenon of a relational shift (Gentner &
                                                                         bottom-up mechanisms given inputs consisting of
Rattermann, 1991), such that children process relations
                                                                         unstructured feature vectors of objects. However, the
more effectively with increasing age. In particular, children
                                                                         modelers ensured that “size” features were present among
move from a focus on global similarities of objects to
                                                                         the relatively small feature set defining the inputs, setting
similarities defined by specific dimensions, such as size or
                                                                         the stage for selecting these size features to form a part of
color (Smith, 1989; Smith & Sera, 1992). Less is known
                                                                         the to-be-learned relational predicate. While perceptual
about the development of abstract relations that seem yet
                                                                         relations may indeed be derived from the perceptual features
further divorced from perceptual similarity (see Halford,
                                                                         of objects, this assumption is unwarranted for more abstract
1993). Analyses of corpora of child speech have identified
                                                                         relations, for which hand-coding of features is even more
systematic use of antonyms by children aged 2-5 years
                                                                         problematic. In addition, realistic semantic representations
(Jones & Murphy, 2005). Children aged 6-7 years are more
                                                                         would seem to require very large numbers of features,
accurate in detecting the falsity of sentences such as Some
                                                                         raising all the difficulties associated with search in a large
valleys are mountains as compared to Some valleys are
                                                                     871

representational space. Learning models that are developed            A General Framework for Relation Learning
for small, hand-tailored inputs at best postpone the
                                                                    Here we report a preliminary investigation of relation
challenges of “scaling up”. Another approach to learning
                                                                    learning based on two variants of the same basic framework.
relations is to combine statistical techniques with structured
                                                                    Our goal is to learn an explicit representation of a relation
representations. For example, Kemp and Tenenbaum (2008)
                                                                    from a training set, S, consisting of pairs of concepts that
showed how Bayesian techniques can operate on relational
                                                                    each instantiate the relation. We assume that a decision
structures to learn relational systems such as hierarchies and
                                                                    regarding whether a pair of concepts instantiates a particular
linear orderings. The relational structures are provided to the
                                                                    relation R is determined by a representation that includes
system by including a grammar that generates possible
                                                                    both the basic features of the input concepts and additional
structures. Although this approach may be appropriate for
                                                                    features that the model automatically derives from the basic
relations that have a well-defined logical structure known to
                                                                    features. The full input representation is comprised of the
the modeler, it is not clear that it can readily be extended to
                                                                    basic features of two concepts, A and B, which are
the full range of “messy” semantic relations. In addition,
                                                                    represented by LSA vectors, and of derived features Φ(A,
since the postulated grammar of relations is not itself
                                                                    B) computed from A and B (see Fig. 1). In this study the
learned, rather strong nativist assumptions remain.
                                                                    derived features included two types, product features AB =
Learning Relations from Unstructured Inputs                         [ A1 B1 A2 B2 ⋯ Ad Bd ] and absolute difference features
In this project, we have taken the tack of attempting to             A − B =  A1 − B1 A2 − B2 ⋯ Ad − Bd  , both defined
model the learning of abstract relations through essentially        across corresponding positions in the A and B vectors. The
data-driven statistical learning, using Bayesian algorithms         length of each type of derived vector is thus equal to the
applied to large, unstructured input representations that we        length of each basic vector, so that the total size of the input
the modelers did not create. The raw inputs are vector              vector scales linearly with the number of basic features.
representations of words, derived by Latent Semantic                   If we let X denote the full vector including basic and
Analysis (LSA; Landauer & Dumais, 1997). Such vectors,              derived features, X = [A, B, Φ(A, B)], then the
the product of singular value decomposition applied to              computational goal of relation learning is to estimate the
lexical co-occurrence data from a large corpus of text, have        distribution of a corresponding weight vector w from a set
proved extremely useful in many applications, often serving         of training pairs that share the same relation. That is, we
as good measures of semantic similarity of concepts (Wolf           calculate P ( w | X S , R S = 1) , where the subscript S indicates
& Goldman, 2003). However, LSA vectors do not provide
any direct basis for identifying abstract relations between         the set of training examples (the source) and R S is a set of
concepts (although some modest success has been achieved            binary indicators, each of which (denoted by R) indicates
by exploiting LSA vectors for relation words, such as               whether a particular pair of concepts instantiates the relation
opposite; Mangalath, Quesada & Kintsch, 2004). Related              or not. The vector w constitutes the learned relational
machine-learning algorithms have had some success in                representation, which can be interpreted as attention weights
solving relational analogies by working directly from co-           reflecting the importance of the corresponding features in X.
occurrence data for word combinations found in a large              To test generalization of the learned relational
corpus of text (Turney & Littman, 2005). However, our goal          representation, we test on new transfer pairs, denoted by the
is different in that we aim to model learning of relational         subscript T. The inference step needs to estimate the
representations from the LSA vectors for a small (< 20) set         probability that a target pair shares the same relation as the
of word pairs that instantiate each abstract relation. The task     training pairs, P ( RT = 1| X T , X S , R S = 1) .
of learning relations from representations of simpler
concepts bears at least some resemblance to the task a child
might face in acquiring an abstract relation from a modest-                          A              B          Φ(A, B)
sized set of examples that instantiate it.
   For our present purpose, we do not assume that LSA
provides anything like an optimal psychological
representation of concepts (indeed, it has well-known and
serious limitations, notably problems dealing with lexical                                                             w
ambiguity). However, by using LSA inputs we ensure that                                             R
we have in no way tailored the inputs so as to “hand hold”
the learning algorithms we test. Moreover, we do not
assume that it is in fact possible to acquire human-like            Figure 1: Graphical representation of the general
representations of abstract relations solely by data-driven         framework. A and B denote two vectors of concept features
learning. Rather, by pressing the limits of data-driven             (LSA inputs); Φ(A, B) denotes derived features based on
approaches, we may be able to identify more clearly what            the two concepts, i.e., product features AB and absolute
nativist assumptions may ultimately prove essential.                difference features |A – B|. Vector w represents the
                                                                    unknown relational weights that define R, and is learned
                                                                    using the training set of examples instantiating R.
                                                                872

   The models we consider are both based on Bayesian
logistic regression, as described by Silva, Airoldi and Heller                         A              B           Φ(A, B)
(2007) and Silva, Heller and Gharamani (2007). Given a
small set of word-pairs S that all instantiate a given abstract
relation R, both models compute the posterior probability                                                                                  α
that ( A T , BT ) is an example of the same relation,
                 P( RT = 1 | X T , X S , R S = 1) =                                                   R                     w
                                                                   (1)
                 ∫ P( RT = 1 | X T , w ) P( w | X S , R S = 1)
                  w
where the likelihood is assessed using a logistic regression               Figure 2: Graphical representation of hierarchical model.
function to predict the probability of a word-pair                         Distribution of α is determined by the hyperparameters that
instantiating a given relation,                                            model the variance of the relational weight vector w. The
                  P( R = 1 | X , w ) = logistic(w T X )            (2)     other notations are the same as in Figure 1.
where logistic (x ) = (1 + e − x ) .
                                     −1
                                                                           of the set of positive training cases, and numerous unrelated
   For the first model we consider (based directly on Silva et             pairs as negative cases. An alternative empirical prior could
al., 2007), the posterior distribution for w is found by                   be computed by considering pairs of a specific relation as
applying Bayes’ rule using the prior distribution for w and                positive examples and pairs instantiating other relations as
the training word-pairs:                                                   negative examples. Although empirical priors are a sensible
                                     P( R S = 1 | w, X S ) P ( w )         choice to facilitate inference in the high-dimensional space,
          P( w | X S , R S = 1) =                                  (3)     the question of how the best data set for learning an
                                   ∫ P( R S = 1 | w, X S ) P( w )
                                     w                                     empirical prior could be constructed remains unresolved.
Because of the high dimensionality of the learning problem                   Here we explored a different approach, specifying a
we are tackling, the choice of a good prior P( w ) is                      hierarchical prior on the distribution of the weight vector w
essential to the performance of any model. We investigated                 (see Fig. 2). Specifically, the posterior distribution of w
two kinds of priors, a simple empirical prior proposed by                  learned from training data is derived (replacing Eq. 3) by
Silva and colleagues, and our own hierarchical model.                               P( w | X S , R S = 1) = ∫ P( w | α, X S , R S = 1)P (α )     (6)
                                                                                                                α
The Empirical Prior                                                        where vector α = [α1 , α 2 ,…] determines the precision (the
Intuitively, our simple empirical prior distinguishes word-                inverse variance) of each element of the weight vector w .
pairs that instantiate any of the to-be-learned relations from             We use a conjugate prior distribution in the form of a
unrelated word-pairs. The empirical prior takes the form                   Gamma distribution for α i with two hyperparameters a0
 P( w ) = N ( w; w, ˆ Σˆ ) , in which the sample mean estimate             and b0:
 ŵ is by found by fitting a logistic regression classifier                                      P(α i ) ~ Gamma (α ; a0 , b0 )                  (7)
using maximum-likelihood estimation on a relatively small                    The individual prior for each element in vector w is
set of related word pairs (positive examples), and a larger                assigned in the form of a normal distribution:
set of unrelated word pairs (negative examples), reflecting                                      P( wi | α i ) ~ N ( wi ; 0, α i )               (8)
the fact that most pairs of actual concepts do not instantiate               This normal distribution imposes a general prior that the
any abstract relation. The covariance matrix Σ̂ for this                   value of wi is centered at 0 (i.e., the ith feature dimension is
empirical prior is calculated by                                           not expected to be relevant in predicting whether a certain
                        ( )
                         Σˆ −1 = c ⋅ ( X T MX ) N                  (4)     relation exists between the two words). However, the value
                                                                           of α i controls the certainty about this prior belief. A low
where c is a user-defined smoothing parameter set to twice
the number of related pairs in the training samples, N is the              precision value makes the prior belief uninformative,
total number of word pairs in the training set, and X is a                 whereas a high precision value imposes a strong bias that
matrix containing the features of all (related and unrelated)               wi is most likely 0. Accordingly, the hyperparameters play
word pairs in the training set. M is a diagonal matrix with                an important role in determining the relevance of feature
each entry defined as                                                      dimensions in predicting the existence of a relation.
                         ( M )ii = pˆ (i ) (1 − pˆ (i ) )          (5)       The other term in Eq. (6) can be derived by applying
where pˆ (i ) is the MLE predicted probability of the ith word             Bayes rule directly,
                                                                                                         P (R S = 1 | w, X S ) P( w | α )
pair being related, given by Eq. (2).                                       P( w | α, X S , R S = 1) =                                       (9)
The Hierarchical Prior
                                                                                                        ∫ P ( R S = 1 | w, X S ) P ( w | α )
                                                                                                         w
The above model computes its prior based on the observed
data. This empirical prior uses all related pairs as members
                                                                       873

The Inference Algorithm                                              Table 1: Examples of word pairs used in the training sets
Although the general framework of the relation learning              and generalization tests (correct option on left).
models is straightforward, the inference step is non-trivial
because the calculation of the normalization terms in Eqs.              Training pairs                     Testing pairs
(3) and (9) and integrals in Eq. (6) are intractable, lacking
                                                                       Function
analytic solutions. A sampling approach is impractical for
dealing with high feature dimensionality. We therefore                      door-open              rabbit-hop vs. rabbit-bunny
employed variational methods developed by Jaakkola and                      sun-warm                  cup-drink vs. cup-mug
Jordan (2000) to obtain a closed-form approximation to the                 zoo-animals            smile-happy vs. smile-frown
posterior distribution. Specifically, the variational method
updates the mean of vector w and its covariance matrix V               Synonyms
iteratively:                                                            liberty-freedom                 car-auto vs. car-bus
                  V −1 = a / b + 2∑ λ (ξ n )x n xTn ,                   huge-enormous             weak-feeble vs. weak-strong
                                                                          forest-woods             sad-unhappy vs. sad-sadder
                  w = V ∑ x n / 2,
                           n
                                                                       Linear ordering
                  a = a0 + 1 / 2,                          (10)
                                                                           worse-worst              inch-foot vs. inch-length
                  b = b0 + Ε w ( ww T ) / 2,                                 kitten-cat            rain-downpour vs. rain-fall
                  ξ 2 = xT (V + ww T )x.                                     tap-strike           pebble-rock vs. rock-mineral
                                                                       Antonyms
             Computational Experiments
                                                                           weak-strong          shallow-deep vs. shallow-depth
The Training Set and Generalization Test                                    start-finish             float-sink vs. float-boat
Table 1 shows some examples of pairs of concepts that we                 slowly-quickly              find-lose vs. find-search
used to train and test the two models. We used four different
relations: function, synonyms, linear ordering, and                  Simulation Details
antonyms. For each relation, we chose 15-20 pairs that
were examples of that relation to use as the training set. We        Inputs for each word were LSA vectors of length 300. The
will refer to pairs used for training as AB pairs. All pairs         LSA algorithm orders its features from highest to lowest in
were selected from experimental materials used previously            terms of their predictive power. Preliminary tests indicated
to form four-term verbal analogy problems, and for which             that most of the information useful for our learning models
LSA vectors (derived using the tasaALL corpus) were                  was encoded in the first ten features of the LSA vectors.
available. We selected pairs for which the cosine similarity         Accordingly, we used just these first ten features for each
between the words (based on their LSA vectors) was at least          word as inputs. The full vector for a word pair included the
0.1, aiming to exclude pairs that included highly ambiguous          basic and derived features, X = [A, B, AB, |A – B|], with a
words (e.g., gift-present as an example of synonyms).                total length of 40 features.
After learning representations of the abstract relations based          In the implementation of the model by Silva et al. (2007),
on the AB pairs, the model was tested on a two-alternative           the dataset for computing the empirical prior included all
forced-choice generalization task. For each test item, the           AB word pairs plus a large number (>3500) of unrelated
model was asked to choose which of two alternative pairs             word pairs. Each unrelated word pair was weighted by
instantiated a specified relation. We will refer to correct and      approximately the ratio of the total population of unrelated
incorrect options as CD and CD', respectively. For example,          word pairs to the number of unrelated word pairs that were
one item required the models to decide which pair                    sampled. After obtaining the prior, the model employed
instantiated antonymy, shallow-deep (CD) or shallow-depth            variational methods to compute the posterior distribution for
(CD'). As this example suggests, the discrimination was              w using the AB training pairs for each relation separately.
quite subtle, as the C term was common to both options and              In the simulation of our hierarchical model, the values of
the CD' pair also instantiated an abstract relation (but not the     hyperparameters (a0, b0) were searched separately for each
relation being queried). The words used in this                      relation to maximize generalization performance.
generalization test did not overlap at all with the AB pairs            To provide baselines for evaluating the two Bayesian
used in training, but were selected according to the same            learning models, we applied three simpler methods of
general criteria. For each test problem, the models                  judging the correct relational alternative. First, we
calculated the probability of CD and of CD' being examples           calculated the mean cosine distances of the correct
of the relation, respectively, according to Eq. (1), and chose       alternative and its foil to the training set using “raw” LSA
the pair with the higher probability as the answer. The              vectors, i.e., using only the basic features [A, B] over all
percentage of test questions that each model answered                300 dimensions of the LSA vector for each word in a pair
correctly for each relation was calculated.                          (yielding 600 features total). Specifically, we computed the
                                                                     average of cosine distances between a CD pair and all AB
                                                                 874

pairs in the training set, and for the corresponding CD’ pair     The Importance of the Prior
and all AB pairs. The baseline decision for the                   The improvement in generalization performance of the
discrimination task was determined by which pair yielded          Bayesian models over the MLE logistic regression model
the closer cosine distance. The performance of this method        illustrates the importance of the prior distribution on the
informs us about the amount of information that “raw” LSA         relational weights w. This result suggests the possibility that
vectors provide for the four abstract relations of interest.      children may also benefit from prior knowledge, either
   Second, we used an additional cosine distance measure          innate or acquired through previous experience, when
defined over the same feature vectors as those used by the        learning new abstract relations. They may, for example, first
Bayesian models, i.e., the X vectors, which included the          learn to distinguish related or generally similar concepts
first ten features of the LSA vector for each word, plus the      from unrelated concepts before discriminating among more
corresponding derived features.                                   specific relations. Future experiments could explore the
   Third, we examined the performance of simple logistic          kinds of prior training that best aid human learning of new
regression (which obtains the relational representation w         abstract relations, and compare the results with model
through maximum-likelihood estimation) using the first ten        performance using different priors.
LSA dimensions and the full set of derived features.                 The superior generalization of the Bayesian model using
                                                                  the hierarchical prior compared with the model using the
                 Results and Discussion                           empirical prior indicates that learning can be further
The five modeling methods were evaluated on nine different        improved by introducing a more effective prior. Using the
sets of training pairs and testing pairs. Each set was            general prior knowledge obtained by contrasting related and
randomly chosen from the analogy problems available to us.        unrelated relations is a sensible choice in the applications on
Mean proportion correct over the nine different training/test     which Silver et. al. (2007) focused. However, this empirical
sets for each of the methods described above is shown in          prior may not be sufficient to provide informative guidance
Fig. 3. Overall, the Bayesian model incorporating the             for inferences in the high dimensional space created using
hierarchical prior yielded the best generalization                LSA inputs. Adopting a hierarchical prior increases learning
performance for all four relations, and in each case was          power by incorporating soft constraints on the relational
reliably more successful than any of the three baseline           representation, w, and its associated uncertainty.
models. The proportions correct for the hierarchical model
were .78 for function, .72 for synonyms, .86 for linear           Why are Antonyms so Hard?
ordering, and .66 for antonyms. In general, the                   The fact that the Bayesian models performed relatively
generalization performance for the Bayesian models was            poorly on antonyms warrants further analysis. It should be
best for linear ordering and weakest for antonymy. It should      noted that for antonyms only, the cosine distance method
be noted that the linear ordering relation can be viewed as a     based on 300 LSA dimensions (with basic features only)
generalization of the type of specific comparative relation       outperformed cosine distance based on 10 LSA dimensions
(e.g., “larger than”) to which the learning model proposed        and the full set of derived features. This finding raises the
by Doumas et al. (2007) has been applied.                         possibility that finding a good representation for antonymy
 Figure 3: Simulation results. Prediction accuracy for generalization of relations in the two-alternative forced-choice
 relation-discrimination task. Error bars represent 1 standard error of the mean, based on 9 random samples of training/test
 items.
                                                              875

may require attention to more feature dimensions than is the          University Press.
case for the other relations. Another possible reason for their     Glass, A. L., Holyoak, K. J., & Kossan, N. E. (1977).
greater difficulty is that antonyms are usually very similar          Children’s ability to detect semantic contradictions. Child
concepts that are dissimilar in only a few aspects (e.g., both        Development, 48, 279-283.
love and hate can be used as a noun as well as a verb, and          Halford, G. S. (1993). Children’s understanding: The
are strong emotions that one sentient being can have about            development of mental models. Hillsdale, NJ: Erlbaum.
another). Moreover, the aspects or dimensions on which              Jaakkola, T. S., & Jordan, M. I. (1999). Bayesian parameter
antonymous concepts differ vary from one pair to another              estimation via variational methods. Statistics and
(e.g., love-hate vs. black-white). The shifting relevance of          Computing, 10, 25-37.
features makes learning a good representation for antonyms          Jones, S., & Murphy, M. L. (2005). Using corpora to
challenging, especially using a method that learns weight             investigate antonym acquisition. International Journal of
distributions over a fixed set of features.                           Corpus Linguistics, 10, 401-422.
                                                                    Kemp, C., & Tenenbaum, J. B. (2008). The discovery of
                         Conclusions                                  structural form. Proceedings of the National Academy of
We investigated the possibility that abstract semantic                Sciences, USA, 105, 10687-10692.
relations can be learned at least in part by purely data-driven     Landauer, T. K., & Dumais, S. T. (1997). A solution to
statistical techniques applied to concept pairs represented by        Plato's problem: The Latent Semantic Analysis theory of
unstructured feature vectors. By using LSA vectors as                 the acquisition, induction, and representation of
inputs we avoided any hand-coding of semantics or                     knowledge. Psychological Review, 104, 211-240.
relational structure, while assuring that inputs were of            Mangalath, P., Quesada, J., & Kintsch, W. (2004). Analogy-
realistic complexity. Compared to baseline performance                making as predication using relational information and
(inference based on cosine similarity of test options to the          LSA vectors. In K. D. Forbus, D. Gentner & T. Regier
training set and MLE logistic regression), two models of              (Eds.), Proceedings of the Twenty-sixth Annual Meeting
relation learning based on Bayesian logistic regression               of the Cognitive Science Society. Austin, TX: Cognitive
achieved higher overall performance on a transfer test                Science Society.
requiring discrimination between learned relations                  Penn, D. C., Holyoak, K. J., & Povinelli, D. J. (2008).
instantiated entirely by new concepts. The more successful            Darwin’s mistake: Explaining the discontinuity between
of the two models incorporated hierarchical priors.                   human and nonhuman minds. Behavioral and Brain
   Neither model approached perfect performance on                    Sciences, 31, 109-178.
transfer problems. However, considering the small size of           Rogers, T. T., & McClelland, J. L. (2008). Précis of
the training set (less than 20 examples of each relation), the        Semantic cognition: A parallel distributed processing
total absence of overlap between training and test items, and         approach. Behavioral and Brain Sciences, 31, 689-714.
the relatively subtle discrimination of relations required on       Silva, R., Airoldi, A., & Heller, K. (2007). Small sets of
the generalization test, these preliminary findings are               interacting proteins suggest latent linkage mechanisms
encouraging. Further exploration of statistical approaches to         through analogical reasoning (Tech. Rep. GCNU TR
learning abstract semantic relations appears to be warranted.         2007-001). London: University College London, Gatsby
                                                                      Computational Neuroscience Unit.
                    Acknowledgments                                 Silva, R., Heller, K., & Ghahramani, Z. (2007). Analogical
                                                                      reasoning with relational Bayesian sets. In M. Mella & X.
We thank Walter Kintsch, Tom Landauer and Praful                      Shen (Eds.), Proceedings of the Eleventh International
Mangalath at the University of Colorado Institute of                  Conference on Artificial Intelligence and Statistics.
Cognitive Science for kindly providing us with LSA                  Smith, L. B. (1989). From global similarities to kinds of
vectors. This research was funded by a University                     similarities: The construction of dimensions in
Fellowship and a Chancellor’s Prize from the Graduate                 development. In S. Vosniadou & A. Ortony (Eds.),
Division at the University of California, Los Angeles, and            Similarity and analogical reasoning. Cambridge, UK:
by ONR grant N000140810186.                                           Cambridge University Press.
                                                                    Smith, L. B., & Sera, M. D. (1992). A developmental
                         References                                   analysis of the polar structure of dimensions. Cognitive
Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M.                   Psychology, 24, 99–142.
   (2008). A theory of the discovery and predication of             Turney, P., & Littman, M. (2005). Corpus-based learning
   relational concepts. Psychological Review, 115, 1-43.              of analogies and semantic relations. Machine Learning,
Fodor, J. A. (1975). The language of thought. Cambridge,              60, 251–278.
   MA: Harvard University Press.                                    Wolfe, M. B. W., & Goldman, S. R. (2003). Use of latent
Gentner, D., & Rattermann, M. J. (1991). Language and the             semantic analysis for predicting psychological
   career of similarity. In S. A. Gelman & J. P. Byrnes               phenomena: Two issues and proposed solutions.
   (Eds.), Perspectives on thought and language:                      Behaviour Research Methods, 35, 22-31.
   Interrelations in development. London: Cambridge
                                                                876

