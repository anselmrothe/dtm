UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Joint perception: gaze and beliefs about social context
Permalink
https://escholarship.org/uc/item/9q2717xg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Richardson, Daniel
Street, Chris
Tan, Joanne
Publication Date
2010-01-01
Peer reviewed
  eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                         Joint Perception: Gaze and Beliefs about Social Context
                                           Daniel C. Richardson (dcr@eyethink.org)
                                             Chris N.H. Street (chris@eyethink.org)
                                                  Joanne Tan (tan.yin@ucl.ac.uk)
                                 Cognitive, Perceptual & Brain sciences, University College London
                                                 Gower Street, London WC1E 6BT, UK
                              Abstract                                 symbols. In each set of images, there was one picture with a
                                                                       negative valence (such as crying child), one with a positive
  The way that we look at images is influenced by social
  context. Previously we demonstrated this phenomenon of               valence (a smiling couple) and two neutral images with no
  joint perception. If lone participants believed that an unseen       strong valence. When participants believed that they were
  other person was also looking at the images they saw, it             the only ones currently looking at the images, they looked
  shifted the balance of their gaze between negative and               more at the unpleasant ones. When they thought they were
  positive images. The direction of this shift depended upon           looking jointly with another, they looked more at the
  whether participants thought that later they would be                pleasant images.
  compared against the other person or would be collaborating             Participants in this experiment could not see or interact
  with them. Here we examined whether the joint perception is          with each other. Yet their gaze was systematically shifted if
  caused by beliefs about shared experience (looking at the            they imagined that another person was looking at the same
  same images) or beliefs about joint action (being engaged in
                                                                       stimuli. There have previously been similar demonstrations
  the same task with the images). We place our results in the
  context of the emerging field of joint action, and discuss their     of the influence of social context on social or affective
  connection to notions of group emotion and situated                  responses, for example, that people will smile and laugh
  cognition. Such findings reveal the persuasive and subtle            more if they imagine that a friend elsewhere is currently
  effect of social context upon cognitive and perceptual               watching the same comedy clip as themselves (Fridlund,
  processes.                                                           1991). However, the joint perception result showed that, on
                                                                       a trial-by-trial basis, social context can shape a low level
   Keywords: vision; joint action; eye movements; social
   cognition, situated cognition                                       perceptual/cognitive process.
                                                                          The original experiment was carried out at UC Santa Cruz
                                                                       in the US. A replication was soon performed at University
                          Introduction                                 College London in the UK (Richardson et al., 2009). The
Cognition is enveloped by social context. It is rare that we           same pervasive effect of social context was found. Gaze
use our cognitive or perceptual faculties outside of the world         patterns shifted in response to joint perception. However, in
of social influence, what Allport (1954/1979) described as             this case, when participants believed that they were looking
the real or imagined presence of other people. Yet in                  together, they looked more at the negative images. The
cognitive and perceptual laboratories, we typically place              contrasting US and UK data is shown in the top panel of
participants in experimental quarantine away from the                  Figure 1. What is depicted is the total fixation duration for
confounds of social interaction. The risk of this strategy is          the positive and negative images during joint and alone
that we overlook the ways in which cognitive and perceptual            looking. Each study found a significant interaction between
processes interact with social context.                                picture valence and social context, and between the two
  It is now well demonstrated that social cues such as eye             experiments there was a significant three way interaction,
contact and gaze direction are attended to in fundamentally            showing that the direction of the effect changed.
different ways from non-social stimuli, both in terms of                  Though there were many differences between the
higher-level attentional selection (e.g. Birmingham, Bischof           laboratories’ set up and the participant populations, we
& Kingstone, 2008a, b, 2009; Frischen, Bayliss & Tipper,               hypothesised that an important determinant might be how
2007; Senju & Johnson, 2009) and their different                       participants construed that task. One criticism of the first
neurological subsystems (e.g. Greene et al., 2009; Itier &             study was that participants did not know why they were
Batty, 2009; Ristic, Friesen & Kingstone, 2002). These                 looking at the images, and why the person next door was
studies, and many others, show how perceptual processing               (sometimes) doing the same thing. So, in subsequent
differs for social and non-social stimuli (Cacioppo, Visser &          research in London (Richardson et al., 2009), we repeated
Pickett, 2005).                                                        the experiments but told pairs of participants either that we
  In studies of joint perception, this relationship is turned          would be comparing their picture preferences (comparison
on its head; we keep the stimuli constant and examine how              task), or that they would be collaborating on a memory task
different social cues exert an influence on perceptual                 afterwards (collaboration task). As Figure 2 shows, we
processing. The first demonstration (Richardson, Hoover &              found a pattern of results that mimicked the US / UK
Ghane, 2008) presented participants with a set of four                 differences, and also produced a significant three way
images on screen for eight seconds. On different trials,               interaction. People who thought they were being compared
participants either believed that in a cubicle next door               to each other tended to look at the negative and positive
another participant was looking at the same images, or that            images equally in the joint condition, like the US
the person next door was looking at a set of unrelated                 participants. People who thought that they were
                                                                   290

                                                                             positive                                negative
                                                      /,-)0(1*),!                                                                          /(*0(*!
                                                      California                                                                           London
                              &"""#                                                                          &"""#
   total looking time (ms)                                                         total looking time (ms)
                              %$""#                                                                          %$""#
                              %"""#                                                                          %"""#
                              !$""#                                                                          !$""#
                              !"""#                                                                          !"""#
                                             '()*+#                 ,-(*.#                                                      '()*+#               ,-(*.#
                                       !"#$#"#%&#'(/)--#0.#1(23,4.5#                                                     /.0(12#+.3+4#5!""#$!%#&'()
                                               Comparison task                                                                Collaboration Task
                              &"""#                                                                          &"""#
    total looking time (ms)                                                        total looking time (ms)
                              %$""#                                                                          %$""#
                              %"""#                                                                          %"""#
                              !$""#                                                                          !$""#
                              !"""#                                                                          !"""#
                                             '()*+#                 ,-(*.#                                                      '()*+#               ,-(*.#
                                      Figure 1. Results from Richardson, Hoover and Ghane (2008) and Richardson et al. (2009).
collaborating looked more at the negative images in the joint                                                                            Methods
condition, like the London participants who did not get task                                         Participants
instructions. There could be other reasons, of course, why
the US and UK participants differed, but one plausible                                               32 University College London students (9 male) participated
reason appears to be that in the absence of instructions, they                                       voluntarily or for course credit. Data from 4 participants
interpreted the task in opposite ways. We can only speculate                                         were unusable due to equipment calibration problems.
as to the reason the US participants might felt that they were                                         Note that although we actually ran pairs of participants
being compared (they are academically evaluated more                                                 simultaneously in the lab, their experiments were run and
frequently than UK students), or it might have been that the                                         their data analysed independently from each other. This is
physical setup of the lab (two adjoining cubicles, rather than                                       because participants could not see or interact with each
one big room) engendered a feeling of being contrasted.                                              other during the experiment. In effect, they acted as a mute
   These previous studies have shown that gaze patterns can                                          social context for each other.
by systematically influenced by beliefs about social context,
and that the direction of this influence is sensitive to                                             Procedure
differences in how participants construe their task. In the                                          Participants provided informed consent and then sat in
current experiment, we zoom in to this concept of looking at                                         opposite corners of the laboratory with their backs to each
something ‘together’.                                                                                other, facing their display monitor. They could not see each
   For the joint perception effect to occur, is it enough to                                         other or each other’s display. A brief 9-point calibration was
experience a set of stimuli at the same time as another                                              carried out for each, and then task instructions were
person? Or do participants have to believe that they are                                             presented on screen. Two tasks were defined for the
engaged in the same task as the other person? In this                                                subjects. In the memory task they had to remember as many
experiment, unlike those described above, the participants                                           of the pictures as possible for a later test. In the search task,
always believed that they were looking at the same images                                            they had to look for a translucent X superimposed on one
as each other. What changed, trial-by-trial, was the task that                                       image, and press the mouse button that they held in one
they were doing, and the task that they believed their partner                                       hand if they detected it. They were informed that their task
was doing. Inspired by the seminal work on joint action                                              could change from trial to trial, but that their partner would
(Sebanz, Bekkering & Knoblich, 2006) that we discuss                                                 always be looking at the same pictures as them.
below, we predicted that joint perception effects would be
strongest when participants believed that they were not just
passively sharing an experience, but acting jointly.
                                                                                 291

                                                                  You                 time their gaze was tracked. There was a 1 second interval,
                                                          will be searching.          and then the instructions for the next trial began.
                                                         Your partner will be           There were 40 trials. In half the participant was told that
                                                             memorising               they were to memorise the stimuli and in half they were told
                                                                                      that they were searching for an X. Similarly, they were told
                                                                                      that their partner performed the memory task half the time,
                                                                                      the search task the other half. These task conditions were
                                                                                      counterbalanced so that half the time the participant and
                                                                                      their partner were doing the same task, half a different task.
                                                                                      On eight trials (spread evenly across conditions), an X
                                                                                      appeared at a random location on one of the images.
                                                                                      Stimuli
                              8000ms
                                                                                      Images were taken from the International Affective Picture
                                                                                      System (IAPS), a set of photographs that have been
                                   Figure 2. Trial schematic                          extensively normed on a range of attributes (Lang, Bradley
                                                                                      & Cuthbert, 2005). We chose 40 negative items with
Design                                                                                valence ratings from 1.6 to 2.4 and a mean of 2, 40 positive
                                                                                      items from 7.6 to 8.3 and a mean of 8, and 80 filler items
At the start of each trial, participants were told their task for                     from 4.8 to 5.2 and a mean of 5. For each trial, stimuli were
the upcoming presentation. A large icon at the top of the                             chosen at random from these categories.
screen showed their task (visual search or memory), and a
smaller icon below that showed their partner’s task (Figure                           Apparatus
2). They also heard a voice say “You will be [memorising/
searching]. Your partner will be [memorising/searching]”.                             The stimuli were presented on 19” LCD screen at a distance
   Participants then saw one negative, one positive and two                           of approximately 60cm. Beneath each display was a
filler images in random positions in a 2x2 grid (see Figure                           Bobax3000 remote eye tracker that sampled fixations at 100
2). They were presented for eight seconds, during which                               Hz. iMac computers behind a partition presented the stimuli,
                                                                                      calculated gaze position, and collected the data.
                                                                          Own task
                           $%""#                   search                                           memory
 total looking time (ms)
                           $$""#
                                                                                                                               ()*+,-)#
                           $"""#
                                                                                                                               ./01,-)#
                           !'""#
                           !&""#
                           !%""#
                           !$""#
                           !"""#
                                        same                    different          different                          same
                                                                       Partnerʼs task
                               Figure 3. Looking times showed a significant interaction between valence and whether or not
                                      the participant’s partner was believed to be doing the same or a different task
                                                                                292

                           Results                                  spatial codes) then reaction times increase (Simon, 1969).
                                                                    Sebanz, Knoblich & Prinz (2003) divided such a task
Participants looked more towards the negative images when           between two people. The participants sat next to each other,
they believed that their partner was doing the same task as         and each person responded to one colour: in effect, each
them, regardless of what the task was. We did not analyse           acting as one of the fingers of a participant in Simon’s
the 20% of trials when there was an X present, as X and             (1969) experiment. Though each person had only one
participants’ responses to it would interfere with how they         response to execute, they showed an incompatibility effect
allocated their attention to each image. We calculated the          when acting together. There was no incompatibility effect
total amount of time spent looking at the critical negative         when performing the same single response task alone. When
and positive images on trials where there was not X present.        acting jointly, participants represented their partners’ actions
A 2 (valence: negative/positive) x 2 (own task: memory/             as if they were their own.
search) x 2 (other’s task: same/different) ANOVA was                   Joint action effects do not occur if the participant is
performed, and the means for each cell are displayed in             simply sat next to another person (Tsai et al., 2006), or if
Figure 3. There was a significant two way interaction               that person’s button pressing actions are not intentional
between valence and other’s task (F(1,27)=10.08, p=.004).           (their finger is moved by a mechanical device). Also, if the
Post hoc tests show that the difference between positive and        participant is acting jointly, but with a computer program
negative images was significant when the participants               (Tsai et al., 2008) or a marionette’s wooden hand (Tsai &
believed they were doing the same task (using Tukey’s at            Brass, 2007) there is not a stimulus-response incompatibility
0.01), but did not reach significance when they were doing a        effect. Therefore, participants only form representations of
different task. There was also a main effect of valence (F          another when that person’s genuine, intentional actions are
(1,27)=19.19, p<.0001), but all other main effects and              engaged in the same task.
interactions were non significant (all Fs <1).                         Our results fill out this picture. We have shown that a
                                                                    participant’s perceptual process is changed when they
                    General Discussion                              believe that another person is co-acting with them: they do
The effects of joint perception do not occur simply when            not have to see the person (c.f. Tsai et al., 2008), and the
someone believes that another person is experiencing the            ‘actions’ do not have to be overt behaviour. If the participant
same stimuli as themselves. We have shown that it is                thinks that the other person is memorising or scanning the
necessary that they believe that the other, unseen person is        images together with them, then that mutual cognitive
engaged in the same task as themselves. This task could be          process will shape their gaze patterns.
to memorise the pictures, which presumably would engage
processing something of the meaning of an image, or the             Focal Images
task could just be to search for a visual feature, which            The term ‘focal image’ comes from Schelling (1960) who
requires only superficial processing: regardless, the effect of     found that people were very good at guessing what images
joint perception arises whenever these tasks are believed to        others would find salient. Schelling realised that everyday
be done together. In each case, the effect of this co-              cases of verbal reference are often ambiguous. We say,
engagement is to fixate the negative images more than the           ‘Hand me the fork,’ in the presence of many such items, yet
positive. Below, we discuss other areas of research that            listeners unproblematically infer the same referent. For
throw light on joint perception, and the direction of its           example, when presented with a page full of items, such as
effects in this situation.                                          watches from a catalog, participants agreed with each other
                                                                    which one was most likely to be referred to as ‘the
Joint Action                                                        watch’ (Clark, Schreuder & Buttrick, 1983).
Though the standard cognitive model marginalises social                When we enter into any joint activity, such coordination is
context, there have been notable exceptions. Studies of             all important (Clark, 1996). When we talk, we implicitly
situated cognition (Barsalou, Breazeal & Smith, 2007;               agree upon names for novel objects (Clark & Brennan,
Robbins & Ayded, 2009) show that cognition ‘in the wild’ is         1991), align our spatial reference frames (Schober, 1993),
intimately linked not only to representations of the external       use each others’ syntactic structures (Branigan, Pickering &
world, but also to the cognitive processes of others.               Cleland, 2000), sway our bodies in synchrony (Shockley,
Hutchins (1995) observed the ways that navy navigators              Santana & Fowler, 2003; Condon & Ogston, 1971) and even
distribute cognitive processes between themselves by using          scratch our noses together (Chartrand & Bargh, 1999). We
external tools and representations, such as maps and                also coordinate our gaze patterns with each other
notations.                                                          (Richardson & Dale, 2005), taking into account the
   Recently, experimental methods are starting to reveal the        knowledge (Richardson, Dale & Kirkham, 2007) and the
mechanisms involved in such joint action (Galantucci &              visual context (Richardson, Dale & Tomlinson, 2009) that
Sebanz, 2009; Sebanz, Knoblich & Bekkering, 2006).                  we share. Perhaps participants in our experiment,
Social context can modulate even the simplest of tasks. For         anticipating a future discussion of the stimuli, attempted to
example, in a traditional stimulus-response compatibility           coordinate gaze patterns with their partner when they
task, participants make a judgment about one stimulus               believed they were acting jointly. In other words, they
property (color) and ignore another stimulus property               looked at the pictures they thought another person would
(location). If there is an incompatibility between the              look at: the focal image.
irrelevant property and the response (such as different
                                                                293

Responses to Negative Stimuli                                                         Acknowledgments
Our discussion so far has not touched upon one question:           We are grateful to Merrit Hoover, Arezou Ghane and
why is it that the effect of joint perception is sometimes to      Natasha Eapen for help in designing the experiments,
increase looks to the negative pictures, and sometimes to the      running subjects and for many insightful discussions.
positive images? It seems plausible that participants who
thought that they were being compared to each other might                                  References
want to look equally at the positive and negative images,
since they may feel that ogling a disturbing image might not       Allport, G.W. (1954/1979). The nature of prejudice.
reflect well upon them. However why is it that in the                Cambridge, MA: Perseus Books.
collaborative memory task and the joint visual search tasks,       Barsade, S.G. (2002). The ripple effect: Emotional
the participants looking together tend to look at the negative       contagion and its influence on group behaviour.
images?                                                              Administrative Science Quarterly, 47(4), 644-675.
   We are generally very responsive to unpleasant or               Barsalou, L.W., Breazeal, C., & Smith, L.B. (2007).
threatening things. Negative images are considered more              Cognition as coordinated non-cognition. Cognitive
potent than equivalently-valenced positive images, so much           Processing, 8, 79-91.
so that when combinations of equivalent positively and             Baumeister, R.F., Bratlavsky, E., Finkenauer, C., & Vohs,
negatively valenced stimuli are presented simultaneously             K.D. (2001). Bad is stronger than good, Review of
participants rate the overall set as unpleasant (for reviews,        General Psychology, 5(4), 323-370.
see Baumeister et al., 2001; Lewicka, Czapinski & Peeters,         Birmingham, E., Bischof, W.F., & Kingstone, A. (2008a).
1992; Rozin & Royzman, 2004; Skowronski & Charlston,                 Gaze selection in complex social scenes. Visual
1989). Negative stimuli are likely to receive attention more         Cognition, 16(2/3), 341-355.
quickly (Norris et al., 2004, Smith et al., 2003) and for          Birmingham, E., Bischof, W.F., & Kingstone, A. (2008b).
longer (Hajcak & Olvet, 2008). But why might this bias               Social attention and real world scenes: The roles of
towards negative images be amplified during joint                    action, competition, and social content. Quarterly Journal
perception?                                                          of Experimental Psychology, 61(7), 986-998.
                                                                   Birmingham, E., Bischof, W.F., & Kingstone, A. (2009). Get
Emotion and Social Interaction                                       real! Resolving the debate about equivalent social stimuli.
When people collaborate in groups, they tend to align with           Visual Cognition, 17(6), 904-924.
the group emotion (Barsade, 1998; Hatfield, Cacioppo &             Branigan, H. P., Pickering, M. J., & Cleland, A. A. (2000).
Rapson, 1993; Wageman, 1995). That emotion arises from               Syntactic coordination in dialogue, Cognition, 75, B13-
the majority’s personal disposition for positive or negative         B25.
mood states (George, 1990). Since, as we’ve seen, negative         Cacioppo, J.T., Visser, P.S.& Pickett C.L. (Eds.) (2005).
stimuli are usually attended to more by individuals, when            Social neuroscience: People thinking about thinking
they cooperate together this would serve to amplify the              people. Cambridge, MA: The MIT press.
negativity bias (Taylor, 1991). Affect can influence               Chartrand, T. L., & Bargh, J. A. (1999). The chameleon
behaviour without necessarily having to personally                   effect: The perception-behavior link and social
experience the emotion (Winkielman, Berridge & Wilbarger,            interaction. Journal of Personality and Social Psychology,
2005). In this light, our joint perception phenomenon could          76, 893-910.
be seen as a form of minimal, imagined cooperation that is         Clark, H.H. (1996). Being there: Putting brain, body, and
sufficient to produce an alignment of group emotional                the world together again. Cambridge: MIT Press.
biases.                                                            Clark, H.H., & Brennan, S.E. (1991). Grounding in
                                                                     communication. In L.B. Resnick, J.M. Levine, &
Conclusion                                                           S.D.Teasley (Eds.), Perspectives on Socially Shared
                                                                     Cognition. Washington, DC: American Psychological
How we move our eyes is swayed by a belief that others are           Association
looking at the same scene and thinking the same thing.             Clark, H.H., Schreuder, R. & Buttrick, S., (1983). Common
These results broaden the notion of joint action to include          ground and the understanding of demonstrative reference.
perceptual processes, unseen collaborators and mental                Journal of Verbal Learning and Verbal Behavior, 22,
actions such as remembering and visual search. They also             245-258.
suggest a possible experiment to perform at a poster session.      Condon, W., & Ogston, W. (1971). Speech and body motion
Sidle up to another conference attendee gazing over the              synchrony of the speaker-hearer. In D. Horton & J.
results of an experiment. If our results generalise, a slight        Jenkins (Eds.), The Perception of Language. Columbus,
cough will alert them to your presence, engage their feeling         OH: Charles E. Merrill.
of joint perception and perhaps sway their gaze towards            Fridlund, A.J., (1991). Sociality of Solitary Smiling:
more negative aspects of the poster, demonstrating that an           Potentiation by an Implicit Audience. Journal of
effect of social context can even be found at a cognitive            Personality and Social Psychology, 60, 229-240.
science conference.                                                Frischen, A., Bayliss, A.P., & Tipper, S.P. (2007). Gaze
                                                                     cueing of attention: Visual attention, social cognition, and
                                                               294

   individual differences. Psychological Bulletin, 133(4),       Rozin, P., & Royzman, E.B. (2001). Negativity bias,
   694-724.                                                        negativity dominance, and contagion. Personality and
Galantucci, B., & Sebanz, N. (2009). Joint action: Current         Social Psychology Review, 5(4), 296-320.
   perspectives. Topics in Cognitive Science, 1, 255-259.        Schelling, T. C. (1960). The Strategy of Conflict,
George, J.M. (1990). Personality, affect, and behavior in          Cambridge, Mass.: Harvard University Press.
   groups. Journal of Applied Psychology, 75, 107-116.           Schober, M.F. (1993). Spatial perspective-taking in
Greene, D.J., Mooshagian, E., Kaplan, J.T., Zaidel, E., &          conversation. Cognition, 47(1), 1-24.
   Iacoboni, M. (2009). The neural correlates of social          Sebanz, N., Bekkering, H., & Knoblich, G. (2006). Joint
   attention: Automatic orienting to social and nonsocial          action: Bodies and minds moving together. TRENDS in
   cues. Psychological Research, 73, 499-511.                      Cognitive Sciences, 10(2), 70-76.
Hajcak, G., & Olvet, D.M. (2008). The persistence of             Sebanz, N., Knoblich, G., & Prinz, W. (2003). Representing
   attention to emotion: Brain potentials during and after         others’ actions: Just like one’s own? Cognition, 88(3),
   picture presentation. Emotion, 8(2), 250-255.                   B11-B21
Hatfield, E., Cacioppo, J.T., & Rapson, R.L. (1993).             Senju, A., & Johnson, M.H. (2009). Atypical eye contact in
   Emotional contagion, Current Directions in                      autism: Models, mechanisms and development.
   Psychological Science. 2(3), 96-99.                             Neuroscience and Biobehavioral Reviews, 33(8),
Itier, R.J, & Batty, M. (2009). Neural bases of eye and gaze       1204-1214.
   processing: The core of social cognition. Neuroscience        Shockley, K., Santana, M-V., & Fowler, C.A. (2003).
   and Biobehavioral Reviews, 33, 843-863.                         Mutual interpersonal postural constraints are involved in
Knoblich, G., & Sebanz, N. (2006). The social nature of            cooperative conversation. Journal of Experimental
   perception and action. Current Directions in                    Psychology: Human Perception and Performance, 29(2),
   Psychological Science, 15(3), 99-104.                           326-332
Lang, P.J., Bradley, M.M., & Cuthbert, B.N. (2005).              Simon, J.R. (1969). Reactions toward the source of the
   International affective picture system (IAPS): Digitized        stimulation. Journal of Experimental Psychology, 81(1),
   photographs, instruction manual, and affective ratings          174-176.
   (Tech. Rep. A-6). Gainesville: University of Florida,         Skowronski, J.J., & Carlston, D.E. (1989). Negativity and
   Center for Research in Psychophysiology                         extreme biases in impression formation: A review of
Lewicka, M., Czapinsky, J., & Peeters, G. (1992). Positive-        explanations. Psychological Bulletin, 105(1), 131-142.
   negative asymmetry or ‘When the heart needs a reason’.        Smith, N.K., Cacioppo, J.T., Larsen, J.T., & Chartrand, T.L.
   European Journal of Social Psychology, 22, 425-434.             (2003). May I have your attention, please: Electrocortical
Norris, C.J., Chen, E.E., Zhu, D.C., Small, S.L., &                responses to positive and negative stimuli.
   Cacioppo, J.T. (2004). The interaction of social and            Neuropsychologia, 41, 171-183.
   emotional processes in the brain. Journal of Cognitive        Taylor, S.E. (1991). Asymmetrical effects of positive and
   Neuroscience, 16(10), 1818-1829.                                negative events: The mobilization-minimization
Richardson, D.C & Dale, R. (2005). Looking to understand:          hypothesis. Psychological Bulletin, 110(1), 67-85.
   The coupling between speakers’ and listeners’ eye             Tsai, C-C., Kuo, W-J., Hung, D.L., & Tzeng, O. J-L. (2008).
   movements and its relationship to discourse                     Action co-representation is tuned to other humans.
   comprehension. Cognitive Science, 29, 1045–1060.                Journal of Cognitive Neuroscience, 20(11), 2015-2024.
Richardson, D.C, Hoover, M.A. & Ghane, A. (2008). Joint          Tsai, C-C., Kuo, W-J., Jing, J-T., Hung, D.L., & Tzeng, O.
   perception: gaze and the presence of others. Proceedings        J-L. (2006). A common coding framework in self-other
   of the 30th Annual Conference of the Cognitive Science          interaction: Evidence from joint action task. Experimental
   Society (pp. 309-314). Austin, TX: Cognitive Science            Brain Research, 175, 353-362.
   Society.                                                      Tsai, C.-C., & Brass, M. (2007). Does the human motor
Richardson, D.C., Dale, R., & Kirkham, N.Z. (2007). The            system simulate Pinocchio’s actions? Co-acting with a
   art of conversation is coordination: Common ground and          human hand versus a wooden hand in a dyadic
   the coupling of eye movements during dialogue.                  interaction. Psychological Science, 18(12), 1058-1062.
   Psychological Science, 18(5), 407-413.                        Wageman, R. (1995). Interdependence and group
Richardson, D.C., Dale, R., & Tomlinson, J.M. (2009).              effectiveness. Administrative Science Quarterly, 40,
   Conversation, gaze coordination, and beliefs about visual       145-180.
   context. Cognitive Science, 33(8), 1468-1482.                 Winkielman, P., Berridge, K.C., & Wilbarger, J.L. (2005).
Richardson, D.C., Hoover, M.A. Ghane, A. Eapen, N. &               Unconscious affective reactions to masked happy versus
   Tan, J. (2009). Joint perception across tasks: gaze and         angry faces influence consumption behavior and
   social cognition. Proceedings of the 31st Annual                judgments of value. Personality and Social Psychology
   Conference of the Cognitive Science Society (pp. 66-72).        Bulletin, 31(1), 121-135.
   Austin, TX: Cognitive Science Society                         Robbins, P. & Aydede, M. (Eds.) (in press). The Cambridge
Ristic, J., Friesen, C.K., & Kingstone, A. (2002). Are eyes        Handbook of Situated Cognition. Cambridge, UK:
   special? It depends on how you look at it. Psychonomic          Cambridge University Press.
   Bulletin & Review, 9(3), 501-513.                             Hutchins, E., (1995). Cognition in the Wild. Cambridge,
                                                                   MA: MIT Press.
                                                             295

