UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Designing state-trace experiments to assess the number of latent psychological variables
underlying binary choices
Permalink
https://escholarship.org/uc/item/7hm362tm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Hawkins, Guy
Prince, Melissa
Brown, Scott
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Designing State-Trace Experiments to Assess the Number of Latent Psychological
                                         Variables Underlying Binary Choices
                                         Guy Hawkins (Guy.Hawkins@newcastle.edu.au)
                                        Melissa Prince (Melissa.Prince@newcastle.edu.au)
                                           Scott Brown (Scott.Brown@newcastle.edu.au)
                                   Andrew Heathcote (Andrew.Heathcote@newcastle.edu.au)
                                               School of Psychology, University of Newcastle
                                             University Drive, Callaghan, 2308, NSW Australia
                               Abstract                                    State-trace analysis results are shown in a state-trace plot:
   State-trace analysis is a non-parametric method that can iden-
                                                                        a scatterplot of the co-variation of performance for the levels
   tify the number of latent variables (dimensionality) required to     of the state factor (e.g., faces or houses). Memory accuracy
   explain the effect of two or more experimental factors on per-       results for the two levels of the state factor form the two axes
   formance. Heathcote, Brown, and Prince (submitted) recently          of the state-trace plot. Each point on the plot represents a pair
   proposed a Bayes Factor method for estimating the evidence
   favoring one or more than one latent variable in a state-trace       of measurements, with a pair of (x, y) coordinates for each
   experiment, known as Bayesian Ordinal Analysis of State-             level of the dimension factor (e.g., upright and inverted). For
   Traces (BOAST). We report results from a series of simula-           our example there would be two coordinate pairs on the state-
   tions indicating that for larger sample sizes BOAST performs
   well in identifying dimensionality for single and multiple la-       trace plot, one for upright stimuli and one for inverted stimuli.
   tent variable models. A method of group analysis convenient          To infer dimensionality a third variable, referred to as a trace
   for smaller sample sizes is presented with mixed results across      factor, is added to the state-trace design. The trace factor
   experimental designs. We use the simulation results to provide
   guidance on designing state-trace experiments to maximize the        sweeps out a set of coordinate pairs for each level of the di-
   probability of correct classification of dimensionality.             mension factor. Levels of the trace factor within each level of
   Keywords: State-trace analysis; Bayesian analysis; Bayes             the dimension factor are usually connected with a line in the
   Factor; Encompassing prior method; Simulation.                       state-trace plot, with each line referred to as a data trace.
                                                                           Latent dimensionality is identified by assessing whether all
                    State-Trace Analysis
                                                                        of the data points in the state-trace plot fall on a single mono-
State-trace analysis (Bamber, 1979), also known as dimen-               tonic (i.e., always increasing or always decreasing) function,
sional analysis (Loftus, Oberg, & Dillon, 2004), is a method            indicating evidence for a single latent variable. Monotonicity
for determining whether a single latent variable is capable of          holds if all of the x axis values in a state-trace plot have the
explaining the joint effect of two experimental factors. Di-            same order as the y axis values. Although a monotonic plot is
mensionality is traditionally assessed by testing for an inter-         necessary to infer a single latent variable, it is not sufficient:
action between the two factors. However, interactions can               monotonicity cannot be diagnostic unless the data traces over-
be scale dependent (e.g., distorted by floor or ceiling effects)        lap on at least one axis. Hence, an assessment of whether data
when response variables are bounded (e.g., accuracy data, see           traces overlap is essential to a proper assessment of dimen-
Dunn & Kirsner, 1988; Loftus, 1978). State-trace analysis               sionality. Similarly, it is important to establish that the trace
overcomes this problem by assessing the ordinal relationships           factor does not itself affect dimensionality, so that results in
between the effects of experimental factors. One factor is              favor of more than one dimension can be unambiguously at-
comprised of a set of indicator variables, and is referred to           tributed to the effect of the dimension factor. This can be
as the state factor. A second factor is a variable thought to           checked by determining if the trace factor has a monotonic
differentially influence performance over levels of the state           effect within each level of the dimension factor.
factor, and is referred to as the dimension factor.
   State-trace analysis is most easily described by an exam-              A Bayesian Approach to State-Trace Analysis
ple. For this purpose we use the disproportionate face in-
version effect (DFIE), the finding in perceptual and recog-             Given an observed state-trace plot, where the effects of the
nition memory studies that stimulus inversion has a more                underlying latent variable(s) are perturbed by measurement
deleterious effect on faces than other mono-oriented stimuli            error, how can we determine whether a monotonic curve best
(Valentine, 1988; Yin, 1969). This result has been taken to             describes the data? A number of statistical methods for as-
suggest that faces are encoded along a ‘configural’ dimen-              sessing departures from monotonicity have been suggested
sion that is not available to mono-oriented non-face stimuli            (see Loftus et al., 2004; Newell & Dunn, 2008). Recently
(e.g., houses; Maurer, Le Grand, & Mondloch, 2002). In this             Heathcote et al. (submitted) proposed a Bayes Factor ap-
example, stimulus type (faces or houses) is the state factor            proach to state-trace model selection, known as Bayesian Or-
and stimulus orientation (upright or inverted) is the dimension         dinal Analysis of State-Traces (BOAST), based on Klugkist,
factor, as inversion is thought to differentially affect memory         Laudy, and Hoijtink’s (2005) encompassing prior method.
for faces and houses.                                                   The encompassing prior method uses Bayes Factors to select
                                                                    2224

among models defined by inequalities. The advantage of this             for any k = 1 . . . m which includes i. Throughout we assume
approach is that it automatically accounts for differences in           each model is equally likely to be the best model before ob-
flexibility amongst models, which is a key issue in state-trace         serving the data.
analysis as a one-dimensional model is far less flexible than a            Our aim here is to assess, via simulation, how often
multi-dimensional model.                                                BOAST analysis selects the correct number of latent vari-
   BOAST assumes binomially distributed data (e.g., a bi-               ables, either one or more than one. We begin by simulating
nary two-alternative forced choice response used to measure             an individual participant analysis. We then examine a method
recognition accuracy in the DFIE example), with state-trace             of aggregating participant results to select the best character-
models being defined by sets of inequality constraints on bi-           ization of dimensionality for a group of participants.
nomial probability parameters. For example, we define a
‘trace’ model, which instantiates the assumption that the trace                                                Simulations
factor does not change dimensionality, by specifying that the           Figure 1 shows state-trace data consistent with a single latent
trace factor has a monotonic effect on performance within               variable model (1D) and a two latent variable model (2D).
each level of the dimension factor. This specification im-              In both cases the trace factor has a clear monotonic effect on
plies that, for a trace factor with three levels and an overall         performance; that is, as the level of the trace factor increases
increasing effect on accuracy, that accuracy is smaller for the         so too does the dependent variable. The two models also both
first level of the trace factor than the second level, and smaller      exhibit moderate and equal data trace overlap. These two pat-
for the second level than the third. The trace model is, there-         terns were used to generate simulated data (by using their co-
fore, an order constrained special case of an ‘encompassing’            ordinates to specify binomial probability parameters) and we
model that places no restrictions on the order of parameters.           will refer to them as the 1D and 2D models.
   When model Mi is an order constrained version of an en-
compassing model Mk , Bayes Factors can be estimated from                                                     1D                               2D
prior and posterior samples from the encompassing model                                  0.80                              ●
(Klugkist, Kato, & Hoijtink, 2005). The proportion of prior
                                                                                         0.75                       ●                                ●
(π̂) and posterior (Π̂) samples that adhere to the order con-
                                                                            p(State 2)
straints of the more restricted model Mi are used to estimate                            0.70           ●                                                   ●
a Bayes Factor from the ratio of the two sample counts,
                                                                                         0.65    ●                                ●
                                  Π̂
                            BFik ≈ .                            (1)                      0.60                                            ●
                                  π̂
                                                                                                0.65   0.70        0.75   0.80   0.65   0.70        0.75   0.80
This Bayes Factor indicates the strength of evidence in favor                                                             p(State 1)
of Mi over Mk . Intuitively this is the case because it is the
ratio of the probability that the model fits the data before the        Figure 1: The two models on which simulations were based.
data are observed, which is proportional to the complexity of           p(State 1) and p(State 2) refer to the proportion of correct
the model (e.g., the maximally complex encompassing model               responses for the first and second level of the state factor, re-
will always fit any data pattern), to the actual fit of the model       spectively. The two lines on each plot represent data traces,
to the data. If this ratio is greater than one it indicates that the    one for each level of the dimension factor. The solid lines
model fits better than chance.                                          are identical for both models, and the dashed line for the 2D
   A set of such Bayes Factors, assuming the same encom-                model is the same as the dashed line for the 1D model but
passing model, can be used to compare a set of order-                   transposed downward by 0.1.
restricted models by calculating each models posterior model
probability, p(Mi |D), given observed data D. The quantity
p(Mi |D) is the probability that model Mi is the ‘true’ (data              We next elaborated the 1D and 2D models with 2 trace
generating) model, on the assumption that one model in the              levels shown in Figure 1, which we call the T 2 designs, by
set is the true model. Model selection based on p(Mi |D) can            creating variants with three and four trace levels, T 3 and T 4
also be justified on other grounds, even when the set does not          designs respectively. In T 2 designs the two levels of the trace
contain the true model (e.g., it selects the model that is most         factor provided data for the end points of the data traces. For
likely to minimize a measure of error in predicting new data),          T 3 and T 4 designs the additional levels were evenly spaced
so we refer to it simply as a method of selecting the ‘best’            between the end points of each data trace. One purpose of
model. For a set of models Mi , 1 . . . m that are assumed to           these simulations was to provide guidance on experimental
have a probability pi of being the best model prior to observ-          design in terms of the trade-off between number of trials con-
ing the data, the posterior model probability for Mi is:                tributing to the estimates of each point in the state-trace plot
                                                                        and the number of levels in the trace factor. For a fixed sam-
                                   pi × BFik                            ple size (number of trials) there is a trade-off between these
                  p(Mi |D) =                                    (2)
                                ∑mj=1 p j × BFjk                        two factors, with more trace levels resulting in fewer trials
                                                                     2225

per point. For each model and each T we explored 6 total              have a consistent effect irrespective of underlying dimension-
trial numbers (n) with total n conserved across each T at 192,        ality. Secondly, as total sample size increases the lines always
384, 768, 1536, 3072 and 6144. For example, a model with              approach zero, indicating consistent selection of the trace
n = 192 had 24 observations per coordinate of each point for          model. That is, BOAST recovers the trace model with in-
T 2, 16 observations for T 3, and 12 observations for T 4. In         creasing reliability as measurement error decreases due to an
total we performed 36 simulations (2 models × 3 trace levels          increase in sample size. Finally, the probability of selecting
× 6 sample sizes). For each simulation 1000 Monte Carlo               the non-trace model approached zero with lower total trials
replicates were sampled from binomial distributions with pa-          for T 2 compared to T 3 and T 4. As seen in Figure 2, selec-
rameters determined by the design and model. Sufficient pos-          tion is approximately zero for T 2 at n = 768, whereas this
terior samples were obtained so that posterior proportions            increased to n = 1536 for T 3 and T 4 in the 1D model, and
of monotonic samples had 90% credible intervals less than             to n = 3072 for T 4 in the 2D model. Thus, for smaller n,
0.025; prior proportions were determined analytically assum-          the trace model had a greater chance of being supported in
ing a uniform prior (see Heathcote et al., submitted, for de-         T 2 designs compared to T 3 and T 4 designs. This occurs be-
tails).                                                               cause the combination of a smaller sample size (and hence
                                                                      greater measurement noise) and closer spacing between re-
                      BOAST Results                                   sults for adjacent trace levels as T increases makes a violation
                                                                      of monotonicity within a data trace more likely.
For each simulation we estimated Bayes Factors to test four
mutually exclusive models, which we refer to as the non-              The No-Overlap Model
trace (NT), no-overlap (NO), unidimensional (UD) and mul-
                                                                      When the trace model holds it implies that one of the three
tidimensional (MD) models. Together these models account
                                                                      remaining models best describes the data, as they are each
for all possible orders (i.e., together they constitute the en-
                                                                      trace models. A monotonic state-trace plot is a special case of
compassing model). Posterior model probabilities were cal-
                                                                      the trace model where all data points have the same ordering
culated for each Monte Carlo replicate for each model by di-
                                                                      for both levels of the state factor. A non-overlapping mono-
viding each Bayes Factor by the sum of all four Bayes Fac-
                                                                      tonic plot is a case where data traces for both levels of the
tors (i.e., Equation 2), which we refer to as p(NT), p(NO),
                                                                      dimension factor do not cross over at any point along either
p(UD) and p(MD), respectively. Figure 2 illustrates results in
                                                                      axis of the state-trace plot. In this case, monotonicity is not
terms of the proportion of comparisons selecting one of the
                                                                      diagnostic of dimensionality, as both one-dimensional and
four models (i.e., where the models posterior probability was
                                                                      multi-dimensional data generating models produce mono-
greatest amongst the set of four models). Figure 2 can be
                                                                      tonic state-trace plots when there is a failure of data trace
interpreted by comparing the height of corresponding points
                                                                      overlap. Hence, an important second check in a state-trace
across the panels in each row. In particular, the ‘highest’ point
                                                                      analysis is to determine whether the no-overlap model holds.
indicates which of the four models is most often supported.
                                                                         Results for the no-overlap model differed between the 1D
The Trace Model                                                       and 2D data generating models. The 1D simulations results
                                                                      generally give some support for the no-overlap model, which
An important first check in any state-trace analysis is to de-        is perhaps not surprising given the the 1D model produces
termine whether the trace model is supported. For example,            monotonic data. Of more concern is the fact that this sup-
we described study duration as a possible trace factor. In            port was inconsistent as a function of sample size, n, for T 4
this case the trace model indicates that accuracy increased           and to a lesser degree for T 3. That is, support for the no-
as study durations became longer for both levels of the state         overlap model initially increased with n, but then decreased,
and dimension factors. In contrast, support for the non-trace         from n = 1536 for the T 4 design and from n = 768 for the
model indicates that the order dictated by the trace factor was       T 3 design. In contrast, the no-overlap model consistently re-
violated. Even when the trace model is the data generating            ceived little support across all T and n in the 2D simulations.
model, measurement noise can cause violations of the trace            Overall, these results suggest that when there is in fact trace
model (i.e., support for the non-trace model) to arise more           overlap in a one-dimensional data generating model, the no-
frequently when differences between levels of the study du-           overlap model is more often rejected in designs with fewer
ration factor produce only small changes in accuracy. Support         trace levels.
for the non-trace model clouds any conclusions about under-
lying dimensionality of the state factor since the effects of the     The Unidimensional and Multidimensional Models
dimension and trace factors are confounded, and can suggest           For both data generating models the unidimensional and mul-
that the experimental design needs to be improved by using            tidimensional posterior model probabilities provided support
more widely spaced trace factor levels.                               for the true model dimensionality. For the 1D case support
   The non-trace model results are shown in the left column           for the unidimensional model (middle right column of Fig-
of Figure 2. The figure demonstrates a number of key points.          ure 2) increased with sample size, but the level of support
As expected, evidence for the trace model is similar across           was smaller for larger T . For the 2D case support for the
both 1D and 2D simulations, since the trace factor should             multidimensional model (right column of Figure 2) also in-
                                                                  2226

                               Non−Trace                                No Overlap                               Unidimensional                           Multidimensional
             1.0                                                                                                                            2
                                                                  2 Trace Levels                                                     2
                                                                                                                                            3
             0.8                                                  3 Trace Levels                                             2
                                                                                                                                            4
                                                                  4 Trace Levels                                                     3
                                                                                                                       2
             0.6
    1D (p)
                                                                                                                 2           3       4
                   4
                                                                                                           2           3     4
             0.4
                   3     4                                                      4                                3     4
                                                                  4
                                                                  3       3
                                                                          4     3       4                  3                                               3     4
                                                            3
                                                            2     2                                                                                 2
                                                                                                                                                    3      4
                                                                                                                                                           2     3     4
             0.2         3                                  4             2                                4     4                                  4                  3
                   2             4                                                      3       4                                                                2            4
                                                                                                                                                                              3
                                                                                2                                                                                      2             4
                                                                                                                                                                                     3
                         2       3     4                                                        3                                                                             2
             0.0                 2     3
                                       2      4
                                              3
                                              2      3
                                                     4
                                                     2                                  2       2                                                                                    2
             1.0                                                                                                                                                                     3
                                                                                                                                                                                     4
                                                                                                                                                                                     2
                                                                                                                                                                              4
                                                                                                                                                                              3
                                                                                                                                                                              2
             0.8
                                                                                                                                                                       3
                                                                                                                                                                       4
                                                                                                                                                                       2
             0.6                                                                                                                                                 3
    2D (p)
                   4                                                                                                                                             2
                                                                                                                                                                 4
                                                                                                                 2                                         3
                                                                                                                                                           2
             0.4         4                                                                                 2           2
                   3                                                                                                                                2      4
                                                                                                                             2                      3
                         3       4                                                                                     3
             0.2                                                                                           3     3                                  4
                   2                                        2                                              4     4     4     3
                                 3     4                    3
                                                            4     4
                                                                  3                                                          4       2
                         2                                        2       4
                                                                          3                                                          3
                                                                                                                                     4
             0.0                 2     3
                                       2      4
                                              3
                                              2      3
                                                     2
                                                     4                    2     4
                                                                                3
                                                                                2       3
                                                                                        4
                                                                                        2       3
                                                                                                2
                                                                                                4                                           2
                                                                                                                                            4
                                                                                                                                            3
                   192   384     768   1536   3072   6144   192   384     768   1536    3072    6144       192   384   768   1536    3072   6144    192    384   768   1536   3072   6144
                                                                                       Total Sample Size (n)
Figure 2: Model selection results for both data generating models, type of comparison, number of trace levels, T , and number
of ‘trials’, n. Columns correspond to each of the mutually exclusive models being tested and rows to the type of the data
generating model. On each plot the x axis represents the six levels of n and the y axis represents the proportion of simulations
in which posterior model probability favored the model specified for each column. The lines group designs with the same T .
creased with sample size. In contrast to the 1D case, the level                                        by taking the product of each participants Bayes Factor.
of support was similar for all T , although it was slightly less                                       Hence, a group Bayes Factor for a model Mi is given by
for the T 4 design for smaller n (likely reflecting the larger                                         GBFi = ∏Nj=1 BFi j , where N is the number of subjects. Group
level of support for the non-trace model) and slightly less for                                        Bayes Factors can then be combined to obtain a posterior
the T 2 design for the second and third largest value of n, with                                       model probability for model Mi at the group level. Again
all T designs perfectly selecting the true model for the largest                                       we assume each model is equally likely to be the best model
sample size. Across the 1D and 2D data generating models                                               before observing the data, and so:
support for the wrong dimensionality was generally low and
                                                                                                                                                     GBFi
decreased with sample size, although there was some incon-                                                                          p(Mi |D) =      m                                       (3)
sistency for the three smallest sample sizes.                                                                                                      ∑k=1 GBFk
   Overall, the results of the simulation study indicate that ac-                                      for a set of k = 1 . . . m models that includes model i.
curate results for all comparisons can only be guaranteed for                                             We examined the utility of group Bayes Factors using the
quite large sample sizes. This indicates that analysis of indi-                                        simulations from the previous section. For each simulation
vidual participant data may not produce clear results in appli-                                        we sampled with replacement (i.e., resampled) sets of indi-
cations where it is not possible to measure performance on a                                           vidual Bayes Factors from the 1000 available. The sets were
large number of trials for each individual. In such situations                                         of sizes (N) 8, 16 and 32, representing experiments with dif-
it would be desirable to have a method of combining results                                            ferent numbers of participants. These N’s cross with total
over participants in a way that improves correct identification                                        trials n in a balanced manner. For example, a set of N = 32
at the group level. In the next section we extend the analy-                                           with n = 192 trials provides results from a total of 6144 trials,
sis of our simulation results to assess the performance of one                                         equivalent to the set N = 16 with n = 384 trials, and N = 8
such method suggested by Heathcote et al. (submitted), the                                             with n = 768 trials. The resampling procedure was repeated
group Bayes Factor.                                                                                    500 times for each possible grouping: two data generating
                                                                                                       models (1D, 2D), with three trace levels (T 2, T 3, T 4), three
                         Group Bayes Factors                                                           total trial sizes (n = 192, 384, 768), and three participant sam-
A Bayes Factor for a group of participants, assuming each                                              ple sizes (N = 8, 16, 32), for each of the four comparisons
participant contributes independent evidence, can be obtained                                          (non-trace, no-overlap, unidimensional, multidimensional), a
                                                                                               2227

                                 Non−Trace                                   No Overlap                                   Unidimensional                            Multidimensional
             1.0                                                                                                                                 2    2
                            4                                  2 Trace Levels                   n = 192                                      2
                                                                                                                                        2             3
                       4                                       3 Trace Levels                   n = 384
             0.8                                                                                                                                 3
                                                                                                                                   2
                   4                                           4 Trace Levels                   n = 768                        2             3        4
             0.6                                                                                                                                 4
    1D (p)
                                                                                                                                                               2    2             3
                                                                                                                                             4                      3
                                                                                                                                                                             3
                                                                                                                                   3                       2             3
                                                                                                                 2        2             3                      3
             0.4                                                                                                     2         3                                                  4
                                                                                                                                                           3                 4
                   3               4   4    4                                                                                                                            4             4   4
                       3    3                                                                                        3                                                                 3        4
                                                                               4                                 3                                                       2   2
             0.2                                                                                                          3    4   4    4                                                  3
                                                                                   4                                                                       4
                                                               3               3        4       4                                                              4                  2             3
                                                               2   3                                4            4                                                                     2
                                   3                               2           2                3                    4                                              4
                   2               2   3    3    4
                                                 3   4
                                                     3    3    4   4    3
                                                                        2
                                                                        4          3
                                                                                   2    3       2   3    4
                                                                                                         3                4                                                                2    2
             0.0       2    2          2    2    2   2    2
                                                          4                             2           2    2
             1.0            4                                                                                                                                                3    3    3   3
                                                                                                                                                                                           4    3
                                                                                                                                                                                                4
                                                                                                                                                                                                2
                       4                                                                                                                                            2                  4   2
                                                                                                                                                                                  2
                                                                                                                                                               2         3             2
                   4                                                                                                                                                         2
             0.8                                                                                                                                           2             2
                                                                                                                                                                                  4
                                                                                                                                                                    3        4
             0.6
    2D (p)
                                                                                                                                                               3         4
                                                                                                                                                           3
             0.4   3   3           4
                            3          4
                                            4
                                                                                                                               2
             0.2                                                                                                 2
                                                                                                                                   2         2             4
                                                                                                                     2
                                   3             4                                                               3                      2        2             4
                   2                   3                                                                         4   3    2    3             3        2             4
             0.0       2    2      2   2    3
                                            2    3
                                                 2   4
                                                     3
                                                     2    3
                                                          2
                                                          4    3
                                                               2
                                                               4   3
                                                                   4
                                                                   2    3
                                                                        4
                                                                        2      4
                                                                               3
                                                                               2   4
                                                                                   3
                                                                                   2    3
                                                                                        2
                                                                                        4       3
                                                                                                4
                                                                                                2   3
                                                                                                    2
                                                                                                    4    3
                                                                                                         4
                                                                                                         2           4    3
                                                                                                                          4    4   4
                                                                                                                                   3    3
                                                                                                                                        4    4   3
                                                                                                                                                 4    3
                                                                                                                                                      4
                   8   16   32    8    16   32   8   16   32   8   16   32     8   16   32      8   16   32      8   16   32   8   16   32   8   16   32   8   16   32   8   16   32   8   16   32
                                                                                             Number of Subjects (N)
Figure 3: Group level results for the 216 comparisons. The rows and columns represent the same data generating models and
comparisons as Figure 2. On each plot, the x axis represents the three levels of N that were resampled for each of n = 192, 384,
768, and the y axis represents the proportion of cases in which the posterior model probability at the group level favored the
model specified for each column.
total of 216 combinations (33 × 2 models × 4 comparisons).                                                    ticipant data indicated that large sample sizes produced strong
For each of the 500 repetitions of the 216 combinations we                                                    support for the correct outcome for both 1D and 2D data gen-
estimated group Bayes Factors, and then calculated the pro-                                                   erating models across designs with two, three and four levels
portion of comparisons selecting one of the four models (i.e.,                                                in the trace factor. Classification for the 1D data generat-
where the models posterior probability was greatest amongst                                                   ing model was most reliable in designs with two trace levels,
the set of four models), with results shown in Figure 3.                                                      whereas the opposite tendency was evident for the 2D data
   For the no-overlap model the group Bayes Factors results                                                   generating model; dimensionality assessment was more accu-
were much the same as for the individual analysis, except                                                     rate with larger numbers of trace levels. Overall these results
that the inconsistent effect of sample size for the individual                                                indicate that a design with three trace levels provides the best
analysis of the 1D data generating model disappeared in the                                                   compromise for accurate diagnosis of both single and multi-
group analysis. For the trace model performance was excel-                                                    ple latent variable data generating models.
lent when n = 768 but the wrong (non-trace) model received                                                       We also explored a group analysis procedure that is ad-
increasing support when there were fewer observations per                                                     vantageous where it is practically difficult to obtain a large
participant for all but the T 2 design. These problems with the                                               number of responses from each individual participant, such as
trace model caused corresponding failures to identify the cor-                                                in cases where the number of available stimuli is limited, but
rect dimensionality for lower values of n, whereas for n = 768                                                where larger numbers of participants are available. Generally,
performance in identifying dimensionality was similar to that                                                 this method was found to be very effective in identifying the
of the largest samples sizes in the individual analysis. In par-                                              2D data generating model. However, our results indicate that
ticular, the 2D data generating model was almost perfectly                                                    it should be used with caution as it could be biased against
identified, but with higher T designs being slightly better,                                                  detecting cases in which only one latent variable is present
whereas performance in classifying the 1D data generating                                                     in certain experimental designs. When each participant con-
model was very good for T 2 designs but decreased markedly                                                    tributed a smaller number of responses (192 or 384) results
for the T 3 and T 4 designs.                                                                                  could be inaccurate even for the largest number of partici-
                                                                                                              pants (32). For 768 observations per participant performance
                                       Conclusions                                                            was more accurate and improved with group size for the 1D
We aimed to investigate the ability of BOAST analysis to
identify latent dimensionality. The results of individual par-
                                                                                                    2228

data generating model. In contrast to the individual partic-                              Acknowledgments
ipant results, the group level analyses indicate that designs          We acknowledge support from the Keats Endowment Re-
with two levels in the trace factor produce the best compro-           search Fund.
mise of most accurate classification across number of trials
per participant and different numbers of participants for both                                 References
1D and 2D data generating models. However, these results               Bamber, D. (1979). State-trace analysis: A method of test-
should be used with some caution given the three and four                ing simple theories of causation. Journal of Mathematical
trace level designs demonstrated a large proportion of cases             Psychology, 19, 137–181.
supporting the non-trace model (possibly due to the small ex-          Dunn, J. C., & Kirsner, K. (1988). Discovering functionally
perimental effects of the trace factor in these larger trace level       independent mental processes: The principle of reversed
designs), which had strong consequences for the correct clas-            association. Psychological Review, 95, 91–101.
sification of dimensionality.                                          Heathcote, A., Brown, S., & Prince, M. (submitted). The de-
   Our individual and group analyses indicate that the ideal             sign and analysis of state-trace experiments. Psychological
number of trace levels in a state-trace experiment is depen-             Methods.
dent on the intended approach to data collection. If only a            Klugkist, I., Kato, B., & Hoijtink, H. (2005). Bayesian
small number of trials per participant are obtainable it seems           model selection using encompassing priors. Statistica
wiser to use a trace factor with few levels so as to maximise            Neerlandica, 59, 57–69.
data per point, and then combine across participants with              Klugkist, I., Laudy, O., & Hoijtink, H. (2005). Inequal-
group Bayes Factors. In contrast, if many trials per partici-            ity constrained analysis of variance: A Bayesian approach.
pant can be obtained, correct classification of dimensionality           Psychological Methods, 10, 477–493.
is possible with a three level trace factor through individual         Loftus, G. R. (1978). On interpretation of interactions. Mem-
participant analysis, which confers additional benefits such as          ory & Cognition, 6, 312–319.
the exploration of individual differences in performance.              Loftus, G. R., Oberg, M. A., & Dillon, A. M. (2004). Linear
   In summary, these results indicate that the success of                theory, dimensional theory, and the face–inversion effect.
BOAST analysis, and likely any state-trace analysis method,              Psychological Review, 111, 835–863.
depends strongly on the particular model producing the state-          Maurer, D., Le Grand, R., & Mondloch, C. J. (2002). The
trace plot. This highlights a caveat on our group analysis,              many faces of configural processing. Trends in Cognitive
which assumes all participants have an identical underlying              Sciences, 6, 255–260.
model (rather than just having the same dimensionality but             Newell, B. R., & Dunn, J. C. (2008). Dimensions in data:
possibly different magnitudes of the effects of experimental             Testing psychological models using state-trace analysis.
factors). As well as being unrealistic, this assumption likely           Trends in Cognitive Sciences, 12, 285–290.
magnifies the effects of a particular data pattern. In ongoing         Valentine, T. (1988). Upside-down faces: A review of the
research we will simulate groups of participants that vary in            effect of inversion upon face recognition. British Journal
the effects of experimental factors (while maintaining a con-            of Psychology, 79, 471–491.
sistent dimensionality) in order to check the generality of the        Yin, R. K. (1969). Looking at upside-down faces. Journal of
group analysis results reported here.                                    Experimental Psychology, 81, 141–145.
                                                                   2229

