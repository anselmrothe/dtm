UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Motor Affordances in Object Perception
Permalink
https://escholarship.org/uc/item/193354fq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Flusberg, Stephen
Dils, Alexia Toskos
Boroditsky, Lera
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                     Motor Affordances in Object Perception
                                              Stephen J. Flusberg (sflus@stanford.edu)
                                            Alexia Toskos Dils (atoskos@stanford.edu)
                                                 Lera Boroditsky (lera@stanford.edu)
                                              Stanford University, Department of Psychology
                                 Jordan Hall, 450 Serra Mall, Building 420, Stanford, CA 94305 USA
                            Abstract                                    2001). In one experiment, participants had to make a left or
                                                                        right-handed button press to indicate whether an image of an
   Recently, researchers have suggested that when we see an
                                                                        object on the screen was upright or inverted. The objects
   object we automatically represent how that object affords
   action (Tucker & Ellis, 2001). However, the precise nature of        were chosen to have clear right or left-handed affordance
   this representation remains unclear: is it a specific motor plan     (e.g. a frying pan with a handle oriented to the left affords a
   or a more abstract response code? Furthermore, do action             left-handed grasp). Participants responded faster and made
   representations actually influence what we perceive? In              fewer errors when their responding hand was congruent
   Experiment 1, participants responded to an image of an object        with the (task-irrelevant) affordance of the object on the
   and then made a laterality judgment about an image of a hand.        screen. Similar stimulus/response compatibility (SRC)
   Hand identification was fastest when the hand corresponded
                                                                        effects have been obtained for other types of m i c r o -
   to both the orientation and grasp type of the object,
   suggesting that affordances are represented as specific action       affordances, such as grasp type (Tucker & Ellis, 2001) and
   plans. In Experiment 2, participants saw an image of a hand          wrist orientation (Tucker & Ellis, 1998).
   before interpreting an ambiguous object drawing. Responses              Others have argued that the motor representations
   were biased towards the interpretation that was congruent            activated when we observe an object form an integral part of
   with the grasp type of the hand prime. Together, these results       our perception of the object (e.g. Helbig, Graf, & Kiefer,
   suggest that action representations play a critical role in          2006). For example, Helbig et al. (2006) presented
   object perception.
                                                                        participants with images of two objects in quick succession.
   Keywords: object perception; motor affordances                       Participants were more accurate in naming the second object
                                                                        when similar actions were required to make use of two
                          Background                                    objects (e.g. pliers and a nutcracker). These findings raise
   Traditional approaches to visual perception have assumed             important questions regarding, (1) the level at and
that the primary goal of the visual system is to construct a            specificity with which affordance information is
detailed internal picture of the external world based on a              represented, and (2) the potential causal role this
noisy retinal image (e.g. Marr, 1980). Recently, however,               information plays in the process of object perception.
there has been a growing appreciation for the possibility that             For instance, several researchers have argued that the
visual perception may be equally concerned with how we                  SRC effects obtained by Tucker and Ellis actually reflect
move around and act in our environment (Milner &                        abstract response coding rather than specific motor plans
Goodale, 1995). The idea that vision and action are                     (e.g. Anderson, Yamagishi, & Karavia, 2002). Indeed, even
intimately linked can be traced to the ecological psychology            Tucker and Ellis (2001) suggested that these effects could
of James Gibson (1979), who argued that organisms see the               not be explained by appealing exclusively to the neural
world in terms of how it affords action. While Gibson                   systems responsible for the on-line control of actions
eschewed the notion of mental representation, contemporary              because they were obtained using both images of objects as
scholars have suggested that visual perception may be at                well as real-world objects that were out of reach of
least partially characterized by a mental representation of             participants. Rather, affordance representations might be
the affordances in the environment (Tucker & Ellis, 1998).              more abstract, specifying, for example, the general class of
For example, seeing the coffee mug on the desk before me                hand shape required to interact with an object rather than
might involve mentally representing how I could reach out               precise motor parameters. Further, while the results of
and grasp it in order to drink from it. However, the precise            Helbig et al. (2006) are consistent with motor affordance
nature of these affordance representations and how they                 representations contributing to object perception, the data
relate to object perception remains unclear.                            could also be explained by the fact that objects that are used
   Several researchers have suggested that affordances are              in similar ways are typically similar to one another in other
represented as action plans in the motor systems of the brain           ways as well (e.g. semantically).
(e.g. Tucker & Ellis, 1998; Chao & Martin, 2000). Tucker                   In this paper we describe two experiments designed to
and Ellis conducted a series of studies to test whether people          address these issues. First, we wanted to know whether
automatically generate a motor representation in response to            motor affordances might be represented as specific action
the visual presentation of an object, even when there is no             plans for interacting with an object rather than as abstract
intention to act on the object (e.g. Tucker & Ellis, 1998,              response codes. To this end, in Experiment 1 we made use
                                                                        of a dependent measure that is known to draw on very
                                                                    2105

specific manual action representations, namely the hand            activated automatically during object perception, regardless
identification task (Parsons, 1987). Previous work has             of current task goals. Conversely, differences in reaction
shown that the time it takes to identify whether an image is       time profiles between the grasp-related and grasp-unrelated
of a left or right hand is directly proportional to the time it    conditions would suggest that the current task goals do
would take, and how difficult it would be, to rotate your          affect the kind of motor representation activated.
own hand into that position (Parsons, 1987). In our study,
participants first made a response towards an image of an          Methods
object that afforded a particular grasp type and wrist             Participants Sixty-eight right-handed individuals from the
orientation. They then saw an image of a hand and had to           Stanford community were recruited to participate in this
indicate whether it was a right or left hand. If seeing an         study in exchange for payment or class credit.
object leads to the activation of a specific manual action
representation, participants should be faster to respond to an     Stimuli Object Images: Objects used in Experiment 1 varied
image of a hand that matches that object on grasp type and         on two dimensions: required grasp type (power, precision,
wrist orientation.                                                 or none) and required wrist orientation (upright or inverted).
   Second, we investigated the possibility that action             The dimensions were fully crossed within-subjects to
representations actually contribute to the perceptual              produce 6 different object types. Two power grasp objects
representation of objects. In Experiment 2, participants           (flashlight and glass), two precision grasp objects (pushpin
were first primed with an image of a hand depicting a              and tweezers), and four objects with no grasp affordance
specific grasp type. They then saw a drawing of an                 (desk, bookcase, grandfather clock, and sofa) populated the
ambiguous object and had to indicate what they thought it          object categories. Hence, participants saw 16 unique
was. The object could be interpreted as affording a power          images, each of which was repeated 32 times for a total of
grasp (e.g. a football) or a precision grasp (e.g. a coffee        512 object presentations.
bean). Responses were biased towards the interpretation               The object stimuli were designed to afford right-handed
that was congruent with the primed hand. We also included          responses because we recruited exclusively right-handed
a control condition designed to rule out task demand and           participants. The upright version of each object faced
memory-based explanations of our findings. Together,               upward and to the left so as to afford an upright right-
these results suggest that action representations play a           handed grasp on the part of the observer. The upright
critical role in object perception.                                version of each object was rotated 90 degrees counter-
                                                                   clockwise in order to create the inverted version, which
                         Experiment 1                              faced down and to the left. Pilot testing confirmed that
What motor information becomes activated when we look at           right-handed individuals most often reached for real-world
an object? Previous research suggests that abstract response       objects in both the upright and inverted orientations with
codes representing individual micro-affordances such as            their right hands.
grasp type or wrist orientation become activated during               Hand Images: The hand images varied on three
object perception (Tucker & Ellis, 2001). Experiment 1             dimensions: grasp type (power or precision), w r i s t
makes use of a novel application of the hand identification        orientation (upright or inverted), and laterality (left or
task in order to test the specificity of motor representations     right). The dimensions were fully crossed within-subjects to
activated during object perception. Participants first made        produce 8 different hand types. Four images of hands
judgments on an image of an object that afforded a                 producing a power grasp and four images of hands
particular grasp type (power, precision, or no grasp               producing a precision grasp were used to populate each of
affordance) at a particular wrist orientation (upright or          the hand categories. Hence, participants saw 32 unique
inverted). Then they made laterality judgments on an image         hand images, each of which was repeated 16 times for a
of a hand that was configured in a particular grasp type           total of 512 hand presentations. The upright and inverted
(power or precision) at a particular orientation (upright or       right and left hand images were generated using the same
inverted). To the extent that viewing objects activates            process described above for the upright and inverted object
specific manual motor plans selective for both grasp type          images.
and wrist orientation, laterality judgments should be fastest
when both of the micro-affordances manipulated align
between the images of the object and hand.
   The degree to which various micro-affordances are
activated during object perception might also depend on
current goals (Bekkering & Neggers, 2002). Experiment 1
was designed to test whether viewing objects activates
motor plans more strongly when participants make grasp-
related compared with grasp-unrelated judgments about the
objects. Similar reaction time profiles between these
conditions would suggest that motor affordances are                          Figure 1: Sample stimuli from Experiment 1
                                                               2106

Procedure Each trial in Experiment 1 had two parts.               repeated measures ANOVA. The analysis produced no
Participants first responded to a picture of an object and        main effects of object affordance (F(2,57)=1.53, ns) or hand
then to a picture of a hand. Participants were randomly           stimulus (F (1,58)=0.436, ns), but a reliable quadratic
assigned to one of two conditions: an Orthogonal Judgment         interaction between the two variables (F(1,58)=13.14, p<
Condition and a Non-orthogonal judgment condition. In the         0.001).
Non-orthogonal Condition, participants made a grasp-                                                          Power Grasp
                                                                                                  Hand
related judgment in response to each object (“Can you pick                             N = 60
                                                                                                 Stimulus     Precision Grasp
                                                                                 80
it up with one hand?”). In the Orthogonal Condition,
participants made a grasp-unrelated judgment in response to                      60
each object (“Is it smaller than a shoebox?”). In both                           40
conditions, participants pressed the “j” key with their right                    20
index finger to enter a “yes” response, and the “f” key with                      0
their left index finger to enter a “no” response. Participants                  -20
were told to respond as quickly and accurately as possible.                     -40
Each object in Experiment 1 was preceded by a 500 ms                            -60
fixation period. The image remained on the screen until the                     -80
participant responded or the 10-second deadline expired, at                            Power      Precision        None
which point the trial advanced to the hand portion.                                           Object Affordance
   Each hand image was preceded by a 500ms fixation
period. Participants pressed the “j” key with their right          Figure 2: Differences in reaction time (Orientation Match –
index finger for pictures of right hands, and pressed “f” with     Mismatch) to the hand stimulus in Experiment 1. Error bars
their left index finger for pictures of left hands. The                       reflect the SE of the mean for each cell.
experiment advanced when the participant entered a
response or at the end of the 10-second deadline. A black            Participants showed a reliable match advantage to images
screen appeared for 750 ms to mark the end of each trial.         of hands in a power grasp after having seen an object
The 16 unique object images were fully crossed with the 32        affording a power grasp (M=-58 ms, SD=158) compared to
unique hand images to generate 512 unique experiment              having seen an object with no manual action affordance
trials, each of which participants saw only once.                 (M =-5 ms, SD=116) (t(59)=-2.31, p<0.05). Conversely,
                                                                  participants showed a reliable mismatch advantage to
Results                                                           images of hands in a power grasp after having seen an
                                                                  object affording a precision grasp (M=47 ms, SD=177)
The data from eight participants were removed because they        compared to having seen an object with no manual action
did not contribute to all cells in the analysis or they had       affordance (M =-5 ms, SD=116) (t(59)=2.05, p<0.05).
extremely high error rates or reaction times.                     Images of hands in a precision grasp showed analogous
   Trials analyzed: Only trials in which participants made        trends, but none of the relevant comparisons reached
correct responses to both the object and hand images were         significance (all p>0.2). This may be due to the fact that
analyzed, resulting in the exclusion of 13.4% of trials. Any      these hands were harder to correctly identify and thus they
response times faster than 200 ms. or slower than 5000 ms.        produced more errors and more variance in RT compared to
were omitted from all analyses, resulting in the removal of       grasp hands. The effect of orientation for hands in a
1.4% of remaining trials across conditions. Finally, the          precision grasp did, however, differ from the effect of
stimuli used in Experiment 1 were designed to elicit right-       orientation for hands in a power grasp both when the
hand affordances from right-handed individuals. As a              preceding object required a power grasp (M=22.80, SD=
result, only images of right hands were analyzed.                 23.51) (t(59)=-2.58, p< .05) and when the preceding object
   Coding: In ‘Orientation Match’ trials the orientation of       required a precision grasp (M=-17.54, SD=22.63) (t(59)=
the object was identical to that of the subsequent hand           2.05, p< .05).
(collapsing across upright and inverted images). In                  The data appear to follow a Mexican hat distribution
‘Orientation Mismatch’ trials the orientation of the object       (Muller et al., 2005), such that reaction times increase when
differed by 90 degrees in angular rotation from that of the       the object affordance only somewhat overlaps with the hand
subsequent hand.                                                  stimulus and decrease when the two overlap entirely
   RT Analyses: Figure 2 illustrates the mean pairwise RT         (relative to trials where the preceding object had no grasp
differences (Orientation Match – Orientation Mismatch)            affordance). To further test for such a distribution, trials
across all levels of Object Affordance (power, precision,         were binned into five similarity-based categories (Figure 3).
none) and Hand Stimulus (power, precision). Negative              For each of the bins, the object affordance on a given trial
difference scores suggest a match advantage with respect to       relative to the subsequent hand stimulus was either: (1)
orientation. Positive difference score suggest a mismatch         same orientation and grasp type, (2) same grasp type only,
advantage with respect to orientation.         The difference     (3) same orientation only, (4) different orientation and grasp
scores were submitted to a 3 (Object Affordance: power,           type, or (5) had no grasp affordance. A repeated measures
precision, none) x 2 (Hand Stimulus: power, precision)
                                                              2107

ANOVA yielded reliable quadratic (F(1,58)=8.04, p<0.01)                                              Such connectivity further predicts a full Mexican hat-like
and cubic (F(1,58)=6.05, p<0.02) effects of similarity.                                           distribution of response times such that the representations
                                                                                                  in similarity space just beyond the inhibited surround should
                             Increasing similarity between object                                 see facilitation that tapers off as distance increases (Muller
       1020                     affordances and hand stimulus                                     et al., 2005). That is, responses to hands preceded by
       1000                                                                                       objects that afford the wrong grasp in all dimensions should
        980                                                                                       be faster than those preceded by objects that afford no grasp
                                                                                                  at all. The cubic effect of similarity found in Experiment 1
        960                                                                                       is driven by that very difference, suggesting a Mexican hat
        940                                                                                       response time profile (Muller et al., 2005). Studies better
        920
                                                                                                  designed to test for such a pattern are currently underway.
                                                                                                  As it stands, the pattern observed in Experiment 1 is
        900                                                                                       consistent with the kind of connectivity believed to exist in
            Object had no              Object matched hand             Object matched hand        motor cortex. Furthermore, the hand identification task
           manual affordance          orientation but not grasp      on grasp and orientation
                                                                                                  used in this study was selected precisely because it is
                     Object did not match hand        Object matched hand on
                       on grasp or orientation        grasp but not orientation                   believed to be supported by specific motor regions. As a
                                                                                                  result, the present findings are consistent with the
   Figure 3: RT to hand stimuli in Experiment 1, binned by                                        hypothesis that object perception activates highly specific
 how similar the hand was to the set of manual affordances in                                     action representations in the motor system and does so in a
                             the previous object                                                  manner similar to the act of grasping itself.
                                                                                                     Finally, varying participants’ task goals when viewing the
  Finally, there was no main effect of the between-subjects                                       object had no significant effect on these results. Whether
condition (Task Goals: grasp-related, grasp-unrelated)                                            participants made a grasp-related (“Can you pick it up?”) or
(F(1,58)=1.50, p>0.20), nor did condition interact with the                                       grasp-unrelated (“Is it smaller than a shoebox?”) judgment
quadratic Object Affordance by Hand Stimulus interaction                                          towards the object, the same affordance information appears
(F(1,58)=2.81, p>0.10) or the effect of similarity (F(1,58)=                                      to have been represented. This supports the original
1.76, p>0.15). As a result, all analyses described above                                          findings of Tucker and Ellis (1998), who argued that
were run on the combined data from the two conditions.                                            affordance information is represented irrespective of the
                                                                                                  intentions of the observer. However, other researchers have
Discussion                                                                                        found effects of intentions on affordance representation (e.g.
In this experiment we asked whether people generate a                                             Bekkering & Neggers, 2002), and the effects in the present
specific motor plan for interacting with an object when they                                      study tended to be more robust in the task-related than the
see that object. RTs for the hand laterality judgment were                                        task-unrelated condition, which suggests that more research
fastest when the hand corresponded in both grasp type and                                         is called for on this issue.
wrist orientation to the previous object. This suggests that                                         Experiment 1 supports the idea that motor affordances are
when we look at an object we represent the specific motor                                         represented as specific action plans in the motor system
parameters necessary for interacting with that object. In                                         regardless of task goals. However, it is unclear how this
other words, when we see a drinking glass we actually                                             action representation relates to our ability to actually
simulate reaching out and grasping it.                                                            perceive the object. We turn to this issue in Experiment 2.
  Interestingly, RTs for the laterality judgment were slowest
when the object and hand corresponded in just one micro-                                                                   Experiment 2
affordance dimension (i.e. either grasp type or wrist
                                                                                                  Does action representation contribute to object perception?
orientation). Researchers have argued that similar reaction
                                                                                                  One possibility is that the visual and motor aspects of object
time profiles in classic vision and attention tasks suggest an
                                                                                                  perception are fairly independent: extracting the visual
underlying surround inhibition mechanism (Muller et al.,
                                                                                                  features of an object occurs in one processing stream while
2005; Roeber, Wong, & Freeman, 2008), where activating a
                                                                                                  extracting the affordance information relevant for action
particular representation suppresses highly similar but not
                                                                                                  occurs in a different processing stream (Milner & Goodale,
distantly similar representations. Importantly, motor cortex
                                                                                                  1995). Alternatively, visual and motor processes may be
is believed to have the kind of connectivity that would
                                                                                                  more interdependent, and currently activated action
support surround inhibition (Lukashin & Georgopoulos,
                                                                                                  representations might play a causal role in visual object
1993; Sohn & Hallett, 2004). Thus it is plausible that
                                                                                                  processing. Experiment 2 was designed to test the latter
viewing an object in the present study activates a highly
                                                                                                  possibility by priming participants with a specific manual
specific action representation, which in turn spreads
                                                                                                  action to see if it would affect their interpretation of an
inhibition to highly similar but not distantly similar action
                                                                                                  ambiguous object drawing. We also ran a control condition
representations. These patterns of activation and inhibition
                                                                                                  where we presented the ambiguous object image first in
would result in slower RTs to trials in which the images of
                                                                                                  order to control for task demand or memory-based
the object and hand differ on one but not all dimensions,
                                                                                                  explanations for the data.
which is precisely what was found in Experiment 1.
                                                                                              2108

Methods                                                             image as an object affording a power grasp while
Participants 245 individuals from Amazon’s Mechanical               participants primed with a precision grasp hand were more
Turk website participated in exchange for payment.                  likely to interpret the ambiguous image as an object
                                                                    affording a precision grasp.
Stimuli & Procedure The stimuli for this experiment
included four photographs of hands taken from Experiment                                 N = 115
                                                                                                        Perceived
                                                                                                          Object
                                                                                                                         Power
                                                                                                                         Precision
1 and an ambiguous object line drawing created by the                               60
                                                                                                        Affordance       None
authors. The four hand photographs showed either left or
right hands in either a power or precision grasp. Pilot                             50
testing suggested that the ambiguous object drawing could
                                                                                    40
be interpreted as an object that afforded a power grasp (e.g.
football) or as an object that afforded a precision grasp (e.g.                     30
coffee bean).
   In the experimental condition, one of the four hand                              20
images was randomly selected for each participant and                               10
displayed on the screen for three seconds. After this, the                                Power Grasp         Precision Grasp
                                                                                                   Hand Stimulus
ambiguous object drawing was displayed for three seconds.
Then, participants were asked to name the object in the line         Figure 5: Experiment 2, Experimental Condition: Proportion
drawing that they had just seen and to identify whether the             of ambiguous object interpretations coded for perceived
hand they had seen was a left or right hand. The only                 object affordance. Error bars are the SE of the proportion.
difference in the procedure for the control condition was
that participants were shown the ambiguous object image                Control Condition: A 2 (hand stimulus: power grasp vs.
first and hand image second. Thus participants were not             precision grasp) X 2 (perceived object affordance: power vs.
primed with an action representation prior to viewing the           precision) chi-square test of independence showed no
ambiguous object, but they saw the same two images prior            relationship between hand stimulus and perceived object
to making their object interpretation response.                     affordance, χ2 =0.74, p>0.38.
                                                                       Interaction Analysis: A 2 (interpretation: congruent vs.
                                                                    incongruent) X 2 (condition: experimental vs. control)
                                                                    interaction analysis showed that hand stimuli only affected
                                                                    ambiguous object interpretations in the experimental
                                                                    condition, χ2 =4.05, p<0.05.
                                                                    Discussion
 Figure 4: On the left, images of the left hand stimuli used in     In this experiment we asked whether currently active motor
  the experiment displaying precision and power grasps. On          representations would influence what participants saw when
            the right, the ambiguous object drawing.                they looked at an ambiguous object. We found that when
                                                                    participants were primed with a hand displaying a power
Results                                                             grasp they were more likely to interpret an ambiguous
The data from 19 participants were removed because they             image as an object that afforded a power grasp (e.g.
failed to respond to the test questions appropriately (N=8) or      football). Conversely, when they were primed with a hand
because they took the survey more than once (N=11). We              displaying a precision grasp, they were more likely to
then coded the object interpretation responses for the              interpret the image as an object that afforded a precision
remaining participants in terms of what sort of grasp would         grasp (e.g. coffee bean). This finding suggests that action
be afforded by the perceived object. We used the following          representations can play a causal role in the process of
coding scheme: Power (e.g. football or coconut), Precision          object perception.
(e.g. coffee bean or nut), and None (e.g. lips or any response         That said, there are a number of possible alternative
that listed more than one interpretation).                          explanations for these data. First, because of the simple
   Experimental Condition: For our analyses we collapsed            design of this experiment, participants may have simply
across left and right hand prime stimuli and excluded object        figured out what we wanted from them and tried to give it to
interpretation responses coded as none. A 2 (hand prime             us. The results of the control condition suggest that this is
stimulus: power grasp vs. precision grasp) X 2 (perceived           unlikely, however. In that condition, participants also saw
object affordance: power vs. precision) chi-square test of          both the ambiguous object and the hand stimulus prior to
independence showed a significant relationship between              giving their object interpretation response, the only
hand prime stimulus and perceived object affordance, χ2=            difference being they saw the ambiguous object first. If the
7.04, p<0.01. Participants primed with an image of a power          results from the experimental condition were due to demand
grasp hand were more likely to interpret the ambiguous              characteristics, we would expect to find the same pattern of
                                                                    results here. However, in the control condition there were
                                                                2109

no such effects. This also helps rule out the possibility that                        Acknowledgments
the results of the experimental condition were due to
                                                                  The authors would like to thank the members of Cognation
associations in memory rather than the online effects of
                                                                  for their helpful feedback. This research was supported by
action representation on perception.
                                                                  an NSF Career Award Grant given to Lera Boroditsky.
   Finally, because we used purely visual stimuli in this
experiment, it is possible that our results reflect visual
priming rather than motor priming. While prior research                                   References
has demonstrated that visually processing images of hands         Anderson, S. J., Yamagishi, N., & Karavia, V. (2002).
typically involves activating motor representations of one’s           Attentional processes link perception and action.
own hand (Parsons, 1987), it is difficult to rule out visual           Proceedings of the Royal Society of London B, 269,
priming as an explanatory mechanism at the present time.               1225-1232.
Research currently underway in our lab is moving away             Bekkering, H. & Neggers, F. W. (2002). Visual search is
from visual prime images and towards actual motor                      modulated by action intentions. Psychological Science,
movements as priming stimuli. Moreover, we are                         13, 370-374.
developing additional controls that include reversible            Chao, L. L. & Martin, A. (2000) Representation of
images that do not afford grasping in order to rule out                manipulable man-made objects in the dorsal stream.
alternative mechanisms such as altered scanpaths or                    Neuroimage, 12, 478-484.
attentional patterns.                                             Gibson, J. J. (1979). The ecological approach to visual
                                                                    perception. Lawrence Earlbaum: Hillsdale, NJ.
                   General Discussion                             Helbig, H. B., Graf, M., & Kiefer, M. (2006). The role of
                                                                    action representations in visual object recognition,
In this paper we explored the role that action representation
                                                                    Experimental Brain Research, 107(2), 221-228.
plays in visual object processing. In Experiment 1 we took
                                                                  Loach, D., Frischen, A., Bruce, N., & Tsotsos, J. (2008).
a bottom-up approach, asking whether we generate a
                                                                    An attentional mechanism for selecting appropriate
specific motor plan or a more abstract response code when
                                                                    actions afforded by graspable objects. Psychological
we observe an object with a particular set of manual
                                                                    Science, 19, 1253-1257.
affordances. Participants made a judgment about an image
                                                                  Lukashin, A. V., & Georgopoulos, A. P. (1993). A
of an object that afforded a particular grasp type and wrist
                                                                    dynamical neural network model for motor cortical
orientation. They then made a laterality judgment about an
                                                                    activity during movement: population coding of
image of a hand displaying a particular grasp type and wrist
                                                                    movement trajectories. Biological Cybernetics, 69, 517 –
orientation. RTs for the laterality judgment were fastest
                                                                    524.
when the hand corresponded in both grasp type and wrist
                                                                  Marr, D. (1982). Vision. San Francisco, CA: Freeman.
orientation with the previous object. This suggests that
                                                                  Milner, D. & Goodale, M. (1995). The Visual Brain in
when we look at an object we represent the specific motor
                                                                    Action. Oxford: Oxford University Press.
parameters necessary for interacting with that object within
                                                                  Muller, N. G., Mollenhauer, M., Rosler, A., &
the motor systems of the brain.
                                                                    Kleinschmidt, A. (2005). The attentional field has a
   Intriguingly, RTs for the laterality judgment were slowest
                                                                    Mexican hat distribution. Vision Research, 45, 1129-
when the object and hand corresponded in just one micro-
                                                                    1137.
affordance dimension (i.e. either grasp type or wrist
                                                                  Parsons, L. M. (1987). Imagined spatial transformation of
orientation). This “Mexican hat” response time function has
                                                                    one’s body. Journal of Experimental Psychology:
been found by other researchers studying motor
                                                                    General, 19, 178-241.
representation in the brain (Loach, Frischen, Bruce, &
                                                                  Roeber, U., Wong, E. M., & Freeman, A. (2008). Cross-
Tsotsos, 2008; Lukashin & Georgopoulos, 1993; Sohn &
                                                                    orientation interactions in human vision. Journal of
Hallett, 2004), providing further support for the idea that
                                                                    Vision, 8, 1-11.
affordances are represented as specific action plans in the
                                                                  Tucker, M. & Ellis, R. (1998). On the relations between
motor system.
                                                                       seen objects and components of potential actions.
   In Experiment 2 we took a top-down approach, asking
                                                                       Journal of Experimental Psychology: Human
whether activating a particular manual action representation
                                                                       Perception and Performance. 24(3), 830-846.
would influence the perception of an ambiguous object
                                                                  Tucker, M. & Ellis, R. (2001). The potentiation of grasp
image. The results suggest that action representations can
                                                                       types during visual object categorization. Visual
play a causal role in the process of object perception.
                                                                       Cognition, 8(6), 769-800.
   All together, the results of these experiments suggest that
action representation plays a crucial role in visual object
processing. As we look around the world we are not merely
constructing an internal picture of what’s out there, we are
also preparing to act and behave on what’s before us.
Furthermore, our current action state affects how we process
the what that is out there.
                                                              2110

