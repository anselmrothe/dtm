UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic and Controlled Processes in Semantic Priming: an Attractor Neural Network
Model with Latching Dynamics
Permalink
https://escholarship.org/uc/item/6b83k8mt
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Lerner, Itamar
Bentin, Shlomo
Shriki, Oren
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

      Automatic and Controlled Processes in Semantic Priming: an Attractor Neural
                                     Network Model with Latching Dynamics
                                          Itamar Lerner (itamar.lerner@gmail.com)
                      Interdisciplinary Center for Neural Computation, The Hebrew University of Jerusalem
                                                  Giv'at Ram, Jerusalem 91904 Israel
                                          Shlomo Bentin (shlomo.bentin@huji.ac.il)
                                   Department of Psychology, The Hebrew University of Jerusalem
                                               Mount Scopus; Jerusalem 91905 Israel
                                               Oren Shriki (oren70@gmail.com)
               Department of Physiology and Neurobiology, Faculty of Medicine, Ben-Gurion University of the Negev
                                                       Be'er-Sheva 84105 Israel
                             Abstract                                nodes that are connected to each other according to their
                                                                     semantic relatedness. When a concept is activated (by exter-
   Semantic priming involves a combination of automatic proc-
   esses like spreading activation (SA) and controlled processes     nal or internal input) the activity spreads to related concepts
   like expectancy and semantic matching. An alternative ac-         (see figure 1). In priming experiments, activation of the
   count for automatic priming has been suggested using attrac-      prime concept (e.g. table) leads to activation of its related
   tor neural networks. Such networks offer a more biologically      concepts (e.g. chair). This pre-activation facilitates the rec-
   plausible model of real neuronal dynamics but fall short in       ognition of subsequent related targets. If an unrelated or a
   explaining several important effects such as mediated and         neutral target appears, no such head-start is available. Hence
   asymmetrical priming, as well as controlled effects. We de-
   scribe a new attractor network which incorporates synaptic
                                                                     spreading activation may account for the facilitation com-
   adaptation mechanisms and performs latching dynamics. We          ponent of semantic priming. Automatic priming can also be
   show that this model can implement spreading activation in a      conceived in attractor networks with distributed representa-
   statistical manner and therefore exhibit all priming effects      tions of concepts (e.g. Mason, 1995). In such models con-
   previously attributed to automatic priming. In addition, we       cepts are represented by activity patterns of neurons’ as-
   show how controlled processes are implemented in the same         semblies and semantic relationship is implemented as corre-
   network, explaining many other semantic priming results.          lation between these representations. When the prime ap-
   Keywords: Semantic priming; Attractor networks; Latching          pears, the network converges on its corresponding activity
   dynamics                                                          pattern. When the target is then presented, the network
                                                                     changes its activity pattern from that of the prime to the one
                         Introduction                                corresponding to the target. If the target is related to the
Semantic priming is one of the most important phenomena              prime, fewer changes need to take place due to the correla-
in the study of word perception and semantic memory. In a            tions; therefore, the convergence takes less time and a prim-
typical priming experiment (Neely, 1991), subjects are visu-         ing effect emerges.
ally exposed to two words in succession, the prime and the              Attractor networks are probably more true to the biologi-
target, and are required to silently read the prime and either       cal nature of real neuronal dynamics which include content-
name the target (pronunciation task), or decide whether it is        addressable memories, distributed representations and at-
a real word or not (lexical decision task). The target could         tractor states. However, they fall short in explaining several
either be semantically related or unrelated to the prime (or a       important priming results. Mediated priming is one example
nonword, in case of the lexical decision task). The priming          (e.g. McNamara, 1992): It was found that word pairs which
effect is expressed as shorter average reaction times (RT)           are indirectly related to each other (i.e., related only through
and reduced error rates in the related relative to unrelated         a mediating word, like lion and stripes, related through ti-
condition. Sometimes, a neutral prime is used (e.g. a row of         ger) can nevertheless prime each other. Allowing activation
X’s) to allow the differentiation between response facilita-         to spread to more than one step, SA theories could easily
tion (in the related condition) and inhibition (in the unre-         account for such effects. Attractor networks, on the other
lated condition).                                                    hand, cannot explain mediated priming since the activation
   Computational accounts for semantic priming are divided           patterns of indirectly related pairs are not correlated. Simi-
between models based on automatic processes and those                larly, whereas SA models allow asymmetric connections
based on controlled processes. The most famous among the             between nodes and therefore allow asymmetric priming (in
automatic accounts for priming is the spreading activation           which the magnitude of priming varies according to which
(SA) theory of Collins & Loftus (1975). This model sug-              word in a given pair is designated prime and which is the
gests that concepts in semantic memory are represented by            target; e.g. pay-check vs. check-pay), such an effect cannot
                                                                   1112

be obtained by attractor network models because they rely          The neurons themselves are analog with activity in the
on correlation, a symmetric trait by definition.                range [0,1] and obey a logistic transfer function of their lo-
   Here we present an attractor neural network which im-        cal input h(t). The local input itself obeys a linear differen-
plements SA in a statistical manner. By doing so, we bridge     tial equation (following Herrmann, Ruppin & Usher, 1993)
between SA and attractor models and show how attractor          of the form:
networks can exhibit results like mediated and asymmetric                                  N
priming. In addition, we discuss some controlled mecha-                                                                       [                ]
                                                                (1) τ nh&i (t) = −hi (t) + ∑Jij x j (t) − λ ⋅ (x(t) − p) −θ + Iiext (t) −θ ext + +ηi
                                                                                           j=1
nisms like expectancy (Becker, 1980) and semantic match-
ing (Neely, Keefe & Ross, 1989) and suggest how they may           In (1), τn is the time constant of the neuron, xj(t) the activ-
be interpreted within the same network.                         ity at time t of the j-th neuron (with x indicating average
                                                                over all neurons), Jij is the connectivity weight, N is the
                                                                number of neurons (500 in our case), p is the sparseness of
                                                                the representations, λ a regulation parameter which main-
                                                                tains stability of mean activation, and θ is a constant neu-
                                                                ronal threshold (See Herrmann et al. for details). The […]+
                                                                symbol indicates a threshold linear function, such that
                                                                [x]+=0 for x<0, and [x]+=x otherwise. This leads the external
                                                                                                  ext
                                                                input to the neuron, Ii (t), to be consequential only if it
                                                                                                                            ext
                                                                surpasses the constant external threshold θ . Finally, ηi is a
     Figure 1: The spreading activation theory. (A) Related
                                                                noise term drawn from a Gaussian distribution with some
   concepts connected in semantic memory. (B) Activation
                                                                temporal correlations. Relatedness between concepts is im-
                   spreads through the network
                                                                plemented in the model as correlations between memory
                                                                patterns (reflecting the degree of overlap between them).
                   Computational Model                          The stronger two concepts are related, the higher is their
   Following the traditional separation between stages of       correlation. The correlation of unrelated patterns is negligi-
processing (e.g. Smith et al., 2001), our model consists of 2   ble (|c|<0.05 with c being the correlation)
computational layers, lexical and semantic (Figure 2). We          Two major differences distinguish the lexical from the
assume that after a string of letters is analyzed for ortho-    semantic network. First, while the semantic network in-
graphic composition, the result is fed to the lexical network   cludes correlated memory patterns representing semantic
where word identification occurs. If the letters form a real    relations between concepts, there are no correlations in the
word, this word is ‘recognized’ by the lexical network and      memory patterns of the lexical network. This is not to indi-
its activity is fed forward to the semantic network where the   cate there are no lexical relations (such relations obviously
word’s meaning is stored. However, the semantic network         exist), but merely to ensure that they would not influence
can influence lexical processing on line via feedback. Such     the simulations. Indeed, typical semantic priming experi-
a top-down effect contributes to semantic priming: when the     ments do control for such confounds by selecting prime-
semantic network is a priori ‘tuned’ to a concept with some     target pairs that bare no lexical/phonological relations.
relatedness to the newly arrived word, the lexical network         The second difference is, perhaps, the basic premise of
recognizes this word quicker because both bottom-up and         our model: Unlike the lexical network (and the majority of
top-down pathways contribute to the recognition process (as     previous attractor network models), our semantic network is
opposed to the unrelated case, where the top-down pathway       associative in nature. Neuronal adaptation mechanisms at
does not contribute). In the case of a neutral stimulus, none   the synaptic level preclude the network from maintaining
of the networks is activated and no transfer of information     stability for long; therefore, the network, after converging to
occurs.                                                         one attractor, leaves it quickly and jumps to another one.
   The lexical and semantic networks are modeled as Hop-        This process is stochastic in nature and can continue forever
field-type attractor neural networks, with sparse representa-   as long as no new input interferes. These jumps cannot be
tions and continuous-time dynamics (see Tsodyks, 1990). In      accurately predicted, but they tend to happen (although not
our simulations, both the lexical and the semantic networks     necessarily) between correlated patterns. Such network be-
are fully connected recurrent networks, each composed of        havior was termed ‘latching dynamics’ by Treves (2005).
500 neurons. Memory patterns (concepts) encoded by each         Specifically, short-term synaptic plasticity was modeled
network are binary vectors of size 500, with ‘1’ indicating a   according to Loebel & Tsodyks (2002), with each synaptic
maximally active neuron, and ‘0’ an inactive one. The rep-      weight of a neuron decreasing linearly with its activity:
resentations are sparse (i.e., a small number of neurons are                                        max
                                                                                               J ij      − J ij (t )
active in each pattern) with p being the ratio of active neu-                (2) J&ij (t ) =                         − Uxmax xi (t ) J ij (t )
rons (p<<1). The connectivity between neurons assures                                                   τr
stability of these patterns. External inputs to and from the                     max
                                                                   In (2), Jij         is the common Hopfield connectivity weight
network are always excitatory.
                                                                for sparse networks, τr is the time constant of recovery of
                                                                the synaptic efficacy, and U is the utilization of synaptic
                                                              1113

resources. The term xmax is a hypothetical maximum firing        resulted in patterns 1 and 9 being indirectly related. The 17th
rate of a neuron (for example 100 pulses/sec) which adjusts      memory pattern was a ‘baseline’ pattern which the network
the equation to fit a neural firing rate bounded by 1.           was initialized to at the beginning of each trial, and was not
   Links between the lexical and semantic networks are           correlated to any of the other patterns. In the lexical net-
based on connections between active neurons in correspond-       work, all 17 patterns were unrelated to each other. The 17th
ing patterns (See figure 2): An active neuron in a certain       pattern was, again, the initial state for the network, and was
word pattern in the lexical network sends excitatory connec-     not linked through top-down or bottom up lexical-semantic
tions to all active neurons in the corresponding concept-        connections to the baseline pattern in the semantic network
pattern of the semantic network, and vice-versa. Since cor-      (thus forming a ‘neutral’ pattern).
relations between patterns exist in the semantic network,
one neuron in that layer could concurrently influence and        Experimental Procedure and Data Analysis
receive input from different neurons activated in different      Each trial began with the presentation of a binary vector to
patterns in the lexical layer. The lexical network also re-      the lexical network, corresponding to one of its patterns (1’s
ceives bottom-up input, representing the visual letter-string,   in the to-be activated neurons, 0’s in the rest). This vector
which follows the same logic: Neurons belonging to the           served as “prime”. In neutral trials, pattern 17 (the neutral
pattern presented to the lexical network receive excitatory      pattern) was presented. Two experiments were conducted.
inputs, while others receive no input.                           The first tested the general performance of the semantic
                                                                 network. The prime was presented for 100ms and it was
                                                                 always pattern no. 1. The network was allowed to advance
                                                                 according to the dynamic equations without further interfer-
                                                                 ence, for a total period of 3000ms. The procedure was re-
                                                                 peated for 100 trials. Correlation of the momentary network
                                                                 state with each pattern, for each time point in the simulation,
                                                                 was averaged offline. The second experiment tested whether
                                                                 the performance of the model, when semantic priming oc-
                                                                 curs, corresponds with predictions based on human studies.
                                                                 The prime was presented for 100ms and followed by a tar-
                                                                 get after 150 ms, hence creating a 250 ms SOA. The time
                                                                 interval from target onset until convergence of the lexical
                                                                 network indexed the reaction time, providing the network
                                                                 converged to the correct attractor. Primes and targets were
    Figure 2: Architecture of the model. Two recurrent net-      either directly related (i.e., two patterns from the same
   works connected to each other with excitatory links. The      neighborhood), indirectly related (two patterns from differ-
     semantic network contains correlated representations        ent neighborhoods but linked through a mediating pattern as
                                                                 explained earlier), unrelated (two patterns from different
                        Simulations                              neighborhoods with no indirect connections), or neutral (in
                                                                 which the prime was the neutral pattern and the target any of
The simulations were run on an Intel Core 2 Quad CPU
                                                                 the ‘real’ patterns). 100 trials were simulated for each relat-
Q6600 with 2.4 Ghz and 2 GB of RAM. Simulations were
                                                                 edness condition, with prime-target pairs chosen randomly.
written in Matlab 8a. In all the simulations, one numeric
                                                                 Mean reaction times and standard errors were computed for
step represents 0.66ms.
                                                                 each condition.
Encoded Patterns
                                                                 Results
We encoded 17 memory patterns in each network. All pat-
                                                                 Figure 3 presents the typical performance of the two net-
terns were binary vectors with equal mean activity and very
                                                                 works (for presentation purposes, here we used a 1000ms
sparse representations. In the semantic network, the follow-
                                                                 SOA). Correlation of the state of each network with each of
ing basic correlations between patterns were set: four
                                                                 its stored patterns (including the memories and the neutral
groups, each containing four patterns, formed ‘semantic
                                                                 pattern) during a trial is presented in different colors, with
neighborhoods’ (patterns 1-4, 5-6, 9-12 and 13-16): Each
                                                                 convergence to a specific pattern indicated by its number
pattern in a group was correlated with the other patterns in
                                                                 appearing on top. The lexical network followed the external
its group, but, with few exceptions (see below), no correla-
                                                                 input, by converging to the corresponding memory pattern
tions existed between the groups. Correlations within a
                                                                 and keeping stability until a new input arrived. In contrast,
group had one of two values, representing two levels of di-
                                                                 the semantic network converged to the appropriate memory
rect relatedness. In addition, we also added some correla-
                                                                 pattern, only to jump to other attractors in a serial manner,
tions between patterns of different neighborhoods to allow
                                                                 hence presenting latching dynamics. When a new external
indirect priming investigations. For example, we added
                                                                 input arrived, the semantic network stopped its transitions
some correlation between pattern 2 and pattern 9, which
                                                                 and quickly converged to the corresponding memory pattern
                                                               1114

shortly after the lexical network has done so. As evident in       correspond to the network reaching an attractor. In other
Figure 3, most jumps were within the neighborhood, while           words, activation does not spread in a monotonic manner
jumps to different neighborhoods occurred less frequently.         like in the original SA model, but rather in jumps which fit
                                                                   the dynamical jumps from one attractor to another.
        Figure 3: Typical behavior of the two networks
    In the first experiment, trials always included pattern 1 as
the prime. The mean correlation between the state of the
semantic network and all its memory patterns was computed
for each time point over trials. Figure 4A presents the corre-
lations for five different time points after the prime onset.
The x-axis represents different patterns according to their
relatedness to pattern 1, with pattern 1 itself in the middle.
                                                                       Figure 4: Simulations results. (A) Statistical spreading
Evidently, the mean correlations followed the principle of
                                                                     activation portrayed by the network as mean correlation
spreading activation: Initially, the concept represented by
                                                                      over trials. (B) Mean convergence times of the lexical
the external input has the strongest activation (correlation),
                                                                          network for the different relatedness conditions
its directly related concepts are activated to a smaller de-
gree, and concepts not related to it are not activated at all.        The results of the second simulation demonstrate how the
With time, as semantic transitions occur, the mean activa-         dynamics in the semantic network affects the convergence
tion of the initial concept is decreasing, while activation in     time of the lexical network such that priming effects are
its related concepts increases. Indirectly related concepts        produced. When the semantic network state is correlated
also show some activation, with a delayed peak. Unrelated          with the target pattern at the moment the target word ap-
concepts receive no activation at all. After enough time, the      pears, its top-down influence shorten the lexical network’s
mean correlation with each of the network’s patterns is di-        convergence times. Due to semantic transitions, such corre-
vided more or less equally, corresponding to a nearly deac-        lations may occasionally appear in indirectly related trials
tivated state of the whole network (the mean activity would        and produce the mediated priming effect. Although not ex-
have reached near zero values in case more than 16 patterns        plicitly simulated, these jumps can also produce asymmetry
were used).                                                        in priming: Transition probabilities from pattern A to pat-
   In the second experiment, the mean RTs of the lexical           tern B are not necessarily equal to those from B to A since
network were computed and are presented in figure 4B. As           network transitions, in general, are uniquely influenced by
can be seen, priming occurs for both directly and indirectly       the other memory patterns A and B are correlated with
related pairs, although the effect is stronger in the direct       (which can be very different for A and for B). This asymme-
case. In addition, weak relations produced smaller priming         try allows making a distinction between semantic related-
than strong relations. All these effects were significant at p     ness (as indicated by correlation) and associative relatedness
< 0.001. There was no significant difference between the           (as indicated by the probability of one pattern leading to
unrelated and neutral conditions, confirming that only facili-     another pattern). Former attractor models relied solely on
tation occurred.                                                   correlations between prime and target and therefore could
                                                                   not produce either mediated priming or asymmetry in prim-
                         Discussion                                ing.
   The results of these simulations demonstrated that an at-
tractor neural network with latching dynamics can imple-                             Controlled Processes
ment spreading activation in a statistical manner. In a way,          When the SOA between prime and target is sufficiently
one could see the activity of nodes in the original spreading      long, subjects may decide to engage in specific strategies
activation model as an average manifestation of the correla-       while responding. The general aim of such strategies is to
tion in our attractor model. There is, however, an important       shorten reaction times to the target. In contrast to the auto-
distinction between our model and SA models: In our net-           matic nature of SA, strategies are considered to be under the
work, spreading is mixed with relaxation periods which             subject’s cognitive control.
                                                                 1115

   A well known example of such strategies is expectancy          almost always occur from the prime to its most correlated
(Becker, 1980). It is assumed that subjects may be able to        pattern (as opposed to the more stochastic nature of transi-
realize that in part of the trials, the target is semantically    tions in the default state). The first suggestion can be im-
and/or associatively related to the prime and develop a set of    plemented by allowing the network to make a single jump,
expected targets from the prime’s semantic “neighborhood”.        as usual, but then stop any further transitions by lowering
When the target appears, this “expected set” is searched          the background noise. This means, of course, that noise am-
first, while the general lexicon is searched only if the target   plitude must be susceptible to cognitive control. We suggest
is not included in the expected set. Obviously, when the          that this is the equivalence of ‘focusing attention’ on the
target is found in the expected set, its recognition time is      prediction. The second suggestion can be implemented by
accelerated. If it is not found there, however, its recognition   lowering the amplitude of the temporal correlations of the
is delayed by this initial screening procedure. Hence, the        noise, which may be seen as focusing attention on the most
application of an expectancy strategy may account for both        probable prediction. Each of these two manipulations, as
facilitation and inhibition of the priming effect. Two types      well as their combination, may have beneficial results: In
of this strategy were identified (Becker, 1980): A ‘predic-       case they succeed (i.e., the target indeed turns out to be the
tion’ strategy is used when the upcoming target is highly         equivalent of the pattern the network has jumped to), an
predictable. Only one item (or very few) is included in the       increase in priming is to be expected compared to the de-
expected set and, consequently, facilitation is robust while      fault case since all of the activated neurons of the semantic
inhibition is negligible. A ‘general expectation’ strategy is     network would participate in accelerating the response.
used when more than a few items could potentially be tar-         Without such intervention, the network is much less likely
gets and the expected set includes them all. Both facilitation    to be converged on the ‘right’ pattern when the target ar-
and inhibition should result. However, subsequent studies         rives, which implies that on average, only a minor set of the
have shown that not all conditions yield inhibition (for ex-      activated neurons will participate in the acceleration of re-
ample, pronunciation tasks), which put this later strategy        sponse. Naturally, if the prediction is wrong, the response
into question (Keefe & Neely, 1990). In either case, the re-      might be delayed compared to the default case. Hence this
quirements for this controlled process to be initiated are        mechanism should be used only when there are good rea-
sufficiently long SOA and a sufficiently salient proportion       sons to assume the target is predictable, that is, when the
of related pairs in the stimulus set (called the ‘relatedness     relatedness proportion is high. Moreover, the effect of these
proportion’) which makes such expectancies reasonable.            manipulations is expected to be most conspicuous on long
Indeed, it was found that the relatedness proportion is posi-     SOAs, since on short SOAs there is usually not enough time
tively correlated with priming, but only at long SOAs             for a transition to occur, let alone a series of transitions.
(Neely, 1991).                                                       As an illustrative example, we have repeated simulation 2
                                                                  for direct, indirect and neutral primes, for short/long SOAs,
Controlled Processes in the Model                                 but this time we manipulated the amplitude of the noise. In
So far, we implicitly assumed that semantic transitions in        one condition, the noise was reduced after the first transition
the network happen automatically. We now turn to a differ-        in the semantic network (implementing the first mechanism
ent hypothesis: Semantic transitions may be controlled to         we suggested for expectancy). In the other condition, no
some degree; therefore, while SA is the default behavior of       such manipulation was conducted. Figure 5 presents the
the network when no interventions occur, other patterns           results. As can be seen, the manipulation increased the fa-
emerge as soon as subjects attempt to control these transi-       cilitation effect, echoing the results in the literature (e.g.
tions.                                                            Neely, 1991).
   Controlling transitions can allow our model to implement
the ‘prediction strategy’ of expectancy, if we consider the
transition of the semantic network’s state from a given
prime pattern to another pattern as an ‘expected’ word for
that prime. By default, such expected word is determined
according to semantic relatedness principles. However, this
conceptualization of expectancy makes it no different than
our implementation of SA. What, then, makes expectancy a
distinct mechanism? The answer is that expectancy can be
modeled as the controlled operation of manipulating transi-
tion probabilities according to any information acquired by
the subject up to that point, as to induce certain transitions
and avoid others. For instance, expectancy can be realized             Figure 5: average convergence times of the lexical net-
by maintaining just one single transition in the semantic                work with and without an expectancy mechanism
network (as opposed to many transitions in the default case).
Another realization can be by controlling the variability of         Another controlled process presented in the literature is
the semantic network’s transitions, such that transitions will    semantic matching (Neely et al., 1989). This process mainly
                                                                  involves decision making strategies which occur after lexi-
                                                                1116

cal access to the target is achieved. In principle, it suggests                              Conclusion
that subjects engage in comparison between prime and tar-
                                                                     Attractor neural networks have traditionally struggled with
get, which enables them to facilitate word and nonword re-
                                                                     several important aspects of semantic priming compared to
sponses in the lexical decision task (and is also responsible,
                                                                     the more classical views. We have shown that an attractor
as a by-product, to inhibition in priming)
                                                                     network with latching dynamics can in fact implement some
   While the scope of this paper did not allow us to fully
                                                                     of these classical processes and serve as an equally compe-
model the semantic matching mechanism (which would
                                                                     tent model. The model may also be used to predict the time
necessitate incorporating a decision making mechanism), we
                                                                     course of priming with SOA, which in turn could be vali-
would like to point out that any comparison between prime
                                                                     dated by appropriate experiments. Future work will need to
and target must depend on the prime being constantly acti-
                                                                     specify in a more precise manner the exact ways by which
vated in semantic memory throughout the whole trial, which
                                                                     strategies may influence our model’s dynamics and how
in turn may indicate that no semantic transitions should oc-
                                                                     priming is affected by them.
cur in the semantic network. This, of course, can be
achieved in our model by assuming a reduction in the noise
amplitude immediately after lexical access of the prime (as                                  References
opposed to the expectancy strategy case, where such a re-            Becker, C. A. (1980). Semantic context effects in visual
duction is applied only after one semantic transition). We              word recognition: An analysis of semantic strategies.
would therefore expect the usage of semantic matching to                Memory & Cognition, 8, 493–512.
place severe limitations on spreading activation behavior,           Collins, A. M. & Loftus, E. F. (1975). A spreading activa-
and specifically eliminate the indirect priming effect. Inter-          tion theory of semantic processing. Psychological Re-
estingly, this is exactly the result found in the literature (e.g.      view, 82, 407–428.
McNamara, 1992; see Neely, 1991, for a review).                      Herrmann, M., Ruppin, E. & Usher, M. (1993). A neural
                                                                        model of the dynamic activation of memory. Biological
                    General Discussion                                  Cybernetics, 68, 455–463.
                                                                     Keefe, D. E., & Neely, J. H. (1990). Semantic priming in
Our main goal in the current study was to implement classi-
                                                                        the pronunciation task: The role of prospective prime-
cal semantic processes related to semantic priming, with an
                                                                        generated expectancies. Memory & Cognition, 18, 289–
emphasis on spreading activation, in a biologically-plausible
                                                                        298.
framework of attractor neural networks. The results demon-
                                                                     Loebel A., & Tsodyks M. (2002). Computation by ensem-
strate that the basic characteristics of SA can be embedded
                                                                        ble synchronization in recurrent networks with synaptic
in attractor dynamics while maintaining the same explana-
                                                                        depression. Journal of Computational Neuroscience, 13,
tory power of the original process. In addition, we show that
                                                                        111–124.
controlled mechanisms involved in priming such as expec-
                                                                     Masson, M. E. J. (1995). A distributed memory model of
tancy can be implemented within the same network, where
                                                                        semantic priming. Journal of Experimental Psychology:
the definition of ‘controlled’ is narrowed to the subject’s
                                                                        Learning, Memory, and Cognition, 21, 3–23.
influence on some specific parameters of the network.
                                                                     McNamara, T. P. (1992). Priming and constraints it places
   Our network implies that real automaticity is the product
                                                                        on theories of memory and retrieval. Psychological Re-
of correlated representations. Direct semantic priming is a
                                                                        view, 99, 650–662.
purely automatic process since, by definition, one pattern
                                                                     Neely, J. H. (1991). Semantic priming effects in visual
cannot be activated without partially activating its correlated
                                                                        word recognition: A selective review of current findings
patterns. On the other hand, processes which require a trans-
                                                                        and theories. In D. Besner & G. Humphreys (Eds.), Basic
formation from one representation to another can in princi-
                                                                        processes in reading: Visual word recognition. Hillsdale,
ple be the object of cognitive control. Indirect priming can
                                                                        NJ: Erlbaum.
therefore be avoided by eliminating transitions in the se-
                                                                     Neely, J. H., Keefe, D. E. & Ross, K. L. (1989). Semantic
mantic network. Spreading activation, by this view, is best
                                                                        priming in the lexical decision task: roles of prospective
seen as a default mechanism rather than a process which is
                                                                        prime-generated expectancies and retrospective semantic
completely automatic (cf. Smith et al., 2001).
                                                                        matching. Journal of Experimental psychology: Learning,
   Finally, a pure mathematical interpretation of the dynam-
                                                                        Memory, and Cognition, 15, 1003–1019.
ics would suggest that the nature of the transitions between
                                                                     Smith, M. C., Bentin, S. & Spalek, T. M. (2001). Attention
patterns in our model takes the form of a Markov-chain,
                                                                        constraints of semantic activation during visual word rec-
with the average correlation of the network with the various
                                                                        ognition. Journal of Experimental psychology: Learning,
patterns forming a state vector and the transition probability
                                                                        Memory, and Cognition, 27, 1289–1298.
matrix representing word association norms. Controlled
                                                                     Treves, A. (2005). Frontal latching networks: A possible
strategies therefore represent a change in this matrix from
                                                                        neural basis for infinite recursion, Cognitive Neuropsy-
the default values, based on the subject’s expectations. Fu-
                                                                        chology, 22, 276-291.
ture inquiries may reveal the exact way by which accumu-
                                                                     Tsodyks, M. V. (1990). Hierarchical associative memory in
lating data affect these probabilities, with Bayesian infer-
                                                                        neural networks with low activity level. Modern Physics
ence principles possibly governing this procedure.
                                                                        Letters B, 4, 259-265.
                                                                   1117

