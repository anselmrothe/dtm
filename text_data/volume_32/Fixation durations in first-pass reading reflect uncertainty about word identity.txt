UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Fixation durations in first-pass reading reflect uncertainty about word identity
Permalink
https://escholarship.org/uc/item/2d09z0n9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Smith, Nathaniel
Levy, Roger
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                      University of California

    Fixation durations in first-pass reading reflect uncertainty about word identity
                                                            Nathaniel J. Smith
                                                        njsmith@cogsci.ucsd.edu
                                              UC San Diego Department of Cognitive Science
                                         9500 Gilman Drive #515, La Jolla, CA 92093-0515 USA
                                                                 Roger Levy
                                                           rlevy@ling.ucsd.edu
                                                  UC San Diego Department of Linguistics
                                         9500 Gilman Drive #108, La Jolla, CA 92093-0108 USA
                               Abstract                                 word is identified, but when reading, the ultimate outcome is
                                                                        not the name of a single word, but an understanding of the
   In reading, it is often assumed that words are recognized suf-       text as a whole. Here, we ask: can the linguistic processing
   ficiently quickly, accurately, and unambiguously that down-
   stream processes may proceed with perfect information about          associated with a word proceed before that word is uniquely
   word identity. For example, word predictability is believed to       identified? And if so, what are the consequences for pro-
   affect early reading time measures, yet a word’s predictability      cessing? It’s possible that neighborhood effects are limited
   cannot be calculated without knowledge of the word’s identity.
   We argue that such information is not, in general, available         to some early, serial, word identification process, in which
   to the language processing system, and that it proceeds with         any uncertainty is resolved before higher-level linguistic pro-
   only probabilistic information about word identity. We pre-          cesses begin. Alternatively, this uncertainty may be propa-
   dict therefore that what have been analyzed previously as pre-
   dictability effects must instead be based on noisy estimates of      gated through the linguistic processing system itself.
   word predictability that are influenced by the predictability of        Most current models of high-level language processing fall
   visually similar words (neighbors). We test this prediction by
   building a Bayesian model of visual word recognition, using it       into the former category; for instance, they take as input
   to compute the ‘average neighborhood surprisal’ of words in a        words, rather than probability distributions over words. How-
   corpus, and testing the ability of this novel measure to explain     ever, there is some reason to suspect that the latter possibility
   human reading time data.
                                                                        is more plausible. Spoken language, in particular, is a very
   Keywords: Psychology, Cognitive Science, Perception, Lan-            noisy signal, in which word identification is generally im-
   guage Understanding, Bayesian Modeling, Neighborhood Ef-
   fects, Visual Uncertainty, Reading                                   possible without reference to high-level linguistic constraints.
                                                                        Furthermore, listeners are willing to revise their identifica-
   Performance in isolated word recognition tasks is often af-          tion of perceptually ambiguous phonetic material in light of
fected by the existence or properties of words that are not             disambiguating material that follows within a short period
presented, but that are visually similar to the words which             (Connine, Blasko, & Hall, 1991). In reading, the availabil-
are presented. For instance, a word with many neighbors                 ity of a stable visual record makes it possible in principle to
— especially high frequency neighbors — tends to produce                acquire substantially more detailed perceptual information —
a faster response in the lexical decision task, and a slower            but in practice the average fixation length in reading is 200
response in naming or reading tasks (Perea & Rosa, 2000).               ms, comparable to the time required to plan a motor saccade.
Norris (2006) has argued that these divergent results can be            This suggests that the next saccade must be initiated almost
best explained by uncertainty in the processing system. That            as soon as the fixation begins, and that decisions about its
is, noise is an inevitable component of all biological compu-           timing — and thus the fixation time for the current word —
tation, and if the processor receives only noisy information            must be made before the current word is fully processed. In
about a word’s shape, then it must consider all similar look-           addition, Levy, Bicknell, Slattery, and Rayner (2009) have
ing words as candidates for identification. When there are              recently used evidence from a reading task to argue that cer-
many such candidates, identifying the single correct candi-             tain syntactic constructions associated with garden-path-like
date (as in the naming task) becomes more difficult, because            processing difficulty may arise from uncertainty about the
there are many incorrect distractors and only one correct tar-          identity of critical words earlier in the sentence. Therefore
get; resolving this difficulty requires the acquisition of more         it seems plausible that the language processing system not
sensory information, which requires more time. In the lexical           only has the capacity to handle uncertain input, but that this
decision task, however, it is not necessary to determine which          ability is used in natural reading.
word is seen, only whether a word is seen, and therefore in-               Here, we examine this question via the well-known effect
creasing the number of candidates only makes it easier to give          of word predictability on reading time (predictable words are
a correct response (even if for the ‘wrong’ reason).                    read more quickly, Ehrlich & Rayner, 1981). This is a useful
   However, in reading — that is, processing connected lan-             tool, because (i) the effect is very early; it affects the duration
guage, rather than isolated words — another consideration               of initial fixations on a word, in the 200–300 ms range, when
arises. In a naming task, no response can be given until the            we would most expect some uncertainty to remain, and (ii)
                                                                    1313

as word predictability depends on the fit between the present        a word as simply the product of the evidence for each of the
word and its context, it implicates higher-level linguistic pro-     n letters which comprise it. If E is the complete perceptual
cessing in a way that word frequency, for instance, might not,       input derived from a word and Ei is the component of that
and yet (iii) it cannot affect processing until the word is fully    perceptual input arising from the i-th letter, then normative
identified, because different words are differently predictable.     Bayesian inference for the word’s identity looks as follows:
All theories which invoke word predictability to explain early
reading time measures therefore implicitly assume that word                                        P(E|letters)P(letters)
                                                                             P(letters|input) =
identification occurs early and fully.                                                                        P(E)
   We hypothesize that this effect does not arise from pre-                                     ∝ P(E1 , . . . , En |letters)P(letters)
dictability per se, but from the processing system’s ‘best                                                        n
guess’ at the word’s predictability, given the uncertain in-                                    = P(letters) ∏ P(Ei |letteri )
formation available to it. To test this hypothesis, we build                                                     i=1
a simple Bayesian model of visual word recognition, use it           The term P(letters) is simply the prior probability of the word
to estimate ‘best guess’ predictabilities on a corpus, and test      in question; the perceptual evidence for the word is repre-
whether this improves our ability to predict human reading-          sented by the term ∏ni=1 P(Ei |letteri ).
time measures.                                                          To estimate the perceptual evidence P(Ei |letteri ) ob-
                  Word recognition model                             tained from each position in the word, we made use of
                                                                     letter-confusion matrices derived from previous norming
We begin with a standard Bayesian model of word recog-               experiments with the lowercase English alphabet (Engel,
nition in sentence context, in which beliefs about the iden-         Dougherty, & Jones, 1973; Geyer, 1977). In each of these
tity of the word on which the eyes are currently fixated are         experiments, participants were presented with isolated letters
formed by integrating top-down prior expectations from lan-          for durations brief enough to induce considerable identifica-
guage knowledge and context with bottom-up perceptual in-            tion error, and the frequency with some presented letter α was
put:                                                                 identified as some letter β was tabulated as fαβ . Here α = β
                                                                     implies correct identification and α 6= β implies misidentifica-
   P(word|context, input)
                                                                     tion. Finally we used these frequency tables to obtain a matrix
               P(word|context)P(input|word, context)                 M, in which each entry Mαβ denotes the estimated probabil-
            =                                                 (1)
                                P(input)                             ity of identifying letter α as β. For example, Mti is relatively
                                                                     high, presumably reflecting the visual similarity of the letters
The first term in the numerator, P(word|context), corresponds
                                                                     t and i, whereas Mtn is relatively low.
to top-down prior expectations and can be estimated from
                                                                        Since these norming studies used viewing conditions rather
any of a variety of language-modeling techniques standard in
                                                                     unlike those that occur in natural reading, we assume that the
computational linguistics (Manning & Schütze, 1999). The
                                                                     matrix entries Mαβ specify only the relative perceptual ev-
second term in the numerator, P(input|word, context), corre-
                                                                     idence provided by each letter of the word, rather than the
sponds to bottom-up perceptual evidence and is the present
                                                                     absolute evidence. We therefore introduce a single free pa-
focus: we are investigating the possibility that this evidence
                                                                     rameter q which scales the matrix as a whole, so that for the
is imperfect and that this imperfection may be reflected in
                                                                     i-th letter of a word in a sentence,
rapid eye-movement decisions in reading.
   We introduce three simplifying assumptions to make our                              P(Ei = α|letteri = β) ∝ (Mαβ )q .                  (2)
model of perceptual evidence more tractable. First, we as-
sume conditional independence between input and context              This allows us to estimate the overall level of noise in the
given word identity, which is natural since it is the word be-       model when analyzing human reading-time data.1 The pa-
ing identified rather than the preceding context that gener-         rameter q can be interpreted as the overall quantity of in-
ates the relevant perceptual input. Second, we assume that           formation acquired by the reader and used to inform down-
readers are aware of how many letters exist in the word that         stream decisions; each entry in the confusability matrix is
they are looking at, and only their identity is in doubt. (A         raised to the power q, and then rows are renormalized. Thus,
more detailed model would certainly relax this assumption,           q = 0 creates a uniform posterior distribution over letters,
but we believe that the high visual salience of inter-word           or perfect ignorance, while in the limit as q goes to infin-
spaces makes it a reasonable initial approximation.) Third,          ity, the matrix becomes diagonal — representing perfect in-
we assume that the subjective evidence for a given letter de-
                                                                         1 Note that we are making a simplifying assumption by equating
pends only on the noisy input we receive describing that letter
                                                                     the perceptual evidence from the i-th letter with the letter actually
(and this noisy input, of course, depends in turn on the letter      in the word, rather than with noisy perceptual input generated from
that is actually present in the world). In particular, we as-        the actual letter, as is done in models such as (Norris, 2006). This
sume that our bottom-up perceptual evidence for each letter          simplifying assumption can be interpreted roughly as marginalizing
                                                                     over the perceptual input itself; see (Smith, Chan, & Levy, 2010) for
in a word is probabilistically independent of that for the other     discussion of the justification for and implications of this simplifying
letters. Therefore, we can write the perceptual evidence for         assumption.
                                                                 1314

formation about letter identity. Varying q between these ex-           a word with a dense neighborhood may be read either faster
tremes smoothly varies the overall accuracy of letter informa-         or slower than a word with a sparse neighborhood. It’s not the
tion available, while preserving relative differences in letter        size of your neighborhood that matters, it’s who your neigh-
similarity and recognizability. Figure 1 depicts the resulting         bors are.
letter-confusion matrices for q = 1 and q = 2.                             It should also be noted that other models of neighborhood
   This idea of rescaling was also used in producing our per-          effects generally predict that the presence of higher-frequency
ceptual confusion matrix M from the raw norming data. We               neighbors will produce an inhibitory effect on word identi-
assumed that the two experiments had different overall levels          fication, as these neighbors interfere with recognition of the
of perceptual noise, and we used maximum likelihood to find            true word (e.g., Perea & Rosa, 2000). Our prediction is nearly
the single matrix M that — when rescaled for each experi-              the opposite — that in reading, the presence of high probabil-
ment — best explained the data from both. However, simply              ity neighbors should lead to shorter initial fixations (though
averaging the two norming matrices would produce similar               it is possible that later, as more information about the word’s
results.                                                               true identity becomes available, the eyes may slow or regress
   In aggregate, these assumptions give us the following final         in compensation).
estimate of the subjective probability that we are observing a
particular word given both context and visual input:                                                Methods
   P(word|context, visual input)                                       We compared average neighborhood surprisal to raw sur-
                                                                       prisal as predictors of human reading times in the Dundee
         ∝ P(word|context) ∏ P(letteri |visual input).        (3)      eye-movement corpus (Kennedy, Hill, & Pynte, 2003), which
                               i
                                                                       consists of all eye-movements made by 10 subjects while
           Average neighborhood surprisal                              reading a collection of newspaper articles totaling approxi-
                                                                       mately 50,000 words. Several previous studies have already
Now that we have a model of the uncertainty affecting the
                                                                       demonstrated surprisal effects on reading times in the Dundee
language processing system, we can model its consequences
                                                                       corpus (Demberg & Keller, 2008; Frank, 2009; Smith &
for the predictability effect. Word predictability itself is well-
                                                                       Levy, 2008). We analyzed both first fixation times — defined
described computationally by surprisal — the negative log-
                                                                       as the duration of the first fixation to land on each fixated
probability of a word in context (Hale, 2001; Levy, 2008).
                                                                       word in a text — and second fixation times, defined as the
For clarity, in this paper we will refer to this as the raw sur-
                                                                       duration of the second fixation to land on each word that was
prisal (RS). We now define the average neighborhood sur-
                                                                       fixated a second time. We eliminated all fixations on words
prisal (ANS) of a word in some context to be the average
                                                                       that occurred at the beginning or end of a line, which pre-
of the surprisal of every word that might occur in that con-
                                                                       ceded or followed punctuation, that did not occur in the BNC
text, weighted by that word’s similarity to the visible word,
                                                                       (i.e., unknown words), or that occurred in the BNC but in
P(word|context, visual input). More formally,
                                                                       segmented form (e.g., the BNC codes don’t as two words, do
                                                                       followed by n’t). Finally, we eliminated any remaining words
   ANS(wordk |context) =
                                                                       containing uppercase letters, since our confusion norms only
          ∑ P(wordi |context, wordk )RS(wordi |context).      (4)      cover the lowercase alphabet. This left 182,169 first fixations
           i
                                                                       and 42,024 second fixations for further analysis.
Our fundamental prediction is that ANS will better predict                 To obtain conditional word probabilities for both raw sur-
reading times than RS.                                                 prisal estimates and noisy conditional word-probability esti-
   The intuition here is that the processing system would pre-         mates (Equation 3) we used a trigram language model trained
fer to spend an amount of time on a word proportional to               on the 100 million word British National Corpus (BNC),
its RS, but since visual noise makes the RS unavailable, the           using the SRI Language Modeling Toolkit (Stolcke, 2002);
ANS is the best available approximation. The visual system is          the trigram model was smoothed using modified Kneser-
accurate enough that in most cases P(wordk |context, wordk ),          Ney (Kneser & Ney, 1995), a standard technique for broad-
the subjective probability that one is looking at word k given         coverage language modeling. Average neighborhood sur-
that one is, in fact, looking at word k, will be close to one;         prisal was estimated for each fixated word by plugging in raw
therefore ANS will generally be close to the RS for any given          surprisal estimates to Equation (4), and repeating this process
word. However, if a word has visually similar neighbors with           at each value of q required by the fitting process.
higher surprisals, then this will pull up the ANS, and the                 As Smith and Levy (2008) have previously demonstrated
reader will spend more time on that word ‘just in case’ it turns       that the relationship between surprisal and first fixation times
out to be one of those high-surprisal neighbors that require           in this corpus is linear, we simply regressed fixation time on
more time to process. Contrariwise, if a word has visually             RS and ANS simultaneously, with frequency (estimated from
similar neighbors with lower surprisals, then this will pull           the BNC) and word length as controls. The noise parameter
down the average, and our reader will hurry onward faster              q was fit simultaneously with the regression coefficients by
than they otherwise might. Note especially that in this model,         maximum likelihood. Gamma distributed error was assumed,
                                                                   1315

                             Letter confusability matrix, q = 1                                    Letter confusability matrix, q = 2
                     a                                                                   a                                                              1.0
                                                                                                                                                        0.9
                     f                                                                   f                                                              0.8
                                                                                                                                                        0.7
  Presented letter                                                    Presented letter
                     k                                                                   k                                                              0.6
                                                                                                                                                        0.5
                     p                                                                   p                                                              0.4
                                                                                                                                                        0.3
                     u                                                                   u
                                                                                                                                                        0.2
                                                                                                                                                        0.1
                     z                                                                   z
                         a                                  u     z                          a                                        u          z      0.0
                               f        k          p                                                  f         k          p
                                     Hypothesized letters                                                    Hypothesized letters
Figure 1: The letter confusability matrix, for different values of the scaling parameter q. For instance, presentation of the letter
a to the noisy input system eventually gives rise to a particular posterior distribution over letters that is represented by the
top row in each matrix. The diagonal represents the probability of veridical perception; we can see that the letter d is the least
confusable in the lowercase English alphabet. As q increases (right), more information becomes available, causing the posterior
distribution to cluster around the diagonal.
in order to properly account for the long right-ward tail in                                 ever, is examination of the q value; we predicted that a second
fixation durations.                                                                          fixation would provide more visual information about word
                                                                                             identity, and thus result in a higher q. In fact, for second fix-
                                        Results                                              ations, we found q = 2.939, suggesting that by the end of the
First fixations                                                                              second fixation, the eye movement control system has access
                                                                                             to somewhat more than twice the information it has at the end
The best fitting model had a moderate level of noise (q =
                                                                                             of the first fixation.
1.306), corresponding to a mean naming accuracy for individ-
ual letters of 66%. While this may seem low, most words con-
tain enough letters that, combined with the constraint of lin-
guistic context, this allows for substantial information about                               Frequency prior
word identity. As a result, ANS and RS are highly correlated
(R2 = 0.96) — suggesting that while the models differ greatly
in terms of the cognitive processes they postulate, they may                                 Equation (4) suggests that to compute the estimated, aver-
be difficult to disentangle experimentally.                                                  age neighborhood surprisal, the processing system must be
   Even so, our data set turned out to be large enough for the                               able to, in some sense, compute the probability of all possi-
regression model to give an unambiguous result: ANS bet-                                     ble words in the current context, and sum over all of them,
ter predicts human behavior than RS. That is, ANS is highly                                  in time to affect the first fixation. This is a strong claim,
significant after controlling for RS (t(182155) = 4.164, p                                  and so to test it we calculated a simplified version of ANS
0.001), while RS has no significant effect after controlling for                             in which we modified Equation 3 to replace the context-
ANS (t(182155) = 0.489, n.s.). This result also remains after                                sensitive prior over words, P(word|context), with a sim-
controlling for neighborhood size (N).                                                       ple, context-insensitive word frequency prior, P(word). This
                                                                                             modified ANS was then added to our regression as an addi-
Second fixations                                                                             tional control. Our original context-sensitive ANS remained
The same analysis on second fixations produces analogous                                     highly significant (t(182154) = 4.413, p  0.001), suggest-
results; ANS is highly significant (t(42010) = 4.209, p                                     ing that in the neighborhood effects we describe, the defini-
0.001), while RS is marginally significant in the wrong direc-                               tion of ‘neighborhood’ is indeed sensitive to linguistic con-
tion (t(42010) = −1.847, p = 0.06). More interesting, how-                                   text.
                                                                             1316

          Other determiners of reading time                          letter-based word representation, but presumably all models
While in this preliminary work we have focused on surprisal          of word similarity/confusability are similar to the first order,
as a model reading time predictor, the essential argument ap-        and we did not compare against any other noise model; there-
plies to any word property which is believed to affect read-         fore, while our results suggest that average neighborhood sur-
ing time, and one could define average neighborhood X for            prisal drives reading time, it may be premature to conclude
any interesting property X that was believed to affect reading       that the visual system is the source of uncertainty being aver-
time (or language processing behavior more generally). Gen-          aged over.
erally, we would predict that to the extent the brain processes         In future work, we hope to make a sharper test of this
sensitive to property X must work from noisy representations         part of the model in two ways. First, we can fit a differ-
of linguistic input, average neighborhood X would also be a          ent noise parameter q for letters at different degrees of ec-
better predictor of human behavior than X alone.                     centricity from visual fixation; if this reproduces the classic
   We have begun to examine this more general prediction,            curve of acuity falling off with increasing eccentricity, then
and in the process discovered a mystery. Using the above             that would be stronger evidence that our noise arises from vi-
model to define average neighborhood word frequency, we              sual processing limitations. Second, looking the other direc-
find our regression against reading times gives just as unam-        tion, we plan to build a simple phonological/auditory noise
biguous results as for surprisal — but the other way. That is,       model, and use it to estimate ANS for written words. If this
raw frequency is significant, and average neighborhood fre-          model outperforms the visual noise model, then that would
quency is not. This suggests that whatever process produces          be strong evidence that the noise is in fact noise in some post-
word frequency effects in reading times appears to have exact        recoding internal representation. Finding auditory noise in
information about the frequency (and therefore identity) of          a visual paradigm would be quite curious, but there is some
the word being processed, while the process which produces           precedent; for instance, it has been argued that the true de-
predictability effects has only noisy and imperfect informa-         terminer of neighborhood size for purposes of word naming
tion. Furthermore, this is true even on first fixations, so it       effects is the number of words which are simultaneous visual
cannot be a simple matter of the frequency effect arising later      and phonological neighbors (Adelman & Brown, 2007).
in the processing stream, when more information is available.           Finally, we hope that further investigation may shed light
(Evidence for frequency as a later effect than predictability        on the lack of a neighborhood effect on word frequency. One
would also, it seems safe to say, surprise most experts in the       possibility is that further study of the noise, as described
field.)                                                              above, will provide a clue — perhaps visual information is
                                                                     highly accurate, the frequency effect is a relatively early and
                          Discussion                                 low-level effect acting on this low-level, accurate visual rep-
                                                                     resentation, and the predictability-sensitive process is work-
Our fundamental prediction — that early predictability ef-           ing with a later representation more subject to internal noise.
fects in reading are modulated by the predictability of visually     However, this remains mere speculation, and we welcome
similar (but unseen) words — was confirmed. Furthermore,             any suggestions on this matter. In another way, though, this
the reduction of this effect on second fixations gives insight       dissociation of frequency and predictability is quite exciting,
into the time course for resolution of uncertainty about word        as it suggests a possible avenue for understanding the rela-
identity, and the failure of the word frequency prior to ade-        tionship between these highly similar linguistic properties.
quately explain the data argues for the ability of high-level        (Indeed, as they are inherently confounded in any study us-
linguistic constraint to quickly and robustly modulate the res-      ing isolated words stripped of context, and quite difficult to
olution of visual uncertainty. All our results — with the            accurately measure and deconfound in more naturalistic stim-
possible exception of the mysterious frequency non-effect —          uli, it has long been unclear whether they represented distinct
are compatible with a model of reading in which uncertainty          effects at all.) This is, to our knowledge, the first study to
about the input is propagated forward into the linguistic pro-       find qualitatively different effects of each, and we hold high
cessing system itself.                                               hopes that our current confusion may lead to a deeper future
   Going forward, a major question is whether the noise we           understanding.
observe is truly visual noise, or whether it has another source.
After all, biological computation necessarily involves noise                             Acknowledgments
and uncertainty at every level. When reading, for example,
visual information must be gathered at the retina, transmit-         We are grateful to Michael Tanenhaus for the ini-
ted and analyzed by the visual system, and converted to some         tial suggestion of averaging surprisal over the visual
higher level representation of word identity; then, this rep-        neighborhood, and to Shane T. Mueller for maintain-
resentation must be maintained in memory for semantic pro-           ing the invaluable Letter Similarity Data Set Archive
cessing and integration. None of these processes can be per-         (http://obereed.net/lettersim/). This research was
fectly veridical or reliable; all must introduce some amount         partially supported by NIH Training Grant T32-DC000041
of noise and uncertainty. Here, we built a specifically visual       to the Center for Research in Language at UC San Diego to
noise model, relying on a visual confusability matrix and a          NJS, and by NSF grant 0953870 to RL.
                                                                 1317

                        References                                   Proceedings of the 32nd annual meeting of the cognitive
                                                                     science society.
Adelman, J. S., & Brown, G. D. A. (2007). Phonographic
                                                                   Smith, N. J., & Levy, R. (2008). Optimal processing times
  neighbors, not orthographic neighbors, determine word
                                                                     in reading: a formal model and empirical investigation. In
  naming latencies. Psychonomic Bulletin & Review, 14,
                                                                     Proceedings of the thirtieth annual conference of the Cog-
  455–459.
                                                                     nitive Science Society.
The British National Corpus, version 3 (BNC XML edi-
                                                                   Stolcke, A. (2002). SRILM — an extensible language mod-
  tion). (2007). (Distributed by Oxford University Com-
                                                                     eling toolkit. In Proc. intl. conf. on spoken language pro-
  puting Services on behalf of the BNC Consortium. URL:
                                                                     cessing (Vol. 2, pp. 901–904). Denver.
  http://www.natcorp.ox.ac.uk/)
Connine, C. M., Blasko, D. G., & Hall, M. (1991). Effects of
  subsequent sentence context in auditory word recognition:
  Temporal and linguistic constraints. Journal of Memory
  and Language, 30(2), 234–250.
Demberg, V., & Keller, F. (2008). Data from eye-tracking cor-
  pora as evidence for theories of syntactic processing com-
  plexity. Cognition, 109(2), 193–210.
Ehrlich, S. F., & Rayner, K. (1981). Contextual effects on
  word perception and eye movements during reading. Jour-
  nal of Verbal Learning and Verbal Behavior, 20(6), 641–
  655.
Engel, G. R., Dougherty, W. C., & Jones, G. B. (1973). Cor-
  relation and letter recognition. Canadian Journal of Psy-
  chology, 27(3), 317–326.
Frank, S. L. (2009). Surprisal-based comparison between a
  symbolic and a connectionist model of sentence process-
  ing. In Proceedings of the 31st annual conference of the
  cognitive science society (pp. 1139–1144).
Geyer, L. H. (1977). Recognition and confusion of the low-
  ercase alphabet. Perception and Psychophysics, 22, 487–
  490.
Hale, J. (2001). A probabilistic Earley parser as a psycholin-
  guistic model. In Proceedings of NAACL-2001 (pp. 159–
  166).
Kennedy, A., Hill, R., & Pynte, J. (2003). The Dundee cor-
  pus. In Proceedings of the 12th European conference on
  eye movement.
Kneser, R., & Ney, H. (1995). Improved backing-off for M-
  gram language modeling. In Proc. ICASSP (pp. 181–184).
Levy, R. (2008). Expectation-based syntactic comprehen-
  sion. Cognition, 106, 1093–1582.
Levy, R., Bicknell, K., Slattery, T., & Rayner, K. (2009).
  Eye movement evidence that readers maintain and act on
  uncertainty about past linguistic input. Proceedings of the
  National Academy of Sciences, 106(50), 21086–21090.
Manning, C. D., & Schütze, H. (1999). Foundations of sta-
  tistical natural language processing. MIT Press.
Norris, D. (2006). The Bayesian reader: Explaining word
  recognition as an optimal Bayesian decision process. Psy-
  chological Review, 113(2), 327–357.
Perea, M., & Rosa, E. (2000). The effects of orthographic
  neighborhood in reading and laboratory word identification
  tasks: A review. Psicológica, 21(3), 327–340.
Smith, N. J., Chan, W.-H., & Levy, R. (2010). Is perceptual
  acuity asymmetric in isolated word recognition? evidence
  from an ideal-observer reverse-engineering approach. In
                                                               1318

