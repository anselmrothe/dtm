UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognition for action: an architectural account for “grounded interaction”
Permalink
https://escholarship.org/uc/item/2p2237x8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Harrison, Anthony M
Trafton, J. Gregory
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                      University of California

         Cognition for action: an architectural account for “grounded interaction”
                                  Anthony M. Harrison (anthony.harrison@nrl.navy.mil)
                                       J. Gregory Trafton (greg.trafton@nrl.navy.mil)
                                                       Naval Research Laboratory
                                                      Washington, DC 20375 USA
                              Abstract                                     Mahon & Caramazza (2008) argue that the strict
                                                                      embodiment argument against abstract/symbolic theories
  The effects of priming are not limited to semantics but have        neglects to consider the possibility that activation, spread
  also been witnessed in visual-motor tasks (Tucker & Ellis,          through abstract symbols to modal representations, can
  2001). By generalizing ACT-R’s (Anderson, 2007) existing
                                                                      account for these very same phenomena. While recognizing
  spreading activation account to include visual representations
  and broadening the context within which associations are            that abstract/symbolic theories could accommodate such
  established, we have been able to replicate this small but          tight perceptual/action coupling, they acknowledge that
  reliable phenomenon both in simulation and embodied on a            most theories do not adequately specify the computations
  humanoid robotic platform. This model illustrates that the          and representational content that would permit such
  effect doesn’t require strict embodiment (e.g., Barsalou, 1999)     coupling through the spreading of activation. Such an
  but can instead be accounted for with abstract representations      abstract/symbolic system would be “grounded by
  that are “grounded by interaction” (Mahon & Caramazza,              interaction” (Mahon & Caramazza, 2008), if the abstract
  2008).                                                              symbols come to be tightly coupled with their related
                                                                      percepts and required actions through experience acting in
                           Introduction
                                                                      the environment. In this manner, the system would be able
One of the current drumbeats in cognitive science is that             to exploit both the flexibility of the abstract representations
cognition is for action. The strongest evidence for cognition         and the richer context afforded by grounded representations.
for action comes from experiments that show that there is a                We present an ACT-R (Anderson, 2007) model that fits
much tighter coupling of perception and action than                   within Mahon & Caramazza’s “grounded interaction”
previously thought. For example, Glenberg and Kaschak                 framework (2008) that provides a process explanation of a
(2002) found that when a sentence implied action in one               classic embodied phenomenon – the visual-motor
direction (e.g., “Close the drawer”), participants had                compatibility effect observed by Tucker & Ellis (2001).
difficulty making a sensibility judgment that required a
response in the opposite direction.              Similarly, when                          Tucker & Ellis (2001)
participants indicated whether an object like a teapot was            Tucker & Ellis (2001) report a series of experiments that
upright or upside down, reaction times were fastest when              show a small but significant effect of visual presentation on
the response hand was the same as the hand that would be              grasp responses. In experiment 1, participants viewed a
used to grasp the object (e.g., the right hand response was           series of objects of different categories (e.g., natural or man-
fastest if the teapot’s handle was on the right) (Tucker &            made) that were either large or small. The object size maps
Ellis, 1998). Many of these researchers argue that this data          directly to the normal grasp used to manipulate the object: a
shows that our thinking is fundamentally embodied, not                power-grip (i.e., full hand) for large objects and a precision-
abstract.                                                             grip (i.e., thumb and forefinger) for small ones. Objects
     The main idea behind the embodied cognition                      were placed either near the response hand (15cm) or far
movement is that cognitive representations and operations             away (2000cm). Subjects responded with either a power- or
are firmly grounded in their physical context and that                precision-grip response based on the category (i.e.,
cognition relies heavily on modality-specific systems and             natural/man-made) of the object seen. The task response-
actual bodily states (Tucker & Ellis, 1998; Barsalou, 1999;           mapping (e.g., natural/precision) was varied between
Wilson, 2002; Niedenthal, Barsalou, Winkielman, Krauth-               subjects.
Gruber, & Ric, 2005). The typical counter to embodied                      While there were some simple main effects, the critical
cognition theories are old-style abstract/symbolic theories           result from the first experiment was the interaction between
(Newell & Simon, 1972; Pylyshyn, 1984), which argue that              the size of the object and response-mapping. Despite the
actual      experience        occurs     in     modality-specific     fact that the size of the object was irrelevant to the task, its
representations, but those modality-specific states are               compatibility with the response-mapping resulted in reduced
abstracted and preserved as abstract, amodal symbols.                 reaction times and error rates (figures 1 & 2). Specifically,
Given the strength of abstract/symbolic theories, some have           when viewing large objects, power responses were faster
suggested that the only way that these theories can explain           and more accurate than precision responses. Similarly,
embodied effects is by adding increasingly complex post               viewing small objects resulted in faster and more accurate
hoc assumptions about representations and processing                  precision responses than power responses.
(Barsalou, 1999; Niedenthal et al., 2005).
                                                                  200

    In experiments 2-4b, Tucker & Ellis used a go/no-go                          To summarize, Tucker & Ellis have shown that when
paradigm, with the response-mapping cued by a tone and                      the object’s normal grasp response is compatible with the
go/no-go cued by the object category. Experiment 2                          experiment’s response-mapping, there is a small but
presented the response-mapping cue tone 500ms before                        significant benefit (experiment 1). However, this is
object presentation. The lack of a compatibility effect in the              conditional on the motor system not already being prepared
results showed that prior knowledge of the required                         for a particular response (experiments 2 & 3) and that the
response was sufficient to override the phenomenon.                         object is visible at response selection (experiments 4a &
                                                                            4b). They discount the theory that this is an example of the
                           Visual-Motor Compatibility                       percept directly priming a particular motor response,
                     510        Effect : Latency                            arguing that the object would have to be within reach and
                                                                            that such a mechanism would not work for images of
                     500                                                    objects as well (Tucker & Ellis, 1998). Instead they propose
                                                                            that this is evidence of “a more general representational
    RT (ms)
                     490                                                    mechanism that describe object properties in motor terms”
                                                                            (Tucker & Ellis, 2001).
                     480
                                                              Small
                                                                                                Architectural Account
                     470
                                                                            Within the ACT-R cognitive architecture (Anderson, 2007),
                                                              Large
                     460                                                    the time it takes to retrieve a specific memory (i.e., chunk)
                               Precision              Power                 is inversely related to that chunk’s activation. The chunk’s
                                           Response                         activation is composed of three primary components: base-
                                                                            level activation, spreading activation, and some stochastic
    Figure 1. Visual-motor compatibility effect for latency
   (Tucker & Ellis, 2001, experiment 1). Dotted lines are                   noise. Base-level activation is a learned quantity subject to
           model fit (R2=0.99, RMSE=2.95ms).                                decay that incorporates the effects of frequency and recency
                                                                            of the memory’s use. Spreading activation is context
                                                                            dependent, allowing chunks that are the focus of attention to
                           Visual-Motor Compatibility                       activate related memories. In this way, the chunks within a
                                Effect : Accuracy                           given buffer (i.e., the focus of attention for a given module
                     7
                                                                            in ACT-R) can make related concepts more readily
                     6                                                      retrievable. Spreading activation is the mechanism used to
    Error Rate (%)
                     5                                                      account for semantic priming effects (Anderson & Reder,
                     4                                                      1999). This same mechanism is used here to model the
                                                                            visual-motor priming reported by Tucker & Ellis (2001).
                     3
                                                                                 ACT-R defines the current context as the contents of
                     2                                                      the chunks currently in the model’s buffers. If chunk i is in a
                                                              Small
                     1                                                      buffer k, then all of the chunks that i references are in the
                                                              Large         context. The source activation of buffer k is shared equally
                     0
                                                                            among those context chunks, and they in turn spread that
                              Precision               Power
                                                                            activation to all the chunks that contain references to them.
                                           Response                         ACT-R only establishes associative links from the
   Figure 2. Visual-motor compatibility effect for accuracy                 referenced chunk to the referring chunk. The more chunks
   (Tucker & Ellis, 2001, experiment 1). Dotted lines are                   that reference a specific chunk j, the weaker its associative
            model fit (R2=0.88, RMSE=2.48%).                                strengths are to the referring chunks. Chunk j becomes a less
                                                                            effective retrieval cue because the weaker associative links
     Experiment 3 reversed the time delay of the prior                      spread less of the source activation.
experiment and presented the response-mapping cue tone                           This mechanism of spreading activation through
300ms after object presentation. In this circumstance the                   associative links from the currently defined context allows
compatibility effect was present. These results and those                   ACT-R to model semantic priming (Anderson & Reder,
from experiment 2 show that the effect is dependent upon                    1999). However, in order to address the visual-motor
the motor system not already being prepared for a particular                priming shown in Tucker & Ellis (2001), ACT-R’s existing
response.                                                                   mechanisms must to be modified slightly.                These
     In experiments 4a and 4b, the visibility of the object                 modifications are not complex post-hoc assumptions, rather
was manipulated. In 4a the object disappeared at the same                   they are consistent with the existing framework.
time as the response-mapping cue tone was presented. In 4b
the object disappeared 300ms before the response-mapping                    Visual Representation and Activation Normally, ACT-R
cue tone. The compatibility effect was present in 4a and not                models use only the intentionality system (i.e., goal buffer)
4b, showing that the object’s visibility at response selection              as a source of activation, even though all buffers have the
is critical.                                                                capability. Obviously, in order to support visual priming,
                                                                      201

the visual buffer must also be used as a source of activation.      Execution The model completed 160 trials (as did
However, the utility of visual activation is limited due to the     participants) where it was presented small and large objects
traditional structure of the visual representations. The visual     that were either natural or man-made (e.g., strawberry, key,
representation does not represent a semantic concept; rather,       potato, frying pan). Retrieving the visual-symbol associated
it is a raw percept made up predominantly of non-chunk,             with the percept, the model was able to classify the object.
primitive features (e.g., numbers, strings). They are               With this information the model retrieved the appropriate
therefore highly insular, having little connection to other         response-mapping        for      the    classification    (e.g.,
chunks, which dramatically limits the spread of activation.         natural/precision or man-made/precision). The final retrieval
Typically the visual object’s value slot (usually a string          was of the appropriate grip command itself. Once the motor
literal) is used to uniquely associate it with the semantic
                                                                    command was retrieved it was passed to the motor system to
representation of that percept (i.e., its symbol). To allow a
                                                                    be executed as the trial response.
visual percept to activate a semantic symbol, as well as
other chunks related to that concept, the value slot was
                                                                    Assumptions This model relies upon three key
modified to reference the semantic symbol chunk directly.
To access the semantics, a retrieval must still be made, but        assumptions. First, that activation is spread through not only
now the percept itself can prime that retrieval.                    the goal buffer but also the visual buffer. Second, that the
                                                                    process of encoding a visual percept includes linking that
Co-occurring Contextualization Canonical ACT-R only                 percept to its semantic representation (i.e., its visual-
establishes associative links between chunks through                symbol). Finally, associative links are not limited to
symbolic references (i.e., chunk j can activate chunk i since       containment relationships. Over the history of interacting
i directly references j as a slot value). We propose that           with the environment, both the visual-symbol for a percept
symbolic links can also occur through co-occurrence. The            and the motor command used to manipulate the object come
context within which processing occurs is not limited to the        to be associated with each other via co-occurrence.
symbolic structure of the chunks currently in buffer, but                 Since priming within ACT-R is function of spreading-
actually includes the patterns within the processing units          activation, base-level activations are not of theoretical
(i.e., productions) that execute cognition. If a production         interest. However, these values do come into play with
matches against both contents of the goal and visual buffers        respect to the rapid retrieval times in the data (figure 1) and
in order to fire, then the contents of those buffers do not         are discussed in detail later.
define the context independently, but jointly, and should be
linked associatively. Because productions can contain               Spreading Activation The model proposes that the visual-
perceptual and motor patterns, perception and action can            motor compatibility effect reported in Tucker & Ellis (2001)
become linked through co-occurrence.                                is due to activation spreading both from the intentionality
      The application of this mechanism is relatively               (i.e., goal) and visual systems. Once the object is visually
straightforward. Specifically, the semantic symbol of a             encoded, activation is spread to the learned motor response
percept and the motor command used to grasp the object are          through the co-occurrence associative link between it and
associated with each other even though neither has a direct         the visual-symbol. When the model has retrieved the
symbolic relationship to the other. These associations are          appropriate response-mapping for the object’s category,
learned from the environment as a consequence of attending          activation is spread to the task appropriate response. For
to an object, considering its meaning, and manipulating it.         incompatible responses, activation is spread to two different
      In the language of Mahon & Carmazza (2008), the               motor commands. However, when the responses are
semantic symbol that is linked to a percept provides the            compatible, both activation sources converge on a single
abstract representation that mediates perceptual processing         motor command (figure 3). Because of the higher total
and motor activation. The motor and visual representations          activation of the compatible motor response, it can be
are grounded to this abstraction through a history of               retrieved faster. The lower activation of the incompatible
interaction, allowing the establishment and strengthening of        response also makes misretrieval more likely since noise
associative links through co-occurrence. Activating the             might exceed the differences due to spreading activation.
abstract symbol propagates activation both to experienced
percepts and motor commands.
                     Model Details & Fit
The model presented here focuses on a simplification of
Tucker and Ellis’ (2001) first experiment; how it accounts
for the subsequent experiments will be saved for the
discussion. Because their presentation distance manipulation
had no influence on the visual-motor compatibility effect, it
was eliminated from the simulation. Otherwise the
simulation is identical to the actual experiment including the
timing of object presentations.
                                                                202

                                                                    there is only 105ms left for the three retrievals. Second, we
                                                                    assume that over a lifetime of observing and interacting with
                                                                    these objects, the base-level activations for the visual-
                                                                    symbols and grasp-commands are both stable (i.e. relatively
                                                                    immune to decay) and strong. Since we generally see
                                                                    objects more often than we grasp them, visual-symbol
                                                                    activations were set greater than the grasp-commands.
                                                                    Finally, while the response-mapping chunks would benefit
                                                                    from recency, their frequency of use would still be small, so
                                                                    base-level activations were set lower than those of the
                                                                    grasp-command chunks. Base-level activations of 5, 3, and
                                                                    2.25 were used for the visual-symbol, grasp-command, and
                                                                    response-mapping chunks respectively. While these values
                                                                    are necessary for the low RMSE latency fit, the qualitative
                                                                    (R2) fit is less sensitive to the base-level values.
   Figure 3. Total activation of incompatible and compatible             To account for the errors in performance, the model
           response motor commands (with noise).                    relied upon misretrievals. This was accomplished by setting
                                                                    the activation noise parameter to 0.06. The qualitative error
Results and Fits 1000 iterations of the model were run on           results are largely unchanged for most published noise
the simulated version of the experiment. Reaction time fits         values since the noise only affects the incompatible
were quantitatively very strong (R2=0.99, RMSE=2.95ms,              responses (unless noise exceeds the activation spread to the
figure 1). Accuracy fits were less strong, but captured the         chunks by the visual buffer). The model’s fit of the accuracy
qualitative effect (R2=0.88, RMSE=2.48%, figure 2). The             data is weaker due largely to the simplification of removing
weaker accuracy fit was due largely to the exclusion of             base-level learning. Since compatible responses receive all
base-level learning from the model. With only spreading-            of the spreading-activation, they are effectively immune to
activation, compatible response trials are effectively              noise (figure 3), which results in 100% accuracy for those
immune to noise making false retrievals impossible (figure          trials. To achieve the average 3.5% error rate for compatible
2 & 3).                                                             trials seen in the data, base-level learning would have to be
                                                                    enabled. This could produce situations where successive
Parameters The fits reported above required the                     retrievals of one particular response might boost its base-
manipulation of a few parameters, some of which were                level activation such that it could falsely intrude on a
dictated by the architecture and the structure of the model.        subsequent trial. Attempting to fit the error data in this
     The maximum associative strength was set to 3.1                manner would have required seven additional parameters
(default of 1). This parameter is completely constrained by         (base-level learning rate, and average age and access counts
the structure and connectivity of the model. Conceptually,          for the visual-symbol, grasp-command, and response-
any chunk that has many references should be a weak                 mapping chunks) instead of the three fixed base-levels used.
retrieval cue; that is its associative strength should be near
zero. A maximum associative strength of less than 3.1                                     Robotic Embodiment
would result in negative (i.e., inhibitory) associative             One of the challenges in modeling embodied cognition is
strengths for the most heavily referenced chunks. If one of         the lack of a physical body. This lack is especially relevant
these chunks were to be used as a retrieval cue, it would           because one of the embodied cognition claims is that the
actually become harder to retrieve its related concept.             body is central to both perception and action; it is
     The source activation from the goal buffer was kept at         disingenuous to claim that we can account for embodied
the default value of 1. The activation from the visual buffer       cognition phenomena without a body.
was set to 0.3, instead of the default of 0. This allows the             One aspect of running cognitive models on embodied
contents of the visual buffer (namely the semantic symbol)          platforms is that actual perception and action must occur.
to weakly prime the normal motor response for the object.           Critically, both perception and action must use cognitively
     While base-level learning was not used in this model,          plausible representations and cause the physical body to
base-level activations were still critical to achieve the rapid     move.
retrieval times implied by the average response time of                  We have modified ACT-R by allowing it to perceive
490ms. Three separate factors influenced the selection of the       and act on the physical world by attaching robotic sensors
base-level activations for the visual-symbol, grasp-                and effectors to it; we call our system ACT-R/E (Embodied)
command, and response-mapping chunks. First, the model,             (Trafton, Harrison, Fransen, & Bugaska, 2009). Changes to
as implemented, requires five productions with three                the visual and motor modules are described below.
retrievals before a response can be started. At 50ms per                 The Visual Module is used to provide a model with
production, an additional 85ms for the visual object                information about what can be seen in the current
encoding, and a minimum motor execution time of 50ms,               environment. ACT-R normally sees information presented
                                                                203

on a computer monitor. We modified the original visual             related effects when novel objects are used; such as those
module to accept input from a video camera. The visual             seen when subjects concurrently perform a compatible
module allows access to object identification through              manual rotation during the classic Shepard & Metzler
fiducial (Kato, Billinghurst, Poupyrev, Imamoto, &                 (1971) mental rotation task (Wexler, Kosslyn, & Berthoz,
Tachibana, 2000) and face (Fransen, Hebst, Harrison, &             1998).
Trafton, 2009) trackers.
     Traditional ACT-R has a virtual motor system that             Experiments 2-4 While the model presented only addresses
allows virtual hand movements (e.g., typing, mouse                 Tucker & Ellis’s (2001) first experiment, its extension to the
movements). ACT-R/E’s motor module allows control over             other experiments is fairly straightforward. All of the
all of the robot’s effectors. When a motor chunk enters into       subsequent experiments used a go/no-go paradigm where
the motor module, a specified motor controller executes the        the response to be given was cued by a tone and the go/no-
actual physical response.                                          go was determined by the object’s category. Recall that in
     Our current robot platform is the Mobile-Dexterous-           experiment 2, subjects heard the response cue 500ms before
Social (MDS) Robot (Breazeal, 2009). The MDS robot                 the object was presented. This 500ms window of time
neck has 18 degrees-of-freedom (DoF) for the head, neck            would allow the model to retrieve the appropriate motor
and eyes allowing the robot to look at various locations in        response before it had to determine whether or not to
3D space and 11 DoF on its four-fingered hand, allowing it         execute it. The lack of a visual-motor compatibility effect
to make various gestures and grips. Perceptual inputs              observed would be due to the fact that the response had
include two color video cameras and a SR3000 camera to             already been selected, leaving visual priming no opportunity
provide depth information. For the current project, the            to influence performance.
MDS head can identify various objects through the fiducial              In contrast, in experiment 3 the response cue tone was
tracker and can move its hands in a power or precision             presented 300ms after object presentation. As in experiment
grasp.                                                             1, the visual presence of the object would allow activation to
     The 10ms visual-motor compatibility effect is                 spread to the learned motor response, facilitating retrieval
completely obscured by the robot’s motor system’s slower           when it was compatible with the response cued by the tone.
execution times. In order to illustrate the effect, we                  Experiment 4a removed the object at the same time as
dramatically increased the retrieval time scalar. In the video     the cue tone was presented. If the model were able to
(see acknowledgments for the URL) the visual-motor                 retrieve the motor command at the moment of the cue-onset
priming accounts for around a 500 ms performance                   and visual-offset, the compatibility effect would be
improvement.                                                       observed. However, ACT-R’s encoding time for auditory
                                                                   information would actually result in the retrieval starting at
                          Discussion                               least 50ms after presentation. Since ACT-R’s spreading
ACT-R has a long history of accounting for semantic                activation mechanism is instantaneous, that activation would
priming effects (Anderson, 1974), but its perceptual/motor         drop to 0 immediately after the percept disappeared,
integration has been less explored. To address this                eliminating visual priming entirely. The results from
theoretical gap, we have modified the visual representation        experiment 4b are more easily accounted for. Since the
linking the percept to its derived abstract symbol. This           object was removed 300ms before the cue tone, the
allows source activation to usefully spread from the visual        activation of the learned motor response would have been
system, instead of just from the intentionality system (i.e.,      eliminated before the retrieval of the task response.
goal buffer). We also present a broadened definition of            However, theoretical proposals that would allow spreading-
predictive context for the establishment of associative links.     activation to decay gradually (e.g., van Maanen & van Rijn,
Traditional ACT-R only establishes associative links from          2007) would not only support the compatibility effect in
the contained chunk to the container. In this way, when            experiment 4a but also make predictions regarding how long
another chunk has a reference to the contained chunk, it is        the delay in 4b would have to be before the effect
potentially predictive of the need for the containing chunk.       disappeared.
We augment spreading activation to deal with co-occurrence
so that we can establish a richer context. In this manner, the                              Conclusions
visual-symbols and motor commands come to be associated
as productions fire that simultaneously match both of the          Tucker & Ellis interpret their results through a lens of strict
representations in their respective buffers. While only the        embodiment (e.g., Barsalou, 1999). They argue that the
consequences of this mechanism are exploited in the model          phenomenon could not be due to the perceptual priming of
presented, the actual process is under active investigation.       the motor response, rather posit that the evidence supports
     A particular limitation of this account is that it does       activation of a more general representation that incorporates
depend upon both visual and motor experience with a given          both visual and motor properties (Tucker & Ellis, 2001).
object. Lacking such experience, the modal representations              Mahon & Caramazza (2008) counter that this line of
will not be associatively linked to the abstract symbolic          reasoning unjustifiably discounts the possibility that
representation. As such this model cannot account for              abstract/symbolic systems could account for visual-motor
                                                                   priming by the spreading activation through abstract
                                                               204

symbols. They propose that the challenge for                        Craighero, L., Fadiga, L., Rizzolatti, G., & Umilta, C.
abstract/symbolic systems is to “1) develop a model of the                (1999). Action for perception: a motor-visual
computations and representations that mediate between                     attentional effect. Journal of experimental
perceptual processing and motor activation, and 2) specify                psychology: Human perception and performance, 25.
the conditions under which those computations are                         1673-1692.
deployed” (Mahon & Carmazza, 2008). In this paper, we               Fransen, B.R., Herbst, E., Harrison, A.M., Adams, W.,
present a cognitive model that addresses both of those                    Trafton, J.G. (2009) Real-time face and object
challenges while remaining within ACT-R’s existing                        tracking. Proceedings from 2009 IEEE/RSJ
architectural constraints. While ACT-R is a traditional                   international conference on intelligent robots and
abstract/symbolic system, this work moves the architecture                systems.
towards one that is “grounded by interaction”, allowing it to       Kato, H. Billinghurst, M., Pouplrev, I., Imamoto, K., &
not only exploit the flexibility of disembodied abstractions              Tachibana, K. (2000). Virtual object manipulation on
but also the richly contextualized representations inherent in            a table-top AR environment. In IEEE and ACM
more strictly embodied accounts (Mahon & Carmazza,                        International symposium on augmented reality. 111-
2008).                                                                    119.
     Combining the generalization of activation spread and          Mahon, B.Z., & Caramazza, A. (2008) A critical look at the
co-occurrence associations allows ACT-R to account for                    embodied cognition hypothesis and a new proposal
semantic (Anderson & Reder, 1999), visual-motor Tucker &                  for grounding conceptual content. Journal of
Ellis, 2001), and potentially even motor-visual (Craighero,               physiology - Paris, 102, 59-70.
Fadiga, Umilta, & Rizzolatti, 1999) priming. This richer            Newell, A., & Simon, H. A. (1972). Human problem
account may also be a fundamental component in enabling                   solving. Englewood Cliffs, NJ: Prentice-Hall.
symbol acquisition/grounding within ACT-R (Barsalou,                Niedenthal, P. M., Barsalou, L. W., Winkielman, P.,
2003; Mahon & Caramazza, 2008).                                           Krauth-Gruber, S., & Ric, F. (2005). Embodiment in
                                                                          attitudes, social perception, and emotion. Personality
                      Acknowledgments                                     and Social Psychology Review, 9(3).
This work was performed while the first author held a               Pylyshyn, Z. W. (1984). Computation and cognition. Mit
National Research Council Research Associateship Award                    Press Cambridge, MA.
and was partially supported by the Office of Naval Research         Shepard, R., & Metzler, J. (1971). Mental rotations of three-
under job order number N0001408WX30007 and 09-Y861                        dimensional objects. Science, 171. 701-703.
awarded to the second author. The views and conclusions             Trafton, J.G., Harrison, A.M., Fransen, B.R., & Bugajska,
contained in this document should not be interpreted as                   M. (2009) An embodied model of infant gaze-
necessarily representing official policies, either expressed or           following. In A. Howes, D. Peebles, R. Cooper
implied, of the U.S. Navy.                                                (Eds.), 9th International conference on cognitive
                                                                          modeling - ICCM2009, Manchester, UK.
The models and videos are available for download at                 Tucker, M., & Ellis, R. (1998). On the relations between
http://www.nrl.navy.mil/aic/iss/aas/CognitiveRobots.php.                  seen objects and components of potential actions.
                                                                          Journal of Experimental Psychology-Human
                         References                                       Perception and Performance, 24(3), 830-846.
Anderson, J. R. (1974). Retrieval of propositional                  Tucker, M., & Ellis, R. (2001) The potentiation of grasp
       information from long-term memory. Cognitive                       types during visual object categorization. Visual
       Psychology, 5, 451-474.                                            cognition, 8, 769-800.
Anderson, J. R. (2007) How Can the Human Mind Occur in              Van Maanen, L., & Van Rijn, H. (2007). An accumulator
       the Physical Universe? New York: Oxford                            model of semantic interference. Cognitive Systems
       University Press.                                                  Research, 8(3), 174-181.
Anderson, J. R. & Reder, L. M. (1999). The fan effect: New          Wexler, M., Kosslyn, S.M., & Berthoz, A. (1998). Motor
       results and new theories. Journal of Experimental                  processes in mental rotation. Cognition, 68, 77-94.
       Psychology: General, 128, 186-197.                           Wilson, M. (2002). Six views of embodied cognition.
Barsalou, L. W. (1999). Perceptions of perceptual symbols.                Psychonomic Bulletin & Review.
       Behavioral and brain sciences, 22(04), 637-660.
Barsalou, L.W. (2003). Abstraction in perceptual symbol
       systems. Philosophical Transactions of the Royal
       Society of London: Biological Sciences, 358, 1177-
       1187.
Breazeal,         C.       (2009).         MDS          Robot.
       http://robotic.media.mit.edu/projects/robots/mds/over
       view
                                                                205

