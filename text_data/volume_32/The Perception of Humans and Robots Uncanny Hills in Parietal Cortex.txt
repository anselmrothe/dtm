UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Perception of Humans and Robots: Uncanny Hills in Parietal Cortex
Permalink
https://escholarship.org/uc/item/71m6d8bk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Saygin, Ayse Pinar
Chaminade, Thierry
Ishiguro, Hiroshi
Publication Date
2010-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                        The Perception of Humans and Robots:
                                              Uncanny Hills in Parietal Cortex
                                             Ayse Pinar Saygin (saygin@cogsci.ucsd.edu)
                                  Department of Cognitive Science, University of California, San Diego
                                                       La Jolla, CA 92093-0515 USA
                                             Thierry Chaminade (tchamina@gmail.com)
                         Mediterranean Institute for Cognitive Neuroscience, Aix-Marseille University CNRS
                                                           Marseille, 13402 France
                                        Hiroshi Ishiguro (ishiguro@ams.eng.osaka-u.ac.jp)
                                       Department of Adaptive Machine Systems, Osaka University
                                                              Suita, Osaka, Japan
                               Abstract                                     In primates, the perception of body movements is
                                                                         supported by network of lateral superior temporal, inferior
   We report on a functional magnetic resonance imaging                  parietal and inferior frontal brain areas (Rizzolatti &
   (fMRI) study of the perception of human and artificial agents.        Craighero, 2004). Here we will refer to this network as the
   Participants viewed videos of familiar body movements                 Action Perception System (APS). The frontal and parietal
   enacted by the android Repliee Q2, the human after whom it
   was modeled, and the “skinned” version of Q2 revealing its
                                                                         nodes of the system are known to contain mirror neurons,
   mechanical parts. We used a neural adaptation (repetition             which respond not only when the monkey executes a
   suppression) analysis to reveal brain areas sensitive to body         particular action, but also when it observes another
   movements, and explored whether the identity of the                   individual perform the action. The existence of a similar
   perceived agents modulated these responses. We found                  system in humans has been suggested by several
   significantly higher activity in a distributed network of brain       neuroimaging and lesion studies (e.g., Fadiga, Fogassi,
   areas for the android, most notably in anterior intraparietal         Pavesi, & Rizzolatti, 1995; Grafton, Arbib, Fadiga, &
   cortex. The responses for the human and the robot with the
   mechanical appearance resembled each other. We interpret              Rizzolatti, 1996; Hari et al., 1998; Iacoboni et al., 1999;
   these results within the framework of predictive coding and           Saygin, 2007; Saygin, Wilson, Dronkers, & Bates, 2004).
   suggest that the “uncanny valley” phenomenon may have its                The neural activity in premotor and parietal regions
   roots in processing conflicts within the brain’s action               during action perception is often interpreted within the
   perception system.                                                    framework motor resonance, where “an action is understood
      Keywords: action perception; body perception; biological           when its observation causes the motor system of the
   motion; social robotics; artificial agents; neuroimaging;             observer to ‘resonate”’ (Rizzolatti, Fogassi, & Gallese,
   fMRI; uncanny valley                                                  2001). But what are the boundary conditions for this
                                                                         resonance?
                           Introduction                                     There is a small neuroscience literature on the perception
In the near future, artificial agents and humanoid robots are            of artificial agents, including robots (Chaminade &
expected to be part of our daily lives, not only in                      Hodgins, 2006; MacDorman & Ishiguro, 2006).
entertainment and retail, but also in important domains such             Unfortunately, the results are not consistent. Some
healthcare and education (Billard, Robins, Nadel, &                      experiments have reported that robot actions affect the
Dautenhahn, 2007; Dautenhahn, 2007; Kanda, Ishiguro,                     observers’ own motor processing or the activity of the APS,
Imai, & Ono, 2004). Thus, exploring human factors in                     whereas others have argued that the APS does not respond,
interactive robot design and development is crucial                      or responds weakly if the perceived actor is an artificial
(Ishiguro, 2007; MacDorman & Ishiguro, 2006).                            agent (Catmur, Walsh, & Heyes, 2007; Chaminade,
Conversely, experiments using artificial agents can address              Hodgins, & Kawato, 2007; Gazzola, Rizzolatti, Wicker, &
questions about the functional properties of mechanisms                  Keysers, 2007; Kilner, Paulignan, & Blakemore, 2003;
involved in the perception of others’ actions (Blake &                   Oberman, McCleery, Ramachandran, & Pineda, 2007;
Shiffrar, 2007; Rizzolatti & Craighero, 2004). Here, we                  Press, Gillmeister, & Heyes, 2007; Tai, Scherfler, Brooks,
summarize a neuroimaging study that we performed as part                 Sawamoto, & Castiello, 2004). Furthermore, the specific
of an interdisciplinary research program that aims to reveal             roles of biological appearance or biological motion have not
factors that can guide the design of future artificial agents,           been sufficiently explored in these experiments, but is an
as well as to improve our understanding of action and body               area of interest in social robotics, cognitive neuroscience,
movement perception more generally.                                      and vision science (Chaminade, Hodgins, & Kawato, 2007;
                                                                         Cook, Saygin, Swain, & Blakemore, 2009; Kanda,
                                                                     2716

Miyashita, Osada, Haikawa, & Ishiguro, 2008; Minato,                motion and Q2H and Q2R are identical, both with
Shimada, Itakura, Lee, & Ishiguro, 2006; Oyedele, Hong, &           mechanical kinematics.
Minor, 2007; Saygin, Wilson, Hagler, Bates, & Sereno,
2004).
   On the one hand, it seems reasonable that the closer the
match between the observed action and the observers’ own
sensorimotor representations, the more efficient the
simulation will be. In support for this, the APS is modulated
by whether the observer can in fact perform the seen
movement (Calvo-Merino, Grezes, Glaser, Passingham, &
                                                                          Figure 1. Still frames from the videos used in the
Haggard, 2006; Casile & Giese, 2006). The appearance of
                                                                                experiments depicting the three agents.
the observed agent may be additionally important (Buccino
et al., 2004; Chaminade, Hodgins, & Kawato, 2007).
   On the other hand, human resemblance is not necessarily             The articulators of Repliee Q2 were programmed over
always a positive feature in robots. The “uncanny valley”           several weeks at the Intelligent Robotics Laboratory at
phenomenon points out that as a robot is made more                  Osaka University. The same movements were videotaped in
human-like in its appearance, the reaction to it becomes            both appearance conditions (Q2R and Q2H). The human
more and more positive and empathetic, until a point is             (the same female adult to whom Repliee Q2 was designed to
reached at which the robot becomes oddly repulsive (Mori,           resemble) was asked to watch each of Repliee Q2’s actions
1970). The effect is well-known in robotics and animation.          and then perform the same action naturally. All agents were
For example, the movie Polar Express (Warner Bros) was              videotaped in the same room and with the same background.
criticized for the characters that viewers found creepy and         A total of 8 actions per actor were used in the experiment,
disturbing. The more recent feature Avatar (20th Century            including both transitive (drinking water from a cup,
Fox) received praise for animations that did not fall into the      picking up a piece of paper from a table, grasping a tube of
uncanny valley. Despite such well-known examples, and               hand lotion, wiping a table with a cloth) and intransitive
significant anecdotal evidence, there is little scientific data     actions (waving hand, nodding affirmatively, shaking head
to characterize the uncanny valley (MacDorman, Green, Ho,           (negative), and introducing self). Video recordings were cut
& Koch, 2009; Steckenfinger & Ghazanfar, 2009).                     into 2 second long clips, were converted to grayscale,
                                                                    cropped to a uniform size.
                     The Present Study                                 20 right handed healthy adults participated. We used a 3T
                                                                    Siemens Allegra scanner at the Wellcome Trust Centre for
This paper briefly describes the approach we took to this           Neuroimaging in London, UK and a standard T2* weighted
topic and summarizes the data from an fMRI repetition               gradient echo pulse sequence to obtain functional images
suppression study. We performed fMRI as participants                (TR=2340 ms, TE=65 ms). 36 slices were acquired at an in-
viewed video clips of human (H) and robotic agents                  plane resolution of 3 x 3 mm and a through plane resolution
carrying out recognizable actions. We used Repliee Q2, a            of 2 mm and 1 mm gap. Each participant was given exactly
humanoid robot developed at Osaka University in                     the same introduction to the study and the same exposure to
collaboration with Kokoro Ltd (Ishiguro et al., 2006). This         the videos prior to scanning since prior knowledge can
robot has a very human-like appearance (Figure 1b). In              affect attitudes to artificial agents differentially (Saygin &
order to achieve this, the robot’s face was modeled after an        Cicekli, 2002). Participants were told whether each agent
adult Japanese female (Figure 1a). Importantly, Repliee Q2          was a human or a robot such that by the time scanning
was videotaped both in its original human-like appearance           started, they were not uncertain about the identity of the
(the Q2H condition, Figure 1b) and in a modified, more              android.
mechanical appearance (the Q2R condition, Figure 1c). In               A limitation of previous neuroimaging studies on this
this latter condition, we removed as many of the surface            topic is that they explored the BOLD fMRI response
elements as possible in order to reveal the electronics and         (Logothetis, 2008). Repetition suppression (henceforth RS,
mechanics underneath. The silicone covering the face and            also called fMRI adaptation) is a method applied to fMRI
hands could not be removed, so we used a custom mask and            from neurophysiology and refers to the phenomena of
gloves to change the appearance of these body parts. The            reduced neural response to a repeated stimulus compared to
end result was that the robot’s appearance became obviously         the response to a novel stimulus (Grill-Spector & Malach,
mechanical (e.g., metal arms and joints).                           2001; Henson & Rugg, 2003; Krekelberg, Boynton, & van
   There were three conditions: human (H), robot with               Wezel, 2006). RS affects neurons sensitive to the repeated
human appearance (Q2H) and robot with mechanical                    stimulus, so it can be used as a means to explore functional
appearance (Q2R). However, since the Q2H and Q2R are in             properties of brain areas. In recent years, RS has been
fact the same robot, the kinematics are identical for these         applied to the study of action perception (Chong,
two conditions. In terms of appearance, H and Q2H are very          Cunnington, Williams, Kanwisher, & Mattingley, 2008;
close to each other, whereas Q2R lies on the mechanical             Dinstein, Gardner, Jazayeri, & Heeger, 2008; Dinstein,
end. In terms of kinematics, H represents truly biological          Hasson, Rubin, & Heeger, 2007; Fujii, Hihara, & Iriki,
                                                                2717

 2008; Hamilton & Grafton, 2006, 2008; Kilner, Neal,               brings to mind the uncanny valley, except we observed
 Weiskopf, Friston, & Frith, 2009; Lestou, Pollick, &              “hills” in the form of increased neural responses rather than
 Kourtzi, 2008). This approach was well-suited to our goals        valleys. Although we cannot include the details here due to
 as it allows us to test whether neurons in the APS code for       space constraints, a region of interest (ROI) analysis further
 biological appearance or biological motion.                       quantified these results, revealing a significant interaction in
    Participants watched the action videos in 30 second            the inferior parietal lobule between the agents.
 blocks. There were 12 videos in each block with a 500 ms
 ISI. Each video was preceded by the same video and the                                       Discussion
 other videos equal number of times and orders were                   We interpret these data within the predictive coding
 counterbalanced across runs. Each video was preceded by           framework, which is based on minimizing prediction error
                                                                   though recurrent interactions among levels of a cortical
                                                                   hierarchy (Bar, 2009; Friston, 2005; Kilner, Friston, &
                                                                   Frith, 2007). During the perception of H and Q2R, where
                                                                   there is no mismatch between the appearance and the
                                                                   movement of the agent. For Q2H on the other hand, there is
                                                                   a human-like appearance that leads to a conflict when this
                                                                   information is integrated with the movement kinematics of
                                                                   the agent. This will lead to the generation of a prediction
                                                                   error, which is propagated in the network until the errors of
                                                                   each node are minimized. It is possible to measure
                                                                   prediction errors using neuroimaging (Friston, 2010). It is
                                                                   not possible from the current data to know the exact source
                                                                   and time course of error propagation, but it is clear that the
                                                                   cortical network is engaged strongly during the perception
                                                                   of Q2R compared with the agents that lead to less prediction
                                                                   error. The effect is largest in parietal cortex, which is the
                                                                   node of the network that links the posterior, visual
                                                                   components of the APS and the frontal, motor components
                                                                   (Matelli & Luppino, 2001; Seltzer & Pandya, 1994).
                                                                      The present study is only a beginning. This framework
Figure 2. Repetition suppression results for the human (a),
                                                                   provides hypotheses that we are testing in new studies. We
                   Q2H (b), and Q2R(c).
                                                                   are now utilizing animation to modulate the appearance and
                                                                   movement parameters more precisely (although this may
 the same video (Repeat) or a different video (Non-repeat).        lead to decrease in presence (Sanchez-Vives & Slater,
 To make sure subjects attended throughout, every 30-              2005), whose importance in modulating APS is currently
 seconds, they were presented with a statement about which         not known). We also need to use other neuroimaging and
 they made a True/False judgment using a button box (e.g.,         psychological methods in addition to, or in conjunction with
 “I did not see her waving her hand”). The fMRI data were          fMRI to study the temporal dynamics of action processing.
 analyzed with SPM5 using standard procedures                         With brief exposure times, Repliee Q2 can be mistaken
 (http://www.fil.ion.ucl.ac.uk/spm).                               for a human being, but longer exposure usually triggers the
                                                                   feeling of repulsion or discomfort characteristic of the
                             Results                               uncanny valley (Ishiguro, 2006). While we did not explicitly
                                                                   assess the uncanny valley in this study, our results suggest
 For each agent, we identified regions showing a repetition        an intriguing relationship between the APS and this
 suppression effect at p<0.05 and cluster size of > 30 voxels.     phenomenon. We are currently exploring this in more
 The effect of repetition suppression differed between the         sophisticated analyses as well as with new experiments.
 agents (Figure 2). Posterior temporal cortex showed                  In summary, we found that a robot with very humanlike
 suppression for all agents, but in the left hemisphere there      appearance can cause differential responses compared with
 was significantly less response to Q2R. This area                 the same robot with a mechanical appearance, or with a
 corresponds the Extrastriate Body Area or EBA (Peelen,            human being that maximally resembles the robot. These
 Wiggett, & Downing, 2006), which responds to the visual           differences were found in a network of brain areas, but most
 perception of the human body.                                     prominently in inferior parietal cortex, which connects the
    We otherwise did not find evidence for APS coding for          posterior areas involved in the visual perception of actions
 the biological appearance or biological movement of the           and biological motion to premotor areas in frontal cortex.
 perceived agents. Instead, in comparison to H and Q2R, a          We propose these “hills” in the brain activity reflect the
 larger network showed suppression for Q2H, despite the use        prediction error that is generated as the brain processes these
 of the same procedures and thresholds. This of course,            stimuli. We suggest that the uncanny valley may arise from
                                                               2718

processing conflicts in the APS, and can be investigated           Dinstein, I., Gardner, J. L., Jazayeri, M., & Heeger, D. J.
using fMRI.                                                          (2008). Executed and observed movements have different
                                                                     distributed representations in human aIPS. J Neurosci,
                     Acknowledgments                                 28(44), 11231-11239.
  This research was supported by an innovative research            Dinstein, I., Hasson, U., Rubin, N., & Heeger, D. J. (2007).
grant to A.P. Saygin from the Kavli Institute for Brain and          Brain areas selective for both observed and executed
Mind (UCSD). Additional support was contributed by the               movements. J Neurophysiol, 98(3), 1415-1427.
European Commission and by the Wellcome Trust. We are              Fadiga, L., Fogassi, L., Pavesi, G., & Rizzolatti, G. (1995).
grateful to members of the Intelligent Robotics Laboratory           Motor facilitation during action observation: a magnetic
for their help in creating the experimental stimuli and to Jon       stimulation study. J Neurophysiol, 73(6), 2608-2611.
Driver, Chris Frith, James Kilner and members of the               Friston, K. (2005). A theory of cortical responses.
Wellcome Trust Centre for Neuroimaging for their support             Philosophical Transactions B, 360(1456), 815.
of the fMRI study. We also appreciate discussions with Karl        Friston, K. (2010). The free-energy principle: a unified brain
MacDorman, Takashi Minato, Javier Movellan, and Marty                theory? Nat Rev Neurosci, 11(2), 127-138.
Sereno in the early stages of this project.                        Fujii, N., Hihara, S., & Iriki, A. (2008). Social cognition in
                                                                     premotor and parietal cortex. Soc Neurosci, 3(3-4), 250-
                                                                     260.
                          References
                                                                   Gazzola, V., Rizzolatti, G., Wicker, B., & Keysers, C.
Bar, M. (2009). Predictions: a universal principle in the            (2007). The anthropomorphic brain: the mirror neuron
  operation of the human brain. Introduction. Philos Trans           system responds to human and robotic actions.
  R Soc Lond B Biol Sci, 364(1521), 1181-1182.                       Neuroimage, 35(4), 1674-1684.
Billard, A., Robins, B., Nadel, J., & Dautenhahn, K. (2007).       Grafton, S. T., Arbib, M. A., Fadiga, L., & Rizzolatti, G.
  Building Robota, a mini-humanoid robot for the                     (1996). Localization of grasp representations in humans
  rehabilitation of children with autism. Assist Technol,            by positron emission tomography. 2. Observation
  19(1), 37-49.                                                      compared with imagination. Exp Brain Res, 112(1), 103-
Blake, R., & Shiffrar, M. (2007). Perception of human                111.
  motion. Annu Rev Psychol, 58, 47-73.                             Grill-Spector, K., & Malach, R. (2001). fMR-adaptation: a
Buccino, G., Lui, F., Canessa, N., Patteri, I., Lagravinese,         tool for studying the functional properties of human
  G., Benuzzi, F., et al. (2004). Neural circuits involved in        cortical neurons. Acta Psychol (Amst), 107(1-3), 293-321.
  the recognition of actions performed by nonconspecifics:         Hamilton, A. F., & Grafton, S. T. (2006). Goal
  an FMRI study. J Cogn Neurosci, 16(1), 114-126.                    representation in human anterior intraparietal sulcus. J
Calvo-Merino, B., Grezes, J., Glaser, D. E., Passingham, R.          Neurosci, 26(4), 1133-1137.
  E., & Haggard, P. (2006). Seeing or doing? Influence of          Hamilton, A. F., & Grafton, S. T. (2008). Action outcomes
  visual and motor familiarity in action observation. Curr           are represented in human inferior frontoparietal cortex.
  Biol, 16(19), 1905-1910.                                           Cereb Cortex, 18(5), 1160-1168.
Casile, A., & Giese, M. A. (2006). Nonvisual motor training        Hari, R., Forss, N., Avikainen, S., Kirveskari, E., Salenius,
  influences biological motion perception. Curr Biol, 16(1),         S., & Rizzolatti, G. (1998). Activation of human primary
  69-74.                                                             motor cortex during action observation: a neuromagnetic
Catmur, C., Walsh, V., & Heyes, C. (2007). Sensorimotor              study. Proc Natl Acad Sci U S A, 95(25), 15061-15065.
  learning configures the human mirror system. Curr Biol,          Henson, R. N., & Rugg, M. D. (2003). Neural response
  17(17), 1527-1531.                                                 suppression, haemodynamic repetition effects, and
Chaminade, T., Hodgins, J., & Kawato, M. (2007).                     behavioural priming. Neuropsychologia, 41(3), 263-270.
  Anthropomorphism influences perception of computer-              Iacoboni, M., Woods, R. P., Brass, M., Bekkering, H.,
  animated characters' actions. Social Cognitive and                 Mazziotta, J. C., & Rizzolatti, G. (1999). Cortical
  Affective Neuroscience, 2(3), 206-216.                             mechanisms of human imitation. Science, 286(5449),
Chaminade, T., & Hodgins, J. K. (2006). Artificial agents in         2526-2528.
  social cognitive sciences. Interaction Studies, 7(3), 347-       Ishiguro, H. (2006). Android science: conscious and
  353.                                                               subconscious recognition. Connection Science, 18(4),
Chong, T. T., Cunnington, R., Williams, M. A., Kanwisher,            319-332.
  N., & Mattingley, J. B. (2008). fMRI adaptation reveals          Ishiguro, H. (2007). Projects and Vision in Robotics.
  mirror neurons in human inferior parietal cortex. Curr             Lecture Notes in Computer Science, 4314, 451.
  Biol, 18(20), 1576-1580.                                         Ishiguro, H., Asada, M., Shapiro, S. C., Thielscher, M.,
Cook, J., Saygin, A. P., Swain, R., & Blakemore, S. J.               Breazeal, C., Mataric, M. J., et al. (2006). Human-
  (2009). Reduced sensitivity to minimum-jerk biological             Inspired Robots. IEEE Intelligent Systems, 21(4), 74-85.
  motion in autism spectrum conditions. Neuropsychologia.          Kanda, T., Ishiguro, H., Imai, M., & Ono, T. (2004).
Dautenhahn, K. (2007). Socially intelligent robots:                  Development and evaluation of interactive humanoid
  dimensions of human-robot interaction. Philos Trans R              robots. Proceedings of the IEEE, 92(11), 1839-1850.
  Soc Lond B Biol Sci, 362(1480), 679-704.
                                                               2719

Kanda, T., Miyashita, T., Osada, T., Haikawa, Y., &                   understanding and imitation of action. Nat Rev Neurosci,
  Ishiguro, H. (2008). Analysis of humanoid appearances in            2(9), 661-670.
  human-robot interaction. IEEE Transactions on Robotics,           Sanchez-Vives, M. V., & Slater, M. (2005). From presence
  24(3), 725-735.                                                     to consciousness through virtual reality. Nat Rev
Kilner, J. M., Friston, K. J., & Frith, C. D. (2007). The             Neurosci, 6(4), 332-339.
  mirror-neuron system: a Bayesian perspective.                     Saygin, A. P. (2007). Superior temporal and premotor brain
  Neuroreport, 18(6), 619-623.                                        areas necessary for biological motion perception. Brain,
Kilner, J. M., Neal, A., Weiskopf, N., Friston, K. J., & Frith,       130(Pt 9), 2452-2461.
  C. D. (2009). Evidence of mirror neurons in human                 Saygin, A. P., & Cicekli, I. (2002). Pragmatics in human-
  inferior frontal gyrus. J Neurosci, 29(32), 10153-10159.            computer conversation. Journal of Pragmatics, 34(3),
Kilner, J. M., Paulignan, Y., & Blakemore, S. J. (2003). An           227-258.
  interference effect of observed biological movement on            Saygin, A. P., Wilson, S. M., Dronkers, N. F., & Bates, E.
  action. Curr Biol, 13(6), 522-525.                                  (2004). Action comprehension in aphasia: linguistic and
Krekelberg, B., Boynton, G. M., & van Wezel, R. J. (2006).            non-linguistic deficits and their lesion correlates.
  Adaptation: from single cells to BOLD signals. Trends               Neuropsychologia, 42(13), 1788-1804.
  Neurosci, 29(5), 250-256.                                         Saygin, A. P., Wilson, S. M., Hagler, D. J., Jr., Bates, E., &
Lestou, V., Pollick, F. E., & Kourtzi, Z. (2008). Neural              Sereno, M. I. (2004). Point-light biological motion
  substrates for action understanding at different description        perception activates human premotor cortex. J Neurosci,
  levels in the human brain. Journal of Cognitive                     24(27), 6181-6188.
  Neuroscience, 20(2), 324-341.                                     Seltzer, B., & Pandya, D. N. (1994). Parietal, temporal, and
Logothetis, N. K. (2008). What we can do and what we                  occipital projections to cortex of the superior temporal
  cannot do with fMRI. Nature, 453(7197), 869-878.                    sulcus in the rhesus monkey: A retrograde tracer study.
MacDorman, K. F., Green, R. D., Ho, C. C., & Koch, C. T.              The Journal of Comparative Neurology, 343(3).
  (2009). Too real for comfort? Uncanny responses to                Steckenfinger, S. A., & Ghazanfar, A. A. (2009). Monkey
  computer generated faces. Computers in Human                        visual behavior falls into the uncanny valley. Proceedings
  Behavior, 25(3), 695-710.                                           of the National Academy of Sciences of the United States
MacDorman, K. F., & Ishiguro, H. (2006). The uncanny                  of America., 106 (43), 18362-18366
  advantage of using androids in cognitive and social               Tai, Y. F., Scherfler, C., Brooks, D. J., Sawamoto, N., &
  science research. Interaction Studies, 7(3), 297-337.               Castiello, U. (2004). The human premotor cortex is
Matelli, M., & Luppino, G. (2001). Parietofrontal circuits            'mirror' only for biological actions. Curr Biol, 14(2), 117-
  for action and space perception in the macaque monkey.              120.
  Neuroimage, 14(1 Pt 2), S27-32.
Minato, T., Shimada, M., Itakura, S., Lee, K., & Ishiguro,
  H. (2006). Evaluating the human likeness of an android
  by comparing gaze behaviors elicited by the android and a
  person. Advanced Robotics, 20(10), 1147.
Mori, M. (1970). The uncanny valley. Energy, 7(4), 33-35.
Oberman, L. M., McCleery, J. P., Ramachandran, V. S., &
  Pineda, J. A. (2007). EEG evidence for mirror neuron
  activity during the observation of human and robot
  actions: Toward an analysis of the human qualities of
  interactive robots. Neurocomputing, 70, 2194-2203.
Oyedele, A., Hong, S., & Minor, M. S. (2007). Contextual
  factors in the appearance of consumer robots: exploratory
  assessment of perceived anxiety toward humanlike
  consumer robots. Cyberpsychol Behav, 10(5), 624-632.
Peelen, M. V., Wiggett, A. J., & Downing, P. E. (2006).
  Patterns of fMRI activity dissociate overlapping
  functional brain areas that respond to biological motion.
  Neuron, 49(6), 815-822.
Press, C., Gillmeister, H., & Heyes, C. (2007). Sensorimotor
  experience enhances automatic imitation of robotic
  action. Proc Biol Sci, 274(1625), 2509-2514.
Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron
  system. Annu Rev Neurosci, 27, 169-192.
Rizzolatti, G., Fogassi, L., & Gallese, V. (2001).
  Neurophysiological        mechanisms      underlying     the
                                                                2720

