UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognitive Models and the Wisdom of Crowds: A Case Study Using the Bandit Problem
Permalink
https://escholarship.org/uc/item/5k71f0vd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Zhang, Shunan
Lee, Michael
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                            Cognitive Models and the Wisdom of Crowds:
                                  A Case Study Using the Bandit Problem
                                              Shunan Zhang (szhang@uci.edu)
                                               Michael D. Lee (mdlee@uci.edu)
                                Department of Cognitive Sciences, 3151 Social Sciences Plaza A
                                      University of California, Irvine, CA 92697-5100 USA
                             Abstract                                common signal and reduce the idiosyncratic noise, lead-
                                                                     ing to superior group performance.
   The “wisdom of the crowds” refers to the idea that                   One challenge in producing wisdom of crowds effects
   the aggregated performance of a group of people on a              arises when tasks are more complicated than estimating
   challenging task may be superior to the performance of            a single quantity, or predicting a simple outcome. Many
   any of the individuals. For some tasks, like estimating
   a single quantity, it is straightforward to aggregate indi-       interesting and real-world decision-making situations are
   vidual behavior. For more complicated multidimensional            inherently multidimensional or sequential. In these situ-
   or sequential tasks, however, it is not so straightforward.       ations, it is often not possible to combine the raw be-
   Cognitive models of behavior are needed, to infer what            haviors of people, because they are not commensurate.
   people know from how they behave, and allow aggrega-
   tion to be done on the inferred knowledge. We provide             For example, imagine trying to combine the expertise of
   a case study of this role for cognitive modeling in the           basketball fans trying to predict the result of an eight-
   wisdom of crowds, using a multidimensional sequential             team single elimination tournament, with quarter-finals,
   optimization problem, known as the bandit problem, for            semi-finals and a final. Based on their decisions about
   which there are large differences in individual ability. We       the quarter-finals, these people may be making decisions
   show that, using some established cognitive models of
   people’s decision-making on these problems, aggregate             about different teams in the semi-finals and final. This
   performance approaches optimality, and exceeds the                makes simple aggregation based on their raw decisions
   performance of the vast majority of individuals.                  impossible for the later rounds.
   Keywords: Wisdom of crowds, Cognitive models,
                                                                        For more difficult decision problems like these, we be-
   Bandit problem, Hierarchical Bayesian modeling                    lieve cognitive science has a key role to play in wisdom
                                                                     of the crowd research. Rather than aggregating people’s
                                                                     behaviors, it is necessary to aggregate their knowledge,
                        Introduction                                 as inferred from their behavior. This inference needs
                                                                     models of cognition, accounting for how latent knowl-
An enticing idea in the study of individual and group                edge manifests itself as observed behavior within the
decision-making is the phenomenon known as the “wis-                 constraints of a complicated task. Steyvers, Lee, Miller,
dom of crowds”. The idea is that, by aggregating                     and Hemmer (in press) present an example of this ap-
the behavior of a group of people doing a challeng-                  proach, using Thurstonian models of judgment to com-
ing task, it is possible for group performance to match              bine people’s ranking decisions for a variety of general-
or exceed the performance of any of the individuals.                 knowledge questions, such as the chronology of the US
Surowiecki (2004) provides an extensive survey of wis-               Presidents.
dom of crowds results over a diverse set of human en-                   In this paper, we present a case study of the application
deavors and decision-making situations, ranging from                 of cognitive models for a sequential task known as the
guessing the weight of an ox at a county fair, to infer-             bandit problem. By applying a series of existing mod-
ring the location of a missing submarine, to predicting              els of human decision-making on the task to a variety of
the outcome of sporting events. Recent research in cog-              data sets, we show that it is sometimes possible to pro-
nitive science has looked at issues including whether it             duce aggregate performance that is near optimal, and far
is possible to have a “crowd within”, such that multiple             exceeds the performance of most of the individuals. We
estimates from the same person can be combined to im-                discuss what sort of properties cognitive models might
prove their performance (Vul & Pashler, 2008).                       need to achieve this sort of useful aggregation of individ-
   While the exact conditions needed for group perfor-               ual knowledge.
mance to exceed individual performance are not com-
pletely understood, it seems clear that crowds can be                                   Bandit Problems
wise in any situation where people have some partial
knowledge, and the gaps in their knowledge are subject               Bandit problems are a type of sequential decision-
to individual differences. Under these circumstances, ag-            making problem widely studied in statistics and machine
gregation of individual decisions can serve to amplify the           learning (Gittins, 1979; Kaebling, Littman, & Moore,
                                                                1118

                                                                     a Beta(2, 2) distribution. The reward rates were drawn
                                                                     only once, but the order of the games was randomized.
    15
       Ratio: 0.000
                    15
                       Ratio: 0.667
                                    15
                                       Ratio: 0.667
                                                    15
                                                       Ratio: −−        The second and third experiments involve new data. A
    14              14              14              14               total of 47 and 31 participants, respectively, completed
    13              13              13              13
                                                                     100 bandit problems, all with 4 alternatives and 16 trials.
    12              12              12              12
    11              11              11              11
                                                                     For the second experiment, the reward rates were drawn
    10              10              10              10               independently for each game from Beta(8, 4) (called a
     9
     8
                     9
                     8
                                     9
                                     8
                                                     9
                                                     8
                                                                     “plentiful” environment, because reward rates tend to be
     7               7               7               7               high). For the third experiment, reward rates came from
     6               6               6               6
                                                                     a Beta(4, 8) (called a “scarce” environment, because re-
     5               5               5               5
     4               4               4               4
                                                                     ward rates tend to be low)
     3               3               3               3
     2
     1
                     2
                     1
                                     2
                                     1
                                                     2
                                                     1
                                                                               Four Decision-Making Models
     0               0               0               0
                                                                     In this paper, we consider four well-established mod-
                                                                     els of decision-making on bandit problems. These come
                                                                     from the reinforcement- and machine-learning literatures
                                                                     (see Sutton & Barto, 1998), and have previously been ex-
Figure 1: An experimental interface, giving an example               amined as models of human decision-making (e.g., Lee,
of a Bandit problem.                                                 Zhang, Munro, & Steyvers, 2009).
                                                                     Win-Stay Lose-Shift
1996; Sutton & Barto, 1998), as well as in cognitive sci-            Perhaps the simplest reasonable approach for making
ence (Cohen, McClure, & Yu, 2007; Daw, O’Doherty,                    bandit problem decisions is the Win-Stay Lose-Shift
Dayan, Seymour, & Dolan, 2006; Steyvers, Lee, & Wa-                  (WSLS) heuristic. In its deterministic form, it assumes
genmakers, 2009). In Bandit problems, a decision maker               that the decision-maker continues to choose an alterna-
chooses from a set of alternatives with fixed but un-                tive following a reward, but shifts to the other alterna-
known reward rates, which are drawn from a fixed but                 tive following a failure to reward. In the stochastic form
unknown environment, with the goals of maximizing the                we use, the probability of staying after winning, and the
total number of rewards after a fixed number of trials.              probability of shifting after losing, are both parameter-
   A representative experimental interface of Bandit                 ized by the same probability γ.
problems is shown in Figure 1. The four large panels
                                                                     Extended Win-Stay Lose-Shift
contain information of choices and outcomes on four al-
ternatives. On each trial, an alternative is chosen, and             A natural, and psychologically-motivated, extension to
either succeeds in giving a reward (green, light) or fails           the WSLS model is to have different rates for staying
(red, dark). At the top of each panel, the ratio of suc-             after a reward (i.e., reinforcement) and shifting after a
cesses, defined as the ratio of successes to total choices,          lack of reward (i.e., negative reinforcement). Formally,
is shown. The interface provides a count of the total                in our extended WSLS model, a decision-maker stays
number of rewards obtained up to the current trial. The              with probability γw following a reward, but shifts with
current game and trial are also shown.                               probability γl following a failure to reward.
   The bandit problem has a well-known optimal
decision-making process (e.g., Kaebling et al., 1996,                ε-Greedy
p. 244), calculated by dynamic programming. This al-                 The ε-greedy model assumes that decision-making is
lows human decision-making, and plausible psycholog-                 driven by a parameter ε that controls the balance between
ical models of decision-making, to be assessed in terms              exploration and exploitation inherent in bandit problems.
of their optimality. In particular, Bandit problems pro-             On each trial, with probability 1 − ε the decision-maker
vide a natural task to study the inherent trade-off be-              chooses the alternative with the greatest estimated re-
tween exploration (seeking rewarding alternatives among              ward rate (i.e., the greatest proportion of rewards ob-
those relatively unexplored) and exploitation (staying               tained for previous trials where the alternative was cho-
with alternatives known to be reasonably good) inher-                sen). This can be conceived as an ‘exploitation’ deci-
ent in many real-world sequential decision-making situ-              sion. With probability ε, the decision-maker chooses ran-
ations.                                                              domly. This can be conceived as an ‘exploration’ deci-
                                                                     sion.
                         Human Data
We use data from three experiments. In the first ex-                 ε-Decreasing
periment, reported by Steyvers et al. (2009), a total of             The ε-decreasing model is a variant of ε-greedy, in which
451 participants completed a total of 20 bandit prob-                the probability of an exploration move decreases as trials
lems, each with 4 alternatives and 15 trials. Reward                 progress. In its most common form, which we use, the ε-
rates were drawn for each alternative independently from             decreasing model starts with an exploration probability ε0
                                                                 1119

                     γw                  γl                                        µw      σw               µl     σl
                                a                                                      γkw                     γkl
                              θij
                                                                                                      a
                                                                                                    θijk
                              dij
                                      i trials
                                  j problems
                                                                                                    dijk
Figure 2: Bayesian graphical model for the extended                                                         i trials
WSLS decision-making model.                                                                              j problems
                                                                                                            k people
                                                                 Figure 3: Bayesian graphical model for a hierarchical
on the first trial, and then uses an exploration probability     version of the extended WSLS decision-making model,
of ε0 /i on the ith trial.
                                                                 which allows for individual-level parameter variation.
                    Modeling Analysis
                                                                 chosen on the ith trials of the jth game, as
In this section, we implement the four decision-making                        w
models in a way that allows for differences in individual                    
                                                                               γ                 if succeeded on a last trial
                                                                             
                                                                                1 − γl            if failed on a last trial
behavior to be aggregated, culminating in model-based                 θi j =
                                                                       a
wisdom of crowds analyses of our experimental data sets.                     
                                                                               (1 − γ w )/3 if succeeded on ā last trial
                                                                              l
                                                                                γ /3              if failed on ā last trial,
Bayesian Graphical Model Implementation                          where ā refers to not choosing the ath alternative. Since
                                                                 θi j is a deterministic function of γw and γl , it is shown as
We implemented all four decision-making models using             a double-bordered node. Given the choice probabilities
the formalism provided by Bayesian graphical models,             in θaij , the actual decision made by the ith trial of the
as widely used in statistics and computer science (e.g.,          jth problem— which is represented by a shaded square
Koller, Friedman, Getoor, & Taskar, 2007). A graphical           node di j , since it is observed, and discrete—is modeled
model is a graph with nodes that represents the proba-           as di j ∼ Discrete(θ1i j . . ., θ4i j).
bilistic process by which unobserved parameters gener-
ate observed data. Details and tutorials are aimed at cog-       Parameter Differences
nitive scientists are provided by Lee (2008) and Shiffrin,       One obvious possibility for individual differences is that
Lee, Kim, and Wagenmakers (2008). The practical ad-              two people—even if they are both using, for example,
vantage of graphical models is that sophisticated and            extended WSLS—might not have the same probabilities
relatively general-purpose Markov Chain Monte Carlo              of wining and staying or losing and shifting. To accom-
(MCMC) algorithms exist that can sample from the full            modate variation in these parameters on an individual-
joint posterior distribution of the parameters conditional       by-individual uses, we use a hierarchical or multi-level
on the observed data. More specifically, for our purposes,       approach. The updated graphical model is shown in Fig-
graphical models can be specified that naturally combine         ure 3. In this model, the parameters for individual peo-
information across multiple sources, and so can model            ple are drawn from over-arching Gaussian distributions,
the individual differences at the heart of the wisdom of         so that, for the kth person, γwk ∼ Gaussian(µw , σw ), and
crowds phenomenon.                                               γln ∼ Gaussian(µl , σl ). This allows different people to
   As a concrete example, Figure 2 shows the graphi-             have different parameter values, while still estimating the
cal model implementation of the extended WSLS model.             mean parameter value of the group as a whole.
The two model parameters, the probability of win-stay                We implemented the graphical model in Figure 3, as
γw and lose-shift γl , are shown as unshaded (i.e., unob-        well as analogous graphical models for the three other
served) and circular (i.e., continuous) variables. These         decision-making models, in WinBUGS (Spiegelhalter,
determine the probability of the ath alternative being           Thomas, & Best, 2004). This software uses a range
                                                             1120

                                                                                 
                         µγ    σγ   σw    µw    µl    σl   µ     σ           µ      σ
                                                                                         
                            γk           γkw    γkl            k                  k
                             γ               wl                                    
                           θijk             θijk              θijk                θijk
                                                     θijk                                     zk            φ
                                                     dijk
                                                                                  i trials
                                                                              j problems
                                                                                           k people
       Figure 4: Graphical model using a hierarchical mixture of all four hierarchical decision-making models.
                                                                     ering rewards. The reasonably large standard deviations
Table 1: Means, and standard deviations in brackets, of              for most group distributions also indicate that there are
the group distributions for each parameter in the four               significant individual differences.
decision-making models.
   Parameter        Exp. 1         Exp. 2           Exp. 3           Model Differences
        γ         0.71 (.10)     0.70 (0.10)     0.52 (0.10)         An even more fundamental source of individual differ-
       γw        0.99 (0.27)     0.97 (0.19)     0.81 (0.18)         ences arises when different people use different decision
       γl        0.59 (0.25)     0.28 (0.23)     0.37 (0.23)         processes. Rather than just varying the parameters of a
                                                                     model, people may differ in terms of which decision-
        ε        0.24 (0.10)     0.18 (0.11)     0.42 (0.12)
                                                                     making model they use. We accommodate this type of
       ε0        0.61 (0.11)     0.61 (0.11)     0.90 (0.14)         individual differences using a mixture or latent assign-
                                                                     ment model where people are categorized into different
                                                                     model-users.
                                                                        The graphical model for achieving this mixture of de-
of MCMC computational methods, including adaptive                    cision models, while retaining the possibility of parame-
rejection sampling, splice sampling, and Metropolis-                 ter variation within each model, is shown in Figure 4. Hi-
Hastings to perform posterior sampling (e.g., MacKay,                erarchical versions of all four decision-making models—
2003). For all four decision-making models, we made                  those used individual to assess parameter variation in the
inferences about individual- and group-level parameters              previous section—are all shown.
for all three data sets, using all of the participants. In              The key addition, in terms of individual differences,
each analysis, we collected 1,000 samples from 2 chains,             involves the model indicator variable zk , which indexes
collected after a burn-in period of 1,000 samples, and us-           which of the four models the kth participant uses. That
ing standard checks for convergence.                                 is, depending on whether zk is 1, 2, 3 or 4, the kth par-
   Table 1 summarizes individual differences in parame-              ticipant uses WSLS, the extended WSLS, ε-greedy or ε-
ters for each decision-making model, giving the means                decreasing to make their bandit problem decisions. The
and standard deviations for each parameter in the hier-              latent indicator variable has prior zk ∼ Categorical(φ),
archical analysis. Remembering that experiments 1, 2,                where φ is a latent base-rate, measuring the proportion
and 3 correspond to neutral, plentiful and scarce envi-              of people who follow each model. We use the prior
ronments, the aggregated group parameters make sense.                φ ∼ Dirichlet(1/4, . .., 1/4), so that there is no initial bias
For example, there is more winning and staying (e.g.,                towards one decision model over another.
in the γ and γw parameters) in environments that deliver                Table 2 gives the posterior expectation of the base-rate
rewards, and there is more random exploration (e.g., in              parameter φ, for all three experiments. This provides a
the ε and ε0 ) in scarce environments that are not deliv-            natural summary of what proportion of people were us-
                                                               1121

                           Exp 1 (Neutral)                                     Exp 2 (Plentiful)                             Exp 3 (Scarce)
                                                   Group player 3
                20                                                                                                 2
                                                   Optimal player
    WSLS
                                                                  2
                10                                                                                                 1
                                                                 1
                 0                                               0                                                 0
                     140   160     180       200   220                1060   1080   1100   1120   1140   1160          500     550       600      650
    Ext. WSLS
                20                                               3                                                 2
                                                                 2
                10                                                                                                 1
                                                                 1
                 0                                               0                                                 0
                     140   160     180       200   220                1060   1080   1100   1120   1140   1160          500     550       600      650
                                                                 3
 ε−greedy
                20                                                                                                 2
                                                                 2
                10                                                                                                 1
                                                                 1
                 0                                               0                                                 0
                     140   160     180       200   220                1060   1080   1100   1120   1140   1160          500     550       600      650
 ε−decreasing
                20                                               3                                                 2
                                                                 2
                10                                                                                                 1
                                                                 1
                 0                                               0                                                 0
                     140   160     180       200   220                1060   1080   1100   1120   1140   1160          500     550       600      650
                                                                               Total Rewards
Figure 5: Distribution of rewards for individual participants, the group model, and the optimal decision-making pro-
cess, for each decision-making model and each experiment. See text for details..
                                                                                           mance.1 This approach solves the problem of aggregat-
Table 2: Proportion of people using each model, for the                                    ing the knowledge of different people solving different,
three experiments, as measured by the posterior expecta-                                   but related, bandit problems. Rather than aggregating
tion of the φ parameter.                                                                   their behavioral choices, we are aggregating the psychol-
                          Model          Exp. 1    Exp. 2        Exp. 3                    ogy parameter values that lead to those choices.
                          WSLS             0%        0%            0%                         To complete the model-based wisdom of crowd anal-
                Extended WSLS             75%       81%           70%                      yses, we used the group mean parameter values to define
                                                                                           a “group model” that used the same decision-process,
                        ε-greedy          22%       16%           29%
                                                                                           and completed the same problems given to participants in
                    ε-decreasing           3%        3%            1%                      each of the three experiments. Because the number of re-
                                                                                           wards obtained is inherently stochastic, we repeated this
                                                                                           many times to approximate the distribution of rewards.
                                                                                           We also applied the optimal decision-making process to
ing each of the four models, and so summarizes indi-                                       each experiment, to approximate the best possible distri-
vidual differences results at this fundamental level. The                                  bution of rewards for each experiments
findings are consistent across all three experiments—                                         The results are shown in Figure 5. The columns corre-
even though they have different distributions of reward                                    spond to the three experiments. The rows correspond to
rates—with the clear majority of the participants inferred                                 the WSLS, extended WSLS, ε-greedy and ε-decreasing
to be using the extended WSLS model, and a minority                                        decision models. Within each panel, the squares piled
using ε-greedy. The proportion inferred to be using the                                    into histograms show the distribution of performance
other two models is negligible.                                                            (i.e., how many rewards were obtained) for the individual
                                                                                           participants. The two curves then correspond to the dis-
Wisdom of Crowds Analysis                                                                  tribution of performance for the group model (red, dotted
                                                                                           line) and the optimal decision process (green, solid line).
Our modeling of individual differences in models and                                          Figure 5 shows that some of our decision-making
parameters immediately allows a range of wisdom of                                            1 We tried more involved analyses, using the full mixture
the crowd analyses. The most basic analyses involve
                                                                                           model in Figure 4 to sample a model, and then parameters, to
taking each of our decision-making models, and using                                       define a group model. We never found a wisdom of crowd ef-
the inferred group mean in the hierarchical analysis, as                                   fect comparable to what was achieved with the basic analyses,
shown in Table 1 as the aggregate of individual perfor-                                    so we just report those.
                                                                                    1122

models do produce a clear wisdom of the crowds ef-                                        References
fect, whereas others do not. The distributions of rewards          Cohen, J. D., McClure, S. M., & Yu, A. J. (2007). Should
for the group model formed by the WSLS and extended
                                                                     I stay or should I go? Exploration versus exploitation.
WSLS models does not improve on the distribution of in-
dividual performance, and are not close to optimal. For              Philosophical Transactions of the Royal Society B: Bi-
the ε-greedy and ε-decreasing group models, however,                 ological Sciences, 362, 933–942.
there is significant improvement. In particular, the ε-            Daw, N. D., O’Doherty, J. P., Dayan, P., Seymour, B., &
decreasing group model has a distribution of rewards that            Dolan, R. J. (2006). Cortical substrates for exploratory
is extremely close to the optimal distribution for all three         decisions in humans. Nature, 441, 876–879.
experiments.                                                       Gittins, J. C. (1979). Bandit processes and dynamic allo-
                                                                     cation indices. Journal of the Royal Statistical Society,
                           Discussion                                Series B, 41, 148–177.
There are some intriguing features of our wisdom of                Kaebling, L. P., Littman, M. L., & Moore, A. W. (1996).
crowd results presented in Figure 5. Most obviously, it              Reinforcement learning: A survey. Journal of Artifi-
is very encouraging that it is possible to take a simple             cial Intelligence Research, 4, 237–285.
decision-making model like ε-decreasing, take the win-
                                                                   Koller, D., Friedman, N., Getoor, L., & Taskar, B.
dow it provides onto human decision-making, and pro-
duce an aggregate decision-maker that performs near op-              (2007). Graphical models in a nutshell. In L. Getoor &
timally. But, we note that this wisdom of crowd effect               B. Taskar (Eds.), Introduction to statistical relational
is not achieved for all of the cognitive models we tried,            learning. Cambridge, MA: MIT Press.
and, most particularly, was not achieved for the extended          Lee, M. D. (2008). Three case studies in the Bayesian
WSLS that provided the best account of the vast majority             analysis of cognitive models. Psychonomic Bulletin &
of individual behavior, as detailed in Table 2.                      Review, 15(1), 1–15.
   We think the explanation for this finding is that , the ε-      Lee, M. D., Zhang, S., Munro, M. N., & Steyvers, M.
greedy and ε-decreasing models are able to match more                (2009). Using heuristic models to understand human
closely optimal behavior. Detailed analysis showing this             and optimal decision-making on bandit problems. In
was presented by Lee et al. (2009) and makes intuitive               A. Howes, D. Peebles, & R. Cooper (Eds.), Proceed-
psychological sense. Neither WSLS model is sensitive
                                                                     ings of the Ninth International Conference on Cogni-
to which trial in the total sequence is being completed,
which is important information in managing the trade-                tive Modeling — ICCM2009. Manchester, UK.
off between early exploration and late exploitation. As a          MacKay, D. J. C. (2003). Information Theory, Infer-
consequence of this sub-optimality, it is not surprising a           ence, and Learning Algorithms. Cambridge: Cam-
wisdom of crowd effect was not achieved for these sim-               bridge University Press.
ple models.                                                        Shiffrin, R. M., Lee, M. D., Kim, W.-J., & Wagenmakers,
   What is more surprising is that the effect could be               E.-J. (2008). A survey of model evaluation approaches
achieved for a decision-making model like ε-decreasing               with a tutorial on hierarchical Bayesian methods. Cog-
that is not an especially good account of individual be-             nitive Science, 32(8), 1248–1284.
havior. An important topic for future wisdom of crowds             Spiegelhalter, D. J., Thomas, A., & Best, N. G. (2004).
research is to identify what properties of cognitive mod-            WinBUGS Version 1.4 User Manual. Cambridge, UK:
els are important in producing good aggregations of indi-
                                                                     Medical Research Council Biostatistics Unit.
vidual knowledge. Being able to mimic optimal behavior
is a start, but it is not currently clear how effective models     Steyvers, M., Lee, M. D., Miller, B., & Hemmer, P. (in
must be able to account for what people do.                          press). The wisdom of crowds in the recollection of
   More generally, we think our case study with bandit               order information. In J. Lafferty & C. Williams (Eds.),
problems demonstrates a very general approach for ap-                Advances in neural information processing systems,
plying cognitive models to study and use the wisdom of               23. Cambridge, MA: MIT Press.
crowds phenomenon. Using graphical models allows hi-               Steyvers, M., Lee, M. D., & Wagenmakers, E.-J. (2009).
erarchies of parameters, and mixtures of decision pro-               A Bayesian analysis of human decision-making on
cesses, to combine the individual differences in people,             bandit problems. Journal of Mathematical Psychol-
at the level of their basic knowledge about a task. This             ogy, 53, 168–179.
leads naturally to a principled sort of aggregation that is
                                                                   Surowiecki, J. (2004). The wisdom of crowds. New York:
applicable to complicated, multidimensional and sequen-
tial tasks, which might be among those most needing the              Random House.
pooling of individual capabilities to achieve good perfor-         Sutton, R. S., & Barto, A. G. (1998). Reinforcement
mance.                                                               learning: An introduction . Cambridge (MA): The MIT
                                                                     Press.
                      Acknowledgments                              Vul, E., & Pashler, H. (2008). Measuring the crowd
This work is was supported by an award from the Air                  within: Probabilistic representations within individu-
Force Office of Scientific Research (FA9550-07-1-0082).              als. Psychological Science, 19(7), 645–647.
                                                               1123

