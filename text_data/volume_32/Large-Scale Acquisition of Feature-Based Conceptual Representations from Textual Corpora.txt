UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Large-Scale Acquisition of Feature-Based Conceptual Representations from Textual Corpora
Permalink
https://escholarship.org/uc/item/5pv3178f
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Devereux, Barry
Pilkington, Nicholas
Poibeau, Thierry
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

      Large-Scale Acquisition of Feature-Based Conceptual Representations from
                                                            Textual Corpora
            Barry Devereux (barry@csl.psychol.cam.ac.uk)1 , Nicholas Pilkington (ncvp2@cam.ac.uk)2 ,
                   Thierry Poibeau (thierry.poibeau@ens.fr)3 , Anna Korhonen (alk23@cam.ac.uk)2
        1 Centre for Speech, Language and the Brain, Department of Experimental Psychology, University of Cambridge
                                               2 Computer Laboratory, University of Cambridge
                                                     3 Laboratoire LaTTiCe-CNRS, Paris
                               Abstract                                  from property norming studies. Currently, the largest set of
                                                                         norms available is that collected by Ken McRae and col-
   Methods for estimating people’s conceptual knowledge have
   the potential to be very useful to theoretical research on con-       leagues which contains features for 541 concrete concepts
   ceptual semantics. Traditionally, feature-based conceptual rep-       (McRae, Cree, Seidenberg, & McNorgan, 2005). Participants
   resentations have been estimated using property norm data;            listed features for each concept word and McRae et al. nor-
   however, computational techniques have the potential to build
   such representations automatically. The automatic acquisition         malised them by mapping different feature descriptions with
   of feature-based conceptual representations from corpora is a         the same meaning to the same feature label.
   challenging task, given the unconstrained nature of what can
   constitute a semantic feature. Existing computational methods            Feature-based representations of concepts based on
   typically do not target the full range of concept-relation-feature    property-norming studies have played an important role in
   triples occurring in human generated norms (e.g. tiger have           testing theories of conceptual knowledge. However, property
   stripes) but rather focus on concept-feature tuples (e.g. tiger
   – stripes) or triples involving specific relations only. We in-       norms come with several important caveats (see e.g. Mur-
   vestigate the large-scale extraction of concept-relation-feature      phy, 2002, for a discussion). One issue is that participants
   triples and the usefulness of encyclopedic, syntactic and se-         tend to under-report features which are present in many of the
   mantic information in guiding the extraction process. Our
   method extracts candidate triples (e.g. tiger have stripes, flute     concepts in a category (McRae et al., 2005; Murphy, 2002,
   produce sound) from parsed corpus data and ranks them on              p. 32); for TIGER for example, participants list salient fea-
   the basis of semantic information. Our investigation shows            tures like has teeth but not less salient features like has eyes.
   the usefulness of external knowledge in guiding feature ex-
   traction and highlights issues of methodology and evaluation          Thus has eyes is not listed for TIGER although presumably all
   which need to be addressed in developing models for this task.        McRae et al.’s participants knew that tigers have eyes. An-
   Keywords: distributed conceptual representations; semantic            other concern is the size of the currently available property
   features; corpus-based acquisition                                    norms. Although the largest collection of norms lists features
                                                                         for over 500 concepts, larger sets of norms would be useful
                           Introduction                                  given the number of confounding variables (word length, fa-
Concrete concepts like TIGER, APPLE and CHISEL constitute                miliarity, etc) that need to be controlled for in studies of con-
a fundamental part of people’s coherent mental representa-               cepts and word meaning. Unfortunately, large scale property
tions of the world around them. A key question in cogni-                 norming studies are costly and time consuming.
tive science is how these semantic representations are organ-               In recent years, researchers have begun to develop meth-
ised and accessed. Most theories of conceptual representa-               ods which can automatically extract feature norm-like repre-
tion assume a distributed, feature-based model of conceptual             sentations using corpus-based computational techniques (e.g.
knowledge (e.g. Cree, McNorgan, & McRae, 2006; Randall,                  Almuhareb & Poesio, 2005; Barbu, 2008; Baroni, Murphy,
Moss, Rodd, Greer, & Tyler, 2004; Tyler, Moss, Durrant-                  Barbu, & Poesio, 2009). These approaches – and the ap-
Peatfield, & Levy, 2000). According to such theories, con-               proach we present in this paper – have their antecedents
ceptual knowledge is distributed across a network of intercon-           in early methods for extracting and organizing the seman-
nected feature units (such as has eyes, has ears, has stripes)           tic feature information implicit in dictionary definitions (e.g.
with concepts’ meanings being represented as patterns of ac-             Chodorow, Byrd, & Heidorn, 1985). The automatic approach
tivation across these units. The relative prominence of this             is cost-effective and can gather large-scale frequency data
distributed, feature-based account of conceptual representa-             from text corpora. As corpora contain words denoting con-
tion in the literature reflects the many perceived strengths of          cepts and their features in natural language, they provide ideal
such a framework.                                                        material for feature generation. However, current methods
   A key issue for all studies which aim to test distributed             target concept-feature tuples only or are restricted to specific
theories of concepts is the accurate estimation of the knowl-            relations between concepts and their features. For example,
edge that people are likely to represent in such a system. Re-           Almuhareb and Poesio (2005) targeted is-a and part-of rela-
cent connectionist, behavioural and neuropsychological stud-             tions, whilst Barbu (2008) combined linguistic patterns with
ies (e.g. Cree et al., 2006; Grondin, Lupker, & McRae, 2009;             a co-occurrence based method to extract six types of features:
Randall et al., 2004; Tyler et al., 2000; Taylor, Salamoura,             superordinate, part, stuff, location, quality and action.
Randall, Moss, & Tyler, 2008) have relied on data derived                   The Strudel model (Baroni et al., 2009) also uses linguis-
                                                                      49

tic patterns, but more generally. Strudel uses “connector pat-        were created from the resultant set of 1.84 million articles.
terns” consisting of sequences of part-of-speech tags to look         The first of these (Wiki500) includes the Wikipedia articles
for candidate feature terms near a target concept. Proper-            that correspond to each of the McRae concepts. It contains
ties are scored based on the number of distinct patterns con-         c. 500 articles (1.1 million words). The second subcorpus
necting them to a concept, rather than on the overall number          consists of those articles which contain one of the McRae
of corpus co-occurrences. When evaluated against the ESS-             concept words in the title and the title is less than five words
LLI dataset that includes 44 concepts from the McRae norms            long.1 This Wiki110K corpus includes 109,648 plaintext ar-
(Baroni, Evert, & Lenci, 2008), Strudel yields the precision          ticles (36.5 million words).
of 23.9% – which is the best state of the art result for uncon-
strained acquisition of concept feature tuples.                       Recoding the McRae features
   Due to the difficulty of the task, we believe that additional      We recoded a British English version of the McRae norms
linguistic and world knowledge will be required to extract            to a uniform representation that is more appropriate for our
more accurate representations. Moreover, Strudel has the lim-         computational work. Each concept-feature pair in the norms
itation that it produces concept-feature tuples – not concept-        (e.g. TIGER has stripes) was automatically recoded to a triple
relation-feature triples similar to those in human generated          of the form concept relation feature-head where concept was
norms (although the distribution of the connector patterns for        the singular of the concept noun (e.g. ‘tiger’), relation was
a tuple does cue information about the broad class of semantic        the root form of a verb (e.g. ‘have’) and feature-head was al-
relation that holds between concept and feature).                     ways a singular noun or an adjective (e.g. ‘stripe’). Feature-
   In this paper, we investigate the challenges that need to          heads containing more complex information than could be
be met in both methodology and evaluation when aiming                 captured with a single noun or adjective were split into two
to move towards unconstrained, large-scale extraction of              or more triples (for example, the norm feature is a musical
concept-relation-feature triples in corpus data. The extrac-          instrument for ACCORDION was recoded to the two triples
tion of such realistic, human-like feature norms is extremely         accordion be instrument and accordion be musical). Where
challenging and we do not predict a high level of accuracy in         “beh” and “inbeh” appeared in features in the norms (indi-
these first experiments. We investigate the usefulness of three       cating behaviour features of animate and inanimate concepts;
types of external knowledge in guiding feature extraction:            e.g. DOG beh bark) this was replaced with the verb “do”.
encyclopedic, syntactic and semantic knowledge. We first              Prepositions and determiners were also removed when con-
compile large automatically parsed corpora from Wikipedia             structing the triples. Although this recoding involves a loss of
which contains encyclopedic information. We then intro-               information to some extent, it also enables us to clearly dis-
duce a novel method which extracts concept-relation-feature           tinguish between the relation and feature-head parts in each
triples from grammatical dependences produced by a parser.            feature norm. It is triples of this form that we aim to extract
We use probabilistic information about semantic classes of            with our computational method.
features and concepts to guide the acquisition process. Our
investigation shows that external knowledge can be useful in
                                                                      Candidate feature extraction
guiding the extraction of human-like norms.                           Our method for extracting concept-relation-feature triples
                                                                      consists of two stages: we first extract large sets of candidate
                    Extraction Method                                 feature triples for each target concept from the corpus, and
                                                                      then re-rank and filter the triples with the aim of retaining
Corpora
                                                                      only those triples which are most likely to be true semantic
We chose Wikipedia as our corpus as it is a freely available          features.
and comprehensive encyclopedia that includes basic informa-              For the first stage, the corpora are parsed using the Robust
tion on many everyday topics. Almost all concepts in the              Accurate Statistical Parsing (RASP) system (Briscoe, Car-
norms have their own Wikipedia articles, and the articles of-         roll, & Watson, 2006). For each sentence in the corpora, this
ten include facts similar to those elicited in norming studies        yields the set of grammatical relations (GRs) for the most
(e.g. the article Elephant describes how elephants are large,         probable analysis returned by the parser. The GR sets for
are mammals, and live in Africa). By using Wikipedia, we in-          each sentence containing the target concept noun are then re-
vestigate the usefulness of a smaller amount of more focused          trieved from the corpus. We construct an undirected acyclyic
(encyclopedic) corpus data for the task.                              graph of the GRs that spans the sentence and which has the
   The XML dump of Wikipedia was filtered to remove non-              target concept word as its root node. The nodes are labelled
encyclopedic articles (e.g. talk pages), article sections that are    by the words occurring in the sentence and an edge is present
unlikely to contain parsable text (e.g. bibliography sections),       when a GR links those two words in the sentence. Edges can
and inline references (e.g. book citations). The remain-              thus be labelled by the GR types. For example, the graph
ing content was preprocessed with Wikiprep (Gabrilovich
                                                                          1 The subset was limited to articles with titles less than five words
& Markovitch, 2007), removing tables, unparsable elements
                                                                      long in order to avoid articles on very specific topics which are un-
(e.g. Wikipedia infoboxes) and the WikiMedia mark-up,                 likely to contain basic information about the target concept (e.g.
yielding a plaintext version of each article. Two subcorpora          Coptic Orthodox Church of Alexandria for CHURCH.)
                                                                   50

constructed for the sentence Tabby tigers can often have pale            Clusters       Example Members
stripes contains a path connecting tiger, have and stripe.               Concept clusters
   Our method considers the set of paths through the tree be-            Reptiles       alligator, crocodile, iguana, rattlesnake
tween the target concept root node and the other nodes which             Fruit/Veg      cucumber, honeydew, mushroom, plum
are either an adjective or a noun; these adjectives and nouns            Vehicles       ambulance, helicopter, car, rocket, jet
are the potential feature heads in the concept-relation-feature          Feature clusters
triples. If there is a verb in the path between the target con-          Body Parts ear, foot, fuzz, nose, tongue
cept and the feature head, we extract the candidate triple con-          Plant Parts bark, berry, blade, grape, prune
cept verb feature-head. The first stage of our method extracts           Activities     cluck, drip, emergency, flow, funeral
all possible candidate triples from the set of paths. As this
                                                                      Table 1: Example members of concept and feature clusters
method is maximally greedy, the second stage evaluates the
quality of these extracted candidates using semantic informa-                               Reptiles    Fruit/Veg     Vehicles
tion, with the aim of filtering out the poor quality features.
                                                                             Body Parts     0.164       0.031         0.023
Re-ranking based on semantic information                                     Plant Parts    0.009       0.130         0.014
                                                                             Activities     0.100       0.060         0.140
The more often a triple is extracted for a concept, the more
                                                                    Table 2: P(F|C) for C ∈ {Reptiles, Fruit/Veg, Vehicles} and
likely it is that the triple corresponds to a feature related to
                                                                    F ∈ {Body Parts, Plant Parts, Activities}
the concept. However, production frequency alone is an in-
adequate measure of the quality of the feature term because
concept terms and candidate feature terms can co-occur for all      feature cluster given a concept cluster using the data in
sorts of reasons. For example, one of the extracted triples for     the McRae norms. Table 2 gives the conditional prob-
TIGER is tiger have squadron (because of the RAF squadron           ability for each of the three feature clusters given each
called the Tigers).                                                 of the three concept clusters that were presented in Ta-
   The probability of a feature being part of a concept’s rep-      ble 1. For example, P(Body Parts|Reptiles) is higher than
resentation is dependent on the semantic category that the          P(Body Parts|Vehicles): given a concept in the Reptiles clus-
concept belongs to (used for cutting should have low prob-          ter the probability of a Body Part feature is relatively high
ability for animals, for example). We conducted an analysis         whereas given a concept in the Vehicle cluster the probability
of the norms to quantify this type of semantic information.         of a Body Part feature is low. The cluster analysis therefore
Our aim was to identify higher-order structure in the distri-       supports our hypothesis that the likelihood of a particular fea-
bution of semantic classes for features and concepts, with the      ture for a particular concept is not independent of the seman-
goal of investigating whether this information is useful in fea-    tic categories that the concept and feature belong to.
ture extraction. More formally, we assume that there is a 2-        Reranking We used this distributional semantic informa-
dimensional probability distribution over concept and feature       tion to improve the quality of the concept relation feature can-
classes, P(C, F), where C is a concept class (e.g. Animal) and      didate triples, by using the conditional probabilities of the ap-
F is a feature class (e.g. Body-Part). Knowing this distribu-       propriate feature cluster given the concept cluster as a weight-
tion gives a way of evaluating how likely it is that a candidate    ing factor. To get the probabilities for a triple, we first find the
feature f is true for a concept c, assuming that we know that       clusters that the concept and the feature-head words belong
c ∈ C and f ∈ F. We can regard the McRae norms as being             to. When the feature-head word of the extracted triple appears
a sample drawn from this distribution, provided the concept         in the norms, its cluster membership is looked up directly;
and feature terms appearing in the norms can be assigned to         when it is not in the norms we assign the feature-head to the
suitable concept and feature classes. Clustering was used to        feature cluster with which it has the highest average similar-
identify such classes.                                              ity. Given the concept and feature clusters determined for the
Clustering Our cluster analysis used Lin’s (1998) similar-          concept and feature in the triple, we reweight the triple’s fre-
ity metric, which uses the WordNet ontology as the basis for        quency by multiplying it by the conditional probability. This
calculating similarity. Such a measure is appropriate for our       helps downgrade incorrect triples that occur frequently in the
purposes as we are interested in generating suitable superor-       data and boost the evidence for correct triples.
dinate classes for which we can calculate the distributional        Baseline model For the purposes of evaluation, we also im-
statistics. The concepts and feature-head terms appearing in        plemented a co-occurrence-based model based on the “SVD”
the recoded norms were each clustered independently into 50         (Singular Value Decomposition) model described by Baroni
clusters using hierarchical clustering. Table 1 presents three      et al. (2009). A word-by-word co-occurrence matrix was con-
concept clusters and three feature clusters with five represen-     structed for both our corpora, storing how often each target
tative members of each cluster (we have given intuitive labels      word co-occurred in the same sentence as each context word.
to the clusters for explanatory purposes). In general, seman-       Context words were defined to be the 5,000 most frequent
tically similar concepts and features clustered together.           content words in the corpora. Target words were the concept
   We calculated the conditional probability P(F|C) of a            names in the recoded norms, supplemented with the 10,000
                                                                 51

most frequent content words in the corpora (with the excep-              Extraction set            Corpus          Prec.       Recall
tion of the 10 most frequent words). The dimensionality of
                                                                                                   Wiki500         0.0235      0.4712
the co-occurrence matrix was reduced to 150 columns by sin-              SVD Baseline
                                                                                                   Wiki110K        0.0140      0.2798
gular value decomposition. Cosine similarity between pairs
                                                                                                   Wiki500         0.0239      0.5081
of target words was calculated and, for each concept word,               Method - unfiltered
                                                                                                   Wiki110K        0.0068      0.8083
we chose the 200 most similar target words to be the feature-
                                                                         Method - top 25%          Wiki500         0.0470      0.2735
head terms extracted by the model.
                                                                         unweighted                Wiki110K        0.0179      0.6260
                                                                         Method - top 25%          Wiki500         0.0814      0.4167
                Experimental Evaluation                                  weighted                  Wiki110K        0.0230      0.6851
                                                                     Table 3: Results for the baseline model and the extraction
Methods of Evaluation                                                method, when matching on features but not relations.
We considered several methods for evaluating the quality of          Precision and Recall
the extracted feature triples. One method is to calculate pre-
cision and recall for the extracted triples with respect to the      The recall score for a concept is defined as the number of
McRae norms “gold standard”. However, direct comparison              extracted features for the concept that appear in the recoded
with the recoded norms is problematic since an extracted fea-        norms divided by the total number of features for that concept
ture which is semantically equivalent to a triple in the norms       in the norms. High recall indicates that a high proportion of
may have a different lexical form. For example, avocado have         the McRae features are being extracted. The precision score
stone appears in the recoded norms whilst avocado contain            for a concept is defined as the number of extracted features
pit is extracted by our method; direct comparison of these           for that concept that appear in the norms divided by the total
two triples results in avocado contain pit being incorrectly         number of features extracted for the concept.2 As discussed
counted as an error. To deal with the fact that semantically         above, we aim to maximize recall.
identical features can be lexically different, we followed the           Table 3 presents the results when we evaluate using the
approach taken in the ESSLLI 2008 Workshop on semantic               feature-head term alone (i.e. in calculating precision and re-
models (Baroni et al., 2008). The gold standard for the ESS-         call we disregard the relation verb and require only a match
LLI task was the top 10 features for 44 of the McRae con-            between the feature-head terms in the extracted triples and the
cepts: for each feature an expansion set was given, listing          recoded norms). Evaluating tuples (rather than triples) is how
words that were synonyms of the feature term that appeared           large-scale models of feature extraction have typically been
in the norms. For example, the feature lives on water was            evaluated in the past (e.g. Baroni et al., 2009).
expanded to the set {aquatic, lake, ocean, river, sea, water}.           Results for four sets of extractions are presented. The first
   We expect to find correct features in corpus data which           set is the set of features extracted by the SVD baseline. The
are not in the “gold standard” (e.g. breathes air is listed          second set of extracted triples are the full set of triples ex-
for WHALE but for no other animal). We therefore aim for             tracted by our method, prior to the reweighting stage. “Top
high recall in the evaluation against the ESSLLI set (since          25% unweighted” gives the results when all but the top 25%
all features in the norms should ideally be extracted) but not       most frequently extracted triples for each concept are filtered
necessarily high precision (since extracted features that are        out. Note that the filtering criteria here is raw extraction
not in the norms may still be correct; e.g. breathes air for         frequency, without reweighting by conditional probabilities.
TIGER ). To evaluate the ability of our model to generate
                                                                     “Top 25% weighted” are the corresponding results when the
such novel features, we also conducted a manual evaluation           features are weighted by the conditional probability factors
of the highest ranked extracted features which did not appear        prior to filtering; that is, using the top 25% reranked features.
in the norms. Finally, we introduce a novel evaluation method        The effectiveness of using the semantic class-based analysis
which makes no direct use of McRae norms. This is based on           data in our method can thus be assessed by comparing the
analysis of the extracted feature-based semantic reprentations       filtered results with and without feature weighting.
in terms of conceptual structure properties. Conceptual struc-           For the baseline implementation, the results are better us-
ture statistics such as feature distinctiveness, sharedness and      ing the smaller Wiki500 corpus than the larger Wiki110K cor-
correlation strength have an important role to play in testing       pus. This is not surprising, since the smaller corpus contains
distributed theories of conceptual knowledge (e.g. see Ran-          only the articles corresponding to the concepts in the norms.
dall et al., 2004; Taylor et al., 2008). Therefore, we were          This smaller corpus thus minimizes sources of noise such as
interested in the accuracy of the conceptual structure statis-       word polysemy that are more apparent in the larger corpus
tics that can be calculated from the extracted features. If the      (e.g. “tiger” almost always refers to the animal in the Wiki500
conceptual structure statistics calculated for the extracted fea-    corpus, but can have other meanings in larger or general cor-
tures resemble those obtained from human-generated norms,                2 Since we define precision over the whole set of extracted fea-
it provides evidence that the extracted features capture impor-      tures, our precision score is not comparable to Baroni et al. (2009),
tant aspects of the semantics of concrete concepts.                  where the top 10 extracted features are used.
                                                                  52

pora (the RAF squadron called the Tigers, etc)).                          Measure                              Correl           p
   The results for the baseline model and the unfiltered exper-           Number of features                   0.203     < 0.001
imental method are quite similar for the Wiki500 corpus. As               Number of distinctive features       0.168     < 0.001
our extraction method is deliberately greedy, extracting many             Number of shared features            0.113       0.983
candidate features per sentence, it is not surprising that its            Mean distinctiveness                 0.167     < 0.001
performance is comparable to a purely co-occurrence-based                 Proportion of shared features        0.155     < 0.001
method. The innovation of our method is that it uses infor-               Mean correlational strength          -0.118      0.014
mation about the GR-graph of the sentence to also extract the                Table 4: Evaluation in terms of CSA variables
verb which appears in the path linking the concept and fea-
ture terms in the sentence, which is not possible in a purely        Evaluation in terms of conceptual structure
co-occurrence-based model.
   The results for the unfiltered model using the Wiki110K           Of particular interest to distributed, feature-based theories of
corpus give the maximum recall achieved by our method;               conceptual knowledge is how relationships which exist be-
81% of the features are extracted. Precision is low (because of      tween the features of concepts influence conceptual process-
the large number of features being extracted) although, as dis-      ing. Statistics capturing such relationships have proven useful
cussed above, we are less interested in precision, particularly      in testing theories of distributed semantic representation, in-
for the unfiltered model. For the results of the filtered feature    cluding the conceptual structure account (Randall et al., 2004;
sets, where all but the top 25% of features were discarded,          Tyler et al., 2000). Researchers have calculated several vari-
we see the benefit of reranking, with the reranked frequencies       ables from norm data which capture various aspects of the
yielding higher precision and recall scores than the method          structural organization of the semantic space (e.g. McRae et
using the unweighted extracted frequencies.                          al., 2005; Randall et al., 2004). Here, we propose a novel
   We also evaluated the extracted triples using the full rela-      method for evaluating feature extraction methods which is
tion + feature-head pair (i.e. both the feature and the relation     based on testing whether conceptual structure statistics cal-
verb have to be correct). Previous researchers have typically        culated from the extracted features exhibit similar qualities to
only compared extracted features to the feature-head term; to        those calculated on the McRae norms.
our knowledge our work is the first to try and compare ex-              Various kinds of conceptual structure variables can be cal-
tracted features to the full relation + feature norm. Unsurpris-     culated. The simplest is the number of features in the con-
ingly, this reduces recall and precision compared to the case        cept (i.e. the number of features with non-zero production
where only the feature-head terms need match. For example,           frequency). Features can also be distinguished by whether
for the Wiki110K corpus recall falls from 69% to 35% for             they are shared or distinctive. Highly shared features occur
the filtered re-ranked model. However, given that we impose          in many concepts (e.g. has legs); highly distinctive features
no constraints on what the relation verb can be and that we          occur in few concepts (e.g. has an udder). The reciprocal
do not have expanded synonym sets for verbs it is actually           of the number of concepts that a feature occurs in is a mea-
impressive that the verb agrees with what is in the recoded          sure of the feature’s distinctiveness (so a feature occurring in
norms about 50% of the time.                                         two concepts has distinctiveness of 0.5). In particular, a fea-
                                                                     ture is defined to be distinguishing if it occurs in one or two
Manual Evaluation Analysis                                           concepts and shared if it occurs in more than two concepts.
Inspection of the extracted triples reveals that some of them        For each concept, we can then define the mean distinctive-
are correct although they do not appear in the gold standard         ness of its features, the number of shared and distinguishing
norms. One motivation for developing NLP technology for              features it has, and the proportion of shared features. We can
feature extraction is the need to enrich existing models of          also define a measure of the strength of interconnection be-
conceptual representation with novel features. To evaluate the       tween a pair of features. For example, has eyes and has ears
method’s ability to learn this type of novel data, 10 concepts       co-occur together in concepts more often than do the features
were selected at random from among the McRae concepts                is gray and has teeth. The correlation strength for a pair of
and the top 20 extracted triples not present in the norms were       features is calculated as the Pearson correlation of their pro-
selected. Two judges evaluated whether these were genuine            duction frequencies across concepts. We can then calculate
errors or valid data missing from the norms. The judges rated        the mean correlational strength of a concept’s constituent fea-
each “erroneous” triple as correct, plausible, wrong, or wrong       tures (using only the shared features; see Cree et al., 2006;
but related. The judges worked first independently and then          Taylor et al., 2008).We therefore define a total of six concep-
discussed the results to reach consensus. Across the 10 con-         tual structure variables, summarized in Table 4.
cepts, 23% and 26% of the relation+feature pairs were con-              The results show a significant correlation between the
sidered correct and plausible respectively, indicating roughly       norms and the extracted triples for five of the six conceptual
half of the errors were not true errors but potentially valid        structure variables. This is important as it indicates that the
triples missing from the norms. This demonstrates the poten-         semantic representations generated from the extracted fea-
tial of NLP methods in enriching existing models of concep-          tures are capturing some aspects of the conceptual structure
tual representation.                                                 that is present in the norms. However, the correlations are
                                                                  53

quite weak, and we do not see expected differences between                                     References
living and non-living domains that are observed in the McRae          Almuhareb, A., & Poesio, M. (2005). Concept learning and
norms. What we wish to highlight here is the potential use-             categorization from the web. In Proceedings of the 27th
fulness of conceptual structure statistics as a means for evalu-        Annual Meeting of the Cognitive Science Society (pp. 103–
ating models: improvements to the extraction method should              108).
yield better quality conceptual structure statistics.                 Barbu, E. (2008). Combining methods to learn feature-norm-
                                                                        like concept descriptions. In Proceedings of the ESSLLI
                         Discussion                                     Workshop on Distributional Lexical Semantics (pp. 9–16).
The feature acquisition method that we have presented above           Baroni, M., Evert, S., & Lenci, A. (Eds.). (2008). ESSLLI
aims to extract semantically unconstrained concept-relation-            2008 Workshop on Distributional Lexical Semantics.
feature triples from corpus data. High accuracy extraction of         Baroni, M., Murphy, B., Barbu, E., & Poesio, M. (2009).
such general representations from corpora is unrealistic given          Strudel: A corpus-based semantic model based on proper-
the state of the art. The main goal of our experiment was to            ties and types. Cognitive Science, 1–33.
investigate issues in both methodology and evaluation which           Briscoe, E., Carroll, J., & Watson, R. (2006). The second
need to be addressed when aiming towards higher accuracy                release of the RASP system. In Proceedings of the Interac-
feature extraction in the future. In particular, we examined            tive Demo Session of COLING/ACL-06 (pp. 77–80).
the usefulness of three types of knowledge for guiding feature        Chodorow, M. S., Byrd, R. J., & Heidorn, G. E. (1985). Ex-
extraction: encyclopedic, syntactic, and lexical-semantic. We           tracting semantic hierarchies from a large on-line dictio-
have also compared different approaches to evaluation: direct           nary. In Proceedings of the 23rd Annual Meeting of the
evaluation against existing norms, qualitative analysis, and            Association for Computational Linguistics (pp. 299–304).
evaluation against conceptual structure variables.                    Cree, G. S., McNorgan, C., & McRae, K. (2006). Distinctive
   Our extraction method performs better than the co-                   features hold a privileged status in the computation of word
occurrence-based baseline, demonstrating the benefits of                meaning: Implications for theories of semantic memory.
using syntactic information for feature extraction. Using               Journal of Experimental Psychology. Learning, Memory,
GRs also allows us to extract a relation verb for each                  and Cognition, 32(4), 643–58.
concept-feature pair, which is not possible using a purely co-        Gabrilovich, E., & Markovitch, S. (2007). Computing se-
occurrence-based approach like the SVD baseline. Perfor-                mantic relatedness using Wikipedia-based explicit seman-
mance was improved further by using semantic constraints                tic analysis. In Proceedings of IJCAI’07 (pp. 1606–1611).
calculated from the concept and feature clusters: the re-             Grondin, R., Lupker, S. J., & McRae, K. (2009). Shared fea-
weighting of features based on distributional data increased            tures dominate semantic richness effects for concrete con-
the rank of higher-quality features.                                    cepts. Journal of Memory and Language, 60(1), 1–19.
   Our paper highlights the difficulties inherent in evaluating       Lin, D. (1998). An information-theoretic definition of simi-
the quality of extracted features. Evaluation that tests against        larity. In Proceedings of ICML’98 (p. 296-304).
existing property norms is problematic, since participants in         McRae, K., Cree, G. S., Seidenberg, M. S., & McNorgan, C.
property norming studies list features in unsystematic ways.            (2005). Semantic feature production norms for a large set
Furthermore, as property norms are created by normalizing               of living and nonliving things. Behavior Research Meth-
participants’ responses to a set of feature labels, direct lexical      ods, 37, 547–559.
comparison with property norms is not necessarily meaning-            Murphy, G. (2002). The big book of concepts. Cambridge,
ful. Although the ESSLLI sub-set of the norms which ex-                 MA: The MIT Press.
pands the set of features in the norms with their synonyms            Randall, B., Moss, H. E., Rodd, J. M., Greer, M., & Tyler,
goes some way towards addressing the latter issue, the for-             L. K. (2004). Distinctiveness and correlation in conceptual
mer issue remains: norms are not complete in the sense that             structure: Behavioral and computational studies. Journal
there are true features which are not included in the norms.            of Experimental Psychology: Learning, Memory & Cogni-
   We therefore considered other forms of evaluation. Our               tion, 30(2), 393–406.
qualitative analysis shows that about 50% of the errors against       Taylor, K. I., Salamoura, A., Randall, B., Moss, H., & Tyler,
the recoded norms are in fact correct or plausible features.            L. K. (2008). Clarifying the nature of the distinctiveness
Our novel evaluation in terms of the conceptual structure               by domain interaction in conceptual structure: comment
variables acts as a valuable task-based evaluation that avoids          on cree, McNorgan, and McRae (2006). Journal of Ex-
direct comparison with the norms, and instead compares                  perimental Psychology: Learning, Memory & Cognition,
higher-level structural properties of concepts. Future work             34(3), 719–725.
can aim for larger-scale qualitative evaluation using multiple        Tyler, L. K., Moss, H. E., Durrant-Peatfield, M. R., & Levy,
judges as well as investigate other task-based evaluations.             J. P. (2000). Conceptual structure and the structure of con-
                                                                        cepts: A distributed account of category-specific deficits.
                     Acknowledgments
                                                                        Brain and Language, 75(2), 195–231.
This research was supported by EPSRC grant EP/F030061/1.
We thank McRae et al. for making their norms available.
                                                                   54

