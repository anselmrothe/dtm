UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Eye Movements During Mental Imagery are Not Reenactments of Perception

Permalink
https://escholarship.org/uc/item/3bb802qj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Johansson, Roger
Holsanova, Jana
Holmqvist, Kenneth

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Eye Movements During Mental Imagery are Not Reenactments of Perception
Roger Johansson (Roger.Johansson@ling.lu.se)
Department of Cognitive Science, Lund University
Kungshuset, Lundagård, 222 22, Lund, Sweden

Jana Holsanova (Jana.Holsanova@lucs.lu.se)
Department of Cognitive Science, Lund University
Kungshuset, Lundagård, 222 22, Lund, Sweden

Kenneth Holmqvist (Kenneth.Holmqvist@humlab.lu.se)
Humanities Laboratory, Lund University
Box 201, 221 00, Lund, Sweden

play an important role in visual imagery and in the
construction of mental models. However, what role these
eye movements have, and why they appear, are issues of
debate (cf., Johansson et al., 2006; Ferreira, Apel, &
Henderson, 2009; Richardson, Altmann, Spivey & Hoover,
2009).
Hebb (1968) suggested a functional role for eye
movements during mental imagery, and proposed that they
are necessary to assemble and organize “part images” into a
whole visualized image. This functional view has gained
strong support from a study by Laeng and Teodorescu
(2002). In their study participants inspected visual stimuli of
two kinds: 6×6 grid patterns with 5 black filled cells or a
small fish in various locations on the screen. One group was
instructed to maintain fixation onto the screen’s center and
another group was free to inspect the stimuli. In a
subsequent imagery phase, both groups were instructed to
‘build a visual image of the figure’ they had just seen and
were then allowed to move their eyes freely while looking at
a blank screen. The results revealed that those who
maintained their gaze centrally in the perception phase did
the same, spontaneously, during the imagery phase, while
those who inspected the original stimuli freely had eye
movements during the imagery phase which, to a high
degree, resembled those in the perception phase. Laeng and
Teodorescu (2002) argued that this implied eye movements
are stored along with a visual representation of the scene,
and are used as spatial indexes to properly arrange the parts
of a mental image. They concluded that eye movements
during mental imagery are re-enactments of perception and
have a necessary and functional role in “constructing” the
mental image. However, the question can be raised whether
the instruction to ‘build a visual image’, in combination
with the relatively simple stimuli, might necessarily lead to
spatial scanning of the mental image.
As discussed in Johansson et al. (2006), the task and the
complexity of the stimuli are important when the scene is
recalled during mental imagery. For instance, it is possible
that the mental image is only covertly scanned or is not
scanned at all. Thomas and Lleras (2009) have shown that
shifts in covert attention can produce identical results in a

Abstract
In this study eye movements were recorded for participants
under three different conditions. All three conditions
consisted of a perception phase and a mental imagery phase.
The imagery phase was similar for all conditions: i.e.,
participants looked freely at a blank white screen. The
perception phase was different for each condition. In the
control condition, participants looked freely at a complex
picture. In the first experimental condition, they looked at
another complex picture but maintained fixation at the center
of the picture. In the second experimental condition, they
maintained central fixation while listening to a verbal scene
description. The results revealed that despite central fixation
during the perception phase under the two experimental
conditions, participants’ eye movements were spread out
during the imagery phase, reflecting the spatial positions and
directions within the picture or scene. These results contradict
the theory that eye movements during mental imagery are reenactments of perception.
Keywords: Eye movements, mental imagery, spatial
cognition, visual attention, scene description.

Introduction
Since the late Nineties, several eye-tracking studies have
reported that spontaneous eye movements occur with mental
imagery and that these eye movements closely reflect the
content and spatial relations from an original picture or
scene (e.g., Brandt & Stark, 1997; Holsanova, Hedberg &
Nilsson, 1998; Laeng & Teodorescu, 2002; Gbadamosi &
Zangemeister, 2001; Altmann, 2004; Johansson, Holsanova
& Holmqvist, 2006; Humphrey & Underwood, 2008). A
similar effect has been found for spatial relations and scenes
that are verbally described (e.g., Demerais & Cohen, 1998;
Spivey, Tyler, Richardson, & Young, 2000; Spivey & Geng,
2001; Johansson et al, 2006). It has further been shown that
this effect is equally strong irrespective of whether the
original elicitation was visual or verbal (Johansson et al.,
2006). Additionally, an eye movement effect of this kind
has also been found during problem-solving tasks (e.g.,
Yoon & Narayanan, 2004; Freksa & Bertel, 2007) as well as
with visual motor imagery (Heremans, Helsen & Feys,
2007; Gueugneau, Crognier & Papaxanthis, 2008). From
this large body of research, it appears that eye movements
1

1968

seconds long). An English translation of the scene
description follows:

problem-solving task to overt eye movements. It is however
less likely that shifts in covert attention, or lack of scanning
altogether, would be sufficient when recalling scenes that
are rich in detail and contain many objects: i.e., visualizing
highly complex scenes would increase the cognitive load
such that more internal operations would be needed to
construct the parts of the image and then tie them together
and place them into a context.
The purpose of the present study is to investigate whether
Laeng and Teodorescus’ (2002) ‘central gaze effect’ occurs
even for visual scenes of high complexity. To ensure that
spatial scanning is actually employed, the experimental
design and method from Johansson et al. (2006) was used.
In this method the imagery task is to orally describe the
scene from memory, which introduces a great need for
spatial scanning. Additionally, by including two types of
stimuli – visual scenes and verbal descriptions – we can
investigate mental imagery for scenes that have never been
seen in the first place.

“In the center, right in front of me, I see a large, green spruce. At
the top of the spruce, a bird is sitting. To the left of the spruce – to
the far left – there is a yellow house with a black tin roof and with
white corners. The house has a chimney on which a bird is sitting.
To the right of the large spruce – to the far right – there is a tree
as high as the spruce. The leaves of the tree are colored yellow and
red. Above the tree a bird is flying. Between the spruce and the
tree is a man in blue overalls, raking leaves. Below the spruce, the
house, the tree and the man, i.e. in front of them there is a long red
fence, which runs all the way from left to right. At the left end, a
bike is leaning against the fence. Just to the right of the bike is a
yellow mailbox. On top of the mailbox, a cat is sleeping. Below the
fence, i.e. in front of and along the fence, a road leads from the left
side to the right side. On the road, to the right of the mailbox and
the bike, a black-haired girl is bouncing a ball. To the right of the
girl, a boy in a red cap is sitting and watching her. To the far right
along the road, a lady in a big red hat is walking with some books
under her arm. Just to the left of her, on the road, a bird is eating a
worm.”

Experiment
Procedure

The experiment consisted of three conditions: a control
condition, a fixed-picture condition and a fixed-verbal
condition. All three conditions consisted of a perception
phase and a mental imagery phase. The imagery phase was
similar for all conditions: i.e., participants looked freely at a
blank white screen. The perception phase was different for
each condition. In the control condition, participants looked
freely at a complex picture. In the fixed-picture condition,
they looked at another complex picture but were instructed
to maintain fixation at the center of the picture. In the fixedverbal condition, they were instructed to maintain central
fixation while listening to a verbal description of a scene.

Participants were told that the experiment concerned pupil
dilation in relation to mental workload. It was explained that
we would be filming their eyes, but nothing was said about
us recording their eye movements. They were asked to keep
their eyes wide open so that we could film their pupils, and
to look directly ahead so that our equipment could
accurately measure their pupil dilation. The eye tracker was
calibrated using a five-point calibration procedure with
validation. (This is the default setting in Experiment Center
2.4). Participants’ eye movements were recorded during
both the perception and imagery phase under all three
conditions.
In the control condition, a picture was shown for thirty
seconds. Then the screen went blank, and participants were
asked to describe the picture in their own words. They were
told explicitly to keep their eyes wide open and to look
directly ahead so that the equipment could record their pupil
dilation. Figure 1 shows the schematics of the control
condition.

Participants
Twenty students at the University of Lund – ten females and
ten males – participated in the experiment. All subjects
reported either normal vision or vision corrected to normal
(i.e., with contact lenses or glasses). All participants were
native Swedish speakers. The mean age of the participants
was 21.4 years (SD = 1.9).

Apparatus and stimuli
The participants were seated in front of a computer screen at
a distance of 600-700 mm. (The distance varied slightly
because of the subjects’ freedom to move their head and
body.) The eye tracker used was the SMI iView RED250,
which has a sampling frequency of 250 Hz and a precision
of 0.02°. The data was recorded with the iView X 2.4
software. The eye-tracking data was analyzed with BeGaze
2.4 and in-house MatLab programs.
The visual stimulus in the experiment was presented using
Experiment Center 2.4 on a 480 mm. x 300 mm. computer
screen with a resolution of 1680 × 1050 pixels. The auditory
stimulus was a pre-recorded description (one minute and 38

Perception phase: Free viewing

Imagery phase: Free viewing

Picture viewing (30 sec.)

Verbal description

Figure 1: Control condition
In the fixed-picture condition, participants were instructed to
maintain fixation on a cross in the center of the screen until
2

1969

i.e., their eye movements should have similar spatial
dispersion as during the perception phase and therefore not
correspond to directions and positions from the imagined
scene. To test this, we chose to analyze eye movements in
two regards. First, the overall spatial dispersion of the eye
movements was considered. However, spatial dispersion
does not give any information about how eye movements
correspond to directions and positions in a mental image.
Also, it is common that participants “shrink” their mental
image and only look at a limited part of the screen during
imagery (Gbadamosi & Zangemeister, 2001; Johansson et
al., 2006). Therefore, as a second step, a method combining
eye movement data and verbal data (cf., Holsanova, 2008)
was used.
To analyze the overall spatial dispersion of the eyetracking data, a modified version of the coverage measure
proposed by Wooding (2002) was calculated for each phase
(perception/mental imagery) and condition. An "attention
map" was created by centering a Gaussian function (σ =
0.1W, W = 1680 pixels) at each fixation point and then
superimposing all the other functions. The volume under the
attention map, after being normalized to unit height, was
then used to estimate the spatial dispersion of the eyetracking data. Within-subject ANOVAs were done to
analyze the spatial dispersion between the perception and
imagery phases in each condition, as well as between
conditions for the imagery phase.
To analyze whether eye movements corresponded to
directions and positions from the verbal descriptions and
retellings, the method developed and described in Johansson
et al. (2006) were used. Since it is possible that participants
can make use of either the whole screen or only a part of it
in imagining the scene, one cannot simply take physical
coordinates on the computer screen as one’s areas of
interest. Instead, this method uses the relative position of an
eye movement compared to each participant’s individual
gaze pattern over the entire description or retelling. Eye
movements are then scored as correct or incorrect according
to either global correspondence or local correspondence
coding. The spatial criteria for an eye movement to be
considered correct in global correspondence coding is
defined as when an eye movement shifts from one object to
another it must finish in a position that is spatially correct
relative to the participant’s gaze pattern over the entire
description or retelling. The spatial criteria for local
correspondence is defined as when an eye movement shifts
from one object to another during the description or the
retelling it must move in the correct direction (up, down, left
or right). The minimum threshold for the saccadic amplitude
to be considered an actual movement from one object to
another was set at 35 pixels (10 mm on the screen). In
addition to these spatial criteria, we used the temporal
criteria from Johansson et al. (2006), where an eye
movement from one position to another must appear within
five seconds before or after an object is mentioned.
The key difference between global and local
correspondence is that global correspondence requires

it disappeared. The cross was first shown for five seconds,
after which a picture appeared behind it for an additional
thirty seconds. Then the screen went blank, and participants
were asked to describe the picture in their own words. They
were told explicitly to keep their eyes wide open and to look
directly ahead so that the equipment could record their pupil
dilation. Figure 2 shows the schematics of the fixed-picture
condition.

Perception phase: Central fixation

Imagery phase: Free viewing

Picture viewing (30 sec.)

Verbal description

Figure 2: Fixed-picture condition
In the fixed-verbal condition, participants were likewise
instructed to maintain fixation on a cross in the center of the
screen until it disappeared. The cross appeared in an
otherwise blank screen while a pre-recorded scene
description was played from speakers in front of the
participants for 1:38 minutes. Then the cross disappeared.
Participants were asked to retell the scene. They were told
that they could retell it in their own words and did not have
to follow the same order. Participants were told explicitly to
keep their eyes wide open and to look directly ahead so that
the equipment could record their pupil dilation. Figure 3
shows the schematics of the fixed-verbal condition.

Perception phase: Central fixation

Imagery phase: Free viewing

Listening to scene descr. (1.38 min)

Verbal retelling

Figure 3: Fixed-verbal condition
Afterwards, to assess whether any of the participants had
seen through the nature of the experiment, we asked what
they thought the true objective of the experiment was.

Analysis
If Laeng and Teodorescus’ (2002) conclusion – that eye
movements during imagery functionally reenact those of
perception – is supported then participants’ eye movements
should remain centrally fixated during the imagery phase for
the fixed-picture condition and the fixed-verbal condition:
3

1970

under each condition is presented in Table 1. Consistent
with the results from Johansson et al. (2006) the control
condition generated a high proportion of correct eye
movements, both by local and global correspondence.
However, also the central gaze conditions generated a high
degree of correct eye movements in the local
correspondence coding as well as a certain degree of correct
eye movements in the global correspondence coding. Except
for the eye movements in global correspondence coding in
the fixed-picture-condition the results were significantly
above chance (p < 0.001).
The comparison of correct eye movements by global and
local correspondence coding in the imagery phase between
the three conditions revealed a significant main effect for
global correspondence coding (F(2,38) = 5.544, p = 0.008)
but not for local correspondence coding. Bonferroni posthoc tests revealed that there were significantly more correct
eye movements (for global correspondence coding) under
the control condition than under the fixed-picture condition
(p = 0.03). No significant difference was found between the
other conditions.

fixations to take place at the categorically correct spatial
position relative to the whole gaze pattern, whereas local
correspondence only requires that the eyes move in the
correct direction between two consecutively mentioned
objects. Eye movements are considered incorrect when
neither the local correspondence nor the global
correspondence criteria are met: e.g., when the eyes move
with amplitudes below the 35-pixel threshold or in the
wrong direction.
As a consequence of applying these spatial criteria a
binomial distribution in the data is obtained: the spatial
relations are either correct or incorrect. The possibility that a
participant would move his or her eyes to the correct
position by chance was then defined. For global
correspondence coding, both the direction and the distance
of the movement must be correct. Many movements are
possible. In this study a conservative estimate was chosen,
whereby the eyes could move in at least four directions (up,
down, left, and right) to at least two locations (full and half
distance). In addition to these eight possibilities, the eye
might stand still (or move with an amplitude below the 35pixel threshold). For global correspondence, the probability
that the eyes moved to the correct position at the correct
time by chance is thus definitely less than one in nine
(11%). For local correspondence coding, which requires
only correct direction, the corresponding probability is one
in five (20%). The data could then be analyzed using a
Wilcoxon signed-rank test for significance between the total
number of correct eye movements and the expected number
of correct movements made by chance.
Finally, to compare the proportion of correct eye
movements in global and local correspondence coding
between the three conditions a within-subjects ANOVA was
used.

Table 1: Percentages of objects with correct eye movements
in the imagery phase for all three conditions by both local
and global correspondence coding.

Global
Local

Control
55.8 %
81.6 %

Fixed-Picture
26.5 %
73.6 %

Fixed-Verbal
34.5 %
60.0 %

These results reveal that spatial dispersion of the eye
movements was significantly larger in the imagery phase
than in the perception phase under the two central gaze
conditions, and that there was a significant degree of correct
eye movements under the two central gaze conditions;
especially for local correspondence coding. However, the
results also showed that spatial dispersion was smaller in the
imagery phase under the two central gaze conditions than
under the control condition.
Figures 4-6 show scanpaths in both the perception and
imagery phase for one and the same participant. Figure 4
shows that in the control condition this participant used a lot
of the computer screen during imagery and her eye
movements had a large spatial dispersion. Positions and
directions for the eye movements corresponded to a high
degree with described elements of the picture. Figure 5
shows that in the fixed-picture condition this participant had
a large number of fixations in the center of the screen during
the mental phase but also executed eye movements away
from the center, resulting in a larger spatial dispersion than
during the perception phase, and eye movements that
spatially corresponded to what was described. For example,
the eye movements to the far left were executed when the
flowers to the far left of the picture were described. It is
clear that during the perception phase, the participant looked
at the central cross the entire time and never shifted to the
flowers. Figure 6 shows that in the fixed-verbal condition

Results and discussion
None of the participants saw through to the true objective of
the experiment and data from all participants could be
included in the results.
The comparison of spatial dispersion between the
perception and imagery phases revealed a significantly
larger spatial dispersion in the imagery phase under the
fixed-picture condition (F(1,19) = 29.429, p < 0.001) and
the fixed-verbal condition (F(1,19) = 32.934, p < 0.001).
The results for the control condition were the opposite: i.e.,
spatial dispersion was significantly larger in the perception
phase (F(1,19) = 114.553, p < 0.001). The comparison of
spatial dispersion in the imagery phase between conditions
revealed a significant main effect (F(2,38) = 8.175, p =
0.002). Bonferroni post-hoc tests revealed that spatial
dispersion was significantly larger for the control condition
than for either the fixed-picture condition (p = 0.01) or the
fixed-verbal condition (p = 0.02). No significant difference
was found between the fixed-picture and the fixed-verbal
condition.
The average proportion for all participants of correct eye
movements by local and global correspondence coding
4

1971

phase to some degree did affect eye movements during
imagery. We do, however, propose that this is an effect of
the limitation of not being able to move the eyes during
perception rather than a support for Laeng and Teodorescus’
(2002) functional view. For example, under the fixedpicture condition most of the picture was only seen
peripherally and participants were not able to describe as
many objects (mean: 4.1) as in the control condition (mean:
7.6) and the description focused to a high degree on picture
elements that were in focus during perception (the tree and
the bird’s nest). For the fixed-verbal condition we propose a
similar explanation. Since the participants could not move
their eyes when they listened to the scene description it was
harder for them to form a mental image of the scene and less
objects and spatial relations among them were remembered
when the scene was recalled.
If eye movements during imagery are not reenactments of
perception would this mean that they do not have a
functional and necessary role for the construction of mental
images? There has been a vibrant debate recently whether
‘looking at nothing’ can facilitate memory retrieval of visual
scenes and what role internal depictive image
representations have in this process (Ferreira, Apel, &
Henderson, 2008; Richardson, Altmann, Spivey, & Hoover,
2009). Nevertheless, in this debate, eye movements to
regions of a blank screen are interpreted in relation to a
previous perception phase: i.e., again eye movements during
mental imagery were seen as reenactments of perception.
We propose that this is the wrong approach. Johansson et al.
(2006) showed that participants who listened to a scene
description while looking at a blank screen spontaneously
performed eye movements that closely corresponded to
spatial positions and directions from their visualizations of
the scene. In this case, there was no previous perception
phase that the eye movements could be reenacting. Another
big problem for the ‘reenactment approach’ is that eye
movements during imagery are idiosyncratic. For example,
participants frequently “shrink” their mental image, and
only look at a limited part of the screen when visualizing a
previously seen picture that covered the entire screen
(Gbadamosi & Zangemeister, 2001; Johansson et al., 2006).
The results from the current study together with these
previous findings strongly show that the phenomenon of eye
movements during mental imagery is more complex than a
mere reenactment of a perceptual phase. Therefore, to
conclude that eye movements are necessary and functionally
connected with the construction of a mental image is too
strong of an assumption. A better approach might be to see
them as a support that can relieve working memory load
during imagery. If this is right, they become more likely to
appear when a difficult imagery task is performed. This
could explain why the results in this paper differ from those
of Laeng and Teodorescu (2002). It is a much harder task to
visualize and verbally describe a complex picture or scene
description than to ‘build an image’ of the much simpler
stimuli used in their study. Another possible interpretation
comes from various versions of simulation theory (e.g.

this participant executed a lot of eye movements across a
large extent of the screen during the imagery phase,
resulting in a larger spatial dispersion than during the
perception phase, and eye movements that spatially
corresponded to the described scene. For example, the eye
movements to the left in this figure were executed when the
house, the bike and the mailbox were mentioned, and the
eye movements to the far right were executed when the
second tree and the lady on the road were mentioned.

Figure 4: Control condition
(left: perception phase, right: imagery phase)

Figure 5: Fixed-picture condition
(left: perception phase, right: imagery phase)

Figure 6: Fixed-verbal condition
(left: perception phase, right: imagery phase)

General discussion
The results show that despite maintaining central fixation
during visual perception of either a complex picture or a
verbal scene description, eye movements spread out and to a
high degree correspond to spatial positions and directions
during mental imagery of the picture or scene. These results
contradict Laeng and Teodorescus’ (2002) conclusion that
eye movements during visual imagery reenact those of
perception of the same scene. Nevertheless, it was also
revealed that eye movements were less spread out during
imagery under the two central gaze conditions than under
the control condition and the proportion of correct eye
movements was by global correspondence coding
significantly lower (and not significantly above chance) for
the fixed-picture condition than for the control condition.
Therefore, it seems that central gazing in the perception
5

1972

Hebb, D. O. (1968). Concerning imagery. Psychological
Review, 75, 466-477.
Heremans, E., Helsen, W. F., & Feys, P. (2008). The eyes as
a mirror of our thoughts: quantification of motor imagery
through eye movement registration, Behavioural Brain
Research, 187(2), 351–360.
Hesslow, G. (2002). Conscious Thought as Simulation of
Behaviour and Perception. Trends in Cognitive Science, 6,
pp. 242-247.
Holsanova, J., Hedberg, B., & Nilsson, N. (1998). Visual
and Verbal Focus Patterns when Describing Pictures. In
Becker, Deubel & Mergner (Eds.), Current Oculomotor
Research: Physiological and Psychological Aspects.
Plenum: New York, London, Moscow.
Holsanova, J. (2008). Discourse, vision, and cognition.
Human Cognitive Processes 23. John Benjamins
Publishing Company: Amsterdam/Philadelphia.
Humphrey, K., & Underwood, G. (2008). Fixation
sequences in imagery and in recognition during the
processing of pictures of real-world scenes. Journal of
Eye Movement Research, 2(2):3, 1-15.
Johansson, R., Holsanova, J., & Holmqvist, K. (2006).
Pictures and spoken descriptions elicit similar eye
movements during mental imagery, both in light and in
complete darkness. Cognitive Science, 30:6, 1053-1079.
Laeng, B., & Teodorescu, D.-S. (2002). Eye scanpaths
during visual imagery reenact those of perception of the
same visual scene. Cognitive Science, 26, 207-231.
Richardson, D. C., Altmann, G. T. M., Spivey, M. J., &
Hoover, M. A. (2009). Much ado about eye movements to
nothing: a response to Ferreira et al.,: Taking a new look
at looking at nothing, Trends in Cognitive Science, 13(6),
235-236.
Spivey, M., & Geng, J. (2001). Oculomotor mechanisms
activated by imagery and memory: eye movements to
absent objects, Psychological Research, 65, 235-241.
Spivey, M., Tyler, M., Richardson, D., & Young, E. (2000).
Eye movements during comprehension of spoken scene
descriptions. Proceedings of the 22nd Annual Conference
of the Cognitive Science Society (pp. 487-492). Mahwah,
NJ: Lawrence Erlbaum Associates, Inc.
Thomas, N. J. T. (1999). Are Theories of Imagery Theories
of Imagination? An Active Perception Approach to
Conscious Mental Content. Cognitive Science, vol. 23 (2).
Thomas, L. E., & Lleras, A. (2009). Covert shifts of
attention function as an implicit aid to insight. Cognition,
111, 168-174.
Wooding, D. S. (2002). Fixation maps: quantifying eyemovement traces. Proceedings of the 2002 symposium on
Eye tracking research & applications, New Orleans,
Louisiana.
Yoon, D., & Narayanan, N. H. (2004). Mental imagery in
problem solving: An eye tracking study. Proceedings of
the Third ACM Symposium on Eye Tracking Research &
Applications, Association for Computing Machinery,
ACM Press pp. 77-83.

Hesslow, 2002; Thomas, 1999), where eye movements
during imagery do not have a direct and necessary link to
eye movements from a perception phase. For example, the
perceptual activity theory (Thomas, 1999) states that
imagery is the reenactment of a perceptual behavior that
would be appropriate for exploring the imagined scene as if
it were actually present. Eye movements would therefore be
likely to appear independently of how they were executed in
perception.
Nevertheless, to explain the complex interplay between
eye movements and mental imagery fully, further studies
need to be performed: e.g., to investigate whether memory
retrieval is enhanced by eye movements to blank areas of a
screen and how individual differences in spatial cognition
and working memory capacity are related to these
movements.

Summary
This study showed that despite maintaining central fixation,
either while looking at a complex picture or listening to a
scene description, participants’ eye movements spread out
and did correspond to directions and positions during mental
imagery of the picture or the scene. Laeng and Teodorescus’
(2002) conclusion that eye movements during imagery
reenact those of perception was therefore not supported.

Acknowledgements
This research was funded by the Swedish Research Council
(Vetenskapsrådet 2007–2637) and by a Fellowship at Hanse
Wissenschaftskolleg Delmenhorst. Special thanks to Marcus
Nyström for programming the MatLab algorithms.

References
Altmann, G. T. M. (2004). Language-mediated eye
movements in the absence of a visual world: the 'blank
screen paradigm’. Cognition, 93 (2): B79-B87.
Brandt, S. A., & Stark, L. W. (1997). Spontaneous eye
movements during visual imagery reflect the content of
the visual scene. Journal of Cognitive Neuroscience, 9,
27–38.
Demarais, A., & Cohen, B.H. (1998). Evidence for imagescanning eye movements during transitive inference.
Biological Psychology, 49, 229-247.
Ferreira, F. Apel, A., & Henderson, J. M. (2008). Taking a
new look at looking at nothing. Trends in Cognitive
Science, 12(11), 405-410.
Freksa, C., & Bertel, S. (2007). Eye movements and smart
technology. Computers in Biology and Medicine, 37, 983
– 988.
Gbadamosi, J., & Zangemeister, W. H. (2001). Visual
imagery in hemianopic patients, Journal of Cognitive
Neuroscience. 13 (7), 45–56.
Gueugneau, N., Crognier, L., & Papaxanthis, C. (2008). The
influence of eye movements on the temporal features of
executed and imagined arm movements. Brain Research,
1187, 95–102.
6

1973

