UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Proposing Artificial Subtle Expressions as an Intuitive Notification Methodology for Artificial
Agents' Internal States
Permalink
https://escholarship.org/uc/item/9xj064xt
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Komatsu, Takanori
Yamada, Seiji
Kobayashi, Kazuki
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                       University of California

                                          Proposing Artificial Subtle Expressions
        as an Intuitive Notification Methodology for Artificial Agents’ Internal States
                                           Takanori Komatsu (tkomat@shinshu-u.ac.jp)
                                International Young Researcher Empowerment Center, Shinshu University,
                                                   3-15-1 Tokida, Ueda 386-8567, Japan
                                                     Seiji Yamada (seiji@nii.ac.jp)
                                                National Institute of Informatics/ SOKEDAI,
                                                2-1-2 Hitotsubashi, Tokyo 101-8430, Japan
                                            Kazuki Kobayashi (kby@cs.shinshu-u.ac.jp)
                                     Graduate School of Science and Technology, Shinshu University
                                                 4-17-1 Wakasato, Nagano 380-8553, Japan
        Kotaro Funakoshi (funakoshi@jp.honda-ri.com) and Mikio Nakano (nakano@jp.honda-ri.com)
                                                  Honda Research Institute Japan Co., Ltd,
                                                    8-1 Honcho, Wako 351-0188, Japan
                                 Abstract                                 Ward (2003) reported that the subtle flections of the pitch
   We describe artificial subtle expressions (ASEs) as an
                                                                          information in speech sounds reflect one’s emotional states
   intuitive notification methodology for artifacts’ internal states      even when contradicted by the literal meanings of the
   for users. We prepared two types of audio ASEs: one was a              speech sounds, and Cowell & Ayesh (2004) offered a
   flat artificial sound (flat ASE), and the other was a sound that       similar argument in terms of facial expressions.
   decreased in pitch (decreasing ASE). These two ASEs were                  It is therefore believed that such subtle expressions can be
   played after a robot made a suggestion to the users.                   utilized to help humans easily understand an artifact’s
   Specifically, we expected that the decreasing ASE would                internal state because humans can intuitively understand
   inform users of the robot’s lower level of confidence in its
   suggestion. We then conducted a simple experiment to                   such subtle expressions. For example, Sugiyama et al.
   observe whether the participants accepted or rejected the              (2006) developed a humanoid robot that can express
   robot’s suggestion based on the ASEs. The results showed               appropriate gestures based on a recognition of its situation,
   that they accepted the robot’s suggestion when the flat ASE            and Kipp & Gebhard (2008) developed a human-like avatar
   was used, whereas they rejected it when the decreasing ASE             agent that can control its gaze direction according to the
   was used. We thereby concluded that the ASEs succeeded in              user’s gaze direction. However, since these researchers tried
   conveying the robot’s internal state to users accurately and
                                                                          to implement subtle expressions on artifacts (e.g., humanoid
   intuitively.
                                                                          robots or dexterous avatar agents), it resulted in
   Keywords:         Artificial    subtle   expressions    (ASEs);        considerably high implementation costs.
   Complementary; Intuitive; Simple; Accurate.                               In contrast to the above approaches, Yamada & Komatsu
                                                                          (2006) and Komatsu & Yamada (2007) reported that simple
                            Introduction                                  beeping sounds from a robot with decreasing/increasing
   Although human communications are explicitly achieved                  frequency enabled humans to interpret the robot’s
through verbal utterances, paralinguistic information (e.g.,              negative/positive states. Funakoshi et al. (2008) also
pitch and power of utterances) and nonverbal information                  reported that the robot’s blinking LED could convey to
(e.g., facial expressions, gaze direction, and gestures) also             users a robot’s internal state (processing or busy) for the
play important roles (Kendon, 1994). This is because one’s                sake of reducing the occurrence of speech collisions during
internal state is deeply reflected in one’s paralinguistic and            their verbal conversations. It then seemed that such simple
nonverbal information. In other words, other people can                   expressions (beeping sounds or blinking LEDs) from
intuitively and easily understand a person’s internal state               artifacts could play a similar role to the subtle expressions
from such information when it is expressed (Cohen et al.,                 of humans, so we named these expressions in artifacts
1990). Recently, some researchers have reported that very                 “Artificial Subtle Expressions (ASEs),” referring to
small changes in the expression of such information, called               artifacts’ simple and low-cost expressions that enable
subtle expressions (Liu & Picard, 2003), significantly                    humans to estimate the artifacts’ internal state accurately
influence human communications, especially in the                         and intuitively. We stipulate that the ASEs should
conveyance of one’s internal state to others. For example,
                                                                      447

simultaneously meet two design and two functional
requirements.
   Specifically, the two design requirements are as follows:
z Simple: ASEs should be implemented on a single
      modality. This is expected to lower the implementation
      cost.
z     Complementary: ASEs should only have a
      complementary role in communication and should not
      interfere with communication’s main protocol. This
      means that the ASEs themselves do not have any
      meaning without a communication context.
   The two functional requirements are as follows:
z     Intuitive: ASEs should be understandable by humans
      who have no prior knowledge of the ASEs.
z     Accurate: ASEs should convey the designer’s
      intended meanings accurately. Specifically, ASEs
      should convey the internal states of the artifact just as
      subtle expressions do in nonverbal information by
      humans.
   In this study, we focused on audio ASEs. Related studies
with audio ASEs include those that proposed simple and
effective information to convey specific meaning to users,
e.g., “earcon (Blattner, 1989)” or “auditory icon (Gaver,
1989; Gaver, 1997)” These earcons and auditory icons play
an effective role in informing users of specific meanings as
communication’s main protocol, while ASEs play a
complementary role for the main protocol. This is the
significant difference between ASEs and earcons or auditory
icons.
   In this paper, we investigated whether the ASEs could
convey the artifacts’ internal state to the users accurately
and intuitively; specifically, we created audio ASEs that
were intended to meet the two design requirements and
investigated whether they also met the two functional
requirements by conducting a simple psychological
experiment.
                        Experiment
Setting                                                                        Figure 1: Treasure hunting video game.
   We used a “treasure hunting” video game as an
experimental environment to observe participants’ behavior            The position of the coin in the three hills was randomly
(Figure 1). In this game, a game image scrolls forward on a         assigned. In each trial, an artifact placed next to the
straight road, with small hills appearing along the way. A          participants told them in which position it expected the coin
coin is inside one of three hills, while the other two hills        to be placed. The artifact placed next to the participants was
have nothing. The game ends after the player encounters 20          the MindStorms robot (LEGO Corporation, see Figure 2).
sets of hills, and the approximate duration of this video           The robot told the participant the expected position of the
game is about three minutes. The purpose is to get as many          coin using its speech sounds. The participants could freely
coins as possible. In this experiment, the participant was          accept or reject the robots’ suggestions. In each trial, even
awarded 1 point for each coin that s/he found. The                  though the participants selected one hill from among three,
participants in this experiment were informed that 1 point          they did not know whether the selected hill had the coin or
was equivalent to 50 Japanese yen (about 50 US cents) and           not (actually, the selected hill just showed a question mark
that after the experiment they could use their points to            and a closed treasure box, as depicted in the center of Figure
purchase some stationery supplies (e.g., file holders or USB        1). The participants were informed of their total game points
flash memory) of equivalent value.                                  only after the experiment.
                                                                448

                                                                   the text-to-speech (TTS) function of “Document Talker
                                                                   (Create System Development Company).” Just 0.2 seconds
                                                                   after these speech sounds, one of the two simple artificial
                                                                   sounds was played as the ASE (Figure 3). These two ASEs
                                                                   were triangle wave sounds 0.5 seconds in duration, but their
                                                                   pitch contours were different (Figure 4); that is, one was a
                                                                   flat sound (onset F0: 400 Hz and end F0: 400 Hz, called
                                                                   “flat ASE”), and the other was a decreasing one (onset F0:
                                                                   400 Hz and end F0: 250 Hz, called “decreasing ASE”).
                                                                   These ASE sounds were created by “Cool Edit 2000 (Adobe
                                                                   Corporation).” Komatsu & Yamada (2007) reported that the
                                                                   decreasing artificial sounds expressed from the robot were
                                                                   interpreted as negative feelings by humans; therefore, we
                                                                   intended that the decreasing ASE would inform users of the
                                                                   robot’s lower confidence in the suggestions as the robot’s
                                                                   internal state.
                 Figure 2: MindStorms Robot.                          Here, the main protocol of the robot was to tell the
                                                                   expected position of the coin, while the ASE protocol was
                                                                   to indicate the robot’s confidence level in a complementary
Utilized ASEs                                                      manner. The two ASE sounds were created quite easily by
                                                                   simply editing the consumer software. Thus, the ASEs met
                                                                   the two design requirements, that is, simple and
                                                                   complementary. Therefore, to confirm whether the ASEs
                                                                   were able to convey the robot’s internal states to the users
                                                                   accurately and intuitively, we needed to investigate whether
                                                                   the utilized ASE met the two requirements for functioning,
                                                                   that is, being intuitive and accurate.
                                                                   Procedure
Figure 3: Speech sound “ni-ban (no.2)” and decreasing ASE.
                                                                                    Figure 5: Experimental setting.
                                                                      Nineteen Japanese university students (10 men and 9
                                                                   women; 22 – 25 years old) participated. The treasure
                                                                   hunting video game was projected on a 46-inch LCD in
                                                                   front of the participants, and the robot was placed in front of
 Figure 4: Flat and decreasing ASEs (duration: 0.5 second).        and to the right of the participants, with the distance
                                                                   between them being approximately 50 cm (see Figures 5
  We implemented the audio ASEs in the robot’s speech              and 6). The sound pressure of the robot’s speech sounds at
sounds. In this experiment, the robot expressed Japanese           the participants’ head level was set at about 50 dB (FAST,
artificial speech sounds to tell the expected position of the      A). The robot’s speech sounds with the ASEs were remotely
coin; that is, “ichi-ban (no. 1),” “ni-ban (no. 2),” and “san-     controlled by the experimenter in the next room using the
ban (no. 3).” These artificial speech sounds were created by       Wizard of Oz (WOZ) method. Before the experiment started,
                                                               449

the experimenter told the participant the setting and purpose       many of the robot’s suggestions the participants rejected for
of the game. However, the experimenter never mentioned or           10 flat ASEs and 10 decreasing ASEs. For all 19
explained the ASEs. Therefore, the participants had no              participants, the average rejection rate of the 10 flat ASEs
opportunity to acquire prior knowledge about the ASEs.              was 1.73 (SD=1.51), while the rejection rate of the 10
Among the 20 trials, the robots expressed the flat ASE 10           decreasing ASEs was 4.58 (SD=2.43, see Figure 7). These
times and the decreasing ASE 10 times. The order of                 rejection rates for the 10 flat ASEs and 10 decreasing ASEs
expression for these two types of ASEs was                          were analyzed using a one-way analysis of variance
counterbalanced across participants. Actually, the robot told       (ANOVA) (within-subjects design; independent variable:
the exact position of the coin in all 20 trials, but the            type of ASE, flat or decreasing, dependent variable:
participants did not know whether or not the robot was              rejection rate). The result of the ANOVA showed a
telling the right position because the participants were not        significant difference between the two groups
able to find out whether the selected hill had the coin or not.     (F(1,18)=13.38, p<.01, (**)); that is, the robot’s suggestions
If the participant actually knew whether or not the selected        with the decreasing ASE showed a significantly higher
hill had the coin just after their selections, they would have      rejection rate compared to those with the flat ASE.
associated the ASE with the robot’s performance, e.g.,              Therefore, the ASEs significantly affected the participants’
whether or not the robot pointed to the right position. Thus,       behavior, and we found evidence supporting our previously
this experimental setting, where the participants were not          mentioned assumption .The most interesting point was that
notified of whether the selected hill was correct or not, was       the ASEs affected the behavior of the participants without
intended to reduce such associations and to clarify the effect      their being informed of the meaning or even existence of the
of the ASEs on the participants’ behavior.                          ASEs.
                                                                            Figure 7: Rejection rate for all 19 participants.
                                                                      In the interview sessions, 5 out of the 19 participants said
                Figure 6: Experimental Scene
                                                                    that they immediately realized the meanings of the ASEs
                                                                    after the robot’s speech sounds and that they utilized these
   The purpose of this experiment was to observe the
                                                                    ASEs when it came to accepting or rejecting the robot’s
participants’ behavior as to whether they accepted or
                                                                    suggestions, e.g., “I felt that the decreasing artificial sounds
rejected the robot’s suggestions in terms of the types of
                                                                    meant that the robot had less confidence in its answer.”
ASEs used. We assumed that the participants would accept
                                                                    However, the remaining 14 participants said that they did
the robot’s suggestion when the flat ASE was added to the
                                                                    not notice the existence of the ASEs. Here, if there were
speech sounds while they would reject the suggestion when
                                                                    significant differences between flat and decreasing ASEs in
the decreasing ASE was used. If we could observe these
                                                                    their rejection rate, the ASEs were interpreted by these 14
phenomena, we could recognize that the utilized ASE had
                                                                    participants unconsciously. In this case, we strongly argue
succeeded in conveying the robot’s internal state to the
                                                                    that the ASEs were able to convey the robot’s internal state
participants accurately and intuitively; that is, the ASE had
                                                                    to the participants accurately and intuitively. For these 14
successfully met all four requirements. In addition, after the
                                                                    participants, the average rejection rate of 10 flat ASEs was
experiment, we conducted interviews to determine whether
                                                                    2.28 (SD=1.73), while the rejection rate of the 10 decreasing
or not the participants had noticed the ASEs and, if so, how
                                                                    ASEs was 3.43 (SD=1.59, see Figure 8). These rejection
they had interpreted them.
                                                                    rates were analyzed using a one-way ANOVA (within-
                                                                    subjects design; independent variable: ASE type, flat or
                                                                    decreasing, dependent variable: rejection rate). The result of
                           Results                                  the ANOVA showed a significant difference between them
   To investigate the effect of the ASEs on participants’           (F(1,13)=4.98, p<.05, (*)); that is, the robot’s suggestions
behavior, we calculated the rejection rate, indicating how
                                                                450

with the decreasing ASE had a significantly higher rejection        and the confidence level in interpreting the user’s
rate compared to those with a flat ASE, even though these           expressions. This consecutive study would also contribute to
participants did not notice the existence of the ASEs. To           expanding the applicability of ASEs to various interactive
sum up, the results of this experiment clearly show that the        situations.
utilized ASEs succeeded in conveying the robot’s internal
states to the participants accurately and intuitively; that is,     Advantage of utilizing ASEs
the ASEs succeeded in meeting all four requirements.                  It is said that the most significant advantage in utilizing
                                                                    ASEs is the lower implementation cost compared to
                                                                    utilizing human-like expressions. Therefore, it is expected
                                                                    that many applications in human-computer interaction or
                                                                    human-robot interaction will be able to include the ASEs
                                                                    quite easily. In addition to the lower cost, we believe that
                                                                    the advantage of utilizing ASEs includes the possibility of
                                                                    solving several problems such as those reported in the above
                                                                    research areas.
                                                                      So far, it has been strongly believed that most robots or
                                                                    on-screen agents required to interact with users should have
                                                                    a human-like appearance and produce human-like
                                                                    expressions. However, we feel that these research directions
                                                                    have had two difficulties; one is the implementation cost
                                                                    mentioned above, and the other is that users have
   Figure 8: Rejection rate for 14 participants who did not         unexpected attitudes or impressions toward human-like
                         notice ASEs.                               artifacts; i.e., artifacts having a human-like appearance have
                                                                    a higher possibility of diving them into the “uncanny
                                                                    valley” (Mori, 1970). Moreover, users are likely to
                         Discussion                                 overestimate the artifacts’ ability when it has a human-like
                                                                    appearance or expressions, so they would be disappointed if
Future Applications                                                 these artifacts were to demonstrate unpredictable or poor
  As a result of the experiment, we could confirm that the          behavior (Komatsu & Yamada, 2010).
robot’s suggestions with the decreasing ASEs showed a                 Therefore, our approach that the artifact should not
significantly higher rejection rate compared with those with        produce human-like expressions but artifact-like ones to
flat ASEs. Moreover, these ASEs were interpreted by the             convey its internal state to the users has succeeded in
participants even though they were not informed of the              proposing a novel research approach in the research area of
meaning or even the existence of the ASEs. Therefore, our           human-computer interaction or human-robot interaction in
experiment clearly showed that the utilized ASEs succeeded          order to resolve the above issues. Now we are planning to
in conveying the robot’s internal states to the participants        conduct a consecutive study to compare ASEs to human-
accurately and intuitively.                                         like expressions in terms of users’ cognitive load or cost-
  Currently, we are planning to implement the ASEs in               benefit relationships. Comprehending the advantages and
various kinds of spoken dialogue systems such as ATMs               disadvantages of these two expressions (ASEs and human-
and automatic telephone reservation systems. Specifically,          like expressions) would constitute a design methodology for
we are now focusing on car navigation systems’ speech               artifacts’ expressions in order to achieve smooth interaction
sounds; the reason for this is that current car navigation          between users and artifacts.
systems still sometimes give poor driving routes to users.
However, if this navigation system’s confidence level
regarding the route instruction is not very high, the                                          Conclusions
instructions of speech sounds with ASEs could implicitly               In this paper, we investigated whether the ASEs could
convey a lower confidence level. If the ASEs are still              convey artifacts’ internal states accurately and intuitively to
effective in such situations, they could be utilized in various     users; specifically, we created audio ASEs intended to meet
situations in which artifacts have to convey their internal         the two requirements for design, and we investigated
states to users.                                                    whether these ASEs met the two requirements for function
   In our experiment, we only focused on the internal state         by conducting a simple psychological experiment. As a
of the artifact in order to convey to users its level of            result of this experiment, the robot’s suggestions
confidence in its own expressed information. However, we            accompanied by decreasing ASEs showed a significantly
are planning to investigate which kinds of internal states          higher rejection rate compared with those accompanied by
could be conveyed to the users by means of ASEs. For                flat ASEs. Moreover, these ASEs were accurately
example, it is expected that the artifacts should also convey       interpreted by participants even though they were not
other kinds of internal states, such as feelings or conditions,     informed of the meaning or even the existence of the ASEs.
                                                                451

Therefore, our experiment clearly showed that the utilized         Liu, K. & Picard, W. R. (2003). Subtle expressivity in a
ASEs succeeded in conveying the robot’s internal states to           robotic computer. In Proceedings of CHI2003 Workshop
the participants accurately and intuitively; that is, the ASEs       on Subtle Expressivity for Characters and Robots, pp. 1-5.
succeeded in meeting all four requirements. Thus, we               Mori, M. (1970). Bukimi no tani (The uncanny valley, K. F.
confirmed that simple and low-cost expression ASEs could             MacDorman & T. Minato, Trans.). Energy 7, 4, 33–35.
be utilized as an intuitive notification methodology for             (Originally in Japanese).
artifacts to convey their internal states to users through         Sugiyama, O., Kanda, T., Imai, M., Ishiguro, H., Hagita, N.
paralinguistic or nonverbal information.                             & Anzai, Y. (2006). Humanlike conversation with
                                                                     gestures and verbal cues based on a three-layer attention-
                                                                     drawing model. Connection Science 18, 4, 379-402.
                   Acknowledgments                                 Yamada, S. & Komatsu, T. (2006). Designing Simple and
This study was partially funded by the Special                       Effective Expression of Robot’s Primitive Minds to a
Coordination Funds for Promoting Science and Technology              Human, In Proceedings of the 2006 IEEE/RSJ
granted by the Ministry of Education, Culture, Sports,               International Conference on Intelligent Robots and
Science and Technology (MEXT), Japan.                                Systems (IROS’06), pp. 2614-2619.
                                                                   Ward, N. (2003). On the Expressive Competencies Needed
                                                                     for Responsive Systems, In Proceedings of CHI2003
                                                                     Workshop on Subtle Expressivity for Characters and
                        References                                   Robots, pp. 33-34.
Blattner, M. M., Sumikawa, D. A. & Greenberg, R. M.
  (1989). Earcons and Icons: Their Structure and Common
  Design Principles. SIGCHI Bulletin. 21, 1, 123-124.
Cohen, P. R., Morgen, J., & Pollack, M. E. (1990).
  Intentions in Communication, The MIT Press, MA, USA.
Cowell, J. & Ayesh, A. (2004). Extracting subtle
  expressions for emotional analysis, In Proceedings of
  2004 IEEE International Conference on Systems, Man,
  Cybernetics (IEEE SMC 2004), pp. (1) 677-681.
Funakoshi, K., Kobayashi, K., Nakano, M., Yamada, S.,
  Kitamura, Y., & Tsujino H. (2008). Smoothing human-
  robot speech interactions by using a blinking-light as
  subtle expression. In Proceedings of the 10th International
  Conference on Multimodal Interface (ICMI 2008), pp.
  293-296.
Gaver, W. W. (1989). The SonicFinder: An Interface That
  Uses Auditory Icons. Human-Computer Interaction 4, 1,
  67-94.
Gaver, W. W. (1997). Auditory Interfaces. Handbook of
  Human-Computer Interaction, Elsevier Science.
Kendon, A. (1994). Do gestures communicate? A Review.
  Research in Language and Social Interaction 27, 3, 175-
  200.
Kipp, M. & Gebhard, P. (2008). IGaze: Studying reactive
  gaze behavior in semi-immersive human-avatar
  interactions, In Proceedings of the 8th International
  Conference on Intelligent Virtual Agent (IVA2008), pp.
  191-199.
Komatsu, T. & Yamada, S. (2007). How do robotic agents’
  appearances affect people’s interpretation of the agents’
  attitudes? In Extended Abstracts of CHI2007, pp. 2519-
  2524.
Komatsu, T. & Yamada, S. (2010). Effects of Adaptation
  Gap on Users’ Differences in Impressions of Artificial
  Agents, In Proceedings of the 14th. World
  Multiconference on Systemics, Cybernetics and
  Informatics (WMSCI 2010), to appear.
                                                               452

