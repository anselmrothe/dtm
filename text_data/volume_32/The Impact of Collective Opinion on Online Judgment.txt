UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Impact of Collective Opinion on Online Judgment

Permalink
https://escholarship.org/uc/item/1qv50385

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Author
Sakamoto, Yasuaki

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Impact of Collective Opinion on Online Judgment
Yasuaki Sakamoto (ysakamot@stevens.edu)
Center for Decision Technologies
Howe School of Technology Management, Stevens Institute of Technology
Hoboken, NJ 07030 USA
Abstract
Social media are part of our everyday lives. These
technologies allow people to share their opinions with others.
Here I examine whether the opinions posted online actually
change people’s perception of the world or they simply serve
as anchors when people post their own opinions. Participants
rated the interestingness of given stories. In one condition, the
stories were presented with invented average ratings of others
that matched the rating task. In another condition, the
assumed opinions of others mismatched the rating task. Only
in the task match condition, people used the opinions of
others when rating the stories. The results suggest that the
other’s opinions are used as anchors when making judgments
and do not influence people’s perception as much as one may
expect. The current work provides insights into cognitive
mechanisms underlying collective behavior in online
environments as well as a lesson for users and designers of
social media websites.
Keywords: Collective opinion; online judgment; social
influence; anchoring and adjustment.

Introduction
Many websites allow users to contribute content. Examples
include the product reviews on Amazon, the user ratings on
eBay, and the votes for stories on Digg. Although these
social media websites are used to share information with
others (Glushko, Maglio, Matlock, & Barsalou, 2008), little
is known about how people process the opinions of others in
online environments. In the current work, I examine
whether the opinions posted online actually change the way
people perceive the world or they simply serve as anchors
when people post their own opinions.
Previous offline studies have suggested that people have a
strong motivation to compare their opinions with others
(Festinger, 1954). People often adopt the decisions of others
(e.g., Cialdini & Goldstein, 2004; Deutsch, & Gerard, 1995;
Gureckis & Goldstone, 2006) due to their desire to make
correct responses under uncertainty (Sherif, 1935) or their
desire to be like others (Asch, 1951; 1956).
More recent work has shown that knowing other’s
decisions also influences people’s decisions online.
Salganik, Dodds, and Watts (2006) found in an online
market study that whereas good music was always
downloaded by many and bad music was always unpopular,
the popularities of the pieces in between varied depending
on whether or not the number of downloads the pieces had
was publicly available. Sakamoto, Sadlon, and Nickerson
(2008) showed that only a computational model that
assumed that users copied other users’ decisions could

account for the popularity of stories in an online
community. Sakamoto, Ma, and Nickerson (2009) further
showed that participants in their online experiments
switched their preferences for stories when the assumed
numbers of previous supporters were flipped.
These previous studies clearly show that the opinions of
others influence decisions. Nevertheless, it is unclear
whether the opinions of others change people’s mental
representations. For instance, when people become aware
that many others like a story and decide that they also like
the story, (1) are they simply using the opinions of others as
anchors for making their response or (2) do the opinions of
others actually change their perception of the story?
Relevant to this question, Berns et al. (2005) found changes
in the activation of the visual regions of the brain when
participants conformed to the majority’s decisions,
suggesting that the decisions of others might actually
influence people’s perception of what they saw. On the
other hand, the anchoring and adjustment heuristic often
observed in decision making (Tversky & Kahneman, 1974)
has been proposed as a process consumers use to weight
information from others when evaluating products (Wooten
& Reed, 1998).
To tease apart the two accounts, the current experiment
examined how people behave online using materials from
real environments. Participants from an online community
(Amazon’s Mechanical Turk) were asked to rate the
interestingness of stories obtained from another online
community (Digg). The assumed opinions of others
associated with the stories were manipulated. In the task
match condition, the opinions of others took the form of
previous average ratings, which matched the rating task the
participants completed (see Figure 1). In the task mismatch
condition, the opinions of others took the form of the
number of previous users who found the story interesting,
which mismatched the rating task (see Figure 2). The two
conditions differed only in the information about collective
opinion associated with the stories.
If people use the opinions of others as anchors to make
their own judgments, then the participants in only the task
match condition will be influenced by the collective
opinion. According to this account, when the format of the
other’s opinions and the format of the task mismatch, people
will not be able to use the previous opinions as anchors to
complete the task. This account predicts that whereas the
stories associated with higher pervious ratings will be rated
higher in the task match condition, there will be no
influence of collective opinion in the task mismatch
condition.

1869

Figure 2: Four news stories presented to the task
mismatch condition are shown. The information about
the collective opinion mismatches the rating task. The
first and third stories have fewer supporters than the
second and fourth stories.

Figure 1: Four news stories presented to the task match
condition are shown. The information about the
collective opinion matches the rating task. The first and
third stories have lower previous ratings than the
second and fourth stories.
In contrast, if the opinions of others actually change the
participants’ representations, both the task match condition
and the task mismatch condition should show influence of
collective opinion. This is because according to this
account, knowing the other’s opinions lead to actual
changes in people’s perception, and such changes will
transfer across tasks that differ on the surface. In this way,
the current work will provide new insights into cognitive
mechanisms underlying collective behavior in online
environments as well as a lesson for users and designers of
websites.

Method
Participants
Two hundred and seven (109 females and 98 males, M = 31
years old, SD = 11 years) members of Amazon’s
Mechanical Turk community (www.mturk.com) completed
the experiment. They earned 10 cents for participation.

Materials
Six news stories were selected randomly from an online
community (www.digg.com) with the constraints that
they (1) were not about exceptional events, (2) were not
promoted to the front page, (3) were submitted to the
community on the same date, and (4) had between 3 and 5
supporters in the community. These constraints were used
to minimize the possibility that participants were already
familiar with and had strong opinions about the stories.

Design and Procedure
Table 1 summarizes the manipulation of collective
opinion in the current work. There were three conditions:
task match, task mismatch, and control. The same six stories
were used in the three conditions. To measure any
differences in interests among groups, no information about
the opinions of others was provided for the same two stories
in all groups (Story X and Story Y in Table 1). Collective
opinion was manipulated for the remaining four stories
(Story 1 – 4 in Table 1). No information about the opinions
of others was given in the control group.

1870

Condition
Task match
Task mismatch
Control

Low-high
High-low
Low-high
High-low

Story X
−
−
−
−
−

Story Y
−
−
−
−
−

Story 1 (A)
2
4
82
2377
−

Story 2 (B)
4
2
2377
82
−

Story 3 (A)
2
4
85
2412
−

Story 4 (B)
4
2
2412
85
−

Table 1: Manipulation of collective opinion is summarized. Each value represents the average interestingness rating of
the story in the task match condition, and the number of people who found the story interesting in the task mismatch
condition. A dash indicates that no information about collective opinion was provided. Story X and Story Y were used to
measure if the three groups differed in their interests. Stories 1 and 3 are grouped as Story A because they are the same
type within each condition. For the same reason, Stories 2 and 4 are grouped as Story B.
In the task match condition, the four stories were
associated with the invented average interestingness ratings
from previous raters. This information about collective
opinion matched the interesting rating task the participants
completed. Although the stories selected had similar number
of supporters in Digg, suggesting that they are similar in
popularity, some stories might be inherently more
interesting than others for some participants. To cancel out
any effect due to the difference in stories, the assumed
information about collective opinion was counterbalanced.
In the low-high group in the task match condition, the
previous ratings were 2, 4, 2, 4 for the first, second, third,
and fourth stories, respectively, as shown in Table 1. In the
high-low group in the task match condition, the previous
ratings were 4, 2, 4, 2 for the first, second, third, and fourth
stories respectively, the flip of those in the low-high group.
In the task mismatch condition, the four stories were
associated with the invented number of people who found
the stories interesting, which mismatched the rating task. As
shown in Table 1, for the low-high group in the task
mismatch condition, the number of people who found the
stories interesting were 82, 2377, 85, 2412 for the first,
second, third, and fourth stories, respectively. In the highlow group in the task mismatch condition, the number of
people who found the stories interesting were 2377, 82,
2412, 85 for the first, second, third, and fourth stories,
respectively. The first and third stories are grouped as Story
A because they are the same type within each condition. For
the same reason, the second and fourth stories are grouped
as Story B.
The results from previous studies (e.g., Sakamoto et. al,
2009) suggest that in the task match condition, whereas the
low-high group will provide lower ratings on the first and
third stories (Story A) than on the second and fourth stories
(Story B), the high-low group will provide higher ratings on
Story A than on Story B. Thus, there will be an interaction
between Group (low-high vs. high-low) and Story (A vs. B)
in the task match condition. Whether this interaction will
result in the task mismatch condition is unclear. If knowing
the collective opinions of others can indeed change people’s
internal representations, then there should be an interaction
in the task mismatch condition. This is because if knowing

how many people think a story is interesting indeed changes
one’s perception of the story, this change should influence
her responses when she rates the interestingness of the story.
Failure to find an interaction in the task mismatch condition
suggests that knowing the opinions of others merely anchors
people’s responses in a task that is compatible with the
format of the opinions. The control group’s responses will
provide the baselines for the interestingness of the stories.
Participants completed the experiment online. They were
instructed to read six brief news stories and rate the
interestingness of the stories using a 5-point scale. The
instruction for the task match condition informed the
participants that the previous ratings indicated the average
ratings of previous readers. The instruction for the task
mismatch condition informed the participants that the
number of people indicated how many readers found the
stories interesting previously. The instruction for the control
group contained no information about the opinions of
others. The first two stories were the ones used to measure
whether the groups differ in their interests and had no
information about the other’s opinions in all groups. Then,
the participants rated the four stories. Finally they
completed the questions asking demographic information.

Results
All participants were included in the analyses. The groups
did not differ in their ratings for the first two stories (F < 1),
suggesting that the groups did not differ in their interests. I
first present the results from analyzing the task match
condition. One interest is whether the current work
replicates previous findings (Sakamoto et al., 2009) that one
can influence people’s judgment by manipulating the
information about the opinions of others. A 3 by 2 Analysis
of Variance (ANOVA) was performed on the task match
condition’s interestingness ratings, with Group (task match
low-high vs. task match high-low vs. control) and Story (A
vs. B) as independent variables. The main effect of Group
approached significance, F(2, 123) = 2.79, p = .07. As
shown in Figure 3, the control group had overall higher
ratings than the other groups. Perhaps people tend to use
higher end of scales in these tasks, and the invented
previous ratings shifted their responses down. Alternatively,

1871

all stories might have been quite interesting to the
participants, and the information about the previous ratings
could only lower their ratings. There was no significant
main effect of Story, F < 1. As predicted, there was a
significant interaction, F(2, 123) = 5.75, p = .004. As can be
seen in Figure 3, whether Story A or B was rated higher
depended on the type of the Group. As predicted, whereas
the low-high group rated Story B higher than Story A, the
high-low group rated the rated Story A higher than Story B,
F(1, 83) = 5.96, p = .017. The participants conformed to the
opinions of others.
Further analyses revealed that whereas the high-low
group rated Story A significantly more interesting than
Story B, t(41) = 2.03, p = .049, the difference in the lowhigh group’s ratings on Story A and Story B did not reach
significance t(42) = 1.40, p = .17. Unexpectedly, the control
group rated Story B significantly more interesting than
Story A, t(40) = 2.73, p = .009. The information about the
opinions of others in the low-high group was consistent with
the participants’ ratings without social influence. Thus the
previous ratings might have provided no new information to
the participants in the low-high group.
It is surprising that the high-low group in the task match
condition shows the opposite pattern from the natural
ratings shown by the control group. The participants in the
high-low group were willing to rate Story B less interesting
than Story A consistent with the invented collective
opinions, even though the invented collective opinions went
against the true collective opinions suggested by the control
group’s ratings. This suggests that either the participants did
not have strong opinions about these stories, or the desire to
conform was so strong that they gave untruthful ratings. The
results from the task match condition showed that the
participants conformed to the given information about the
opinions of others.
Our main interest is whether a similar pattern of results
can be found in the task mismatch condition. Figure 4
shows that the pattern of results for the task mismatch
condition was rather flat. A 3 by 2 ANOVA was conducted
on the task mismatch condition’s interestingness ratings,
with Group (task mismatch low-high vs. task mismatch
high-low vs. control) and Story (A vs. B) as independent
variables. There was no significant main effect of Group, F
< 1. There was a significant main effect of Story, F(1, 119)
= 6.95, p = .009. Figure 4 shows that collapsing across
Group, Story B has overall a higher rating than Story A.
However, the effect of Story was mostly due to the control
group. Both the low-high group and the high-low group did
not differ significantly in their ratings of Story A and Story
B, t(40) = 1.41, p = .17, and t < 1, respectively. As can be
seen in Figure 4, there was no significant interaction, F < 1.
The similar pattern of ratings in the three groups in the task
mismatch condition indicates that knowing how many
people found the stories interesting had little influence on
the participants ratings.

Discussion
In the current study, the participants rated the
interestingness of stories with varying information about the
opinions of others. In one condition, the information about
other’s opinions matched the rating task they were asked to
complete. In another condition, the information about the
other’s opinions mismatched the format of the rating task. In
this way, I examined whether the opinions of others could
actually change the way people perceived the world, or they
simply served as anchors when people made their own
judgments. The results were consistent with the latter
hypothesis. Only when the format of the information about
the opinions of others matched the format of the rating task,
the opinions of others had significant influence on the
participants’ judgments.
One might say that perhaps knowing the number of
previous readers who found the stories interesting simply do
not influence people’s judgment. However, previous work
showed that information about the number of people who
liked a story had significant influence on which of two
stories the participant liked better (Sakamoto et al., 2009).
Thus, I predict that knowing the number of previous people
who have found the stories interesting will influence
people’s responses on a binary decision task that asks which
of the two stories they find more interesting. I further
predict that information about the previous ratings will have
no significant influence on such binary tasks because the
information and the task mismatch in this case. Data from
these two groups are being collected right now.
The current work provides insights into cognitive
mechanisms underlying collective behavior. Anchoring and
adjustment (Tversky & Kahneman, 1974) may be one
cognitive mechanism that drives preferential attachment,
(Barabási & Albert, 1999), which characterizes the rich-getricher effect observed in real social networks. Further, the
current findings extend existing theories of social influence
by suggesting that social influence is not as internal as one
may think.
The current results may also have connections to other
cognitive theories. The finding that the information about
other’s opinions must match the task to have influence
might be related to the idea of transfer appropriate
processing from the memory literature (Morris, Bransford,
& Franks, 1977). In transfer appropriate processing,
performance is improved not only by the depth of
processing but also by the extent that the format of initial
encoding of information matches the format of later
retrieval. Analogously, the current work suggests a kind of
transfer appropriate processing in online social influence:
the information about other’s opinions needs to match the
online judgment task.

1872

Figure 3: The low-high group, the high-low group, and
the control group’s interestingness ratings in the task
match condition are shown for Story A and Story B.
Error bars represent the 95% confidence intervals
(Loftus & Masson, 1994). The low-high group thought
Story A was rated less interesting than Story B. The
high-low group thought the opposite. The control group
had no information about the previous ratings.

Figure 4: The low-high group, the high-low group, and
the control group’s interestingness ratings in the task
mismatch condition are shown for Story A and Story B.
Error bars represent the 95% confidence intervals
(Loftus & Masson, 1994). The low-high group thought
fewer people found Story A interesting than Story B.
The high-low group thought the opposite. The control
group had no information about the previous ratings.

The idea of alignability in analogy also has a bearing on
the current findings. Two things are alignable when they
have common dimensions. For example, knowing that the
previous rating of a story is 4 and the task of rating the
interestingness of a story using a 5-point scale are alignable.
On the other hand, knowing the number of people who
found the story interesting and the task of rating the
interestingness of a story using a 5-point scale are
nonalignable. Work in analogy has shown that alignability
plays major roles in memory retrieval (Markman & Gentner,
1997) and preference formation (Zhang & Markman, 1998).
The current work suggests that alignability also plays an
important role in people’s use of other’s opinions.
Related to the idea of transfer appropriate processing
and alignability, previous studies in social influence have
shown that only other’s decisions that are relevant have
influences on decisions (Cialdini, 1998; Cason & Mui,
1998). Although the social information in both the task
match condition and the task mismatch condition was
relevant to the interestingness task, perhaps the
participants did not regard the number of previous readers
who found the stories interesting as appropriate
information for the rating task.

The present study also provides useful information for
users and designers of websites. Many people use online
stores, such as eBay and Amazon, which provide
information about collective opinion in the forms of reviews
and ratings, and by listing the top selling items or the
number of items available in stock. Knowing the responses
produced by others can bias people’s sampling of
information (e.g., Lewandowsky et al., 2009; Stasser &
Titus, 1985). The current results show that not all outputs by
others influence people’s behavior in the same fashion. The
information about other’s opinions needs to align with the
response task to have significant influence on people’s
response. This is a note for the designers of social media
websites, whether they want to encourage or minimize
online social influence, as well as for marketers who want to
take advantage of social media.
The users of social media websites may also find the
current findings useful. Often times, users put too much
attention to the opinions of others and too little attention to
the actual content of the item (Sakamoto et al., 2009). By
doing so they may be creating a trend for an item whose
content is not so great. Knowing the present findings, users
may be able to focus more on the content and less on what
others think.
Perhaps people’s desire to attend to the other’s opinions
survived for a good reason. Observing and imitating others

1873

can allow people to try out solutions that they would not
have considered otherwise (Bandura, 1965). Solutions
selected by many people are often useful. Collective opinion
of a community can be more informative than the opinions
of a few experts (Surowiecki, 2004). Learning from the
previous outputs of others is considered as a process for the
creation of innovative solutions (Kraatz, 1998), the
evolution of language (Smith et al., 2003), and the
development of culture (Dennett, 1995).
In conclusion, we are surrounded by the opinions of
others in online environments. Although online decisions
are usually made privately and anonymously, online users
influence and are influenced by their opinions as in offline
environments. We need to know more about how people
process collective opinion in online environments.

References
Asch, S. E. (1951). Effects of group pressure upon the
modification and distortion of judgment. In H. Guetzkow
(Ed.) Groups, leadership and men. Pittsburgh, PA:
Carnegie Press, pp.177–190.
Asch, S. E. (1956). Studies of independence and
conformity: A minority of one against a unanimous
majority. Psychological Monographs, 70 (Whole no.
416).
Bandura, A. (1965). Behavioral modification through
modeling procedures. In L. Krasner & L. P. Ulmann
(Eds.), Research in behavior modification: New
development and implications (pp. 310–340). New York:
Rinehart and Winston.
Barabási, A. L., & Albert, R. (1999). Emergence of scaling
in random networks. Science, 286, 509–512.
Berns G. S., Chappelow J., Zink C. F., Pagnoni G., MartinSkurski M. E., Richards J. (2005). Neurobiological
correlates of social conformity and independence during
mental rotation. Biological Psychiatry, 58, 245–253.
Cason, T., & Mui V.-L. (1998). Social influence in the
sequential dictator game. Journal of Mathematical
Psychology, 42, 248–265.
Cialdini, R. B. (1998). Influence: The Psychology of
Persuasion. Perennial Currents.
Cialdini, R. B., & Goldstein, N. J. (2004). Social influence:
Compliance and conformity. Annual Review of
Psychology, 55, 591–621.
Dennett, D. C. (1995). Darwin’s dangerous idea. New
York: Touchstone.
Deutsch, M., & Gerard, H. B. (1995). A study of normative
and informational social influences upon individual
judgment. Journal of Abnormal Social Psychology, 51,
629–636.
Festinger, L. (1954). A theory of social comparison
processes. Human Relations, 7, 117–140.
Glushko, R. J., Maglio, P. P., Matlock, T., and Barsalou, L.
W. (2008). Categorization in the wild. Trends in
Cognitive Sciences, 12, 129–135.
Gureckis, T. M., & Goldstone, R. L. (2006). Thinking in
groups. In S. Harnad & I. Dror (Eds.), Distributed

cognition: Special issue of pragmatics & cognition, 14
(pp. 293–311). Amsterdam, The Netherlands: John
Benjamins.
Kraatz, M. S. (1998). Learning by association?
Interorganizational networks and adaptation to
environmental change. Academy of Management Journal,
41, 621–643.
Lewandowsky, S., Griffiths, M. L., and Kalish, M. L.
(2009). The wisdom of individuals: Exploring people’s
knowledge about everyday events using iterated learning.
Cognitive Science, 33, 969–998.
Loftus, G. R., & Masson, M. E. J. (1994). Using confidence
intervals in within-subject designs. Psychonomic Bulletin
& Review, 1, 476–490.
Markman, A. B., & Gentner, D. (1997). The effects of
alignability on memory. Psychological Science, 8, 363–
367.
Morris, C. D., Bransford, J. D., & Franks, J. J. (1977).
Levels of processing versus transfer appropriate
processing. Journal of Verbal Learning and Verbal
Behavior, 16, 519-533.
Sakamoto, Y., Sadlon, E., & Nickerson, J. V. (2008).
Bellwethers and the emergence of trends in online
communities. In Proceedings of the 30th Annual
Conference of the Cognitive Science Society.
Sakamoto, Y., Ma, J., & Nickerson, J. V. (2009). 2377
people like this article: The influence of others' decisions
on yours. In Proceedings of the 31st Annual Conference
of the Cognitive Science Society.
Salganik, M. J., Dodds, P. S., and Watts, D. J. (2006).
Experimental study of inequality and unpredictability in
an artificial cultural market. Science, 311, 854-856.
Sherif, M. (1935). A study of some social factors in
perception. Archives of Psychology, 27, 1–60.
Smith, K., Kirby, S., and Brighton, H. (2003). Iterated
learning: A framework for the emergence of language.
Artificial Life, 9, 371–386.
Stasser, G., & Titus, W. (1985). Pooling of unshared
information in group decision making: Biased information
sampling during discussion. Journal of Personality and
Social Psychology, 48, 1467–1478.
Surowiecki, J. (2004). The wisdom of crowds: Why the
many are smarter and how collective wisdom shapes
business, economies, societies, and nations. New York:
Random House.
Tversky, A. & Kahneman, D. (1974). Judgment under
uncertainty: Heuristics and biases. Science, 185, 11241130.
Wooten, D. B., & Reed, A., II. (1998). Informational
influence and the ambiguity of product experience: Order
effects on the weighting of evidence. Journal of
Consumer Psychology, 7, 79–99
Zhang, S., & Markman, A. B. (1998). Overcoming the early
entrant advantage via differentiation: The role of
alignable and nonalignable differences. Journal of
Marketing Research, 35, 413–426.

1874

