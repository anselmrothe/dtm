UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Emergence of Adaptive Eye Movements in Reading
Permalink
https://escholarship.org/uc/item/8zm8h00d
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Liu, Yanping
Reichle, Erik
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        The Emergence of Adaptive Eye Movements in Reading
                                                 Yanping Liu (yanping@pitt.edu)
                                              Department of Psychology, 3939 O’Hara St.
                                                        Pittsburgh, PA 15260 USA
                                                 Erik D. Reichle (reichle@pitt.edu)
                                              Department of Psychology, 3939 O’Hara St.
                                                        Pittsburgh, PA 15260 USA
                             Abstract                                        Finally, the third “camp” maintains that the eyes and
  Simulations were completed using artificial reading “agents”
                                                                        mind are tightly coupled, with the completion of some
  that are subject to known physiological (e.g., limited visual         cognitive process (e.g., lexical access) being the “trigger”
  acuity) and psychological (e.g., limited attention) constraints       that normally causes the eyes to move from word to word
  and capable of learning to move their eyes and allocate               during reading. Advocates of this cognitive-control account
  attention to read as efficiently as possible. These simulations       (Just & Carpenter, 1980; Reichle et al., 1998; Reichle,
  indicate that agents learn when and where to move their eyes          Warren, & McConnell, 2009; Reilly, 1993; Salvucci, 2001)
  to attain maximal reading efficiency, generalize this behavior        argue for a strong eye-mind link, with individual fixation
  from training sentences to novel test sentences, and use word
  length to predict word-identification times and thereby make          durations usually reflecting local processing difficulty.
  optimal decisions about when to initiate saccadic                          Perhaps not too surprisingly, all three theoretical
  programming—even if word length is only moderately                    positions have been remarkably successful explaining the
  predictive of word-identification times. These results suggest        basic patterns of eye movements that are observed during
  that humans may exploit even modestly informative cues in             reading; each position has provided one or more
  learning to decide when to move their eyes during reading.            computational models that formally instantiates the core
   Keywords: Attention; Eye Movements; Genetic Algorithms;              assumption of their respective positions and that simulate
   Neural Networks; Reading; Reinforcement Learning                     many or all of the “benchmark” findings related to eye-
                                                                        movement behavior in reading (Reichle et al., 2003). This
                         Introduction                                   makes it difficult to evaluate the models purely on the basis
     One of the outstanding unanswered questions in the                 of their ability to account for data, and because the models
psychology of reading (Rayner & Pollatsek, 1989) is: To                 make different a priori assumptions about the factors that
what extent are the moment-to-moment decisions about                    guide readers’ eye movements (e.g., how attention is
when to move the eyes during reading determined by                      allocated), model evaluation is like the proverbial problem
cognition? Attempts to answer this question can be divided              of “comparing apples and oranges.” The present simulations
into three theoretical “camps” (Reichle, 2006; Reichle,                 therefore adopt an entirely different approach to
Rayner, & Pollatsek, 2003).                                             understanding eye-movement control in reading.
     The first maintains that when the eyes move is largely                  Rather than developing a computational model around a
determined by the constraints imposed by the visual and                 priori assumptions about the precise manner in which
oculomotor systems (e.g., limited visual acuity). Advocates             perception, cognition, and motor control guide eye
of this oculomotor-control account (Feng, 2006; McDonald,               movements in reading, the present approach is a direct
Carpenter, & Shillcock, 2005; Reilly & O’Regan, 1998;                   extension of the work reported by Reichle and Laurent
Suppes, 1990; Yang, 2006) argue against an eye-mind link                (2006). In this work, artificial reading “agents” that were
in reading, and maintain that individual fixation durations             subject to known physiological (e.g., limited visual acuity)
provide only minimal information about ongoing lexical                  and psychological (e.g., limited capacity attention)
and/or linguistic processing difficulty.                                constraints were given the task of learning how to move
     According to the second “camp,” most decisions about               their eyes and attention so as to “read” (i.e., identify
when to move the eyes are determined by the activity of an              sequences of “words”) as efficiently as possible. The key
autonomous random timer that causes the eyes to move at a               results of this work were that the agents learned: (1) to
rate that reflects a reader’s comprehension goals and overall           direct their eyes towards the centers of words, the viewing
text difficulty, with cognition only intervening to inhibit             location that afforded the most rapid identification of the
saccadic programming when processing difficulty is                      words; (2) to use word length to predict when a given word
encountered and thereby lengthening fixation durations.                 would be identified, and then initiate saccadic programming
Advocates of this autonomous-timer account (Engbert,                    to move its eyes from that word right as it was identified;
Longtin, & Kliegl, 2002; Engbert et al., 2005; Reilly &                 and (3) to incur local fixation duration costs by identifying
Radach, 2006) argue for a weak eye-mind link, with                      short, easy-to-identify words from peripheral vision, and
individual fixations occasionally reflecting ongoing lexical            thereby avoiding more costly saccades to those words.
or linguistic processing difficulty.
                                                                    1136

     The present simulations replicate and extend the               spent processing a sentence. Learning continues until the
Reichle and Laurent (2006) results using artificial agents          values of the states reach asymptote.
that are capable of learning to move their eyes and attention
via reinforcement learning (Sutton & Barto, 1998).                          Table 1. State information (S) used by agents.
However, in contrast to the Reichle and Laurent agents, the
present agents were implemented using artificial neural                 #                   Available Information
networks (ANNs), and we demonstrated in two simulations                 1    Attended word (i.e., wordn) identified? (Y/N)
that the behavior of these agents: (1) generalizes to novel             2    # time steps processing wordn
sentences and words; (2) can be learned even in less than               3    # spaces between center of wordn and fixation
optimal learning conditions; and (3) is generally congruent             4    Length of wordn
with assumptions of cognitive-control theories. The                     5    Length of wordn+1
theoretical implications of these results will be discussed             6    Length of wordn-1
after the simulation results are described.                             7    Saccade being programmed? (Y/N)
                                                                        8    Length (# spaces) of intended saccade
               General Simulation Method                                9    # time steps programming saccade
     The artificial reading “agents” that were used in the
present simulations were given the task of learning how to               As mentioned, the agents are subject to several
“read” (i.e., identify sequences of words in their canonical        constraints. First, visual acuity is limited, so that the rate of
order) as efficiently as possible. These words could vary in        lexical processing decreases as the spatial distance between
terms of their length (1-8 letters) and/or the time required        the agent’s center of vision and the center of the word being
for their identification (2-14 time steps). The agents learned      processed increases (i.e., a word that takes N time steps to
to perform this task (subject to various constraints,               identify when its middle letter is fixated will take 1
discussed below) using trajectory sampling, a variant of the        additional time step to identify for each character space of
value iteration reinforcement-learning algorithm (Sutton &          disparity between the letter being fixated and the center of
Barto, 1998) that is often used with large-scale problems.          the word). Saccades also require 3 time steps to program
This algorithm is specified by:                                     and 1 time step to execute, and are subject to Gaussian (µ =
                                                                    0; σ = 1) random error. Finally, because the perceptual span
i=0                                                                 is known to be of limited spatial extent (Rayner & Pollatsek,
for all initial S:                                                  1989; Rayner, 1998), the agents were only allowed to
   Vi(S) = ANN(S)                                                   process one word at a time, instantiating the assumption that
   repeat                                                           attention is allocated serially during reading (e.g., Reichle et
     i=i+1                                                          al., 1998) or approximating the assumption that attention is
     if (random value < greed) then:                                allocated as a gradient—albeit a tightly focused one (e.g.,
         Vi(S) = Vi-1(S) + ε{maxaction∈M[reward(S, action)          Engbert et al., 2005). Although this assumption about
                + γ Vi-1(S′)] – Vi-1(S)}                            attention is quite controversial (e.g., see Reichle et al.,
     else random action                                             2009), it was intended as a simplifying assumption to make
until learning has completed.                                       the simulations as tractable as possible.
                                                                         In the Reichle and Lauent (2006) simulations, the value
where i indexes the learning iteration, Vi(S) is the value          of each state, Vi(S), was stored in a look-up table (i.e., one
associated with state S at time i, and M is the set of              value per combination of dimensions in Table 1). In the
permissible actions from a given state. There are three             present simulations, the values were learned and stored in
parameters: ε (= 0.5) controls the learning rate, greed (=          the connection weights of an ANN whose architecture and
0.5) controls how often an agent exploits what it already           principle weights were selected using NeuroEvolution of
knows in selecting actions versus exploring the                     Augmenting Topologies (NEAT) (Stanley & Miikkulainene,
consequences of randomly selected actions, and γ (= 0.9)            2002) and whose weights were optimized via the
determines how much the agent weighs the reward that is             Covariance Matrix Adaptation Evolution Strategy (CMA-
anticipated from the next state, S′, versus the immediate           ES; Hansen, Müller, & Koumoustsakos, 2003) when trapped
reward that it receives from the action that it selects. Each       in local maxima. Figure 1 is a schematic diagram of how the
state, S, consists of information that is available to the agent    NeuroEvolution and CMA-ES algorithms are used in
at any given point in time (see Table 1). The agents can            conjunction with task-specific training to select network
perform one of three actions: (1) continue attending (i.e.,         architectures that are well suited to solve the types of
lexically processing) the current word; (2) shift attention to      problems explored in this article.
the next word; and (3) request an eye movement of ±10                    Each network was comprised of nine input units (one
character spaces. An agent selects the actions that result in       per dimension in Table 1), one bias unit, one output unit
the most (anticipated) reward, being “rewarded” +1 for              (representing the learned value of each state), and an
every identified word and “punished” -1 for every time step         unspecified number of hidden units. In contrast to many
                                                                    neural networks, the hidden units were not strictly layered,
                                                                1137

but could be configured in a variety of ways (e.g., as              optimization stagnated. Each reported simulation is based
additional bias units; see Fig. 1). The activation of input unit    on populations of 100 individuals evaluated across 300
i when given some value x of one of the dimensions in               generations to solve the tasks of interest. Each individual
Table 1 was scaled to the interval [-1, 1] using:                   networks agent also learned to perform its task using value
                                                                    iteration across five learning trials and using the specific
acti(x) = {x – [max(x) / 2]} / [max(x) / 2]                         training regimens.
where the function “max” returns the maximum value of the           Simulation 1
dimension. (Note that acti(x) = -1/1 when Dimensions 1 and               The first simulation replicated and extended the Reichle
7 equal false/true.)                                                and Laurent (2006) results using agents implemented as
                                                                    ANNs (as described above) and various novel test
                                                                    sentences.
                                                                    Method. Five agents were trained on a corpus of five 8-
                                                                    word “sentences” comprised of random permutations of 1-,
                                                                    3-, 5-, and 7-letter “words.” (These sentences were
                                                                    randomly selected from 20 used by Reichle & Laurent,
                                                                    2006.) The first and last words were always 1-letter in
                                                                    length and required 2 time steps to identify, and always
                                                                    excluded from our analyses because their processing
                                                                    started/ended abruptly. The remaining 1-, 3-, 5-, and 7-letter
                                                                    words respectively required 2, 6, 10, and 14 time steps to
                                                                    identify when fixated from their central letters. After
                                                                    training, agents were tested on: (1) the same five sentences;
                                                                    (2) five novel 8-word sentences comprised of different
                                                                    random permutations of 1-, 3-, 5-, and 7-letter words; and
                                                                    (3) five 8-word sentences comprised of random
                                                                    permutations of 2-, 4-, 6-, and 8-letter novel words.
                                                                    Results. Figure 2 shows the simulated fixation landing-site
                                                                    distributions on the words, as a function of their length and
                                                                    whether the sentences being using used to evaluate the
                                                                    agents were old (i.e., used during training), novel, or
                                                                    comprised of novel words (i.e., 2-, 4-, 6-, and 8-letter
                                                                    words). (In all of the figures shown below, the data points
                                                                    indicate the condition means and the error bars indicate the
                                                                    standard errors of the means.) As indicated, the agents
                                                                    learned to direct their eyes towards the centers of the words
                                                                    because this was the viewing position that afforded the most
                                                                    rapid identification of the words. However, because of
                                                                    saccadic error, the fixation landing sites are approximately
                                                                    normally distributed, in line with what is observed with
                                                                    human readers (McConkie et al., 1988, 1991; Rayner,
                                                                    Sereno, & Raney, 1996). Finally, the behavior generalized
                                                                    across both novel sentences and words.
        Figure 1. Method use to evolve and train agents.
     This NeuroEvolution algorithm was used to select
network architectures that were adapted to use the value
iteration reinforcement-learning algorithm (via using a
residual algorithm to implement back-propagation in the
ANNs) for the tasks that are the focus of this article—
learning to move the eyes and attention to read efficiently.
The CMA-ES algorithm was used to optimize weights when
                                                                        Figure 2. Simulated fixation landing-site distributions.
                                                                1138

                                                                   “trigger” that initiates saccadic programming; Reichle et al.,
      Figure 3 shows the mean probabilities of making a            1998, 2003, 2009.)
single fixation, making two or more fixations, or skipping,
again as a function of word length and the nature of the test
sentences. As the figure shows, agents tended to either make
a single fixation on or skip the shorter words, and to make
two or more fixations on the longer words. These results are
consistent with what is observed with humans (Rayner et
al., 1996) and did not vary by testing condition.
                                                                        Figure 4. Simulated time-based dependent measures.
                                                                        These results of Simulation 1 replicate and extend the
                                                                   key findings reported by Reichle and Laurent (2006) by
                                                                   showing that the reading agents, implemented as ANNs, are
                                                                   able to generalize from a small set of training sentences to
                                                                   sentences containing novel configurations of words. This is
                                                                   methodologically important because it shows how ANNs
      Figure 3. Simulated fixation probabilities.
                                                                   might be used to solve large-scale reinforcement learning
                                                                   problems that might otherwise be impossible to solve (e.g.,
      Figure 4 shows the mean simulated values of five
                                                                   a look-up table version of the agents would require the
dependent measures (in time steps), again as a function of
                                                                   storage and updating of the more than 6 million different
word length: (1) first-fixation duration (FFD), or the
                                                                   states listed in Table 1). This demonstration also makes it
duration of the first fixation on a word during the first pass
                                                                   possible to explore more complex contingencies between
through the sentence; (2) gaze duration (GD), or the sum of
                                                                   eye-movement behavior and lexical variables, as described
all first-pass fixations; (3) total-viewing time (TT), or the
                                                                   next.
sum of all fixations, irrespective of whether they occur
during the first pass; (4) word-identification times (ID), or      Simulation 2
the time spent processing the words; and (5) saccadic-
programming initiation times (SPIT), or the time spent                  The second simulation examined the consequences of
processing wordn prior to initiating the saccade that moved        training on a more realistic sentence corpus—one in which
the eyes to wordn+1. As Figure 4 indicates, the measures           word length is only moderately predictive of the time
increased with increasing word length (which is perfectly          required to identify words.
correlated with identification time), but with the mean
processing time being longer than the minimal identification       Method. Five agents were trained and tested on five 8-word
time because saccadic error often caused words to be               sentences in which 1-, 3-, 5-, and 7-letter words required 4-9
processed from poor viewing locations, where lexical               time steps to identify, and where word length was only
processing was slower. Importantly, if an agent spent N time       moderately correlated to word-identification times across
steps processing wordn, then it on average spent                   the corpus (r = 0.31).
approximately N-3 time steps processing wordn before
initiating saccadic programming to move its eyes to wordn+1.       Results. The simulated landing-site distributions, fixation
This is an optimal strategy for deciding when to move the          probabilities, and time-based measures (grouped by both
eyes because initiating saccadic programming any earlier           word length and identification time) are shown in Figures 5-
would cause the eyes to leave wordn prematurely, resulting         7, respectively. As indicated in the left panel of Figure 5, the
in it being processed more slowly from wordn+1 (because of         agents learned to direct their eyes towards the centers of
reduced visual acuity). Conversely, initiating saccadic            words because this location afforded the most rapid
programming any later would cause the fixations to be              identification of words. And as the left panel of Figure 6
unnecessary long in duration. Thus, by initiating saccadic         shows, the agents were also more likely to make single
programming at the observed times, an agent insures that, in       fixations on or skip the shorter words, and make two or
most cases, the eyes move from wordn right when it has             more fixations on the longer words. Both of these findings
been identified. (It is also worth noting that this strategy is    are consistent with human readers (McConkie et al., 1988,
similar to the “familiarity check” assumption of the E-Z           1991; Rayner, 1996) and the results of Simulation 1. The
Reader model of eye-movement control during reading,               right panels of Figures 5 and 6 indicate that similar word-
where a preliminary stage of lexical processing is the             targeting behaviors were evident when the words are
                                                                   grouped by their identification times, but that there are some
                                                                   irregularities (e.g., bimodal landing-site distributions with
                                                               1139

the more-difficult-to-identify words) because these items         “intelligent” eye-movement behavior can emerge from
included a mixture of both short and long words.                  artificial reading agents that are subject to fairly
                                                                  uncontroversial physiological and psychological constraints
                                                                  and that are capable of learning to coordinate attention and
                                                                  eye movements to support efficient reading. Simulation 1
                                                                  extended the Reichle and Laurent results by implementing
                                                                  the reading agents within an ANN and then showing that the
                                                                  agents’ eye-movement behaviors generalize to novel
                                                                  sentences and words. And importantly, the agents used
                                                                  word-length cues to predict when words would be
                                                                  identified, and then used this knowledge to learn when to
                                                                  initiate saccadic programming. Simulation 2 indicated that
  Figure 5. Simulated fixation landing-site distributions, by     the agents learned the same eye-movement behaviors,
      word length (left) and identification times (right).        including learning to use word length to initiate saccadic
                                                                  programming in an optimal manner—even though word
                                                                  length was only moderately predictive of word-
                                                                  identification time.
                                                                       The simulation results have important theoretical
                                                                  implications for our general understanding of eye-
                                                                  movement control in reading and the specific questions of
                                                                  what determines when our eyes move during reading. First,
                                                                  the simulations suggest how information that is predictive of
                                                                  when a word will be identified can be used to initiate
                                                                  saccadic programming in a manner that affords efficient
                                                                  reading. In the absence of such predictive information, it
  Figure 6. Simulated fixation probabilities, by word length      may be optimal to either simply wait until wordn has been
             (left) and identification times (right).             identified before initiating saccadic programming to move
                                                                  the eyes to wordn+1, or to base the decision on the mean time
                                                                  required to identify wordn. Although both of these strategies
                                                                  prevent the eyes from moving prematurely (which would
                                                                  then slow reading considerably because words would have
                                                                  to be identified from poorer viewing locations), the
                                                                  strategies are also conservative because they often produce
                                                                  unnecessarily long fixations. This suggests that any strategy
                                                                  that simply ignores lexical processing difficulty and uses
                                                                  saccadic programming and visual acuity constraints to
                                                                  decide when to move the eyes will not be optimal because it
                                                                  ignores information (about the rate of lexical processing)
  Figure 7. Simulated time-based measures, by word length         that can be used to inform those decisions. This conclusion
             (left) and identification times (right).             provides one argument against oculomotor-control theories
                                                                  of eye-movement control in reading (Feng, 2006; McDonald
     Finally, the most striking result from Simulation 2 is       et al., 2005; Reilly & O’Regan, 1998; Suppes, 1990; Yang,
that the agents learn to use word length information to           2006). And although our results admittedly say less about
predict the time required to identify words, and then used        the feasibility of autonomous-timer theories (Engbert et al.,
this knowledge to program saccades so that the eyes would         2002, 2005), such theories are not parsimonious if
leave a word right as it was identified. This “strategy” is       decisions about when to move the eyes can be made using
similar to the one that was adopted by the agents in              information that is readily available to the reader (i.e.,
Simulation 1, even though the relation between word length        information about lexical processing difficulty). In other
and identification times was much weaker in Simulation 2 (r       words, it is not parsimonious to posit an autonomous timer
= 0.31) than Simulation 1 (r = 1). And as the left and right      that is occasionally overridden by lexical processing
panels of Figure 7 indicate, this strategy was evident            difficulty if this information is itself sufficient to decide
irrespective of whether the words are grouped by their            when to move the eyes in an optimal manner.
length or by their identification times.                               Second, the simulations suggest that humans may
                                                                  exploit cues that may be only modestly predictive of lexical
                                                                  processing difficulty in learning to decide when to initiate
                    General Discussion                            saccadic programming. These cues probably include word
     The simulations reported in this article replicated the      length, but also orthographic cues (e.g., prefixes and
Reichle and Laurent (2006) results by showing that
                                                              1140

suffixes, unusual letter sequences, etc.), and possibly cues        Rayner, K. & Pollatsek, A. (1989). The Psychology of
that are generated via top-down processing (e.g., the                 Reading. Englewood Cliffs, NJ: Prentice Hall.
syntactic and/or semantic constraints imposed by a word’s           Rayner, K., Sereno, S. A., & Raney, G. E. (1996). Eye
prior sentence context). It is an open question as to how             movement control in reading: A comparison of two types
these different sources of information are combined in                of models. Journal of Experimental Psychology: Human
making moment-to-moment decisions about when to move                  Perception and Performance, 22, 1188-1200.
the eyes during reading, but a vast experimental literature         Reichle, E. D. (2006). Theories of the “eye-mind” link:
(e.g., for a review, see Rayner, 1998) indicates that these           Computational models of eye-movement control during
variables (and many others) do influence such decisions.              reading. Cognitive Systems Research, 7, 2-3.
Future simulations using our artificial reading agents will         Reichle, E. D. & Laurent, P. A. (2006). Using reinforcement
provide testable hypotheses regarding this question.                  learning to understand the emergence of “intelligent”
                                                                      eye-movement behavior during reading. Psychological
                     Acknowledgments                                  Review, 113, 390-408.
      Address correspondence to: Erik Reichle, University of        Reichle, E. D., Liversedge, S. P., Pollatsek, A., & Rayner,
Pittsburgh, 635 LRDC, 3939 O’Hara St., Pittsburgh, PA                 K. (2009). Encoding multiple words simultaneously in
15260 USA (or via email at: reichle@pitt.edu.) This work              reading is implausible. Trends in Cognitive Sciences, 13,
was supported by a China Scholarship Council award to the             115-119.
first author and an NIH grant (R01HD053639) awarded to              Reichle, E. D., Pollatsek, A., Fisher, D. L., & Rayner, K.
the second author.                                                    (1998). Toward a model of eye movement control in
                                                                      reading. Psychological Review, 105, 125-157.
                                                                    Reichle, E. D., Rayner, K., & Pollatsek, A. (2003). The E-Z
                          References                                  Reader model of eye movement control in reading:
Engbert, R., Longtin, A., & Kleigl, R. (2002). A dynamical            Comparisons to other models. Behavioral and Brain
   model of saccade generation in reading based on spatially          Sciences, 26, 445-476.
   distributed lexical processing. Vision Research, 42, 621-        Reichle, E. D., Warren, T., & McConnell, K. (2009). Using
   636.                                                               E-Z Reader to model the effects of higher-level language
Engbert, R., Nuthmann, A., Richter, E., & Kliegl, R. (2005).          processing on eye movements during reading.
   SWIFT: A dynamical model of saccade generation during              Psychonomic Bulletin & Review, 16, 1-21.
   reading. Psychological Review, 112, 777-813.                     Reilly, R. (1993). A connectionist framework for modeling
Feng, G. (2006). Eye movements as time-series random                  eye movements in reading. In G. d’Ydewalle & J. Van
   variables: A stochastic model of eye movement control in           Rensbergen (Ed.), Perception and cognition: Advances in
   reading. Cognitive Systems Research, 7, 70-95.                     eye movement research (pp. 193-212). Amsterdam:
Hansen, N., Müller, S. D., & Koumoutsakos, P. (2003).                 North-Holland.
   Reducing the complexity of the Derandomized Evolution            Reilly, R. & O’Regan, J. K. (1998). Eye movement control
   Strategy with Covariance Matrix Adaptation (CMA-ES).               in reading: A simulation of some word-targeting
   Evolutionary Computation, 11, 1-18.                                strategies. Vision Research, 38, 303-317.
Inhoff, A. W. & Rayner, K. (1986). Parafoveal word                  Reilly, R. G. & Radach, R. (2006). Some empirical tests of
   processing during eye fixations in reading: Effects of             an interactive activation model of eye movement control
   word frequency. Perception & Psychophysics, 40, 431-               in reading. Cognitive Systems Research, 7, 34-55.
   439.                                                             Salvucci, D. D. (2001). An integrated model of eye
Just, M. A. & Carpenter, P. A. (1980). A theory of reading:           movements and visual encoding. Cognitive Systems
   From eye fixations to comprehension. Psychological                 Research, 1, 201-220.
   Review, 87, 329-354.                                             Stanley, K. O. & Miikkulainen, R. (2002). Evolving neural
McConkie, G. W., Kerr, P. W., Reddix, M. D., & Zola, D.               networks through augmenting topologies. Evolutionary
   (1988). Eye movement control during reading: I. The                Computation, 10, 99-127.
   location of initial eye fixations in words. Vision Research,     Suppes, P. (1990). Eye movement models for arithmetic and
   28, 1107-1118.                                                     reading performance. In E. Kowler (Ed.), Eye movements
McDonald, S. A., Carpenter, R. H. S., & Shillcock, R. C.              and their role in visual and cognitive processes (pp. 395-
   (2005). An anatomically constrained, stochastic model of           453). Amsterdam: Elsevier.
   eye movement control in reading. Psychological Review,           Sutton, R. S. & Barto, A. G. (1998). Reinforcement
   112, 814-840.                                                      learning: An introduction. Cambridge, MA: MIT Press.
Rayner, K. (1998). Eye movements in reading and                     Yang, S.-N. (2006). An oculomotor-based model of eye
   information processing: 20 years of research.                      movements in reading: The competitive/interaction
   Psychological Bulletin, 124, 372-422.                              model. Cognitive Systems Research, 7, 56-69.
Rayner, K. & Duffy, S. A. (1986). Lexical complexity and
   fixation times in reading: Effects of word frequency, verb
   complexity, and lexical ambiguity. Memory & Cognition,
   14, 191-201.
                                                                1141

