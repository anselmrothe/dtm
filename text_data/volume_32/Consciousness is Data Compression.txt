UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Consciousness is Data Compression
Permalink
https://escholarship.org/uc/item/0bc3p5sv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Maguire, Phil
Maguire, Rebecca
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                         Consciousness is Data Compression
                                              Phil Maguire (pmaguire@cs.nuim.ie)
                                           Department of Computer Science, NUI Maynooth
                                                           Co.Kildare, Ireland
                                         Rebecca Maguire (rebecca.maguire@dbs.ie)
                                         Department of Psychology, Dublin Business School
                                             34/35 South William Street, Dublin 2, Ireland
                             Abstract                                 scientist is to craft a model which can describe a dataset in
                                                                      more concise terms. These models are called theories. The
   In this article we advance the conjecture that conscious
   awareness is equivalent to data compression. Algorithmic           more compression a theory achieves, the greater its value.
   information theory supports the assertion that all forms of        For example, Kepler’s heliocentric model of the heavens is
   understanding are contingent on compression (Chaitin, 2007).       considered superior to Ptolemy’s geocentric model, because
   Here, we argue that the experience people refer to as              it manages to describe astronomical observations in terms of
   consciousness is the particular form of understanding that the     three simple mathematical laws rather than a convoluted set
   brain provides. We therefore propose that the degree of            of epicycles.
   consciousness of a system can be measured in terms of the               The idea that compression underpins scientific endeavor
   amount of data compression it carries out.                         is not new. Occam’s razor is a fundamental scientific
   Keywords: Information theory, data compression,                    principle which is attributed to the 14th century English
   Solomonoff induction, phenomenal experience, Turing test.          friar, William of Ockham. The principle states that the
                                                                      explanation of any phenomenon should make as few
                         Introduction                                 assumptions as possible, eliminating those that make no
According to Einstein, the most incomprehensible thing                difference to the observable predictions: “entities should not
about the world is that it is comprehensible. But what does it        be multiplied unnecessarily”. This law of parsimony implies
mean to comprehend? A common feature of understanding                 that if you have two competing theories which both describe
in both science and mathematics is that it involves the               a phenomenon, the simpler (i.e. more compressed)
reduction of a set of observations or truths to a more basic          explanation is better.
set of assumptions. Indeed, Chaitin (2007) has proposed that
all forms of understanding can be viewed as instances of              Algorithmic Information Theory
data compression. Have a look at the sequence below and               As homo sapien sapiens (Latin for knowing man), the urge
see if you can ‘understand’ it:                                       to understand is a defining characteristic of our species. But
                                                                      why is it that we should devote so much energy to
                     4, 6, 8, 12, 14, 18, 20, 24...                   understanding the world around us? In order to answer this
                                                                      question we must turn to algorithmic information theory.
    What is involved in understanding this sequence?                  Algorithmic information theory is a field which brings
Intuitively, one searches for a pattern that links all of the         together mathematics, logic and computer science. The
numbers together. If the numbers were randomly selected,              foundations of this field were laid by Chaitin, Solomonoff
then, more than likely, no pattern could be identified. In this       and Kolmogorov in the 1960s (see Li & Vitányi, 1997).
case the sequence could not be described any more                     According to Chaitin, it is “the result of putting Shannon’s
concisely: it would be incompressible. However, the above             information theory and Turing’s computability theory into a
sequence seems amenable to compression. For example, one              cocktail shaker and shaking vigorously”. The basic idea is
can posit the following hypothesis: “start at 4 and keep              that the complexity of an object can be represented by the
adding 2, except if the digits of the previous number sum to          size of the smallest program for computing it. This new way
2, 5 or 8, in which case add 4”. These instructions provide a         of thinking about information was first proposed by
complete description of the sequence. However, because the            Solomonoff (1964) and subsequently independently
description seems somewhat unwieldy, it is not particularly           identified by Kolmogorov and Chaitin.
convincing. A more concise description is possible: “go                    Algorithmic theory provides a clear answer as to why
through all odd prime numbers and add 1”. Because this                organisms should seek to compress observational data.
hypothesis is more concise, it intuitively reflects a deeper          Specifically, Solomonoff’s (1964) theory of inductive
understanding of the sequence.                                        inference reveals that compression is a necessary component
    Scientific understanding is furthered by exposing greater         of prediction. The theory provides a universal measure of
levels of redundancy in observational data. The goal of the           the probability of an object by taking into account all of the
                                                                      ways in which it might have been produced. This universal a
                                                                  748

priori probability can then be incorporated into Bayes’ rule        rigorous link between consciousness and compression.
for inductive inference in order to make optimal predictions        Systems that are good at compressing data seem to produce
based on a set of prior observations.                               consciousness. But why should this be the case?
    Solomonoff’s theory of inductive inference reveals that
the more a set of observations can be compressed, the more          The Brain as a Compressor
accurately subsequent events can be predicted. Consider             In order to answer this question, we must consider the
again the sequence 4, 6, 8, 12, 14, 18, 20, 24... The long-         nature of the compression that the brain carries out. In other
winded description predicts that the next number in the             words, what type of understanding does the brain provide?
sequence will be 26, while the more succinct description                The success of an organism is dependent on cooperation
predicts that 30 will follow. According to Solomonoff’s             between all of its constituent components. In order to
theory, the latter must be the better prediction, because it        achieve the goal of reproduction, it must exhibit coordinated
involves a fewer number of assumptions: the shorter the             behavior. For example, it does not make sense for an
length of the description, the more likely it is to be correct.     organism’s legs to maintain independent agenda. Because
    Algorithmic information theory reveals that compression         the interests of both legs are intimately bound, it is more
is the only systematic means for generating predictions             productive for them to cooperate with each other in
based on prior observations. All successful predictive              achieving a single set of objectives (e.g. putting one foot
systems, including animals and humans, are approximations           forward while the other stays on the ground). Accordingly,
of algorithmic induction. All useful contributions to human         the brain sources sensory information from all over the body
knowledge work by coaxing people into modifying their               and compresses it in parallel, thereby optimizing predictive
inductive strategies in such a way that they better                 accuracy for the organism as a whole. Tactile information
approximate algorithmic induction.                                  from every limb is compressed in parallel with visual
    In order to thrive in an uncertain environment,                 information from the eyes and audio information from the
organisms must be able to anticipate future events; the more        ears, giving rise to a form of understanding that is
efficiently they can compress their experiences, the more           centralized and representative of the organism’s experiences
accurate these predictions will be. Consequently, organisms         as a singular unit. The resulting decisions of the organism
have evolved brains which are prodigious compressors of             also appear centralized: to the external observer it seems as
information: compressing sensory information provides               if the organism’s body is being ‘controlled’ by a single
them with an ‘understanding’ of their environment (see              entity with a singular set of objectives.
Chater & Vitányi, 2002; Schmidhuber, 2006; Wolff, 1993).                Not only does the success of an organism depend on
Tononi (2008) has proposed that the feeling of being                cooperation between its constituent components, it also
conscious must be linked in some way to the integration of          depends on cooperation between its past and future states.
information which occurs in the brain. In the following             Snapshots of an organism’s behavior taken at different
sections we specify precisely the relationship between              points in time again reveal evidence of a singular set of
information processing and subjective awareness:                    objectives. For example, if you know you will be hungry in
specifically, we argue that the experience people describe as       several hours time, you might pack a lunchbox in your bag.
consciousness is equivalent to the compression that the             In this case, you are cooperating with your future self. From
brain carries out. Henceforth, this idea is referred to as the      an evolutionary perspective, organisms cooperate with their
‘compression conjecture’. It should be noted that the               future selves because reproduction is a challenging task
conjecture does not merely suppose an association between           which requires coordinated behavior manifested over an
consciousness and compression; rather it asserts that no            extended period of time. As a result, the brain goes to the
meaningful distinction can be drawn between the two                 effort of distilling memories which are maintained with the
concepts.                                                           expectation that they will facilitate data compression at a
                                                                    future point.
                      Consciousness                                     The utility of memory can again be explained in terms of
From an evolutionary perspective, the sole purpose of the           enhancing algorithmic induction. Memory allows us to
brain is to produce behavior that optimizes the reproductive        make greater sense of the world by enhancing our ability to
success of an organism and its genetic material. Features of        carry out compression. Incoming sensory data are
the brain which are not linked to optimizing behavior should        compressed in parallel with stored historical data, allowing
therefore not have been rigorously preserved by evolution.          redundancy to be identified more efficiently and,
Why then should brains go to the trouble of producing               consequently, enhancing predictive accuracy. Thus, the
consciousness?                                                      form of understanding that the brain produces unites not
    Algorithmic information theory tells us that the key to         only distributed sensory organs but also past and current
enhancing prediction (and hence reproductive success) is to         states of an organism. The compression conjecture proposes
optimize data compression. If the principal evolutionary            that the experience of this unitary form of understanding is
pressure determining the structure of the brain has been its        what we mean when we use the term ‘consciousness’.
capacity to compress data, and if brains are the only system
we know of that support consciousness, then this suggests a
                                                                749

Self-Awareness                                                     of data which has been gathered over a wide cross section of
Intuitively, the above account does not seem fully                 space and time. The structure of the brain allows a sensory
satisfactory. For example, one might conceive of an                stimulus to be translated into the subjective experience of
artificial compressor which compresses large amounts of            understanding through the process of compression.
current and historical data in parallel, though without                In sum, people don’t passively observe the world around
experiencing the same form of awareness that we humans             them; they gaze through the lens of understanding provided
are familiar with. Indeed, the compression carried out by the      by their brains. When people talk about their subjective
brain has one additional ingredient which sets it apart from       experience they are referring to the particular form of
simpler compression systems: it compresses its observations        compression that their brain provides. The reason that these
of its own behavior. The capacity for a system to model its        qualitative descriptions differ from objective scientific
own actions necessarily involves the identification of itself      descriptions is because the subjective experience of a
as an entity separate to its surroundings. As a result, self-      stimulus is dependent on how it is processed. The particular
compression entails self-awareness.                                ‘flavors’ of qualia that we humans are familiar with are
    The human brain is a self-representational structure           artifacts of our cognition, which are determined by the
which seeks to understand its own behavior. For example,           patterns our brains have evolved to detect and encode.
people model their own selves in order to more accurately
predict how they are going to feel and react in different          Describing Qualia
situations. They build up internal models about who they           Intuitively, qualia appear to resist objective description.
think they are and use these models to inform their                However, this intuition must be flawed, for if qualia could
decisions. In addition, the human brain compresses the             not be recorded in some informational form in the brain then
observed behavior of other organisms. When we watch                we would not be able to remember them. In this case, all
other individuals, we realize that there is a great deal of        current subjective experiences would seem random and
redundancy in their activity: rather than simply cataloguing       meaningless because there would be no previous subjective
and memorizing every action they perform, we can instead           experiences with which to reconcile them.
posit the more succinct hypothesis of a concise ‘self’ which           According to the compression conjecture, which
motivates these actions. By representing this self we can          supposes that subjective experience and data compression
then make accurate predictions as to how the people around         are equivalent, it should be possible to provide a full
us will behave. The idea that the actions of an organism are       description of a quale by detailing the compression that a
controlled by a singular self is merely a theoretical model        system achieves in response to a stimulus. Thus, for
which eliminates redundancy in the observed behavior of            example, the experience of red could be captured by
that organism. People apply this same process to                   describing the changing structure of the brain in response to
themselves: what you consider to be the essence of you is          the sight of a red object. This experience could then be
simply a model which compresses your observations of your          comprehensively represented in terms of bits of bytes and
own past behavior.                                                 could feasibly be contained in a book. Yet, intuitively, a
                                                                   book containing symbols could never capture the experience
Phenomenality                                                      of the color red in the same way that we feel it; leafing
A significant obstacle to providing a fully satisfactory           through the pages of the book would not give rise to the
theory of consciousness lies in explaining the phenomenon          subjective feeling of red. How can this apparent incongruity
of subjective experience: why is it that we experience qualia      be rationalized?
which seem to elude scientific description? According to the           The compression conjecture indicates that even if a book
consciousness conjecture, the ‘flavor’ of a quale can be           does carry a complete description of a subjective
linked to the particular form of compression that the brain        experience, merely reading the book is not sufficient for
carries out in response to a stimulus.                             reproducing that experience. To appreciate it, the reader
    If an organism perceives a stimulus, yet can discern no        must be capable of compressing the data in the same manner
pattern in the sensory data, then that stimulus will appear        in which it was originally compressed. For example, rather
completely random and meaningless to the organism: the             than simply leafing apathetically through pages of symbols,
stimulus will not be experienced at all. On the other hand, if     the reader must be capable of identifying the underlying
some redundancy can be identified, then the stimulus can be        patterns which link those symbols together. If a system is
‘understood’ (i.e. experienced) by relating it to previously       incapable of compressing the data, then it cannot
gathered sensory information. For example, when people             ‘understand’ the experience which is contained within.
look at an apple, they perceive a round shape by identifying       Experience is dependent on the system which is doing the
redundancy between the appearance of the apple and                 experiencing, as opposed to being intrinsic to a stimulus.
previously encountered round objects; they perceive a green        Because reading a description of compression will not
color by identifying redundancy between the appearance of          necessarily cause the same compression to occur in your
the apple and previously encountered green objects. When           own brain, reading about the experience of red will not
we ‘see’ an apple we are not just processing an                    make you experience red.
instantaneous visual stimulus but, rather, compressing a set
                                                               750

The Hard Problem                                                      in a manner which reflects the interests of the system as a
Initially, it might not be clear that the above satisfactorily        whole. People ‘feel’ the effect of being burned because the
addresses the hard problem of consciousness, which                    compression carried out by their brain reflects an
Chalmers (1995) identifies as the question of why                     understanding of what it feels like to be burned. In contrast,
consciousness feels like anything at all. In order to tackle          no matter how many times you burn a chair, it will never
this question, let us consider the case of an assembly of             react any differently.
coordinated neurons (or, indeed, logic gates) called Amy. If
we observe Amy’s behavior over time, we will notice                   Artificial Consciousness
considerable redundancy in her actions. We can compress               The consciousness conjecture suggests that any system that
Amy’s behavior through the succinct hypothesis of a core              carries out compression can be considered conscious to
centralized self which is motivating her actions and which            some extent. However, it should be noted that no known
feels experiences. But this is just an abstract hypothesis            system is capable of matching or even approaching the
based on a dataset: why should the formation of a                     depth of compression carried out by the organic brain.
hypothesis result in experience? The answer to this question              Although computer algorithms such as Lempel-Ziv and
lies in the realization that the hypothesis of Amy’s                  BZip2 are used to compress files and text, these programs
subjective experience is a hypothesis which Amy herself               simply skim through data looking for trivial redundancy.
holds, an understanding which is manifested through the               Such compressors cannot realistically be described as
compression she carries out. Understanding the hypothesis             ‘understanding’ text because the only patterns they can
that one is feeling something and the actual experience of            identify are based on simple statistical repetitions of
feeling are the same thing. Amy’s feeling therefore exists            symbols. In contrast, when people read a book they can
relative to the assumption of her own existence, an                   ‘explain’ the text in terms of an underlying narrative derived
assumption which the system itself is capable of making.              from their own experiences of the world, a feat which
                                                                      involves a much deeper level of compression.
                     Conscious Systems                                    Nevertheless, there is no theoretical obstacle that would
                                                                      prevent consciousness from being implemented in an
Algorithmic information theory makes clear predictions
                                                                      artificial medium. Any system that is arranged and updated
regarding what systems are conscious: objects which carry
                                                                      in a way which allows for the compression of information
out compression are conscious, all other objects are not. Let
                                                                      will support consciousness, be it implemented in windmills,
us consider a chair. Intuitively, we would not expect a chair
                                                                      beer cans or toilet rolls. Although toilet rolls take up a lot
to be conscious. Can this intuition be justified by the
                                                                      more space and interact a lot more slowly, they can be
compression conjecture?
                                                                      arranged in such a manner so as to perfectly replicate the
    Chairs do not carry out compression. They do not source
                                                                      compression carried out by neurons in the brain.
sensory information from multiple locations and process it
                                                                          Of course, the idea that a conscious being could be
in parallel. They do not store memories to enhance future
                                                                      implemented in toilet rolls is very unsatisfactory. Such an
compression. And they do not develop a theory of self by
                                                                      implementation exacerbates the hard problem of reconciling
compressing their own actions. Therefore they are not
                                                                      a clearly reducible system with the feeling of intuitively
conscious.
                                                                      irreducible experiences. One might ask: where does the
    Imagine holding a flame to the leg of a chair. The flame
                                                                      consciousness reside? In this case the consciousness is not a
leaves a black mark, therefore the chair has certainly been
                                                                      property of any particular toilet roll. Rather, it is a property
affected by the flame. But intuitively, it does not seem
                                                                      of the toilet roll system as a whole. Just like the behavior of
reasonable to claim that the chair has experienced the flame.
                                                                      a human, the output of the toilet roll system exhibits deep
This difference between effect and experience is directly
                                                                      redundancy which can be effectively compressed through
related to compression: specifically, the chair fails to
                                                                      the hypothesis of a single centralized ‘self’. In particular, the
experience the flame because the information it provides is
                                                                      toilet roll system is itself aware of this hypothesis, and uses
not compressed in any way. If a chair’s leg is burned it has
                                                                      the theory of selfhood to guide its processing. The
no effect on any of the other legs. No information is
                                                                      consciousness of the system therefore resides in its capacity
communicated, and consequently there is no inter-leg data
                                                                      to understand (i.e. compress) what it senses, thereby
compression to bind the experiences of the chair together.
                                                                      identifying itself as an entity separate to its environment.
Furthermore, the chair stores no memory (other than a black
mark). The burning event has no effect on how subsequent
events are processed, meaning that the experiences of the                          The Location of Consciousness
chair are not bound together across time. Finally, because            Thus far, we have used the term ‘compression’ without
the chair does not compress its own response to the flame, it         describing precisely how compression can be identified in
has no awareness of any subjective experience.                        the brain. Where is it to be found? Intuitively, people
    In contrast, if a flame is held to the leg of a human, it has     assume that conscious experience must be drawn together at
an immediate effect on how information from all other parts           a single point, an idea which Dennett (1991) derisively
of the body is processed. The brain also stores a memory of           refers to as the ‘Cartesian theatre’. However, brain imaging
being burned, thus altering the individual’s future behavior          studies indicate that cognitive processing is widely
                                                                  751

distributed and does not appear to be bound at any particular       computes T(A). If T(A) = 1 it then outputs 1 – T(x), which is
point in space or time (Zeki, 2003).                                the opposite of T, while if T(A) = 0 it then outputs T(x),
    Although intuition might suggest the need for a                 which is the same as T. In other words, the machine A
Cartesian theatre, it is important to note that the                 checks to see whether T recognizes it as being equivalent or
evolutionary demands which have shaped the brain’s                  not. If T recognizes A as being equivalent then A proceeds to
structure have not required information processing to be            do the exact opposite, making it not equivalent to T.
integrated in this way. The only moment that the brain is           However, if T does not recognize A as being equivalent then
required to bring information together is when some action          A produces the same output at T, making it equivalent to T.
must be elicited; furthermore, only data relevant to that           There is no way around this obstacle (see Rice’s theorem;
action needs to be integrated. Outside of this constraint,          Rice, 1953). Since no system can recognize an equivalent
processing can remain distributed in space and time, with no        system from within itself, developing a complete theory of
impact on the success of the organism.                              consciousness is not possible: the more precisely a theory
    Accordingly, external time and ‘conscious time’ need            attempts to define the conscious structure of the brain, the
not be synchronized to any greater extent other than to             less feasible it will be to validate it.
facilitate the undertaking of action when required. However,             The unrecognizability of the self has important
conscious observers have no possible means for observing            implications for how we think about ourselves. For instance,
any distribution in their consciousness relative to the             we can never know who we really are; we can never fully
environment: whenever they act on their surroundings the            explain our actions; we can never be certain as to what we
appropriate information processing is pulled together ‘just in      are going to do next. In effect, the self is a helpless observer
time’. Since it always appears to the observer as if they are       carried along by the compression going on in the brain. Of
embodied at a particular point in space and time, this leads        course, one feels like one is directing one’s own actions
them to mistakenly assume that their consciousness must be          because, as far as one is aware, one is. According to the
brought together at a single point in the brain, giving rise to     compression conjecture, the model of the self is simply an
the Cartesian theatre fallacy.                                      explanatory mechanism that the brain uses to explain and
                                                                    predict its own behavior. As a result, the actions of the brain
How Does the Brain Create Consciousness?                            cannot help but be consistent with those of the self (see
One of the goals of consciousness research is to identify           Gazzaniga, 1992). However, it is the activity of the brain
how it is created in the brain: which neural structures             which defines the nature of the self, rather than the other
support consciousness and which are merely superfluous              way around. Are you controlling your own actions?
biological apparatus? Using elementary computability                Certainly, but at the same time you can never know who you
theory we will prove that, if the compression conjecture            is.
holds, then the goal of identifying a complete theory of
consciousness is unattainable.                                                      Measuring Consciousness
    Let us imagine that somebody someday submits a theory           If, as the compression conjecture supposes, consciousness is
which offers a full description of how the brain produces           equivalent to data compression, then it should be possible to
consciousness. The theory is complete, meaning that it is           measure consciousness by quantifying the amount of
capable of identifying precisely which structures in the brain      compression that a system is capable of. The formal
give rise to consciousness, separating the conscious part           measure of compression is logical depth (see Bennett,
from the non-conscious meat. Now, of course, the reviewers          1988). Bennett's idea is that objects can be trivial, random or
wish to check that the theory is correct. Accordingly, they         deep. Trivial objects, being completely predictable, contain
apply the theory to their own brain activity to see whether         no useful information; random ones, being completely
the predictions match their experience. However, this raises        unpredictable, do not contain any useful information either.
the question: are the reviewers able to define their own            In contrast, objects that are neither random nor trivial are
consciousness, as required to validate the theory? Is it            called deep objects, because they support deep compression.
possible for a system to define its own self? In fact,                   Deep objects are useful because they provide a store of
computability theory rules this out, meaning that a complete        mathematical work, allowing associated data to be
theory of consciousness is not possible.                            compressed far more efficiently than can be achieved using
    According to the compression conjecture, the                    shallower tools. Indeed, Bennett’s (1988) theory implies that
recognition of one’s own consciousness involves the                 the concepts of ‘depth’ and ‘intelligence’ are equivalent,
identification of a structure which carries out the same form       since the facilitation of compression that depth provides
of compression. We can therefore present the problem                cannot be replicated by alternative means. Of all known
formally in terms of a Turing machine which is capable of           objects, the human brain is the deepest, representing the
recognizing a program with the same input-output                    stored mathematical work of decades of active cognitive
relationship. Consider a Turing machine T which takes input         processing on top of billions of years of evolution. The brain
x and outputs 1 if L(T) = L(x) (i.e. the languages recognized       relies on its depth to mitigate the physical limitations on
by T and x) and 0 if L(T) ≠ L(x). Is such a machine possible?       information processing imposed by its biological structure,
    The machine T is not consistent. We can imagine                 such as limited storage capacity, processing speed and
another machine A which takes input x. The machine A first
                                                                752

susceptibility to degradation. The complexity of its structure        associated with consciousness. It explains why
allows people to effortlessly identify patterns which                 consciousness is not amenable to scientific description. It
continue to elude the most advanced artificial intelligence           explains what we mean by ‘the self’ and why brains provide
programs.                                                             self-awareness. It explains the apparent paradox of
                                                                      experiencing a singular perspective in a brain which carries
The Turing Test                                                       out distributed processing. It predicts what systems are
Turing (1950) suggested that if a computer, through a                 conscious and what systems are not; it reveals that a
textual interface, can successfully convince a human judge            complete theory of consciousness is not possible. It tells us
that it is human, then it should be considered equal in               how to identify consciousness and it even provides a
intelligence to a human. However, the Turing test is not a            standard by which to measure consciousness.
reliable indicator of depth. Fooling a human judge is                     The compression conjecture does not require special
unlikely to require a deep program: a far simpler solution is         neuro-biological causal properties. It does not require
to exploit the weaknesses of human psychology.                        mysterious quantum fluctuations in micro-tubules. It does
    We propose an alternative test, involving compression,            not require an additional imperceptible dimension to the
on which it is not possible to cheat. Because of its                  universe. It does not require the actions of a divine being. In
complexity, natural language provides the ideal medium for            fact, it requires nothing except data compression.
testing compressor depth. People use complex linguistic
patterns to communicate with each other and assume that                                         References
other speakers are capable of compressing the words they              Bennett, C.H. (1988). Logical depth and physical
produce. If a computer system is as intelligent as a human,               complexity. In Herken, R., editor, The Universal Turing
then it should be capable of compressing language to the                  Machine: A Half-Century Survey, 227-258. Oxford:
same extent as a human.                                                   University Press.
    According to algorithmic information theory,                      Chaitin, G.J. (2007). The halting probability Ω: irreducible
compression can be quantified in terms of predictive                      complexity in pure mathematics. Milan Journal of
accuracy. For example, Shannon (1951) examined the                        Mathematics, 75, 291-304.
human-perceived entropy of English by asking people to                Chalmers, D.J. (1995). Facing up to the problem of
predict each letter in a document, one by one. The entropy                consciousness. Journal of Consciousness Studies, 2(3),
rate turned out to be less than 1 bit per letter. People are able         200-219.
to predict language because of the fact that they                     Chater, N. and Vitányi, P. (2003). Simplicity: A unifying
‘understand’ the text. In contrast, artificial compressors like           principle in cognitive science? Trends in Cognitive
BZip2 and Lempel-Ziv achieve much poorer levels of                        Sciences, 7(1), 19-22.
compression because they rely on predictable sequences of             Dennett, D. (1991). Consciousness Explained. Boston:
characters, without any regard for the deeper connections                 Little, Brown and Company.
between words, sentences and narrative. If a computer was             Gazzaniga, M.S. (1992). Nature’s Mind. London: Basic
genuinely as intelligent as a human, it would be capable of               Books.
matching the entropy rate of 1 bit per letter that Shannon            Li, M. & Vitányi, P. (1997). An Introduction to Kolmogorov
observed.                                                                 Complexity. New York: Springer.
    We propose that the compression test is far more reliable         Rice, H. G. (1953). Classes of recursively enumerable sets
and practical than the Turing test. For a start, there is no              and their decision problems. Transactions of the
way to cheat: by definition, deep processing cannot be                    American Mathematical Society, 74, 358-366.
reproduced by any means other than underlying depth (the              Schmidhuber, J. (2006). Developmental robotics, optimal
Slow Growth Law; see Bennett, 1988). It is also extremely                 artificial curiosity, creativity, music, and the fine arts.
quick and reliable: the probability of guessing the correct               Connection Science, 18(2), 173-187.
symbols decreases exponentially with the length of the test.          Shannon, C.E. (1951). Prediction and entropy of printed
While the Turing test is ambiguous and is affected by the                 English. The Bell System Technical Journal, 30, 50-64.
gullibility of the tester, the compression test is simple,            Solomonoff, R.J. (1964). A formal theory of inductive
rigorous, reproducible and provides an exact measure of                   inference. Information and Control, 7, 1-22.
intelligence by means of the relative entropy score.                  Tononi, G. (2008). Consciousness as integrated information:
                                                                          a provisional manifesto. Biological Bulletin, 215, 216-
                         Conclusion                                       242.
Intuitions regarding consciousness seem to create many                Turing, A.M. (1950). Computing machinery and
problems which have not been satisfactorily resolved (see                 intelligence. Mind, 59, 433-460.
Dennett, 1991). In contrast, the framework we have                    Wolff J.G. (1993). Computing, cognition and information
described here can explain many of the questions regarding                compression. AI Communications, 6(2), 107-127.
consciousness in an unambiguous and consistent manner.                Zeki, S. (2003). The disunity of consciousness. Trends in
    The compression conjecture explains why a brain that                  Cognitive Sciences, 7, 214-218.
evolved to optimize an organism’s behavior should be
                                                                  753

