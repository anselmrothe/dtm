UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Deconfounding Hypothesis Generation and Evaluation in Bayesian Models
Permalink
https://escholarship.org/uc/item/560667c9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Bonawitz, Elizabeth Baraff
Griffiths, Thomas L.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

        Deconfounding Hypothesis Generation and Evaluation in Bayesian Models
                                          Elizabeth Baraff Bonawitz (liz b@berkeley.edu)
                                                Department of Psychology, 5427 Tolman Hall
                                                           Berkeley, CA 94720 USA
                                         Thomas L. Griffiths (tom griffiths@berkeley.edu)
                                                Department of Psychology, 3210 Tolman Hall
                                                           Berkeley, CA 94720 USA
                               Abstract                                  as data are observed. However, the assumption that learners
   Bayesian models of cognition are typically used to describe
                                                                         possess all relevant hypotheses before seeing data is at odds
   human learning and inference at the computational level, iden-        with numerous findings suggesting that generating appropri-
   tifying which hypotheses people should select to explain ob-          ate hypotheses can be one of the hardest parts of inductive in-
   served data given a particular set of inductive biases. However,      ference (e.g., Kuhn, 1989; Klahr, Fay, & Dunbar, 1993). We
   such an analysis can be consistent with human behavior even
   if people are not actually carrying out exact Bayesian infer-         thus consider the consequences of separating the processes of
   ence. We analyze a simple algorithm by which people might             generating hypotheses and evaluating those hypotheses, as-
   be approximating Bayesian inference, in which a limited set of        suming that learners perform Bayesian inference with only
   hypotheses are generated and then evaluated using Bayes’ rule.
   Our mathematical results indicate that a purely computational-        the set of hypotheses they generate.
   level analysis of learners using this algorithm would confound           To investigate this, we present a mathematical analysis of
   the distinct processes of hypothesis generation and hypothe-
   sis evaluation. We use a causal learning experiment to estab-         a simple algorithm in which hypothesis generation and evalu-
   lish empirically that the processes of generation and evalua-         ation are separated. This produces a surprising result: This
   tion can be distinguished in human learners, demonstrating the        algorithm results in behavior that can still be analyzed in
   importance of recognizing this distinction when interpreting
   Bayesian models.                                                      terms of Bayesian inference, but with a prior that conflates
                                                                         the plausibility of a hypothesis with the ease of generating
   Keywords: Approximate Bayesian Inference; Hypothesis
   Generation; Hypothesis Evaluation; Causal Learning                    that hypothesis. This result suggests that we should be cau-
                                                                         tious when interpreting the priors of Bayesian models esti-
                          Introduction                                   mated from behavioral data. Such priors will always reflect
Learning causal relationships, categories, and languages all             the inductive biases of human learners – those factors that
require solving challenging inductive problems, using lim-               lead people to select one hypothesis over another when both
ited data to assess underdetermined hypotheses. In the last              are equally consistent with the data. However, human induc-
decade an increasing number of papers have argued that peo-              tive biases can include components that result from processes
ple solving inductive problems act in ways that are consis-              at the algorithmic level, such as generating hypotheses.
tent with optimal Bayesian inference (e.g., Griffiths & Tenen-              To demonstrate the importance of taking into account
baum, 2005; Goodman, Tenenbaum, Feldman, & Griffiths,                    algorithmic-level factors in interpreting Bayesian models, we
2008; Xu & Tenenbaum, 2007). However, most of these                      present an experiment exploring the separability of hypoth-
analyses operate at what Marr (1982) termed the computa-                 esis generation and evaluation. In the task, we conduct a
tional level, using Bayesian inference to identify the hypothe-          causal learning experiment in which we manipulate the hy-
ses that an ideal learner with particular inductive biases would         potheses that people generate: by “priming” an appropriate
choose to explain the observed data. An important question               hypothesis, we increase the probability of people producing
for this approach is what learners are doing at the algorithmic          responses consistent with that hypothesis; however, when we
level: identifying the psychological processes by which learn-           employ a more standard Bayesian reasoning task, providing a
ers solve inductive problems, and understanding how these                set of hypotheses and asking participants to evaluate them, the
algorithms connect back to the computational level.                      effect of priming goes away. A computational-level analysis
   Connecting the algorithmic and computational levels in-               would require postulating different prior distributions in or-
volves two challenges: identifying algorithms that can pro-              der to explain behavior on these two components of the task.
duce behavior consistent with Bayesian inference, and deter-             However, an algorithmic-level analysis shows that this differ-
mining how the assumptions of a computational-level analy-               ence can be explained as the result of the separate effects of
sis relate to the components of these algorithms. In this pa-            hypothesis generation and evaluation. Finally, we discuss the
per, we take up these two challenges for one class of algo-              implications of this work for future models of human cogni-
rithms for inductive inference. The most naı̈ve translation of           tion and for studies of developmental changes.
Bayesian inference into an algorithm for inductive inference
would be to assume that learners implement Bayes’ rule di-                           Analyzing inductive inferences
rectly, having a fixed set of hypotheses and updating a proba-           Bayesian inference indicates how a rational learner should
bility distribution over all of those hypotheses simultaneously          change his or her beliefs about a set of hypotheses in light
                                                                     2260

of observed data. Let h be a hypothesis belonging to a set           et al., 1993). Hypotheses can be generated in many differ-
of hypotheses H . Assume that the learner has different de-          ent ways, including detecting cues from context, recognizing
grees of belief in the truth of these hypotheses, and that these     similarities to previous experiences, and making analogies to
degrees of belief are reflected in a probability distribution        other domains (e.g., Gick & Holyoak, 1980; Gentner, 2002;
p(h), known as the prior. Then, the degrees of belief the            Nersessian, 1992; Koslowski, 1996). We will not attempt to
learner should assign to each hypothesis after observing data        model these processes here, but for our purposes, it is suffi-
d are given by the posterior probability distribution p(h|d)         cient to assume that the result of all of these processes can be
obtained by applying Bayes’ rule                                     summarized in a single probability distribution over hypoth-
                                                                     esis spaces. Using this probability distribution, q(H ∗ ), we
                                 p(d|h)p(h)                          define the Generate-Evaluate (GE) algorithm for Bayesian
                 p(h|d) =                                    (1)
                            ∑h0 ∈H p(d|h0 )p(h0 )                    inference with a reduced hypothesis space:
                                                                     Step 1: Generate Sample a reduced hypothesis space
where p(d|h) indicates the probability of observing d if h
were true, and is known as the likelihood.
                                                                     H ∗ ⊆ H from the probability distribution q(H ∗ ).
   Bayes’ rule provides a computational-level theory of in-          Step 2: Evaluate Evaluate the hypotheses in the reduced
ductive inference, being a component of the optimal solu-            hypothesis space H ∗ by applying Bayesian inference, using
tions to a variety of problems of reasoning under uncer-             a prior distribution on H ∗ proportional to the prior on the full
tainty (Anderson, 1990; Anderson & Schooler, 1991; Free-             hypothesis space H . Using p(h) to denote the prior on the
man, 1994; Geisler, Perry, Super, & Gallogly, 2001; Griffiths        full hypothesis space, as in Equation 1 we obtain the reduced
& Tenenbaum, 2007; Huber, Shiffrin, Lyle, & Ruys, 2001;              posterior distribution
Knill & Richards, 1996; Körding & Wolpert, 2004; Shiffrin
& Steyvers, 1997; Weiss, Simonvelli, & Adelson, 2002). As                                                  p(d|h)p(h)
                                                                                      p∗ (h|d) =                                     (2)
an account of inductive inference, the prior p(h) captures the                                       ∑ h0 ∈H ∗ p(d|h0 )p(h0 )
inductive biases of the learner, indicating which hypothesis a
learner will favor when multiple hypotheses are equally con-         for h ∈ H ∗ , with all other hypotheses receiving a posterior
sistent with the observed data (ie. which hypothesis will have       probability of zero. Because we are only sampling a subset
higher probability when multiple hypotheses have equal like-         of hypotheses, those that are not sampled will never be con-
lihood). This account is attractive in that it can potentially       sidered.
allow us to identify the inductive biases of human learners,
comparing different Bayesian models to find an appropriate           Mathematical analysis
prior. However, as we show in the remainder of this section,
one should be cautious in interpreting such a prior: Consid-         Having defined an algorithm that takes into account the pro-
ering algorithms by which people might be making inductive           cess of hypothesis generation, we can now analyze the con-
inferences shows that multiple processes can be reflected in a       sequences of using this algorithm. We have two questions of
prior estimated from behavioral data.                                interest. First, will a learner using the GE algorithm produce
                                                                     behavior that appears to be consistent with Bayesian infer-
Inferences with a reduced hypothesis space                           ence? Second, how does the process of hypothesis generation
As a computational-level theory of inductive inference,              influence the interpretation of the resulting Bayesian model?
Bayesian models make no commitments about the psycholog-             We can answer both of these questions for a special case of
ical mechanisms by which people actually learn and reason.           this algorithm by exploiting its relationship to a Monte Carlo
The most naı̈ve interpretation of experiments demonstrating          method known as importance sampling.
that people produce behavior consistent with Bayesian infer-            Monte Carlo methods are a class of algorithms that are
ence is that people are actually computing Bayes’ rule in their      used to approximate probabilistic computations by substitut-
heads. There are many reasons why such an algorithm is im-           ing samples from a probability distribution for the distribution
plausible, not least the requirement that people have all rele-      itself. For example, if we wanted to perform computations
vant hypotheses available whenever they make an inductive            involving a distribution p(x), we could instead substitute a
inference. However, this naı̈ve algorithm provides a good            set of m values x1 , . . . , xm drawn from p(x), each with weight
starting point for exploring the consequences of different psy-      1/m. Importance sampling is a Monte Carlo method that
chological processes that could play a role in inductive infer-      takes this one step further, substituting samples from another
ence. Here we explore the consequences of modifying one              distribution (the surrogate distribution) for samples from the
aspect of this algorithm: rather than considering all possible       target distribution (for details, see Neal, 1993). Thus, if we
hypotheses in the hypothesis space, considering only a subset        wanted to perform computations involving p(x), we would
of these hypotheses.                                                 generate a set of samples x1 , . . . , xm from the surrogate distri-
   Research in inductive inference and scientific reasoning          bution q(x). We can get away with doing this if we no longer
has shown that hypothesis generation is a challenging compo-         assign those samples equal weights. Instead, we give each
nent of solving inductive problems (e.g., Kuhn, 1989; Klahr          sample xi a weight proportional to p(xi )/q(xi ). The approxi-
                                                                 2261

mation to p(x) is thus                                                  therefore lead to counter-intuitive results where we need to
                                                                        use different priors to explain behavior across contexts where
                                   p(xi )/q(xi )                        all that differs is the ease in which hypotheses are generated.
                       p∗ (x) =                                 (3)
                                ∑mj=1 p(x j )/q(x j )
                                                                        Generation and evaluation in human inferences
for xi ∈ {x1 , . . . , xm }, and zero otherwise. Intuitively, the
                                                                        Our analysis assumes that the spontaneous generation of hy-
weights proportion to p(xi )/q(xi ) reflect the “importance” of
                                                                        potheses can be separated from the evaluation of a given hy-
each sample. If xi is more probable under q(x) than p(x), it
                                                                        pothesis. Thus, if the analysis is correct, generation and eval-
will be over-represented in the sample, and thus should re-
                                                                        uation should be separable components of human inductive
ceive lower weight. If xi is more probable under p(x) than
                                                                        inference. If a learner does not sample the correct hypoth-
q(x), there will be fewer such values than there should be,
                                                                        esis, she will never consider it and thus cannot evaluate it;
and it receives higher weight to compensate. This yields an
                                                                        however, if a hypothesis is given to her (e.g., supplied by an
asymptotically unbiased approximation to probabilistic com-
                                                                        experimenter), she should be able to evaluate the hypothesis
putations involving the target distribution, provided certain
                                                                        just as if she generated it herself. We can empirically explore
constraints are observed (for example q(x) has to be greater
                                                                        whether confounding generation and evaluation is a problem
than zero wherever p(x) is greater than zero).
                                                                        for Bayesian models in practice.
   Importance sampling gives us the tools we need to analyze
                                                                           Testing the assumption that generation and evaluation are
the GE algorithm. If we assume that the samples are drawn
                                                                        separable requires finding a task that allows us to manipulate
independently, with q(H ∗ ) = ∏h∈H ∗ q(h), then the GE algo-
                                                                        the ease of generating different hypotheses. Previous work
rithm is an importance sampler for the target distribution
                                                                        suggests that priming of a hypothesis can help people solve
                             p(d|h)p(h)q(h)                             complex reasoning tasks. For example, Schunn and Dunbar
                                                                (4)     (1996) found that even though participants do not sponta-
                         ∑h∈H p(d|h)p(h)q(h)
                                                                        neously make an explicit analogy between domains, knowl-
which is the posterior distribution obtained when using a prior         edge from one domain can influence reasoning in the other.
proportional to the product of p(h), the prior on the original          Encouraged by this finding, we predicted that participants
hypothesis space, and q(h), the probability of generating that          should generate different samples of hypotheses if primed
hypothesis. It is straightforward to check that this is the case:       differently. Priming hypotheses would thus modify the prob-
if we approximate the distribution given in Equation 4 using            ability of generating those hypotheses, q(h). However, such
q(h) as the surrogate distribution, then we should generate             priming should not affect the evaluation of hypotheses pro-
a reduced hypothesis space H ∗ by sampling from q(h) and                vided for a learner.
then assign each sampled hypothesis a weight proportional to               In order to test whether the processes of generating and
p(d|h)p(h)q(h)/q(h) = p(d|h)p(h). This is exactly the pro-              evaluating hypotheses are separable, we designed a priming
cedure followed in the GE algorithm, with Equation 2 being              task and a two part causal learning experiment. Prior to the
equivalent to Equation 3.1                                              causal learning experiment, half the participants read a vi-
   This analysis answers our two questions about the GE al-             gnette that primed them to think about the correct causal rule;
gorithm. First, it shows that a learner using this algorithm will       the other half of the participants were given a “neutral” vi-
still produce behavior consistent with Bayesian inference, al-          gnette. In the causal learning experiment, participants were
beit with a modified prior. Second, it indicates how the pro-           given experience with sets of blue blocks (individuated by a
cess of hypothesis generation affects behavior: If we estimate          letter on the block) that sometimes lit up when they inter-
a prior by assuming people are performing Bayesian infer-               acted with each other. In the first part of the causal learn-
ence, that prior will reflect both the a priori plausibility of         ing experiment, as participants encountered data, they were
hypotheses, p(h), and the probability of generating those hy-           asked to make predictions about the result of new block inter-
potheses, q(h). One needs not consider q(h) when hypotheses             actions2 , and following all evidence, participants were asked
are provided to the learner to evaluate, and thus no generation         to describe the rule they had discovered that best captured
is required. However, the analysis indicates that we should be          the pattern of lighting/nonlighting blocks. The actual rule by
careful in interpreting priors estimated using Bayesian mod-            which evidence was generated was a “rank order” rule, which
els: if we do not take algorithmic processes into account,              meant that a latent feature of “block strength” dictated which
hypothesis generation and evaluation are confounded. This               blocks could light others. The evidence was ambiguous such
can be problematic, as processes that change the way people             that the rule was not immediately obvious, but still potentially
generate hypotheses, such as priming a particular hypothe-              discoverable. In the second part of the causal learning ex-
sis, will influence the distribution q(h) and hence the esti-           periment, participants completed a more standard task, tradi-
mated prior, without influencing the plausibility of a hypoth-          tionally taken as reflecting the posterior in Bayesian learning
esis p(h). Critically, ignoring the algorithmic level could             paradigms; participants were given several rules and asked
    1 Technically, we also require that H ∗ be a multiset, allowing         2 The block task was inspired by a similar method used by
multiple instances of the same hypothesis.                              Tenenbaum and Niyogi (2003).
                                                                    2262

to evaluate the degree to which each rule seemed plausible,
given the blocks’ interactions previously demonstrated in the
learning phase.
   Note that because the participants are required to discover
the correct causal rule in the first part of the causal learning
experiment, their ability to produce the correct predictions
and the correct description require both steps of the GE algo-
rithm: the subjects must generate a set of possible hypotheses
and evaluate those hypotheses to discover the causal rule that
best captures the observed data. In contrast, the second part
of the causal learning experiment requires only evaluation,
because the set of possible hypotheses is already provided for
the participant. If generation is an important factor in deter-
mining people’s inferences, we should observe a difference
between the two parts of the experiment, and in particular,                  Figure 1: Example page from experiment booklet.
a difference in participants’ sensitivity to the prime manip-
ulation. Specifically, if the prime affects only generation, it
should only affect participant responses in the first part of the     height. The text read, in its entirety: “Teachers at an ele-
experiment: participants given a strong prime should be more          mentary school taught their students a game for two children
likely to generate the correct hypothesis than participants who       to play. They observed the results of pairs of students play-
are given a weak prime, but strong prime and weak prime par-          ing the game and tried to come up with a way to predict (for
ticipants should be equally likely to correctly rate the expla-       any given pair of students) who was going to win the game.
nations provided to them in the second part of the experiment         At first it was difficult for the teachers to notice anything
because this task only requires evaluation and does not re-           that would help them correctly predict the outcomes of the
quire generation. However, if the prime affects other things,         games. Then the teachers started organizing the children by
like the prior, it will affect both parts of the experiment: the      the height of the children and the pattern of results quickly
strong prime participants should not only be more likely to           became apparent. The teachers were able to use the height
generate the correct causal explanations in the first part of the     of the children and make very accurate predictions as to who
experiment, but they should also be more likely than the weak         (for any given pair of students) was going to win the game.”
prime participants to provide a higher rating of the provided,        The Neutral Prime vignette was identical, except that instead
correct explanation in the second part of the experiment.             of organizing the children by height, children were organized
                                                                      by the shirt color. Shirt color was chosen because pilot work
Methods                                                               suggested that numerous possible orderings may be plausi-
                                                                      ble (e.g. sorting by the color wheel; bold colors vs. neutral
Participants and Design Participants were 40 undergradu-              colors; arranging from lightest to darkest colors, etc.), and
ates from the University of California, Berkeley who partic-          thus the primed causal rule was somewhat arbitrary. Follow-
ipated either for pay or for course credit. Participants were         ing the vignettes, participants were asked to respond to two
randomly assigned to either a Strong Prime or Neutral Prime           simple questions about the story on the back of the sheet.
condition. About half the participants completed an unrelated             Causal Learning: In the first part of the causal learning
experiment prior to completing this experiment.                       task, participants saw sets of blue blocks (individuated by a
                                                                      letter on the block) that sometimes lit up when they interacted
Stimuli The Strong and Neutral Prime vignettes were given
                                                                      with each other. The actual rule, unbeknownst to the partici-
to participants on a single sheet of paper with instructions.
                                                                      pants, was that the blocks could be ordered by “strength” with
The target experiment included six small (6cm × 6cm) card-
                                                                      the “stronger” blocks always causing the “weaker” blocks to
board cutouts that the participants could manipulate as they
                                                                      light (i.e. a variable like “height” given in the Strong Prime
completed the task and a 12 page booklet that included in-
                                                                      vignette, that would result in causal relations following a rank
structions, descriptions of the blocks, and sections to write in
                                                                      order3 ). As participants encountered data, they were asked to
answers (see Figure 1).
                                                                      make predictions about the result of new block interactions
Procedure The procedure involved a priming stage and a                (“Will this block light? Yes or no?”) and provided confi-
two part causal learning task, we outline each in turn.               dence ratings on a scale of 1 to 7 (see Figure 1). Follow-
   Priming: Participants were first given an “unrelated” sur-         ing all evidence, participants were asked to describe the rule
vey, which included a vignette about teachers watching chil-          they had discovered that best captured the pattern of light-
dren interacting on a playground and learning about rules that
                                                                          3 Pilot work suggested that causal relations that follow a rank-
governed which children would win a game. In the Strong
                                                                      order (e.g. dominance hierarchy) are not immediately obvious, but
Prime condition the story suggesting that the rule govern-            still potentially discoverable to participants, following suggestive
ing which children would win was related to the childrens             evidence.
                                                                  2263

ing/nonlighting blocks and whether they could organize the           participants were not able to generate the correct rule on their
blocks to best capture the rule.                                     own, they were perfectly able to evaluate the good and bad
   In the second part of the causal learning task, participants      explanations, being more likely to rate the correct explana-
were asked to evaluate four different explanations describing        tion higher than the incorrect explanations.
how the blocks should interact. Two explanations captured
some, but not all of the data (e.g. “The blocks can be or-                                     Discussion
ganized into two groups: blocks s, k, & m have the power             Connecting the computational and algorithmic levels is a sig-
to light up the other blocks (y, w, & g). Blocks in the same         nificant challenge for Bayesian models of cognition. We have
group do not light each other.”) One explanation was nonde-          shown that considering the algorithms by which people might
scriptive: “The blocks can not be organized. They will light         perform inductive inference can provide insight into how dif-
or not light randomly, but only one block can be lit at a time.”     ferent psychological processes influence the conclusions that
And the final explanation was the target explanation, which          we can draw when using Bayesian models. Mathematical
correctly described the data: “The blocks can be organized           analysis of a simple algorithm in which learners first gen-
by ‘strength’. The stronger blocks will light the weaker ones.       erate and then evaluate hypotheses indicates that while the
Strongest s k m y w/g Weakest”. Participants rated the expla-        resulting behavior is still consistent with Bayesian inference,
nations on a scale from 1 (“not good”) to 7 (“very good”).           estimation of a prior distribution from this behavior will con-
                                                                     found the probability of generating a hypothesis and its a pri-
Results                                                              ori plausibility.
Data were coded by the first author and reliability coded by            The responses of participants in our experiment provide
a research assistant blind to condition and hypothesis out-          some empirical support for the assumptions behind our anal-
comes. Explanation generation responses were labeled as              ysis: While priming influenced whether participants could
“correct” or “incorrect”. Agreement was 98%; the single dis-         generate the correct explanation, it did not affect participants
agreement was resolved conservatively with respect to pre-           ability to correctly evaluate explanations that were provided.
dictions. Two participants were excluded and replaced for            That is, one interpretation of our results is that the prime af-
failing to provide a sensible response to the comprehension          fected the distribution q(h) from which hypotheses are gener-
questions. Otherwise, all participants completed the compre-         ated, but it did not affect the prior probability of any particu-
hension questions for the priming vignettes.                         lar hypothesis p(h), since there were no differences between
   Results confirmed that the ability to generate a hypothesis       conditions when participants were asked to evaluate hypothe-
is separate from the evaluation of hypotheses. As predicted          ses that were provided to them. In the remainder of the paper,
by Bayesian inference, there were no differences in evalu-           we consider some of the implications of these results and di-
ating the hypotheses between conditions: Both the Strong             rections for future work.
Prime and Neutral Prime participants readily rated the cor-
rect explanation equally likely: (Strong: 5.3; Neutral: 5.6;         Errors and approximations
t(38) = .48, p = ns), and both groups ranked it well above           Approaching inductive inference from the algorithmic level
the other (incorrect) provided rules (Strong: 2.8; Neutral: 3.0)     results in additional implications and predictions that may be
(Wilcoxon Signed-Rank: Strong, z = 3.07, p = .001; Neutral,          valuable to explore in future work. For example, the algo-
z = 3.60, p < .001) (Figure 2). However, there was a sig-            rithmic approach taken in this paper offers some reconcilia-
nificant effect of condition: Participants in the Strong Prime       tion between computational level theories that suggest peo-
condition were significantly more likely to answer the pre-          ple are carrying out rational inference, with approaches that
diction questions correctly (Wilcoxon Signed-Rank: w = 45,           show people performing in seemingly “irrational” ways, such
p < .01; Figure 2a) and were more likely to generate the cor-        as not coming to the correct conclusion despite unambigu-
rect rule, Pearson χ2 (N = 40, 1) = 3.6, p = .058. 65% of the        ous or compelling evidence. By suggesting that people may
participants in the Strong Prime condition provided the cor-         be approximating rational inference by sampling a subset of
rect hypothesis, whereas only 35% of participants in the Neu-        hypotheses, these failures of inductive inference can be ex-
tral Prime condition generated the correct hypothesis (Figure        plained as the result of not generating appropriate hypothe-
2b). That is, even though participants in the Neutral Prime          ses.
condition were able to correctly evaluated the rules when they          This makes predictions about the factors that should influ-
were provided, they were not necessarily able to generate the        ence the errors that people make in inductive inference. For
correct rule from the evidence alone.                                example, as the hypothesis space becomes large, the prob-
   We also looked at participant explanation ratings with the        ability of sampling the correct hypothesis decreases. Thus,
dependent factor being whether or not the participant gener-         we should observe a trade-off between the size of the space
ated the correct prediction on their own. Participants who           and the probability of generating the correct explanation.
did not generate the correct rule on their own still provided a      Similarly, if cognitive limitations are imposed (for exam-
significantly higher rating to the correct explanation (mean =       ple increasing participant computational load, with additional
4.9) than to the incorrect explanations (mean = 3.3)(Wilcoxon        tasks) then the set size of samples generated should decrease,
Signed-Rank: z = 2.63, p < .01). That is, even though these          and thus decrease the probability of generating the correct
                                                                 2264

Figure 2: (a) Participants’ responses to the final four prediction questions in the Neutral and Strong Prime conditions. (b)
Percentage of participants who generated the correct explanation. (c) Average rating (1 weakest - 7 strongest) of the provided
explanations by participants in both conditions.
sample. It may also be valuable to explore these questions in               based reasoning: Science, technology, values. New York, NY:
a developmental setting, examining how changes in informa-                  Kluwer Academic, Plenum Publisher.
                                                                          Gick, M., & Holyoak, K. (1980). Analogical problem solving. Cog-
tion processing capacity influence the conclusions that chil-               nitive Psychology, 12, 306-355.
dren reach.                                                               Goodman, N., Tenenbaum, J., Feldman, J., & Griffiths, T. L. (2008).
                                                                            A rational analysis of rule-based concept learning. Cognitive Sci-
Conclusion                                                                  ence, 32:1, 108-154.
                                                                          Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and strength
Bayesian models of cognition provide a computational-level                  in causal induction. Cognitive Psychology, 51, 354-384.
account of inductive inference. Here, we have presented an                Griffiths, T. L., & Tenenbaum, J. B. (2007). Two proposals for
analysis that shows how taking an algorithmic-level approach                causal grammars. In A. Gopnik & L. Schulz (Eds.), Causal learn-
                                                                            ing: Psychology, philosophy, and computation. Oxford: Oxford
can allow us to tease apart two processes that are confounded               University Press.
in computational-level models: hypothesis generation and                  Huber, D. E., Shiffrin, R. M., Lyle, K. B., & Ruys, K. I. (2001). Per-
evaluation. We also present experimental results that suggest               ception and preference in short-term word priming. Psychological
                                                                            Review, 108, 149-182.
that these two processes are separable in human inductive in-             Klahr, D., Fay, A., & Dunbar, K. (1993). Heuristics for scientific
ference. Together, our analysis and empirical findings indi-                experimentation: A developmental study. Cognitive Psychology,
cate that we should take both the probability of generating a               25, 111-146.
                                                                          Knill, D. C., & Richards, W. A. (1996). Perception as Bayesian
hypothesis and its a priori plausibility into account when in-              inference. Cambridge: Cambrdige University Press.
terpreting prior distributions estimated using Bayesian mod-              Körding, K., & Wolpert, D. M. (2004). Bayesian integration in
els. More generally, these results illustrate that understanding            sensorimotor learning. Nature, 427, 244-247.
                                                                          Koslowski, B. (1996). Theory and evidence: The development of
human inductive inference will require working at both com-                 scientific reasoning. Cambridge, MA: MIT Press.
putational and algorithmic levels of analysis, and establishing           Kuhn, D. (1989). Children and adults as intuitive scientists. Psy-
the connections between them.                                               chological Review, 96, 674-689.
                                                                          Marr, D. (1982). Vision. San Francisco, CA: W. H. Freeman.
                                                                          Neal, R. M. (1993). Probabilistic inference using Markov chain
Acknowledgments. We thank Nannick Bonnel and Jason Martin                   Monte Carlo methods (Tech. Rep. No. CRG-TR-93-1). University
for assistance in data collection. This research was supported by the       of Toronto.
                                                                          Nersessian, N. (1992). How do scientists think? capturing the dy-
James S. McDonnell Foundation Causal Learning Collaborative and             namics of conceptual change in science. In R. Giere & H. Feigle
grant number IIS-0845410 from the National Science Foundation.              (Eds.), Minnesota studies in the philosophy of science. Minneapo-
                                                                            lis: Minnesota: University of Minnesota Press.
                            References                                    Schunn, C., & Dunbar, K. (1996). Priming, analogy, and awareness
                                                                            in complex reasoning. Memory & Cognition, 24:3, 271-284.
Anderson, J. R. (1990). The adaptive character of thought. Hills-         Shiffrin, R. M., & Steyvers, M. (1997). A model for recognition
   dale, NJ: Erlbaum.                                                       memory: REM: Retrieving Effectively from Memory. Psycho-
Anderson, J. R., & Schooler, L. J. (1991). Reflections of the envi-         nomic Bulletin & Review, 4, 145-166.
   ronment in memory. Psychological Science, 2, 396-408.                  Tenenbaum, J. B., & Niyogi, S. (2003). Learning causal laws. In
Freeman, W. T. (1994). The generic viewpoint assumption in a                R. Alterman & D. Kirsh (Eds.), Proceedings of the 25th annual
   framework for visual perception. Nature, 368, 542-545.                   meeting of the cognitive science society. Hillsdale, NJ: Erlbaum.
Geisler, W. S., Perry, J. S., Super, B. J., & Gallogly, D. P. (2001).     Weiss, Y., Simonvelli, E. P., & Adelson, E. H. (2002). Motion
   Edge co-occurrence in natural images predicts contour grouping           illusions as optimal percepts. Nature Neuroscience, 5, 598-604.
   performance. Vision Research, 41, 711-724.                             Xu, F., & Tenenbaum, J. B. (2007). Word learning as Bayesian
Gentner, D. (2002). Analogy in scientific discovery: The case of            inference. Psychological Review, 114, 245-272.
   johannes kepler. In L. Magnani & N. Nersessian (Eds.), Model-
                                                                      2265

