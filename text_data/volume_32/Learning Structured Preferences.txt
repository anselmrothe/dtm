UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Structured Preferences
Permalink
https://escholarship.org/uc/item/5b0767hd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Bergen, Leon
Evans, Owain
Tenenbaum, Joshua
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                            Learning Structured Preferences
                                     Leon Bergen1 , Owain R. Evans, Joshua B. Tenenbaum
                                                     {bergen, owain, jbt}@mit.edu
                                               Department of Brain and Cognitive Sciences
                                                    Massachusetts Institute of Technology
                                                            Cambridge, MA 02139
                              Abstract                                   that the principle of rationality is descriptively true, but rather
                                                                         that it is assumed by people’s intuitive theory of mind. These
   Learning the preferences of other people is crucial for predict-
   ing future behavior. Both children and adults make inferences         models treat the problem of preference learning as one of in-
   about others’ preferences from sparse data and in situations          verting the principle of rationality: in order to infer some-
   where the preferences have complex internal structures. We            one’s preferences from their behavior, consider what prefer-
   present a computational model of learning structured prefer-
   ences which integrates Bayesian inference and utility-based           ences would have made this behavior rational.
   models of preference from economics. We experimentally test
   this model with adult participants, and compare the model to             In the inverse-planning model of Baker, Tenenbaum, and
   alternative heuristic models.                                         Saxe (2007), the task is to determine which of several candi-
   Keywords: Theory of Mind; Bayesian Modeling; Prefer-                  date goals an agent desires on the basis of partial movements
   ence Learning                                                         towards those goals. The agent is assumed to have a rank-
                                                                         ing of the goals, from best to worst, and which of the goals
                           Introduction                                  is desired is inferred by assuming that the agent is moving
Children and adults are highly adept at inferring hidden men-            efficiently towards the desired goal. Using Bayesian infer-
tal states such as preferences from observed behavior. Work              ence, the model recovers a distribution over desired goals by
in developmental psychology has shown that by 18 months,                 supposing that a given goal makes efficient movement toward
children have learned that others have preferences which are             that goal highly likely. In this paper, there is a sophisticated
different from their own; moreover, they can infer these pref-           link between preference and behavior, but preferences them-
erences on the basis of observing several choices (Repacholi             selves have a simple structure.
& Gopnik, 1997). Further work has shown that children’s in-
                                                                            Lucas et al. (2009) again use a Bayesian model for in-
ferences are sensitive to the statistical properties of observed
                                                                         ference, but use a more sophisticated model for preferences.
choices, so that choices which are less likely a priori are more
                                                                         Instead of having preferences over outcomes, different pos-
likely to reflect strong preferences (Kushnir, Xu, & Wellman,
                                                                         sible object features have different utilities (are differentially
2008).
                                                                         preferred). Preferences over objects are given by a weighted
   Despite the ease with which people appear to reason about
                                                                         sum over the objects’ features. Agents are assumed to choose
others’ preferences, such reasoning is a highly challenging
                                                                         the object which gives them the maximal quantity of desirable
computational task. An individual’s preferences are never
                                                                         features.
fully determined by their past choices. Moreover, people have
to infer preferences on the basis of sparse data, perhaps only              These models were not intended to capture how prefer-
a few observed choices.                                                  ences might be learned when the goods being chosen between
   Our goal in this paper is to develop a computational model            have complex functional relationships. Suppose, for example,
of preference learning on the basis of sparse observations. In           that someone is choosing between a bicycle frame and bicy-
the spirit of Marr’s levels of explanation, we must first spell          cle wheels. It will not generally make sense to say that they
out the computational problem which has to be solved. In                 prefer the frame to the wheels, or vice-versa. Rather, they
this case, the problem has two parts. First, what exactly has            most likely want an entire bicycle, meaning that whether they
to be learned? Are an agent’s preferences simply a ranking               want the wheels will depend on whether they already have
of different choices, or do they have more internal structure?           a suitable frame. Any computational model of this situation
Second, how can these preferences be learned on the basis of             will have to account for this additional structure in the agent’s
observing an agent’s choices?                                            preferences.
Previous Work                                                               We combine the Bayesian modeling of Baker et al. and
Previous computational models of preference learning have                Lucas et al. with formal models of structured preferences de-
mostly focused on the second question. Central to these mod-             veloped by economists. We test our model experimentally
els is the principle of rationality, according to which people           by examining adult inferences in tasks that provide informa-
are rational agents whose behavior is directed towards satis-            tion about the interactions between goods. By systematically
fying their preferences. Crucially, these models do not claim            varying these interactions, we try to determine whether pref-
                                                                         erence learning is sensitive to the structure of the preferences
    1 The first two authors contributed equally to the paper             being learned.
                                                                    853

           Modeling Structured Preferences                                The Cobb-Douglas utility function is defined by:
Economists are interested in modeling agents who are choos-
ing between goods that can have a range of functional rela-                                  u(A, B) = Aα · B1−α                     (3)
tionships. They are also interested in modeling agents over
long spans of time, meaning that they have to account for                 As in the case of complements, the parameter α determines
how novel goods may interact with goods already possessed              the optimal ratio of the two goods. Unlike in the case of com-
by the agent. In order to model these interactions and effects         plements, additional units of a single good can still increase
of context, economists often will not assign utilities to indi-        utility without additional units of the other good. Crucially,
vidual goods, but rather to bundles of goods, where the bundle         there is diminishing marginal utility in each good, holding
(A, B) consists of A units of one good and B units of another          the other good fixed. In other words, each additional unit of a
good. Different interactions between goods in a bundle can             single good increases utility less and less, unless more of the
be captured by different utility functions on these bundles.           other good is added.
   We will be considering three kinds of interactions between             These utility functions are often the first introduced in mi-
goods, each of which is standard in economics (see, e.g.,              croeconomics textbooks, both because of their simplicity and
Mas-Colell, 1995). The first class of goods are known as sub-          because the structures which they encode are so common.
stitutes. Two goods will be substitutes if either can be used,         However, the space of possible utility functions and possible
independent of the other, to accomplish a single goal. For             interactions between goods is enormous (Mas-Colell, 1995).
example, two brands of cherry soda are substitutes for each            Though we will only be considering these three cases, our
other: if someone wants to drink cherry soda, they can sat-            model of preference learning, which we describe next, is
isfy that goal by drinking either brand. The second class of           compatible with any parameterized utility function.
goods are complements. These goods must both be used in a              Computational Modeling
specific proportion to accomplish a particular goal. Bicycle
wheels and a bicycle frame must be put together in a ratio of          Economists have supposed that individual preferences can
two to one in order to accomplish the goal of building a func-         be represented by the utility functions above and that agents
tional bicycle. The last class of goods will be described by           choose bundles with highest utility. By assuming that prefer-
a Cobb-Douglas utility function, which is presented below.             ences have this form, predictions can be made about choice
These goods perform some goal most effectively in a particu-           in unobserved situations, by computing the relevant utilities.
lar ratio, but can still perform the goal to some extent in other         On our model of human intuitive preference inference,
ratios as well. If someone wants to have a fun vacation, it            people’s intuitive inferences use the same representation of
may be best to spend some number of days on the beach and              preferences as economists—people are intuitive economists.
some number of days on a cruise, as an entire vacation on the          They can represent different utility function types, corre-
beach might get boring. However, additional days on either             sponding to the way goods interact in a particular situation.
the beach or the cruise will still improve the trip.                   For a given utility function type, they can represent different
   These interactions can be captured by three different utility       relations between the goods involved—e.g. that a particu-
functions on bundles of goods. If two goods are substitutes,           lar ratio of one good to another is optimal. Again following
then we can set:                                                       economics, we propose that people employ the principle of
                                                                       rationality, connecting preference to choice.
                   u(A, B) = α · A + (1 − α) · B               (1)        In order to model reasoning about agents’ choices in sit-
   where A is the quantity of the first good and B is the quan-        uations where the objects of choice interact with each other,
tity of the second good. The weight encodes how well each              we integrate the structured utility functions discussed above
of the goods serves its function. This equation says that we           with Bayesian inference and the principle of rationality. We
always get the same amount of utility out of an extra unit of          assume that the observed agent’s preferences over a given set
the first good, regardless of how much of the second good we           of objects is well-described by one of the utility functions dis-
have, and vice-versa. This is essentially the utility function         cussed above; which of the utility functions is appropriate in
used in Lucas et al., with A and B representing the quantities         a particular situation will depend on both the causal relations
of two different features.                                             between the objects and the agent’s goals. Whatever the util-
   For complements, we set the utilities of the two goods to           ity function of the agent, we assume that she is approximately
be:                                                                    rational and softly maximizes her utility. The probability of
                                                                       a choice given her utility function is therefore given by the
                 u(A, B) = min(α · A, (1 − α) · B)             (2)     Luce-Choice rule:
   Parameter α in this case determines the required propor-                                 P(c|u) ∝ exp(β · u(c))                   (4)
tions between the two goods. Once the goods are in their cor-
rect proportions, an additional unit of either good alone will         where u is the agent’s utility function, c is a choice, and β is
not increase utility. In order to increase utility, extra units of     a noise parameter that determines how close the agent is to
both goods have to be added.                                           rational. We set β equal to 15 throughout.
                                                                   854

   We do not attempt to model how an observer might deter-           that different functional relationships will lead to different
mine, before seeing any of an agent’s choices, which utility         patterns of preference across bundles of the same size. For
function the agent is using in a particular situation. Rather,       example, once you have two wheels for your bike, additional
we assume that the observer has a prior distribution P(u) over       wheels are worth very little, while after two days at the beach,
the possible utility functions which apply in the situation. For     further days might still be very desirable. To test this, we de-
example, we will not attempt to model how one might learn            signed scenarios for which the numerical properties of the
that bicycle wheels and bicycle frames are complements. In           bundles could be held fixed while the functional relationship
general, P(u) will depend on the observer’s prior knowledge          between the goods in the bundles was varied.
about the relations between the goods in question. The ob-
server is also given a prior P(α) for each utility function u        Methods
over the parameter alpha of the utility function. Throughout,        Participants Participants were 480 individuals on Amazon’s
we assume P(α) follows a Beta(2,2) distribution.                     Mechanical Turk who received a small compensation for their
   These assumptions allow us to use Bayesian inference to           time.
infer an agent’s utility function from her choices. Given ob-           Materials and Procedure As noted above, we designed
served choices C, the posterior over utility functions is given      three groups of scenarios: Substitutes, Complements and
by:                                                                  Cobb-Douglas. Scenarios differed across the groups in how
                     P(u|C) ∝ P(C|u) · P(u)                  (5)     the goods being acquired related functionally, and hence in
where u is the utility function with parameter α. This formula       which utility function models preferences for the goods in
inverts the generative model of the agent’s behavior captured        the scenario.
by her utility function and the Luce-Choice rule (Equation 4).          An example stimulus for the Cobb-Douglas group is the
From observed choices C, we can infer the probability of a           following:
novel choice c by averaging over the agent’s utility functions:
                            Z                                                Last year, John and his wife took a one-week va-
                  P(c|C) =     P(c|u)P(u|C)du                (6)        cation in the Caribbean. When John was booking the
                                                                        trip he had the choice between two package deals, which
Using the Luce-Choice rule to give the likelihood P(c|u), we            both cost the same amount:
recover the mixed multinomial logit model which is used in                   (A) 4 days on the beach and 2 days on a cruise
Lucas et al. as well as many papers in econometrics (McFad-                  (B) 3 days on the beach and 4 days on a cruise.
den & Train, 2000).                                                          John chose package (B) and thought that was the best
                                                                        choice given his options. This year John and his wife
                         Experiment                                     are planning another trip to the Caribbean. John needs
In the following experiment we test the quantitative predic-            to book the trip in advance. He has to decide between
tions of the structured preference learning model. We de-               two package deals. Both deals cost the same amount:
signed scenarios in which an agent chose between bundles                     (C) 5 days on the beach and 5 days on a cruise
of goods, with each bundle containing A amount of one good                   (D) 8 days on the beach and 2 days on a cruise.
and B amount of another good. In order to distinguish our                    Which option should John take?
model from previous utility-based models (Baker et al., 2007;
Lucas et al., 2009) we varied the functional relationship be-           As this example illustrates, the scenarios consisted of three
tween the goods described in the scenarios in order to match         parts: (1) setup of the first choice situation, (2) the agent
the three utility function types described above. Thus we            chooses one bundle of goods over another, and (3) the agent
constructed three separate groups of scenarios. In the Sub-          faces a new choice situation. Each scenario was shownin 16
stitutes Group, the two goods were substitutes for each other.       numerical conditions: these were the quantities of goods in
Hence, economists would model the preferences of an agent            each bundle in the two choice situations. In the example
over these goods using a substitutes utility function (Equa-         above, the bundle (3,4) was chosen over the bundle (4,2), and
tion 1). In the Complements Group of scenarios, the goods            participants were asked to choose between the bundles (5,5)
were complements for each other and so preferences over              and (8,2). In different numerical conditions, the quantities
them would be modeled by a complements utility function              in these bundles were varied. In pre-testing, we found that
(Equation 2). In the Cobb-Douglas Group, the goods were              participants were making inferences about the cost of each
related in the way described by Cobb-Douglas utility func-           bundle on the basis of bundle size; as a result, we subse-
tion (Equation 3).                                                   quently stated in each scenario that the bundles being cho-
   Our experiment aims to question whether people are intu-          sen from were the same price. Because this was incompatible
itive economists. That is, whether they recognize the func-          with one of the scenarios, it was removed from subsequent
tional relationship between goods in a particular scenario and       testing. This left a total of 11 scenarios: three in the Cobb-
model an agent’s preferences with a utility function over bun-       Douglas Group, four in the Substitutes Group, and four in the
dles of the goods that is appropriate to that functional rela-       Complements Group. Pre-testing also suggested possible or-
tionship. A key prediction of the theory from economics is           der effects in some of the numerical conditions, which were
                                                                 855

controlled in subsequent experiments. The scenarios were              Ratio Heuristic, except that instead of considering a range of
crossed with the numerical conditions, for a total of 11x16           possible ideal ratios, it treats the ratio of goods in the ob-
inference questions.                                                  served choice as ideal. The Max Heuristic assumes that one
   Participants each received five or six distinct scenarios; nu-     of the two goods is preferred, and that agents will always
merical conditions were randomized across participants.               choose the bundle that contains the greatest quantity of the
   If people are sensitive to the structure of the agents’ util-      preferred good. This differs from the substitutes utility func-
ity functions, then identical numerical conditions should give        tion in being insensitive to the quantity of the non-preferred
rise to different patterns of inference, depending on the sce-        good. These three heuristics do not assign utilities to bundles
nario group. For example, if the goods are complements, then          but instead simply select one outcome as the best.
the observer should be uncertain about the optimal propor-
tion of one good to the other. They will take the agent’s             Table 1: Correlations between the three different utility mod-
initial choice as evidence about the optimal proportion, and          els and subject judgments. Scenarios 1-3 were intended to be
will subsequently choose the bundle which fits this inferred          best fit by a Cobb-Douglas utility function; scenarios 4-7 by
proportion as closely as possible. On the other hand, if the          a Substitutes utility function; and scenarios 8-11 by a Com-
goods are substitutes, then they will take the initial choice         plements utility function.
as evidence about how well each good serves its function,
and will subsequently choose the bundle which maximizes                      Scenario     Cobb    Substitutes    Complements
the weighted sum of the two goods. If both bundles have the                       1       0.79        0.83           0.50
same size, then they will choose the one with the most of the                     2       0.62        0.72           0.30
better good.                                                                      3       0.80        0.70           0.80
   Model Predictions                                                              4       0.85        0.95           0.45
   In order to make model predictions, we used the multino-                       5       0.69        0.83           0.32
mial logit model (Equation 6) to find the probability of taking                   6       0.87        0.91           0.49
option (C) or (D) conditional on the agent’s first choice. This                   7       0.81        0.93           0.36
probability was approximated through MCMC simulations,                            8       0.64        0.34           0.87
using the Metropolis-Hastings method.                                             9       0.63        0.41           0.86
   We computed these probabilities under a variety of settings                   10       0.78        0.74           0.69
for the noise parameter β in the soft-max equation (Equation                     11       0.46        0.23           0.87
4) and for the prior distribution Beta(α, α) over the utility
functions’ weight parameter. The noise parameter was set to
15 and α was set to 2 based on the fit of the model to the
data over all conditions. Figure 1 shows the sensitivity of the       Table 2: Correlations between the best heuristic models and
model’s predictions to the value of β. The mean squared error         participant judgments.
of the model varied between 0.04 and 0.1 as β varied between
0.1 and 20. We similarly analyzed the model’s sensitivity to                          Scenario    Crude Ratio     Max
the value of α. We found that the mean squared error of the                               1           0.55        0.89
model varied between 0.04 and 0.1 as α varied between 1 and                               2           0.57        0.73
10.                                                                                       3           0.91        0.76
                                                                                          4           0.48        0.95
   Our computational model predicts agent preferences by
                                                                                          5           0.37        0.76
matching the appropriate utility function to the scenario.
                                                                                          6           0.61        0.93
Thus, e.g. scenarios in the Complements group will be mod-
                                                                                          7           0.55        0.96
eled with very strong prior probability on the Complements
                                                                                          8           0.82        0.44
utility function and likewise for the other two groups.
                                                                                          9           0.94        0.49
   In order to assess the distinctive predictions of our model,                          10           0.70        0.80
we implemented three heuristic models of preference infer-                               11           0.87        0.26
ence. These heuristics implement rules for making prefer-
ence inferences that are not based on calculations of utility.
The heuristics worked as follows. The Sophisticated Ratio                Results. We first consider the model fit when all of the
Heuristic was a model of ratio-matching, in which goods are           weight of the prior probability distribution is placed on a
selected based on how close their ratio is to an optimal ra-          particular utility function type. As noted above, scenarios
tio. The heuristic considers a range of possible optimal ratios       were grouped based on which utility function we believed
and uses Bayesian inference to integrate over these ratios in         would best fit the goods in the scenario. If participants are
making predictions. This differs from the complements func-           sensitive to the functional relationship between the goods in
tion in being insensitive to absolute quantities of the goods.        each scenario, then their judgments should be best fit when a
The Crude Ratio Heuristic was similar to the Sophisticated            high prior probability is placed on the group’s utility function
                                                                  856

                                                                                                                         M
                        Figure 1: Sensitivity of model performance to the value of the noise parameter β.
                                                                                                                             M
Figure 2: Human judgments vs. utility model predictions (blue dots) and heuristic predictions (green triangles) for a com-
plements scenario. Other scenarios showed a similar relationship between human judgments and the predictions of the two
models.
type. In all of the Substitutes scenarios and three of the four     Douglas and Substitutes scenarios. The Crude Ratio Heuris-
Complements scenarios, the human data was best fit by the           tic had similarly high correlations on all of the Complements
scenario’s corresponding utility function type. Participants’       scenarios. These results are shown in Table 2.
judgments in two of the three Cobb-Douglas scenarios are
best fit by the substitutes utility function. These results are                              Discussion
shown in Table 1.                                                   Our experiment aimed to investigate two questions. The first
   We next tested the fit of our heuristic models. The free         was whether people are sensitive to the functional relation-
parameters of the heuristics were chosen to maximize over-          ships between goods when they make inferences about peo-
all correlation with the human data. The Crude Ratio and            ple’s preferences. The second was, if people are sensitive to
Max heuristics had the highest correlations, so we restrict         these functional relationships, what do they learn about oth-
our attention to them. The Max Heuristic had high (above            ers’ preferences from their observations? Our results pro-
0.7) correlations with human judgments on all of the Cobb-          vide evidence that participants were sensitive to the func-
                                                                857

tional relationships between goods. In particular, participants       scenarios so that subjects’ prior beliefs about these relations
appeared to distinguish between the Complements scenarios             do not come into play. This suggests a further line of research:
and the other scenarios, although we did not find evidence            studying whether individuals can make use of more complex
that they distinguish between the Cobb-Douglas and Substi-            functional relationships than the ones that were considered
tutes scenarios. This is indicated by the fit of both the utility     here. If individuals can effectively learn others’ preferences
and heuristic models. A single utility model (with all of its         in a range of situations, then it is unlikely that these prefer-
prior weight on the substitutes utility function) and a single        ences will be captured by the simple functional forms studied
heuristic (the Max Heuristic) correlate well with human judg-         here.
ments in the Cobb-Douglas and Substitutes scenarios. On the
other hand, these two models fare poorly on most of the Com-                                   References
plements scenarios. The complements utility model and the             Baker, C. L., Tenenbaum, J. B., Saxe, R. R. (2007). Goal
Crude Ratio Heuristic provide better fits for these scenarios.               inference as inverse planning. In Proceedings of the
   The performance of the Max Heuristic on a particular sce-                 twenty ninth annual conference of the Cognitive Sci-
nario is very well predicted by the performance of the substi-               ence Society.
tutes utility function on that scenario; the same is true of the      Kushnir, T., Xu, F., Wellman, H. (2008). Preschoolers use
Crude Ratio Heuristic and the complements utility function.                  sampling information to infer the preferences of others.
The Max Heuristic naively tracks a relationship which is im-                 In Proceedings of the thirtieth annual conference of the
portant to the substitutes utility function, namely which good               Cognitive Science Society.
is favored over the other. The Crude Ratio Heuristic gives a          Lucas, C., Griffiths, T. L., Xu, F., Fawcett, C. (2009). A
noisy estimate of the optimal ratio between goods, which is                  rational model of preference learning and choice pre-
similarly important to the complements utility function. This                diction by children.In Advances in Neural Information
provides evidence that participants were sensitive to the op-                Processing Systems 21.
timal ratio of goods in the Complements scenarios, and to             Mas-Colell, A., Whinston, M. D., Green, J. R. (1995). Mi-
which was the preferred good in the other scenarios.                         croeconomic Theory. Oxford University Press.
   It is an interesting question whether the utility-based or         McFadden, D. Train, K. E. (2000). Mixed MNL models
heuristic models provides a more promising approach to mod-                  of discrete response. Journal of Applied Econometrics,
eling preference learning. The best heuristic models were                    15, 447-470.
able to capture the qualitative shape of participants’ judg-          Repacholi, B. M., Gopnik, A. (1997) Early reasoning about
ments. The heuristics were able to correctly classify bundles                desires: Evidence from 14- and 18-month-olds. Devel-
as more or less likely to be chosen. A representative scenario               opmental Psychology, 33(1), 12-21.
is shown in Figure 2. On the other hand, human judgments
showed a gradedness that was better captured by the utility
models. As predicted by the utility models, participants var-
ied across numerical conditions in how strongly they thought
one bundle should be chosen over another. This is also shown
in Figure 2.
                          Conclusion
We have presented a computational model of structured pref-
erence learning. Our model incorporates Bayesian inference
with economic models of internally complex preferences. Us-
ing a standard tool from econometrics, it can be used to model
how individuals infer what someone prefers on the basis of
past observations. We experimentally tested the model, and
found that participants were sensitive to the functional rela-
tionships between goods in some of the ways that the model
predicts. Future experiments could help to differentiate the
utility-based and heuristic models. These models will make
distinct predictions, for example, when the sizes of the bun-
dles being chosen between are different. Bigger bundles will,
all things being equal, be preferred by the utility-based mod-
els, while this is not always true for the heuristics.
   Further work needs to be done in systematically varying
the structure of the preferences being learned. This may be
done by explicitly varying the causal structures of the choice
                                                                  858

