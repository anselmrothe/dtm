UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Estimation of Trade-off between Costs of Preprocessing and Primary Processing

Permalink
https://escholarship.org/uc/item/71r059t1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Maehigashi, Akihiro
Miwa, Kazuhisa

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Estimation of Trade-off between Costs of Preprocessing and Primary Processing
Akihiro Maehigashi (mhigashi@cog.human.nagoya-u.ac.jp)
Kazuhisa Miwa (miwa@is.nagoya-u.ac.jp)
Graduate School of Information Science Nagoya University, Furo-cyo, Chikusa-ku, Nagoya, Japan
Abstract

the utility of preprocessing in relation to the task complexity. As shown in Figure 1, from the point where the task
complexity (the amount of processing) exceeds a threshold
level, the effectiveness of the preprocessing becomes significant. The utility of preprocessing differs depending on the
task complexity; therefore, people should decide whether or
not preprocessing is worthwhile depending on the situation.
Many researchers have studied cost estimation in situations
where there is a trade-off between the costs of two different
types of processing, e.g., a trade-off between processing using external resources (called external processing) and internal processing (Gray & Fu, 2004; O’Hara & Payne, 1998). In
these studies, it was revealed that people adaptively estimate
the costs of external processing and internal processing, and
effectively adjust the usage of external resources depending
on the cost of their use. Moreover, Matthew and Anderson
(2009) found that people could adaptively determine whether
or not external resources should be used depending on the
task complexity. These studies show that people can adaptively estimate and allocate the costs of external processing
and internal processing. On the other hand, in the current
study, we investigate cost estimation in a situation where a
different task needs to be conducted as preprocessing in order to reduce the cost of primary processing. The purpose
of this study is to investigate whether people can adaptively
estimate the utility of preprocessing and take rational action
when there is a trade-off between the costs of preprocessing
and primary processing as described above.

People often conduct preprocessing to simplify primary processing. Usually, there is a trade-off between the costs of performing preprocessing and primary processing. Therefore, the
utility of preprocessing differs depending on the task complexity. We conducted three experiments to find out whether people
could adaptively estimate the utility of preprocessing and then
take rational action. The overall result was that in performing a high complexity task, almost all the participants made a
rational choice. However, for a low complexity task, the participants gradually learned to conduct preprocessing despite it
not being effective. These results were explained based on theoretical perspectives proposed in previous studies.
Keywords: Strategy selection; Task environment; Cost; Time;
Preprocessing

Introduction
When people engage in a task, they often create and conduct
an additional preliminary task in order to conduct the main
task more easily by using the result of the additional task.
For example, people create preliminarily index cards for documents so that needed documents can be easily found. Moreover, people program preliminarily macros on a computer so
that data can be easily processed later. In this study, we call
such preliminary processing “preprocessing”. People conduct preliminarily preprocessing so that primary processing
in the task can be easily carried out. Preprocessing is often
performed in our daily lives.
Kirsh (1996) referred to a “complementary action” which
redesigns a task environment before engaging in the task in
order to complete the task easily. He explained: “Complementary actions are a part of a strategy for restructuring the
environment to improve the speed, accuracy, and robustness
of cognitive processes” (p. 442). Such complementary actions taken before engaging in a task are also considered to
be preprocessing. Moreover, Martin and Schwartz (2009) described preprocessing as an expertised action and call it an
“adaptive pattern” in their manuscript. They stated that “in
the adaptive pattern, people take an initial period to explore
or adapt their ideas, practices, and/or environment. They are
slower to start, but they can make up the lost time if they make
an appropriate adaptation” (p. 372).
When preprocessing is conducted, the cost in primary processing is reduced. However, since conducting the preprocessing itself incurs a cost, there is a trade-off between the
costs of preprocessing and primary processing. In such a situation, the utility of preprocessing seems to differ depending
on the task complexity. When primary processing is conducted in a task without preprocessing, the task completion
time increases with the task complexity. In contrast, when
preprocessing is conducted for a certain period of time, it is
considered that the increase in total task completion time for
preprocessing and primary processing will be reduced, compared to the increase in the task completion time without preprocessing. Figure 1 illustrates our basic concept, showing

Preprocessing
Ineffective
Effective
Task completion time without preprocessing
(Primary processing time)
Task completion time with preprocessing
(Preprocessing time + Primary processing time)

e
im
T

Preprocessing time

Task complexity
(Amount of processing)

Figure 1: Concept diagram of trade-off between costs of preprocessing and primary processing

Experimental task
In the following experiments, we used a routine task of transcribing scores from test sheets to a tally sheet. In this task,
fifty test sheets were prepared. On each test sheet, a student
ID number was printed in the upper left and a test score in
the center. In the experiments, three trials were conducted. In
each trial, all the scores on the fifty individual test sheets had
to be transcribed to a tally sheet to correspond to each student
ID number.
943

Task complexity Each student ID number consisted of an
eleven-digit number that encoded four categories, Grade, Major, Course, and Individual number. We set up a situation in
which there were two grades, two majors, and five courses,
and also there were twenty students in each course. Each student ID number on the test sheet was represented differently
from that of the tally sheet, but could be collated by a certain transformation rule. In order to find the right place to fill
out in the tally sheet, the student ID number on the test sheet
needed to be transformed by the rule so that the transformed
number could be found in the tally sheet (Figure 2). In the
high task complexity condition, the participants had to calculate the student ID numbers on the test sheets for the transformation using a certain formula. On the other hand, in the low
complexity condition, a student ID number correspondence
table was given to the participants for the transformation so
that they could find the referred numbers in the tally sheet
without performing a calculation.
Test sheet

18 024 019 001

controlled using the number of times, and the order in which
the operations of carrying and borrowing were required for
the calculation to transform the student ID numbers. The
tally sheet was made of A3 sized paper. A scenario with
two grades, two majors, and five courses were conjectured
with twenty students belonging to each course. Therefore,
400 empty cells (= 2 × 2 × 5 × 20) were placed on the tally
sheet. By transcribing all the scores to the tally sheet, fifty
cells out of the 400 blank spaces had to be filled in. A desk
with space large enough to accommodate ten A4 sized papers
was used for preprocessing. Also, another desk was used for
primary processing, that is, transcribing the scores to the tally
sheet with a pencil.
Factorial design The experiment had a three-factor mixed
design. The factors were: (1) Task complexity (high and low)
between participants; (2) Preprocessing (preprocessing and
no preprocessing) between participants; (3) Trial (1, 2, and 3)
within participants.
Procedure In order to confirm participants’ ability to calculate, they were required to solve computational problems that
consisted of a total of 25 addition and multiplication problems. The main task was conducted three times with different
sets of the test sheets and the tally sheets. At the beginning of
each trial, the participants were informed of their task completion time and the number of errors in the previous trial as
feedback. As a preprocessing condition, the participants had
chosen a particular way of grouping the test sheets in the first
trial and were instructed to rearrange them in the same way
throughout the three trials.

Tally sheet

18 031 001

Grade
Major
Course Individual
Grade Major/ Course Individual
Figure 2: Transformation of student ID number; In the high
task complexity condition, a transforming formula was used
as follows: (1) add Major number to Course number (24 +
19 = 43). (2) multiply the first digit by the second digit of the
result of (1) (4 × 3 = 12). (3) subtract the result of (2) from
the result of (1) (43 − 12 = 31). In the low task complexity
condition, a correspondence table was used to transform the
student ID numbers.

Result
In order to maintain homogeneity of the participants’ calculation ability, two participants whose computational time in the
calculation problems fell outside 2 SD from the mean computational time for each condition were eliminated from the
analysis. In addition, it was assumed that the participants who
made too many errors in the task could not conduct the task
appropriately, therefore three participants whose mean number of errors throughout the three trials fell outside 2 SD from
the mean number of errors in each condition were eliminated
from the analysis. Moreover, one participant who violated
the instructions, i.e., conducted the transforming calculation
on the desk space for preprocessing, was eliminated from the
analysis. In the following experiments, the identical criteria
were used for selecting appropriate participants. As a result,
the performance of forty participants, of whom ten were assigned to each condition, was analyzed.
There was no significant difference in performing the calculation problems between the four conditions (F(3, 36) =
.07, n.s.). Therefore, the calculation abilities of the participants among the four conditions were considered equivalent.
Task completion time On the task completion time, a 2
(Task complexity: high/low) × 2 (Preprocessing: preprocessing/no preprocessing) × 3 (Trial) ANOVA was conducted. As a result, there was no significant three-way interaction (F(2, 72) = 2.17, n.s.). There was a significant
two-way interaction between task complexity and preprocessing (F(1, 36) = 9.80, p < .005). There was neither significant two-way interactions between task complexity and trial

Preprocessing To carry out the preprocessing, a desk space
was available for participants. Initially, the test sheets were
arranged in random order and handed to the participants.
They could rearrange the test sheets on the desk space so that
they could group the test sheets according to the categories
of Major and Course numbers. By preliminarily grouping the
test sheets, the participants could transform the student ID
numbers of a bundle of multiple test sheets in the same Major and Course number at one time. There was no need to
transform each student ID number on each test sheet one by
one. Therefore, the participants could reduce the number of
transformations of the student ID numbers by preliminarily
grouping the test sheets as a preprocessing task.

Experiment 1
Purpose
We investigated the relationship between the task performance and the task complexity, i.e., the task completion time
and the number of errors respectively, when preprocessing is
conducted or not.

Method
Participants Forty-six university students participated in
this experiment.
Material A set of fifty test sheets made from A4 sized paper was prepared for each trial. Three trials were performed
and a different set was used in each trial. All three sets were
944

(F(2, 72) = 1.83, n.s.) nor between preprocessing and trial
(F(2, 72) = .46, n.s.). Figure 3 illustrates the mean task completion time in Experiment 1 based on the basic concept depicted in Figure 1. In Figure 3, the preprocessing time was
measured from the time when the test sheets were put on the
desk space for grouping (preprocessing) until they were lifted
up for transcribing the scores to the tally sheet (primary processing).
Next, we conducted a simple main effect test on the preprocessing factor. As a result, (1) in the high task complexity condition, there was a marginally significant difference showing that the task completion time was faster in the
preprocessing condition than in the no preprocessing condition (F(1, 36) = 3.19, p < .10), whereas (2) in the low task
complexity condition, it was significantly faster in the no
preprocessing condition than in the preprocessing condition
(F(1, 36) = 6.98, p < .05).
1400

vestigated whether people could adaptively estimate the utility of preprocessing and take rational action depending on the
task complexity.

Experiment 2
Purpose
Using the transcribing task, we investigated whether people
could adaptively estimate the utility of preprocessing and take
rational action depending on the task complexity.

Method
Participants Twenty-seven university students participated
in this experiment.
Material Identical materials were used as in Experiment 1.
Factorial design The experiment had a two-factor mixed
design. The factors were: (1) Task complexity (high and low)
between participants; (2) Trial (1, 2, and 3) within participants.
Procedure Basically an identical procedure to that of Experiment 1 was followed. In Experiment 2, the participants
were instructed: “it is allowed to rearrange and group the test
sheets, but it is not a requirement to do so.” In addition, when
the participants chose to conduct preprocessing at the beginning of each trial, they were allowed to decide their own way
of rearranging the test sheets.

No preprocessing
(Primary processing time)

1200

Preprocessing
(Preprocessing time + Primary processing time)

)d1000
no
ecs 800
(
e 600
imT
400

Preprocessing time

200
0
Low task complexity High task complexity

Result

Figure 3: Task completion time in Experiment 1 represented
by the basic concept

Three participants were excluded from the analysis based on
the same criterion as in Experiment 1. As a result, the performance of twenty-four participants, of whom twelve were
assigned to each condition, was analyzed. First, there was no
significant difference in performing the calculation problems
between the two conditions (t(22) = .23, n.s.).

Number of errors We defined a transcribing error as being a transcription of an incorrect score or a transcription
to an inappropriate cell. On the number of errors, a 2
(Task complexity: high/ low) × 2 (Preprocessing: preprocessing/no preprocessing) × 3 (Trial) ANOVA was conducted. As a result, there was no significant three-way interaction (F(2, 72) = .61, n.s.). There was a significant twoway interaction between task complexity and preprocessing (F(1, 36) = 4.37, p < .05) and a marginally significant
interaction between task complexity and trial (F(2, 72) =
2.56, p < .10). There was no significant interaction between
preprocessing and trial (F(2, 72) = 1.98, n.s.).
Next, we conducted a simple main effect test on the preprocessing factor. As a result, (1) in the high task complexity
condition, the number of errors was significantly smaller in
the preprocessing condition than in the no preprocessing condition (F(1, 36) = 11.12, p < .005), whereas (2) in the low
task complexity condition, there was no significant difference
between the preprocessing and no preprocessing conditions
(F(1, 36) = .14, n.s.).

Preprocessing and minimal transformation strategy In
Experiment 2, we calculated the ratio of participants conducting preprocessing for each condition. Moreover, there was a
rearranging strategy with which the participants could transform the student ID numbers with the minimum number of
times in primary processing. This strategy could minimize
the cost of primary processing. In particular, this strategy
was to group the test sheets according to the categories of Major and Course numbers first. We calculated the ratio of participants using this minimal transformation strategy for each
condition. Figure 4 shows the ratio of participants conducting
preprocessing and the ratio of participants using the minimal
transformation strategy. In the low task complexity condition,
the participants gradually learned to conduct preprocessing
from the first to third trial. On the other hand, in the high task
complexity condition, the participants conducted preprocessing from the first trial. Moreover, the minimal transformation
strategy was used more in the high task complexity condition
than in the low task complexity condition.

Discussion
As a result of Experiment 1, it is revealed that conducting preprocessing is effective for the high complexity task, and contrarily, not conducting preprocessing is effective for the low
complexity task. These results proved that our transcribing
task is an appropriate task for embodying a trade-off between
preprocessing and primary processing.
In the following Experiment 2, using the same task, we in-

Discussion
As a result of Experiment 2, when the participants were allowed to choose whether to conduct preprocessing or not, the
participants conducted ineffective preprocessing in the low
complexity condition. Moreover, the minimal transformation
945

1
0.9
0.8
0.7
0.6
tioa0.5
R
0.4
0.3
0.2
0.1
0

Preprocessing

estimate the task completion time and the number of errors
after each trial had been completed. They were neither informed of the actual task completion time nor the number of
errors as feedback. Moreover, in Experiment 3, we set up
the fourth trial in which the participants were not allowed to
conduct preprocessing in order to compare the performance
with the performance when preprocessing was conducted in
the former three trials. Also, the participants were instructed
to estimate the task completion time and the number of errors
after the fourth trial had been completed.

Minimal transformation
strategy

1st
2nd
3rd
Low task complexity

1st
2nd
3rd
High task complexity

Figure 4: Ratio of participants conducting preprocessing and
ratio of participants using minimal transformation strategy in
Experiment 2

Result
Two participants were excluded from the analysis based on
the same criterion as in Experiment 1. As a result, the performance of fifteen participants was analyzed.

strategy was used more for the high complexity task than for
the low complexity task.
At this point, we have questions. Was it possible the participants were trying to reduce fatigue by grouping the test
sheets as a routine work throughout the trials although they
realized that conducting preprocessing was ineffective for the
low complexity task? Moreover, was it also possible for
them to try to reduce the number of errors by grouping the
sheets although they noticed that conducting preprocessing
increased the task completion time for the low complexity
task? To answer these questions, in Experiment 3, we conducted a questionnaire directly asking the participants which
makes the task faster and more accurate, preliminarily grouping the test sheets as preprocessing or not. Furthermore, in
Experiment 2, at the beginning of each trial, the participants
were told the task completion time and the number of errors in
the previous trial as feedback. Throughout the trials, the task
completion time gradually decreased because of the learning
effect. Consequently, the participants might have misunderstood that preprocessing is effective because of the effect of
this feedback. Therefore, in Experiment 3, we gave no feedback to the participants.

Preprocessing and minimal transformation strategy
Figure 5 shows the ratio of participants conducting preprocessing and the ratio of participants using the minimal transformation strategy. The participants gradually learned to conduct preprocessing from the first to third trial. Moreover, the
ratio of participants using the minimal transformation strategy was low.
1
0.9
0.8
0.7
0.6
iot
Ra0.5
0.4
0.3
0.2
0.1
0

Preprocessing
Minimal transformation
strategy

1st

2nd

3rd

Figure 5: Ratio of participants conducting preprocessing and
ratio of participants using minimal transformation strategy in
Experiment 3
Estimation of preprocessing utility Figures 6 and 7 show
the numbers of choices made in the questionnaire at the beginning of each trial for the task completion time and the accuracy. With each subsequent trial, the participants shifted
towards estimating that conducting preprocessing is effective
in producing a more rapid performance. They also either estimated that preprocessing was effective or produced no difference in performance accuracy.

Experiment 3
Purpose
We replicated Experiment 2 and confirmed whether people
could adaptively estimate the utility of preprocessing and take
rational action in the low complexity task.

15

Method

Preprocessing is effective

st
na12
ipc
it
ra 9
p
fo 6
re
b
3
um
N

Paticipants Seventeen university students participated in
this experiment.
Material Identical materials were used as in Experiment 2.
Procedure Basically an identical procedure to that of Experiment 2 was followed. In Experiment 3, at the beginning
of each trial, we gave the participants a questionnaire asking them to estimate the utility of preprocessing for the task
completion time and the accuracy. The participants were instructed to choose one out of four choices: (1) preprocessing
is effective, (2) no preprocessing is effective, (3) no difference, and (4) impossible to estimate. When the participants
chose to conduct preprocessing at the beginning of each trial,
they were allowed to decide their own way of rearranging the
test sheets. In addition, the participants were instructed to

No preprocessing is effective
No difference
Impossible to estimate

0

1st

2nd

3rd

Figure 6: Respondents estimation for task completion time
Actual/ Estimated performance In Experiment 3, almost
all participants conducted preprocessing as in Experiment 2.
Consequently, we compared the participants’ performance
when preprocessing was conducted in the first three trials
with their performance in the fourth trial where they were
not allowed to conduct preprocessing. In particular, the mean
946

15

Preprocessing is effective

st
na12
ipc
it
ra 9
p
fo 6
re
b
3
um
N

periment 2. This result eliminated the possibility that the
feedback from their previous performance had encouraged
the participants to mistakenly elect to perform preprocessing. Second, the ratio of participants using the minimal
transformation strategy was also as low as in Experiment 2.
Third, the results of the questionnaire indicated the participants overestimated the utility of preprocessing for the task
completion time and the accuracy. This result eliminated the
possibility that the participants conducted preprocessing as
a strategy for reducing fatigue and reducing the number of
errors, because they had reported that conducting preprocessing could reduce the task completion time in the questionnaire. Moreover, we compared the performances when preprocessing was conducted and when it was not conducted in
the within-participant experiment. As a result, we confirmed
the result was consistent with that of Experiment 1. Contrarily, the participants estimated the actual task completion
time faster when preprocessing was conducted than when not
conducted. This result is consistent with the result of participants’ estimation for the task completion time in the questionnaire given at the beginning of each trial.

No preprocessing is effective
No difference
Impossible to estimate

0

1st

2nd

3rd

Figure 7: Respondents estimation for accuracy
performance of nine participants, who had conducted preprocessing in all the first three trials, and four participants, who
had conducted preprocessing in the second and third trials,
was calculated. The result was regarded as the representative performance for when preprocessing was conducted. The
performance of these thirteen participants in the fourth trial
was regarded as the representative performance for when preprocessing was not conducted. Moreover, we compared the
participants estimated performance when preprocessing was
conducted in the first three trials with their estimated performance in the fourth trial.
Actual/ Estimated task completion time Figure 8 shows
the actual task completion time and the estimated task completion time. We conducted a t-test on the actual task completion time when preprocessing was conducted and when
it was not conducted. As a result, the actual task completion time was significantly faster when preprocessing was
not conducted than when conducted (t(12) = 4.49, p < .001).
Moreover, we conducted a t-test on the participants estimated task completion time when preprocessing was conducted and when it was not conducted. As a result, there
was a marginally significant difference showing that their estimated time was faster when preprocessing was conducted
than when not conducted (t(12) = 1.89, p < .10).
1400

Preprocessing
No preprocessing

1200

1400

General Discussion
The purpose of this study was to investigate whether people
can adaptively estimate the utility of preprocessing and take
rational action. First, Martin and Schwartz (2009) investigated preprocessing to create representational tools before engaging in a task. However, they evaluated the performances
of preprocessing and primary processing separately and did
not address the issue of a trade-off between the costs of the
two types of processing. They used a learning task to investigate how learning experiences in preprocessing influence the
following behavior for learning. In contrast, in this study, we
used a problem solving task. In order to investigate the utility of preprocessing, it is crucially important, especially in
problem solving tasks, to consider the trade-off between increasing the cost of preprocessing and decreasing the cost of
primary processing.
As a result of our experiments, in the low complexity task,
preprocessing was aggressively conducted despite it not being effective. In our experimental task, preprocessing was
performed with a desk space as an external resource. Brown,
Collins, and Duguid (1989a, 1989b) suggested that people
actively use external resources at the initial stage as an initial human impulse. In addition, Kirsh (2009) referred to the
activity-centric model as an instinctive human behavior of using external resources without thinking. The human nature to
instinctively use external resources described in the research
of Brown et al. and Kirsh may explain the participants’ behavior in our experiments.
Sirouzu, Miyake, and Masukawa (2002) experimentally
confirmed such a human nature. They suggested that people
actively use external resources as their “proto-plan”. In their
experiment, the existence of external resources prevented the
participants from noticing the availability of usable internal
processing. In contrast, in our experiments, the participants
conducted preprocessing although they were explicitly offered the choice of using preprocessing or not. Moreover,
Sirouzu et al. (2002) stated that the participants divided a sin-

Preprocessing
No preprocessing

1200

d)n1000
oc
es 800
(
e 600
imT
400

d)n1000
oc
es 800
(
e 600
imT
400

200

200

0

0
Low task complexity

Low task complexity

Figure 8: Comparisons of actual task completion time (left)
and estimated task completion time (right) when preprocessing was conducted and when it was not conducted
Actual/ Estimated number of errors We conducted t-tests
on the actual number of errors and on the participants estimated number of errors when preprocessing was conducted
and when it was not. As a result, there was neither significant
difference in the actual number of errors (t(12) = .66, n.s.)
nor in their estimated number of errors (t(12) = 1.54, n.s.).

Discussion
First, as a result of Experiment 3, when the participants were
allowed to choose whether to conduct preprocessing or not,
the participants conducted ineffective preprocessing as in Ex947

gle over-all task into multiple simpler sub-tasks using an external resource so that they could visually confirm the completion and the result of each sub-task, and plan the next step.
In our experiments, the participants could divide one transcribing task into two different tasks: rearranging the test
sheets (preprocessing) and transcribing scores (primary processing). The participants could take advantage of the result
of preprocessing, allowing them to conduct primary processing smoothly and easily. It is considered that the effect of
such task decomposition causes the overestimation of the utility of preprocessing. Kirsh (1996) explained such human action of task decomposition as a complementary action, which
enables the externalization of plans into sub-goals in order to
easily achieve a final goal and that this is a central element of
human activities.
The result of our experiments about the estimation of a
trade-off between two types of processing is not consistent
with the findings of Matthew and Anderson (2009). In their
experiment, the participants had to choose between solving
each problem using a calculator as an external resource or by
using mental calculation. The participants were able to make
the correct choice whether to use the external resource or not,
dynamically and instantly, depending on the task complexity. Matthew and Anderson (2009) used calculation problems
that each took around ten seconds to solve. In contrast, in our
experiments, we used the transcribing task that took around
ten minutes to complete. In order to conduct preprocessing,
the participants had to create an additional sub-task as a preliminary task, once stepping away from the primary task, and
thus conduct two different types of tasks sequentially. One
reason why the participants failed to estimate the costs might
be because the cost estimation in our task was much harder
than such estimation in the previous study.
Another reason may depend on the participants’ time perception. The task completion time in the low complexity task
was estimated to be faster when preprocessing was conducted
than when not conducted. This trend in estimation was opposite to that of the actual task completion time. In studies
of time perception, it has been verified that the more cognitive processing people perform, the less attention they direct
to time, so that they underestimate time duration. This phenomenon is explained by the attentional model (Hicks, Miller,
& Kinsbourne, 1976; Zakay, 1993). Hicks et al. (1976) investigated the attentional model using a card sorting task. As a
result, it was revealed that the more stacks the cards were
sorted into, the faster the task completion time was estimated
to be, because more cognitive processing was performed as
there were more stacks to sort. In our experiments, when
preprocessing was conducted, the participants had to sort the
test sheets. Therefore, there is a possibility that the participants estimated the task completion time faster when preprocessing was conducted than when not conducted because
they performed more cognitive processing when preprocessing was conducted than when it was not conducted in the low
complexity task.
Last, the minimal transformation strategy was used more
in the high complexity task than in the low complexity task.
Cary and Carlson (1999) found that in a situation where high
internal costs were demanded, the participants tended to use a

strategy to minimize their internal costs. On the other hand, in
a situation where low internal costs were demanded, the participants chose a strategy of following structures in the problem, and did not focus on reduction of internal processing. In
our experiments, in the high complexity task, the participants
rearranged the test sheets according to the categories of Major
and Course numbers first. Using this strategy, the participants
successfully transformed the student ID numbers for referring
to the numbers on the tally sheet using the minimum number
of times and minimized internal cost. On the other hand, in
the low complexity task, the participants tended to rearrange
the test sheets according to the category of Grade number
first, affected by the structure of the student ID number in
which the first two digits represented the Grade. This meant
that they used a strategy to follow the structure of the problem. Our results were consistent with the findings of Cary
and Carlson (1999).

References
Brown, J. S., Collins, A., & Duguid, P. (1989a). Debating situation: A rejoinder to palinscar and wineburg. Educational
Researcher, 18, 10–12.
Brown, J. S., Collins, A., & Duguid, P. (1989b). Situated cognition and the culture of learning. Educational Researcher,
18, 32–42.
Cary, M., & Carlson, R. A. (1999). External support and
the development of problem-solving routines. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 25, 1053–1070.
Gray, W. D., & Fu, W.-T. (2004). Soft constraints in interactive behavior: the case of ignoring perfect knowledge
in-the-world for imperfect knowledge in-the-head. Cognitive Science, 28, 359–382.
Hicks, R. E., Miller, G. W., & Kinsbourne, M. (1976).
Prospective and retorospective judgements of time as a
function of amount of information processed. American
Journal of Psychology, 89, 719–730.
Kirsh, D. (1996). Adapting the environment instead of oneself. Adaptive Behavior, 4, 415–452.
Kirsh, D. (2009). Problem solving and situated cognition. In
P. Robbins & M. Aydede (Eds.), The cambridge handbook
of situated cognition. Cambridge University Press.
Martin, L., & Schwartz, D. L. (2009). Prospective adaptation in the use of external representations. Cognition and
Instruction, 27, 370–400.
Matthew, M. W., & Anderson, J. R. (2009). The strategic
nature of changing your mind. Cognitive Psychology, 58,
416–440.
O’Hara, K. P., & Payne, S. J. (1998). The effects of operator
implementation cost on planfulness of problem solving and
learning. Cognitive Psychology, 35, 34–70.
Sirouzu, H., Miyake, N., & Masukawa, H. (2002). Cognitively active externalization for situated reflection. Cognitive Science, 26, 469–501.
Zakay, D. (1993). Time-estimation methods - do they influence prospective duration estimates. Perception, 22, 91–
101.
948

