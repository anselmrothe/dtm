UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modulation of motor-meaning congruity effects for valenced words

Permalink
https://escholarship.org/uc/item/2ch97289

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Brookshire, Geoffrey
Ivry, Richard
Casasanto, Daniel

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Modulation of motor-meaning congruity effects for valenced words
Geoffrey Broookshire1
(geoff.brookshire@mpi.nl)
1

Richard Ivry2

Daniel Casasanto1,3

(ivry@berkeley.edu)

(daniel.casasanto@mpi.nl)

Max Planck Institute for Psycholinguistics, Neurobiology of Language Group, Nijmegen, NL
2
University of California at Berkeley, Department of Psychology, Berkeley CA, USA
3
Donders Center for Brain, Cognition, and Behavior, Nijmegen, NL
Abstract

We investigated the extent to which emotionally valenced
words automatically cue spatio-motor representations.
Participants made speeded button presses, moving their hand
upward or downward while viewing words with positive or
negative valence. Only the color of the words was relevant to
the response; on target trials, there was no requirement to read
the words or process their meaning. In Experiment 1, upward
responses were faster for positive words, and downward for
negative words. This effect was extinguished, however, when
words were repeated. In Experiment 2, participants performed
the same primary task with the addition of distractor trials.
Distractors either oriented attention toward the words’
meaning or toward their color. Congruity effects were
increased with orientation to meaning, but eliminated with
orientation to color. When people read words with emotional
valence, vertical spatio-motor representations are activated
highly automatically, but this automaticity is modulated by
repetition and by attentional orientation to the words’ form or
meaning.
Keywords: Automaticity, Metaphor, Motion, Space, Valence

Introduction
Do some abstract concepts depend, in part, on mental
representations of physical space? According to theories of
metaphorical mental representation, linguistic metaphors
like ‘a rising price’, ‘a sliding scale, or ‘a long engagement’
suggest that many of our abstract ideas are grounded in
representations of motion and space. These are, in turn,
grounded directly in perceptuo-motor experiences (e.g.,
Clark, 1973; Lakoff & Johnson, 1999; Talmy, 1988).
Although initial arguments for metaphor theory were based
on descriptive linguistic data, psychological experiments
provide evidence for important links between spatio-motor
representations and mental representations in more abstract
domains like power (Schubert, 2005), happiness (Meier &
Robinson, 2004), time (Boroditsky, 2000), number
(Dehaene et al., 1993), and similarity (Casasanto, 2008). Yet
researchers are just beginning to specify what roles spatial
representations may play in abstract thought.
Debates about metaphorical representation have focused
on two theoretical possibilities outlined by Murphy (1996),
which were impossible to distinguish based on
observational linguistic data, alone. On the Strong View,
representations in metaphorical source domains (e.g., space)
are necessary for conceptualizing target domains (e.g.,
time). According to Lakoff and Johnson (1999), activating

source-target mappings is obligatory: without them,
“abstract thought is virtually impossible.” On the Weak
View, however, source domain representations make an
optional contribution to people’s understanding of target
domains. Boroditsky (2000) tested whether spatial
representations are necessary for understanding temporal
language, and concluded that “spatial schemas are useful,
but not necessary” (italics added).
Framing experiments in terms of the necessity of source
domain representations for understanding target domains
(and for understanding target-domain language in particular)
helped to transform a question that was long the province of
linguists and philosophers into a question that is tractable
using the psychologist’s toolkit. Yet continuing to test a
Strong-Weak dichotomy seems unlikely to lead to further
new discoveries.
On nearly any theory of metaphor, source domain
representations are hypothesized to be part of a more
complex mental representation or word meaning: on the
Strong View, a necessary part. The idea that there are
necessary parts (i.e., features) of concepts or word
meanings, however, is difficult to maintain. Wittgenstein
(1953) famously exploded the notion that even a simple,
relatively concrete word like game has any features that are
necessarily present in all of its instantiations. It seems
unlikely that more abstract words like value or justice,
whose meanings are notoriously fluid, would have any
necessary parts. This suggests the necessity question should
be reframed in terms of functionality: What causes source
domain representations to be activated, and what functional
roles do they play in understanding target domains?
Psychologists have also raised a related question about
metaphor (e.g., Meier & Robinson, 2004; Meier, et al.,
2007): Are source domains activated automatically when
people understand target domains? Automaticity is of
interest because it is taken as evidence against the
possibility that source-domain representations are only
activated strategically (perhaps consciously) when people
need to communicate about abstract ideas, or in response to
task demands (Meier, et al., 2007). Curiously, however,
automaticity has been treated as binary; source domains
either are or are not activated automatically. Yet for most
aspects of concepts and word meanings, it seems unlikely
that activation is fully automatic − not in the same sense that
people automatically perceive the lines in the Müller-Lyer
illusion to be of different lengths. As classic studies of
‘semantic flexibility’ suggest, context can modulate the

1940

activation of even those aspects of a word’s meaning that
might seem to be indispensable (e.g., Barclay, et al., 1974).
Notions of automaticity that are well-suited for
characterizing aspects of perceptual and motor processes
may not be appropriate for characterizing aspects of
meaning: meaning is not a reflex.
Traditional notions of necessity and automaticity must be
tailored to fit questions about metaphor (and about meaning,
more broadly). Rather than asking whether source domains
are necessary for understanding target domains, it may be
more fruitful to ask ‘what functional roles do source-domain
representations play in understanding target domains?’
Rather than investigating whether source domain
representations are activated automatically, it may be useful
to ask ‘to what extent is their activation automatic, and
under what conditions is their activation increased or
diminished?’ We take up these latter questions of
automaticity here, assuming automaticity to be a continuum.
Emotional valence is an abstract domain that people often
talk about using metaphors from space and motion: when
people are optimistic they’re looking up, and when they’re
sad they’re feeling down; hopes can rise; morale can drop;
spirits can soar or plummet. Behavioral studies suggest
these linguistic metaphors correspond to mental metaphors:
non-linguistic associative mappings from representations of
motion or space to the representations of emotional valence.
Stroop-like experiments show these mappings are activated
when people process language with positive or negative
valence, even when they’re not using any linguistic
metaphors.
In one study (Meier & Robinson, 2004), participants were
faster to judge words like polite and rude as having positive
or negative valence when positive words were presented at
the top and negative words at the bottom of a computer
screen (Experiment 1). Furthermore, judging words to be
positive directed attention to the top of the computer screen,
and judging them to be negative directed attention to the
bottom (Experiment 2). Yet based on these experiments it
would be premature to conclude that space-valence
associations are ‘automatic’. For one thing, the spatial
variation from trial to trial was highly salient in Meier &
Robinsons’ experiments (in fact, impossible to ignore), and
for another, participants made explicit judgments about the
valence of the words. Thus, the tasks strongly focused
attention on both the source and target domains.
To address these concerns, Casasanto (2008) adapted a
spatial interference task of Zwaan & Yaxley’s (2003) for
use with valenced words. Participants saw pairs of words,
one above and the other below fixation, and made speeded
synonym-antonym judgments. Target word pairs were
antonyms, one with positive and the other with negative
valence. Participants were fastest to classify the pairs as
antonyms when the positive word appeared above the
negative (e.g., wealthy above poor). In a second experiment,
participants were faster to make lexical decisions on
positive-valence words (e.g., brave, ethical) when they were
presented above non-word distractors, and on negative-

valence words (e.g., failure, hate) when presented below
non-word distractors. This was true even though neither the
spatial position of the words, nor their valence, nor any
other part of their meaning was relevant to the task.
In a third experiment, Casasanto (2008) presented positive
and negative words in the center of a screen, in either red or
blue letters. On the right and left of the screen there were
three large boxes. The top box was red and the bottom box
was blue (or vice versa). The middle box was white, and
was filled with marbles. Participants were instructed that as
soon as each word appeared, they should move one marble
with each hand into the box corresponding to the color of
the word’s font, as quickly as possible. They moved marbles
fastest when the direction of movement was congruent with
the spatial schema suggested by the word’s valence. This
was true even though movements were cued only by the
words’ colors: not only was their meaning irrelevant, the
tasks did not even require participants to process the words
as words.
These Stroop-like congruity effects suggest that spatial
representations are activated with a considerable degree of
automaticity when people read valenced words. The goal of
the present study was to test the limits of this automaticity.
In Experiment 1, we tested whether repeating stimuli
modulated the magnitude of the space-valence congruity
effect. Casasanto’s (2008) marble-moving task was adapted
for use with button presses, to automate response coding.
Stimuli were presented twice, in successive blocks, and
reaction times were compared across blocks. In Experiment
2, we tested whether attentional orientation influenced the
magnitude of space-valence congruity effects. We used a
Task Set Inertia manipulation (Allport & Wylie, 2000).
Distractor trials oriented attention during the target trials
toward either semantic or perceptual aspects of the target
words.

Experiment 1: Does repetition modulate
motor-meaning congruity effects?
Experiment 1 tested whether motor-meaning congruity
effects observed in previous studies would be modulated by
repetition of the same stimulus words.

Methods
Participants Native English-speaking UC Berkeley
students (N=20) participated in exchange for course credit
or payment.
Materials
Two lists of 48 English words were created, one with
positive and the other with negative valence (e.g., wealthy,
poor, virtuous, evil, joy, disgust, etc.), totaling 96 stimuli.
The words were nouns and adjectives that have no literal
spatial meaning, but which subjects in a previous norming
study spatialized consistent with their metaphorical
associations (e.g., placing wealthy above poor; virtuous
above evil, etc.) Positive and negative words did not differ

1941

in frequency (p=0.70), number of syllables (p=0.60), or
number of letters (p=0.12), by two-tailed t-tests.
Stimuli were presented on a CRT monitor with a refresh
rate of 60 Hz. A standard QWERTY keyboard was mounted
vertically directly underneath the monitor, and participants
responded using three of the keys: top (the A key), bottom
(the apostrophe key), and middle (the H key). The top and
bottom keys were colored green and purple, and the
assignment of colors to keys was counterbalanced across
participants. The middle key was always colored white.
Procedure All 96 words were presented one at a time in
random order in block 1, and again in a new random order
in block 2. Half of the words were in green letters and half
in purple letters. The assignment of colors to words was the
same for both blocks within-subjects, and counterbalanced
between subjects.
Participants began each trial by holding down the middle
(white) key with the pointer or middle finger of the
dominant hand. A fixation cross appeared for 1000ms1500ms on a rectangular distribution (to prevent
anticipatory releases of the middle key). When the fixation
disappeared, a word appeared in the center of the screen for
2000 ms in lowercase, bold 28-point Arial font (purple or
green), on a black background. Participants were instructed
to release the white key and press the key matching the
color of the text as quickly as possible. Only the color of the
word was relevant to the response: the word’s meaning was
irrelevant, and the direction of the response was incidental.
But because the purple and green keys were positioned
vertically, one above the other, each key press required the
participant to make either an upward or a downward
movement. After pressing the colored key, participants
returned their finger to the white key. Pressing the white key
initiated the next trial.
The color of the words was orthogonal to their valence.
Therefore, for half of the trials the direction of the correct
response was congruent with the valence of the word (e.g.,
if the word joy appeared in green and the green key was on
top), and for the other half of the trials direction and valence
were incongruent (e.g., if the word joy appeared in purple
and the purple key was on bottom).
Participants received warning messages, displayed for
2500 ms, if they released the middle key too early (less than
200 ms after word onset) or too late (more than 1000 ms
after word onset). Participants performed 16 practice trials
prior to the first block. Halfway through each block, they
were given a rest, and chose when to continue.

Results and Discussion
Accuracy
Participants pressed the correct button for over 99% of
trials. Accuracy did not differ as a function of congruity or
block (t-values<1).
Reaction Times
We collected two reaction times: Release Time (measured
from the onset of the word to the release of the middle white

key), and Press Time (measured from the onset of the word
to the press of the colored key). From these we computed
Travel Time (Press Time - Release Time). Trials for which
Press Time was more than two standard deviations from the
participant’s mean were excluded from further analysis (143
out of 3840 trials, 3.7%).
Release Times Mean Release Times are given in fig 1a-b.
Omnibus 2 × 2 × 2 ANOVAs showed a 3-way interaction of
Direction (upward, downward), Valence (positive,
negative), and Presentation (first, second), both by subjects
(F1(1,19)=5.95, p=.03) and by items (F2(1,94)=5.83, p=.02).
The predicted motor-meaning congruity effect would be
indicated by a 2-way interaction of Direction × Valence.
There were no significant 2-way interactions in the data
from both presentations, combined (all F’s<1), so separate
2-way ANOVAs were conducted to test for this effect
within each block.
Presentation 1 showed the predicted Direction × Valence
interaction (F1(1,19)=4.67, p=.04; F2(1,94)=3.26, p=.07).
Presentation 2 showed a slight trend in the opposite
direction, but the Direction × Valence interaction did not
approach significance (F1(1,19)=1.60, ns; F2(1,94)<1, ns).
Press Times Mean Press Times are given in Figure 1c-d.
Omnibus 2 × 2 × 2 ANOVAs showed a 3-way interaction of
Direction (upward, downward), Valence (positive,
negative), and Presentation (first, second), by subjects and
by items (F1(1,19)=9.17, p=.007; F2(1,94)=3.72, p=.06).
Presentation 1 considered alone showed the predicted
Direction × Valence interaction (F1(1,19)=4.43, p=.05;
F2(1,94)=3.32, p=.07). Presentation 2 showed a slight trend
in the opposite direction, but the Direction × Valence
interaction did not approach significance (F1(1,19)=2.84, ns;
F2(1,94)<1, ns).
Overall, there was a strong main effect of direction for
Press Times (F1(1,19)=131.62, p=.0001; F2(1,94)=764.76,
p=.0001), which was not present for Release Times. This
effect appears to be an artifact of kinematic differences
between top and bottom key presses, which used different
muscle groups due to the positioning of the keyboard. This
main effect is not relevant to the predicted motor-meaning
congruity effect.
Travel Times Neither the omnibus 3-way ANOVAs nor the
separate 2-way ANOVAs testing relationships between
Direction and Valence in Presentation 1 and Presentation 2
showed any interactions that approached significance. This
suggests that congruity effects arise during action planning
rather than action execution.
In summary, we found the predicted Direction × Valence
interaction only during the first presentation of the stimulus
words. This motor-meaning congruity effect was absent
when words were presented a second time (in Block 2). To
test the effect of repetition directly, we compared the
magnitude of the congruity effect (incongruent trials -

1942

congruent trials) across blocks, both for Release Times
(t1(19)=2.46, p=.02; t2(95)=2.37, p=.02) and Press Times
(t1(19)=3.02, p=.007; t2(95)=1.95, p=.05). Repetition
significantly reduced the effect of congruity between
movement direction and valence.

Figure 1. Results of Experiment 1. Top: RT measured from the
release of the middle key for Presentation 1 (1a) and Presentation 2
(1b). Bottom: RT measured from the press of the colored key for
Presentation 1 (1c) and Presentation 2 (1d). Error bars indicate
s.e.m.

Experiment 2: Does attentional orientation
modulate motor-meaning congruity effects?
What accounts for the disappearance of the congruity effect
when words are repeated? On one possibility, participants
may have become so efficient at performing the task that
there was no opportunity to detect any interference from
irrelevant dimensions of the stimuli: a ceiling effect. Yet an
increase in efficiency should result in an overall decrease in
reaction times from Presentation 1 to Presentation 2. Since
we found no main effect of Presentation, this explanation is
not well supported.
Alternatively, it may be that with practice, participants
are better able to attend to the relevant dimension of the
stimuli (their color) as opposed to irrelevant dimensions
(their valence, and more generally their meaning). To test
this explanation, for Experiment 2 we adapted Allport &
Wylie’s (2000) Task Set Inertia paradigm. Target trials were
the same as in Experiment 1, but distractor trials were
added. For one group of participants, the distractor trials
oriented attention toward the meanings of the target words.
For the other group, distractors oriented attention toward the
target words’ colors. We compared reaction times across
groups to determine whether attentional orientation
modulates the magnitude of space-valence congruity effects.

Methods
Participants Native English-speaking UC Berkeley
students (N=48) participated for course credit or payment.
Materials and Procedure
The experimental apparatus for Experiment 2 was the same
used in Experiment 1. The primary task was identical to
Presentation 1 of Experiment 1, except that 48 distractor
trials were added, randomly intermixed with the 96 target
trials, for a total of 144 trials. Participants were assigned to
perform one of the two versions of the task, one with
distractors designed to orient attention to the Meaning of
target words, and the other to the Color of target words.
Responses to these distractors were not recorded.
Stimuli in the Meaning Orientation condition were 24
concrete nouns, half referring to animate and half to
inanimate objects. Whereas target words were shown in
purple or green letters, distractors were in white letters.
Participants performed a go/no-go animacy judgment,
releasing and then re-pressing the middle white button to
indicate the distractor word named something animate. In
the Color Orientation condition, a 2×2 grid of grey squares
appeared. On half of the trials the grid was empty, and on
the other half an unsaturated red “X” appeared in one of the
squares, balanced across the 4 positions. Participants
performed a go/no-go X-detection judgment, re-pressing the
middle white button to indicate that a red X was present.
Only one block of trials was performed, and brief rests
were provided twice, after the first 48 trials and then after
the next 96 trials.
Initially, 16 participants were assigned to each of the
distractor conditions. Upon preliminary analyses, the
predicted congruity effect was present in the Meaning
Orientation condition but not in the Color Orientation
condition. Sixteen new participants were added to the Color
Orientation condition, to ensure that the absence of a
congruity effect was not due to lack of statistical power.
Since results for the second cohort did not differ from
results in the first, data from both cohorts were combined
for the analyses reported here.

Results and Discussion
Accuracy
Participants correctly pressed the button corresponding to
the color of the word for 100% of target trials. Performance
on distractor trials was not analyzed.
Reaction Times
Omnibus 2 × 2 × 2 ANOVAs showed no significant 3-way
interaction of Direction (upward, downward), Valence
(positive, negative), and Distractor Type (Meaning, Color).
The Press Time data showed the predicted 2-way interaction
of Direction and Valence in the Meaning Orientation
condition (F1(1,15)=6.12, p=.03; F2(1,94)=4.23, p=.04), but
not in the Color Orientation condition (F1(1,31)=.11, ns;
F2(1,94)=.55, ns). A slight trend toward the same Direction
× Valence interaction in the Meaning Orientation condition

1943

was found for Release Times (F1(1,15)=1.61, p=.22;
F2(1,94)=1.57, p=.21) and Travel Times (F1(1,15)=4.81,
p=.05; F2(1,94)=.82, p=.37). The absence of a significant
effect on Release Times was unexpected, given the results
of Expt. 1. This may have been the result of noise
introduced into the early phase of target responses when
participants were required to task-switch following
distractor trials.
To test the predicted effect of attentional orientation on
Press Times directly, we compared the magnitude of the
congruity effect (incongruent trials - congruent trials) across
conditions. According to a Wilcoxon signed rank test, the
congruity effect was greater in the Meaning Orientation
condition (15.1 ms) than in the Color Orientation condition
(1.7 ms; difference of means=13.4 ms, W=176, p=.04, onetailed). Orienting attention toward Meaning or toward Color
during distractor trials modulated the size of the motormeaning congruity effect observed during target trials.

Figure 2. Results of Experiment 2. Space-valence congruity
effects were found for target trials when distractors oriented
attention to word meaning but not to word color. Error bars
indicate s.e.m.

General Discussion
In two experiments, we show effects of congruity between
the valence of a word and the spatial direction of the
response it cued. In both experiments participants responded
only to the color of the target words, pressing the button that
matched in color. The spatial directions of the responses
were task-irrelevant, as were the meanings of the words.
Still, participants responded fastest when the direction of the
response and the valence of the word were in agreement:
upward movements for positive-valence words, and
downward for negative-valence words. The presence of
space-valence congruity effects even during shallow,
incidental processing of both space and valence suggests
that the spatial component of the words’ meanings was
activated with a high degree of automaticity.
Both experiments also illustrate that automaticity has its
limits. In Experiment 1, the motor-meaning congruity effect
was found only during the first presentation of the stimuli,
but not upon their repetition. Since there was no overall
reduction in response times between Presentation 1 and

Presentation 2, the extinction of the congruity effect does
not appear to be a ceiling effect.
Experiment 2 tested an alternative explanation for the
effect of repetition: perhaps with practice, participants
became more adept at focusing on the task-relevant
dimension of the stimuli (their color) rather than the taskirrelevant dimension (their meaning). Consistent with this
proposal, when distractor trials oriented participants to the
meaning of the target words, a strong congruity effect was
found. By contrast, when distractor trials oriented
participants to the color of the target words the congruity
effect disappeared.
It is possible to interpret both the repetition effect (in
Expt. 1) and the Task Set Inertia effect (in Expt. 2) as
effects of attention. During the initial presentation of the
words in Expt. 1 and in the Meaning Orientation condition
of Expt. 2, participants failed to fully disregard the taskirrelevant meanings of the target words, one component of
which is a spatial (or spatio-motor) representation with a
certain direction. During the second presentation in Expt. 1
and the Color Orientation condition of Expt. 2, participants
more successfully attended to the target words’ colors. In
Expt. 1, this was because the participants became better at
restricting attention to the task-relevant dimension of the
stimuli, as a result of practice. In Expt. 2, this was because
of attentional ‘inertia’ from the colored-letter-detection
distractor task.
Although this standard interpretation may be valid, there
is a potential alternative that does not rely on the construct
of attention (“psychology’s Weapon of Mass Explanation”,
according to Vincent Walsh (2003). Implicit in the
attentional account is an assumption that reading a word
activates its meaning. On standard psycholinguistic theories,
the meaning of a word is retrieved from the mental lexicon,
much the way a definition can be looked up in a dictionary.
Then attention determines how strongly the word’s meaning
is activated, and which aspects of the meaning are
highlighted.
On alternative accounts of the mental lexicon, however
(e.g., Elman, 2004), words don’t have meanings; rather,
words are cues to activate stored information. The particular
constellation of information that gets activated in any
instance depends both on the cue, per se, and on the context
in which the cue is encountered. As a consequence, a word’s
meaning is unlikely to ever be the same over successive
experiences (see James, 1892/2001). ‘Meaning’, then, is
nothing more (or less) than the effect that the word-incontext has on the representations formed in the mind of its
reader (or hearer).
On this dynamic view of word meaning, our stimulus
words cued the activation of spatio-motor representations in
some contexts more than in others. The results of the first
block of Expt. 1 suggest that the target words typically cue
upward or downward spatio-motor representations such that
these representations were activated even though they are
irrelevant to the task at hand. But the same words serve as
weaker cues for activating such task-irrelevant

1944

representations in contexts where the participant’s
experience (either with the preceding block of target trials or
with the intermixed distractor trials) has adjusted the cue
validity of the words’ color relative to validity of other
pieces of information associated with the words, such as
their valence.
Ordinarily, for the words we used as stimuli, valence has
high cue validity and the color of the ink has low cue
validity: reading that someone is a hero is normally a valid
cue that the reader should construe the referent positively,
regardless of the color hero is printed in. But the typical cue
validity of words’ color and valence is reversed in our tasks,
because of the tasks’ goals. Seeing a word in green letters is
a valid cue that the item should be construed as a member of
the category of “up-words” (or “down-words”), regardless
of the word’s valence or other aspects of its meaning. The
weights that participants assign to Color and Meaning as
cues, it seems, can be adjusted by the experience of doing
the primary task repeatedly, or by the addition of distractor
trials that require either color processing or meaning to be
processed exclusively.
The present data may be equally consistent with the first
proposed account (that words have meanings and attention
determines which parts of their meanings get activated) and
with the second (that words are cues, and the same cues
activate different sets of information depending on the
contexts in which they are encountered). Arguably, the
second view is preferable on grounds of parsimony: the
appearance and disappearance of space-valence congruity
effects can be explained based on contextual modulation of
retrieval cue weights, alone, rather than on retrieval
dynamics and the intervention of attention. Distinguishing
these accounts definitively will require further experiments.

Conclusions
Some versions of metaphor theory propose that source
domain representations are activated automatically when
people process words or concepts in target domains (Lakoff
& Johnson, 1999). Experimental results have been
interpreted as evidence for this automaticity (e.g., Meier &
Robinson, 2004). Here we show that, indeed, spatio-motor
representations are activated with a surprising degree of
automaticity when people read words with positive or
negative emotional valence. Space-valence congruity effects
are found even when both space and valence are processed
shallowly and incidentally.
The present results make clear that automaticity has its
limits. The magnitude of space-valence congruity effects
was modulated both by repetition of the valenced words and
by a Task Set Inertia manipulation (Allport & Wylie, 2000).
Spatio-motor representations may be activated by default
when people read valenced words, but their activation is
also context-dependent. These results are consistent with
dynamic views of mental metaphor and of meaning
construction, more broadly (Elman, 2004; Evans, 2009;
Feldman, 2006).

Acknowledgments
Research was supported in part by a Haas Fellowship to GB and by
an NRSA Fellowship #F32MH072502 and a grant from the
Spanish Ministry of Education and Science (#SEJ200604732/PSIC, DGI) to DC.

References
Allport, A. & Wylie, G. (2000). ‘Task-switching’, stimulusresponse bindings, and negative priming. In S. Monsell & J. S.
Driver (Eds.), Control of cognitive processes: Attention and
Performance XVIII. Cambridge: MIT press.
Barclay, J. R., Bransford, J. D., Franks, J. J., McCarrell, N. S., &
Nitsch, K. (1974). Comprehension and semantic flexibility.
Journal of Verbal Learning and Verbal Behavior, 13, 471–481.
Boroditsky, L. (2000). Metaphoric structuring: understanding time
through spatial metaphors. Cognition, 75(1), 1-28.
Casasanto, D. (2008). Universal processes generate body-specific
representations. Proceedings of the 30th Annual Conference of
the Cognitive Science Society. Washington, D.C.
Casasanto, D. (2009). Embodiment of abstract concepts: good and
bad in right- and left-handers. Journal of Experimental
Psychology: General, 138, 351-67.
Clark, H. H. (1973). Space, time, semantics and the child. In T. E.
Moore (Ed.), Cognitive Development and the Acquisition of
Language. New York: Academic Press.
Dehaene, S., Bossini, S., & Giraux, P. (1993). The mental
representation of parity and number magnitude. Journal of
Experimental Psychology: General, 122, 371–396.
Elman, L. J. (2004). An alternative view of the mental lexicon.
Trends in Cognitive Sciences, 8(7), 301-306.
Evans, V. (2009). How words mean: Lexical concepts, cognitive
models and meaning construction. Oxford, Oxford University
Press.
Feldman, J. (2006). From molecules to metaphor: A neural theory
of language. Cambridge: MIT Press.
James, W. (1892/2001). Psychology (Briefer Course). New York:
Dover Publications.
Lakoff, G., & Johnson, M. (1980). The metaphorical structure of
the human conceptual system. Cognitive Science, 4, 195–208.
Lakoff, G., & Johnson, M. (1999). Philosophy in the flesh: The
embodied mind and its challenge to Western thought. Chicago:
University of Chicago Press.
Meier, B. P. & Robinson, M. D. (2004) Why the sunny side is up:
Associations between affect and vertical position. Psychological
Science, 15, 243-247.
Meier, B. P., Robinson, M. D., Crawford, L. E., & Ahlvers, W. J.
(2007). When ‘light’ and ‘dark’ thoughts become light and dark
responses: Affect biases brightness judgments. Emotion, 7, 366376.
Murphy, G. (1996). On metaphoric representation. Cognition, 60,
173–204.
Schubert, T. (2005). Your highness: Vertical positions as
perceptual symbols of power. Journal of Personality and Social
Psychology, 89, 1–21.
Talmy, L. (1988). Force dynamics in language and cognition.
Cognitive Science, 12, 49–100.
Walsh, V. (2003) Time: the back-door of perception. TRENDS in
Cognitive Sciences, 7, 335 – 338.
Wittgenstein, L. (1953/2001). Philosophical Investigations.
Oxford: Blackwell Publishing.
Zwaan, R. A. & Yaxley, R. H. (2003). Spatial iconicity affects
semantic relatedness judgments. Psychonomic Bulletin &
Review, 10, 954–958.

1945

