UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Assessing Behavioral and Computational Approaches to Naturalistic Action Segmentation
Permalink
https://escholarship.org/uc/item/73z951gj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Meyer, Meredith
DeCamp, Philip
Hard, Bridgette
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           Assessing Behavioral and Computational Approaches
                                        to Naturalistic Action Segmentation
              Meredith Meyer1 (mermeyer@umich.edu), Philip DeCamp2 (decamp@media.mit.edu),
              Bridgette Hard3 (martin@psych.stanford.edu), Dare Baldwin4 (baldwin@uoregon.edu),
                                                Deb Roy2 (dkroy@media.mit.edu)
                         1
                           Department of Psychology, University of Michigan, Ann Arbor, MI 48103 USA
                         2
                           Media Lab, Massachusetts Institute of Technology, Cambridge, MA 02139 USA
                            3
                              Department of Psychology, Stanford University, Stanford, CA 94305 USA
                            4
                              Department of Psychology, University of Oregon, Eugene, OR 97403 USA
                              Abstract                                  by a hierarchy reflecting the goals and sub-goals of an actor
   Recognizing where one action ends and another begins is an
                                                                        (e.g., Schank & Abelson, 1977).
   automatic and seemingly effortless process that supports                Notably, human observers’ skill in segmenting the action
   understanding of goal-directed action. One characteristic of         stream has been observed on a variety of different levels in
   such action segmentation is that it is hierarchical; it reflects     line with this hierarchical structure. For example,
   the goals and sub-goals of an actor, which correspond to             segmentation of “chop carrot” can be on a coarse level, with
   coarse- and fine-grained action units respectively. We report        event boundaries noted at the onset and offset of the entire
   on the success of one method of assessing hierarchical               chopping event, or it can be on a fine level, with each
   segmentation of naturalistic footage taken from an extensive
   corpus of unscripted human action (Speechome project, e.g.,          vertical movement of the knife noted as marking a discrete
   Roy et al., 2006). Results indicate that hierarchical                unit. In tasks assessing hierarchical segmentation, here again
   segmentation occurs in an on-line fashion, with event                a high degree of consistency has been observed in people’s
   boundaries marked by surges in attention that are modulated          segmentation behaviors (e.g., Hard, 2006; Zacks et al.,
   based on whether a boundary marks a fine, intermediate, or           2001a), and fMRI studies have revealed differing activation
   coarse unit. We also describe a method by which objective            levels in frontal and posterior areas in response to fine and
   changes in an actor’s movement can be measured and
                                                                        coarse event boundaries, suggesting that the distinction
   analyzed as a predictor of participants’ segmentation
   behaviors.                                                           between fine and coarse units is psychologically real on a
                                                                        neural level (e.g., Zacks et al., 2001b).
   Keywords: action segmentation; event processing                         The ability to determine when one action has ended and
                                                                        another has begun, as well as segmenting action on multiple
   Drawing inferences and generating predictions about                  levels, supports how we make sense of the goal-directed
others’ actions are processes most people undertake every               action we observe in others. The fact that hierarchical event
day. The ways in which people use such inferences and                   segmentation appears to be a relatively effortless process
predictions to make sense of others’ action is supported in             despite the complexity of the action stream itself suggests
part by the ability to segment continuous action into discrete          the workings of an equally complex system enabling this
units. For instance, while observing an individual preparing            segmentation. Of particular relevance for the current studies,
dinner, we might identify and recognize individual units of             work by Hard and colleague (e.g., Hard, 2006; Hard &
action such as chopping a carrot, opening a refrigerator, or            Recchia, 2006) suggests that event boundaries are processed
rinsing off a dish. Investigations of action segmentation               differently than within-unit moments, with the detection of
have suggested that people are highly consistent in where               boundaries associated with a transient increase in cognitive
they judge event boundaries to exist; people typically report           processing load.
dynamic human action to consist of units corresponding to                  The idea that event boundaries might elicit an upsurge in
initiation or completion of goals, with considerable                    cognitive processing is consistent with a comprehensive
agreement across individuals regarding where event                      account of action segmentation put forth by Zacks and
boundaries are located (Baldwin & Baird, 1999; Newtson,                 colleagues. These authors (e.g., Kurby & Zacks, 2007;
Engquist, & Bois, 1977; Zacks, Tversky, & Iyer, 2001).                  Zacks et al., 2007) describe the Event Segmentation Theory,
Further, action segmentation is seemingly spontaneous and               an account of how the human observer perceives and
automatic, engaged in as a routine and ongoing component                conceptualizes action in terms of events. A crucial
of perception (Hard, 2006; Zacks & Swallow, 2007).                      component of Event Segmentation Theory rests on the
   The apparent ease with which people recognize                        observer’s ability to make predictions about upcoming
breakpoints in action is remarkable given the complexity of             action. Such prediction generation is considered a
the action stream itself. Human action is unquestionably a              spontaneous, online process that integrates incoming
rich and highly variable stimulus; it is evanescent, often              sensory information with prior knowledge and learning in
proceeds without pauses to mark the completion of                       an attempt to create a stable “event model.” Event units
individual units, and frequently features occlusion of                  correspond to periods in which prediction error rate is low;
relevant objects and body parts. Further, the underlying                the observed action is consistent with the predictions being
structure of action is also complex, typically characterized
                                                                    2710

made by the perceptual system, and the event model is               comparison to images taken from within action units,
stable. For example, within the event of cleaning off plates        suggesting that breakpoints elicited surges in attention.
at the kitchen sink, the predictive system is able to generate      Further, paralleling results observed in text processing, the
accurate predictions of further plate cleaning based on such        effect was modulated by the level of the action breakpoint,
cues as the person’s movements and prior knowledge about            with slides close in time to moments judged as coarse-
kitchen clean-up. Event boundaries, in contrast, are                grained breakpoints receiving the longest looking times and
experienced when prediction error rate is high; to extend the       those near fine-grained breakpoints receiving the least. This
example above, such boundary moments are likely to occur            phenomenon, dubbed the dwell time effect, provided
at the completion of a task (e.g., cleaning off plates in the       evidence that hierarchical segmentation occurs as part of
kitchen) and before the initiation of another task (e.g.,           real-time perception, without requiring explicit after-the-fact
wiping the countertop), because these moments correspond            judgments of breakpoint locations. It further demonstrated
with a reduced ability to predict the onset and content of the      the cognitive importance of action breakpoints; heightened
second event.                                                       attention was associated with moments participants
   In order to update the event model at moments of reduced         explicitly judged to be breakpoints, and this effect was
predictability, the system is believed to increase attention to     modulated based on whether that breakpoint was judged to
the perceptual characteristics of the action stream and to          be coarse, intermediate, or fine.
activate new event schemata to replace the prior                       In the current paper, we report on another study that
unsuccessful one. Hard and colleague (Hard, 2006; Hard &            investigated hierarchical processing of action, this time
Recchia, 2006) provided an empirical test of whether                using in vivo recordings collected from the Human
boundaries were indeed associated with differential degrees         Speechome Project. Audio-video data was collected from
of cognitive processing. As their methodology formed the            from the home of a single child using 11 ceiling mounted
basis of the first experiment in the current study, an in-depth     cameras and 16 boundary layer microphones. Over the first
explanation of their methods is in order. These authors             three years of the child’s life, 90,000 hours of video was
reasoned that well-known paradigms developed for                    collected, representing roughly 70% of the child’s waking
investigations of hierarchical processing of text would also        experience (Roy et al., 2006).
be suitable for revealing aspects of hierarchical processing           As described above, past work has made much progress
of action. In one such text processing study, individuals saw       on elucidating the cognitive processes that make up the
one word at a time from a passage of text and advanced              system enabling segmentation; however, these studies have
themselves through word-by-word by pressing a button. The           examined segmentation of either scripted or animated
length of time between button presses was the primary               scenes (e.g., Hard, 2006; Hard & Recchia, 2006; Zacks,
dependent variable in this “moving window” method, with             2004; Zacks et al., 2001a; Zacks, Kumar, & Abrams, 2009).
the idea being that longer reading times would be indicative        The use of Speechome footage has the advantage of
of increased cognitive load associated with integration of          providing unscripted activity, allowing a test of the validity
past elements within and across text units into                     of methods that have been successful in revealing aspects of
comprehensible larger units. Results indicated that                 hierarchical segmentation of more artificial action scenes.
participants tended to spend longer periods of time on words        Validation of the dwell time paradigm in Speechome
located at the ends of unit boundaries. Further, this “wrap         footage additionally provides opportunities for the
up” effect was modulated by the level of any given unit;            assessment of automated means of detecting action units,
reading times were longer for words located at the ends of          the topic taken up in Study 2.
clauses and longer still for words located at the ends of
sentences (Haberlandt & Graesser, 1989).                                                 Study 1 Method
   To study processing of hierarchical action using a similar
technique, Hard and colleague adapted the moving window             Stimuli
method for use with human action by asking participants to             Images for a slideshow viewing task were created by
advance through a sequence of still-frame images. These             extracting one image every second from a 108-second
images were taken from regular time intervals of footage of         movie clip take from the Speechome corpus (e.g., see Figure
scripted human goal-directed action (e.g., one still-frame          1). The clip selected depicts an adult male preparing a meal.
image sampled every second). Following this “slideshow”             This video clip also served as the live action footage for
viewing phase, participants watched the live action footage         which participants provided explicit segmentation
from which the still images had been sampled and marked             judgments. For the explicit segmentation task, a different,
with a button press the locations of action boundaries              40-second clip of a woman cleaning the kitchen was used
(hereafter, ‘breakpoints’). Participants completed this             for training purposes.
segmentation task a total of three times, providing
judgments on fine, intermediate, and coarse levels.                 Participants and Procedure
   Results from the slideshow task indicated that participants
                                                                       Participants were 28 university students (14 male)
tended to spend a longer period of time looking at images
                                                                    receiving class credit for participation. The experiment had
close in time to moments judged to be breakpoints in
                                                                    two major phases, the slideshow viewing task and the
                                                                2711

                                                                    the least (M coarse = 5.75 [SD = 2.81]), F (1.13, 30.42) =
                                                                    61.44, p < .0001. (Greenhouse-Geisser statistics are reported
                                                                    due to violations in sphericity.) A significant linear trend
                                                                    characterized these data, F (1, 27) = 64.18, p < .0001. Thus,
                                                                    participants were clearly capable of recognizing breakpoints
                                                                    on different levels, providing the predicted differences in
                                                                    number of judgments according to level (fine vs.
                                                                    intermediate vs. coarse). As well, although individual
   Figure 1: Sample image from slideshow depicting a person         differences in number of judgments were substantial
                       preparing food.                              (particularly in fine and intermediate judgments, as
                                                                    evidenced by the large standard deviations), 100% of
explicit segmentation judgment task. All participants began         participants provided the most judgments for fine
the session with the slideshow viewing task, in which they          breakpoints and the least for coarse breakpoints (sig. by a
were instructed to advance at their own pace through the            binomial test, p < .0001).
108 still-frame images. Participants were told to click a              Participants were also fairly consistent in where they
mouse to advance the pictures. A Macintosh G4 computer              marked the locations of breakpoints. Figure 2 displays the
was used to present stimuli on a 19.5” x 12” monitor, and           number of fine, intermediate, and coarse level judgments
Psychtoolbox (Brainard, 1997) was used to record                    across the 108 seconds of footage, with judgments “binned”
participants’ responses.                                            into one-second intervals. As demonstrated by the distinct
   Following the slideshow, participants heard a brief              peaks and valleys reflecting moments commonly judged and
description of how action can be seen as consisting of units,       rarely judged as breakpoints, respectively, it is apparent that
and examples of fine, intermediate, and coarse units in             participants frequently marked the same moments for all
actions unrelated to those displayed during test were               three levels of judgments, a pattern largely consistent with
provided in these instructions. Participants then provided          past studies using the same explicit segmentation method
explicit judgments of where they believed breakpoints to be         (e.g., Hard, 2006; Zacks et al., 2001a; Zacks et al., 2009).
located, first providing judgments for the training video and
then for the 108-second test (Speechome) video.                                            25
                                                                        No. of Judgments
Participants indicated their judgments with a key press.
Participants were asked to provide segmentation judgments                                  20
on fine, intermediate, and coarse levels, resulting in a total                             15                               9ine
of three viewings of the movie clip. Half of the participants                              10
were asked to segment on a fine level on their first viewing                                                                intermediate
of the clips, followed by segmenting on an intermediate                                    5
                                                                                                                            coarse
level, and finishing with segmenting on a coarse level (fine-                              0
to-coarse order). The other half was asked to segment in the
                                                                                                  1
                                                                                                 11
                                                                                                 21
                                                                                                 31
                                                                                                 41
                                                                                                 51
                                                                                                 61
reverse order (coarse-to-fine order). Assignment of
                                                                                                 71
                                                                                                 81
                                                                                                 91
                                                                                                101
participants to these orders was random.                            Figure 2: Participants’ explicit judgments of fine, intermediate, and
                                                                                          coarse level boundaries.
                    Study 1 Results
                                                                    Does dwell time increase at breakpoints?
Do participants’ explicit segmentation judgments reflect            We next turned to one of the major hypotheses guiding
understanding of hierarchical structure?                            Study 1, namely that participants’ dwell time would be
One important preliminary question to answer is whether             longer for images judged to be breakpoints compared to
participants understood our instructions regarding                  those that weren’t. We used the participants’ own explicit
segmentation on fine, intermediate, and coarse levels.              segmentation judgments, provided during the segmentation
Because we planned to compare the dwell times provided by           task, as the basis for determining which slides were
each subject to their explicit breakpoint judgments made            considered breakpoints. Specifically, we applied a binning
afterwards, it was important to ensure that participants            method, splitting the 108-second test clip into 1 second
differentiated among fine-, intermediate-, and coarse-level         intervals, each corresponding to a single slide. Breakpoint
breakpoints during the explicit segmentation task.                  judgments that fell into a given interval were matched to the
  Evidence for this understanding comes in part from                corresponding slide, allowing us to classify breakpoint vs.
results indicating that participants provided significantly         non-breakpoint slides for each participant.
different numbers of judgments for breakpoints at different            We then treated participants’ raw dwell times to
levels, with fine-level breakpoints receiving the most              individual slides according to the following steps. Outliers
judgments (M fine = 39.04 [SD = 23.32]), intermediate-              (>3 SD above an individual’s mean dwell time to all 108
level breakpoints receiving the next most (M intermediate =         slides) were removed from the data. Data were positively
12.68 [SD = 8 86]), and coarse-level breakpoints receiving          skewed, and thus a log transformation was applied. Due to
                                                                 2712

participants’ tendency to dwell longer on slides at the              receiving the shortest dwell-times. The main effect for order
beginning of the sequence and to speed up as the task                was not significant (M coarse-to-fine = .161, SEM = .057; M
continued, most participants’ data were consistent with a            fine-to-coarse = .087, SEM = .073), F (1, 26) = 1.23, p >
power function. Significant portions of the variance were            .05; there also was no order x segmentation level significant
accounted for by the model for all participants (highest p           interaction (F (1.57, 39.43) = .95, p > .05.
value was .02). Thus, data were de-trended, and the
residuals calculated based on the power function were used                                                                        0.47
                                                                                                  0.6
for analysis.
                                                                              Dwell Time Scores
   Because there were unequal numbers of slides in the
different classifications (e.g., far fewer slides classified as                                   0.4                 0.22
breakpoints vs. non-breakpoints), means for each type were
                                                                                                  0.2   0.03
divided by standard deviations of that type, producing an
effect size. All reported analyses are on these scores,
hereafter referred to as dwell time scores. (Note that dwell                                       0
time scores can be zero or negative since the residuals                                                 9ine      intermediate   coarse
represent the difference between actual dwell time and times
predicted by the power function; however, it is still the case                Figure 3: Dwell-time scores to slides designated as fine,
that higher dwell time scores indicate overall longer                    intermediate, and coarse breakpoint. Data were characterized by a
dwelling on any given slide.)                                                                 linear trend, p < .0001.
   A 2 (breakpoint status: breakpoint vs. non breakpoint) x 2
(segmentation order: fine-to-coarse vs. coarse-to-fine)
                                                                                                               Study 2
mixed ANOVA (with breakpoint status as a within-subjects               Another line of investigation in action segmentation has
variable and segmentation order as a between-subjects                focused on determining what perceptible features in the
variable) revealed only the predicted breakpoint status              movement stream are relevant to segmentation. For
effect. Dwell time scores for breakpoint slides (M = .124,           instance, in the same study in which Hard and Recchia
SEM = .046) were higher than for non-breakpoint (within-             (2006) showed attentional differences to event boundaries,
unit) slides (M = -.044, SEM = .026), F (1,26) = 6.40, p =           they additionally found that greater body movements on the
.02. The main effect for segmentation order was not                  part of the actor (as measured by overall pixel change
significant (M fine-to-coarse = .01, SEM .03; M coarse-to-           between slides) significantly predicted observers’
fine = .07, SEM = .02), F (1, 26) = 3.1, p > .05, nor was the        segmentation behavior. Similarly, in Zacks and colleagues’
segmentation order x breakpoint status interaction                   (2009) investigation of live action, the authors studied how
significant, F (1, 26) = .03, p > .05. Dwell time scores were        changes in movement features such as the actor’s
thus higher for breakpoints than non-breakpoints,                    acceleration and speed were predictive of observers’ explicit
supporting the first hypothesis.                                     segmentation judgments. In that study, an actor wore
                                                                     magnetic tracking devices on his hands while filming an
Do dwell times vary according to fine, intermediate, and             action sequence, allowing for later extraction and
coarse levels?                                                       calculation of the relevant movement features. The authors
  Using the same binning method used to distinguish                  found that several movement features, including speed,
between breakpoint and non-breakpoint slides for each                acceleration, and change in distances among the actor’s
participant, classification of slides as breakpoints vs. non-        hands and head were predictive of observers’ segmentation
breakpoints for each individual participant, slides were             judgments, particularly for fine-grained event markings (see
additionally categorized as falling at fine, intermediate, and       also Zacks 2004 for similar analyses with animated figures).
coarse level boundaries. We then examined whether the                  The ability to predict event boundaries based on
dwell time effect was modulated based on whether a                   perceptible features that can be extracted from video has
breakpoint was judged to be on a fine, intermediate, or              great relevance to designers of informational systems that
coarse level. A 3 (segmentation level: fine, coarse,                 use identified actions as units of analysis. In addition to
intermediate) x 2 (order: fine-to-coarse vs. coarse-to-fine)         testing the validity of the dwell-time methodologies in
mixed between-within ANOVA was run, with segmentation                naturalistic action, another goal of the current paper was to
level as the within-subjects variable and order as the               assess whether features visible in the action input were
between-subjects variable. Because of sphericity violations,         predictive of individuals' segmentation judgments. In Study
we report Greenhouse-Geisser statistics. The predicted main          2, we extracted a set of predictive features, then analyzed
effect for segmentation level was found, F (1.52, 39.43) =           how well these predictors correlated to the human
16.17, p < .0001 (see Figure 3 for means). These differences         judgments collected for Study 1
were characterized by a significant linear trend, F (1, 26) =
21.20, p < .0001, with coarse-level breakpoi nts    receiving
                                                                                                        Study 2 Method
the longest dwell times, intermediate-level breakpoints
receiving the next longest, and fine-level breakpoints                 A set of motion features was extracted from the
                                                                     Speechome test clip using an accurate, semi-automatic
                                                                  2713

tracking system to annotate the positions of the body and                                                Discussion
hands of the actor appearing in the video (DeCamp & Roy,
                                                                                In Study 1, we examined human observers’ segmentation of
2009). Positions were recorded as image coordinates (2D
                                                                                naturalistic action, taking our stimuli from a large corpus of
positions on the image, as compared to 3D positions in real
                                                                                unscripted action (Speechome, e.g., Roy, 2006). Participants
space). Body position was defined as the center of the
                                                                                tended to dwell on images depicting breakpoints longer than
visible portion of the actor's head and torso. The positions
                                                                                non-breakpoints, and this difference was modulated based
of the hands were defined relative to the position of the
                                                                                on whether a breakpoint was judged to be marking the
body in order to reduce the covariance between them. After                      completion of a fine-, intermediate-, or coarse-level unit.
the position information was collected from the test video, it                  Despite the fact that our stimuli depicted naturalistic action,
was used to compute the speed and acceleration of each                          as well as the fact that participants had a decidedly different
body part, resulting in six features (see Table 1). The first                   viewpoint of the action sequence itself than past studies of
and last seconds of data were also removed from analysis at                     action (i.e., a ceiling-mounted camera provided the stimuli,
this point because it was not possible to robustly define                       and thus participants saw the actor from above), we
speed and acceleration at these points.                                         replicated past findings of the dwell time effect (e.g., Hard,
   Kernel density estimation was applied to the breakpoints                     2006; Hard & Recchia, 2006). Our findings suggest that the
at each granularity level (i.e., fine, intermediate, and                        dwell time effect is a robust and valid phenomenon, capable
coarse). While this process smoothed the data, it also                          of providing another window into the cognitive processes
provided a continuous distribution of the breakpoints over                      underlying segmentation.
time, which was more convenient for analysis than the raw                          The fact that participants’ implicit behavior (dwell time)
judgment counts. Density estimation was performed with a                        was associated with their explicit segmentation judgments
Gaussian kernel. Bandwidths at were selected for each level                     also offers an exciting direction for future research within
using unbiased cross-validation, resulting in 0.92 s for fine                   the developmental domain. There is clear indication already
breakpoints, 1.13 s for intermediate, and 1.27 s for coarse.                    that infants as young as nine months can segment an action
                                                                                stream, a remarkable finding given infants’ relatively
                                 Study 2 Results                                impoverished understanding of goals and intentions (e.g.,
  We found that each of the six features was significantly                      Baldwin et al., 2001; Saylor et al., 2007). Although this
correlated to each breakpoint distribution (all p’s < .001, see                 work represents an important demonstration of infants’
Table 1). The body speed feature achieved the highest                           action processing skill, the adaptation of dwell time
correlation (r = 0.71) when correlated with coarse-grained                      methodology to this population has the potential to further
judgments (see Figure 4). Right and left hand speeds had                        expand our understanding of the developmental trajectory
maximum correlations of 0.64 and 0.35, respectively. The                        characterizing the segmentation process. The looking time
acceleration features performed slightly worse, but were                        methods used in these past developmental studies were not
nevertheless significant.                                                       suitable for discerning hierarchical processing; further, the
                                                                                work examining hierarchical processing in adults has largely
                          Table 1: Correlations Between Visual                  relied on participants’ explicit understanding of what
                          Features and Breakpoint Distribution                  constitutes fine, intermediate, and coarse units (e.g., Zacks
                                           Correlation                          et al., 2001a, 2001b; Zacks et al., 2009), a task that is clearly
                                           Fine        Intermed    Coarse       beyond the capacity of infants and young children. We are
              Body Speed                   0.49        0.65        0.71         actively pursuing adapting dwell time techniques for use
                                                                                both with preverbal infants as well as young preschool-aged
              Right-Hand Speed             0.47        0.64        0.64
                                                                                children (e.g., Meyer, Hard, & Baldwin, 2009), a
              Left-Hand Speed              0.45        0.44        0.35         methodological advance that will allow us to study
              Body Accel                   0.40        0.52        0.54         hierarchical processing across the lifespan.
              Right-Hand Accel             0.35        0.51        0.47            In Study 2, we examined how perceptible movement
              Left-Hand Accel              0.34        0.40        0.36         features predicted human observers’ judgments. Our results
                                                                                demonstrated that specific sources of information (i.e., head
                                                                                and hand speed and acceleration) were significantly
                                                                                associated with participants’ segmentation judgments. Our
                         coarse breakpoints
                         regression                                             results are consistent with similar movement change
              0.04
Probability
                                                                                analyses performed by Zacks et al. (2009), suggesting that
              0.02                                                              analysis of movement features may have broad utility in the
                                                                                design of automated systems of action analysis.
              0.00                                                                 Notably, we additionally observed results that differed
                     0      20        40          60          80   100          from those of Zacks et al., (2009); whereas we observed
                                      Time (seconds)                            lower correlations as the judgment granularity was increased
               Figure 4: Univariate linear regression on coarse breakpoint      (i.e., correlations were highest when examining coarse-
                      distribution using body speed as predictor.               grained judgments and lowest when examining fine-grained
                                                                             2714

judgments), Zacks and colleagues actually observed the               Video Retrieval (CIVR).
opposite. We speculate that this might be attributed to the         Haberlandt, K., & Graesser, A. C. (1989). Processing of
differences between videos; in our footage the actor had no          new arguments at clause boundaries. Memory &
discernible facial features, and local movements of the              Cognition, 17, 186-193.
hands and fingers were difficult to see; this may have              Hard, B. (2006). Reading the language of action:
reduced the ability of subjects to identify breakpoints as           Hierarchical encoding of observed behavior. Doctoral
consistently at finer granularities. As well, the actor in our       dissertation, Stanford University.
video moved his entire body through space (e.g., walking            Hard, B., & Recchia, G. (2006). Reading the language of
from a kitchen island to the sink), whereas the actor in             action. In N.A. Taatgen & H. van Rijn (Eds.), Proceedings
Zacks et al.'s videos was seated. These gross bodily                 of the 28th Annual Conference of the Cognitive Science
movements were frequently judged as coarse breakpoints               Society, (pp. 1433-1439), Vancouver, CA.
and were clearly associated with several of our movement            Kurby, C. A., & Zacks, J. M. (2008). Segmentation in the
cues. Finally, the use of 2D video annotations in place of 3D         perception and memory of events. Trends in Cognitive
motion sensor features may have provided less accurate                Sciences, 12, 72-79.
measures that limited our ability to predict finer-grain            Meyer, M., Hard, B., & Baldwin, D. (2009, October).
events. In any event, the differences we observe offer                Children’s processing of action boundaries. Poster
inviting topics for future investigation relevant to the              presented at Cognitive Development Society, San
development of automated action analysis.                             Antonio, TX.
   To summarize, we both validated the dwell time effect in         Newtson, D., Engquist, G., & Bois, J. (1977). The objective
naturalistic stimuli as well as found objective movement              basis of behavior units. Journal of Personality and Social
parameters predictive of individuals’ segmentation                   Psychology, 35, 847–862.
behavior. The latter finding is of great relevance for              Roy, D., Patel, R., DeCamp, P., Kubat, R., Fleischman, M.,
researchers developing automated action analysis systems.            Roy, B., Mavridis, N., Tellex, S., Salata, A., Guinness, J.,
Given that tracking whole people is now feasible for many            Levit, M., & Gorniak, P. (2006). The human speechome
types of video, current tracking technologies may enable the         project. Symbol Grounding and Beyond: Proceedings of
first steps towards systems that can automatically segment           the Third International Workshop on the Emergence and
and identify actions from raw video, opening up new                  Evolution of Linguistic Communication. (pp. 192-168).
possibilities for human behavioral analysis.                        Saylor, M. M., Baldwin, D., Baird, J. A., & LaBounty, J.
   Human action is an undeniably rich and complex                    (2007). Infants’ on-line segmentation of dynamic human
stimulus. Yet, as we parse the events of our daily lives with        action. Journal of Cognition and Development, 8, 113-
little thought or apparent effort, the process may strike us as      128.
trivially easy. Nevertheless, the complexity of human action        Schank, R. C., & Abelson, R. P. (1977). Scripts, plans,
is apparent upon any attempt at formalization, and it poses a        goals, and understanding: An inquiry into human
considerable challenge towards understanding human                    knowledge structures. Hillsdale, NJ: Lawrence Erlbaum
cognition. In this paper, we supply part of the solution by           Associates.
demonstrating how the human mind reacts and imparts                 Zacks, J. M. (2004). Using movement and intentions to
structure to action sequences as they unfold. We also                understand simple events. Cognitive Science, 28, 979–
provide promising results from attempts to predict and               1008.
model these reactions, suggesting future possibilities for the      Zacks, J. M., Braver, T. S., Sheridan, M. A., Donaldson, D.
data driven analysis of events at a massive scale.                    I., Snyder, A. Z., Ollinger, J. M., et al. (2001b). Human
                                                                      brain activity time-locked to perceptual event boundaries.
                   Acknowledgements                                  Nature Neuroscience, 4, 651–655.
                                                                    Zacks, J. M., Kumar, S., & Abrams, R. A. (2009). Using
   This research was supported by the U.S. Office of Naval
                                                                     movement and intentions to understand human activity.
Research, award no. N000140910187.
                                                                     Cognition, 201, 201-216.
                                                                    Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S., &
                         References                                  Reynolds, J. R. (2007). Event perception: A mind/brain
Baldwin, D., & Baird, J. A. (1999). Action analysis: A               perspective. Psychological Bulletin, 133, 273-293.
   gateway to intentional inference. In P. Rochat (Ed.), Early      Zacks, J. M. & Swallow, K. M. (2007). Event segmentation.
   social cognition, (pp. 215–240). Hillsdale, NJ: Lawrence          Current Directions in Psychological Science, 16, 80-84.
   Erlbaum Associates.                                              Zacks, J. M., Tversky, B., & Iyer, G. (2001a). Perceiving,
Baldwin, D., Baird, J., Saylor, M. M., & Clark, M. A.                remembering, and communicating structure in events.
   (2001). Infants parse dynamic action. Child Development,          Journal of Experimental Psychology: General, 130, 29–
   72, 708–718.                                                      58.
DeCamp, P., & Roy, D. (2009). Human-machine
   collaborative approach to tracking human movement in
   multi-camera video. Proceedings of the 2009
   International Conference on Content-based Image and
                                                                2715

