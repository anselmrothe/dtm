UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Adaptive Integrative Ambient Agent Model to Intervene in the Dynamics of Beliefs and
Emotions

Permalink
https://escholarship.org/uc/item/62b0h2n3

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Memon, Zulfiqar Ali
Treur, Jan

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

An Adaptive Integrative Ambient Agent Model
to Intervene in the Dynamics of Beliefs and Emotions
Zulfiqar A. Memon 1,2, Jan Treur 1 ({zamemon, treur}@few.vu.nl)
1

VU University Amsterdam, Department of Artificial Intelligence,
De Boelelaan 1081, 1081 HV Amsterdam, The Netherlands
2
Sukkur Institute of Business Administration (Sukkur IBA),
Air Port Road Sukkur, Sindh, Pakistan

generation process beliefs trigger emotional responses that
result in certain feelings. In a reciprocal manner, the
generated feelings affect the belief as well; for some
literature on such reciprocal interactions between cognitive
and affective astates, see, for example, (Eich, Kihlstrom,
Bower, Forgas, and Niedenthal, 2000; Forgas, Goldenberg,
and Unkelbach, 2009; Niedenthal, 2007; Schooler and Eich,
2000; Winkielman, Niedenthal, and Oberman, 2009).
In this paper, a computational dynamic model is adopted
from (Memon and Treur, 2009) that models the client’s
reciprocal interaction between feeling and believing. This
model is based on neurological theories on the embodiement
of emotions as described, for example, in (Damasio, 1994,
1996, 1999, 2004; Winkielman, Niedenthal, and Oberman,
2009). More specifically, in accordance with, for example
(Damasio, 1999, 2004), for feeling the emotion associated to
a belief a converging recursive body loop is assumed. A
second converging feedback loop introduced in the model,
inspired the Somatic Marker Hypothesis (Damasio, 1994,
1996), involves the interaction back from the feeling to the
belief.
This dynamical model is integrated within an ambient
agent model to enable the agent to assess the strength of the
belief and feeling, and to intervene when desired. As a
personal characteristic represented by a parameter indicating
a bias of the belief in a positive or negative direction, is hard
to determine at forehand, the ambient agent is equipped with
an adaptation model to adjust the value of this parameter
over time. This results in an adaptive integrative agent model
that learns to estimate the human’s belief and feeling better
and better over time.
To illustrate the model, the following example scenario is
used. A person (client) develops strong (false) beliefs due to
strong negative feelings (of insecurity) about a product
offered by the bank, for example, buying bonds or shares.
The ambient agent estimates the level of belief and feeling of
the client related to this insecurity. When the client becomes
too insecure, i.e., the emotion level goes above certain
threshold, the ambient agent can take measures in order to
achieve a reduction of the insecure feeling, e.g., by providing
information that makes the client feel more secure.
In this paper, first in Section 2 the dynamical model for the
interaction between belief and feeling is described. In
Section 3 the ambient agent model is described which
integrates the dynamical model. Section 4 describes the
parameter adaptation model integrated within the agent.
Section 5 presents some simulation results. Finally, Section 6
is a discussion.

Abstract
In this paper an adaptive integrative ambient agent model is
introduced incorporating estimation of a human’s interactive
dynamics of believing and feeling. The integrative agent
model is equipped with a dynamical model which describes
how the strength of a belief depends both on information
obtained and emotional responses on the belief. In addition,
the agent model integrates an adaptation model to tune
parameter values representing personal characteristics. In a
simple personalised case it is shown how the ambient agent
model is able to assess a person’s state and use this assessment
to interact in a personalised manner.
Keywords: Integrative agent, believing, feeling, adaptive

Introduction
An important and interesting recent class of applications for
software/hardware agents can be found in Ambient
Intelligence: the area of ambient or pervasive systems; e.g.,
(Aarts, Collier, Loenen, Ruyter, 2003; Aarts, Harwig,
Schuurmans, 2001; Riva, Vatalaro, Davide, Alcañiz, 2005).
One of the more ambitious challenges in this area is to create
ambient agents with an appropriate awareness of the (mental)
states of humans. Human-aware ambient agent systems can
be taken to perform a certain type of mindreading or to
possess what in the psychological and philosophical
literature is called a Theory of Mind; e.g., (Gärdenfors, 2003;
Goldman, 2006). As developed during the evolutionary
human history, mindreading addresses different types of
mental states, such as intention, attention, belief or emotion
states; e.g., see (Gärdenfors, 2003). Inspired by these
facilities available in nature, ambient agent models can be
developed that have mindreading capabilities for one or
some of these types of mental states. However, it is more and
more acknowledged that such mental states can be quite
dynamic and often interact with each other intensively. To
obtain an adequate ambient agent model, dynamical models
describing such dynamics and interaction has to be integrated
within the agent model.
Human-aware ambient agent systems equipped with the
ability to reason about the different types of mental states can
be applied in the area of personalised customer relationships
and marketing. A recent trend is to dig deeper into the
clients’ minds and lives. The work reported here focuses on
the dynamics and interaction of an individual client’s beliefs
and emotions and integrates models for these dynamics in an
ambient agent model to provide effective intelligent
marketing strategies by a better understanding of the
cognitive and affective system of the client. In their

441

Belief and Emotion
In this section a computational model for the interaction
between believing and feeling is briefly discussed, as
adopted from (Memon and Treur, 2009). As any mental state
in a person, a belief state induces emotions felt within this
person, as described by Damasio (1999; 2004, p. 93):

world_
sensor_
state(w, V) state(w, V)

belief → preparation for bodily response → bodily response
→ sensing the bodily response → sensory representation of
the bodily response → feeling

sensor_
state(b,V)

As a variation, an ‘as if body loop’ uses a direct causal
relation: preparation for the bodily response → sensory
representation of the bodily response; as a shortcut in the causal
chain. The body loop (or as if body loop) is extended to a
recursive body loop (or recursive as if body loop) by
assuming that the preparation of the bodily response is also
affected by the state of feeling the emotion: feeling →
preparation for the bodily response; as an additional causal
relation. Within the model used in this paper both the bodily
response and the feeling are assigned a level, expressed by a
number; for example, the strength of a smile and the extent
of happiness.
Although beliefs in an idealised rational agent might only
depend on informational sources, real life persons may, for
example, have a more optimistic or pessimistic character and
affect their beliefs accordingly. To model this a causal
relation: feeling → belief; is added. Therefore two recursive
loops result, as shown in Figure 1. From a neurological
perspective the existence of a connection from feeling to
belief may be considered plausible, as this may be developed
based on a general Hebbian learning mechanism (Hebb,
1949; Bi and Poo, 2001) that strengthens connections
between neurons that are activated simultaneously. Another
type of support for a connection from feeling to belief can be
found in Damasio’s Somatic Marker Hypothesis; cf.
(Damasio, 1994, 1996; Bechara and Damasio, 2004;
Damasio, 2004). This is a theory on decision making which
provides a central role to emotions felt. Each decision option
induces (via an emotional response) a feeling which is used
to mark the option. Usually the Somatic Marker Hypothesis
is applied to provide endorsements or valuations for options
for a person’s actions. However, it may be considered
plausible that such a mechanism is applicable to valuations
of internal states such as beliefs as well.
The hybrid dynamic modelling language LEADSTO used
subsumes qualitative and quantitative causal relationships,
and dynamical systems; cf. (Bosse, Jonker, Meij and Treur,
→ b
2007). Within LEADSTO the temporal relation a →
denotes that when a state property a occurs, then after a
certain time delay (which for each relation instance can be
specified as any positive real number), state property b will
occur. A dedicated software environment is available to
support specification and simulation.
An overview of the model for believing and feeling is
depicted in Figure 1. Note that the precise numerical
relations between the indicated variables V shown are not
expressed in this picture. The detailed specification of the
model can be found in (Memon and Treur, 2009).

srs(w, V)

srs(b, V)

belief(w, V)

preparation_
state(b, V)

effector_
state(b, V)

feeling(b, V)

body_state(b,V)

Figure 1: Dynamical model for belief and feeling

As an example, the dynamic property for the process for
belief generation is described. The level for the belief is
calculated based on a function g(β, V1, V2) of the original
levels, where β is the personal characteristic (with values
from 0 to 1) indicating positive or negatieve bias for the
belief.
LP3 Generating a belief for a feeling and a sensory representation

If
and
and
and
and
then

a sensory representation for w with level V1 occurs,
the associated feeling of b with level V2 occurs
the belief for w has level V3
β1 is the person’s orientation for believing
γ1 is the person’s flexibility for beliefs
a belief for w with level V3 + γ1 (g(β1, V1, V2)-V3) ∆t
will occur.

has_state(human, srs(w, V1)) &
has_state(human, feeling(b, V2)) &
has_state(human, belief(w, V3) )
→ has_state(human, belief(w, V3 + γ1 (g(β 1, V1,V2) - V3) ∆t)

For the function g(β, V1, V2) the following was taken:
g(β, V1, V2) = β(1-(1-V1)(1-V2)) + (1-β)V1V2
Dynamic property LP4 describes the emotional response to a
belief in the form of the preparation for a specific bodily
reaction. This dynamic property uses the same combination
model based on g(β, V1, V2) as above.
LP4 From belief and feeling to preparation of a body state

If

and
and
and
and
then

belief w with level V1 occurs
feeling the associated body state b has level V2
the preparation state for b has level V3
β2 is the person’s orientation for emotional response
γ2 is the person’s flexibility for bodily responses
preparation state for body state b will occur with
level V3 + γ2 (g(β2, V1, V2)-V3) ∆t.

has_state(human, belief(w, V1)) &
has_state(human, feeling(b, V2)) &
has_state(human, preparation(b, V3))
→ has_state(human, preparation(b, V3+γ2 (g(β 2, V1, V2)-V3) ∆t)

The Ambient Agent Model
Within the integrative ambient agent model, the model for
the dynamics of belief and feeling is embedded in order to
enable the agent to reason about this process, and to assess
the person’s beliefs and feelings. In psychology, this
capability is often referred to as mindreading or Theory of
Mind (e.g., Gärdenfors, 2003). The embedding uses the
format that the causal relationships of the model described in
442

Section 2 above are transformed into relationships for beliefs
of the ambient agent on mental states of the person. In order
to achieve this, the idea of recursive modelling is used; e.g.,
(Marsella, Pynadath and Read, 2004). This means that the
beliefs that agents have about each other are represented in a
nested manner. Each mental state is parameterized with the
name of the agent considered, thus creating concepts like

ALP6 From preparation to body modification

If

AA believes that the human’s preparation state for body state b
with level V occurred,
then it will believe that the human’s body state will have level V.
has_state(AA, belief(has_state(human, preparation(b, V))))
→ has_state(AA, belief(has_state(human, effector_state(b, V))))

ALP7 From body modification to modified body

If
AA believes that the human’s body is modified with level V,
then it will believe that the human’s body is showing b with level V.

has_state(human, feeling(b, 0.5))
has_state(AA, performed(add_pos_info))

has_state(AA, belief(has_state(human, effector_state(b, V))))
→ has_state(AA, belief(has_state(human, body_state(b, V))))

In addition, a number of meta-representations are introduced.
For example, has_state(AA, belief(has_state(human, feeling(b, 0.7))))
states that the ambient agent (AA) believes that the human
has a feeling level of 0.7 for b. The following are the
resulting agent local properties (ALP) that specify the
processes within the ambient agent. The first property
specifies how the agent AA observes that the human senses
external information.

ALP8 Sensing a body state

If
AA believes that the human’s body is showing b with level V,
then it will believe that the human will sense this body state.
has_state(AA, belief(has_state(human, body_state(b, V)))) →
has_state(AA, belief(has_state(human, sensor_state(b, V))))

ALP9 Generating a sensory representation of a body state

If
AA believes that the human has sensed body state b with level V,
then it will believe that the human has a sensory representation for
body state b with level V.

ALP1 Observing the human’s sensing external information

If
the human senses external information,
then the ambient agent AA will observe this.

has_state(AA, belief(has_state(human, sensor_state(b, V))))
→ has_state(AA, belief(has_state(human, srs(b, V))))

has_state(human, sensor_state(externalinfo, V))
→ has_state(AA, observed(
has_state(human, sensor_state(externalinfo, V))))

ALP10 From sensory representation of body state to feeling

If

AA believes that the human has a sensory representation for body
state b with level V,
then it will believe that the human has feeling b with level V.

ALP2 Generating a belief for the human’s sensing

If

the ambient agent AA observes that the human senses an external
information,
then it will generate a belief on it.

has_state(AA, belief(has_state(human, srs(b, V))))
→ has_state(AA, belief(has_state(human, feeling(b, V))))

has_state(AA, observed(
has_state(human, sensor_state(externalinfo, V))))
→ has_state(AA, belief(
has_state(human, sensor_state(externalinfo, V))))

In addition, a number of other rules have been established to
model the behaviour of the human and the ambient agent,
and its effect on the world:

ALP3 Generating a belief for a sensory representation

If
AA believes that the human senses external information,
then it will generate a belief that the human will have a sensory
representation for this.

ALP11 Intervention by the Ambient Agent

AA believes that the human has feeling b with level V which is
higher than a certain threshold th1,
then it will add some positive information to the external environment

If

has_state(AA, belief(
has_state(human, sensor_state(externalinfo, V))))
→ has_state(AA, belief(has_state(human, srs(externalinfo, V))))

has_state(AA, belief(has_state(human, feeling(b, V)))) & V ≥ th1
→ has_state(AA, performed(add_pos_info))

ALP4 From sensory representation and feeling to belief

If

AA believes that the human has a sensory representation for
external information with level V1
and AA believes that the human has feeling b with level V2,
and the belief for w has level V3
and β1 is the person’s estimated orientation for emotional response
and γ1 is the person’s flexibility for bodily responses
then it will generate the belief that the human’s belief with level V3+γ1
(g(β1, V1, V2)-V3) ∆t will occur

ALP12 Effect of intervention in the world

As long as AA does not add some positive information to the external
environment,
then positive information will remain 0.
not has_state(AA, performed(add_pos_info))
→ added_pos_info(0)

As soon as AA adds some positive information to the external
environment, it will be available in the environment.
has_state(AA, performed(add_pos_info))
→ added_pos_info(0.2)

has_state(AA, belief(
has_state(human, srs(externalinfo, V1)))) &
has_state(AA, belief(has_state(human, feeling(b, V2)))) &
has_state(AA, belief(has_state(human, belief(w, V3))))
→ has_state(AA, belief(has_state(human,
belief(w, V3+γ1 (g(β 1, V1, V2)-V3) ∆t ))))

The Adaptation Model
Characteristics of a human, used as parameters in a
dynamical model (such as the β used in the belief generation
in the model described above) are often not easy to
determine at forehand, and can only be given to the agent as
initial beliefs. This section describes a method by which an
agent is able to adapt these beliefs concerning human
characteristics to the real characteristics. Using the
dynamical model with parameter values as represented by
these initial beliefs, the agent predicts the human belief and
feeling state, up to a certain time point. When at that time
point, for example by observation, information is obtained
about the real value of this belief or feeling state, this is used

ALP5 From belief and feeling to preparation of a body state

If
and
and
and
and
then

AA believes that the human has a belief for w with level V1
AA believes that the human has feeling b with level V2,
the preparation for body state b has level V3
β2 is the person’s orientation for emotional response
γ2 is the person’s flexibility for bodily responses
it will generate the belief that the human’s preparation state for
body state b will occur with level V3+γ2 (g(β2, V1, V2)-V3) ∆t.

has_state(AA, belief(has_state(human, belief(w, V1)))) &
has_state(AA, belief(has_state(human, feeling(b, V2))))
has_state(AA, belief(has_state(human, preparation(b, V3)))) &
→ has_state(AA, belief(has_state(human,
preparation(b, V3+γ2 (g(β 2, V1, V2)-V3) ∆t))))

443

as input for the adaptation process. The agent adjusts the
belief on the human characteristic, to reduce the difference
between predicted and real value.
For reasonable adjustments, information is required on
how a change in parameter value affects the difference
between predicted and real value of the variable that is
considered; this is called the sensitivity of the variable value
for the parameter value. The sensitivity S of variable X (e.g.,
the belief or feeling level) for parameter P (e.g., the β used in
belief generation) is the number such that a change ∆P in the
value of parameter P will lead to a change ∆X in X which is
(approximately) proportional to ∆P with S as proportion
factor: ∆X = S ∆P. This is an approximation which is more
accurate when the ∆’s are taken small. To determine a
sensitivity S the following approximation method is used. A
small change ∆P in the parameter is used to make an
additional prediction for X, and based on the resulting
difference ∆X found in the two predicted values for X, by
SX,P = ∆X/ ∆P the sensitivity S can be estimated. Once the
sensitivity and a deviation ∆X between estimated and
observed level have been determined, the value W of the
parameter P is adjusted by ∆P in the following manner (with
α the adaptation speed):
∆P = α*(1 - W)* (-∆X/ SX,P) if -∆X/ SX,P ≥ 0

and
and
and
then

AA believes that the sensitivity is V3
- V2 / V3 > 0
α is the adaptation speed
AA will generate the belief in an estimated beta with
level (α * (1 - V1)* (-V1 / V3) + V1)

has_state(AA, belief(estimated_beta(V1))) &
has_state(AA, belief(deviation, V2)) &
has_state(AA, belief(sensitivity, V3)) &
- V2 / V3 > 0
→ has_state(AA,
belief(estimated_beta(α * (1 - V1)* (-V1 / V3) + V1)))

If
AA believes estimated beta is V1
and AA believes that the deviation between estimated and observed
belief is V2
and AA believes that the sensitivity is V3
and - V2 / V3 ≤ 0
and α is the adaptation speed
then AA will generate the belief in an estimated beta with
level (α * V1 * (-V1 / V3) + V1)
has_state(AA, belief(estimated_beta(V1))) &
has_state(AA, belief(deviation, V2)) &
has_state(AA, belief(sensitivity, V3)) &
- V2 / V3 <= 0
→ has_state(AA, belief(estimated_beta(α * V1 * (-V1 / V3) + V1)))

Simulation Results
Based on the model described in the previous section, a
number of simulations have been performed within the
LEADSTO simulation environment (Bosse, Jonker, Meij and
Treur, 2007). The model was tested in a small scenario,
involving an ambient agent and a human (indicated by AA
and human, respectively). The agent model was equipped
with the model to estimate human’s emotion level. The
central emotion used in the scenario is insecurity for the
particular product, as discussed in Section 1. In order to
simulate this, every now and then certain events take place,
which influence the level of insecurity of the human either
positively (e.g., some good news about the product published
in a newspaper) or negatively (e.g., some friend informed
him about his own past bad experience with that product). To
model this behavior, the following property has been used:

∆P = α* W* (-∆X/ SX,P)

if -∆X/ SX,P ≤ 0
This has been specified in LEADSTO-format as follows.
ALP13 Calculating change ∆X in predicted belief X

If

AA believes that the human has a sensory representation for
external information with level V1
and AA believes that the human has feeling b with level V2,
and AA believes that the predicted belief for w has level V3
and β1 is the person’s estimated orientation for emotional response
and γ1 is the person’s flexibility for bodily responses
and the change to be made in person’s estimated β 1 is V4
then it will generate the predicted belief for w with
level V3+γ1 (g(β 1+ V4, V1, V2)-V3) ∆t
has_state(AA, belief(as_state(human,srs(externalinfo, V1)))) &
has_state(AA, belief(has_state(human, feeling(b, V2)))) &
has_state(AA, belief(predicted_belief(w, V3)))
→ has_state(AA, belief(
predicted_belief(w, V3+γ1 (g(β 1+V4, V1, V2)-V3) ∆t ))))

ALP17 Generating a sensor state for external information

If
a sensor state of external information of level V1 occurs
and the ambient agent has added some positive information V2, has
flexibility η
and some positive information V3
and some negative information V4 is present from the environment,
then the human will sense external information with level
(V1-η*(V2+V3)*V1+η*V4*(1-V1)).

ALP14 Generating sensitivity

If
AA believes that the predicted belief for w has level V1
and AA believes that the human has a belief for w with level V2
and the change to be made in person’s estimated β 1 is V3
then AA will generate the belief for sensitivity by (V1 – V2)/V3

has_state(human, sensor_state(externalinfo, V1)) &
added_pos_info(V2) &
flexibility(η ) &
positive_externalinfo(V3) &
negative_externalinfo(V4)
→ has_state(human, sensor_state(
externalinfo, (V1-η*(V2+V3)* V1+η*V4*(1-V1))))

has_state(AA, belief(predicted_belief(w, V1))) &
has_state(AA, belief(has_state(human, belief(w, V2))))
→ has_state(AA, belief(sensitivity, (V1 – V2) / V3))

ALP15 Calculating deviation

If
AA believes that the human has a belief for w with level V1
and AA believes that the observed human belief is V2
then AA will generate the belief that the deviation between estimated
and observed belief is (V1 – V2)

Here positive_externalinfo and negative_externalinfo represent the
positive and negative events that are occurring randomly in
the environment which influence the insecurity level of the
human. For the example simulations the probability for the
positive events to occur has been taken 0.8 and for negative
events to occur is 0.3. The main goal of the ambient agent is
to estimate the level of insecurity of the human. To this end,
it starts with some initial values of the human’s belief and
feeling levels, and then keeps on updating this, using the

has_state(AA, belief(has_state(human, belief(w, V1)))) &
has_state(AA, belief(observed_human_belief, V2))
→ has_state(AA, belief(deviation, V1 – V2))

ALP16 Adapt estimated beta

If
AA believes the estimated beta is V1
and AA believes that the deviation between estimated and observed
belief is V2

444

strategies explained earlier. him some positive information
about the product). When it is estimated that the human
becomes too (unreasonably) insecure, the ambient agent can
take measures to calm him down (e.g., informing
Some example simulation traces (under different but
fixed parameter settings) are illustrated in Figures 2 and 3
(here the time delays within the temporal LEADSTO
relations were taken 1 time unit). In all of these figures,
where time is on the horizontal axis, the upper part shows the
time periods, in which the binary logical state properties hold
(indicated by the dark lines); for example, added_pos_info.
Below this part, quantitative information is provided about
the human’s actual belief and feeling level, and the ambient
agent AA’s estimation of this belief and feeling level,
respectively. Values for these levels for the different time
periods are shown by the dark lines. Note that only a
selection of the relevant state properties is shown.
The first trace (see Figure 2), shows a situation in which
the estimated β (0.95) is substantially higher than the real β
(0.7), as indicated in the upper part of Figure 2. As shown in
the figure, the ambient agent AA estimates the level of
emotion of the human too high so that it is too early in
adding the positive information indicated in the upper part by
state property: has_state(AA, performed(add_pos_info)), at time
point 52.

Figure 2: Simulation 1: the estimated β is higher than the real β

Figure 4: Simulation 3: the estimated β is adapted and
approximates the real β

Figure 3: Simulation 2: the estimated β is lower than the real β

445

References

The second trace (see Figure 3) shows a situation in
which the estimated β (0.45) is substantially lower than the
real β (0.7), as indicated in the upper part of the Figure 3. As
shown in the figure, the ambient agent AA estimates the
level of emotion of the human much too low, so that it is too
late in adding the positive information, indicated in the upper
part by state property: has_state(AA, performed(add_pos_info)),
at time point 128. This is too late, because, as shown in the
actual emotion graph below, the human’s emotion level has
gone too high already at time point 118.
In Figure 4 a simulation trace is shown where the
parameter β is adapted to the person. Here the initial value of
β is too high (0.95) compared to the actual value (0.7). To
compensate for that, the adaptation model first reduces the
estimated value to below 0.6, after which it almost
monotonically approximates the real value 0.7.

Aarts, E.; Collier, R.; Loenen, E. van; Ruyter, B. de (eds.) (2003).
Ambient Intelligence. Proc. EUSAI 2003. Lecture Notes in
Computer Science, vol. 2875. Springer Verlag, 2003.
Aarts, E., Harwig, R., and Schuurmans, M. (2001). Ambient
Intelligence. In: P. Denning (ed.), The Invisible Future.
McGraw Hill, pp. 235-250.
Bechara, A., and Damasio, A. (2004). The Somatic Marker
Hypothesis: a neural theory of economic decision. Games and
Economic Behavior, vol. 52, pp. 336-372.
Bi, G.Q., and Poo, M.M. (2001) Synaptic Modifications by
Correlated Activity: Hebb’s Postulate Revisited. Ann Rev
Neurosci, vol. 24, pp. 139-166.
Bosse, T., Jonker, C.M., Meij, L. van der, and Treur, J. (2007). A
Language and Environment for Analysis of Dynamics by
Simulation. International Journal of Artificial Intelligence
Tools, vol. 16, 2007, pp. 435-464.
Bosse, T., Jonker, C.M., and Treur, J. (2008). Formalisation of
Damasio's Theory of Emotion, Feeling and Core
Consciousness. Consciousness and Cognition Journal, vol. 17,
2008, pp. 94–113.
Damasio, A. (1994). Descartes’ Error: Emotion, Reason and the
Human Brain, Papermac, London.
Damasio, A. (1996). The Somatic Marker Hypothesis and the
Possible Functions of the Prefrontal Cortex. Philosophical
Transactions of the Royal Society: Biological Sciences, vol.
351, pp. 1413-1420
Damasio, A. (1999). The Feeling of What Happens. Body and
Emotion in the Making of Consciousness. New York: Harcourt
Brace, 1999.
Damasio, A. (2004). Looking for Spinoza. Vintage books, London.
Eich, E., Kihlstrom, J.F., Bower, G.H., Forgas, J.P., & Niedenthal,
P.M. (2000). Cognition and Emotion. New York: Oxford
University Press.
Forgas, J.P., Goldenberg, L., and Unkelbach, C. (2009). Can bad
weather improve your memory? An unobtrusive field study of
natural mood effects on real-life memory. Journal of
Experimental Social Psychology, vol. 45, 2009, pp. 254–257.
Gärdenfors, P. (2003). How Homo Became Sapiens: On The
Evolution Of Thinking. Oxford University Press, 2003.
Goldman, A.I. (2006). Simulating Minds: the Philosophy,
Psychology and Neuroscience of Mindreading. Oxford
University Press.
Hebb, D. (1949). The Organisation of Behavior. Wiley, New York.
Memon, Z.A., and Treur, J., (2009). Modelling the Reciprocal
Interaction between Believing and Feeling from a Neurological
Perspective. In: N. Zhong et al. (eds.), Proc. of the First Intern.
Conf. on Brain Informatics, BI'09. Lecture Notes in Artificial
Intelligence, vol. 5819. Springer Verlag, 2009, pp. 13-24.
Marsella, S.C., Pynadath, D.V., and Read, S.J. (2004). PsychSim:
Agent-based modeling of social interaction and influence. In:
Lovett, M. et al. (eds.), Proceedings of the International
Conference on Cognitive Modelling, ICCM’04, pp. 243-248.
Niedenthal, P.M. (2007). Embodying Emotion. Science, vol. 316,
(2007), pp. 1002-1005.
Riva, G., F. Vatalaro, F. Davide, M. Alcañiz (eds.) (2005). Ambient
Intelligence. IOS Press.
Schooler, J.W., and Eich, E. (2000). Memory for Emotional Events.
In: E. Tulving, F.I.M. Craik (eds.), The Oxford Handbook of
Memory. Oxford University Press, 2000, pp. 379-394.
Winkielman, P., Niedenthal, P.M., and Oberman, L.M. (2009).
Embodied Perspective on Emotion-Cognition Interactions. In:
Pineda, J.A. (ed.), Mirror Neuron Systems. Springer Science,
2009, pp. 235-257.

Discussion
To function in a knowledgeable manner, ambient agents
(e.g., Aarts, Collier, Loenen, Ruyter, 2003; Aarts, Harwig,
Schuurmans, 2001; Riva, Vatalaro, Davide, Alcañiz, 2005)
need a model of the humans they are supporting. Such a
model enables them to perform a form of mindreading (e.g.,
Gärdenfors, 2003; Goldman, 2006). The ambient agent
model presented here focuses on mindreading concerning the
interaction between beliefs and emotions, based on
neurological theories that address this interaction. A belief
usually triggers an emotional response and may also depend
on this emotional response, as, for example, shown in
literature such as (Eich et al., 2000; Forgas et al., 2009;
Niedenthal, 2007; Schooler and Eich, 2000).
The ambient agent model presented uses a computational
model of this interaction, adopted from (Memon and Treur,
2009). For feeling the emotion, based on elements taken
from (Damasio, 1999, 2004; Bosse, Jonker and Treur, 2008),
a converging recursive body loop is included in the model.
As a second loop the model includes a feedback loop for the
interaction between feeling and belief. The causal relation
from feeling to belief in this second loop was inspired by the
Somatic Marker Hypothesis described in (Damasio, 1994,
1996; Bechara and Damasio, 2004), and may also be
justified by a Hebbian learning principle (cf. Hebb, 1949; Bi
and Poo, 2001). Both the strength of the belief and of the
feeling emerge as a result of the dynamic pattern generated
by the two loops.
The adaptive integrative agent model equipped with the
dynamical model for the dynamics of belief and feeling was
specified in the hybrid dynamic modelling language
LEADSTO, and simulations were performed in its software
environment; cf. (Bosse, Jonker, Meij, and Treur, 2007). An
adaptation model was integrated within the agent to be able
to tune beliefs on the human’s characteristics used as
parameters in the dynamical model to the real characteristics.
Here feedback can be used when at times the human reveals
his or her belief or feeling. To evaluate the ambient agent
model in human experiments is left to future work.

446

