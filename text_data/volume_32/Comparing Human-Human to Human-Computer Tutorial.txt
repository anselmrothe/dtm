UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Comparing Human-Human to Human-Computer Tutorial
Permalink
https://escholarship.org/uc/item/64n11394
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Steinhauser, Natalie
Campbell, Gwendolyn
Harrison, Katherine
et al.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              Comparing Human-Human to Human-Computer Tutorial Dialogue
                                    Natalie B. Steinhauser (Natalie.Steinhauser@navy.mil) &
                                   Gwendolyn E. Campbell (Gwendolyn.Campbell@navy.mil)
                                 Naval Air Warfare Center Training Systems Division, Code 4.6.5.1
                                          12350 Research Parkway, Orlando, FL 32826-3275
                              Katherine M. Harrison (Katherine.M.Harrison.ctr@navy.mil)
                                                            Kaegan Corporation
                                          12000 Research Parkway, Orlando, FL 32826-2944
                                        Leanne S. Taylor (Leanne.Taylor.ctr@navy.mil)
                                                       University of Central Florida
                                             4000 Central Florida Blvd. Orlando, FL 32816
         Myroslava O. Dzikovska (M.Dzikovska@ed.ac.uk) & Johanna D. Moore (J.Moore@ed.ac.uk)
                                 Human Communication Research Centre, University of Edinburgh
                                     2 Buccleuch Place, Edinburgh EH8 9LW, United Kingdom
                             Abstract                                   determined that this is a good strategy. Two unresolved
                                                                        questions are whether you will find the same kinds of
  Intelligent Tutoring Systems are often modeled after human
  tutors; however, the effectiveness of this strategy is yet to be      dialogue when a student is interacting with a human and a
  determined. Research on media interactions suggests that              computer tutor (ITS) and whether those types of dialogue
  behaviors with humans are similar to those with computers.            can be interpreted in the same way with regards to the
  Intelligent Tutoring System studies have said the opposite. In        learning that is occurring.
  this study we compared a human-human and a human-                        Research on media interactions has stated that people
  computer tutoring system in terms of metacognitive, social, and       interact socially and naturally with media (to include
  nonsense statements to dig deeper into these interactions. We         computers) as they do humans (Reeves & Nass, 1996). The
  discovered that the interactions were quite different between         researchers suggest that people follow rules of social
  human-human and human-computer tutoring. With a human,
                                                                        relationships when interacting with media and that this
  participants expressed more positive metacognitive statements
  and social statements. When interacting with a computer tutor,        occurs naturally and unconsciously. For example, media has
  students were more likely to make negative metacognitive              been shown to induce emotions such as frustration and
  statements and social statements. In addition, the interpretation     politeness.
  of these results differed between the two corpora. In human-             Similarly, studies examining interactions with virtual
  human tutoring, the more often a participant made positive            humans have shown that people react in the same manner to
  metacognitive statements, the worse their learning gain. Their        these entities as they do with other humans (Zanbaka,
  social dialogue had no impact on learning gain. In human-             Ulinski, Goolkasian, & Hodges, 2004; Pertaub, Slater, &
  computer tutoring, the more negative and positive                     Barker, 2002). While being observed by a crowd of virtual
  metacognitive statements and the more negative social
                                                                        agents, people showed nervousness just as they did with a
  statements they gave the worse their learning gain. It is clear
  from this study that students do not act the same with a human        human audience. Women also show social inhibition effects
  tutor as they do with a computer tutor. Therefore, designers of       with virtual agents like they do with humans.
  ITS systems should not just blindly model their systems after            In contrast, more recent research using ITSs has shown
  human tutors. The differences in human and computer                   that students do not behave the same with computers as they
  interactions should also be considered.                               do with humans, as evident in their dialogue acts. When
                                                                        students were conversing with a computer, but believed they
  Keywords: Human Computer Interaction (HCI), Intelligent               were conversing with a human, they used more words and
  Tutoring Systems (ITS), Metacognition, Social dialogue,               conversed longer than did students who were told they were
  Tutorial dialogue                                                     talking to a computer (Schechtman & Horowitz, 2003). In
                                                                        addition, students provided more explanations and longer
                          Introduction                                  turns when they believed they were talking to a human
                                                                        versus a computer, even though they were talking to a
Over the years, Intelligent Tutoring Systems (ITSs) have
                                                                        computer in both cases (Rosé & Torrey, 2005).
become popular learning and teaching tools. Thus, their
                                                                           Therefore, results as to how people respond to computers
design is becoming more sophisticated. One approach to
                                                                        and computer entities, in comparison to humans, are mixed.
creating ITSs is to model them after a human tutor because
                                                                        While previous ITS studies have looked at the content based
human tutoring has been said to be the most effective form
                                                                        dialogue (dialogue relevant to the lesson material), we took
of teaching (Bloom, 1984). However, it has not yet been
                                                                    1738

a broader perspective and considered other dialogue
categories, such as metacognition, because they have also
been shown to predict learning gain (Campbell et al., 2009).
We examined and compared a human-human and a human-
computer tutorial dialogue corpus. We categorized five
types of dialogue found in these corpora. Most of the
dialogue was related to the content of the lessons. The other
four categories of dialogue that were present were
management (discussing the flow of the lesson),
metacognition (describing one’s understanding), social
(chit-chat and signs of frustration), and nonsense words
(random sequences of letters). For this comparison, we will
focus on metacognition, social dialogue, and nonsense
words because these are the categories where research
hasn’t yet explored and, we believe, will also differ in
regards to the interactions.                                                 Figure 1. Participant screen for human-human tutoring.
                              Method                                      Procedure
                                                                          After completing informed consent paperwork, participants
To explore our research questions we conducted a human-                   filled out a demographic questionnaire and took a pre-test
human and a human-computer study. The two corpora were                    consisting of 38 multiple choice questions. The participants
then analyzed and compared in terms of their dialogue.                    were then introduced to their tutor and given a brief
                                                                          demonstration of how to operate the learning environment.
             Human-Human Tutoring Study                                   The students spent the majority of the experimental session
                                                                          working through the lesson material and building circuits.
                                                                          At the conclusion of the experiment, participants completed
Data collection environment                                               a post-test, which included 21 multiple choice questions,
A curriculum incorporating lessons on basic electricity and               and a reaction questionnaire. They were then debriefed and
electronics was constructed. The curriculum covered topics                excused.
including open and closed paths, voltage reading between
components and positive and negative terminals, series and                Corpus
parallel configurations, and finding faults in a circuit with a           The corpus of the human-human study was comprised of
multimeter. These basic concepts were taught in a computer-               dialogues from each of the thirty participants distributed
based learning environment within a single session lasting                across three experienced tutors. The average age of the
approximately four hours1.                                                participants was 22.4 years (SD = 5.0) and exactly half of
   Figure 1 shows a screenshot of the learning environment                them were female. The corpus of this study includes 8,085
that the participants interacted with during the study. The               dialogue turns taken by the student and tutor and 56,133
screen was divided into three sections. The top left-hand                 tokens (words and punctuation).
section displayed the core lesson material in slide form,
including educational text, activities, and discussion
questions. The participants were able to move through the
                                                                                   Human-Computer Tutoring Study
lesson slides at their own pace. The top right-hand section
provided participants with a circuit simulator, which                     Data collection environment
allowed them to construct and manipulate circuits as a                    As much as possible, the same curriculum as the human-
supplement to the material in the slides. The bottom section              human study was used in the BEETLE II computer tutoring
was the chat window where the participants and tutor                      system (Dzikovska et al., 2010). Small changes were made
conversed by typing.                                                      to the curriculum so that the computer would be able to
   The tutor and student were located in the same room, but               understand student responses (e.g., multi-part questions
were separated by a divider. The tutor had the ability to                 were simplified into single questions). The computer tutor
observe the student’s learning environment and interact with              (ITS) was created to implement the effective tutorial
the student through a computer screen and chat window.                    strategies used in our human-human corpus (e.g., hints). The
The tutor gave feedback, technical assistance, and/or                     ITS understood and responded to content (by providing
encouragement that he or she considered appropriate.                      feedback) and negative metacognitive statements (by giving
Participants directed their answers, comments, and/or                     a hint) made by a student, but not to the other types of
questions to the tutor throughout the curriculum.                         dialogue (management, social, and nonsense). The
                                                                          responses and feedback given by the ITS was modeled after
                                                                          the human tutors from the previous corpus. The ITS used a
   1
                                                                          friendly and encouraging tone similar to the human tutor. In
     Note that there was a second session, covering additional topics,
but it will not be addressed further in this paper.
                                                                      1739

fact, in most cases, the ITS used identical phrasing for its                                   Coding
comments to the student.
                                                                  For the human-human data, two independent raters coded
  A screenshot of the learning environment is shown in
                                                                  the student-tutor transcripts and were able to identify and
Figure 2. The learning environment was similar to that of
                                                                  distinguish between content, management, metacognitive,
the human-human environment. The screen was divided into
                                                                  and social dialogue statements with perfect reliability
three sections. The upper left-hand section had the same
                                                                  (kappa = 1.00). In addition, raters were able to differentiate
function as the previous study; however the navigation
                                                                  between positive and negative metacognitive statements
buttons were slightly different. The right-hand section was
                                                                  made by the student with high inter-rater reliability (kappa =
the chat window where the participants and tutor interacted
                                                                  0.99).
through typing. The lower-left section included the circuit
                                                                     For the human-computer data, four independent raters
simulator, which had the same purpose as the previous
                                                                  coded the student-tutor transcripts and were able to identify
study, although the tools used to build circuits had a
                                                                  and      distinguish      between     content,    management,
different display interface.
                                                                  metacognitive, social dialogue, and nonsensical statements
                                                                  with high reliability (kappa = 0.88). In addition, raters were
                                                                  able to differentiate between positive and negative
                                                                  metacognitive statements made by the student with high
                                                                  inter-rater reliability (kappa = 0.96).
                                                                     A summary of the codes used in this study are presented
                                                                  in Table 1.
                                                                     Content statements were described as comments including
                                                                  domain concepts that pertained to the lesson material.
                                                                  Answering a question fit into the content category (e.g.,
                                                                  “The battery and the bulb in diagram 1”, “1.5 volts”, etc.).
                                                                     Management consisted of dialogue that dealt with the
                                                                  flow of the lesson but does not contain information relevant
                                                                  to the lesson topics (e.g., “I give up”, acknowledging the
                                                                  tutor’s instructions to continue by saying, “OK”, etc.).
                                                                     Metacognitive statements were defined as statements that
     Figure 2. Participant screen for the BEETLE2 ITS.            contained the student’s feeling about his or her
                                                                  understanding, but did not include domain content.
Procedure                                                         Metacognitive statements were further classified as positive
                                                                  or negative. Positive metacognitive statements were defined
The procedure for the human-computer study was
                                                                  as statements that expressed understanding (e.g., “I get it”,
essentially the same as the human-human study with a few
                                                                  “I understand”, etc.), whereas negative metacognitive
exceptions. The pre-test consisted of 22 multiple choice
                                                                  statements expressed confusion (e.g., “I don’t understand”,
questions and the post-test consisted of 21 multiple choice
                                                                  “Give me a hint”, etc.).
questions. The human-computer pre-test had fewer
                                                                     Social dialogue includes positive and negative statements.
questions because we removed questions associated with
                                                                  Positive social dialogue was defined as statements that
material from the second session of the human-human study,
                                                                  included humor, rapport, chit-chat, and saving face.
as mentioned earlier. In addition, instead of a reaction
                                                                  Examples included “Ha-ha”, “Hi, how are you?”, etc.
questionnaire at the conclusion of the study, participants
                                                                  Negative social statements included expressions of
were given a usability and satisfaction questionnaire.
                                                                  frustration, explicit refusals to cooperate, and even offensive
                                                                  statements. Examples included “Because I said so”, “No”,
Corpus
                                                                  “You’re stupid”, expletives, etc.
The human-computer corpus consists of dialogues from                 Nonsense was classified as statements that were made up
each of the forty-one participants in the study. The average      of random letters or numbers that are not content related
age of the participants was 20.8 years (SD = 3.30) and there      (e.g., “ufghp”, “3i9f”, etc.). Nonsense did not occur in the
were almost twice as many females as males. The corpus            human-human dialogue; therefore it was not coded in those
includes an estimated 34,900 total dialogue turns taken by        transcripts.
the student and tutor and an estimated 398,410 total tokens.         Since we wish to look beyond just the content dialogue,
There were many more dialogue turns and total tokens in           we will focus on metacognition, social dialogue, and
the human-computer study because the computer asked the           nonsense words in our results. Management was left out of
questions in this study (versus them being presented on the       the analyses because it was not very prevalent in the
lesson slides in the previous study). In addition, more           computer tutoring data and, when it was, it was ignored by
questions were presented in this study because, as stated         the tutor. Also, it was not a relevant predictor of learning
earlier, multi-part questions were simplified into individual     gain with the human tutor.
questions.
                                                              1740

              Table 1. Coding summary                                                  Results
    Code                Definition          Example         Learning Gain
  Content               Statements         “There is a
                 including domain    battery and bulb in    Pre- and post-test scores were calculated in terms of
                     concepts that        circuit 1.”       percentage correct. A learning gain score was then
                     pertain to the        “1.5 volts.”     calculated for each participant using the formula: (post-test
                         lesson                             score – pre-test score)/(1- pre-test score).
                      Dialogue that
                                           “I give up.”     Metacognitive Statements
                  does not contain
                                              “O.k.”        Students made metacognitive statements in both studies,
                      information
                                       Acknowledging        regardless of whether the tutor was a human or a computer;
Management          relevant to the
                                          the tutor’s       however, the relative frequencies of positive and negative
                  lesson material,
                                       instructions to      metacognitive statements depended upon the type of tutor.
                but deals with the
                                           continue         Specifically, students talking to a human tutor made
                flow of the lesson
                        Statements                          significantly more positive metacognitive statements (M =
                    containing the                          12.9, SD = 8.3) than negative metacognitive statements (M
                                        Metacognitive       = 1.8, SD = 2.0), t(28) = 7.16, p < 0.001. Students talking to
                 student’s feelings
                                     statements can be      a computer tutor, on the other hand, made significantly more
Metacognition      about his or her
                                          positive or       negative metacognitive statements (M = 3.8, SD = 5.5) than
               understanding, but
                                           negative.        positive metacognitive statements (M = 0.2, SD = 0.5), t(39)
                  does not include
                  domain concepts                           = -4.21, p < 0.001.
                     Statements that        “I get it.”        The implications of the presence of metacognitive
   Positive             express         “I understand.”     statements also varied depending upon the type of tutor. For
                    understanding           “Oh, o.k.”      students interacting with a human tutor, the amount of
                                        “I don’t know.”     positive metacognitive dialogue, but not negative
                     Statements that                        metacognitive dialogue, was significantly negatively
  Negative                                  “I don’t
                express confusion                           correlated with learning gains; r = -0.543, p = .002 and r =
                                        understand.”
                                                            -0.210, p = 0.266, respectively. However, for students
                    Dialogue that is
                                                            interacting with the computer tutor, the frequency of both
                  not related to the
                                                            types of statements were negatively correlated with learning
                    content of the
                                      Social statements     gains (positive statements: r = -0.419, p = 0.006; negative
   Social       lessons and serves
                                     can be positive or     statements: r = -0.537, p <.001).
 Dialogue           as motivation,
                                           negative.
                  encouragement,                            Social Statements
                humor, frustration
                      outlets, etc.                         While students made social statements with both types of
                     Statements that                        tutors, students interacting with a human tutor made
                                             “Ha-ha”        exclusively positive social statements and students
                   include humor,
   Positive                               “Hi, how are      interacting with the computer tutor made exclusively
                rapport, chit-chat,
                                        you doing?”         negative social statements. On average, students interacting
                    or saving face
                     Statements that                        with a human tutor typed 37.5 positive social words to their
               include frustration,     “Because I said     tutor (SD = 52.3) and students interacting with the computer
                       refusal to             so.”          tutor typed 8.5 negative social words (SD = 20).
  Negative     cooperate with the             “No.”            Interestingly, the amount of social dialogue with human
                       system, or      “You’re stupid.”     tutors was unrelated to student learning gains, r = -0.211, p
                     offending the          Expletives      = 0.262, but the amount of social dialogue that the student
                         system                             produced when interacting with the computer tutor was
                         Random                             negatively correlated with learning gains, r = -0.372, p =
                     sequences of                           .017.
                                             “oidhf”
                letters or numbers
 Nonsense
                that do not pertain
                                         “dsfafadgdfh”      Nonsense
                     to the lesson                          Finally, as mentioned earlier, students spontaneously
                        material                            exhibited a novel type of “utterance” when interacting with
                                                            the computer tutor – nonsensical sequences of letters and/or
                                                            numbers. On average, the students submitted nonsense to
                                                            the computer tutor 1.7 times. There was quite a bit of
                                                            variability across students in their likelihood of exhibiting
                                                            this behavior, with a standard deviation of 5.1. This
                                                            behavior was not statistically related to learning gains, r =
                                                        1741

-0.073, p = 0.651. However, not surprisingly, the frequency          because it is unclear if they really understand or if they are
of this behavior was significantly negatively correlated to          just being polite.
the students’ report of satisfaction with the computer tutor, r         On the other hand, when interacting with a computer
= -0.33, p = 0.035.                                                  tutor, participants appear to be more honest in terms of their
                                                                     negative statements. If they show signs of confusion or
                         Discussion                                  frustration, they really seem to be indicating that they are
                                                                     struggling with the lessons. Such signs can be interpreted as
As stated before, ITSs are often modeled after human tutors,
                                                                     more accurate indicators that additional remediation is
but it is uncertain whether these interactions are similar and
                                                                     needed. The rules of politeness are ignored and the true
can be interpreted in the same manner. In fact, we found that
                                                                     story seems to emerge.
students did not respond similarly to the computer tutor as
                                                                        From this study we found that students will not
they did with the human tutor. In both corpora, student’s
                                                                     necessarily act the same with a computer tutor as they do
dialogue included metacognitive statements, but the nature
                                                                     with a human tutor. This suggests that designing an ITS to
of those statements was very different. With a human tutor
                                                                     try to mimic a human tutor may not be the best strategy. The
the statements were mostly positive acknowledgements,
                                                                     differences in interactions should also be considered. For
whereas with the computer they were negative statements
                                                                     example, positive social statements were not related to
expressing confusion.
                                                                     learning gains, so they do not necessarily need to be
   Social dialogue differed drastically as well. With a human
                                                                     supported in an ITS; however, negative social and nonsense
the social dialogue was all positive and served the purpose
                                                                     statements were negatively correlated with learning gains in
of creating rapport. With the computer, the social dialogue
                                                                     the ITS and should be addressed. Perhaps additional help
was all negative and was concerned more with showing
                                                                     should be given or students should be offered a break when
frustration with the system. Nonsense did not occur in the
                                                                     these forms of dialogue occur. All forms of metacognition
human corpus at all. This was a new category that occurred
                                                                     impacted learning gain in the human-computer corpus, thus
in the computer corpus only.
                                                                     they should all be addressed in the ITS. Possibly giving
   The human-human and human-computer dialogues also
                                                                     additional remediation to students who make metacognitive
differ in their interpretations, specifically in the
                                                                     statements could be helpful.
metacognition and social categories. In the human-human
                                                                        While modeling a human tutor may be a reasonable first
corpus, metacognition was a negative predictor of learning
                                                                     step in the design of an ITS, the design cannot stop there.
gain only when it consisted of positive statements. The more
                                                                     The ITS needs to be evaluated and tested with users to
frequently students said things like “I get it” the worse they
                                                                     determine its effectiveness. Tweaks to the system should be
did. In the human-computer corpus, both types of
                                                                     made according to the ITS evaluation, like the ones
metacognitive statements (positive and negative) were a bad
                                                                     suggested above, for each individual system and curriculum.
sign, though they rarely gave positive metacognitive
                                                                        In this study we tried to model the human tutor as much
statements.
                                                                     as possible, but were limited by the current technological
   Social interactions also differ in their interpretation. With
                                                                     capabilities in computational natural language processing.
human-human tutoring, social dialogue was not related to
                                                                     Further advancements and improvements to the system’s
learning gain, whereas in human-computer tutoring it was
                                                                     capabilities might yield different results. Additionally, these
negatively correlated with learning gain. The social
                                                                     comparisons should be replicated in other domains and
statements made in the ITS environment were all negative,
                                                                     other curriculums to see how results compare. It would also
reflecting the participant’s frustration. Thus, expressing
                                                                     be interesting to compare human-human and human-
frustration through social dialogue was a good indicator that
                                                                     computer tutoring with spoken dialogue to see if the results
the student was struggling with the content.
                                                                     would hold since tutoring is commonly done in spoken
   These results indicate that interactions and interpretations
                                                                     form.
may indeed be different between human-human and human-
computer tutoring. They also suggest that perhaps human
tutors are able to handle negative metacognitive statements                              Acknowledgments
like “I don’t get it” more effectively than our computer             We would like to thank our sponsors from the Office of
tutor, since negative metacognition was not negatively               Naval Research, Dr. Susan Chipman and Dr. Ray Perez,
correlated with learning gain in the human-human corpus.             three former Research Associates who worked on this
   Overall, it appears that politeness may be playing a role in      project, Leslie Butler, Lisa Durrance, and Cheryl Johnson,
human-human interactions, but is put aside in human-                 and two additional team members, Elaine Farrow and
computer interactions. When conversing with another                  Charles Callaway for their contributions to this effort.
human, participants positively acknowledged what their
tutor said and participated in rapport building with chit-chat.                               References
This seems to be driven by a need to be polite and courteous
                                                                     Bloom, B.S. (1984). The 2 Sigma problem: The search for
to the tutor, but wasn’t a good indicator of what was really
                                                                        methods of group interaction as effective as one-to-one
going on as far as learning was concerned. Based on the
                                                                        tutoring. Educational Researcher, 13, 4-16.
results, you may not be able to really trust a student who
                                                                     Campbell, G.E., Steinhauser, N.B., Dzikovska, M.O.,
says “I understand” when they are interacting with a human
                                                                        Moore, J.D., Callaway, C.B., & Farrow, E. (2009, July).
                                                                        Metacognitive awareness versus linguistic politeness:
                                                                 1742

  Expressions of confusions in tutorial dialogues. Poster
  presented at the 31st Annual Conference of the Cognitive
  Science Society. Amsterdam, Netherlands.
Dzikovska, M.O., Moore, J.D., Steinhauser, N.B.,
  Campbell, G.E., Farrow, E., & Callaway, C.B. (2010).
  Beetle II: a system for tutoring and computational
  linguistic experimentation. In Proceedings of ACL-2010
  demo session.
Pertaub, D., Slater, M., & Barker, C. (2002). An experiment
  on public speaking anxiety in response to three different
  types of virtual audiences. Presence: Teleoperators and
  Virtual Environments, 11(1), 68-78.
Reeves, B. & Nass, C. (1996). The Media Equation: How
  People Treat Computers, Television, and New Media Like
  Real People and Places. Cambridge, UK: Cambridge
  University Press.
Rosé, C.P. & Torrey, C. (2005). Interactivity and
  expectation: eliciting learning oriented behaviour with
  tutorial dialogue systems. Proceedings of INTERACT (pp.
  323-336).
Schechtman, N. & Horowitz, L.M. (2003). Media inequality
  in conversation: how people behave differently when
  interacting with computers and people, In Digital
  Sociability, 5(1), 281-288.
Zanbaka, C., Ulinski, A., Goolkasian, P., & Hodges, L.F.
  (2004). Effects of virtual human presence on task
  performance. Paper presented at the International
  Conference on Artificial Reality & Telepresence. Retrieved
  from http://www.vrsj.org/ic-at/papers/2004/S4-1.pdf .
                                                            1743

