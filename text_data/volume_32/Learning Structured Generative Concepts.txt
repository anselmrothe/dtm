UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Structured Generative Concepts
Permalink
https://escholarship.org/uc/item/5z52d2wj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Stuhlmuller, Andreas
Tenenbaum, Joshua B.
Goodman, Noah D.
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                    Learning Structured Generative Concepts
                              Andreas Stuhlmüller, Joshua B. Tenenbaum, Noah D. Goodman
                                                     Brain and Cognitive Sciences, MIT
                                                           {ast, jbt, ndg}@mit.edu
                              Abstract                                    generative processes. We test whether statistical inference
                                                                          with these generative processes can account for how people
   Many real world concepts, such as “car”, “house”, and “tree”,          categorize novel instances of structured concepts and com-
   are more than simply a collection of features. These objects
   are richly structured, defined in terms of systems of relations,       pare with more heuristic, exemplar-based approaches.
   subparts, and recursive embeddings. We describe an approach               Because a structured concept like “house” has no single,
   to concept representation and learning that attempts to capture        simple perceptual prototype that is similar to all examples,
   such structured objects. This approach builds on recent proba-
   bilistic approaches, viewing concepts as generative processes,         learning such a concept might seem very difficult. However,
   and on recent rule-based approaches, constructing concepts in-         each example of a structured concept itself has internal struc-
   ductively from a language of thought. Concepts are modeled             ture which makes it potentially very informative. Consider
   as probabilistic programs that describe generative processes;
   these programs are described in a compositional language. In           figure 1, where from only a few observations of a concept it
   an exploratory concept learning experiment, we investigate hu-         is easy to see the underlying structural regularity that can be
   man learning from sets of tree-like objects generated by pro-          extended to new items. The regularities underlying structured
   cesses that vary in their abstract structure, from simple proto-
   types to complex recursions. We compare human categoriza-              concepts can often be expressed with instructions for gener-
   tion judgements to predictions of the true generative process as       ating the examples: “Draw a sequence of brown dots, choose
   well as a variety of exemplar-based heuristics.                        a branch color, and for each brown dot draw two dots of this
                                                                          color branching from it.”
                          Introduction
Concept learning has traditionally been studied in the con-
text of relatively unstructured objects that can be described
as collections of features. Learning and categorization can be
understood formally as problems of statistical inference, and
a number of successful accounts of concept learning can be
viewed in terms of probabilistic models defined over different
                                                                          Figure 1: Three examples of a structured concept described by a
ways to represent structure in feature sets, such as prototypes,          simple generative process.
exemplars, or logical rules (Anderson, 1990; Shi, Feldman,
& Griffiths, 2008; Goodman, Tenenbaum, Feldman, & Grif-                      We build on the work of Goodman, Tenenbaum, et al.
fiths, 2008). Yet for many real world object concepts, such as            (2008), who introduced an approach to concept learning as
“car”, “house”, “tree, or “human body”, instances are more                Bayesian inference over a grammatically structured hypoth-
than simply a collection of features. These objects are richly            esis space—a “language of thought.” Single concepts ex-
structured, defined in terms of features connected in systems             pressed in this language were simple propositional rules for
of relations, parts and subparts at multiple scales of abstrac-           classifying objects, but this approach naturally extends to
tion, and even recursive embedding (Markman, 1999). A tree                richer representations, providing a concept learning theory
has branches coming out of a trunk, with roots in the ground;             for any representation language. Here we consider a language
branches give rise to smaller branches, and there are leaves              for generative processes based on probabilistic programs: in-
at the end of the branches. A human body has a head on top                structions for constructing objects, which may include prob-
of a torso; arms and legs come out of the torso, with arms                abilistic choices, thus describing distributions on objects—in
ending in hands, made of fingers. A house is composed of                  our case distributions on colored trees. Because this language
walls, roofs, doors, and other parts arranged in characteristic           describes generative processes as programs, it captures regu-
functional and spatial relations that are harder to verbalize but         larities as abstract as subparts and recursion.
still easy to recognize and reason about. Besides objects, ex-               The theory of concept representation that we describe here
amples of structured concepts can be found in language (e.g.              shares many aspects with previous approaches to concepts.
the mutually recursive system of phrase types in a grammar),              Like prototype and mixture models (Anderson, 1990; Grif-
in the representation of events (e.g. a soccer match with its             fiths, Canini, & Sanborn, 2007), probabilistic programs de-
fixed subparts), and processes (e.g. the recipe for making a              scribe distributions on observations. However, prototypes and
pancake with steps at different levels of abstraction).                   mixtures generate observations as noisy copies of ideal pro-
   Such concepts have not been the focus of research in the               totypes for the concept and thus cannot capture more abstract
probabilistic modeling tradition. Here we describe an ap-                 structures such as recursion. Like rule-based models of con-
proach to representing structured concepts—more typical of                cept learning, our approach supports compositionality: com-
the complexity of real world categories—using probabilistic               plex concepts are composed out of simple ones—but rather
                                                                      2296

than deterministic rules, our concepts denote distributions.             a distribution on return values—which may be complex val-
Finally, the probabilistic program approach can be seen as a             ues such as nested lists—and any given execution results in
generalization of previous approaches to generative represen-            a sample from this distribution. In what follows we describe
tations of concepts (Kemp, Bernstein, & Tenenbaum, 2005;                 Church programs which sample colored trees.
Rehder & Kim, 2006; Feldman, 1997).                                         We group generative models into classes by the abstract
   We investigate human learning for classes of generating               constructions they use. Table 1 illustrates each of these types
processes that vary in their abstract structure, from simple             using a single concept program and observations drawn from
prototypes to complex multiply recursive programs. We com-               this program. The simplest tree-generating processes in our
pare predictions for categorization judgments based on the               language use only the stochastic function node, which takes
true generative model to the predictions of exemplar models,             as its first argument a color symbol and as its remaining ar-
which exploit the relational structure of the examples to vary-          guments subtrees. With high probability, node returns a tree
ing degrees but cannot detect more abstract structure. We                that has the given color symbol at its root and the given sub-
find two regimes: for concepts with simple prototype-like                trees as its children, but with some probability ε, it switches
structures, human judgements are well described by a rela-               to a noise process that can return any tree, that is, node in-
tional exemplar model, but humans can also easily learn more             troduces a random noise process into the tree construction.
abstract regularities—such as sub-concepts and recursion—                Under the noise process, the number of children for a node is
which are better captured by a model using more expressive               sampled from a geometric distribution with parameter ε and
generative descriptions based on probabilistic programs.                 the node color is sampled uniformly.
                                                                            Programs like (node • (node •) (node •)) denote
                    Formal Framework
                                                                         stochastic prototypes. They are most likely to gener-
In the following, we first explain the formal language we use            ate the tree that corresponds to the given colors, in this
to describe generative processes, then the different methods             case (• (•) (•)), but they can return any tree with a certain
                                                                             ´
of categorization (or generalization) we compare to subjects’            probability. The more a tree deviates from the prototype, the
judgements.                                                              less likely this process is to generate it. For example, the
Concept Representation                                                   simple program described above could switch at the third
                                                                         node to the noise process and produce (• (•) (• (•)))
                                                                                                                      ´
We analyze concepts as generative models, i.e. as formal de-             instead of the prototype. By introducing the noise process,
scriptions of processes that generate observations. We do so             node turns a deterministic prototype into a stochastic process.
within a simple domain where we can fully know and manip-
                                                                            All of the more abstract ways of formalizing generative
ulate the actual generating processes behind complex objects.
                                                                         models in our tree domain compose these basic processes.
We use tree-structured graphs with colored nodes as observa-
                                                                         Nested prototypes formalize the intuition that a concept or a
tions in our experiments—these are a simple proxy for many
                                                                         part of a concept can be “either this or that”. Running the
real-world concepts, where the dependencies among parts are
                                                                         program (if (flip .5) (node •) (node •)) will flip a fair
hierarchical or tree-like. Human bodies, buildings, and events
                                                                         coin and return a sample from (node •) with probability .5,
all consist of parts that themselves contain parts, with each
                                                                         otherwise a sample from (node •).
part standing in interesting relation to the others.
   We represent these trees as nested lists: each list denotes              One of the central reasons for analyzing concepts as
a tree, with the first element in the list specifying the color          represented in a language of thought is that they com-
of the root node and the remaining elements describing the               pose analogously to the components of natural and artificial
children of this node, each child itself being a list (tree). For        languages—parts similarly allow composition through reuse
example, the second tree shown in figure 1 can be represented            in our domain. A part concept is defined first and can then
as (• (•) (• (•) (•)) (•)).
  ´                                                                      be used in arbitrarily many places within other concepts. For
   We formalize the processes that generate these obser-                 example, the program (define (part) (node • (node •)))
vations using a subset of Church, a Lisp-like stochas-                   names a simple part consisting of only two nodes. This
tic programming language1 (Goodman, Mansinghka, Roy,                     part can now be reused in other concepts. For example,
Bonawitz, & Tenenbaum, 2008). Programs in Church de-                     the most likely return value for (node • (part) (part))
scribe processes that produce values; running a program cor-             is (• (• (•)) (• (•))). When parts are defined, they are
                                                                            ´
responds to generating a value from such a process. Because              available to the noise process. This leads to some invariance
Church contains primitive functions that randomly choose                 to the position of parts and captures the idea that a generating
from a distribution on values (e.g. the function flip that ran-          process may give rise to observations that contain a part in a
domly chooses true or false), Church programs describe                   different place, although with lower probability compared to
stochastic processes. The meaning of a Church program is                 an observation with the part in the correct place.
                                                                            Parameterized parts can capture both deterministic struc-
   1 Church uses prefix notation, i.e. function application is written   ture and random choices and reuse them in multiple places.
with the operator first, the operands following. For example, (node
x y) means that the function node is called with the arguments x and     When a part like (define (part x) (node • x x)) is used,
y.                                                                       for example in the program (part (node •)), it evaluates
                                                                     2297

the body of the part—here (node • x x)—with x assigned to            this distribution, i.e. by the single concept that has the highest
its argument, here (node •). Evaluating the program (part            posterior probability and that (2) the true generating concept
(node •)) is therefore most likely to result in the observa-         Ctrue is a good approximation to the MAP estimate. Thus, for
tion (• (•) (•)).
    ´                                                                each of the concept types we investigate, we model subjects’
   Allowing parts to call themselves introduces recursion,           behavior using the program from which the training data was
a means to capture a large amount of repetitive observed             sampled. The likelihood of a new observation t belonging to
structure in a single short definition. For example, the part        this concept is simply P(t|Ctrue ) which we compute using an
(define (p) (if (flip) (node •) (node • (p)))) can gen-              adaptive importance sampling algorithm.
erate arbitrarily deep lists of single blue nodes, with shorter         We do not claim that subjects necessarily identify the true
ones being more likely.                                              generating concept from a few examples; this approximation
   The power of these program constructs is that they may be         is made for computational tractability. The full Bayesian
used compositionally to build more complex concepts, such            model, which maintains uncertainty over generating con-
as those shown in table 1.                                           cepts, can make different predictions in certain cases, but it
                                                                     is not clear whether this represents a bias for or against the
Categorization
                                                                     approximation—to the extent that people remain uncertain of
In order to model generalization and categorization behav-           the concept after a few examples, the Bayesian model would
ior of human subjects, we need not only a way to represent           capture human inferences better than our approximation.
concepts, but also a way to compute the probability of any
given observation belonging to a known concept. We analyze           Tree Exemplar Model This and the next two models are
our experimental results using four models that differ in how        versions of the exemplar-based generalized context model
much they make use of representational structure.                    (GCM) (Nosofsky, 1986). For observations O1 , . . . , On from
   On the unstructured end of the scale, we use a model that         category C and a new observation t for which we would
computes generalization judgements solely by comparing the           like to estimate the likelihood under category C, we use
fraction of nodes that have a given color. On the other end of       P(t ∈ C|O1 , . . . , On ∈ C) ∝ n1 ∑ni=1 e−d(Oi ,t) where d is a dis-
the scale, a generative Bayesian model uses the likelihood un-       tance measure that is sensitive to the tree structure of the ob-
der the true generative process to judge category membership.        servations. Starting from the root node, this measure matches
In between, an exemplar model makes use of tree structure in         the trees as much as possible, incrementing by 1 for each node
the observations, but not of the more abstract generative pro-       that differs in color between the two trees and for each node
cess that led to the observations.                                   that must be generated because it exists in one tree but not in
                                                                     the other tree. This approach is similar to the structure map-
Generative Model In modeling concept learning as                     ping approach used by Tomlinson and Love (2006).
Bayesian program induction, we follow the approach taken
                                                                     Frequency-based Exemplar Models As in the tree exem-
by Goodman, Tenenbaum, et al. (2008). Since we formalize
                                                                     plar model, we use a distance measure d to estimate the like-
concepts as probabilistic programs, the likelihood P(O|C) of
                                                                     lihood of an observation belonging to a category for which
an observation O under a given concept C corresponds to the
                                                                     we have only positive examples. In this version of the model,
probability of the program making its random choices such
                                                                     d(t1 ,t2 ) is the RMSE between the transition count vectors of
that it returns the observation as its value (see Goodman,
                                                                     t1 and t2 . For each pair of node colors, the transition count
Mansinghka, et al. (2008)). The posterior probability of a
                                                                     vector contains the number of times this pair occurs adjacent
concept C given observations O is proportional to this likeli-
                                                                     (as parent-child) in the given tree. We call this model Transi-
hood multiplied by the prior:
                                                                     tion GCM. We also investigate a simplified version that uses
                                                                     the distance between the color count vectors. The length of
                   P(C|O) ∝ P(O|C)P(C)                     (1)
                                                                     this vector corresponds to the number of possible node colors,
   In the last section, we described a language for programs         with each entry in the vector denoting how often this node
which generate trees; a prior P(C) could be derived from this        color appears in the tree of interest. We call this Set GCM.
language, as in Goodman, Tenenbaum, et al. (2008). An ideal
learner would then infer the posterior distribution P(C|O)                                    Experiment
over concepts C given the observation O and make predic-
tions about whether a new observation t belongs to the cat-          This experiment is an exploratory investigation into gener-
egory of the observed objects using each concept C ∈ C in            alization from observations of structured objects. Since our
proportion to its posterior probability:                             main goal in this study is to investigate the representation
                                                                     of concepts and their use for categorization and generaliza-
                 P(t|O) ∝ ∑ P(t|C)P(C|O)                   (2)       tion rather than the memory aspects of learning, we use a
                            C                                        paradigm that minimizes memory demands. By doing so,
   In order to make computational modeling tractable, we             we hope to focus on how people represent the commonalities
make the simplifying assumptions that (1) subjects’ reasoning        between observed instances of a concept and how they use
is dominated by the maximum a posteriori (MAP) estimate of           this knowledge to generalize to new instances. We chose a
                                                                  2298

        Prototype            Nested Prototype                Parts             Parameterized         Single Recursion             Multiple
                                                                                     Parts                                       Recursion
  (node •                   (node •                 (define (part)          (define (part x)        (define (part)          (define (part)
    (node •                   (node •                 (node •                 (node •                 (node •                 (node •
      (node •                   (node •                 (node •                 x                       (if (flip .5)           (if (flip .3)
        (node •)                  (if (flip .5)           (node •))))           (node •                   (node •                 (part)
        (node •))))                 (node •                                       x                         (part)                (node •))
                                      (node •)      (node •                       (node •                   (node •))           (if (flip .3)
                                      (node •         (part)                        x                     (node •))))             (part)
                                        (node •       (node •                       (node • x x)                                  (node •))))
                                          (node •))     (node •                     x)              (node •
                                        (node •)))        (part))                 x)                  (node •               (node •
                                    (node •             (part)))                x))                     (node •)              (node •
                                      (node •)                                                          (node •))               (node •
                                      (node •                               (part                     (part))                     (part)))
                                        (node •))                             (if (flip .5)                                   (part))
                                      (node •))))))                             (node •)
                                                                                (node •)))
Table 1: This table illustrates the concept types that can be represented within our language for generative models. For each type, an example
of a concept (a stochastic program) is shown together with observations drawn from this program. The stochastic function node generates
a mixture of the subtrees that are passed to it as its arguments and a noise process that, with low probability, can generate any tree. The
abstraction methods stochastic branching, (parameterized) parts and recursion compose these stochastic prototypes into more structured
generative processes.
domain that both contains observations with simple structure               Procedure In order to ensure that subjects process the train-
and allows for interesting generative processes—the domain                 ing stimuli, a control question on each page asked how many
of colored trees generated by probabilistic programs.                      of the training trees consist of more than 7 dots. 55 subjects
                                                                           answered less than 13 out of the 18 control questions cor-
Methods                                                                    rectly within an error margin of 2. We did not include these
                                                                           subjects in the analysis.
Participants 250 members of Amazon’s crowdsourcing                            The categorization question asked: “How likely is it that
service Mechanical Turk took part in the online experiment.                the following plant is the same kind of plant as the plants
Subjects were compensated for participation.                               above?” Subjects chose on a seven-step scale ranging from
Stimuli Subjects were told that they are looking at newly                  “certainly the same kind” to “certainly not the same kind”.
discovered kinds of plants that grow in extreme environments.              For each subject, the responses were normalized to [0, 1].
Each subject saw 18 pages, with each page consisting of 15
training examples, a control question, and a test example to-
                                                                           Results
gether with a classification question. Both training and test              Table 2 summarizes the correlation results for all models.
examples were images of simple trees with colored nodes                    Figure 2 shows for each concept type human results and
drawn from tree-generating programs (see e.g. table 3). For                model results for both the exemplar and generative model.
each of the concept types shown in table 1, there were three               For each concept type, three different concepts were part of
tree-generating programs, and for each program there were 7                the experiment, and for each concept, seven different test ob-
test examples. These test examples were chosen to cover a                  servations were shown. A single point in the scatterplot con-
wide range of both intuitive and model judgements of cate-                 tains information on the mean subject response for a single
gory membership. Both training example order and stimuli                   test tree and on the model prediction for this tree.
colors were randomized.                                                       Neither of the two exemplar models based on simple statis-
                                                                       2299

                                            Prototype                      Nested Prototypes                                  Parts                       Parameterized Parts                       Single recursion                   Multiple Recursion
                                                               ●                                    ●●                                          ●
                                                                                                                                                ●                                        ●                                 ●                                      ●
 GCM Log Score
                                                           ●
                                                               ●
                                                               ●                                    ●●●
                                                                                                    ●                                       ●       −2                          ●
                                                                                                                                                                                        ●
                                                                                                                                                                                        ●●                              ● ●
                                                                                                                                                                                                                        ● ●
                                                                                                                                                                                                                          ●                                   ● ●
                                                                                                                                                                                                                                                                ●
                                                         ●●
                                                        ●●                                  ●
                                                                                            ●●                                                                                 ●● ●                                                                       ●
                                        ●                ●                             ●
                                                                                          ●●●               −4           ●          ● ● ●●                                      ●●
                                                                                                                                                                            ● ● ● ●          −5                             ●                         ●
                                                                                                                                                                                                                                                             ●●●
                                                                                                                                                                                                                                                             ●  ●
                                             ● ● ●                   −4                ● ●●
                                                                                                                              ●
                                                                                                                                                                                                          ●●            ●
                                                                                                                                                                                                                                −15
                                            ● ●         ●                                                                                                                                                                                                  ●●
                        −4                  ●                                         ●●                            ●              ●
                                                                                                                                   ●    ●           −8                  ●                                          ●●
                                                                                                                                                                                                                                             ●●
                                                                                                                                                                                                                                              ●●               ●
                                             ●
                                                                                                            −8          ●          ●   ●                        ●
                                                                                                                                                                ●                                   ●● ●●         ●                                        ●
                                                                                                                         ●                                                                                        ●                                          ●
                                                                              ●                                           ●             ●                                                                         ●
                                                                             ●                                                                                      ●
                                                                     −8                                                        ●
                        −8              ●                                                                                                           −14                                      −15                                −30
                                                                                                            −14
                                         ●●                                  ●                                                 ●                                                ●                             ●   ●                                   ●
                                      0.0         0.4       0.8            0.0        0.4          0.8            0.0         0.4       0.8               0.0       0.4             0.8            0.0    0.4           0.8            0.0           0.4          0.8
 Generative Log Score
                                                                     0
                                      Human Judgement                      Human Judgement                        Human Judgement                          Human Judgement
                                                    ●                                    ●●●                                 ●●
                                                                                                                                                    0                                                                           0                          ●●
                                                  ● ●●                                ●● ● ●                                  ●                                    ●● ●●●
                                                                                                                                                                        ●                                                  ●●
                                                                                                                                                                                                                        ●● ●
                                                                                                                                                                                                                           ●
                                                                                                            −10                                                                                                                                       ●● ●
                                               ●● ●
                                                                                                                                                                                             −10
                                                                                 ●                                   ●                                              ● ●                                                                                  ●●●
                        −50 −30 −10
                                                                                    ●                                                                                                                             ●     ●
                                            ●●                                              ●●
                                                                                             ●●
                                                                                               ●                    ●              ● ●●                                             ●
                                                                                                                                                                                    ●                                   ●                                  ●
                                            ● ● ● ●●
                                                   ●                                                                                 ●
                                                                     −20                                                      ● ●●                                                                            ●   ●
                                                                                                                                                                                                                                −40
                                               ●                                                                                                                                ●   ●                                                            ●
                                        ●                                             ●●
                                                                                       ●                                                                                        ●                                   ●
                                                                                                                                                                                                                                                           ●●
                                                                                                                                                                                                                                                           ●
                                                                                                                                                    −30
                                                                                                                                ●     ●                                 ●                                 ●●
                                                                                 ●
                                                                                                            −40                ●
                                                                                                                                    ●
                                                                                                                                                                                             −40     ●
                                                                                                                                                                                                                   ●
                                              ●                                                                         ●●●                                                                               ●                                           ●       ●
                                                                             ●                                                                                                                                    ●
                                                                                                                                                                                                         ●
                                                                     −50                                                                                                    ●
                                                                                                                                                                                                                                −100
                                                                                                                                                                ●                                                                                ●
                                                                                                            −70
                                                                                                                                                                                                                                                 ●
                                                                                                                                                    −60
                                         ●●
                                        ●                                    ●                                                 ●                                ● ●
                                                                                                                                                                                             −70    ●             ●                          ●
                                      0.0         0.4       0.8            0.0        0.4          0.8            0.0         0.4       0.8               0.0       0.4             0.8            0.0    0.4           0.8            0.0           0.4          0.8
Figure 2: Comparison between human and model responses across concept types for tree exemplar and generative model. For each of the
six concept types, three examples were shown; the color of the dots indicates to which example any given datapoint belongs. Empty circles
denote isolated part cases that were excluded from the correlation analysis.
                                                                    Set          Transition               Tree          Generative                  predict human behavior in ways similar to the tree exemplar
                                                                   GCM            GCM                     GCM           Model
                                                                                                                                                    model for less structured examples and similar to the true gen-
 Prototype                                                         0.589          0.751                   0.803          0.748
                                                                                                                                                    erating process model for the more structured examples.
 Nested Prototype                                                  0.544          0.851                   0.937          0.904
 Parts*                                                            0.320          0.617                   0.705          0.835
                                                                                                                                                       Having seen how different models predict human judge-
                                                                                                                                                    ments for different concept types, we will now look at indi-
 Parameterized                                                     0.298          0.591                   0.778          0.911
 Parts                                                                                                                                              vidual response patterns in order to determine ways in which
 Single Recursion                                                  0.284             0.499                0.637           0.773                     both of the two structural models can be improved.
 Multiple                                                          0.505             0.561                0.451           0.770                        The part example in table 3 shows how changes to the lo-
 Recursion                                                                                                                                          cation of a part can have significantly different effects de-
                                                                                                                                                    pending on whether the overall concept is preserved (result-
Table 2: Human-model correlations for the experiment. Each row
shows how well the different models predicted subjects’ perfor-                                                                                     ing in high generalization) or the part is moved into a com-
mance for a particular concept type. *Correlations excluding iso-                                                                                   pletely different environment (resulting in low generaliza-
lated part cases (see text).                                                                                                                        tion). By analogy, a Picasso face, with eyes in odd places,
                                                                                                                                                    is still more of a face than an eye alone. Parts seen out of
tics was the best predictor for any of the concept types, with                                                                                      context constitute a problem for all models (except for the
the transition-based exemplar model performing strictly bet-                                                                                        simplest set-based one): subjects judged these isolated parts
ter than the set-based model. An effect that is not accounted                                                                                       as unlikely to come from the concept that included them as
for by the less structural exemplar models is illustrated by                                                                                        subparts whereas the models did give a high score to these ex-
the nested prototype example in table 3: Subjects generalize                                                                                        amples. Since including these outliers dramatically changed
significantly more to examples with branches they have seen                                                                                         the scores and made the interpretation of the model compar-
before than to examples that have a mixture of two known                                                                                            ison difficult, we excluded these data points from the analy-
branches. Likewise, subjects seem to generalize significantly                                                                                       sis in table 2. Without correction, the model-human correla-
more to trees with known branches than to trees that have new                                                                                       tions for the part concepts are: 0.403 for the set-based exem-
branches with similar surface statistics. Both results are ex-                                                                                      plar model, 0.505 for the transition exemplar model, 0.512
pected under the two models that make use of tree structure.                                                                                        for the tree-based exemplar model, and 0.543 for the genera-
   If we group prototype and nested prototype as “less struc-                                                                                       tive model (note that rank-order among the models does not
tured” and subconcepts with and without arguments, single                                                                                           change as a result of excluding these data points).
recursions, and multiple recursions as “more structured”, then                                                                                         For the parameterized part example in table 3, changing the
the tree exemplar model best predicts human responses for                                                                                           argument uniformly, i.e. in all places where it occurs, leads
the less structured stimuli whereas the true generative model                                                                                       to consistently higher scores than changing the argument dif-
best predicts performance for the more structured stimuli.                                                                                          ferently in different places; however, this difference is not
   Our generative model makes the simplifying assumption                                                                                            significant. This difference is expected if subjects inferred
that the learner infers a single generating concept from the ex-                                                                                    the true generative model, since changes to the argument re-
amples whereas one interpretation of the tree exemplar model                                                                                        quire only one use of the noise process, whereas nonuniform
is that it uses each of the training examples as a hypothesis                                                                                       changes require many different nodes to be generated by the
on what the true concept looks like. A fully Bayesian learner,                                                                                      noise process. Future research needs to determine whether
which maintains a distribution over generative processes, may                                                                                       this effect is real, perhaps by manipulating the diversity of
                                                                                                                                             2300

       Concept           Nested Prototypes               Parts            Parameterized        Single Recursion             Multiple
        Type                                                                  Parts                                         Recursion
       Training
                                  ...                      ...                  ...                        ...                 ...
                                       ***                       ***                                        **
                                 ***                     ***                                          **
                        0.8                     0.8                       0.8                0.8                      0.8
                        0.4                     0.4                       0.4                0.4                      0.4
          Test
                        0.0                     0.0                       0.0                0.0                      0.0
Table 3: This table illustrates a small selection of our experimental results. For five different concept types, training observations from a
single concept of this type are shown together with subjects’ generalizations for particularly interesting test examples. The error bars are
standard errors of the mean.
parameter arguments in the observations.                                  cepts in this domain. Our results suggest that humans are
   For the single recursion example in table 3, changing the              able to extract abstract regularities, such as recursive struc-
color of a few nodes within the recursion results in a signif-            ture, from examples, but also that there are many subtle ef-
icantly lower generalization. At the same time, a very sim-               fects to be discovered and accounted for in such domains.
ilar manipulation does not result in a significant change in
                                                                          Acknowledgements We thank Frank Jäkel and Brenden
the generalization rating for the multiple recursion example.
                                                                          Lake for useful comments. This work was funded in part
Intuitively, we sometimes see a change as destroying a very
                                                                          by grants from the ONR (N00014-09-0124) and the AFOSR
obvious pattern structure whereas at other times, the change
                                                                          (FA9550-07-1-0075).
in structure is not assumed to be relevant. Future research
needs to characterize when subjects infer that such a pattern                                       References
exists, and when they instead assume coincidence.                         Anderson, J. (1990). The adaptive character of thought.
   The comparison between the frequency based exemplar                    Feldman, J. (1997). The structure of perceptual categories. Journal
models and the two models that rely on tree structure in the                of Mathematical Psychology.
observations makes clear that subjects do make use of the                 Goodman, N. D., Mansinghka, V., Roy, D. M., Bonawitz, K., &
                                                                            Tenenbaum, J. B. (2008). Church: a language for generative
fact that the observations are structured in their generaliza-              models. Proceedings of the 24th Conference in Uncertainty in
tion judgements. Furthermore, comparing the tree exemplar                   Artificial Intelligence, 220–229.
model to the true generative model that makes use of more ab-             Goodman, N. D., Tenenbaum, J. B., Feldman, J., & Griffiths, T. L.
                                                                            (2008). A rational analysis of rule-based concept learning. Cog-
stract structure hints at the possibility that subjects are relying         nitive Science, 32(1), 108–154.
on recursive structure in the observations. The individual re-            Griffiths, T., Canini, K., & Sanborn, A. (2007). Unifying ratio-
sponse patterns in the results of our exploratory experiment                nal models of categorization via the hierarchical dirichlet process.
                                                                            Proceedings of the 29th Annual Conference of the Cognitive Sci-
highlight ways in which both the exemplar-based model and                   ence Society.
the generative model can be improved to more closely reflect              Kemp, C., Bernstein, A., & Tenenbaum, J. (2005). A generative
human generalization patterns.                                              theory of similarity. Proceedings of the Twenty-Seventh Annual
                                                                            Conference of the Cognitive Science Society.
                                                                          Markman, A. (1999). Knowledge representation.
                          Conclusion                                      Nosofsky, R. (1986). Attention, similarity, and the identification-
                                                                            categorization relationship. Journal of Experimental Psychology:
Most studies of concept learning have focused on relatively                 General, 115(1), 39–57.
unstructured objects based on simple features. We have sug-               Rehder, B., & Kim, S. (2006). How causal knowledge affects clas-
gested viewing concepts as probabilistic programs that de-                  sification: A generative theory of categorization. Journal of Ex-
                                                                            perimental Psychology: Learning, Memory, and Cognition.
scribe stochastic generative processes for more structured ob-            Shi, L., Feldman, N., & Griffiths, T. L. (2008). Performing bayesian
jects. In this view concepts denote distributions over objects,             inference with exemplar models. Proceedings of the 30th Annual
and these distributions are built compositionally. We explored              Conference of the Cognitive Science Society, 745–750.
                                                                          Tomlinson, M., & Love, B. (2006). From pigeons to humans:
this idea within a domain of tree-like objects, and carried out             Grounding relational learning in concrete examples. Proceedings
a study of human generalization using a broad variety of con-               of the National Conference on Artificial Intelligence, 21(1), 199.
                                                                       2301

