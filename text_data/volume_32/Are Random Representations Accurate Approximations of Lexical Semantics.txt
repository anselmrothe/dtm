UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Are Random Representations Accurate Approximations of Lexical Semantics?
Permalink
https://escholarship.org/uc/item/2ns6v8r3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Johns, Brendan T
Jones, Michael N
Publication Date
2010-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

      Are Random Representations Accurate Approximations of Lexical Semantics?
                                          Brendan T. Johns (johns4@indiana.edu)
                                         Michael N. Jones (jonesmn@indiana.edu)
                              Department of Psychological and Brain Sciences, Indiana University
                                          1101 E. Tenth St., Bloomington, In 47405 USA
                            Abstract                               decision mechanism. The use of random representations in
                                                                   these models produces a hidden assumption that the
   A common assumption made by cognitive models is that
   lexical semantics can be approximated using randomly            distribution of similarity across randomly selected words is
   generated representations to stand in for word meaning.         symmetric and approximately Gaussian.
   However, the use of random representations contains the            The distributional assumption comes from the design of a
   hidden assumption that semantic similarity across randomly      typical memory experiment in which random words are
   selected words is normally distributed. We evaluated this       used. In these experiments, random words are selected from
   assumption by computing similarity distributions for            a word pool (e.g., Friendly, et al., 1982). Because words are
   randomly selected words from a number of well-know
   semantic measures and comparing them with the distributions
                                                                   randomly selected, they are assumed to have only random
   from random representations commonly used in memory             similarity on dimensions extraneous to the experimental
   models.                                                         manipulation (e.g., orthography, phonology, semantics,
                                                                   etc.); however, this assumption is unlikely to be true. Hence,
   Keywords: Memory models; semantics; episodic recognition
                                                                   it is common to explicitly control extraneous factors such as
                                                                   frequency. In this examination, we focus on semantics—a
                        Introduction                               factor often ignored because it is difficult to quantify and
   A model of a cognitive phenomenon typically requires an         control. In assuming that two randomly selected words have
account of both representation and process, and how the two        only a random expected semantic similarity, random
interact (Estes, 1975). These two aspects of a model are           representations seem appropriate.
interdependent, with the process requiring a representation           However, the use of these representations assumes that
on which to operate, and the representation requiring a            semantic similarity is randomly distributed across all
process to simulate behavior. A common practice in                 sampled words. We demonstrate in the following analysis
cognitive modeling is to use randomly generated                    that this is unlikely to be the case with real words, and may
representations if the theorist wishes to evaluate a process       produce consequences for conclusions drawn from process
mechanism, but is unsure of the correct psychological              models that have used random representations.
structure or features to use as a representation. This practice
makes it unlikely that the representation is biased towards                                   Analysis
supporting the process model, and the process account can
                                                                   To evaluate the assumption of random similarity,
be later refined when further research reveals the correct
                                                                   comparison distributions are needed. Our analysis will
representation. Over the history of computational modeling,
                                                                   utilize three types of semantic similarity measures to create
emphasis has been placed on processing over representation.
                                                                   distributions—similarity measures computed from: 1) free
   If insufficient research exists to point towards the correct
                                                                   association data, 2) a hand-coded lexical ontology
representation, random representations often provide a
                                                                   (WordNet), and 3) corpus-based co-occurrence models.
useful alternative or simulation of the process would be
impossible. An excellent example is Hintzman‘s (1986) use
of random representations to simulate schema abstraction           Semantic Measures
using Posner and Keele‘s (1968) stimuli. Briefly, stimuli             1. Word Association Space (WAS). Steyvers, Shiffrin,
were random dot patterns, and exemplars of the same                and Nelson (2004) developed a method for inferring
category were random perturbations of a prototype pattern.         semantic representations from free association data.
Without needing to account for how the human visual                Steyvers et al. represented the free association data for the
system represents dot patterns, Hintzman was able to create        5000 cue words from Nelson, McEvoy, and Schreiber‘s
equivalent structure in his simulation by generating random        (1999) norms in a word-by-word matrix, where each entry
prototypes and exemplars.                                          was the probability of a cue word (the row) eliciting the
   Random representations have been commonly used in               response (the column). This matrix was then reduced in
models of episodic memory, for example, recognition,               dimensionality using singular value decomposition so that
recall, and paired-associate learning. In global matching          each word was represented by an abstracted 400-
models of recognition memory (e.g., Hintzman, 1986;                dimensional vector. Steyvers et al. demonstrated that the
Murdock, 1982; Shiffrin & Steyvers, 1997) decisions are            resulting vectors are a good predictor of similarity effects in
made by assessing the similarity of the probe word to the          recognition, recall, and other behaviors.
(usually noisy) study items with a particular processing and
                                                                55

   2. WordNet Similarity. WordNet (Miller, 1990) is a             word x and word y together and dividing by the probability
hand-coded lexical database encoded as a network in which         of observing x and y independently. Recchia & Jones
nodes contain one or more synonymous words. These nodes           computed PMI values over a very large corpus of Wikipedia
are then linked together via different types of lexical           articles (approximately 400,000 articles), and found that
relationships (e.g. hypernymy and holonymy) and based on          PMI produced a significantly better fit to human rating data
these relationships it is possible to build a measure of          than LSA or other semantic similarity metrics.
semantic similarity between two given words using network
statistics. A variety of methods that have proposed to do         Random Representations
compute similarity, but the measure that seems to best map
                                                                  To compare to the distributions created by the semantic
onto human similarity ratings is the Jiang-Conrath distance
                                                                  measures, we explored five common types of random
measure (JCN; Maki, McKinely, & Thompson, 2004). JCN
                                                                  vectors that have been used to represent semantics in
is a network distance measure that basically counts the
                                                                  influential models of memory.
number of nodes and edges between two concepts in the
                                                                     1. Random Gaussian Vectors. A word‘s representation
database.
                                                                  is created by randomly sampling vector elements from a
   3. Latent Semantic Analysis (LSA). This method (and
                                                                  Gaussian distribution with a certain mean (typically zero)
those that follow) differs from the WAS of Steyvers, et al.
                                                                  and variance (usually 1/N, where N is vector
(2004) in that it does not use human behavioral data to
                                                                  dimensionality). This type of representation has been used
create a semantic representation but, rather, uses statistical
                                                                  in a variety of models of recognition (e.g. Murdock, 1982),
regularities computed from a large text corpus. In LSA
                                                                  and recall, among others. In the following analysis, vectors
(Landauer & Dumais, 1997), a word-by-document matrix is
                                                                  were created as in Murdock (1982), with a vector size of
created by tabulating the frequency that each word occurs in
a given document, inversely weighted by the word‘s                250, a mean of 0 and an SD of ( 1/250).
marginal frequency and entropy over documents. The                   2. Gamma Vectors. A word vector is created by
dimensionality of this matrix is then reduced using singular      sampling integers from a gamma distribution:
value decomposition so that each word is represented by a
vector containing the 300-400 dimensions with the largest
                                                                              P[V  j]  (1 g) j1 g, j 1,...,            (1)
eigenvalues. Words that frequently co-occur in similar               Where g is a parameter between 0 and 1 that defines the
documents will be represented by similar vectors.                 environmental base rates for the different feature values.
   4. BEAGLE. In the BEAGLE model of Jones and                    This type of representation has been used in the highly
Mewhort (2007), a distributed holographic representation of     successful REM model of recognition memory (Shiffrin &
a word is built through experience with a text corpus. Words      Steyvers, 1997), and related models. We constructed these
are initially represented by random Gaussian vectors, and a       vectors as specified in Shiffrin & Steyvers (1997), with a
word‘s semantic representation is created by summing and          length of 20, and a g = 0.45 (the parameter used to create
convolving (cf. Murdock, 1982) other words that occur in          high frequency words).
sentences with a target word. The use of convolution allows          3. MINERVA vectors. In the influential MINERVA 2
order information to be included (the sentential position of      model of memory (Hintzman, 1986), vector elements are
the word relative to other words), as well as the basic co-       assumed to be randomly selected from the set of {-1, 0, 1}.
occurrence information in LSA. This associative mechanism         A value of 1 is intended to represent a positive link between
affords inclusion of rudimentary syntactic knowledge in the       the word and that feature, a -1 represents an inhibitory link,
vector representation of the word.                                while a 0 is defined as either irrelevant or unknown for that
   5. The COALS model. Unlike the two previous models,            particular word and feature. Vectors were constructed with a
COALS (Rohde, Gonnerman, & Plaut, submitted) is not               length of 20. Similarity for these vectors was calculated
designed to explain human learning, but rather to create a        with the following equation:
co-occurrence metric that yields the best predictions on a
                                                                                              Pi  Ti, j
                                                                                  si  
                                                                                          D
variety of semantic tasks. The model creates a word-by-
                                                                                                                           (2)
word matrix, with modifications to how values within the                                  j1    n
matrix are computed (i.e. correlations are used instead of
                                                                  Where D is the size of the vectors, P is the probe word, T is
pure co-occurrence count). This large, sparse matrix is
                                                                  a studied memory trace and n is the number of non-zero
subsequently reduced in dimensionality with SVD in the
                                                                  items in P. The value is then transformed by cubing it.
same way LSA reduces a co-occurrence matrix.                         Sparse Binary Vectors. In this type of distributed
                                                                     4.
   6. Pointwise Mutual Information (PMI). PMI uses a
                                                                  representation, the majority of entries are zero, with some
pure co-occurrence count across a large text corpus to create
                                                                  entries having the value of 1 at random locations. For
a measure of similarity between two words (e.g., Recchia &
                                                                  instance, in Plaut (1995) items in a word‘s semantic
Jones, 2009). As with COALS, PMI is not meant to be a
                                                                  representation had a 10% probability of being non-zero.
model of human learning or representation, but rather a
                                                                  Sparse binary vectors have been used to model lexical
scalar measure of similarity between two words. PMI is
                                                                  priming (Plaut) and recognition memory (Dennis &
essentially computed by taking the probability of observing
                                                                  Humphreys, 2001), among other domains. Similar to Plaut‘s
                                                               56

simulations we generated vectors with a length of 100 and
each item having a 10% probability of being non-zero. In
addition, binomial distributions (with a sparsity of 50%)
will also be tested to examine the effect of sparseness on the
similarity distributions.
  5. Dichotomous Vectors. Another common type of
representation used in connectionist modeling is a random
vector composed equally of 1 or -1. These are similar to
MINERVA vectors, but without any zero-valued elements.
Dichotomous vectors have been used in variety of models,
such as connectionist models of semantic priming (e.g.,
Masson, 1995). We use vectors with a length of 100 in the
following simulations.
                           Method
                                                                   Figure 1. Levels of skewness for the different distributions.
To calculate similarity distributions using the semantic
measures, 1000 words were selected from the Toronto word          (Recchia & Jones, 2009). In the middle was the JCN
pool (Friendly, et al., 1982), and the similarity between each    measure with a skewness of 2.61 and the WAS of Steyvers,
word in the pool was computed. Next, 50,000 of these              et al. (2004) with a skewness of 8.04, which signals a highly
semantic comparison values were randomly sampled to               skewed distribution.
examine the distribution of similarity values. In the WAS,           In contrast, all of the random representations produced
LSA, and BEAGLE models the similarity metric used was a           skewness values of essentially zero (this is expected by their
vector cosine (a normalized dot-product), while in COALS          construction). The only distribution that is mildly positively
Pearson‘s correlation was used.                                   skewed is the sparse binomial distribution with a skewness
  For the randomly generated representations, we created a        of 0.21, while the Gamma distribution is actually mildly
distribution of 100,000 similarity comparisons for each           negatively skewed with a value of -0.17.
representation type. The distribution was constructed by             The Q-Q plots are displayed in Figure 2 for the semantic
randomly generating two vectors from the given                    space distributions (left panel) and the distributions
representation type and computing the similarity between          computed from the random representations (right panel).
them. Similarity was vector cosine for all representations.       Due to space limitations, only 4 graphs were included, but
  Toevaluate distribution shape, two different methods of         these are diagnostic of the remaining distributions. Again,
assessing normality were employed: 1) skewness, and 2)            the semantic space distributions show significant deviation
normal quantile-quantile (Q-Q) plots. Skewness is the third       from the expected Gaussian distribution. Specifically, the
moment about the mean, and signals asymmetry in a                 semantic space distributions are skewed to the right, with all
distribution. Q-Q plots are used to assess the difference         of the models having lower than expected number of large
between an observed distribution and a theoretical (in this       similarity values. They also tend to have greater than
case Gaussian) distribution. The standardized values of the       expected low similarity values. Again, the random
comparison distribution are plotted against the respective        representation distributions produce very different results—
values for the Gaussian, and any discrepancy signals a            there is little deviation from normality.
deviation from the theoretical Gaussian distribution.
                             Results
  The skewness values for the similarity distributions of
both the semantic spaces and random representations are
displayed in Figure 1. As the figure shows, all the semantic
spaces create positively skewed similarity distributions.
That is, there tends to be a greater number of low similarity
scores and a small number of high similarity scores in a
given distribution of randomly selected words. Co-
occurrence models (LSA, BEAGLE, and COALS) have the
lowest skew (from 1.06 for BEAGLE to 2.01 for COALS).
The PMI distribution produced the largest skew, likely due
to the fact that this method does not abstract across
documents, but is instead a pure co-occurrence count. Even
with this shortcoming, PMI has been shown to be very
effective in fitting human semantic similarity ratings                   Figure 2. Q-Q plots for semantic and random vectors.
                                                               57

   This simple analysis demonstrates that the similarity            statistically reliable, t(11) = 4.75, p < 0.001. To evaluate the
distributions created by semantic space models and                  effect of skew in the similarity distributions on the resulting
randomly generated representations are considerably                 d-prime values, we computed the partial correlation between
different. Two randomly selected words are likely to be less        d-prime and skewness (controlling for kurtosis and
similar (relative to the other values in the distribution) for      variance) for the distributions, which resulted in a robust r =
semantic models, than for random representations.                   0.913, p < 0.001.
                                                                       The skewness of the similarity distribution has a large
                      Demonstrations                                effect on the calculation of evidence distributions because
                                                                    the probability of sampling lower similarity values is much
In order to show the potential impact that the use of random        greater than in a symmetric distribution. Hence, with ‗true‘
representations may have, two simple demonstrations were            semantic representations an old item tends to be more
conducted using data from recognition memory tasks.                 distinct from other random items on the list, producing a
                                                                    greater difference between old and new evidence
Demonstration #1: Signal Detection Theory                           distributions. This demonstration is certainly not meant as a
   The purpose of this demonstration is to show what effect         refutation of signal detection theory, but instead
skewed similarity distributions will have on a signal               demonstrates that using realistic representations of
detection theory (SDT) based process, which is the                  semantics will impose significant constraint on a processing
dominant decision making process within recognition                 model‘s ability to simulate data.
memory (Shiffrin & Steyvers, 1997; Dennis & Humphreys,
2001). In order to accomplish this, a recognition process
with SDT is simulated by sampling from both skewed
(semantic) similarity distributions as well as normal
(random) similarity distributions. Recognition is then
simulated by fitting an optimal criterion to separate old and
new items, and the resulting d-prime values for the different
distributions will be compared to behavioral results.
   In order to compare the different similarity distributions,
a normalization procedure was necessary. This was done
by taking the distributions from each of the semantic
metrics and random representations and normalizing them
to have a range of 0 and 0.5 and a mean of 0.25. This
procedure allows us to evaluate the shape of the distribution
while centering the distributions on the same mean.
   Evidence distributions for new and old items were                  Figure 3. Levels of discriminability (d-prime) for SDT
simulated for lists of 20 words. The evidence for a probe          simulations; behavioral data from Dennis, et al. (2008).
was the similarity of the probe to the 20 items on the list.
For ‗new‘ probes, this evidence was simply the mean of 20           Demonstration #2: MINERVA 2 and False Recognition
randomly sampled similarity values (as new probes are                  This demonstration was conducted in order to show that
randomly similar to the contents of memory). For ‗old‘              random representations provide an increase amount of
probes, this evidence was the average of the similarity of the      freedom to fit data. The MINERVA 2 model of Hintzman
item to itself and the other items on the list (simulated as the    (1986) has been used to successfully account for a variety of
mean of 19 randomly sampled similarities and the value of           categorical false recognition effects (Arndt & Hirshman,
1, representing the similarity of the word to itself). This         1998). Here, we simulate associative false recognition with
process was repeated 50,000 times for each similarity               the model, using both random and structured representations
distribution.                                                       of semantics. Robinson and Roediger (1997) found that as
   To compare the resulting evidence values, the                    the number of studied items that are related to a critical lure
discriminability (measured with d-prime) was calculated for         is increased, so is the probability of falsely recognizing that
each simulation—d-prime is a measure of how distinct                critical lure. The purpose of this demonstration is to
studied items are from non-studied items. Figure 3 displays         compare the ease with which a simple process model like
the d-prime values for the different similarity distributions       MINERVA is able to model this effect when using random
compared with the d-prime from a simple recognition                 representations versus when it is using representations that
experiment which used a list length of 20 (Dennis, Lee, &           contain knowledge about the similarity structure of the
Kinnel, 2008). As the figure illustrates, all of the semantic       actual words.
distributions have higher d-prime than do the random                   To construct MINERVA vectors that contain plausible
distributions. In addition, the d-prime values for the random       semantic structure, we transformed the WAS representations
representations are much closer to the behavioral data from         from Steyvers et al. (2003). Typical applications of
Dennis, et al. The difference in magnitude demonstrated for         MINERVA use ternary vectors with a fairly low
d-prime values for semantic and random similarity was               dimensionality. Hence, WAS vectors were collapsed from
                                                                 58

400 to 20 dimensions by summing every 20 quadrants in the           element switching to zero during study. The simulation with
WAS vector into a single element in the reduced vector.             random representations includes an additional distortion
This reduced vector was then transformed into a ternary             parameter (described above) to create the semantic
vector with values of the set {-1, 0, 1}; the magnitude of the      structure. These parameters were fit to the data from
summed WAS values were recoded so that the highest third            Robinson & Roediger (1997) data using a Nelder-Mead
were assigned +1 (representing a high weighting on that             simplex algorithm. The results of the simulation are
feature), the middle third 0, and the lowest third -1. To           displayed in Figure 4: the MINERVA model that utilizes
ensure that the MINERA transformed vectors still reflected          random representations was able to reproduce the overall
the semantic structure in the original WAS vectors, we              trend in the data. However, this was not the case with the
computed the word-by-word cosines between vectors in                MINERVA model that used semantic representations—this
both representations, and correlated the two matrices: The          model tended to falsely recognize critical items over studied
original vectors and their ternary transformed versions were        items, which is not the case with the human data. The
highly correlated, r = .67, p < .001, indicating that the           random representation version of the model produced an
transformed vectors contain an arrangement of elements that         excellent account of the data, R2 = 0.98, p < .001. However,
reflects the semantic structure in the original WAS vectors.        the version based on the true semantic similarity of the
Using the false recognition lists from Stadtler, Roediger and       words used fit no better than chance, R2 = 0.05, p = .45.
McDermott, (1998) and Gallo and Roediger (2002), there                 This simulation provides a simple demonstration of how a
was a high average similarity of the critical word‘s                process model that has false representation assumptions may
representation to the representations of the list items across      be incorrectly accepted as a plausible model. The only
the 52 word lists, r = 0.35, p< .001.                               difference between the two models is in their representation
   Random representations for critical words and their              structure—the process is identical. While the semantic
corresponding lists were created as in Arndt and Hirshman           version contains the ―true‖ semantic structure for the exact
(1998), by using prototype and exemplar vectors. A                  words used in the experiment, the random version uses the
prototype vector (representing the critical word) is first          distortion parameter to create the semantic structure that is
generated by randomly sampling elements from the set {1,            most likely if this process account is correct. It is
0, -1} with equal probability. Each item in the word list is        exclusively the incorrect inferred semantic structure that
then created by randomly perturbing elements in the                 allows the process account to fit these data. If the correct
prototype vector. This process requires a distortion                representational structure were used, the process account
parameter, which determines the probability of switching            would be rejected. The point is that random representations
elements from the prototype vector when creating a list item        allow unnecessary freedom for the model to fit the data.
vector. The distortion parameter determines how similar the
list items are to the critical word. The important point is that
both the semantic and random representations contain the
exact same elements (same number of -1, 0, and 1s). The
difference is that the elements are arranged independently
for the random representations, whereas they are arranged to
respect the inter-word similarity structure from WAS in the
semantic version.
   For MINERVA with a semantic representation, the results
of Robinson and Roediger (1997) were modeled by
randomly selecting 3 word lists, and adding 3, 6, or 9 items
from one of the lists into a study list. Because the word lists
in Robinson and Roediger were longer (they also used 12
and 15 associates), 27 words selected randomly from the
Toronto word pool were added into the study list. To
simulate this with MINERVA using random representation,
3, 6, or 9 exemplars were created for 3 random prototypes             Figure 4. Results of false recognition simulation.
and added into the study list. Additionally, 27 random
vectors were added into the study list to make the two                                 General Discussion
simulations equivalent. Decisions are based on activation           The use of randomly generated representations contains the
levels of a probe to the studied items (echo intensity:             assumption that semantic similarity is normally distributed
Hintzman, 1986), calculated by summing the similarity               over randomly selected pairs of words. This assumption was
across all items in the study list.                                 shown to be false across many different semantic metrics
    For the MINERVA with semantic representations, there            that have demonstrated success at accounting for human
are two free parameters: 1) a criterion to make a new-old           data. In experiments using words, two randomly selected
decision based on activation levels, and 2) a forgetting            words are likely to be relatively less similar (compared to
parameter which determines the probability of a non-zero            the distribution of all possible pairs) than would be implied
                                                                 59

using randomly generated representations for lexical                  Johns, B. T., & Jones, M. N. (2009). Simulating false recall as an
semantics. Because similarity plays a central role in the                  integration of semantic search and recognition. Proceedings
processing mechanisms used by many memory models, the                      of the 31st Annual Cognitive Science Society.
use of random representations may have consequences for               Jones, M. N., & Mewhort, D. J. K. (2007). Representing word
                                                                           meaning and order information in a composite holographic
conclusions drawn from simulations using these models.                     lexicon. Psychological Review, 114, 1-37.
     As McClelland (2009) has noted, ―…simplification is              Gallo, D.A., & Roediger, H.L. (2002). Variability among word
essential, but it comes at a cost, and real understanding               lists in eliciting memory illusions: evidence for associative
depends in part on understanding the effects of                         activation and monitoring. Journal of Memory and Language,
simplification.‖ (p. 18). The use of random representations             47, 469-497.
in the development of cognitive models has been a                     Hintzman, D. L. (1986). ―Schema abstraction‖ in a multiple-trace
necessary simplification for our understanding of cognitive                memory model. Psychological Review, 93, 411-428.
processes. In doing so, researchers have made use of                  Landauer, T. K., & Dumais, S. T. (1997). A solution to Plato's
representations whose assumptions may not be entirely                      problem: The latent Semantic analysis theory of the
                                                                           acquisition, induction, and representation of knowledge.
accurate, but through the use of this simplification modelers              Psychological Review,104, 211-240.
have made fundamental discoveries about how memory                    Masson, M. E. J. (1995). A distributed memory model of semantic
processes work. However without this assumption these                      priming. Journal of Experimental Psychology: Learning,
results would not have been possible. It has only been                     Memory, & Cognition, 21, 3-23.
within the last decade that researchers have had access to            McClelland, J. L. (2009). The place of modeling in cognitive
realistic representations of lexical semantics. The task for               science. Topics in Cognitive Science, 1, 11-38.
the future is to integrate semantic representations with              Monaco, J. D., Abbott, L. F., & Kahana, M. J. (2007). Lexico-
processing models of memory for a fuller understanding of                  semantic structure and the word-frequency effect in
how they work together to produce observable behavior.                     recognition memory. Learning and Memory, 14, 204–13.
                                                                      Miller, G. A. (Ed.) (1990). WordNet: An on-line lexical database.
     In accordance, recent models have begun to conduct                    International Journal of Lexicography, 3.
this type of integration. For example, Monaco, Abbott, &              Murdock, B. B. (1982). A theory for the storage and retrieval of
Kahana (2007) have created a neural network model of the                   item and associative information. Psychological Review, 89,
mirror effect of frequency, utilizing lexical semantic                     609-626.
representations taken from the WAS of Steyvers, et al.                Nelson, D. L., McEvoy, C. L., & Schreiber, T. A. (1998). The
(2004). Ideally, future models will combine a learning                     University of South Florida word association, rhyme, and
process that builds a representation through exposure to                   word fragment norms. http://www.usf.edu/FreeAssociation/.
environmental information, which can then feed into a                 Plaut, D. C. (1995). Semantic and associative priming in a
processing mechanism. For example, Johns and Jones                         distributed attractor network. Proceedings of the 17th Annual
                                                                           Conference of the Cognitive Science Society.
(2009) have utilized representations built through a co-              Posner, M. I., & Keele, S. W. (1968). On the genesis of abstract
occurrence learning process to drive a processing model of                 ideas. Journal of Experimental Psychology, 77, 353-363.
both false recognition and false recall. These models suggest         Recchia, G. L., & Jones, M. N. (2009). More data trumps smarter
that it is no longer necessary to assume random                            algorithms: Comparing pointwise mutual information to latent
representations for lexical semantics when modeling                        semantic analysis. Behavior Research Methods, 41, 657-663.
cognitive phenomena, but that item-specific semantic                  Robinson, K., & Roediger, H. L. (1997). Associative processes in
representations are now freely available and offer additional           false recall and false recognition. Psychological Science, 8, 389-
modeling constraints about the structure of semantic                    393.
similarity that a process mechanism must operate on to                Rohde, D. L. T., Gonnerman, L., and Plaut, D. C. (submitted). An
                                                                           improved model of semantic similarity based on lexical co-
produce behavior in a given task.                                          occurrence. Cognitive Science.
                                                                      Shiffrin, R.M. & Steyvers, M. (1997). A model for recognition
                          References                                       memory: REM: Retrieving Effectively from Memory.
Arndt, J., & Hirshman, E. (1998). True and false recognition in            Psychonomic Bulletin & Review, 4, 145-166.
     MINERVA2: Explanations for a global matching perspective.        Stadler, M.A., Roediger, H.L., & McDermott, K.B. (1999). Norms
     Journal of Memory and Language, 39, 371-391.                       for word lists that create memories. Memory & Cognition, 29,
Dennis, S., & Humphreys, M. S. (2001). A context noise model of         424-432.
     episodic word recognition.Psychological Review, 108, 452-        Steyvers, M., Shiffrin, R. M., & Nelson, D. L. (2004).Word
     478.                                                                  Association Spaces for Predicting Semantic Similarity Effects
Dennis, S., Lee, M. D., & Kinnel, A. (2008). Bayesian analysis of          in Episodic Memory. In A. Healy (Ed.), Experimental
     recognition memory: The case of the list-length effect.               Cognitive Psychology and its Applications.
     Journal of Memory and Language, 59, 361-376.
Friendly, M., Franklin, P. E., Hoffman, D., & Rubin, D. C. (1982).
     Norms for Toronto word pool: Norms for imagery,
     concreteness, orthographic variables, and grammatical usage
     for 1,080 words. Behavior Research Methods and
     Instrumentation, 14, 375-399.
                                                                   60

