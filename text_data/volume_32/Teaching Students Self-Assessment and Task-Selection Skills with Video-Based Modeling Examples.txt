UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Teaching Students Self-Assessment and Task-Selection Skills with Video-Based Modeling
Examples
Permalink
https://escholarship.org/uc/item/22q2p6bm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Van Gog, Tamara
Kostons, Danny
Paas, Fred
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     Teaching Students Self-Assessment and Task-Selection Skills with Video-Based
                                                       Modeling Examples
                                               Tamara van Gog (vangog@fsw.eur.nl)
                                         Institute of Psychology, Erasmus University Rotterdam
                                          P.O. Box 1738, 3000 DR Rotterdam, The Netherlands
                                               Danny Kostons (danny.kostons@ou.nl)
                        Centre for Learning Sciences and Technologies, Open University of The Netherlands
                                           P.O. Box 2960, 6401 DL Heerlen, The Netherlands
                                                     Fred Paas (paas@fsw.eur.nl)
                                         Institute of Psychology, Erasmus University Rotterdam
                                          P.O. Box 1738, 3000 DR Rotterdam, The Netherlands
                               Abstract                                self-regulated learning, rather, they need additional training
                                                                       or instructional support (e.g., Azevedo & Cromley, 2004;
  For self-regulated learning to be effective, students need to be
  able to accurately assess their own performance on a learning        Van den Boom, Paas, Van Merriënboer, & Van Gog, 2004).
  task, and to select an appropriate new learning task in              Secondly, although the assumption is correct that adaptive,
  response to that self-assessment. This study investigated the        personalized instruction can foster learning compared to
  use of video-based modeling examples to teach self-                  non-adaptive instruction (e.g., Camp, Paas, Rikers, & Van
  assessment and task-selection skills. Students in both the           Merriënboer, 2001; Salden, Paas, Broers, & Van
  experimental and control condition observed the model                Merriënboer, 2004), it is questionable whether self-
  performing a problem solving task; students in the
  experimental condition additionally observed the model
                                                                       regulated learning actually results in adaptivity to students’
  engaging in self-assessment and task selection. Results show         needs.
  that students in both conditions acquired problem-solving              In adaptive instructional systems, learning tasks are
  skills from the examples, as indicated by a substantial pretest      chosen for each individual student based on an assessment
  to posttest knowledge gain. Moreover, students in the                of their current level of knowledge and skill (based on
  experimental condition also acquired self-assessment and             several aspects of students’ performance, e.g., Anderson,
  task-selection skills from the examples: they demonstrated           Corbett, Koedinger, & Pelletier, 1995; Koedinger,
  higher self-assessment and task-selection accuracy on the
  posttest than students in the control condition.                     Anderson, Hadley, & Mark, 1997; or on a combination of
                                                                       their performance and invested mental effort, e.g., Camp et
   Keywords: Example-based learning; self-assessment; task             al., 2001; Corbalan, Kester, & Van Merriënboer, 2008;
   selection; self-regulated learning.                                 Kalyuga, 2006; Salden et al., 2004). The assessment of
                                                                       performance and the selection of an appropriate new
       The Role of Self-Assessment and Task-                           learning task (i.e., based on that assessment) is conducted by
    Selection Skills in Self-Regulated Learning                        the system. For self-regulated learning to be equally
A major aim of many contemporary educational programs is               adaptive and effective, students themselves should be able
to foster students’ self-regulation skills. It is often assumed        to accurately assess their own performance and to recognize
that this aim can be achieved by providing learners with the           what an appropriate new task would be. Unfortunately, there
opportunity to self-regulate their learning processes. In the          is quite some evidence that students, and especially novices
Netherlands, for example, a nationwide innovation was                  who lack prior knowledge of the learning tasks, are not very
implemented in secondary education in 1999 that relies                 accurate self-assessors. Humans seem prone to several
heavily on self-regulated learning (i.e., the ‘study house’;           biases that affect accuracy of self-assessments (for a review,
http://www.minocw.nl/english/education/293/Secondary-                  see Bjork, 1999), such as hindsight bias (i.e., once an
education.html). Self-regulated learning is also assumed to            answer or solution procedure is known, e.g., after feedback,
result in personalized learning trajectories, in which                 students are more likely to think that they could have
instruction is adaptive to the individual student’s needs.             produced it themselves), or availability bias (i.e., answers
Such personalized instruction is expected to enhance                   that come to mind easily are not only more likely to be
students’ motivation and learning outcomes compared to                 provided but are also more likely to be assumed to be
non-adaptive, fixed instruction that is the same for all               correct). Moreover, accurate self-assessment also seems to
students.                                                              require some domain expertise (Dunning, Johnson, Erlinger,
  Unfortunately, there is little evidence for both                     & Kruger, 2003). Individuals with higher levels of prior
assumptions. First of all, research has shown that students            knowledge are more accurate self-assessors, presumably
do not acquire self-regulation skills merely by engaging in            because their experience not only provides them with more
                                                                   296

task knowledge, but also with more knowledge of the              geometry (e.g., Paas & Van Merriënboer, 1994), or physics
criteria and standards that good performance should meet         (e.g., Van Gog, Paas, & Van Merriënboer, 2006), although
(Dunning et al., 2003). In addition, their experience also       recent studies have shown the same effect with less
lowers the cognitive load imposed by the task, allowing          structured tasks such as learning to recognize designer styles
them to devote more cognitive resources to monitoring their      in art education (Rourke & Sweller, 2009).
task performance, which likely provides them with a more            Research inspired by Social Learning Theory (Bandura,
accurate memory representation on which to base their            1986) has mostly focused on modeling, that is, learning by
assessment (Van Gog & Paas, 2009).                               observing another person (the model) perform a task.
  Support for our assumption that novice students’ lack of       Models can be either adults (e.g., Schunk, 1981) or peers
self-assessment skills leads to ineffective self-regulated       (e.g., Braaksma, Rijlaarsdam, & Van den Bergh, 2002;
learning, comes from studies that have shown that providing      Schunk & Hanson, 1985), and they can behave didactically
novice students with control over their learning process may     or naturally (i.e., possibly skipping steps, or making and/or
have beneficial effects on their motivation or involvement,      correcting errors). Moreover, modeling examples can
but often has detrimental effects on learning outcomes (see      consist of a video in which the model is visible (e.g.,
e.g., Azevedo, Moos, Greene, Winters, & Cromley, 2008;           Braaksma et al., 2002), a video consisting of a screen
Niemic, Sikorski, & Walberg, 1996). When positive effects        capture of the model’s computer screen in which the model
on learning outcomes are found, this tends to be mostly for      is not visible (e.g., McLaren, Lim, & Koedinger, 2008; Van
students with higher levels of prior knowledge in the            Gog, Jarodzka, Scheiter, Gerjets, & Paas, 2009), or an
domain (e.g., Niemiec et al., 1996; Moos & Azevedo,              animation in which the model is represented by a
2008), who, as mentioned above, are also likely to be more       pedagogical agent (e.g., Atkinson, 2002; Wouters, Paas, &
accurate self-assessors. In addition, Kostons, Van Gog, and      Van Merriënboer, 2009). Like worked examples, modeling
Paas (2010) investigated differences in self-assessment          examples have also been used to teach highly structured
accuracy between secondary education students who                cognitive tasks such as math (e.g., Schunk, 1981) or
differed in the amount of knowledge gained from studying         chemistry (e.g., McLaren et al., 2008), but they have also
in a learner-controlled instructional environment that           been widely applied with less structured tasks such as
contained heredity problems with varying levels of support       writing (e.g., Braaksma et al., 2002; Zimmerman &
at different levels of complexity. They found that the           Kitsantas, 2002). In addition, they have been used for
students who had gained more knowledge, had also more            teaching metacognitive skills such as self-regulation (e.g.,
accurately assessed their own performance during learning.       Kitsantas, Zimmerman, & Cleary, 2000; Zimmerman &
  Without accurate self-assessment, selecting an appropriate     Kitsantas, 2002). For a more in-depth review of research on
new learning task will also be very difficult. Given the         worked examples and modeling examples, see Van Gog and
central role that self-assessment and task-selection skills      Rummel (in press).
seem to play in self-regulated learning, an important               This study investigated whether video-based modeling
question is whether we can teach novice students to become       examples consisting of screen-recordings could be
more accurate self-assessors and task selectors. We decided      successfully applied for teaching secondary education
to investigate this question, using modeling examples to         students self-assessment and task-selection skills.
teach those skills.
                                                                                            Method
Learning from Examples
Learning from examples is known to be a highly effective         Participants and Design
instructional strategy. Research inspired by cognitive           Participants were 39 Dutch secondary education students
theories such as ACT-R (Anderson, 1993) or Cognitive             (age M = 15.08, SD = 0.48; 26 female) in the fourth year of
Load Theory (Sweller, Van Merriënboer, & Paas, 1998) has         pre-university education (the highest level of secondary
extensively investigated the effects on learning of              education in the Netherlands, which has a duration of six
instruction consisting of studying worked examples, which        years). They were novices on the content domain of the
provide students with a written worked-out didactical            examples (heredity problems), which had yet to be taught in
solution to a problem. These studies have consistently           the formal curriculum. Participants were randomly assigned
shown that for novices, studying worked examples is more         to the experimental (n = 20) or control condition (n = 19).
effective and/or more efficient for learning (i.e., equal or
higher learning outcomes attained with lower or equal            Materials
investment of time and/or effort) than (tutored) problem
solving, which is known as the ‘worked example effect’
(Sweller et al., 1998; for further reviews, see Atkinson,        Pretest and Posttest The pretest and posttest consisted of 5
Derry, Renkl, & Wortham, 2000). Studies on the worked            paper and pencil heredity problems, at five levels of
example effect have mainly used highly structured cognitive      complexity (see Figure 1), presented in random order. The
tasks, such as algebra (e.g., Cooper & Sweller, 1987;            students were informed at what level of complexity each
Sweller & Cooper, 1985), statistics (e.g., Paas, 1992),          problem was. These heredity problems could be solved by
                                                                 going through the following five steps: (1) translate the
                                                             297

phenotypes (expression of genetic trait) described in the           different cover stories. Participants knew the complexity
cover story into genotypes (a pair of upper and/or lower            level of the problem they had just worked on. They did not
case letters representing genetic information); (2) put these       actually get the problem they selected to work on next; test
genotypes into a hereditary diagram; (3) determine direction        problems were the same for all students.
of reasoning and number of Punnett Squares; (4) fill in
Punnett Square(s); (5) extract final solution from Punnett          Modeling examples The four modeling examples consisted
Square(s). The posttest problems were equivalent but not            of a recording of the model’s computer screen along with a
identical to the pretest problems; they had similar structural      spoken explanation by the model of what s/he was doing.
features and were of similar complexity, but the surface            The gender of the models was varied: two examples were by
features (cover stories) differed. On both tests, participants      two different male models, and two examples were by two
were instructed to write down the steps they took to reach          different female models (see Table 1). In the experimental
their solution.                                                     condition, the modeling examples consisted of three
                                                                    “phases”:
                                                                       (1) Problem solving: The model performed the problem
                                                                    solving task. Two models worked on problems of
                                                                    complexity level 1, and two models worked on problems of
                                                                    complexity level 2 (i.e., of the five complexity levels
                                                                    present in the task database and in the pretest and posttest;
                                                                    see Table 1). The quality of the models’ performance varied
                                                                    between the examples: one example showed a model
                                                                    accurately solving the problem, but in the other three
                                                                    examples the models made one or more errors (see Table 1).
                                                                    This was done to create variability in phases 2 and 3 of the
                                                                    examples, that is, in the model’s self-assessment scores and
                                                                    task selections (i.e., if the model would not make any errors
                                                                    or would detect and correct them immediately, they would
                                                                    always have the highest possible self-assessment score).
                                                                       Table 1: Overview of modeling example characteristics.
                                                                      Example      Model            Performance     Complexity
                                                                      1            Male 1           0 errors        Level 1
                                                                      2            Female 1         2 errors        Level 1
                                                                      3            Male 2           4 errors        Level 2
                                                                      4            Female 2         1 error         Level 2
           Figure 1: Overview of the task database.
Mental effort rating After each problem in the pretest and            (2) Self-assessment: Following task performance, the
posttest, participants rated how much mental effort they            model rated invested mental effort on the 9-point rating
invested in solving that problem on a 9-point rating scale          scale and assessed their performance on the 6-point rating
(Paas, 1992).                                                       scale, assigning themselves one point for each correct step.
                                                                    The models’ self-assessment was always accurate.
(Self-)assessment After the mental effort rating, participants        (3) Task selection: Then, the model selected a new task
self-assessed their performance on a 6-point rating scale           based on a combination of the performance score and the
ranging from 0 (none of the five steps correct) to 5 (all steps     mental effort score. The models used a table (see Figure 2)
correct). After the experiment, participants’ performance           in which the relationship between performance and mental
was scored by the experimenter on the same scale (i.e., max.        effort scores was depicted, which could be used to infer a
problem: 5; max. test: 25).                                         recommended ‘step size’ for task selection (e.g.,
                                                                    performance of 4 and mental effort of 3 means a step size of
Task selection After self-assessment, students indicated on         +2). A positive step size means a recommendation to select
an overview of the task database (Figure 1) what problem            a more challenging task (i.e., less support or higher
they would select next. At each of five complexity levels           complexity level), a step size of 0 means repeating a
(left column), there were three levels of support: completion       comparable task (i.e., same level of support and same
problem, 3 steps worked-out (white row); completion                 complexity level), and a negative step size means a
problem, 2 steps worked-out (light gray row); conventional          recommendation to select a simpler task (i.e., higher level of
problem, no steps worked-out (dark gray row). At each level         support or lower level of complexity). This kind of task
of support within each complexity level there were 5 tasks          selection algorithm based on performance and mental effort
to choose from, which had equal structural features but             scores has proven to lead to an effective learning path in
                                                                298

studies on adaptive, personalized task selection (e.g., Camp          assess one’s own performance as 0. This would be highly
et al., 2001; Corbalan et al., 2008; Kalyuga, 2006; Salden et         accurate, but would have led to a substantial overestimation
al., 2004). The models’ task selection was always accurate.           of participants’ self-assessment accuracy, as it is not very
   Participants in the control condition observed only the            indicative of self-assessment accuracy on tasks that they
model’s problem solving (phase 1). In the time in which the           were –at least partly- able to solve.
participants in the experimental condition observed the                 Task selection accuracy on the posttest was determined by
model’s self-assessment and task selection, participants in           computing the absolute difference between the complexity
the control condition were instructed to indicate whether the         level that would be recommended based on the objective
model made any errors during task performance, and if so,             performance assessment and the complexity level
what the errors were and what the correct step would have             participants chose.
been.
                                                                                                  Results
  Performance
               4-5
                           +2              +1               0
                                                                      For all analyses, a significance level of .05 was used, and
                                                                      Cohen’s d is reported as a measure of effect size, with 0.2,
               2-3
                           +1                0             -1
                                                                      0.5, and 0.8 corresponding to small, medium, and large
                                                                      effect sizes, respectively (Cohen, 1988).
               0-1
                            0               -1             -2
                           1, 2, 3          4, 5, 6       7, 8, 9     Acquisition of Problem-Solving Skills
                                                         Effort       Participants’ mean performance score on the pretest was
                                                                      2.08 (SD = 3.58), and on the posttest it was 14.31 (SD =
         Figure 2: Determining task selection step size.              6.43), so all students acquired procedural skills for solving
                                                                      heredity problems from the modeling examples. A t-test
Procedure                                                             showed no significant difference between the control
The experiment was conducted in a computer room at the                condition (M = 12.05, SD = 7.12) and the experimental
participants’ school. First, all participants completed the           condition (M = 12.40, SD = 6.40) in the knowledge gain
pretest on paper. Participants were given four minutes to             from pretest to posttest, t(37) = 0.16, ns.
complete each problem, followed by one minute for
assessing their performance (a previous study had shown               Acquisition of Self-Assessment Skills
this to be sufficient time for solving the problem; Kostons et        A t-test on the mean self-assessment accuracy scores on the
al., 2010). Participants were not allowed to proceed to the           posttest, showed that participants in the experimental
next problem before the time was up; time was kept by the             condition were more accurate (i.e., lower score; M = 0.70,
experimenter using a stopwatch. After completing the                  SD = 0.53) than participants in the control condition (M =
pretest, participants studied the modeling examples on the            1.26, SD = .85), t(37) = 2.51, p = .016 (two-tailed), d = 0.79.
computer; each participant had a head set for listening to the
model’s explanations. In the experimental condition, the              Acquisition of Task-Selection Skills
modeling examples showed participants the task
performance, self-assessment, and task selection by the               Data from 1 participant in the experimental condition were
model. In the control condition, participants only observed           excluded from this analysis because of too many missing
the task performance by the model and then indicated                  values. A t-test on the mean task-selection accuracy scores
whether errors were made and if so, what the correct step             on the posttest, showed that participants in the experimental
was. This part was computer-paced, participants had to view           condition were more accurate (i.e., lower score; M = 0.81,
the examples in the order in which they were offered and              SD = 0.60) than participants in the control condition (M =
could not pause, stop, or replay the examples. Finally, all           1.21, SD = 0.54), t(36) = 2.15, p = .038 (two-tailed), d =
participants completed the posttest on paper, according to a          0.70.
similar procedure as the pretest.
                                                                                               Discussion
Data Analysis                                                         This study showed that students can not only acquire
Self-assessment accuracy on each posttest problem was                 problem solving skills from studying modeling examples,
determined by computing the absolute difference between               but also self-assessment and task selection skills, which are
participants’ objective performance score and their self-             considered to play an important role in the effectiveness of
assessment of their performance. The lower this difference,           self-regulated learning.
the more accurate participants’ self-assessment was (i.e., 0 =          We chose modeling examples as a means to teach self-
100% accurate). We did not compute or analyze self-                   assessment and task-selection skills, because research has
assessment accuracy on the pretest, because participants              shown that example-based learning is a powerful
managed to solve very few problems on that test. When one             instructional strategy. Thus far, in educational settings,
is not able to perform a task at all, it is not very difficult to     examples have mostly been used for teaching cognitive
                                                                  299

skills, and this study adds further evidence that they are             not be very effective, as assessment criteria and standards
useful for teaching metacognitive skills as well (see also             will differ for different types of task. However, we do
Kitsantas et al., 2000; Zimmerman & Kitsantas, 2002). We               expect that experience with self-assessment and task
did not, however, compare whether teaching self-assessment             selection through training in one task or domain may
and task-selection skills via modeling examples was more               facilitate acquisition of those skills for other tasks or
effective than teaching those skills in some other way (e.g.,          domains (i.e., transfer in the sense of preparation for or
via practice after having been explained the assessment and            accelerated future learning; Bransford & Schwartz, 1999).
selection ‘rules’, i.e., how to come to a performance                    Last but certainly not least, the most important question
assessment score and how to combine performance and                    for future research is whether students can apply the self-
mental effort scores to select a new task), so the                     assessment and task selection skills they acquired from
effectiveness of examples compared to other means of                   modeling examples in a self-regulated learning environment
teaching self-assessment and task-selection skills might be            in which they are allowed to select which problems to work
explored in future research.                                           on. If so, one would expect training self-assessment and
  Our control condition received no self-assessment and                task-selection skills to improve learning outcomes attained
task-selection training at all, but engaged in a filler task           as a result of self-regulated learning.
(finding and fixing errors) which may have been relevant for
the acquisition of problem solving skills (see Große &                                      Acknowledgments
Renkl,, 2007) and which we expected to direct students’                The first author was supported by a Veni grant from the
attention towards assessment of performance (of the model)             Netherlands Organization for Scientific Research (NWO;
to some extent. Further analysis of data from the control              451-08-003).
condition was beyond the scope of this paper but could be
interesting in its own right. For example, one might expect
that students with better ability to find and correct errors
                                                                                                References
would have better self-assessment skills and/or would show             Anderson, J. R. (1993). Rules of the mind. Hillsdale, NJ:
more knowledge gain. In addition, it might be interesting to             Erlbaum.
establish whether the errors made by the models had any                Anderson, J. R., Corbett, A. T., Koedinger, K., & Pelletier,
effects on students’ test performance (especially for those              R. (1995). Cognitive tutors: Lessons learned. The Journal
students who were not able to find and fix errors).                      of Learning Sciences, 4, 167-207.
  A question we cannot address based on our data that                  Atkinson, R. K. (2002). Optimizing learning from examples
would be interesting to address in future research concerns              using animated pedagogical agents. Journal of
the relationship between students’ levels of task knowledge              Educational Psychology, 94, 416-427.
and the accuracy self-assessment and task-selection skills.            Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.
Even though there was some variability in pretest scores,                (2000). Learning from examples: Instructional principles
these were in general very low. Problem-solving skills did               from the worked examples research. Review of
increase from pretest to posttest. We cannot rule out that the           Educational Research, 70, 181-214.
increase in problem-solving skills might have increased                Azevedo, R., & Cromley, J. G. (2004). Does training on
students’ self-assessment and task-selection accuracy in the             self-regulated learning facilitate students' learning with
control condition, we only know that the training in the                 hypermedia? Journal of Educational Psychology, 96, 523-
experimental condition led to significantly higher accuracy              535.
than attained in the control condition. A problem that occurs          Azevedo, R., Moos, D. C., Greene, J. A., Winters, F. I., &
in trying to establish gains in assessment and task selection            Cromley, J. G. (2008). Why is externally-regulated
accuracy is that it is hard to establish the level of these skills       learning more effective than self-regulated learning with
at pretest, because –as mentioned above- it is easy to rate              hypermedia? Educational Technology Research and
performance as 0 when one is not able to perform a task at               Development, 56, 45-72.
all. Although this is a highly accurate self-assessment, it            Bandura, A. (1986). Social foundations of thought and
probably does not reflect a high level of self-assessment                action: A social cognitive theory. Englewood Cliffs, NJ:
skill. Therefore, a design in which students have lower and              Prentice Hall.
higher levels of prior knowledge at the start of the                   Bjork, R. A. (1999). Assessing our own competence:
experiment would be required to address this question.                   Heuristics and illusions. In D. Gopher and A. Koriat
  Other important questions for future research in this area             (Eds.), Attention and performance XVII. Cognitive
concern whether training either self-assessment or task-                 regulation of performance: Interaction of theory and
selection skill would automatically lead to improvements in              application (pp. 435-459). Cambridge, MA: MITPress.
the other skill or whether both need training as in our                Braaksma, M. A. H., Rijlaarsdam, G., & Van den Bergh, H.
experimental condition, as well as whether acquired self-                (2002). Observational learning and the effects of model-
assessment and task selection skills can transfer to other               observer similarity. Journal of Educational Psychology,
tasks in the same domain or even to other domains. We                    94, 405-415.
assume that spontaneous transfer is not very likely or would
                                                                   300

Bransford, J. D., & Schwartz, D. L. (1999). Rethinking             Paas, F., & Van Merriënboer, J. J. G. (1994). Variability of
  transfer: A simple proposal with multiple implications.            worked examples and transfer of geometrical problem-
  Review of Research in Education, 24, 61-101.                       solving skills: A cognitive-load approach. Journal of
Camp, G., Paas, F., Rikers, R. M. J. P., & Van Merriënboer,          Educational Psychology, 86, 122-133.
  J. J. G. (2001). Dynamic problem selection in air traffic        Rourke, A., & Sweller, J. (2009). The worked-example
  control training: A comparison between performance,                effect using ill-defined problems: Learning to recognize
  mental effort, and mental efficiency. Computers in                 designers' styles. Learning and Instruction, 19, 185-199.
  Human Behavior, 17, 575-595.                                     Salden, R. J. C. M., Paas, F., Broers, N. J., & Van
Cohen, J. (1988). Statistical power analysis for the                 Merriënboer, J. J. G. (2004). Mental effort and
  behavioral sciences. Hillsdale, NJ: Erlbaum.                       performance as determinants for the dynamic selection of
Cooper, G., & Sweller, J. (1987). The effects of schema              learning tasks in Air Traffic Control training.
  acquisition and rule automation on mathematical                    Instructional Science, 32, 153-172.
  problem-solving transfer. Journal of Educational                 Schunk, D. H. (1981). Modeling and attributional effects on
  Psychology, 79, 347-362.                                           children's achievement: A self-efficacy analysis. Journal
Corbalan, G., Kester, L., & Van Merriënboer, J .J. G.                of Educational Psychology, 73, 93-105.
  (2008). Selecting learning tasks: Effects of adaptation and      Schunk, D. H., & Hanson, A. R. (1985). Peer models:
  shared control on efficiency and task involvement.                 Influence on children's self-efficacy and achievement.
  Contemporary Educational Psychology, 33, 733-756.                  Journal of Educational Psychology, 77, 313-322.
Dunning, D., Johnson, K., Erlinger, J., & Kruger, J. (2003).       Sweller, J., & Cooper, G. A. (1985). The use of worked
  Why people fail to recognize their own incompetence.               examples as a substitute for problem solving in learning
  Current Directions in Psychological Science, 12, 83–87.            algebra. Cognition and Instruction, 2, 59-89.
Große, C. S., & Renkl, A. (2007). Finding and fixing errors        Sweller, J., Van Merriënboer, J. J. G., & Paas, F. (1998).
  in worked examples: Can this foster learning outcomes?             Cognitive architecture and instructional design.
  Learning and Instruction, 17, 612-634.                             Educational Psychology Review, 10, 251–295.
Kalyuga, S. (2006). Assessment of learners’ organised              Van den Boom, G., Paas, F., Van Merriënboer, J. J. G., &
  knowledge structures in adaptive learning environments.            Van Gog, T. (2004). Reflection prompts and tutor
  Applied Cognitive Psychology, 20, 333-342.                         feedback in a web-based learning environment: Effects on
Kitsantas, A., Zimmerman, B. J., & Cleary, T. (2000). The            students’ self-regulated learning competence. Computers
  role of observation and emulation in the development of            in Human Behavior, 20, 551-567.
  athletic self-regulation. Journal of Educational                 Van Gog, T., Jarodzka, H., Scheiter, K., Gerjets, P., & Paas,
  Psychology, 92, 811–817.                                           F. (2009). Attention guidance during example study via
Koedinger, K. R., Anderson, J. R., Hadley, W. H., & Mark,            the model’s eye movements. Computers in Human
  M. A. (1997). Intelligent tutoring goes to school in the big       Behavior, 25, 785-791.
  city. International Journal of Artificial Intelligence in        Van Gog, T., & Paas, F. (2009). Effects of concurrent
  Education, 8, 30-43.                                               performance monitoring on cognitive load as a function of
Kostons, D., Van Gog, T., & Paas, F. (2010). Self-                   task complexity. In N. Taatgen, & H. van Rijn (Eds.),
  assessment and task selection in learner-controlled                Proceedings of the 31st Annual Conference of the
  instruction: Differences between effective and ineffective         Cognitive Science Society (pp. 1605-1608). Austin, TX:
  learners. Computers & Education, 54, 932-940.                      Cognitive Science Society.
McLaren, B. M., Lim, S., & Koedinger, K. R. (2008). When           Van Gog, T., Paas, F., & Van Merriënboer, J. J. G. (2006).
  and how often should worked examples be given to                   Effects of process-oriented worked examples on
  students? New results and a summary of the current state           troubleshooting transfer performance. Learning and
  of research. In B. C. Love, K. McRae, & V. M. Sloutsky             Instruction, 16, 154-164.
  (Eds.), Proceedings of the 30th Annual Conference of the         Van Gog, T., & Rummel, N. (in press). Example-based
  Cognitive Science Society (pp. 2176-2181). Austin, TX:             learning: Integrating cognitive and social-cognitive
  Cognitive Science Society.                                         research perspectives. Educational Psychology Review.
Moos, D. C., & Azevedo, R. (2008). Self-regulated learning         Wouters, P., Paas, F., & Van Merriënboer, J. J. G. (2009).
  with hypermedia: The role of prior domain knowledge.               Observational learning from animated models: Effects of
  Contemporary Educational Psychology, 33, 270–298.                  modality and reflection on transfer. Contemporary
Niemiec, R. P., Sikorski, C., & Walberg, H. J. (1996).               Educational Psychology, 34, 1-8.
  Learner-control effects: A review of reviews and a meta-         Zimmerman, B. J., & Kitsantas, A. (2002). Acquiring
  analysis. Journal of Educational Computing Research,               writing revision and self-regulatory skill through
  15, 157–174.                                                       observation and emulation. Journal of Educational
Paas, F. (1992). Training strategies for attaining transfer of       Psychology, 94, 660-668.
  problem-solving skill in statistics: A cognitive load
  approach. Journal of Educational Psychology, 84, 429-
  434.
                                                               301

