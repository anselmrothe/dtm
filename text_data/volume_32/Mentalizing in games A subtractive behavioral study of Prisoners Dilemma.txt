UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Mentalizing in games: A subtractive behavioral study of Prisoner's Dilemma
Permalink
https://escholarship.org/uc/item/9kx2p9bz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Napoli, Antonio
Fum, Danilo
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                     University of California

                                                   Mentalizing in games:
                          A subtractive behavioral study of Prisoner's Dilemma
                                        Antonio Napoli (antonio.napoli@phd.units.it)
                                                   Danilo Fum (Fum@units.it)
                                    Dipartimento di Psicologia, Università degli Studi di Trieste
                                              via S. Anastasio, 12, I-34134 Trieste, Italy
                            Abstract                                   completely ignore the opponent's behavior and only
   Economists and neuroscientists often explain game playing by
                                                                       manipulate representations about chosen moves and
   assuming that humans try to predict the opponent's behavior         obtained payoffs. They may also be applied to situations of
   on the basis of her past choices. We try to question this           playing without opponents (one-person games); in fact, they
   assumption in a Prisoner's Dilemma Game by using a                  have been proposed by Sutton and Barto (1998) to model
   methodology which we call the “subtractive behavioral               the performance in multi-armed bandit tasks in which
   method”. Our aim is to investigate which task features make         participants make repeated choices among different options
   participants attend to the opponent's behavior or, on the
                                                                       which are followed by a numerical reward that depends on
   contrary, make them take into account only their own choices
   and received payoffs. We find a critical effect of contextual       the choice being made.
   information and we derive some suggestions about the                   On the other hand, full information models manipulate
   methodology of brain imaging and behavioral game theory             representations about the opponents’ moves and payoffs to
   experiments.                                                        anticipate their behavior and obtain thus a strategic
   Keywords: Game Theory; Brain Imaging; Theory of Mind;               advantage. These models address the opponent's beliefs,
   Social Dilemmas; Prisoner's Dilemma                                 intentions, and strategies, and therefore mimic a Theory of
                                                                       Mind (henceforth: ToM) or “mentalizing” mechanism.
                         Introduction                                     Neuroscientist have recently begun to study the cortical
                                                                       circuits involved in game playing through neuroimaging.
   Game Theory (Von Neumann & Morgenstern, 1944) is a
                                                                       Krueger, Grafman, and McCabe (2008), after reviewing the
branch of applied mathematics focused on describing and
                                                                       literature on the topic, propose that two cognitive
predicting the behavior of “players” involved in strategic
                                                                       mechanisms are specifically involved in game playing.
interactions in which the result of every player’s “move” is
                                                                          The first one is a “shared affect system” located in the
contingent on the move(s) made by the other player(s). One
                                                                       Anterior Insula. This area is only activated in non-zero sum
of the critical assumptions of the theory is that games are
                                                                       games in which cooperation between players is possible,
played by completely rational agents whose strategies could
                                                                       and therefore feelings of trust, reciprocity and collaboration
be precisely calculated. In recent years the Game Theory
                                                                       could be developed. The area seems responsible of two
formalism has been adopted to develop models that try to
                                                                       main effects: it makes people feel disgust towards
account for the fact that people often behave differently
                                                                       uncooperative behavior and react to it (for example,
from what the theory predicts. This approach has been
                                                                       rejecting unfair offers in a Ultimatum Game: Sanfey,
named “Behavioral Game Theory” (Camerer, 2003).
                                                                       Rilling, Aronson, Nystrom, & Cohen, 2003) and it makes
   Behavioral Game Theory models make the assumption
                                                                       people reciprocate by distinguishing between cooperative
that people learn during the interaction, i.e., that they change
                                                                       and non-cooperative opponents (Singer, Kiebel, Winston,
their behavior according to the efficacy of their past choices.
                                                                       Dolan, & Frith, 2004).
Among these models there are some, like those based on
                                                                          The second mechanism is a “shared intentions system”,
Reinforcement Learning (Erev & Roth, 1998; Sarin &
                                                                       which is located in the Medial Prefrontal Cortex (MPFC).
Vahid, 2001), which take into account only the player’s own
                                                                       This area is activated both in zero and non-zero sum games,
choices and received payoffs while others, like so-called
                                                                       because it has the function of representing the opponent's
sophisticated (Camerer, Ho, & Chong, 2002) and belief
                                                                       beliefs, desires, and intentions, i.e. it seems to constitute the
learning (Cheung & Friedman, 1997) models, consider also
                                                                       neural substrate of the ToM. Several brain imaging studies
(or only) the opponent's choices and payoff history. We will
                                                                       (see Krueger et al., 2008, for a comprehensive review) have
refer to the former as “partial information models” and to
                                                                       shown MPFC activation during game playing and,
the latter as “full information models”.
                                                                       therefore, it seems plausible that people mentalize while
   Even if Behavioral Game Theory does not make any
                                                                       playing these games.
assumption about the internal mechanisms involved in game
                                                                          There are two other circuits which are not specifically
playing, from a cognitive perspective it is possible to find a
                                                                       involved in game playing but seem to be engaged in all
difference between partial information and full information
                                                                       kinds of learning tasks: a reward-based mechanism situated
models. Partial information models obey to a strictly
                                                                       in a broad network of cortical and subcortical areas (see
behaviorist rule: the more you get from a choice, the more
                                                                       Lee, 2005 for a review), and a system concerned with the
you will choose it in subsequent trials. These models
                                                                  338

prediction of complex behavior independently of its source,        the groups by using a Reinforcement Learning algorithm
which is located in the Posterior Superior Temporal Sulcus         based on ACT-R's utility learning mechanism (Anderson,
(Frith & Frith, 2003).                                             2007). This corroborates the idea that people did not use any
   Studies about mentalizing in game playing usually rely on       information about foregone payoffs in the second condition
the comparison between a condition in which people play            and did not use any information about the opponent's moves
against a computer and one in which they play against a            or payoffs in the first and third condition. In summary,
human opponent on the presumption that mentalizing could           participants did not seem to mentalize at all during the
be promoted by the latter. However, it is not clear whether        experiment.
and when people adopt a “mentalizing stance” and which                There are many possible explanations for this “failure to
task features could promote this activity. In fact, some           mentalize”. Maybe people did not mentalize because they
studies show that a computer opponent could elicit activity        played against a computer; maybe they did not mentalize
in MPFC (Rilling, Sanfey, Aronson, Nystrom, & Cohen,               because the game was a mixed-strategy equilibrium game in
2004), while others claim that not all game situations             which no move was better than the others and a simple
against humans make people mentalize (Sally, 2003).                behaviorist strategy could efficiently cope with the game;
   It is also unclear how mentalizing affects behavior, or, in     maybe people did not mentalize because no cooperation was
other words, how decision making is affected by a ToM. For         possible in playing a competitive game. Or it may be a
example Hill, Sally and Frith (2004) report that autistic          combination of all the three.
adults behave in the same way as healthy participants in the          In this paper we try to clarify the findings of our previous
Prisoner's Dilemma game, even if the autistic participants         work by making participants play a non-zero sum game, the
are severely impaired in other ToM tasks. Also, most               Prisoner's Dilemma, both against what they believed was a
neuroimaging studies lack a comparison between                     human opponent and against a computer. Our aim is to
participant's behavior while playing against a human and a         understand which task features make people mentalize in
computer opponent.                                                 game playing, which features affect game behavior and,
   We are convinced that the study of the ToM mechanisms           possibly, why.
would benefit from experiments which analyze participant's
behavior. Two questions are important to us: 1) Which task                               The experiment
feature make people mentalize? 2) Which effect does                   Prisoner's Dilemma (henceforth: PD) is a non-zero sum
mentalizing have on people's behavior? In the present paper        game which has been extensively studied in psychology
we try to address the first question by investigating some of      (Rapoport & Mowshowitz, 1966), classical game theory
the task features which could promote mentalizing during           (Bo, 2005), behavioral game theory (Camerer, 2003), and
game playing.                                                      neuroimaging studies (Singer et al., 2004). The payoff
                                                                   matrix used in our experiment is presented in table 1.
                       Previous work
   We have already started to explore the behavioral effects                    Table 1: Our experiment's payoff matrix
of mentalizing (Napoli & Fum, 2009) in playing a computer
version of Rock, Papers, and Scissors (henceforth: RPS).                                        Cooperate      Defect
   We had three groups of participants play 100 turns of                         Cooperate                60          100
RPS. In the first group, the computer was presented as an                                       60             0
opponent, and the game was explicitly described as RPS. In                       Defect                    0           20
the second group, the computer was presented as a neutral                                       100            20
device. Participants saw three geometric figures which they
should choose among at each trial; they received a payoff             PD can be thought of as a paradigmatic situation for any
after each choice, and they could see the payoffs they could       social dilemma in which the selfish interest contrasts with
have obtained by making the alternative choices. Thus, this        the common one. Classical game theory states that,
condition was equivalent to a multi-armed bandit task              independently of the choice made by the opponent, the most
(Sutton & Barto, 1998) with the indication of foregone             rational move for a player is to defect. In fact, if the
payoffs. In the third group, the computer was presented as         opponent chooses to cooperate, defection gets 100 points
an opponent. The game was played with the same rules of            and cooperation only 60 while, if the opponent defects,
RPS but the choices were represented by geometric figures          defection gets 20 points and cooperation 0. The result is that
and the hierarchy of the moves (what beats what) had to be         the optimal strategy for both people is to defect.
discovered during the game. This condition served as a                The most intriguing aspect of this game is that, even if
control for the effect of the knowledge of the payoff matrix.      the most rational move is defection, experiments show a
The algorithm which assigned the payoffs was the same in           substantial amount of cooperation between the players when
all groups; the conditions differed therefore only for the         the game is played in the iterated version (Bo, 2005).
setting induced in the participants (and the user interface).      Another finding is that players learn to cooperate more and
   We did not find any behavioral difference between the           more during the experiment (Rapoport & Mowshowitz,
conditions, and we were able to model the behavior of all          1966).
                                                               339

    In order to understand what makes people mentalize, we         choices. Thus, this system should be active in all conditions,
adopted a “subtractive behavioral method” by assigning             because of the repeated nature of the task.
people to four different conditions in a repeated PD                  It has been shown that the complex behavior detecting
decision-making task in which the points earned by the             system is active during game playing against both computer
participants were converted into play money.                       and human opponents (Gallagher, Jack, Roepstorff, & Frith,
     The conditions differed according to the task features        2002; Haruno & Kawato, 2009), and thus it should be
present in them which are summarized in Table 2.                   activated in all conditions except Nature.
                                                                      The shared intentions system is the main concern of this
     Table 2: Features present in the experimental conditions      article. This area is always activated during game playing
                                                                   against humans, but it has been shown to be activated also
                                         Conditions                during game playing against computer opponents, even if it
            Features               N    CB HB HPD                  is unclear which effect it exerts on people’s behavior. If we
  Repeated decision making         Y    Y     Y        Y           find any difference between the CB and HB conditions, we
  Opponent                         N    Y     Y        Y           can argue that mentalizing has a behavioral effect only in
  Believed Human Interaction       N    N     Y        Y           the case of a human opponent.
  Explicit social scenario         N    N     N        Y              Finally, the shared affects system has been shown to be
                                                                   active when game playing involves the possibility of pro-
   In the first condition, named “Nature” (N), participants        social behavior, reciprocity, or fairness, and therefore we
played the PD disguised as a binary decision task: in each         expect it could influence people's behavior only in the HPD
trial they had to choose between two options receiving a           condition. In this case the instructions promote empathizing
reward after each choice. It should be noted that in this          with the opponent both because of the explicit social
condition the PD is presented as a repeated decision making        scenario and because of the labels attributed to the choices,
one-person game, or a game against nature, in which no             which have a strong moral connotation. Therefore, every
opponent is involved.                                              difference between the HB and HPD conditions should be
   In the second condition, named “Computer Bet” (CB)              attributed to this system.
participants were told that they would play a game against
the computer. The instructions, however, presented the PD                  Method
as a betting task: in each trial, the participants and the         Participants and design. Sixty-four students (38 males)
computer should bet on one of two alternatives and,                enrolled at the University of Trieste, Italy, were recruited as
depending on the combination of their choices, they would          participants. Their age varied between 18 and 29 years
receive a given reward.                                            (M=21.2, SD=3.4). Participants played two PD rounds, each
   The third condition, named “Human Bet” (HB), was                one against a different algorithm (see below) whose order
similar to the previous one (CB) except for the fact that          was counterbalanced between rounds. The experiment
participants were made to believe that they would play             followed therefore a 4x2 mixed design with Setting as
against a human opponent while in fact they were engaged           between-subjects and Algorithm as within-subjects factors.
by the computer.
   In the fourth condition, named “Human Prisoner's                Materials. Two algorithms were used in the experiment.
Dilemma” (HPD), participants played PD against what they           The first one, Tit for Tat, cooperated in the first interaction
believed was a human opponent, just as in CB condition.            and then replicated the opponent's previous choice. The
There was, however, a substantial difference in the                second one, named Biased, made his moves by randomly
instructions provided for this condition and the two betting       sampling from a distribution of 60% Cooperate and 40%
ones: the game was introduced by a story which illustrated         Defect moves.
a classical PD scenario (see Procedure for more details) and
the two choices were labeled as “Cooperate” and “Defect”.          Procedure. The experimental sessions were held in groups
   In CB, HB and HPD conditions the instructions stressed          of 10-12 participants convened in a computer laboratory.
that the goal of the participants was to gain as much money        Each participant was randomly assigned to one of the four
as possible independently of the money gained by the               conditions taking care that participants assigned to the same
opponent, and that their opponent had the same objective.          condition were not sitting next to each other. Participants
   According to results of neuroimaging research discussed         were told that they would play different versions of the
in the Introduction, there are four cognitive processes which      same game and received the instruction according to the
may influence participants' behavior in this task: the reward-     condition to which they were assigned. Then, they were
based system, the complex behavior detecting system, the           engaged in two PD rounds lasting eight minutes each.
shared intentions system, and the shared affect system.               The interface was kept as similar as possible in the four
   It is known that the reward-based system plays a role           conditions. Participants made their choices by clicking on
both in individual learning tasks and in game playing (Lee,        one of two circles displayed in the upper part of the screen.
2005) by integrating the information received during the           After a random lag time, in the Nature condition participants
task in order to calculate the expected utility of different       received a feedback about the money gained in the trial,
                                                               340

while in the other conditions they received a feedback about        p < .001).
the opponent's choice, the money gained by themselves and              We then analyzed the factors manipulated in the
by the opponent. The length of a bar representing their             experiment. A mixed design ANOVA revealed a significant
running total was updated and they were allowed to make             effect of Setting and Algorithm (F(3,58)=10.1, p<.001 and
another choice. In all conditions the two circles were labeled      F(1,58)=93.14, p<.001 respectively), while the interaction
as “Yellow” and “Blue” except for the HPD condition, in             was not significant (p=.92). Table 3 reports Means and
which they were named as “Cooperate” and “Defect”.                  Standard Deviations of the participants' total Cooperate
   The main differences between the conditions relied in the        moves.
amount of information and the kind of instructions provided
to participants. In the N condition it was stated that they             Table 3: Means (and Standard Deviations) of Cooperate
would play a binary decision task. After the first round                        per Algorithm in the various Settings
participants were told that the computer would change the
rule according to which it assigned the money. In the other                                             Setting
three conditions participants had the payoff matrix in front          Algorithm         N          CB           HB      HPD
of them from the beginning of the game. In the CB                                    15.69        11.18        14.23   24.24
                                                                      Biased
condition instructions stated that they would play a betting                         (5.41)       (7.7)      (10.03)   (7.09)
game with the computer, and after the first round they were                           32.6          26          28.8   41.35
                                                                      TFT
told that the computer would change its strategy. In the HB                          (9.93)      (10.65)      (17.2)   (10.6)
and HPD condition participants were told they would play
the game with one of the other participants in the room, and           Algorithm and Setting seem to have an addictive effect in
that the opponent would change after the first round. In the        promoting cooperation between participants. While it is
HB condition the task was presented as a betting game               evident that the TFT algorithm promotes Cooperation more
while in the HPD condition the game was introduced                  than the Biased one, it is unclear how Settings exerted its
through a bargaining scenario in which Cooperate meant to           effect. Since there was no main effect of Round and no
respect the contract by delivering the promised goods and           interaction between Algorithm and Setting, we analyzed
valuable money, respectively, while Defect meant to give            separately the participant's performance against the two
the other player an empty bag. The instructions explicitly          algorithms.
underlined this aspects of moral obligation and contract               Two separate one-way ANOVAs for Biased and TFT
infringement involved in the game.                                  Algorithms were performed. Both showed a significant
   All groups played against the same algorithms with the           effect for Setting (F(3,58)=8.95, p<.001 and F(3,58)=4.94,
Yellow and Blue circles equated to Defect and Cooperate,            p<.01 respectively). The probabilities associated with post-
respectively.                                                       hoc Newman-Keuls tests to contrast each Setting condition
   At the end of the experiment we had informal interviews          with the others are summarized in tables 4 and 5. For both
with the participants to assess the possibility that they had       algorithms a significant difference was found between the
some doubts about having played against a computer and              HPD and the other three conditions which, on the other
not a mate. Subjects who reported doubts were discarded             hand, did not differ from each other.
from data analysis. Finally, a collective debriefing session
ensued in which the nature of the opponent was discovered               Table 4: Probabilities for Post-hoc Newman-Keuls tests
to all participants and the reasons for always adopting a                              for the Biased Algorithm
computer as opponent were explained.
                                                                                         N         CB           HB      HPD
         Results                                                           N                        .24           .6   .0029*
   Since the experiment was self-paced, participants made a                CB           .24                      .27    .002*
variable number of choices in each round. To perform                      HB             .6         .27                .0017*
statistic analyses, we took into account their first 50 moves             HPD        .0029*       .002*      .0017*
only.                                                                                          * = significant
Analysis of Cooperations. Being interested in the quality
of participant's behavior more than in their ability to exploit         Table 5: Probabilities for Post-hoc Newman-Keuls tests
the opponent's algorithm, we concentrated the analysis on                                for the TFT Algorithm
the number of Cooperate moves and not on the amount of
money gained.                                                                            N         CB           HB      HPD
   First, we looked for possible differences between the first             N                        .29          .39   .051**
and second round in order to control for effects of learning               CB           .29                      .52    .016*
(or fatigue). A mixed design ANOVA between the Round                      HB            .39         .52                .0049*
and the Setting did not reveal any significant effect for the             HPD        .051** .0049*             .016*
Round (p=.55) or interaction (p=.93), while there was a                         *= significant **=marginally significant
significant effect of the Setting (F(3,58)=10.1,
                                                                341

Analysis of conditional probabilities. We ran another             conditional probability analysis showed that this difference
analysis in order to understand why there was a difference        could be explained by the higher rate of C|DC in both cases.
in the number of Cooperate moves in HPD condition. This           Since the only difference between the HPD and the other
analysis was proposed by Rapoport and Mowshowitz (1966)           groups relied in the use, in the former case, of instructions
and was also utilized by Erev and Roth (2001) in order to         that explicitly underlined the aspects of moral obligation and
assess the efficacy of their reinforcement learning model.        contract infringement involved in the game, the most natural
   Rapoport and Mowshowitz analyzed the probability of            conclusion is that this feature made people more prone to
cooperation in a given trial according to the choices made        regret their defection against a cooperative opponent in the
in the previous trial by both players. Thus, a participant's      previous trial leading thus to more frequent cooperative
strategy can be described by four numbers, C|CC, C|CD, C|         behavior.
DC, and C|DD. In the N condition, these probabilities may            Interpreting the behavioral results in terms of the
be interpreted as an analysis of a “win stay / lose switch”       cognitive systems framework introduced above, we could
behavior. We can assume that, after a few choices, people         safely assume an influence on this task of the reward-based
get acquainted with the payoffs associated with the various       system, being the participants capable of successfully
options. Thus, for example, C|CC would be the probability         adapting their strategy to the opponent in all conditions.
of making the Cooperate/Blue move after receiving the best        However, we cannot exclude that such a performance could
reward associated with that choice; therefore, a high value       reflect the activation of the complex behavior prediction
of this parameter would be an expression of a “win stay”          system too, being the activation of this system not
strategy.                                                         selectively associated with strategic interactions (Frith &
   We analyzed the four conditional probabilities separately      Frith, 2003). As for the shared affect system, it could have
for the two algorithms to search for possible different           played a role in both human conditions (HB and HPD). In
strategies used in the different Settings. We ran a total of      fact, during the debriefing interviews, some HB participants
eight one-way ANOVAs analysis and all post-hoc Newman-            spontaneously told us about their willingness to cooperate
Keuls tests for the significant ones.                             with the opponent, a behavior that is typically associated
   We found a significant difference in three ANOVAs:             with the activation of this system (Singer et al., 2004).
C|DC both in the Biased (F(3,58)=7.94, p<.001) and in the         However it is unlikely that this system played a critical role
TFT condition (F(3,58)=5.21, p<.005) and C|CC in the TFT          in the HB group, whose performance was similar to that of
condition (F(3,54)=4.73, p<.006). Newman-Keuls post-hoc           the N and CB condition where it is not credible that people
tests showed that: in C|DC / Biased, HPD was different            could empathize with a computer, being it an opponent or
from all the other conditions (p<.001 in all cases), which        not. Therefore, this system could be active only in the HPD
were similar between them; in C|DC / TFT, HPD was                 condition.
different from CB and HB (p<.001 in both cases) and only             As for the ToM system, we can exclude that it influenced
marginally significant respect to N (p=.055), and the other       the participant's behavior in CB and HB groups, which was
three conditions were similar between them; in C|CC / TFT,        similar to that of the N group. Therefore, we are left with
the only significant difference was between HPD and CB            two systems (ToM and empathizing) as responsible for the
p<.001.                                                           difference found in the HPD condition. Because brain
                                                                  imaging studies show that playing against a human
              Discussion and conclusions                          opponent activates ToM areas regardless of the specific
   In the experiment, participants played against an              game (see for example Gallagher et al., 2002) and because,
algorithm, the Biased one, that chooses its moves by              according to the participant's reports, it seems likely that
sampling randomly from a given distribution, i.e.,                they did in fact mentalize, we think that this area was active
independently from the move made by the opponent, and             in both situations, and suggest two possible explanations for
against another algorithm, the TFT, that cooperates only if       our results: (1) ToM had no behavioral effect in HB
the opponent cooperated in the previous trial and defects         situation or (2) ToM had no effect both in the CB and HB
otherwise. This means that the most rewarding strategy for        conditions, and the difference between the two groups
participants was to Defect against the Biased algorithm—in        should be attributed to the shared affect system.
order to exploit the trials in which it cooperates and to            We won't take position with regard to this issue, because
defend against the possibility of being exploited when the        the limitations of our behavioral method don't permit us to.
algorithm defects—and to Cooperate against the TFT—in             However we think that, whichever is the real explanation,
order to initiate and maintain a virtuous reciprocation loop.     this study makes some interesting points about both brain
The statistical analyses demonstrated that participants made      imaging and behavioral game theory experiments.
more Cooperate moves against the TFT than against the                With regard to brain imaging studies, even if it has been
Biased algorithm, i.e., that they were successful in adapting     shown that ToM areas are active in almost every game
their strategy to the strategy used by the opponent.              played against human opponents, it is not clear when they
   However, we also found some differences between the            have a behavioral effect, too. We can speculate that there is
groups: in the HPD condition participants made a higher           some mechanism which prevents ToM from influencing the
number of Cooperate moves against both algorithms. The            behavior in some situations. Otherwise, it would seem really
                                                              342

strange that it wouldn't have any effect on behavior at all.         Neural correlates of mentalizing-related computations
Therefore, we think that brain imaging studies should                during strategic interactions in humans. Procedings of the
always take in account people's behavior, in a similar way to        National Academy of Sciences USA, 105, 6741 – 6746.
Haruno & Kawato (2009) and Hampton, Bossaerts, and                 Haruno, M., & Kawato, M. (2009). Activity in the Superior
O'Doherty (2008).                                                    Temporal Sulcus Highlights Learning Competence in an
   As for behavioral game theory, this paper makes a case            Interaction Game. The Journal of Neuroscience, 29,
for Erev and Roth's (2001) proposal of accounting people's           4542–4547.
behavior in Prisoner's Dilemma by the means of                     Hill, E. L., Sally, D. & Frith, U. (2004). Does mentalizing
Reinforcement Learning. In fact, in N condition participants         ability influence cooperative decision – making in a social
did not have any information about foregone payoffs, and             dilemma? Journal of Consciousness Studies, 11, 144 –
nonetheless, their behavior was similar to the other groups.         161.
This means that the knowledge of payoff matrix and of the          Krueger, F., Grafman, J., & McCabe, K. (2008). Neural
opponent's choices had a limited effect on participant's             correlates of economic game playing. Philosophical
behavior. On the other side, the paper shows also the                Transactions of the Royal Society, 363, 3859 – 3874.
importance of contextual information—a variable which is           Lee, D. (2005). Neural basis of quasi-rational decision-
seldom taken into account in game theory. In a more general          making. Current Opinion in Neurobiology, 16, 191–198.
sense, we think that our paper suggests the utility of having,     Napoli, A., & Fum, D. (2009). Applying Occam's razor to
along experiments in which people play one against the               paper (and rock and scissors, too): Why simpler models
other, some more controlled sessions in which the                    are sometimes better. Proceedings of the 9th
participants play against an opponent (be it a computer or a         International Conference of Cognitive Modeling,
human actor) whose strategy was under the control of the             Manchester, United Kingdom.
experimenter and compare them with individual learning             Rapoport, A., & Mowshowitz, A. (1966). Experimental
sessions. This could make the experimenter safely exclude            studies of stochastic models for the prisoner's dilemma.
in most cases unnecessary believes or sophisticated learning.        Behavioral Science, 11, 444–458.
                                                                   Rilling, J. K., Sanfey, A. G., Aronson, J. A., Nystrom, L. E.,
                        References                                   & Cohen, J. D. (2004). The neural correlates of theory of
Anderson, J. R. (2007). How can the human mind occur in              mind within interpersonal interactions. Neuroimage,
   the physical universe? New York: Oxford University                22,1694–1703.
   Press.                                                          Sally, D. (2003). Dressing the mind properly for the game.
Bo, P. (2005). Cooperation under the shadow of the future:           Philosophical Transactions of the Royal Society of
   experimental evidence from inﬁnitely repeated games.              London B, 358, 583 – 592.
   American Economic Review, 95, 1591–1604.                        Sanfey, A. G., Rilling, J. K., Aronson, J. A., Nystrom, L. E.,
Camerer, C. F. (2003). Behavioral game theory:                       & Cohen, J. D. 2003 The neural basis of economic
   Experiments on strategic interaction. Princeton:                  decision-making in the Ultimatum game. Science, 300,
   Princeton University Press.                                       1755–1758.
Camerer, C. F., Ho, T., & Chong, K. (2002). Sophisticated          Sarin, R. & Vahid, F. (2001). Predicting how people play
   Experience-Weighted Attraction learning and strategic             games: a simple dynamic model of choice. Games and
   teaching in repeated games. Journal of Economic Theory,           economic behavior, 34, 104–22.
   104, 137–8.                                                     Singer, T., Kiebel, S. J., Winston, J. S., Dolan, R. J. & Frith,
Cheung, Y., & Friedman, D. (1997). Individual learning in          C. D. (2004). Brain responses to the acquired moral status
   normal form games: some laboratory results. Games and           of faces. Neuron, 41, 653–662.
   Economic Behavior, 19, 46–76.                                   Sutton, R. S., & Bartho, A. G. (1998). Reinforcement
Erev, I. & Roth, A. (1998). Predicting how people play               learning: An introduction. Cambridge, MA: MIT Press.
   games: Reinforcement Learning in Experimental Games             Von Neumann, J., & Morgenstern, O. (1944) Theory of
   with Unique, Mixed Strategy Equilibria. The American             games and economic behaviour. Princeton, N.J.: Princeton
   Economic Review, 88, 848–881.                                    University Press.
Erev, I. & Roth, A.E. (2001). On simple reinforcement
   learning models and reciprocation in the prisoner
   dilemma game. In Gigerenzer, G. and Selten, R. (Eds.),
   The Adaptive Toolbox. Cambridge, MA: MIT Press.
Frith, U., & Frith, C. D. (2003). Development and
   neurophysiology      of     mentalizing.    Philosophical
   Transactions of the Royal Society, 358, 459–473.
Gallagher, H.L., Jack, A. I., Roepstorff, A., & Frith, C. D.
   (2002). Imaging the Intentional Stance in a Competitive
   Game. Neuroimage, 16, 814–821.
Hampton, A. N., Bossaerts, P., & O’Doherty, J. P. (2008).
                                                               343

