UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Motion Aftereffect from Literal and Metaphorical Motion Language: Individual Differences
Permalink
https://escholarship.org/uc/item/3wk172jv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Dils, Alexia Toskos
Boroditsky, Lera
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

           A Motion Aftereffect from Literal and Metaphorical Motion Language:
                                                    Individual Differences
                                          Alexia Toskos Dils (atoskos@stanford.edu)
                                              Lera Boroditsky (lera@stanford.edu)
                                            Stanford University, Department of Psychology
                               Jordan Hall, 450 Serra Mall, Building 420, Stanford, CA 94305 USA
                           Abstract                                   comprehension and that processing language affects
                                                                      performance in subsequent perceptual tasks (e.g., Bergen,
  Do people spontaneously form visual mental images when              Lindsay, Matlock, & Narayanan, 2007; Meteyard, Bahrami,
  understanding language, and if so how truly visual are these        & Vigliocco, 2007; Richardson, Spivey, Barsalou, &
  representations?     We test whether processing linguistic          McRae, 2003; Rinck & Bower, 2000; Rinck, Hähnel,
  descriptions of motion produces sufficiently vivid mental           Bower, & Glowalla, 1997; Spivey & Geng, 2001; Stanfield
  images to cause direction-selective motion adaptation in the        & Zwaan, 2001; Zwaan, Madden, Yaxley, & Aveyard,
  visual system (i.e., cause a motion aftereffect illusion). We
  tested for motion aftereffects (MAEs) following explicit            2004; Zwaan, Stanfield, & Yaxley, 2002;).
  motion imagery, and after processing literal or metaphorical           What mechanism might underlie these interactions
  motion language. Intentionally imagining motion produces an         between linguistic processing and perception?             The
  aftereffect in the overall sample with some participants            explanation frequently offered is that the representations
  showing a greater aftereffect than others. We then find that        generated during the course of language comprehension
  participants who show the strongest imagined motion                 share processing resources with perception, recruiting some
  aftereffects also show aftereffects in the natural course of
                                                                      of the very same brain regions (Barsalou, 1999). As
  processing motion language (without instructions to imagine).
  Individuals who do not show strong motion aftereffects as a         evidence for this possibility fMRI measures have revealed
  result of imagining motion also do not show them from               that classically ‘perceptual’ brain areas are recruited in
  processing motion language. However, the aftereffect from           service of language comprehension (e.g., Saygin,
  language gained strength as people were exposed to more and         McCullough, Alac, & Emmorey, 2010). While these
  more of a motion story. For the last two story installments         findings are consistent with the hypothesis, questions
  (out of 4), understanding motion language produced reliable         remain. The spatial resolution of current fMRI technology
  MAEs across the entire sample. The results demonstrate that
  processing language can spontaneously create sufficiently
                                                                      is coarse.       A typical voxel (the smallest unit of
  vivid mental images to produce direction-selective adaptation       measurement) may include 100,000 neurons. It is possible
  in the visual system. The timecourse of adaptation suggests         then that what appear in fMRI to be the same regions
  that individuals may differ in how efficiently they recruit         activated in linguistic and visual tasks are in fact
  visual mechanisms in the service of language understanding.         neighboring (or closely interleaved) but distinct neural
  Further, the results reveal an intriguing link between the          populations, potentially with quite different computational
  vividness of mental imagery and the nature of the processes
                                                                      properties.
  and representations involved in language understanding.
                                                                         One powerful paradigm for determining whether neural
  Keywords:       embodiment,       language      comprehension,      populations involved in particular tasks indeed overlap is
  perception, motion aftereffect, individual differences              that of adaptation. In this paper, we make use of one such
                                                                      adaptation measure, the motion aftereffect (MAE). The
                         Introduction                                 MAE arises when direction-selective neurons in the human
A good story can draw you in, conjure up a rich visual                MT+ complex lower their firing rate as a function of
world, give you goose-bumps, or even make you feel like               adapting to motion in their preferred direction. The net
you were really there. To what extent is hearing a story              difference in the firing rate of neurons selective for the
about something similar to really witnessing it? What is the          direction of the adapting stimulus relative to those selective
nature of the representations that arise in the course of             for the opposite direction of motion produces a motion
normal language processing? Do people spontaneously                   illusion. For example, after adapting to upward motion,
form visual mental images when understanding language,                people are more likely to see a stationary stimulus or a field
and if so how truly visual are these representations? In this         of randomly moving dots as moving downward, and vice
paper we make use of the motion aftereffect illusion to test          versa (e.g., Blake & Hiris, 1993). To quantify the size of the
whether processing linguistic descriptions of motion                  aftereffect, one can parametrically vary the degree of motion
produces sufficiently vivid mental images to cause                    coherence in the test display of moving dots (as in Blake &
direction-selective adaptation in the visual system (i.e.,            Hiris, 1993). The amount of coherence necessary to null the
cause a motion aftereffect).                                          MAE (i.e. to make people equally likely to report the
  A number of findings suggest that people do                         motion as upward or downward) provides a nice measure of
spontaneously engage in imagery during language                       the size of the aftereffect produced by the adapting stimulus.
                                                                  895

   Winawer, Huk, and Boroditsky (2008, 2010) adapted this          adapting stimulus. This allowed us to compare the effects
technique to test for MAEs after participants either viewed        of language for each participant with those of explicit
still images implying motion (e.g., a runner in mid-leap), or      imagery.
simply imagined motion without any visual stimulus. Both               Finally, the present study is designed to test whether
implied and purely imagined motion produced reliable               literal and metaphorical descriptions of motion recruit
MAEs. These studies support fMRI findings suggesting the           similar perceptual processes. To this end, we contrasted
hMT+ complex is recruited in the service of mental imagery         literal motion stories that described the motion of physical
(Goebel, Khorram-Sefat, Muckli, Hacker, & Singer, 1998;            objects with metaphorical motion stories that used motion
Grossman & Blake, 2001), and further suggest that this             verbs to talk about changes in abstract entities (e.g. rising
activation is driven by direction-selective neurons.               and falling stock prices).
   Here we explore whether natural language comprehension
can likewise produce MAEs. To the extent that people                                           Experiment
spontaneously engage in imagery in service of language             The experiment consisted of five parts: (1) a baseline task in
comprehension, understanding motion language should                which we measured participants’ motion direction
yield MAEs (albeit likely weaker than those produced               sensitivity, (2) a familiarization task in which participants
during explicit, effortful imagery). The present study was         viewed the stimuli to be imagined later in the study (3) the
designed to test this prediction. Participants listened to         main experimental task in which we tested for MAEs
stories describing motion in a particular direction and then       following imagining motion or listening to stories
judged the direction of a moving field of dots. The direction      describing motion, (4) a memory task in which we measured
in which motion language affects subsequent motion                 participants’ recognition memory for the stories, and (5) an
perception speaks to the mechanisms underlying language            exit questionnaire in which we ascertained participants
comprehension. One possibility is that motion language             knowledge of the motion aftereffect and their explicit
adapts the same direction-selective mechanisms that                predictions about the direction of effects.
subserve motion perception; this would cause people to see
a real visual stimulus (e.g., dynamic dots) as moving in a
direction opposite to that described in the adapting
language. Another possibility is that understanding motion
language recruits higher-level convergence areas that
process visual motion, resulting in a bias to see dot motion
in the same direction. Such a congruence effect is reported
by Sadaghiani et al (2009) who showed that hearing the
words ‘right’ and ‘left’ biased participants to see an
apparent motion stimulus as moving in the same direction.
fMRI data revealed that this audiovisual interaction was
driven more by activity in the anterior intraparietal sulcus
(IPS) than hMT+. A third possibility is of course that
motion language does not recruit visual motion processing
resources of any kind, resulting in no bias in dot motion
perception.
   Further, the direction and extent of transfer from language
to perception may depend on an individual’s visual motion                Figure 1: Schematic of experimental design highlighting
imagery ability. People differ from one another in mental            the block and trial structure of the main adaptation task. In
imagery ability, and these differences correlate with                 the imagery blocks, an upward or downward facing arrow
individual differences in spatial tasks and object perception        superimposed on a static image of the grating indicated the
(Kozhevnikov, Kosslyn, & Shephard, 2005). In Winawer et              direction in which to imagine the stripes moving. This cue
al (2010), most but not all participants showed MAEs as a               faded slowly over the course of a second. Once the cue
function of imagining motion, and the degree of adaptation         disappeared completely, a flickering fixation cross appeared
differed across people. We reasoned that people who show              at the center of the screen. Participants were instructed to
stronger adaptation as a result of imagining, should be more       fixate on the cross while imagining the stripes and to use the
likely to show adaptation as a result of understanding                   rate of the flicker to help them remember how fast the
motion language. It would be reasonable to expect that                 stripes should move. Participants were also instructed to
individuals who do not show an MAE as a result of                       use the fixation cross as a cue for when to start and stop
explicitly imagining motion should also not show one as a           imagining motion. In language blocks, participants listened
result of processing motion language. To test for this              to stories using headphones while fixating a dot centered on
possibility, we tested each participant both in an explicit          the monitor. Participants were told to listen carefully to the
visual imagery condition (as in Winawer et al (2010)), and              stories, as there would be a memory test. They were not
in conditions where linguistic motion was used as an                                       instructed to imagine.
                                                               896

Methods                                                                                       3. The squirrels continue to sprint downwards in a flash. They pour onto the wall and
                                                                                              surge directly toward the bottom.
Participants Sixty Stanford students participated in
                                                                                              4. Your eyes remain focused on the mob of squirrels teeming down the wall. You can
exchange for payment.                                                                         no longer pick out individuals as they dash for the bottom.
                                                                                              Metaphorical Motion: Upward Story (Four installments)
Stimuli and Procedure                                                                         1. You are standing in the middle of the trading floor at the New York stock exchange
Main Experimental Task: The task design, procedure, and                                       one busy morning. The room is buzzing with announcements of rising stock prices.
visual stimuli used were modeled on those used in Winawer                                     First JP Morgan rockets dramatically. Accenture and Delaware blaze to new heights.
                                                                                              Suddenly, Lincoln’s stock surges, along with Time Warner. You hear animated
et al (2010). On each trial participants judged the direction                                 reports of Toyota, Coca Cola, and The Gap going sky-high! You can hardly believe
of dot motion after either listening to stories describing                                    it, but Google’s stock soars higher than ever. Walmart zips skyward, too. All
                                                                                              morning, you marvel at the continually spiking stocks!
motion or engaging in explicit visual motion imagery.
Trials were presented in 12 interleaved blocks. There were                                    2. You hear that Ford and Exxon Mobile are really ramping up. Hewlett Packard is
                                                                                              erupting too!
6 block types, 3(motion type: imagined motion, literal
motion, or metaphorical motion) by 2(motion direction:                                        3. Next you hear that Nokia is boosting quickly.         Likewise, Sprint, AT&T and
upward or downward).                                                                          Verizon are surging dramatically.
    Adaptation Stimuli: In the literal motion condition the                                   4. Stock prices heighten rapidly for Proctor and Gamble as well as Clorox.
stories used motion language to describe the movement of                                      McDonalds’ stock also jets to new heights!
physical objects (e.g., squirrels, ping-pong balls). In the                                   Metaphorical Motion: Downward Story (Four installments)
metaphorical motion condition, the stories used motion                                        1. You are standing in the middle of the trading floor at the New York stock exchange
                                                                                              one busy morning. The room is buzzing with announcements of falling stock prices.
language to describe changes in abstract entities (e.g. stock                                 First JP Morgan plummets dramatically. Accenture and Delaware tumble to new
prices, emotions). 12 literal and 12 metaphorical stories                                     lows. Suddenly, Lincoln’s stock plunges, along with Time Warner. You hear
were used with an upward and a downward version for each,                                     agitated reports of Toyota, Coca Cola, and The Gap hitting record lows! You can
                                                                                              hardly believe it, but Google’s stock sinks lower than ever. Walmart zips downward,
yielding a total of 48 stories. Individual participants heard                                 too. All morning, you marvel at the continually diving stocks!
24 stories (either the upward or the downward version of
                                                                                              2. You hear that Ford and Exxon Mobil are really sinking down. Hewlett Packard is
each story, but not both). Example stories are in Table 1. In                                 taking a nose-dive too!
the imagery condition, participants were instructed to
                                                                                              3. Next you hear that Nokia is slumping quickly. Likewise, Sprint, AT&T and
imagine upward and downward moving gratings (as in                                            Verizon are tumbling dramatically.
Winawer et al. (2010)). The trial structure for the language
and imagery conditions is depicted in Figure 1.                                               4. Stock prices level rapidly for Proctor and Gamble as well as Clorox. McDonalds’
                                                                                              stock also plunges to new lows!
              Table 1: Sample stories heard by participants.
                                                                                                  Block structure: In the two language conditions, each
Literal Motion: Upward Story (Four installments)
1. You are running a psychology experiment in which you have trained hundreds of              block consisted of 3 stories with 4 installments each, for a
squirrels to race each other up a wall for a piece of food. Now you want to see what          total of 12 trials per block. Each story was broken up into
happens when they are all released at the foot of the wall at once. You watch through
a small window in the next room as the cages are opened and the squirrels leap onto           one longer paragraph and three shorter ‘top-up’ installments
the wall in a frenzy. The little fur balls scurry up the wall in one relentless stream,       so that multiple measurements could be collected for each
despite obvious defeat in the race. Zip! The brown creatures surge up the wall with
amazing agility. You see the same behavior in squirrel after squirrel – one swift jump
                                                                                              story. The longer installments lasted on average 40.00
onto the wall and an instantaneous burst upward. Zoom! The squirrels rush up the              seconds, and the top-up installments 8.29 seconds. The
wall like a giant current. As if in a trance, the squirrels swiftly stream past your eyes     imagery blocks mirrored this structure.                              Participants
in their race for the top of the wall.
                                                                                              imagined motion for 40 seconds, and on the three
2. Zoom! More and more squirrels jump onto the wall and scurry upwards. You                   subsequent ‘top-up’ trials, participants imagined motion for
watch them course up the wall in a blur.
                                                                                              8 seconds. This pattern was repeated 2 more times within
3. The squirrels continue to sprint upwards in a flash. They spout onto the wall and          the block to parallel the 3 stories used per block in the
surge directly toward the top.
                                                                                              language conditions.
4. Your eyes remain focused on the mob of squirrels teeming up the wall. You can no               Adaptation Test: Following each story or imagery
longer pick out individuals as they dash for the top.                                         installment, participants judged the direction of motion
Literal Motion: Downward Story (Four installments)                                            coherence in a field of moving dots without feedback. The
1. You are running a psychology experiment in which you have trained hundreds of              moving dot stimuli were presented as in Winawer et al.
squirrels to race each other down a wall for a piece of food. Now you want to see
what happens when they are all released at the top of the wall at once. You watch             (2010). Each dot display had net motion coherence either
through a small window in the next room as the cages are opened and the squirrels             up or down. For each subject, two coherence values were
descend onto the wall in a frenzy. The little fur balls scurry down the wall in one
relentless stream, despite obvious defeat in the race. Zip! The brown creatures surge
                                                                                              sampled: 12.5% and 25% of the coherence necessary for
down the wall with amazing agility. You see the same behavior in squirrel after               asymptotic performance (as assessed individually for
squirrel – one swift drop onto the wall and an instantaneous burst downward. Zoom!            participants in the baseline task). Coherence and direction of
The squirrels rush down the wall like a giant current. As if in a trance, the squirrels
swiftly stream past your eyes in their race for the bottom of the wall.                       motion were fully crossed and balanced across trials and
                                                                                              participants.
2. Zoom! More and more squirrels drop onto the wall and scurry downwards. You
watch them course down the wall in a blur.                                                        Exit questionnaire: At the end of the experiment we
                                                                                              ascertained participants’ familiarity with the motion
                                                                                              aftereffect and also asked them to generate a prediction
                                                                                          897

about which way they thought the effect would go.                      In the overall sample, participants showed a reliable MAE
Participants were asked: Have you ever heard of the Motion          after imagining motion (M = 5.7% normalized coherence,
Aftereffect or Waterfall Illusion? and After viewing upward         SD = 9.8%) (F(1,53) = 18.26, p < .001) (replicating
motion, which way would you expect a static image to                Winawer et al, 2010), but not after listening to motion
appear to move?                                                     stories (M = 0.8% normalized coherence, SD = 9.2%)
                                                                    (F(1,53) = 0.40, p > .5). The two conditions differed
Results                                                             reliably from one another (F(1,53) = 10.81, p < .005).
The distance between the null points of the logistic fits for          We reasoned that individuals who do not show MAEs as a
upward and downward motion (normalized coherence                    result of explicitly imagining motion should also not show
values at which participants are equally likely to report           them as a result of processing motion language. However,
upward and downward motion) was computed for both the               participants who do show MAEs from motion imagery may
imagined and linguistic motion conditions for each                  show them from processing motion language as well.
participant.     Positive values reflect adaptation.        Six     Indeed, there was a significant correlation between the
participants whose results exceeded three standard                  effects of motion imagery and motion language (r(52) = .34,
deviations from the mean for all participants were excluded         p < .02), such that stronger adaptation from imagining
from subsequent analyses. The literal and metaphorical              motion predicted stronger adaptation from understanding
linguistic motion conditions did not significantly differ from      motion language (Figure 3).
one another (t(53) = 0.219, p > .5), and so were combined
for analysis. Results are plotted in Figures 2-4.
            a
                     After upward adaptation
                     After downward adaptation
                                                                        Figure 3: Correlation across all participants between the
                                                                      separation in motion response functions for imagined and
                                                                                 linguistic motion, r(52) = .34, p < .02.
                                                                       To confirm that participants who showed adaptation to
            b
                                                                    imagined motion also showed it in response to linguistic
                                                                    motion, we sorted participants based on the magnitude and
                                                                    sign of the effect of explicit motion imagery and divided
                                                                    them into three groups of equal size (Imagery Mdns =
                                                                    15.1%, 3.8%, -1.7%, and SIQRs = 6.6%, 1.6%, 5.0%
                                                                    normalized coherence) (Figure 4). We will refer to these as
                                                                    strong, weak, and no MAE groups respectively.
                                                                       Indeed, the group that showed strong MAEs after
                                                                    explicitly imagining motion also showed reliable MAEs
                                                                    after listening to motion language (Language Mdn = 5.6%,
                                                                    SIQR = 4.7%) (n = 18, p < .031, sign-test, 2-tailed). There
                                                                    was no difference in the strength of this adaptation effect
      Figure 2: (a) Proportion of “UP” responses following          between the literal and metaphorical language conditions, n
       imagined motion and linguistic motion across all             = 18, p > .40. The two groups that showed weak or no
     participants. Error bars represent standard error. (b)         MAEs from imagery, did not show reliable MAEs from
  Separation in motion response functions for imagined and          language: (Mdn = -1.7%, SIQR = 5.0%) (n = 18, p > .05),
   linguistic motion across all participants. Positive values       and (Mdn = 0.8%, SIQR = 5.1%) (n = 18, p > .5) for groups
          reflect adaptation. Error bars denote s.e.m.              that showed weak or no MAEs respectively. The effects of
                                                                898

language in the strongest MAE group differed reliably from          aftereffect (the remaining 11 omitted this portion of the
the other two groups, χ2(1, N=54)=7.27, p<.01.                      study). Only three reported having heard of the motion
                                                                    aftereffect. Participants’ expectations about the direction in
                                                                    which adapting to visual motion in one direction might
                                                                    affect subsequent visual processing did not reliably bias
                                                                    (F(1,39) = 0.37, p>.50) or interact with (F(1,39) = 0.33,
                                                                    p>.50) the effects of imagined and linguistic motion. This
                                                                    finding confirms that the results obtained in this study are
                                                                    not a product of participants’ expectations or explicit biases
                                                                    regarding the direction of the effects.
   Figure 4: Participants were sorted based on the size of the
  aftereffect in the imagery condition and divided into three
  equal-sized groups. The plot shows the median separation
  between motion response functions for each group. Error
                       bars denote SIQR.
   To examine the timecourse of the MAE from imagined
and linguistic motion, we subtracted the proportion of “up”
responses following upward motion from those following
                                                                       Figure 5: Mean difference in proportion upward responses
downward motion across adaptation installments (e.g., the 4
                                                                       following upward and downward motion across the four
installments of a story, or the analogous 4 imagery
                                                                       motion installments. The data are plotted for the overall
installments). The mean difference by installment across all
                                                                      sample. Positive values reflect adaptation, and error bars
participants is plotted in Figure 5. In the explicit imagery
                                                                                             denote s.e.m.
trials, the MAE appears after the initial 40-second
installment of imagining (as would the MAE from real
visual motion), and participants remain adapted for                 Discussion
subsequent installments (there is no linear effect of                  We tested whether processing linguistic descriptions of
installment, F(1,53) = 0.076, p > .5). In the two language          motion produces sufficiently vivid mental images to cause
conditions, however, the MAE does not emerge until later            direction-selective motion adaptation in the visual system
installments (there is a reliable linear effect of installment,     (i.e., cause a motion aftereffect illusion). We predicted that
F(1,53) = 6.59, p < .05). After the 3rd and 4th story               the perceptual consequences of processing language should
installment, there is a reliable motion aftereffect including       depend on an individual’s mental imagery ability. Imagery
all participants, M=4.0%, SD = 12.7%; F(1,53) = 5.42, p <           ability was operationalized as the extent to which explicit
.05. Motion language appears to produce a reliable MAE              visual motion imagery produced an MAE in each
across the entire sample only after sufficient exposure to          participant. Put another way, imagery ability or vividness is
each story.                                                         the extent to which people recruit perceptual resources
   These findings raise the possibility that individual             heavily enough to adapt them during explicit imagery.
differences in the MAE from linguistic motion reflect                  We replicated previous work showing that intentionally
differences in how efficiently people recruit visual                imagining motion produces an aftereffect. We then found
direction-selective mechanisms rather than qualitative              that participants who show the imagined motion aftereffect
differences in which mechanisms are recruited. Indeed, the          most strongly also show this aftereffect in the natural course
linear effect of story installment does not differ among those      of processing motion language (without instructions to
who show strong, weak, and no MAEs from motion                      imagine). The same effects held for both literal and
imagery (F(2,51)=.144, p>.5), with everyone showing the             metaphorical language. Individuals who did not show a
same trend toward more adaptation as they get further into          motion aftereffect as a result of imagining motion also did
the story.                                                          not show an aftereffect from processing motion language
   Testing for effects of explicit bias: Of the 54 participants     overall. However, the aftereffect from language gained
included in the analysis, 43 completed an exit questionnaire        strength with the number of story installments. For the last
about their knowledge and predictions about the motion              two installments (out of 4), understanding motion language
                                                                899

produced reliable MAEs across the entire sample. This               Glenberg, A. M., & Kaschak, M.P. (2002). Grounding
finding suggests the possibility that individuals may differ          language in action. Psychonomic Bulletin & Review, 9,
in how efficiently they recruit visual mechanisms in service          558-565.
of language comprehension. Future work will examine the             Goebel, R., Khorram-Sefat, D., Muckli, L., Hacker, H., &
effects of systematically varying exposure to motion                  Singer, W. (1998). The constructive nature of vision:
language and the degree of story immersion on the MAE.                Direct evidence from functional magnetic resonance
Participants’ knowledge of the MAE and their explicit                 imaging studies of apparent motion and motion imagery.
predictions about the direction that the MAE should go did            European Journal of Neuroscience, 10(5), 1563–1573.
not predict their pattern of results. This helps us ensure that     Grossman, E. D., & Blake, R. (2001). Brain activity evoked
the patterns observed were not simply due to participants’            by inverted and imagined biological motion. Vision
explicit biases or expectations.                                      Research, 41(10–11), 1475–1482.
   A further question concerns the effects from metaphorical        Kozhevnikov, M., Kosslyn, S., & Shephard, J. (2005).
motion language. Some researchers have found that literal             Spatial versus object visualizers: A new characterization
and metaphorical language produce similar transfer effects            of visual cognitive style. Memory and Cognition, 33,
to perceptuo-motor tasks (e.g., Boulenger, Hauk, &                    710-726.
Pulvermüller, 2009; Glenberg & Kaschak, 2002; Richardson            Meteyard, L., Bahrami, B., & Vigliocco, G. (2007). Motion
et al., 2003), while others have found no evidence for                detection and motion verbs. Psychological Science, 18,
transfer from metaphorical language (Bergen et al., 2007).            1007-1013.
In our study, literal and metaphorical motion language              Richardson, D. C., Spivey, M. J., Barsalou, L. W., &
produced the same effects. Our stimuli and methods differ             McRae, K. (2003). Spatial representations activated
from previous studies in many ways. One potentially                   during real-time comprehension of verbs. Cognitive
important difference is that our stimuli were connected               Science, 27, 767–780.
narratives that built over time, whereas the studies just cited     Rinck, M., & Bower, G., H. (2000). Temporal and spatial
used isolated sentences. Our results suggest that for                 distance in situation models. Memory and Cogntion, 28,
language processing to produce effects on low-level visual            1310-1320.
processing, a greater amount of exposure to or immersion in         Rinck, M., Hähnel, A., Bower, G., & Glowalla, U. (1997).
a connected narrative may be necessary.                               Journal of Experimental Psychology: Learning, Memory,
   The results of the present study demonstrate that at least         and Cognition, 23, 622-637.
for a subset of the population, processing language                 Sadaghiani, S., Maier, J. X., & Noppeney, U. (2009).
spontaneously creates sufficiently vivid mental images to             Natural, metaphoric, and linguistic auditory direction
produce direction-selective adaptation in the visual system.          signals have distinct influences on visual motion
Future work will examine the source and possible cognitive            processing. Journal of Neuroscience, 29, 6490 – 6499.
consequences of the individual differences we observed.             Saygin, A.P., McCullough, S., Alac, M., Emmorey, K.
Why might some people be better able to recruit or                    (2009). Modulation of BOLD response in motion
effectively modulate the activity of sensory neurons through          sensitive lateral temporal cortex by real and fictive motion
top-down processes? Further, are there resulting systematic           sentences. Journal of Cognitive Neuroscience. Early
differences in the content and nature of representations              Access       publication     on     Nov.       19,     2009,
people form in the service of understanding language?                 doi:10.1162/jocn.2009.21388.
                                                                    Spivey, M., & Geng, J. (2001). Oculomotor mechanisms
                    Acknowledgments                                   activated by imagery and memory: Eye movements to
We thank Jonathan Winawer and members of Cognation for                absent objects. Psychological Research, 65, 235-241.
their helpful feedback. This research was supported by an           Stanfield, R., & Zwaan, R. (2001). The effect of implied
NSF Career Award Grant given to Lera Boroditsky.                      orientation derived from verbal context on picture
                                                                      recognition. Psychological Science, 12, 153-156.
                                                                    Winawer J, Huk A, Boroditsky L. (2008) A motion
                         References                                   aftereffect from viewing still photographs depicting
Barsalou, L. W. (1999). Perceptual symbol systems.                    motion. Psychological Science, 19, 276-283.
   Behavioral and Brain Sciences, 22, 577-660.                      Winawer J, Huk A, Boroditsky L. (2010). A motion
Bergen, B. K., Lindsay, S., Matlock, T., & Narayanan, S.              aftereffect from visual imagery of motion. Cognition,
   (2007). Spatial and linguistic aspects of visual imagery in        114, 276-284.
   sentence comprehension. Cognitive Science, 31, 733-764.          Zwaan, R. A., Madden, C. J., Yaxley, R. H., & Aveyard, M.
Blake, R., & Hiris, E. (1993). Another means for measuring            E. (2004). Moving words: dynamic representations in
   the motion aftereffect. Vision Research, 33, 1589-1592.            language comprehension. Cognitive Science, 28, 611-619.
Boulenger, V., Hauk, O., & Pulvermüller, F. (2009).                 Zwaan, R., Stanfield, R., & Yaxley, R. (2002). Language
   Grasping ideas with the motor system: semantic                     comprehenders mentally represent the shapes of objects.
   somatotopy in idiom comprehension. Cerebral Cortex,                Psychological Science, 13, 168-171.
   19, 1905-1914.
                                                                900

