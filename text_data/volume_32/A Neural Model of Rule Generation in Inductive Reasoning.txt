UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Neural Model of Rule Generation in Inductive Reasoning
Permalink
https://escholarship.org/uc/item/9x09p399
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)
Authors
Rasmussen, Daniel
Eliasmith, Chris
Publication Date
2010-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       A Neural Model of Rule Generation in Inductive Reasoning
                                            Daniel Rasmussen (drasmuss@uwaterloo.ca)
                                             Chris Eliasmith (celiasmith@uwaterloo.ca)
                                       Centre for Theoretical Neuroscience, University of Waterloo
                                                         Waterloo, ON, Canada, N2J 3G1
                               Abstract                                   have been no models of the inductive process of rule gener-
                                                                          ation. In this paper we present a method of rule generation,
    Inductive reasoning is a fundamental and complex aspect of
    human intelligence. In particular, how do subjects, given a           and implement it in a neural model using simulated spiking
    set of particular examples, generate general descriptions of the      neurons. This model can induce the rules necessary to solve
    rules governing that set? We present a biologically plausible         Raven’s matrices, and also displays many of the most inter-
    method of accomplishing this task, and implement it in a spik-
    ing neuron model. We demonstrate the success of this model            esting cognitive effects observed in humans: improved accu-
    by applying it to the problem domain of Raven’s Progressive           racy in rule generation over multiple trials, variable perfor-
    Matrices, a widely used tool in the field of intelligence testing.    mance in repeated trials, and both quantitative and qualitative
    The model is able to generate the rules necessary to correctly
    solve Raven’s items, as well as recreate many of the experi-          changes in individual performance.
    mental effects observed in human subjects.
    Keywords: inductive reasoning; neural engineering frame-
                                                                                                   Background
    work; fluid intelligence; Raven’s Progressive Matrices; vector        Raven’s Progressive Matrices
    symbolic architectures; cognitive modeling
                                                                          There are several variations of the RPM; the Standard and
                                                                          Coloured versions are generally used to test children or adults
                           Introduction                                   with cognitive deficits, while the Advanced is used to differ-
Inductive reasoning is the process of using a set of exam-                entiate average/above-average adults. In our work we focus
ples to infer a general rule which both describes the relation-           on the Advanced version.
ships shared by those examples and allows us to predict future               Figure 1 depicts an example of a simple Raven’s-style ma-
items in the set. For example, if a person were watching ob-              trix.1 The matrix is shown at the top with one blank cell,
jects in a river or lake and saw a stick, a wooden rowboat,               and the 8 possible candidates for that blank cell are along the
and a telephone pole float past, they might induce the rule               bottom. In order to solve this matrix the subject needs to gen-
that “wooden things float”. This rule both describes the rela-            erate three rules: 1) the number of instances of each shape in-
tionship which linked those items (being wooden) and allows               creases by one across the row, 2) the orientation of the shapes
the person to predict future items which would also float (a              within a cell is constant across the row, 3) each cell in a row
wooden bookcase). Given even more examples—some non-                      contains one shape type from the set {square, triangle, cir-
wooden floating objects—they might infer the general rule                 cle}. Subjects can then determine which elements belong in
that objects float when they displace a volume of water equal             the blank cell by applying the rules to the third row (i.e. there
to their weight.                                                          should be 2 + 1 = 3 shapes, they should be arranged in the
    This type of reasoning is fundamental to our ability to make          same orientation (vertically), and they should be triangles,
sense of the world, and represents a key facet of human intel-            since circle and square are already taken). Once they have
ligence. It determines our ability to be presented with a novel
                                                                              1 For copyright reasons we have created a modified matrix to
situation or problem and extract meaning from it. As such,
                                                                          present here, the model works with the true Raven’s matrices.
it is a process which has been made central to many tests of
general intelligence. One of the most widely used and well
respected tools in this field is the Raven’s Progressive Ma-
trices (RPM) test (Raven, 1962). In the RPM, subjects are
presented with a 3x3 matrix, in which each cell in the ma-
trix contains various geometrical figures with the exception of
the final cell which is blank (Figure 1). The subject’s task is
to determine which one of eight possible answers belongs in
the blank cell. They accomplish this by examining the other
rows and columns and inducing rules which govern the fea-
tures in those cells. They can then apply those rules to the last
row/column to determine which answer belongs in the blank
cell.
    Although there has been much experimental and theoret-
ical effort put into understanding the mental processes in-                           Figure 1: A simple Raven’s-style matrix
volved in performing RPM-like tasks, to our knowledge there
                                                                       61

generated their hypothesis as to what the blank cell should           jects will get previously correct answers wrong and vice versa
look like, they can check for a match among the 8 possible            (Bors & Vigneau, 2003). In the Results section we demon-
answers. Not all subjects will explicitly generate these exact        strate how each of these observations is accounted for by our
rules, and their route to the answer may be more roundabout,          model.
but they do need to extract equivalent information if they are
to correctly solve the problem.                                       Vector encoding
   Despite the test’s broad use, the only other computational         In order to represent a Raven’s matrix in neurons and work
model for the RPM is that of Carpenter et al. (1990). Their           on it computationally, we need to translate the visual infor-
model accurately recreates high-level human data, but does            mation into a symbolic form. Vector Symbolic Architectures
not reflect the flexibility and variability of individual human       (VSAs; Gayler, 2003) are one set of proposals for how to con-
performance nor take into account neurological data. In ad-           struct such representations. VSAs represent information as
dition, Carpenter et al.’s model has no ability to generate new       vectors, and implement mathematical operations to combine
rules; all the rules are pre-programmed. This limitation of           those vectors in meaningful ways.
their model reflects a general lack of explanation in the liter-         To implement a VSA it is essential to define a binding op-
ature as to how this inductive process is performed.                  eration (which ties two vectors together) and a superposition
                                                                      operation (which combines vectors into a set). We use circu-
   The two default assumptions regarding the origin of the
                                                                      lar convolution for binding, and vector addition for superpo-
rules are that people are either 1) born with, or 2) learn earlier
                                                                      sition (Plate, 2003). Circular convolution is defined as
in life, a library of rules. During the RPM, these pre-existing
rules are then applied to the current inductive problem. Hunt
                                                                                            C    = A⊗B
described this theory as early as 1973, and also pointed out
the necessary conclusion of this explanation: if RPM perfor-                            where
                                                                                                     n−1
mance is dependent on a library of known rules, then the RPM                                cj   =                                  (1)
is testing our crystallized intelligence (our ability to acquire
                                                                                                     ∑ ak b j−k mod n
                                                                                                     k=0
and use knowledge or experience) rather than fluid intelli-
gence (our novel problem solving ability). In other words, the        Along with this we employ the idea of a transformation vector
RPM would be a similar task to acquiring a large vocabulary           T between two vectors A and B, defined as
and using it to communicate well. However, this is in direct
contradiction to the experimental evidence, which shows the                                 A⊗T      = B
RPM strongly and consistently correlating with other mea-                                        or
sures of fluid intelligence (Marshalek et al., 1983), and psy-                                   T   = A0 ⊗ B                       (2)
chometric/neuroimaging practice, which uses the RPM as an
index of subjects’ fluid reasoning ability (Perfetti et al., 2009;    where A0 denotes the approximate inverse of A.
Prabhakaran et al., 1997; Gray et al., 2003). A large amount             With these elements we can create a vector representation
of work has been informed by the assumption that the RPM              of the information in any Raven’s matrix. For example, sup-
measures fluid intelligence, yet the problem raised by Hunt           pose we wanted to encode the information contained in the
has been largely ignored. Consequently, there is a need for a         third cell of Figure 1. The first step is to define a vocab-
better explanation of rule induction; by providing a technique        ulary, the elemental vectors which will be used as building
to dynamically generate rules, we remove the dependence on            blocks. These vectors are randomly generated, and the num-
a past library, and thereby resolve the problem.                      ber of vectors that can be held in a vocabulary and still be dis-
   In contrast to the paucity of theoretical results, there has       tinguishable as unique “words” is determined by the dimen-
been an abundance of experimental work on the RPM. This               sionality of those vectors (the more words in the vocabulary,
has brought to light a number of important aspects of hu-             the higher the dimension of the vectors needed to represent
man performance on the test that need to be accounted for             them).
by any potential model. First, there are a number of learning            Once the vocabulary has been generated it is possible to
effects: subjects improve with practice if given the RPM mul-         encode the structural information in the third cell. A sim-
tiple times (Bors & Vigneau, 2003), and also show learning            ple method to do this is by using a set of attribute ⊗ value
within the span of a single test (Verguts & De Boeck, 2002).          pairs: shape ⊗ circle + number ⊗ three + colour ⊗ black +
Second, there are both qualitative and quantitative differences       orientation ⊗ horizontal + shading ⊗ solid and so on, allow-
in individuals’ ability; they exhibit the expected variability in     ing us to encode arbitrary amounts of information. As de-
“processing power” (variously attributed to working memory,           scriptions become more detailed it is necessary to use more
attention, learning ability, or executive functions), but also        complex encoding; however, ultimately it does not matter to
consistent differences in high-level problem-solving strategy         the inductive system how the VSA descriptions are imple-
between low-scoring and high-scoring individuals (Vigneau             mented, as long as they encode the necessary information.
et al., 2006). Third, a given subject’s performance is far            Thus these descriptions can be made as simple or as complex
from deterministic; given the same test multiple times, sub-          as desired without impacting the underlying model.
                                                                   62

Figure 2: Recordings from the output population of the model, which expresses the similarity between the predicted answer
and each of the 8 possible choices. On the left is the spike raster, and on the right is the decoded information from those spikes.
The model correctly picks answer number one (the top line).
   VSAs have a number of other advantages: vectors are eas-           Gi is a function representing the nonlinear neuron
ier to represent in populations of neurons than complex vi-           characteristics—essentially, how will the neuron spike given
sual information, they are easier to manipulate mathemati-            the input described within the brackets. In our model we use
cally, and perhaps most importantly the logical operation of          Leaky Integrate and Fire neurons, but the advantage of this
the inductive system is not dependent on the details of the           formulation is that any neuron model can be substituted for
visual system. All that our neural model requires is that the         Gi without changing the overall framework. αi is a gain on
Raven’s matrices are represented in some structured vector            the input, determined by the characteristics of this particular
form; the visual processing which accomplishes this, though           neuron. Jibias is the background current, modelling the activ-
a very difficult and interesting problem in itself (see Meo et al.    ity in the network which is not a direct input to this neuron.
2007 for an example of the complexities involved), is beyond          φ̃i represents the neuron’s preferred stimulus, that is, which
the scope of the current model. This helps preserve the gen-          inputs will make it fire more strongly. Broadly speaking, the
erality of the inductive system: the techniques presented here        activity of neuron ai is a result of its unique response (de-
will apply to any problem that can be represented in VSAs,            termined by its preferred stimulus) to the input x(t), passed
not only problems sharing the visual structure of the RPM.            through a nonlinear neuron model in order to generate spikes.
                                                                          We can then define the decoding from spike train to vector
Neural encoding                                                       as
Having described a method to represent the high-level prob-
                                                                                          x̂(t) = ∑ h(t) ∗ ai (x(t))φi              (4)
lem in structured vectors, we now define how to represent                                         i
those vectors and carry out the VSA operations in networks of
simulated spiking neurons. There are several important rea-           where h(t) is a model of the post-synaptic current generated
sons to consider a neural model. First, by tying the model to         by one spike, ai (x(t)) are the spikes generated by Equation 3,
the biology we are better able to relate the results of the model     and φi are the optimal linear decoders. The optimal linear
to the experimental human data, both at the low level (eg.            decoders are calculated analytically so as to provide the best
fMRI or PET) and at the high level (eg. non-deterministic             linear representation of the original input x(t); they are essen-
performance and individual differences). Second, our goal is          tially a weight on the post-synaptic current generated by each
to model human inductive processes, so it is essential to de-         neuron (the result of summing the current generated by each
termine whether or not a proposed solution can be realized in         spike).
a neural implementation. Neuroscience has provided us with                We have defined how to transform a vector into neural ac-
an abundance of data from the neural level that we can use to         tivity and how to turn that neural activity back into a vector,
provide constraints on the system. This ensures that the end          but we also need to be able to carry out the VSA operations
result is indeed a model of the human inductive system, not a         (binding and superposition) on those representations. One
theoretical construct with infinite capacity or power.                of the primary advantages of the NEF is that we can calcu-
   We use the techniques of the Neural Engineering Frame-             late the synaptic weights for arbitrary transformations analyt-
work (Eliasmith & Anderson, 2003) to represent vectors and            ically, rather than learning them. If we want to calculate a
carry out the necessary mathematical operations in spiking            transformation of the form z = C1 x +C2 y (C1 and C2 are any
neurons. To encode a vector x(t) into the spike train of neu-         matrix), and x and y are represented in the a and b neural
ron ai we define                                                      populations (we can add or remove these terms as necessary
                               h                     i                to perform operations on different numbers of variables), re-
                 ai (x(t)) = Gi αi φ̃i x(t) + Jibias          (3)     spectively, then we describe the activity in the output popula-
                                                                   63

                 Input                                          Ti
    Ai         Inverse      Ai
               (n=1500)
                                    Circular                                    Cleanup             Solution                Solution
                                                           Integrator
                                 Convolution                (n=6000)
                                                                               Memory              Generator                Checker
                                   (n=11000)                                   (n=10000)            (n=11000)                (n=800)
    Bi           Input      Bi                 Ai  Bi                Ti+1                  T                 RPM3,2  T
               (n=1500)
Figure 3: Schematic diagram of the rule generation section with cleanup memory, displaying the approximate number of
neurons used in each submodule. The inputs (Ai and Bi ) represent two adjacent cells in the matrix. The “Input Inverse” module
calculates A0i , while “Input” simply leaves Bi unchanged. The “Circular Convolution” module calculates A0i ⊗Bi (the rule for that
particular pair of cells). “Integrator” is storing the calculated rule so far (based on previous pairs of adjacent cells), which we
combine with the current calculation. The output of “Integrator” is the overall rule, which we pass through a cleanup memory,
potentially giving us a less noisy version of that rule. Finally, “Solution Generator” generates a prediction of what should be in
the blank cell by convolving the second-last cell with our calculated rule, and then “Solution Checker” calculates the similarity
between that hypothesis and each of the eight possible answers given in the problem.
tion as                                                                  accomplish this by calculating
                                                                                                       1 n 0
                           "                                        #
   ck (C1 x +C2 y) = Gk     ∑ ωki ai (x) + ∑  ωk j b j (y) + Jkbias                              T=      ∑ Ai ⊗ Bi
                                                                                                       n i=0
                             i              j
                                                                            In order to perform this operation in neurons (where we
where ck , ai , and b j describe the activity of the kth, ith,
                                                                         cannnot instantly sum over a set of examples) we translate it
and jth neuron in their respective populations. The ω
                                                                         into the equivalent learning rule, where each pair of A and B
are our synaptic weights: ωki = αk hφ̃kC1 φxi im and ωk j =
           y                                                             vectors is presented sequentially:
αk hφ̃kC2 φ j im . Referring back to our descriptions of the vari-
ables in Equations 3 and 4, this means that the connection
                                                                                            Ti+1 = Ti − wi (Ti − A0i ⊗ Bi )
weight between neuron ai and ck is determined by the pre-
ferred stimulus of ck , multiplied by the desired transformation            We implement this by combining a neural integrator (to
and the decoders for ai . To calculate different transformations         maintain the overall value of T ) with a network which calcu-
all we need to do is modify the C matrices in the weight cal-            lates the Ti for the current pair of examples. We present the
culations, allowing us to carry out all the linear computations          examples in a top-down row-wise fashion, as that is the gen-
necessary in this model. For a more detailed description of              eral scanning strategy employed by humans as revealed by
this process, and a demonstration of implementing the nonlin-            eye-tracking studies (Carpenter et al., 1990; Vigneau et al.,
ear circular convolution (Equation 1), see Eliasmith (2005).             2006). Let us again take Figure 1 as an example, and exam-
                                                                         ine how the model induces one of the rules necessary to solve
                    The Model and Results                                the matrix: “number of objects increases by one”. A0 is the
Rule generation                                                          vector representation of one square, and B0 is the vector rep-
                                                                         resentation of two triangles (we will omit orientation in this
The key to our model is the idea of the transformation vector            example to keep things simple, but it is treated in exactly the
(Equation 2). Since we have our Raven’s matrix items en-                 same way). The network calculates T1 = A00 ⊗ B0 , which is
coded as vectors, we can represent rules as transformations              something like the rule “number of objects increases by one
on those vectors. For example, if A is the vector representa-            and squares become triangles”, and that value is stored in the
tion of one square, and B is the vector representation of two            neural integrator. In the next step A1 is two triangles and B1
squares, then the transformation vector T = A0 ⊗ B will be               is three circles, and T2 is “number of objects increases by one
analogous to the rule “number of squares increases by one”.              and triangles become circles”. However, when T2 is added to
However, we do not just want to calculate individual trans-              the neural integrator, “number of objects increases by one” is
formations, we want general rules for the whole matrix. To               reinforced (since it was already present) while the other in-
accomplish this we treat all adjacent pairs of cells as a set of         formation is not. This process continues with the next two
A and B vectors, and extract a general transformation from               rows. Thus we begin with a very noisy rule, but over time
that set of examples. Neumann (2001) has shown that we can               relations which are particular to individual A and B pairs are
                                                                      64

drowned out by the relation which all the pairs have in com-
mon: “number of objects increases by one”.2
   Once this process is complete we have the overall T vec-
tor, representing a general rule for the problem. Thus we have
accomplished our primary goal, to provide an explanation as
to how subjects can inductively generate descriptions of the
rules governing a set of examples. We use these rules by
applying them to the second-last cell of the Raven’s matrix
A ⊗ T giving us B, a vector representing what our rules tell us
should be in the blank cell. We then compare this hypothesis
to the eight possible answers and take the most similar (de-
termined by the dot product between the two vectors) as our
final answer (see Figures 2 and 3).
Cleanup memory
In addition to being able to generate the rules to solve a ma-
trix, the model should improve at this process given practice.        Figure 5: A demonstration of both low-level (vector dimen-
We accomplish this by adding a cleanup memory, a system               sion) and high-level (strategy) influences on accuracy (dis-
which stores certain values and, when given a noisy version           playing 95% confidence intervals).
of those values as input, outputs the clean version stored in
memory. A cleanup memory can be implemented in neu-
rons by creating a network which contains neural populations
tuned to respond only to certain inputs and output the clean
version of those values (Stewart et al., 2009). We implement          when and where to apply the rule generation system? When
a cleanup memory in this model by storing the past rules the          there are multiple rules to be found, how does the subject dif-
system has induced. The current rule generated by the net-            ferentiate them, and how do they decide they have found all
work, which will be perturbed by neural noise and the de-             the rules? How does the subject decide whether their hypoth-
tails of the particular Raven’s matrix, is passed through this        esis is good enough to settle on as a final answer? These are
cleanup memory, and if the cleanup memory contains a simi-            important questions, but they are dependent on the particular
lar rule then that clean version of the rule is output.               problem the subject is solving.
   The cleanup memory is improved over time by two mech-
anisms. First, if the cleanup memory receives an input that              We have implemented such a strategy system for the RPM
it does not recognize, it adds that input to its memory so that       (although not at the neural level) in order to collect aggre-
it will be recognized in the future. Second, if the cleanup           gate test results and explore individual differences. Figure 5
memory receives an input that it does recognize, it uses that         shows an example of these results, demonstrating the model’s
input to refine the value stored in memory, so that the stored        ability to recreate differences caused by both low-level neural
value becomes increasingly accurate. Thus as the system en-           processing power and high-level strategy. The low-level vari-
counters rules it has calculated before it will be able to draw       able is the dimensionality of the vectors, higher dimension
on its past efforts to provide a more accurate output. See Fig-       vectors requiring more neurons to represent. The high-level
ure 4 for a demonstration of how this improvement in cleanup          variable is how willing the model is to decide it has found a
memory can lead to improved inductive performance.                    correct rule: the lower line represents a subject who has less
   The cleanup memory not only helps account for observed             stringent standards, and is willing to accept rules that may not
learning effects, it also bridges the gap between this model of       be completely correct, whereas the top line represents a sub-
inductive rule generation and theories of a “library” of known        ject employing a more conservative strategy. These results
rules. In short, we are improving on current theories by ex-          demonstrate that both low and high level variables have a sig-
plaining where that past knowledge comes from, and why its            nificant impact on accuracy, and reflect the quantitative and
use is a dynamic, fluid process.                                      qualitative individual differences observed in human perfor-
                                                                      mance. Figure 5 also reveals that although the overall per-
Higher level processes                                                formance trends are clear, there is significant variability (av-
                                                                      erage σ = 0.13) in any given trial, another parallel of human
In addition to the inductive process of rule generation, there
                                                                      subjects. There are many such interesting avenues of explo-
are high-level problem solving effects (what we might call
                                                                      ration, however we will not go into the details of the strategy
the subject’s “strategy”) which will have a significant impact
                                                                      system here; the primary contribution of this research is the
on performance. For example, how does the subject decide
                                                                      general rule-induction system described above, which is not
    2 This same process will help eliminate the noise added at the    dependent on the higher level framework within which it is
neural level.                                                         used.
                                                                   65

Figure 4: An example of the model’s ability to learn over time. The model was presented with a series of matrices that appeared
different but required the same underlying rules to solve; as we can see, the model is able to more quickly and definitively pick
out the correct answer on later matrices.
                          Conclusion                                Gray, J., Chabris, C., & Braver, T. (2003). Neural mecha-
We have presented a novel, neurally-based model of induc-             nisms of general fluid intelligence. Nature Neuroscience,
tive rule generation, and we have applied this system to the          6, 316-322.
particular problem of Raven’s Progressive Matrices. The             Hunt, E. (1973). Quote the Raven? Nevermore! In L. Gregg
success of the system is demonstrated in its ability to cor-          (Ed.), Knowledge and cognition (p. 129-157). Potomac:
rectly find general rules that enable it to solve these matri-        Lawrence Erlbaum Associates.
ces, as well as in the model’s ability to recreate the interest-    Marshalek, B., Lohman, D., & Snow, R. (1983). The com-
ing effects observed in human subjects, such as learning over         plexity continuum in the radex and hierarchical models of
time, non-deterministic performance, and both quantitative            intelligence. Intelligence, 7, 107-127.
and qualitative variability of individual differences. These        Meo, M., Roberts, M., & Marucci, F. (2007). Element
results demonstrate the potential for gaining a deeper under-         salience as a predictor of item difficulty for Raven’s Pro-
standing of human induction by adopting a neurally plausible          gressive Matrices. Intelligence, 35, 359-368.
approach to modeling cognitive systems.
                                                                    Neumann, J. (2001). Holistic processing of hierarchical
                    Acknowledgments                                   structures in connectionist networks. Unpublished doctoral
                                                                      dissertation, University of Edinburgh.
This work was supported by the Natural Sciences and En-
gineering Research Council of Canada, CFI/OIT, Canada Re-           Perfetti, B., Saggino, A., Ferretti, A., Caulo, M., Romani, G.,
search Chairs, and the Ontario Ministry of Training, Colleges,        & Onofrj, M. (2009). Differential patterns of cortical acti-
and Universities.                                                     vation as a function of fluid reasoning complexity. Human
                                                                      Brain Mapping, 30, 497-510.
                          References                                Plate, T. (2003). Holographic reduced representations. Stan-
Bors, D., & Vigneau, F. (2003). The effect of practice on             ford: CLSI Publications.
   Raven’s Advanced Progressive Matrices. Learning and In-          Prabhakaran, V., Smith, J., Desmond, J., Glover, G., &
   dividual Differences, 13, 291-312.                                 Gabrieli, J. (1997). Neural substrates of fluid reason-
Carpenter, P., Just, M., & Shell, P. (1990). What one intelli-        ing: An fMRI study of neocortical activation during perfor-
   gence test measures: A theoretical account of the process-         mance of the Raven’s Progressive Matrices test. Cognitive
   ing in the Raven’s Progressive Matrices test. Psychological        Psychology, 33, 43-63.
   Review, 97, 404-431.                                             Raven, J. (1962). Advanced progressive matrices (sets I and
Eliasmith, C. (2005). Cognition with neurons: A large-scale,          II). London: Lewis.
   biologically realistic model of the Wason task. In B. Bara,      Stewart, T., Tang, Y., & Eliasmith, C. (2009). A biologically
   L. Barsalou, & M. Bucciarelli (Eds.), Proceedings of the           realistic cleanup memory: Autoassociation in spiking neu-
   27th annual conference of the Cognitive Science Society.           rons. In 9th International Conference on Cognitive Mod-
   Stresa: Cognitive Science Society.                                 elling.
Eliasmith, C., & Anderson, C. (2003). Neural engineering:           Verguts, T., & De Boeck, P. (2002). The induction of solu-
   Computation, representation, and dynamics in neurobio-             tion rules in Raven’s Progressive Matrices test. European
   logical systems. Cambridge: MIT Press.                             Journal of Cognitive Psychology, 14, 521-547.
Gayler, R. (2003). Vector Symbolic Architectures answer             Vigneau, F., Caissie, A., & Bors, D. (2006). Eye-movement
   Jackendoff’s challenges for cognitive neuroscience. In             analysis demonstrates strategic influences on intelligence.
   P. Slezak (Ed.), ICCS/ASCS international conference on             Intelligence, 34, 261-272.
   cognitive science (p. 133-138).
                                                                 66

