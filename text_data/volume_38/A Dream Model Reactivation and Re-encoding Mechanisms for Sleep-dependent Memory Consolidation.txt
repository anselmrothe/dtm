 A Dream Model: Reactivation and Re-encoding Mechanisms for Sleep-dependent
                                                    Memory Consolidation
                                        George Kachergis1 (george.kachergis@nyu.edu)
                                           Roy de Kleijn2 (kleijnrde@fsw.leidenuniv.nl)
                                        Bernhard Hommel2 (hommel@fsw.leidenuniv.nl)
                                          1 Psychology   Department, New York University, USA
               2 Institute of Psychology / Leiden Institute for Brain & Cognition, Leiden University, the Netherlands
                              Abstract                                 which of these are suggested by existing empirical evidence.
   We humans spend almost a third of our lives asleep, and             We will begin by considering the computational advantages
   there is mounting evidence that sleep not only maintains, but       and disadvantages of online (i.e., incremental; awake) learn-
   actually improves many of our cognitive functions. Mem-             ing versus offline (i.e., batch; asleep) learning, with intuitions
   ory consolidation–the process of crystallizing and integrating
   memories into knowledge and skills–is particularly benefitted       imported from the machine learning literature. By consid-
   by sleep. We survey the evidence that sleep aids memory con-        ering the often-competing computational needs of the mind
   solidation in various declarative and implicit tasks and review     (e.g., to quickly and accurately store new information, but
   the basic neurophysiological structure of sleep with a focus on
   understanding what neural systems are involved. Drawing on          also to integrate such episodes with existing knowledge), we
   machine learning research, we discuss why it might be useful        hope to better organize existing findings for rational analysis.
   for humans–and robots, perhaps–to have such an offline pe-          Thus, we then proceed to review the physiological character-
   riod for processing, even though humans are clearly capable of
   learning incrementally, online. Finally, we propose and simu-       istics of sleep, along with some of the diverse memory effects
   late two mechanisms for use in computational memory models          that have been found. Typical studies often have a similar
   to accomplish sleep-based consolidation via either or both 1)       design (but different task) to the first one that found a bene-
   re-encoding knowledge representations and 2) reactivating and
   strengthening recent memories.                                      fit for sleep: Jenkins and Dallenbach (1924) found improved
   Keywords: memory consolidation; sleep; dreaming; hip-               retention of nonsense syllables after a night of sleep as com-
   pocampal replay; memory model                                       pared to the same amount of time spent awake. However,
                           Introduction                                more recent studies have looked at shorter periods of sleep
                                                                       and also measured the time spent in different sleep stages,
Researchers have long been confused why people–and many
                                                                       which exhibit different types of neural activity. After syn-
other animals–spend around a third of their lives asleep. Why
                                                                       thesizing the empirical results, we offer the beginnings of a
has nature burdened us with needing to be in such a vul-
                                                                       computational approach to modeling memory consolidation.
nerable, unproductive state for so long? Hypotheses abound
                                                                       Despite the large amount of interest in developing computa-
about why we have evolved to sleep, ranging from it allows
                                                                       tional models of episodic memory (Hintzman, 1984; Shiffrin
us to conserve energy (during a night full of terrors, even),
                                                                       & Steyvers, 1997, e.g.) and semantic memory (Jones & Me-
to it simply being a necessary restorative for tired muscles
                                                                       whort, 2007, e.g.), these models do not yet incorporate sleep-
and minds (Siegel, 2013). Both of these example hypothe-
                                                                       based consolidation mechanisms. We offer several sugges-
ses are both reasonable and hard to refute (especially the for-
                                                                       tions for concrete changes to an existing model of episodic
mer). Evidence in favor of the latter has been mounting: in
                                                                       memory.
a wide variety of cognitive and motoric tasks, performance
drops when sleep patterns are interrupted.                                                Computational Issues
   Not only does sleep deprivation cause performance                   Machine learning algorithms can be classified as either
deficits, but there is now substantial empirical evidence              incremental–allowing data to be added to the model instance
that both declarative (i.e., facts and events–‘what’, ‘where’,         by instance–or batch, requiring a (sometimes large) set of
‘when’) and procedural (i.e., skills–‘how’) memory bene-               training instances before before the model produces useful
fit from even short periods of sleep. Memory is typically              predictions. Before we dive into a high-level discussion of
described as three processes: 1) encoding: forming new                 costs and benefits to these two approaches, let us consider a
traces from experience, 2) consolidation: integrating memo-            motivating example.
ries with prior knowledge and strengthening/crystallizing the
trace, and 3) retrieval: task-dependent extraction of overall          A Tale of Two Robots
familiarity or recall of particular traces. Sleep is generally         Imagine two cooking robots running two different versions
accepted to aid in consolidation, but under what particular            of the same underlying learning algorithm during a week of
circumstances it helps is not fully understood (Diekelmann,            daily training to become pizza chefs: Bob runs a batch ver-
Wilhelm, & Born, 2009, for a review), nor by which mecha-              sion, and Ingrid runs an incremental version. Each day, Bob
nisms it works.                                                        and Ingrid each watch 10 pizzas being made. Bob watches
   It is our goal to hypothesize several mechanisms by which           closely, recording every move for processing later that night,
sleep could serve to improve consolidation, and to evaluate            whereas Ingrid learns while watching–but is sometimes over-
                                                                   1601

whelmed by too many simultaneous things to pay attention               new document is read. It is more sensible to read a batch
to. On the other hand, even after seeing the first pizza made,         of documents–although, of course, this means that any new
Ingrid is able to make predictions about the next, and can             knowledge is not available in the model until the latest batch
evaluate and update her knowledge (and attention to observ-            is incorporated. Fortunately, an incremental SVD algorithm
ing particular steps) based on prediction failures. However,           has been proposed that not only is less computationally ex-
by storing all of the input over the day (and perhaps forever),        pensive, but also does not require storing the full word ×
Bob can often make a model that better approximates the real           document (Sarwar, Karypis, Konstan, & Riedl, 2002).
experience than what Ingrid’s incremental adjustments add up              Models that use batch updating require storing all of the
to. In fact, there may even be particular sequences of expe-           instances in long-term memory, allowing the model to iterate
rience that can lay a false foundation: for example, consider          over all episodes–even multiple times–to extract higher-level
if Ingrid’s first ‘pizza’ experience is a dessert pizza, or ‘pizza     features (e.g., correlations of multiple features). On the other
chicken’–not very stereotypical pizzas. For an incremental             hand, incremental updating can reduce the need to store so
learner who may hastily build a foundation from the first ex-          much information, much of which may be redundant or al-
perience, such a starting point may cause difficulties for fo-         ready over-learned. We conclude that sleep might be a way
cusing on and updating the correct features over the next few          to get the best of both worlds: incremental learning based on
recipes experienced. In contrast, Bob’s batch algorithm has            salient features for immediate use, in addition to storage of
the advantage of being able to downweight outliers at the end          daily episodes–especially exciting or confusing memories–
of the day before building his model. Bob’s batch and In-              that can be replayed during sleep to make more thorough,
grid’s incremental algorithms each have their advantages and           careful updates to knowledge representations before further
disadvantages, and some generalizations are made below.                compressing the memories.
Storage versus Processing                                                                     Effects of Sleep
Incremental or online algorithms (e.g., naı̈ve Bayes) clearly          After a brief summary of the neurophysiological characteris-
offer the advantage of being able to work (however poorly)             tics of sleep, we survey sleep effects found in various declar-
with very little data, and can learn immediately when new              ative and implicit memory tasks.
data are acquired. Moreover, since instances are processed
immediately, they do not need to be stored for later updat-            Structure of Sleep
ing. One disadvantage is that online updating may require              Sleep in mammals and birds consists of cycles of four stages,
significant computational resources, perhaps at an inconve-            proceeding from non-rapid eye movement (NREM) stages 1,
nient time. In contrast, batch (i.e., offline; e.g., support vec-      2, and 3 (also called slow-wave sleep), to rapid eye move-
tor machines, decision trees) learning algorithms may need             ment (REM) sleep. Human adults typically go through four
a large store of data and quite some time to build an initial          or five cycles each night, reaching REM sleep every 90 min-
useful model, and adding a single training instance may re-            utes or so. More slow-wave sleep (SWS; NREM3) occurs
quire iterating over the entire (and increasing) data store to         early in the night, whereas more REM sleep occurs in the last
update the model. A survey of learning algorithms will re-             few hours of a night’s sleep. Each stage is characterized by
veal the classic algorithmic tradeoff: one can store more, and         particular muscle behaviors and brain activity (Schulz, 2008).
process less upfront (but retrieval can be costly), or process            NREM1, between wakefulness and sleep, is recognized by
more upfront and store less.                                           somewhat active muscles (e.g., fluttering eyelids and rolling
   Another problem with many incremental algorithms is the             eyes) and alpha waves (7.5-12.5 Hz)–as in an awake state–
potential to arrive at different learning outcomes based on the        transitioning to a theta rhythm (6-10 Hz).
order the instances are encountered in. In many cases, such               NREM2 exhibits lower muscle activity and no awareness
order effects are undesirable, but on the other hand humans            of surroundings, as well as a theta rhythm (6-10 Hz), with
and animals show a variety of order effects (e.g., in associa-         periodic sleep spindles (11-16 Hz) and K-complexes. It is
tive learning: Kachergis (2012). Could sleep be a chance               thought that sleep spindles reflect the brain inhibiting pro-
to mitigate the order effects brought on during online learn-          cessing, thereby keeping the sleeper asleep, and occur as a
ing? A few batch-update models have been found to have                 result of information flow between thalamic and cortical ar-
roughly-equivalent incremental versions. For example, latent           eas. Sleep spindles often occur together with K-complexes,
semantic analysis (Deerwester, Dumais, Furnas, Landauer, &             which are basically delta waves lasting around one second.
Harshman, 1990, LSA) learns semantic similarities of words             Their function is thought to be stimulus suppression as well
via the singular value decomposition (SVD)–an expensive                as memory consolidation support.
matrix operation–of a large word × document co-occurrence                 Sleepers in SWS (NREM3) show very little reactivity to
matrix. This large matrix–adults know over 70,000 unique               environmental stimuli, and predominantly delta wave activ-
words, and have read thousands of documents–must be kept               ity (< 3.5 Hz, high amplitude). SWS (i.e. deep sleep) is
in memory to be updated when a new document is read. Up-               also when parasomnias such as sleepwalking and night ter-
dating the model requires performing the SVD again, so it              rors occur. This is the hardest part of sleep to wake up from,
would be quite expensive to update knowledge every time a              and sleep interruption during this stage often lead to feeling
                                                                   1602

groggy and sleepy. There is evidence to suggest that this is an      in the REM stage compared to adults, muscle twitching dur-
essential stage of sleep: after sleep deprivation, the amount of     ing REM sleep may be a way for the body to build (especially
SWS increases drastically.                                           in infants) and reinforce (in adults) specific neural pathways
   Additionally, REM sleep is characterized by rapid, random         from brain to muscles that are frequently used. This mecha-
eye movements as well as most memorable dreaming. At the             nism may simply be a low-level version of a similar mecha-
same time, muscle ationa prevents dreamers from acting out           nism known as motor babbling, which allows infants to build
their dreams. Similar to SWS, deprivation of REM sleep in-           higher-level action-effect associations.
creases the amount of REM sleep in a recovery period, indi-             Although most sleep-based consolidation studies have used
cating that REM is crucial for normal functioning. From neu-         implicit memory tasks, several have been done with declara-
ral recordings of rats, it appears that memory replay during         tive memory tasks.
non-REM sleep occurs at a 10x speedup, whereas REM re-
play is roughly at the speed of the behavioral episode (Bendor       Declarative Memory
& Wilson, 2012). During non-REM sleep, replay happens                The type of memory most people are familiar with is declar-
during short periods of increased activity in cortex and hip-        ative or explicit memory. This type of memory provides us
pocampus related to cortical ‘up-states’ (i.e., frames). Both        with knowledge of facts, such as Athens being the capital of
cortex and hippocampus replay similar content, but replay is         Greece (semantic knowledge), as well as knowledge of per-
initiated in the hippocampus, whereas cortical frames start          sonal events, like what you had for dinner last night (episodic
roughly 50ms before hippocampal frame, leading researchers           knowledge).
to conclude that the replay of sequential event memories may            Declarative memory is thought to be largely dependent on
be driven by hippocampus, though the memories may be se-             the hippocampus. Evidence supporting this theory consist of
lected by cortex (Lee & Wilson, 2002).                               patient studies as well as various lesion studies in rats. One
   One of the neurotransmitters that is often studied in rela-       famous case includes memory disorder patient H.M., who
tion to memory (especially Alzheimer’s disease) and sleep            was unable to form episodic memories after surgery remov-
is acetylcholine (ACh). ACh levels are lower during sleep            ing a large part of his hippocampus. In rats, Eichenbaum
than during awake, except during REM sleep when it reaches           (1990) showed that rats with hippocampal system lesions are
higher than awake levels. Hasselmo (1999) postulates that            severely impaired in the flexible use of previously learned
ACh inhibits feedback loops within the hippocampus and               information–normally attributed to episodic memory.
from it to the neocortex). This means that high ACh lev-                But what is exactly the mechanism by which the hippocam-
els during waking hours (and REM) supports encoding new              pus performs this task? The prevailing hypothesis is that
declarative memories, whereas low ACh during SWS allows              the hippocampus enables the consolidation of memory–i.e.,
replay of hippocampal memories, which are then stored more           converting an initial memory trace to a stable representation.
permanently in the neocortex.                                        Sleep is thought to play an important role in memory con-
                                                                     solidation, for both declarative and implicit memory. During
Implicit Memory                                                      SWS, the episodic information that is stored in the hippocam-
Implicit or non-declarative memories are memories we do not          pus is replayed and projected to brain regions in the neocor-
have conscious access to, such as motor skills and procedural        tex, which stores stable, permanent memories. The direction
and perceptual memory. A positive influence of sleep on a            of this information flow reverses during the REM sleep that
finger tapping task has been demonstrated by Walker, Brake-          occurs later in time. It has been proposed that this allows the
field, Morgan, Hobson, and Stickgold (2002), which found             hippocampus to remove the unstable, short-term memories
that subjects performed 20% better after a night of sleep            in order to make room for new memories to be stored there
compared to subjects spending an equivalent amount of time           (Wamsley & Stickgold, 2011).
awake. Furthermore, a correlation was found between the                 Indeed, there are many studies showing that sleep improves
amount of stage 2 NREM sleep and performance improve-                declarative memory using several paradigms. Retention of
ment. The spindles that are characteristic of stage 2 sleep          nonsense syllables has been shown to improve with sleep
are thought to trigger specific intracellular mechanisms re-         since (Jenkins & Dallenbach, 1924), and more recent research
quired for neural plasticity (Walker & Stickgold, 2006). More        has shown improvement on a paired associates word list after
evidence for this specific influence of stage 2 NREM sleep           SWS-rich sleep (Gais & Born, 2004).
comes from selective sleep deprivation studies. Smith and               In fact, it seems that not only sleep, but dreaming specif-
MacNeill (1994) found worse retention of a visuomotor adap-          ically can have beneficial effects on declarative memory.
tation task after stage 2 NREM sleep deprivation compared to         Wamsley, Tucker, Payne, Benavides, and Stickgold (2010)
REM sleep deprivation.                                               showed that after training on a virtual navigation task, im-
   Similar spindles are visible in the somatosensory cortex          proved performance at retest was correlated with relevant
of newborn rats and humans following spontaneous twitches            dream imagery during an afternoon nap. Similar thoughts
during REM sleep, suggesting that learning is taking place           during wakefulness, however, were not correlated with im-
in the brain following these movements (Khazipov et al.,             proved performance. It seems that reactivation of recently
2004). As infants spend relatively more of their sleep time          formed memories facilitates memory consolidation, with
                                                                 1603

dream imagery reflecting this process. Although recall              (Mednick & Alaynick, 2010). Procedural memory is just
shows more consistent sleep-related benefits than recogni-          generally thought to be ‘enhanced’ by sleep, but this idea is
tion, declarative memory often shows benefits even after only       not universally accepted (Mednick & Alaynick, 2010). An
one to two hours of sleep (Diekelmann et al., 2009). Con-           early neural model found that offline replay helped main-
solidation of declarative memories has been found to depend         tain declarative memories using hippocampal-neocortical in-
more on early hours of sleep, perhaps due to the dominance          terplay (Kali & Dayan, 2004). We will focus on proposing
of SWS, and nondeclarative memory was more aided by the             specific computational mechanisms for improving declarative
late, REM-dominated hours of sleep (Plihal & Born, 1999).           memory, since the current models are more readily adapted to
Lee and Wilson (2002) ran rats repeatedly through a sequence        this task, and the empirical evidence indicating the necessity
of spatial receptive fields of hippocampal CA1 place cells,         for this is strong.
and during slow wave sleep (SWS) later ran through the same                                        Model
order of activation at a 20-fold temporal compression of the
                                                                    Here we will propose and test two mechanisms of sleep-
behavioral sequence, showing that the hippocampus is impor-
                                                                    based consolidation that can be added to modern computa-
tant for spatial learning–and likely the formation of long-term
                                                                    tional models of episodic memory. Our modifications will
temporally-extended episodic memories in humans.
                                                                    be specified in terms of the REM1 (Retrieving Effectively
   In general, SWS seems to aid declarative memory whereas          from Memory) model Shiffrin and Steyvers (1997), which
REM enhances procedural and emotional memory in many                is a multitrace memory model that makes optimal recogni-
cases (Mednick & Alaynick, 2010). However, in a study us-           tion decisions assuming that memory is subject to noise. In
ing a sequence learning task (the serial response time task),       multitrace memory models, a memory trace is represented
in which subjects were either explicitly told to learn a (re-       by a large vector of feature values representing the context
peating) sequence of button presses or learned it implic-           and content of the event. Some features may be abstract
itly, the subjects learning explicitly improved only in the         and learned, whereas others are assumed to be simple and
sleep condition, and to an extent that was correlated with the      sensory-based (i.e., primitive). REM has both episodic traces
amount of NREM sleep (Robertson, Pascual-Leone, & Press,            as well as lexical-semantic traces, the latter of which are de-
2004). More intriguing was the fact that implicit learners all      contextualized accumulations of the various episodic traces,
improved–regardless of sleep–over a twelve hour period, but         updated across a lifetime. In REM, individual traces are as-
not after only 15 minutes. Thus, it may be that for proce-          signed random feature values, each drawn from a geometric
dural memories, intentionally encoded memories are consol-          distribution with parameter g. That is, the probability that a
idated during sleep, whereas implicit memory consolidation          feature has value v is
may simply require time.
           Theories of Sleep and Dreaming                                                    P(v) = g(1 − g)v−1                  (1)
An early attempt to explain why we dream was the activation-        The geometric distribution makes small feature values more
synthesis hypothesis (Hobson & McCarley, 1977), which               probable (and thus frequent) than large values. REM uses
posits that dreams come from the cortex trying to make sense        these varying base rates in calculating evidence for a mem-
of the random noise produced in the brainstem during REM            ory match: matching a low (common) feature value is not as
sleep. We now know that dreaming also occurs during non-            strong evidence as matching a high value. Conscious experi-
REM sleep, and even in deep, ‘slow-wave’ sleep.                     ence activates the lexical-semantic (LS) trace for the attended
   Walker, Stickgold, Alsop, Gaab, and Schlaug (2005) pro-          stimuli and updates it with the current context features. An
poses that there is a two-phase process by which memo-              episodic memory trace is formed by copying context and LS
ries are consolidated during sleep. The hippocampus, which          features with probability u per time unit t. When a feature
stores recent episodic memories replays events during slow-         is stored, it is only copied correctly with probability c; oth-
wave sleep for the neocortex, where long-term memories re-          erwise, a random value is drawn according to Equation 1.
side. The communication between the two brain areas at this         Missing features have a value of 0 (uninformative). Our first
time is one way, from the hippocampus to the neocortex. Dur-        proposed modification is to update lexical-semantic (LS) fea-
ing the REM dreaming that follows, though, the flow of in-          tures (i.e., neocortical representations) during a sleep period,
formation flips, from the neocortex back to the hippocampus.        when episodic traces since the last sleep period are (randomly,
Stickgold suggested that once the neocortex connects the new        although it may be more accurate to prioritize surprising or
memories to others in storage, it sends a message back to the       emotionally-charged traces) reactivated. The detailed lexical
hippocampus to erase them.                                          re-encoding mechanism is described in detail below. Updat-
   For declarative memory, there are two basic theories of          ing LS features during sleep leaves the hippocampal episodic
how memory consolidation is improved during sleep: the ac-          traces available for retrieval and recognition throughout the
tive hypothesis states that consolidation depends on sleep,         day. REM assumes that when the same stimuli appear multi-
whereas the permissive hypothesis views consolidation as a          ple times in similar contexts, the old trace may be updated by
time-dependent, interference-sensitive process that uses peri-
ods of low hippocampus input to process prior information               1 In this section, REM refers only to the model.
                                                                1604

filling in missing features from LS traces, instead of making             f = 6) are randomly chosen, and those feature values are in-
a new trace (this differentiation process is how it accounts for         cremented by 1, thus making those features more diagnos-
the word frequency mirror effect and null list strength effect).         tic, and the item easier to remember in the future. How-
    Retrieval in REM uses context features–reinstated by the             ever, now that the LS (i.e., neocortical) representation has
probe, whatever its source (internal or external)–to activate a          changed, memories that were encoded with the old represen-
subset of long-term memory (e.g., to the studied list of items).         tation will be more difficult to retrieve. This can be largely
This is in part done for simplicity of simulation–so that a              remedied by probing memory for copies of the old represen-
number of extra-experimental parameters and processes need               tation while re-encoding, and updating those items in mem-
not be assumed, but is also a reasonable thing to expect from            ory, as well: simply increment whatever is stored for those
memory. For recognition, REM computes a likelihood ra-                    f features. Figure 1 shows the mean d 0 (z(H) − z(FA)) of
tio indicating how well test cue j (from the LS traces) match            50 simulated subjects after studying 100 items one, three, or
each episodic trace i in the activated subset being considered.          five times, using REM alone or either of the proposed con-
This likelihood ratio, in which gsys is the base rate in the long-       solidation mechanisms, both of which aid memory. Note that
term, nq and nm are the number of non-zero mismatching and               these two methods are complementary, and could be used to-
matching features, respectively, is defined                              gether with greater effect. The effect of reactivation lessens
                                                                         with more item repetitions, while the re-encoding effect can
                          h c + (1 − c)g                 v−1 inm
                                        sys · (1 − gsys )
                     ∞
                                                                         be quite strong, regardless of repetitions.
  λi, j = (1 − c)nq ∏                                              (2)
                    v=1          gsys (1 − gsys )v−1
                                                                                                         1.50
Thus, the decision depends on not only the number of match-
                                                                                 Mean Sensitivity (d')
ing features, but also on how diagnostic the features are: large
values are more rare in the geometric distribution, and are                                              1.25                 ●
                                                                                                                                        Consolidation
thus more informative. Therefore, prior knowledge about the                                                            ●
                                                                                                                                         ●   none
base rate of different values (gsys ) may affect recognition.                                                                                reactivate
                                                                                                         1.00
REM decides that cue j was presented on the list if the av-                                                                                  reencode
erage of the likelihood ratios is above a criterion; else it is re-
jected. Since small feature values will tend to be quite com-                                            0.75
mon and thus undiagnostic, whereas the more useful large
                                                                                                                ●
feature values are rarely encountered, a potential mechanism
for improving memory would be to redistribute feature val-                                                      1      3      5
ues. By choosing one or more unique, diagnostic features for                                               Study Repetitions per Item
each trace (or set of highly-related traces), memory will be
improved. Although an exhaustive cross-check to make sure                Figure 1: Mean d 0 for REM simulations using no consolida-
features are unique would be quite computationally expensive             tion, or one of reactivation- or re-encoding-based consolida-
(which is why it should be offline), but a simple, greedy ver-           tion after studying 100 items 1, 3, or 5 times. Error bars show
sion might work well, with high probability. We now describe             +/-1SE for 50 simulated subjects.
and test two consolidation methods that we have hinted at.
                                                                            Variations of these two methods are quite plausible for
                           Simulation                                    modeling sleep-based consolidation in current memory mod-
                                                                         els. However, at least one important aspect is clearly missing:
Using REM as the basis for storing and retrieving memories,
                                                                         structured sequences of events must be linked in some way,
we define and test two sleep-based consolidation mechanisms
                                                                         but are not in the REM framework (what defines an ‘event’
in a simulation of studying 100 items 1, 3, or 5 times2 . The
                                                                         is not yet known). Future models should address how event
reactivation method simply reactivates n (here, n = 50) ran-
                                                                         boundaries are marked. It may be possible–and would be de-
dom memory traces from the day, and then for each of these
                                                                         sirable, for compression–to identify routine sequences (e.g.,
memories m finds the best matching LS trace t and copies in
                                                                         eating your typical breakfast, or driving home from work via
missing (0-valued) features from t to m. In essence, the reac-
                                                                         your usual route) and to replace the specific feature values in
tivation mechanism assumes that people dream about recent
                                                                         traces containing these sequences with placeholders pointing
memories and fill in missing details in the traces using back-
                                                                         to the appropriate LS representation, thus simplifying future
ground knowledge. Although these traces are strengthened,
                                                                         updating. Modeling procedural sleep-consolidation effects
the underlying knowledge representations (the LS traces) re-
                                                                         may require distributed neural models such as Kachergis, Wy-
main static. In contrast, the re-encoding method randomly
                                                                         att, O’Reilly, Kleijn, and Hommel (2014).
selects r LS traces (here, r = 50) for re-encoding, with proba-
bility proportional to their familiarity in recent memory (here,                                                     Discussion
the day). For each of these r LS traces, f features (here,               We have proposed two computational mechanisms that could
                                                                         beneficially operate on memories during sleep, along with
   2 https://github.com/kachergis/REM          consolidation             a rationale for why humans may find it advantageous to be
                                                                     1605

capable of learning by both incremental and batch updat-             Kachergis, G., Wyatt, D., O’Reilly, R. C., Kleijn, R. de, &
ing. The proposed mechanisms are all fairly computation-               Hommel, B. (2014). A continuous time neural model for
ally expensive–involving many comparisons and updates to               sequential action. Phil. Trans. of the Royal Soc: B, 369.
long-term lexical-semantic traces that are presumably stored         Kali, S., & Dayan, P. (2004). Off-line replay main-
in neocortex, making them suitable for conducting during               tains declarative memories in a model of hippocampal-
sleep. Note that while a complex version of redistributing             neocortical interactions. Nature Neurosci., 7(286–294).
diagnostic feature values would have to be done in batch, the        Khazipov, R., Sirota, A., Leinekugel, X., Holmes, G. L., Ben-
simple greedy version used here (choosing random features to           Ari, Y., & Buzsaki, G. (2004). Early motor activity drives
increment) is more batch-incremental. Although we specified            spindle bursts in the developing somatosensory cortex. Na-
these mechanisms in terms of the REM (Shiffrin & Steyvers,             ture, 432(7018), 758–761.
1997) model, the same mechanisms could be used in related            Lee, A. K., & Wilson, M. A. (2002). Memory of sequen-
multitrace modeling frameworks such as SARKAE (Nelson                  tial experience in the hippocampus during slow wave sleep.
& Shiffrin, 2013) or MINERVA2 (Hintzman, 1984). We pro-                Neuron, 36(6), 1183–1194.
posed the reactivation and re-encoding mechanisms based on           Mednick, S. C., & Alaynick, W. A. (2010). Comparing mod-
our survey of sleep-related effects on a variety of declarative        els of sleep-dependent memory consolidation. Journal of
and procedural tasks, which we found to convincingly impli-            Experimental Clinical Medicine, 2(4), 156–164.
cate sleep as beneficial to memory consolidation. Our model-         Nelson, A. B., & Shiffrin, R. M. (2013). The co-evolution
ing confirms that the proposed methods benefit memory, and             of knowledge and event memory. Psychological Review,
offers an avenue for both predicting and matching detailed             120(2), 356–394.
results from sleep studies.                                          Plihal, W., & Born, J. (1999). Effects of early and late noc-
                     Acknowledgments                                   turnal sleep on priming and spatial memory. Psychophysi-
The preparation of this work was supported by the Euro-                ology, 36(5), 571–582.
pean Commission (EU Cognitive Systems project ROBO-                  Robertson, E. M., Pascual-Leone, A., & Press, D. Z. (2004).
HOW.COG; FP7-ICT-2011).                                                Awareness modifies the skill-learning benefits of sleep.
                                                                       Current Biology, 14(3), 208–212.
                         References                                  Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2002).
Bendor, D., & Wilson, M. A. (2012). Biasing the content                Incremental singular value decomposition algorithms for
   of hippocampal replay during sleep. Nature Neuroscience,            highly scalable recommender systems. 5th International
   15(10), 1439–1444.                                                  Conference on Computer and Information Technology.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K.,       Schulz, H. (2008). Rethinking sleep analysis. Journal of
   & Harshman, R. (1990). Indexing by latent semantic anal-            Clinical Sleep Medicine, 4(2), 99–103.
   ysis. Jour. of the American Soc. for Info. Sci., 41(6).           Shiffrin, R. M., & Steyvers, M. (1997). A model for recog-
Diekelmann, S., Wilhelm, I., & Born, J. (2009). The                    nition memory: REM–retrieving effectively from memory.
   whats and whens of sleep-dependent memory consolida-                Psychonomic Bulletin and Review, 4(2), 145–166.
   tion. Sleep Medicine Reviews, 13(5), 309–321.                     Siegel, J. (2013). The evolution of sleep. In Encyclopedia of
Gais, S., & Born, J. (2004). Declarative memory consolida-             sleep (Vol. 1). Waltham, MA: Elsevier.
   tion: Mechanisms acting during human sleep. Learning &            Smith, C., & MacNeill, C. (1994). Impaired motor memory
   Memory, 11(6), 679–685.                                             for a pursuit rotor task following stage 2 sleep loss in col-
Hasselmo, M. E. (1999). Neuromodulation: Acetylcholine                 lege students. Journal of Sleep Research, 3(4), 206–213.
   and memory consolidation. Trends in CogSci, 3, 351–359.           Walker, M. P., Brakefield, T., Morgan, A., Hobson, J. A., &
Hintzman, D. L. (1984). Minerva 2: A simulation model of               Stickgold, R. (2002). Practice with sleep makes perfect:
   human memory. Behavior Research Methods: Instrument                 Practice with sleep makes perfect: Sleep-dependent motor
   and Computers, 76, 96–101.                                          skill learning. Neuron, 35, 205–211.
Hobson, J. A., & McCarley, R. W. (1977). The brain as a              Walker, M. P., & Stickgold, R. (2006). Sleep, memory, and
   dream state generator: An activation-synthesis hypothesis           plasticity. Annual Review of Psychology, 57, 139–166.
   of the dream process. Am. J. of Psych., 134(12), 1335–48.         Walker, M. P., Stickgold, R., Alsop, D., Gaab, N., & Schlaug,
Jenkins, J. G., & Dallenbach, K. M. (1924). Obliviscence               G. (2005). Sleep-dependent motor memory plasticity in
   during sleep and waking. American Journal of Psychology,            the human brain. Neuroscience, 133(4), 911–917.
   35(4), 605–612.                                                   Wamsley, E. J., & Stickgold, R. (2011). Memory, sleep,
Jones, M. N., & Mewhort, D. J. K. (2007). Representing word            and dreaming: Experiencing consolidation. Sleep Medicine
   meaning and order information in a composite holographic            Clinics, 6(1), 97–108.
   lexicon. Psychological Review, 114, 1–37.                         Wamsley, E. J., Tucker, M., Payne, J. D., Benavides, J. A., &
Kachergis, G. (2012). Learning nouns with domain-general               Stickgold, R. (2010). Dreaming of a learning task is asso-
   associative learning mechanisms. In N. Miyake, D. Pee-              ciated with enhanced sleep-dependent memory consolida-
   bles, & R. P. Cooper (Eds.), Proc. of cogsci 34 (p. 533-538).       tion. Current Biology, 20, 850—855.
   Austin, TX: Cog. Sci. Society.
                                                                 1606

