  There is more to gesture than meets the eye: Visual attention to gesture’s referents cannot account for its
                                              facilitative effects during math instruction
                                          Miriam A. Novack1 (mnovack1@uchicago.edu)
                                      Elizabeth M. Wakefield1 (ewakefield@uchicago.edu)
                                           Eliza L. Congdon1 (econgdon@uchicago.edu)
                                       Steven Franconeri2 (franconeri@northwestern.edu)
                                           Susan Goldin-Meadow1 (sgm@uchicago.edu)
                                            1
                                              Department of Psychology, University of Chicago,
                                              5848 S University Ave, Chicago, IL 60637 USA
                                            2
                                              Department of Psychology, Northwestern University
                                                 2029 Sheridan Rd, Evanston, IL 53706 USA
                               Abstract                                  concept of mathematical equivalence as a case study to test
   Teaching a new concept with gestures – hand movements that
                                                                         how gesturing towards a novel mathematical equation
   accompany speech – facilitates learning above-and-beyond              affects not only children’s learning outcomes, but also their
   instruction through speech alone (e.g., Singer & Goldin-              allocation of visual attention across the equation.
   Meadow, 2005). However, the mechanisms underlying this                   There are reasons to think that gesture’s ability to direct
   phenomenon are still being explored. Here, we use eye                 visual attention to relevant objects may underlie its positive
   tracking to explore one mechanism – gesture’s ability to              effects. Because gesture is a spatial, dynamic social cue, it
   direct visual attention. We examine how children allocate             can focus a listener’s visual attention on a specific part of
   their visual attention during a mathematical equivalence
   lesson that either contains gesture or does not. We show that         the visual environment. Even young infants will shift their
   gesture instruction improves posttest performance, and                visual attention in response to gesture (Rohlfing, Longo, &
   additionally that gesture does change how children visually           Bertenthal, 2012). This could, in turn, increase the
   attend to instruction: children look more to the problem being        likelihood that children would focus on crucial aspects of a
   explained, and less to the instructor. However looking                problem being taught, and would thus learn more from
   patterns alone cannot explain gesture’s effect, as posttest           instruction. Learners likely need to attend to the critical
   performance is not predicted by any of our looking-time
                                                                         information in an instructional context in order to learn from
   measures. These findings suggest that gesture does guide
   visual attention, but that attention alone cannot account for its     it. For example, toddlers are more likely to learn pairings
   facilitative learning effects.                                        between objects and labels if their attention is focused on
                                                                         the object while it is being labeled (Yu & Smith, 2012). If
   Keywords: Gesture; eye tracking; learning; visual attention
                                                                         gesture during instruction highlights important features of
                                                                         the problem and causes learners to visually fixate on these
                           Introduction                                  features while relevant information is being provided in
Teachers use more than words to explain new ideas; they                  speech, that increased looking should lead to better learning.
often accompany their speech with gestures – hand                           Previous work using eye tracking to understand how
movements that express information through both form and                 people process gesture has focused on visual processing of
movement patterns. Teachers gesture spontaneously in                     naturally     produced      gesture     during     face-to-face
instructional settings (Alibali et al., 2014) and controlled             communication, such as when watching a person tell a story.
experimental studies have found that children are more                   Most of this work has been descriptive, documenting where
likely to learn novel ideas from instruction that includes               interlocutors focus their visual attention during
speech and gesture, than speech alone (e.g., Ping & Goldin-              communication rather than documenting how patterns of
Meadow, 2008; Singer & Goldin-Meadow, 2005;                              visual attention affect comprehension. Overall, the findings
Valenzeno, Alibali, & Klatzy, 2003).                                     suggest that looking directly toward a speaker’s hands is
   Gesture might improve learning by conveying multiple                  actually quite rare (e.g., Gullberg & Holmqvist, 2006;
ideas simultaneously (Singer & Goldin-Meadow, 2005),                     Gullberg & Kita, 2009). Instead, listeners prefer to look
engaging the motor system (Macedonia, Muller, &                          mostly at a speaker’s face and spend little time overtly
Friederici, 2011), and linking abstract ideas to concrete                attending to gesture. On the rare occasions when
objects in the environment (Valenzeno et al., 2003). One                 interlocutors do look directly at a gesture, it is typically
understudied potential benefit of gesture is that it engages             because the speaker himself is looking towards his own
and directs visual attention. Here we used instruction on the
                                                                     2141

hands, or is holding a gesture in space for an extended            Goldin-Meadow, 1988) and has also been shown to lead to
period of time (Gullberg & Kita, 2009).                            learning when taught to children (Goldin-Meadow, Cook &
   While this descriptive work on visual attention to gesture      Mitchell, 2009). Furthermore, this particular gesture is of
during spontaneous discourse is informative, we cannot             interest because it contains both deictic properties (pointing
assume the findings will be consistent in instructional            to specific numbers) and iconic properties (representing the
settings. First, unlike the discourse studies described above,     idea of grouping through its form). Therefore, the benefits
classroom teachers often gesture towards or near objects           of learning from this type of gesture could arise from
(Alibali & Nathan, 2012). In fact, most of the behavioral          looking to the gesture itself, from looking to the numbers
work that investigates the utility of teachers’ gestures has       that the gesture is referencing, or from some combination
been in situations where gestures are performed in reference       therein.
to objects (e.g., Ping & Goldin-Meadow, 2008; Singer &
Goldin-Meadow, 2005; Valenzeno, et al., 2003). For                                           Methods
example, children learn more when a teacher gestures
toward a math problem that is written on a chalkboard              Participants
(Singer & Goldin-Meadow, 2005). This means that in most            Data from 50 participants were analyzed for the present
formal instructional settings, learners have three demands         study. Children between the age of 8 and 10 (mean age =
on their visual attention capacities – the instructor who is       8.8 years) were recruited through a database maintained by
speaking, the gestures she produces, and the objects she is        the University of Chicago Psychology Department and
gesturing toward. Thus, the way in which gesture affects           tested in the laboratory. The sample includes 26 children in
allocation of visual attention in these situations may differ      the Speech+Gesture Condition (14 females) and 24 children
drastically from other kinds of conversational settings.           in the Speech Alone Condition (14 females). All children in
   Second, and more importantly, the way gesture captures          the current sample scored a 0/6 on a pretest, indicating that
or directs visual attention during instruction may have            they did not know how to correctly solve mathematical
different cognitive implications than how gesture functions        equivalence problems at the start of the study. Prior to the
in discourse. Specifically, learning involves more than just       study, parents provided consent and children gave assent.
comprehension of the content of a message; it requires that        Children received a small prize, and $10 compensation for
learners integrate the presented information with their            their participation.
existing knowledge to arrive at a novel conceptual state.
This is a non-trivial difference between comprehension and
                                                                   Materials
learning, and it may mean that gesture necessarily serves a
                                                                   Pretest/Posttest. The pretest and posttest each contained 6
different function in an instructional context than it does
                                                                   missing addend equivalence problems, presented in one of
during casual conversation. If learners are sensitive to this,
                                                                   two formats. In Form A, the last addend on the left side of
then we might expect that the way gesture affects visual
                                                                   the equals sign was repeated on the right side (e.g., a+b+c=
attention during instruction will meaningfully map onto
                                                                   __+c’) and in Form B, the first addend on the left side of the
learning outcomes.
                                                                   equals side was repeated on the right side (e.g., p+q+r =
   In the current study, we ask how gesture directs visual
                                                                   p’+__). Both pretest and posttest consisted of 3 of each
attention for 8-10 year-old children who are learning how to
                                                                   problem type.
solve missing addend equivalence problems (e.g., 2+5+8 =
__+8). We use eye tracking to compare children’s visual
                                                                   Eye Tracker. Eye tracking data were collected via corneal
attention to instructional videos with either speech alone, or
                                                                   reflection using a Tobii 1750 eye tracker with a 17 inch
speech with accompanying gesture. Previous work using a
                                                                   monitor. Tobii software was used to perform a 5-point
similar paradigm has found that giving children relatively
                                                                   calibration procedure using standard animation blue dots.
brief instruction, using example problems, and allowing
                                                                   This was followed by the collection and integration of gaze
children to solve additional problems themselves results in
                                                                   data with the presented videos using Tobii Studio (Tobii
an increased understanding of mathematical equivalence.
                                                                   Technology, Sweden).
Importantly, incorporating gesture into instruction boosts
this understanding (e.g., Singer & Goldin-Meadow, 2005)
                                                                   Instructional videos. Two sets of 6 instructional videos
relative to instruction with speech alone. In the present
                                                                   were created to teach children how to solve Form A missing
study, we use a grouping gesture during instruction. This
                                                                   addend math problems (e.g., 5+6+3=__+3) – one set for
gesture involves producing a V-point to the first two
                                                                   children in the Speech Alone condition and one set for
numbers in a missing addend equivalence problem followed
                                                                   children in the Speech+Gesture condition. All videos
by a point to the blank space. This V-point gesture
                                                                   showed a woman standing next to a Form A missing addend
represents the idea that one can solve the equation by
                                                                   math problem, written in black marker on a white board. At
adding, or grouping, the first two addends and putting that
                                                                   the beginning of each video, the woman said, “Pay attention
total in the blank. This V-point gesture is one produced
                                                                   to how I solve this problem”, and then proceeded to write
spontaneously by children who already understand how to
                                                                   the correct answer in the blank (e.g., writing 11 in the
solve these sorts of problems (e.g., Perry, Church, &
                                                                   previous example). She then described how to solve the
                                                               2142

problem, explaining the idea of equivalence: “I want to                Speech+Gesture) as fixed factors and subject as a random
make one side equal to the other side. 5 plus 6 plus 3 equals          factor revealed a positive effect of training problem (β=0.91,
14, and 11 plus 3 is 14, so one side is equal to the other             SE=0.15, z=6.21, p<.001), indicating that children became
side.” During this spoken instruction, the woman kept her              more likely to correctly answer problems as training
gaze on the problem. In the Speech+Gesture videos, the                 progressed. There was, however, no effect of condition
woman accompanied her speech with a gesture strategy.                  during training (β=0.03, SE=0.72, z=0.04, p=.96, indicating
When she said “I want to make one side…”, she                          that learning rates during training did not differ by
simultaneously produced a V-point with her index and                   condition. By the final training problem, over 90% of
middle figure to the first two addends, then, as she said              participants in both groups were answering the problems
“…the other side” she moved her hand across the problem,               correctly, which suggests that both types of instruction were
bringing her fingers together to point to the answer with her          equally comprehensible.
index finger. She produced no gestures in the Speech Alone
videos. To ensure that the speech was identical across the
two training conditions, the actress recorded a single audio
track for each problem, prior to filming. Each of the twelve
videos was approximately 25 seconds long.
                              Procedure
Children first completed a written pretest containing 6
missing addend math problems. All children in the current
sample scored 0/61. The experimenter then wrote children’s
(incorrect) answers on a white board and they were asked to
explain their solutions.
   Next, children sat in front of the eye tracking monitor,
approximately 18 inches from the screen, and were told they
would watch instructional videos that would help them
understand the type of math problems they had just solved.
Their position was calibrated and adjusted if necessary, then
they began watching the first of the 6 instructional videos            Figure 1. Performance during training on practice problems.
(either Speech Alone, or Speech+Gesture, depending on the                  Learning increased across the 6 problems, but was not
assigned training condition). At the conclusion of each                         different across the two training conditions.
video, children were asked to solve a new missing addend
problem on a small, hand-held whiteboard, and were given               Posttest. Although the groups did not differ in performance
feedback on whether or not their answer was correct (e.g.,             at the end of training, their scores on an immediate posttest
“that’s right, 10 is the correct answer” or “no, actually 10 is        reflected an advantage of having learned through
the correct answer”). All problems shown in the                        Speech+Gesture instruction (see Figure 2). Participants in
instructional videos were Form A, and all problems that                the gesture condition answered significantly more problems
children had the opportunity to solve were Form A.                     correct at the posttest (M=4.11, SD=2.04) than participants
   After watching all 6 instructional videos and having 6              in the speech condition (M=2.64, SD=2.08). A mixed-
chances to solve their own problems during training,                   effects logistic regression with problem type (Form A:
children completed a new, 6-question paper-and pencil                  trained, Form B: transfer) and Condition (Speech+Gesture,
posttest. The posttest, like the pretest, included 3 Form A            Speech Alone) as fixed factors and subject as a random
problems and 3 Form B problems. As children saw only                   factor showed a significant effect of condition (β = -2.60, SE
Form A problems during training, we refer to these as                  =0.99, z=2.59, p<.01) indicating that posttest performance in
“Trained” problems and Form B as “Transfer” problems.                  the Speech+Gesture Condition was better than performance
                                                                       in the Speech Alone Condition. There was also a significant
                                                                       effect of problem type (β=2.27, SE=0.43, z=5.31, p<.001),
                               Results                                 demonstrating that performance on Form A (trained
                                                                       problems) was better than performance on Form B:
Behavioral Results
                                                                       (transfer problems). There was no significant interaction
Training. Figure 1 shows the proportion of participants in
                                                                       between Condition and Problem Type (β=0.29, SE=0.79,
each condition who answered problems correctly during
                                                                       z=-0.37, p=0.71).
training. A mixed-effects logistic regression predicting the
log-odds of success on a given training problem with
problem number (1-6) and condition (Speech Alone,
   1
     Children who answered pretest problems correctly (n=59) were
still run in the study but are excluded from the current analyses.
   2
      There was a gesture space in the Speech Alone video, despite
                                                                   2143

                                                                          Figure 3. Still shot taking during a gesture segment, with
                                                                                                 AOIs overlaid.
                                                                        the Speech+Gesture condition also saw co-speech
                                                                        instructional gestures. As the strategy was explained twice
    Figure 2. Posttest performance by condition and problem             per problem, data from these epochs were combined into
type. Error bars represent +/-1 standard error of the mean.             one segment of interest. The explanation segment
                                                                        encompassed time when the instructor elaborated on the
Eye-Tracking Results                                                    strategy, highlighting the particular addends in the problems
We used a multistep process to analyze the eye tracking                 (e.g., “5 plus 6 plus 3 is 14, and 11 plus 3 is 14”). This
data: (1) Areas of interest (AOIs) were generated for the               segment was visually identical across the experimental
instructor, problem and gesture space2 (See Figure 3) using             groups, allowing us to ask whether the presence of gesture
Tobii Studio. Fixations outside of these AOIs were                      during the preceding strategy segment caused children in
collapsed into “Other”. (2) Data were extracted and                     the Speech+Gesture condition to focus their visual attention
processed, such that the AOI a participant fixated in could             in the subsequent explanation segment differently than
be determined at 50 msec intervals across the entire length             those in Speech Alone instruction.
of each problem. (3) Time segments of interest, during
which a particular event was happening in the videos (e.g.,                Strategy segment. Figure 4 shows the proportion of time
the instructor stating the equalizer strategy, “I want to make          children spent looking in each of the AOIs during the
one side equal to the other side”) were identified, and total           strategy segment in each condition. On average, children in
gaze duration during a given time segment in each AOI                   the Speech+Gesture condition spent a greater proportion of
were computed. (4) We calculated the proportion of time a               time looking to the problem itself compared to children in
participant spent in each AOI within each segment collapsed             the Speech Alone condition (60% versus 48%) (β=0.11,
across all six problems. For each participant, eye tracking             SE=0.05 t=2.39, p<0.05). In contrast, children in the Speech
data were excluded if visual inspection showed that the                 Alone condition allocated more visual attention to the
calibration was off. On average, children in the Gesture                instructor, compared to children in the Gesture condition
Condition contributed data from 4.96 (SD = 1.34) trials, and            (47% vs. 18%) (β =-0.29, SE=0.04 t=-6.19, p<0.01).
children in the Speech Condition contributed data from 4.90             Finally, children in the Speech+Gesture condition spent
trials (SD = 1.34).                                                     19% of the time looking to the Gesture space.
                                                                        Unsurprisingly, children in the Speech Alone condition
Allocation of visual attention across conditions.                       spent significantly less time (3%) in this AOI (β=.16,
To determine whether patterns of visual attention differed              SE=0.02 t=5.63, p<0.01) as there was nothing there to draw
when children were instructed through Speech+Gesture vs.                their attention. Together, these results suggest that gesture
Speech Alone, we considered the proportion of time                      does affect visual attention in an instructional context,
children spent in each AOI for two time segments of                     leading participants to look more to the objects being
interest. The strategy segment encompassed time when the                referenced, and less to the instructor herself.
instructor stated the equalizer strategy: I want to make one
side, equal to the other side. During this segment, spoken              Explanation segment. Figure 4 also shows the proportion
instruction was identical across conditions, but children in            of time spent in each AOI during the explanation segment,
                                                                        with children across both conditions splitting their time
                                                                        evenly between the instructor and the problem. Analyses
                                                                        indicated that there were no differences in looking times to
                                                                        the AOIs by Condition during the explanation segments.
   2
     There was a gesture space in the Speech Alone video, despite
the fact that there was never any gesture produced in those videos.
                                                                    2144

      Figure 4. Average proportion of gaze duration across all 6 problems during strategy and explanation segments.
Relation between visual attention and learning.                      Our eye tracking results demonstrated that at a global
Given the condition differences between the allocation of         level, gesture directs visual attention towards spoken
visual attention during the strategy segment of instruction,      referents in a formal, instructional context, and that children
we were interested in whether the focus of attention elicited     are more likely to focus on referents of gesture than gesture
by the presence of gesture predicted learning outcomes. To        itself. This is interesting, given that the Speech+Gesture
explore this we conducted a regression to determine whether       videos contained more items (i.e., moving hands) for
looking towards the problem itself (which children did more       children to look at than the Speech Alone videos, and yet,
in the Speech+Gesture condition) predicted posttest               children in this condition focused the majority of their
performance. Proportion of time looking to the problem did        attention on the problem. Relatedly, it is notable that there
not predict performance on the posttest (β=2.53, SE=1.89,         was relatively little overt focus on the gesture form, even
t=1.34 p=0.18). In other words, the presence of gesture did       though previous work suggests that the form of the gesture
lead children to look more to objects referenced by gesture       itself is important for learning in this task (Goldin-Meadow
but that increase in looking was not responsible for the          et al., 2009). Finally, in terms of general looking patterns,
increase in learning outcomes. Focusing just on the gesture       we found that although gesture affects visual attention when
condition, we see that children spend relatively little time      it is being produced, it does not affect visual attention of
looking directly at the gesture (only about 19%), and the         subsequent speech-only instruction, as seen from our
amount of looking to the gesture itself, while it is being        analysis of the explanation segment of instruction.
produced, has no relation to learning outcomes within the            Our looking time findings suggest similarities between
gesture condition (β=1.96, SE=4.47, t=0.44 p=0.66).               natural communicative gesture, and purposeful, instructional
                                                                  gesture. Like work on communicative gesture, we find that
                                                                  looking directly at gesture is relatively uncommon.
                         Discussion                               However, our results may suggest a difference between
   Although decades of work have found that gesture               natural and instructional gesture contexts: even though
supports learning when added to instructional contexts, this      fixation on gesture is relatively rare, gesture in instructional
was the first study to ask how gesture during instruction         contexts may draw more attention than gesture in natural
guides visual attention and facilitates learning through an       communication. When gesture was present in the current
attentional mechanism. Our behavioral results replicate           study, all children in the sample looked directly at it, at least
previous work (e.g., Singer & Goldin-Meadow, 2005). We            for some amount of time. In a study of gesture in discourse,
show that children who learn from watching speech+gesture         only 9% of gestures were ever fixated (Gullberg &
instruction have more robust learning than children who           Holmqvuist, 2006). This difference may be attributable to
learn from speech alone, as demonstrated by higher                the way gestures were used in our instruction that differ
performance on a posttest. Importantly, and surprisingly, we      from their use in discourse. In our videos, gestures were
also add a novel finding to the behavioral literature.            front-and-center – they were in the middle of the screen,
Whereas most researchers consider posttest performance            while the instructor was faced away from the child,
alone as a measure of learning, we asked how children’s           providing a cue to their importance. In contrast, in previous
performance changed during instruction. We show that              studies of communicative gesture in discourse, participants
learning rates during instruction did not differ across the       see face-to-face communication, where the face may take
two groups, but only emerged after a change in context (i.e.,     center stage. Further work examining more types of
moving from sitting in front of the eye tracker to a desk),       instructional gesture (and perhaps less salient instructional
and when intermittent reminders of the strategy were not          gestures) may reveal what is driving this difference.
present. This suggests that our learning paradigm may only           In our final analysis, we asked whether attention to the
produce fragile, temporary learning outcomes, but that the        problem during the strategy segment of instruction led to
addition of gesture to the instruction can help solidify that     better posttest performance, with the rationale that finding
knowledge. This short-term retention effect corroborates          this link would suggest that at least part of the facilitative
previous work showing that the effects of gesture are             effects of gesture in previous studies is driven by its ability
particularly good at promoting long-lasting learning (e.g.,       to guide attention. Although we did not find evidence that
Cook, Mitchell, & Goldin-Meadow, 2008).                           gesture enhances learning by highlighting important features
                                                              2145

of a problem, and increasing fixation to those features, it               Learning Sciences, 21, 247–286.
may be possible for gesture to highlight important relational             doi:10.1080/10508406.2011.611446
aspects of a problem, which will be examined in future                  Alibali, M. W., Nathan, M. J., Wolfgram M. S., Church,
work. For example, adults solving these same kinds of math                R. B., Jacobs, S.A., Johnson Martinez, C. & Knuth, E.
problems are less likely to make errors if they traversed the             J. (2014) How Teachers Link Ideas in Mathematics
equal sign, a gaze pattern that may be highlighting the                   Instruction Using Speech and Gesture: A Corpus
relational structure of the equation (Chesney et al., 2013).              Analysis, Cognition and Instruction, 32, 65-100. doi:
Thus it is possible that gesture could lead to useful eye-                10.1080/07370008.2013.858161
movement patterns not captured by the current analysis,                 Chesney, D. L., McNeil, N. M., Brockmole, J. R., &
which could in turn support learning outcomes.                            Kelley, K. (2013). An eye for relations: eye-tracking
   It also remains possible that the effect of gesture on visual          indicates long-term negative effects of operational
attention is not the main mechanism through which gesture                 thinking on understanding of math equivalence.
facilitates learning. For example, Ping & Goldin-Meadow                   Memory & Cognition, 41, 1079-1095.
(2008) found that 5-6 year olds were just as likely to                  Cook, S. W., Mitchell, Z., & Goldin-Meadow, S. (2008).
improve their understanding of Piagetian conservation after               Gesturing makes learning last. Cognition, 106, 1047-
a lesson that included gesture, irrespective of whether or not            1058. doi: 10.1016/j.cognition.2007.04.010
the objects to which the gestures referred (i.e., glasses that          Goldin-Meadow, S., Cook, S. W., & Mitchell, Z. A.
contained water) were present. In another study, Goldin-                  (2009).Gesturing gives children new ideas about math.
Meadow, Cook, & Mitchell (2009) taught children how to                    Psychological Science, 20, 267–272.
solve missing addend equivalence problems by producing a                  doi:10.1111/j.1467-9280.2009.02297.x
grouping gesture either to the correct, or incorrect addends            Gullberg, M., & Kita, S. (2009). Attention to speech-
to be grouped. Remarkably, children learned even if they                  accompanying gestures: Eye movements and
had produced the V-point to the wrong addends, suggesting                 information uptake. Journal of nonverbal behavior, 33,
that directing visual attention to the wrong place does not               251-277. doi: 10.1007/s10919-009-0073-2
disrupt gesture’s positive effects on learning. Still, it seems         Gullberg, M., & Holmqvist, K. (2006). What speakers do
likely that visual attention is part of the story. In fact, in the        and what listeners look at. Visual attention to gestures
example given above, Goldin-Meadow et al. (2009) found                    in human interaction live and on video. Pragmatics and
that although children could learn from an ‘incorrect’                    Cognition, 14, 53–82.
gesture, they benefitted more from the same gesture, used to              doi: http://dx.doi.org/10.1075/pc.14.1.05gul
highlight grouping of the correct addends, and, presumably,             Macedonia, M., Muller, K., & Friederici, A. D. (2011).
draw visual attention to these addends.                                   The impact of iconic gestures on foreign language word
   In the present study, we have established that instructional           learning and its neural substrate. Human Brain
gesture does drive children to look at a novel equation                   Mapping, 32, 982-998. doi: 10.1002/hbm.21084
differently, and children show increased learning after this            Rohlfing, K. J., Longo, M. R., & Bertenthal, B.I. (2012).
type of instruction; we have just also shown that this shift in           Dynamic pointing triggers shifts of visual attention in
global looking pattern does not provide a simple causal                   young infants. Developmental Science, 15, 426-435.
explanation for this cognitive effect. Future work will                   doi:10.1111/j.1467-7687.2012.01139.x
consider how more nuanced aspects of visual attention, such             Singer, M. a, & Goldin-Meadow, S. (2005). Children
as whether it helps children synchronize their looking with               learn when their teacher’s gestures and speech differ.
spoken instruction, as well as ways in which the ability to               Psychological Science, 16, 85–89. doi:10.1111/j.0956-
guide visual attention may combine with other features of                 7976.2005.00786.x
gesture to support learning.                                            Perry, M., Church, R. B., & Goldin-Meadow, S.
                                                                          (1988).Transitional knowledge in the acquisition of
                    Acknowledgments                                       concepts. Cognitive Development, 3, 359–400.
Funding for this study was provided by NICHD (R01-                        doi:10.1016/0885-2014(88)90021-4
HD47450, to Goldin-Meadow), NSF BCS 1056730, and the                    Ping, R. M., & Goldin-Meadow, S. (2008). Hands in the
Spatial Intelligence and Learning Center (SBE 0541957,                    air: using ungrounded iconic gestures to teach children
Goldin-Meadow is a co-PI) through the National Science                    conservation of quantity. Developmental Psychology,
Foundation. We also thank Kristin Plath, William Loftus,                  44, 1277–87. doi: 10.1037/0012-1649.44.5.1277
and Aileen Campanaro for their help with data collection,               Valenzeno, L., Alibali, M. W., & Klatzky, R. (2003).
and Amanda Woodward for the use of the eye tracker.                       Teachers’ gestures facilitate students’ learning: A
                                                                          lesson in symmetry. Contemporary Educational
                                                                          Psychology, 28, 187–204. doi: 10.1016/S0361-
                         References                                       476X(02)00007-3
   Alibali, M. W., & Nathan, M. J. (2012). Embodiment in                Yu, C., & Smith, L. B. (2012). Embodied attention and
      Mathematics Teaching and Learning: Evidence From                    word learning by toddlers. Cognition, 125, 244-262.
      Learners’ and Teachers’ Gestures. Journal of the                    doi:10.1016/j.cognition.2012.06.016
                                                                   2146

