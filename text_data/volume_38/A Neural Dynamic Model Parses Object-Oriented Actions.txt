                     A Neural Dynamic Model Parses Object-Oriented Actions
                                            Mathis Richter (mathis.richter@ini.rub.de)
                                                  Jonas Lins (jonas.lins@ini.rub.de)
                                          Gregor Schöner (gregor.schoener@ini.rub.de)
                         Institut für Neuroinformatik, Ruhr-Universität Bochum, 44870 Bochum, Germany
                             Abstract                                   of a reference object. The new model integrates this form of
   Parsing actions entails that relations between objects are dis-
                                                                        action parsing with the grounding of spatial relationships of
   covered. A pervasively neural account of this process requires       the earlier model.
   that fundamental problems are solved: the neural pointer prob-          We use dynamic field theory (DFT; Schöner, Spencer, &
   lem, the binding problem, and the problem of generating dis-
   crete processing steps from time-continuous neural processes.        the DFT Research Group, 2015) as a theoretical framework.
   We present a prototypical solution to these problems in a neural     DFT describes neural population activity by activation fields
   dynamic model that comprises dynamic neural fields holding           that are defined over metric feature dimensions and evolve
   representations close to sensorimotor surfaces as well as dy-
   namic nodes holding discrete, language-like representations.         continuously in time through a neural dynamics. While the
   Making the connection between these two types of represen-           fields capture representations in a modal form close to the
   tations enables the model to parse actions as well as ground         sensorimotor surfaces, neural nodes sharing the same dynam-
   movement phrases—all based on real visual input. We demon-
   strate how the dynamic neural processes autonomously gen-            ics enable modeling discrete, amodal representations. Mutual
   erate the processing steps required to parse or ground object-       coupling between fields and nodes allows for interaction be-
   oriented action.                                                     tween these two kinds of representations. By using only tools
   Keywords: relations; neural process model; action parsing;           from the DFT repertoire we arrive at a seamless process ac-
   dynamic field theory; grounded cognition; cognitive schemas
                                                                        count that is pervasively neural. This requires that we solve
                         Introduction                                   the following fundamental problems that arise from restric-
                                                                        tions of neural mechanism and are not commonly addressed
If you were to describe the arrangement of furniture in your            in accounts of higher cognition.
office you would probably make use of the spatial relations
between different items. You may recognize without effort                  First, information represented by neural activity cannot be
that “the bookshelf is to the left of the desk” although this re-       freely moved within and between neural populations, because
lationship is not directly specified by perception and requires         neural connectivity is fixed. In visual cortex, for instance, vi-
active construal. In fact, relational processing may be founda-         sual objects are represented in neural maps. Applying a neu-
tional to higher cognition (Halford, Wilson, & Phillips, 2010).         ral operator to a location or an object in such a map is possible
   Evaluating even simple relations requires several coordi-            only if it is connected to that location. Connecting operators
nated steps (Logan & Sadler, 1996): (1) binding each object             to every location in a map would require unrealistic neural re-
to a role (here, the desk is the reference object, the bookshelf        sources. The alternative is to connect the operator to only one
is the target object); (2) centering the reference frame on             default region, a virtual fovea, and shift the representations of
the reference object; (3) applying a relational operator (here,         objects to that region. This is analogous to the concept of an
“to the left of”) to the target object in that frame. We have           attentional neural pointer of Ballard, Hayhoe, Pook, and Rao
previously realized these computational steps in a neural pro-          (1997) and is achieved in our framework by steerable neural
cess model (Lipinski, Schneegans, Sandamirskaya, Spencer,               mappings (Schneegans & Schöner, 2012).
& Schöner, 2012; Richter, Lins, Schneegans, Sandamirskaya,                Second, for similar reasons of limiting the required neural
& Schöner, 2014) that mapped spatial relational phrases sup-           resources, the nervous system represents high-dimensional
plied in a language-like, discrete form, to a visual scene repre-       visual information in multiple low-dimensional neural feature
sentation, effectively grounding amodal input in perception.            maps, in particular in the early tiers of the cortical hierarchy.
Conversely, the model was able to complete partial phrases              To refer to any particular object, corresponding representa-
by referring to the visual scene.                                       tional pieces must be bound together. In a neural implemen-
   Here, we extend this model to the parsing of object-                 tation of the classical idea of binding through space (Treis-
oriented actions and the grounding of action phrases, such              man & Gelade, 1980), we endow every feature map with a
as “the red ball is moving toward (or away from) the yellow             spatial dimension shared across maps and process objects se-
ball”. This is challenging for a neural process model as the            quentially in time (Schneegans, Spencer, & Schöner, 2015).
perceptual representations are inherently transient. We add                Third, the discrete processing steps this implies and that
two components that extract motion directions through a neu-            are critical to all of higher cognition are natural in informa-
ral dynamic model of motion detection (Berger, Faubel, Nor-             tion processing accounts but hard to achieve in neural process
man, Hock, & Schöner, 2012) and transform the visual scene             models, in which neural activation evolves continuously in
to an intrinsic reference frame (van Hengel, Sandamirskaya,             time under the influence of input and recurrent connectivity.
Schneegans, & Schöner, 2012) based on the motion direction             In our model, discrete events emerge from continuous neural
                                                                    1931

dynamics through dynamic instabilities, at which the match               observing a video. Solving these tasks within a single neural
between neural representations of intentional states and their           architecture requires integrating various components, which
conditions of satisfaction are detected (Sandamirskaya &                 we describe in more detail now.
Schöner, 2010).
   Finally, the problem of preserving role-filler bind-                  Perception
ing (Doumas & Hummel, 2012) at the interface between the                 The architecture receives video input from a camera or video
modal and the amodal representations is also solved by se-               file. This input is fed into two three-dimensional perception
quential processing.                                                     fields (top right of Fig. 1) that hold a representation of the
                                                                         scene. Both fields share the spatial dimensions of the camera
                            Methods                                      image but the perception color field represents the color of
Dynamic field theory describes processes that characterize               objects in the scene and the perception movement field, new
neural activity at the population level. Models in DFT are               over the previous model (Richter et al., 2014), represents their
based on activation patterns defined as dynamic fields, u(x,t),          movement direction. To create the input to the perception
over continuous feature dimensions, x, (e.g., color or space).           fields, each video frame goes through several preprocessing
These activation patterns evolve in time, t, under the influ-            steps. For the color field, the preprocessing is first based on
ence of lateral interactions and external input based on the             generic image processing algorithms. After these, activation
following integro-differential equation                                  is generated that scales with the color saturation of objects in
                                      Z
                                                                         the scene. For the movement field, the preprocessing consists
                                                                         of a neural dynamic implementation of the counter-change
 τu̇(x,t) = −u(x,t) + h + s(x,t) +      g(u(x0 ,t)) w(x − x0 ) dx0 .
                                                                         model of motion perception (Berger et al., 2012). Both per-
                                                                         ception fields always have stable peaks of activation when
Here, the activation’s rate of change, u̇(x,t), depends                  there are colored or moving objects in the scene. They project
on u(x,t) itself, on a time constant, τ, a negative resting              activation into the spatial attention fields along the two spa-
level, h, and external input, s(x,t), from sensors or other              tial dimensions and act as a saliency mechanism. They also
fields. Lateral interaction is determined by convolving the              project directly into the reference and target field and enable
output of the field, g(u(x,t)), a sigmoid function with thresh-          these fields to track moving objects even if spatial attention is
old at zero, with an interaction kernel, w(∆x). The kernel               currently focused elsewhere.
combines local excitation and surround inhibition along the
field’s feature dimension.                                               Attention
   When presented with localized input above the output                  The core of the attentional system consists of two three-
threshold, lateral interaction leads to an instability, in which a       dimensional attention fields. They are defined over the same
subthreshold solution becomes unstable and the field moves               dimensions as the two perception fields but their activation
to a new attractor, a self-stabilized activation peak. From such         remains below threshold unless additional input arrives from
instabilities, neural events emerge at discrete times from the           a feature attention field or a spatial attention field.
time-continuous dynamics of the fields. These events are crit-              A pair of one-dimensional fields spans each feature dimen-
ical for organizing sequential processes in DFT models.                  sion (color and movement direction): the intention field rep-
   Depending on the tuning of their interaction kernel, dy-              resents feature values for guided search and impacts on the
namic fields may either support multiple peaks or may be se-             three-dimensional attention fields; the condition of satisfac-
lective and only create a single peak that suppresses all oth-           tion (CoS) field matches input from the attention fields against
ers. Fields may also be tuned to hold self-sustained peaks               what is represented in the intention field.
that remain even after input is removed. Fields can be defined              Two spatial attention fields are defined over the two spatial
over single or multiple dimensions. Dynamic nodes share the              dimensions of the camera image. One field allows for mul-
fields’ dynamic characteristics but do not span a feature di-            tiple simultaneous peaks and projects into the reference and
mension. Instead, they represent the ‘on’ or ‘off’ state of              target fields. The other only allows for a single peak; it can
discrete elements within an architecture.                                be boosted to induce a selection decision on multiple candi-
   DFT architectures consist of multiple fields and nodes that           date objects. A peak generated in this spatial attention field
are interconnected, where the output of one field is input to            suppresses activation at all other locations in the other spatial
another field. Fields of different dimensionalities may be con-          attention field. It further projects into the three-dimensional
nected along the shared feature dimensions.                              attention fields, enabling peaks to form there that represent
                                                                         the feature values at the selected location (which then impact
                         Architecture                                    on the CoS fields). This implements a neural mechanism of
The DFT architecture shown in Fig. 1 can deal with two types             feature binding across space (Schneegans et al., 2015).
of tasks. First, it can ground a language-like phrase such as
“the red object moving toward the yellow object”, that is, it            Coordinate transformation
can find the objects in the scene that correspond to the phrase.         The two-dimensional reference field and target field each rep-
Second, it can generate a phrase such as the one above from              resent the spatial position of their respective objects. The tar-
                                                                     1932

Fig. 1: Architecture with activation snapshots while it is generating a phrase about a video. Fields are shown as color-coded
activation patterns; for three-dimensional fields, two-dimensional slices are shown. Node activation is denoted in opacity-
coded circles. Spatial templates are illustrated as color-coded weight patterns (bottom left). Excitatory synaptic connections
are denoted by lines with arrow heads, inhibitory connections by lines ending in circles. Transformations to and from polar
coordinates are marked with a ‘T’. Coordinate transformations are denoted as diamonds.
get field projects into the relational field via a steerable neu-     reference object, which is held by the rotation field.
ral mapping (upper left blue diamond in Fig. 1) that shifts              The rotated target representation is projected into the rela-
the representation of the target objects so that it is centered       tional CoS field. A second input to this field from spatial con-
on the reference object. This transformation to a new refer-          cept nodes encodes the associated spatial templates through
ence frame is implemented as a convolution for performance            weight patterns (illustrated in the lower left of Fig. 1). Over-
reasons.                                                              lap of the two inputs leads to a peak that represents the se-
   The shifted representation of the target objects is then ro-       lected target. The steerable neural maps thus make it possible
tated around the reference object. This transforms the tar-           to apply the relational operator encoded in the fixed weight
get representation into an intrinsic reference frame defined          patterns to objects at any visual location in any orientation,
by the reference object’s movement direction. This rotatory           implementing neural pointers.
transformation, new over the previous model, is realized by a            The relational CoS field projects into the selective spatial
steerable neural mapping that shifts activation patterns along        attention field via reverse transformations for rotation and
the azimuth of the polar coordinate representation of the re-         shift (upper and lower right diamonds in Fig. 1). Selec-
lational field (lower left blue diamond in Fig. 1). The extent        tive spatial attention projects into the three-dimensional at-
of the shift is determined by the movement direction of the           tentional fields, forming peaks there that in turn project to the
                                                                  1933

feature fields, which may activate production nodes.                   any further intervention from user or program. First, the ref-
                                                                       erence object is grounded; the target behavior is inhibited by
Concepts                                                               the precondition constraint until the reference behavior is fin-
Concepts like ‘red’ or ‘toward’ are represented by discrete            ished. Without information about which objects to describe,
nodes (denoted by circles in Fig. 1) that project with pat-            the architecture decides based on their saliency. At t1 , the se-
terned synaptic weights into their respective feature fields.          lective spatial attention field shows a saliency advantage for
The nodes come in pairs: memory nodes (blue circles) act               the moving red object in the lower left corner.
as an interface to a user who may activate them as input or               At t2 , the spatial attention field has made a selection deci-
observe them as output; production nodes (pink circles) gate           sion and formed a peak. This creates a self-sustained peak in
the impact of their respective memory nodes onto the archi-            the reference field, selecting the moving object as reference.
tecture. Note that there are copies of such pairs of nodes for         It also activates the production node ‘reference: red’ (top of
each role that a concept may appear in (e.g., two pairs for            Fig. 2) by projecting activation into the color CoS field via
‘red’, as reference and as target), enabling role-filler binding.      the attention color-space field (both not shown in Fig. 2; see
The synaptic weight patterns between nodes and fields could            Fig. 1). At the same time, the rotation angle field (not shown
be learned by Hebbian learning rules but are hand-tuned here.          in Fig. 2) forms a representation of the object’s movement
                                                                       direction, which it receives from the attentional movement-
Process organization                                                   space field. It will later be used as a parameter to rotate the
The processes within the architecture are organized by in-             target objects. At this point, the architecture has grounded the
stabilities of neural nodes that switch components ‘on’ or             reference object. That is, it has formed a connection between
‘off’. These discrete events thus emerge from the time-                the continuous representations in the fields and the discrete
continuous neural dynamics. Process organization is based              representations in the nodes.
on a structural principle borrowed from behavioral organi-                At t3 , the behavior to ground the reference object has been
zation (Richter, Sandamirskaya, & Schöner, 2012). The                 inhibited by its CoS node and the behavior to ground the tar-
core structure is the elementary behavior, which consists of           get object has become active. However, even though the ref-
two dynamic substrates. The intention node (green circle in            erence behavior is inactive, the peak in the reference field
Fig. 1) determines whether a process is active and has impact          is still tracking the position of the moving object, because
on connected structures. The condition of satisfaction node            it receives input from the perception fields. Contrary to the
(CoS, red circle) is activated once a process has terminated           reference behavior, the selective spatial attention field is not
and inhibits the intention node, turning the process off. Here,        boosted during the target behavior, allowing multiple target
we employ elementary behaviors that control the grounding              candidates to be projected to downstream fields. The target
of the reference object (reference behavior), the target object        field has formed three peaks at the positions of the remaining
(target behavior), and the spatial relation term (spatial relation     objects. The field’s output is transformed and projected into
behavior) (top left in Fig. 1). Role-filler binding is preserved       the relational field, where the target positions are now rep-
during grounding by processing reference and target objects            resented relative to that of the reference object. This repre-
sequentially, organized by the precondition node (black cir-           sentation is rotated around the reference object and projected
cle) that inhibits the intention node of the target behavior until     into the relational CoS field.
the reference behavior has terminated.                                    At t4 , the relational CoS field has formed a peak at the tar-
                                                                       get position that overlaps most with the spatial template for
                              Results                                  the relation ‘toward’. This activates the corresponding pro-
In the following, we describe the dynamic processes that un-           duction node ‘spatial: toward’.
fold within the architecture as it executes tasks. The results            At t5 , the activation from the relational CoS field is trans-
come from numerical solutions of the architecture’s differ-            formed and projected back into the selective spatial attention
ential equations.1 To simplify visual object recognition, we           field, from there into the attentional color-space field, and
use a scene with uniformly colored objects on a white back-            from there into the target field as well as the color CoS field.
ground.                                                                The peak in the color CoS field activates the production node
                                                                       ‘target: yellow’.
Parsing an action                                                         At this point, the architecture has produced the relational
Fig. 2 illustrates the processes within the architecture as it         phrase ‘red toward yellow’ and has created a grounding of
generates a phrase about a video in which a red ball rolls to-         this phrase in sensorimotor representations.
ward a yellow ball (see top right of Fig. 1).                          Grounding a phrase
   At t = 0 we give a boost into the architecture, which im-
                                                                       The architecture can also ground a phrase that it is given by
pacts the intention nodes of all behaviors. After this boost, the
                                                                       user input. Due to space constraints, we cannot describe the
architecture runs autonomously in continuous time, without
                                                                       process at the same level of detail. The process is very similar
    1 The architecture is implemented and simulated using the C++      to that of grounding spatial relations reported earlier (Richter
framework cedar (Lomp, Zibner, Richter, Rano, & Schöner, 2013).       et al., 2014). The user supplies the phrase by activating mem-
                                                                   1934

                                                            t1                        t2                                            t3   t4                    t5
                      8
                      4                                                                                                                   spatial toward
activation
                                                                      reference red                                                                                 target yellow
                      0
                      -4
                                                                                                target red       reference yellow                                   spatial away
                      -8
                           0                                                                    1                                                          2                time (s)
                                                                 t1                        t2                          t3                     t4                       t5
                               reference
                               target
                                 spatial     spatial
                                attention   attention
                       5
                               (selective) (multi peak)
                       4
                       3
                       2
                               relational
                       1
                       0
activation colormap
                      -1
                      -2
                      -3       relational
                      -4
                                  CoS
                      -5
     Fig. 2: Activation time courses of relevant production nodes (top) and activation snapshots of relevant fields at five points in
     time (bottom). Fields are color-coded using the color map on the bottom left.
     ory nodes through manual boosts. Visual search for objects                                              tual symbols (Barsalou, 2008) and embodied construction-
     is then guided, as opposed to bottom-up saliency-driven. For                                            grammar (Bergen & Chang, 2013) postulate. The integrative
     instance, to ground the reference object, its red color is rep-                                         nature of the model leads us to confront fundamental issues
     resented in the color intention field, bringing up peaks of red                                         such as the neural pointer problem, the binding problem, and
     objects in the attentional color-space field—analogously with                                           how discrete processing steps emerge from time-continuous
     yellow objects for the target. Similarly, the template for spa-                                         neural dynamics. Our solutions derive from the conceptual
     tial relations preshapes the relational CoS field and only al-                                          commitments of the theoretical framework of dynamic field
     lows peaks that overlap with the template. The grounding is                                             theory.
     established once a representation in the fields has been estab-
                                                                                                                We build on existing modeling approaches to the ground-
     lished for each element of the supplied phrase.
                                                                                                             ing of language that are neurally inspired but do not typi-
                                                                                                             cally adhere to neural principles as consistently. For instance,
                                                          Discussion                                         the Neural Theory of Language (Feldman, 2006) is a hy-
     We have extended a neural process model of spatial relations                                            brid framework that combines neural network concepts with
     to include parsing of object-oriented actions and grounding of                                          ideas that are not compatible with neural process thinking.
     movement phrases. In the model, space-time continuous ac-                                               Similarly, Madden, Hoen, and Dominey’s (2010) model for
     tivation patterns are both coupled to sensory input and linked                                          embodied language complements neural networks with al-
     to neural representations of cognitive schemas like move to-                                            gorithms that are not neurally based. Some models invoke
     ward or move away from. This provides a neural processing                                               neural concepts to account for psychophysical data. For in-
     account of the interaction between sensorimotor activation,                                             stance, Regier and Carlson (2001) use the notion of an atten-
     conceptual processing, and language, that theories of percep-                                           tional vector sum to capture spatial terms. Such models are
                                                                                                    1935

not typically embedded into architectures that autonomously         Lakoff, G., & Johnson, M. (1999). Philosophy in the
generate the complete sequence of processing steps required               flesh: The embodied mind and its challenge to western
to ground and generate language.                                          thought. New York: Basic Books.
   The ambition of a neural process account for higher cog-         Lipinski, J., Schneegans, S., Sandamirskaya, Y., Spencer,
nition is shared with the group of Eliasmith (2013). Their                J. P., & Schöner, G. (2012). A neuro-behavioral model
Neural Engineering Framework (NEF) enables spiking neu-                   of flexible spatial language behaviors. J Exp Psychol
ral networks to realize vector symbolic architectures (Gayler,            Learn, 38(6), 1490–1511.
2004). In this substantially different approach, concepts and       Logan, G. D., & Sadler, D. D. (1996). A computational
objects are represented by high-dimensional vectors through               analysis of the apprehension of spatial relations. In
an encoding and decoding stage and transient neural patterns              P. Bloom, M. Peterson, L. Nadel, & M. Garrett (Eds.),
computed by superposition and projection. DFT, in contrast,               Language and Space (pp. 493–529). Cambridge, USA:
is based on self-stabilized activation patterns defined over a            MIT Press.
few feature dimensions. Whether DFT and NEF can span                Lomp, O., Zibner, S. K. U., Richter, M., Rano, I., & Schöner,
the same range of cognitive phenomena—which approach is                   G. (2013). A software framework for cognition, em-
more consistent with neural reality is open for now.                      bodiment, dynamics, and autonomy in robotics: cedar.
   The current model is open to extension in various direc-               In V. Mladenov (Ed.), ICANN (pp. 475–482). Heidel-
tions, such as incorporating learning, scaling the number of              berg: Springer.
concepts, and building more complex sequences of process-           Madden, C., Hoen, M., & Dominey, P. F. (2010). A cog-
ing steps. Higher-order schemata (e.g., source-path-goal;                 nitive neuroscience perspective on embodied language
Lakoff & Johnson, 1999) may be realized similar to what we                for human-robot cooperation. Brain Lang, 112(3),
demonstrated here. Exploiting the working memory implicit                 180–8.
in our representations may enable us to link to relational men-     Regier, T., & Carlson, L. A. (2001). Grounding spatial lan-
tal models (Knauff, 2013).                                                guage in perception: an empirical and computational
                                                                          investigation. J Exp Psychol Gen, 130(2), 273–98.
                         References                                 Richter, M., Lins, J., Schneegans, S., Sandamirskaya, Y., &
                                                                          Schöner, G. (2014). Autonomous neural dynamics
Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P.                  to test hypotheses in a model of spatial language. In
       (1997). Deictic codes for the embodiment of cognition.             P. Bello & et al. (Eds.), 36th CogSci (pp. 2847–2852).
       Behav Brain Sci, 20(4), 723–42; discussion 743–67.                 Austin, TX: Cognitive Science Society.
Barsalou, L. W. (2008). Grounded cognition. Annu Rev                Richter, M., Sandamirskaya, Y., & Schöner, G. (2012).
       Psychol, 59, 617–45.                                               A robotic architecture for action selection and behav-
Bergen, B., & Chang, N. (2013). Embodied construction                     ioral organization inspired by human cognition. In
       grammar. In T. Hoffmann & G. Trousdale (Eds.), Ox-                 IEEE/RSJ IROS (pp. 2457–2464).
       ford Handbook of Construction Grammar. Oxford Uni-           Sandamirskaya, Y., & Schöner, G. (2010). An embodied ac-
       versity Press.                                                     count of serial order: how instabilities drive sequence
Berger, M., Faubel, C., Norman, J., Hock, H. S., & Schöner,              generation. Neural Networks, 23(10), 1164–79.
       G. (2012). The counter-change model of motion per-           Schneegans, S., & Schöner, G. (2012). A neural mechanism
       ception: an account based on dynamic field theory. In              for coordinate transformation predicts pre-saccadic
       ICANN (pp. 579–586).                                               remapping. Biol Cybern, 106(2), 89–109.
Doumas, L. A. A., & Hummel, J. E. (2012). Computa-                  Schneegans, S., Spencer, J. P., & Schöner, G. (2015). Inte-
       tional models of higher cognition. In K. J. Holyoak &              grating what and where: Visual working memory for
       R. G. Morrison (Eds.), Oxford Handbook of Thinking                 objects in a scene. In G. Schöner, J. P. Spencer, &
       and Reasoning. Oxford University Press.                            the DFT Research Group (Eds.), Dynamic thinking:
Eliasmith, C. (2013). How to build a brain: A neural archi-               A primer on dynamic field theory. Oxford University
       tecture for biological cognition. New York, NY: Ox-                Press.
       ford University Press.                                       Schöner, G., Spencer, J. P., & the DFT Research Group.
Feldman, J. A. (2006). From molecule to metaphor: A neural                (2015). Dynamic thinking: A primer on dynamic field
       theory of language. Cambridge, MA: MIT Press.                      theory. Oxford University Press.
Gayler, R. W. (2004). Vector symbolic architectures answer          Treisman, A., & Gelade, G. (1980). A feature-integration
       Jackendoff’s challenges for cognitive neuroscience.                theory of attention. Cognitive Psychol, 12(1), 97–136.
       CoRR, abs/cs/0412059.                                        van Hengel, U., Sandamirskaya, Y., Schneegans, S., &
Halford, G. S., Wilson, W. H., & Phillips, S. (2010). Rela-               Schöner, G. (2012). A neural-dynamic architecture
       tional knowledge: the foundation of higher cognition.              for flexible spatial language: intrinsic frames, the term
       Trends Cogn Sci, 14(11), 497–505.                                  “between”, and autonomy. In IEEE RO-MAN (pp. 150–
Knauff, M. (2013). Space to reason: A spatial theory of                   157).
       human thought. Cambridge, MA: MIT Press.
                                                                1936

