 Generalisable patterns of gesture distinguish semantic categories in communication
                                                        without language
                                          Gerardo Ortega (gerardo.ortega@mpi.nl) &
                                               Aslı Özyürek (asli.ozyurek@mpi.nl)
                                        Centre for Language Studies, Radboud University and
                                               Max Planck Institute for Psycholinguistics,
                                          Wundtlaan 1, 6525XD Nijmegen, The Netherlands
                             Abstract                                 that after stripping communication from a conventionalised
   There is a long-standing assumption that gestural forms are
                                                                      language, speakers of linguistically diverse languages
   geared by a set of modes of representation (acting,                converge in the same strategies to express information
   representing, drawing, moulding) with each technique               through their silent gestures (Goldin-Meadow, So, Ozyürek,
   expressing speakers’ focus of attention on specific aspects of     & Mylander, 2008a; Hall, Mayberry, & Ferreira, 2013;
   referents (Müller, 2013). Beyond different taxonomies              Langus & Nespor, 2010; Özçalişkan, Lucero, & Goldin-
   describing the modes of representation, it remains unclear         Meadow, 2016). It remains an empirical question whether
   what factors motivate certain depicting techniques over            individuals develop systematic strategies to make
   others. Results from a pantomime generation task show that         distinctions across different semantic domains when
   pantomimes are not entirely idiosyncratic but rather follow        expressing concepts in silent gesture. It is possible that
   generalisable patterns constrained by their semantic category.     gestures will be highly idiosyncratic and thus will be
   We show that a) specific modes of representations are              executed in different ways. Alternatively, it is possible that
   preferred for certain objects (acting for manipulable objects      individuals’ knowledge of the world may interact with the
   and drawing for non-manipulable objects); and b) that use and
   ordering of deictics and modes of representation operate in
                                                                      available techniques of gestural representations and as a
   tandem to distinguish between semantically related concepts        consequence, their silent gestures will display a high degree
   (e.g., “to drink” vs “mug”). This study provides yet more          of systematicity.
   evidence that our ability to communicate through silent            Communication without language and what it
   gesture reveals systematic ways to describe events and objects     reveals about the mind
   around us.                                                         Studies employing descriptive and empirical methods have
   Keywords: pantomime, gesture, action/object distinction,           found that language is a very important factor that shapes
   modes of representation, iconicity                                 many of our cognitive processes (Carrol, 1956; Flecken,
                                                                      Von Stutterheim, & Carroll, 2014; Majid & Burenhult,
                         Introduction                                 2014; Sapir, 1921). Despite the significant differences
Speakers have at their disposal several strategies to                 observed in the behaviours of speakers of linguistically
represent a referent with their gestures. If referring to a           diverse languages, most effects disappear when we look at
glass, for example, a speaker may choose to produce a                 their silent gestures. To date there are now several studies
gesture representing how it should be held, may describe its          showing that, regardless of their language, speakers
outline or perhaps would depict its cylindrical volume in a           converge in the strategies used to represent events in this
three-dimensional space. Despite most research focusing on            mode of manual communication.
the relationship between gesture and speech, the                         One of the most studied effects is the sequencing of
mechanisms responsible for the specific form that iconic              events and the agents that perform them (i.e., word order)
gestures adopt remains largely unknown. It is unclear for             during manual communication without speech. Languages
example whether the physical characteristics of the referent          vary considerably in the way they order the constituents of a
may play a role in gestural production and also whether               sentence. For instance, English favours a Subject-Verb-
people develop systematic strategies to make distinctions             Object sequence while Turkish prefers a Subject-Object-
between different semantic categories (i.e., between actions          Verb. One would expect that when expressing an event
and objects).                                                         through silent gesture, English speakers would favour an S-
   Research investigating the mechanisms responsible for              V-O order while Turkish speakers would follow an S-O-V
gestural production is paramount to better understand the             ordering, as they would in their native language. However,
cognitive system that allows efficient communication                  this is not the case as speakers of both languages coincide in
through the manual channel. A powerful tool to do so is by            an S-O-V sequencing of pantomimes. This effect has been
investigating communication in the absence of speech. By              proven to be quite robust as has been replicated in multiple
exploring individual’s communicative strategies through               occasions with speakers of very diverse languages (Goldin-
silent gestures, we open a window into humans’ internal               Meadow et al., 2008a; Hall et al., 2013; Langus & Nespor,
representations as well as into our capacity to convey                2010).
information in the most effective way. Studies have shown
                                                                    1182

   A similar effect has been observed in the description of        of attention or what is considered to be the relevant
motion events. English is a satellite-framed language and as       information. If a speaker, for instance, wants to emphasise
such encodes information of manner (e.g., run) and path            the specific way to handle an object he will use a depicting
(e.g., towards) in a clause. Turkish, in contrast, is a verb-      technique that expresses this information. If, in contrast, the
framed language often dropping information about the               main focus of his narrations is the form of an object he will
manner and expressing information about the path only              produce a gesture in which the hand configurations
(e.g., enter). When asked to express motion events, the co-        represent the shape of the referent. If the focus of his
speech gestures produced by speakers convey the same               narration is the three-dimensional form of an object he will
information as in their speech (i.e., English speakers express     probably describe the volume of the referent in space. In
manner and path in their gestures and Turkish speakers             other words, iconic gestural forms express visual
express only path) (Kita & Özyürek, 2003; Özyürek, Kita,           information specifically tailored to describe a unique event.
Allen, Furman, & Brown, 2005). However, the same                      Recent evidence has shown, however, that people’s
speakers default to a single strategy when they are                gestures are not entirely dependent on speakers’ focus of
expressing the same information in silent gesture. That is,        attention but rather are constrained by the affordances of the
when speakers are in this mode of communication, they no           referent. Using a referential paradigm, speakers were asked
longer align their gestural strategies with the information        to describe different objects from a visual prompt. Stimuli
conveyed in their speech but rather they resort to a strategy      were categorised as having high or low affordances (i.e., the
that is shared across speakers of different languages              degree to which objects allow to be manipulated). The
(Özçalişkan et al., 2016).                                         analysis of participants’ co-speech gestures showed that
   Together these studies demonstrate that while language is       objects with high affordances (e.g., wine glass) were often
an important factor that governs many of our cognitive             represented through an acting strategy. In contrast, items
behaviours, communication through silent gesture overrides         with low affordances (e.g., sink) were described using a
any linguistic influence and generates communication with          drawing strategy (Masson-Carro, Goudbeek, & Krahmer,
unique properties shared across speakers of different              2015).
languages. The similarities in patterns observed in                   This study suggests that the form of iconic gestures, at
pantomimes in different domains (i.e., word order, motion          least in co-occurrence of speech, are somewhat constrained
events) have been interpreted as silent gesture being a            by the affordances of the referent. A question that remains
window onto our internal representations (Özçalişkan et al.,       unanswered is whether the different representational
2016) and to our capacity to package information in the            techniques are also deployed systematically depending of
most communicatively effective manner (Goldin-Meadow,              the type of referent (i.e., manipulable and non-manipulable)
So, Ozyürek, & Mylander, 2008b; Hall et al., 2013).                in silent gesture. Further, it is remains an empirical question
   Another domain that has the potential to reveal a high          whether gesturers will resort to a different strategy to make
degree of systematicity in silent gestures is the                  distinctions between actions and objects, when there is no
representation of concepts across different semantic               speech to aid marking this differentiation.
categories. If silent gestures are also prone to a high degree
of systematicity across different individuals, it is possible to   Action-object distinctions in the visual modality
expect generalisable patterns in the modes of representation       Most of the investigations attempting to understand how the
used in specific semantic domains. This possibility has not        manual channel makes distinctions between actions and
yet been explored and remains an empirical question.               objects come from sign language research. The first studies
Manual modes of representation                                     exploring this issue found that in American Sign Language
There is general consensus that gestures may adopt at least        (ASL) pairs like HAMMER and TO-HAMMER are
four modes of representation. Acting (or handling) denotes         formally marked in the movement of the sign. While actions
how an object is manipulated (e.g., supination of a closed         have a continuous movement (e.g., TO-HAMMER), objects
fist for ‘key’). Representing (or instrument) uses the hand to     have a restrained, repeated movement (e.g., HAMMER)
recreate the form of an object (e.g., an extended index finger     (Supalla & Newport, 1986). It has also been reported that
to represent a ‘toothbrush’). Drawing (or tracing) describes       signs for actions tend to use a larger signing space and are
the outline of a referent (e.g., two index fingers tracing a       less marked through non-manual features (i.e., mouthings)
square to represent a ‘window’). Moulding depicts the three-       than signs for objects. These characteristics are not universal
dimensional characteristics of an object (e.g., cupped hands       given that different sign languages use different formal
describing the shape of a ‘vase’) (Müller, 2013). Beyond           features to mark these distinctions as has been documented
different taxonomies describing the modes of representation        for Australian Sign Language (Auslan) (Johnston, 2001) and
that gestures can adopt, it remains unclear what factors           Russian Sign Language (RSL) (Kimmelman, 2009).
motivate certain techniques over others.                           Interestingly, emerging sign languages do not seem to
   Müller (2013) proposes that during their narrations,            exhibit a clear mechanism to make such distinctions. Al-
speakers express in both the spoken and manual channel the         Sayyid Bedouin Sign Language (ABSL) is an emerging sign
relevant aspects of a scene or event. Importantly, the form        language that is gradually developing mechanisms to mark
of the gestures will depend primarily on the speakers’ focus       these distinctions more overtly.
                                                                 1183

   More recently, studies have shown that an effective                                 Methodology
mechanism to make distinctions between actions and
objects in the absence of speech is through the                  Participants
representation of the referent with different depicting
strategies (Padden et al., 2013). When users of different sign   Twenty native speakers of Dutch (10 females, age range:
languages were asked to represent vignettes of objects and       21-46, mean: 27 years) living in the area of Nijmegen, the
agents manipulating objects (actions), one can observe that      Netherlands took part in the study.
there is systematicity in their patterning of use. ASL and
ABSL signers tend to depict actions through acting               Procedure
depictions and objects through representing depictions. This     Participants were tested individually in a quiet room with
distinction is language-specific because users of an             two cameras from different angles recording their gestures.
unrelated sign language (New Zealand Sign Language)              They were told that the task consisted of generating a sign
favour the opposite patterns (i.e., acting for nouns and         or gesture that conveyed exactly the same meaning as the
representing for verbs). Interestingly, this study also          word on the screen. They were explicitly told two rules:
revealed that when asked to perform the same task, hearing       they were not allowed to speak or say the target word; and
people always converge in the same strategy to represent the     they could not point at any object present in the room (e.g.,
referent. That is, silent gesturers predominantly favour an      pointing at the table or at a wall). They were also told that
acting strategy for all their gestural depictions (actions and   their videos were going to be shown to another participant
objects alike) with few instances of representing depiction      who would have to guess the meaning of their gesture.
(Padden et al., 2013; Padden, Hwang, Lepic, & Seegers,              The stimuli consisted of a total of thirty words from three
2015). The notion of patterned iconicity postulates that sign    semantic categories: 10 actions with an object (e.g., to
languages may differ in the strategy used to make action-        phone, to smoke), 10 manipulable objects (e.g., telephone,
object distinctions, but they systematically exploit the         lighter), and 10 non-manipulable objects (e.g., pyramid,
available depicting possibilities (modes of representation) to   floor). Words were presented in black font on a white
make such differentiations. In contrast, gesturers default to    background in a different randomised list for each
the same strategy (acting) for both semantic categories.         participant. We decided against presenting the stimulus
   These studies show that sign languages alter the              materials with a visual cue so as to avoid prompting
phonological structure of the sign or their mode of              participants. Each trial started with a fixation cross in the
representation to distinguish actions from objects while         middle of the screen for 500 ms and this was followed by
pantomime overall defaults to the acting technique. A            the word participants had to represent with their gestures.
shortcoming of these studies is that they have limited their     The target word remained on the screen for 4000 ms during
observations to the techniques of depiction only within two      which participants had to come up with their gestural
semantic domains (tools and actions with tools). Given that      depictions. We limited the allowable time for gestural
gestures are holistic units without sub-lexical components       production so as to force participants to produce their most
(McNeill, 1992) individuals are unlikely to modify their         intuitive responses. Participants’ renditions were video
gestures’ kinematics to make semantic distinctions in a          recorded and later annotated using the software ELAN
similar way as signs. It is possible, however, that they may     (Lausberg & Sloetjes, 2009).
deploy additional strategies and bodily cues such as
pointing, showing, eye-gaze, and sequences of gestures to        Coding and data analysis
mark such distinctions.                                          For each target word, participants were observed to produce
                                                                 one gesture or sequences of gestures to depict the referent.
The Present Study                                                Following a strict coding criteria, all gestures produced for
In the present study we turn to the production of silent         each item were annotated. Each gesture or sequences of
gesture to investigate whether actions vs. objects and their     gestures would consist minimally of a preparation phase, a
affordances (i.e., manipulable vs, non-manipulable)              stroke and a (partial/full) retraction. Once all the gestures
modulate the strategy used by speakers to represent a            were isolated, we classified them according to their mode of
referent manually. More specifically, we ask 1) do               representation. Adapting the taxonomy developed by Müller
individuals use a specific depicting strategy for each           (2013), we categorised each gesture as follows: Acting if the
semantic category; and 2) what are the additional strategies     gesture represented how the referent is manipulated;
implemented to make semantic distinctions. To that end, we       representing if the hands were used to recreate the form of
implemented a pantomime generation task to a group of            an object; and drawing if participants used their hands to
Dutch speakers and described the gestures produced for a         describe the outline or the three-dimensional characteristics
list of words, the strategy they used for each semantic          of an object (note that we collapsed Muller’s drawing and
category, and the strategies they implemented to                 moulding categories into one). Aside from these modes of
differentiate actions from objects.                              representation, we also included the category deictic which
                                                                 consisted of pointing, showing and/or ostensive eye-gaze to
                                                                 elements of the gesture (see Figure 1 for examples). This is
                                                               1184

not a mode of representation per se but we decided to               transformed values, a one-way ANOVA revealed a
include this category in the analysis given the high                significant difference in the number of gestures produced
prevalence of this strategy to make semantic distinctions.          for each semantic category F(2,38) = 40.14, p < 0.0001, η2 =
                                                                    0.679. Pairwise comparisons after Bonferroni corrections
                                                                    revealed that the number of gestures produced for each
                                                                    category is significantly different from one another. Actions
                                                                    with objects was significantly lower than manipulable
                                                                    objects [t(19) = 8.39, p < 0.0001] and non-manipulable
                                                                    objects [t(19) = 5.24, p < 0.0001]. Non-manipulable objects
                                                                    elicited significantly fewer gestures than manipulable
                                                                    objects [t(19) = 3.98, p < 0.001].
                                                                       Table 1 shows the proportion of instances in which
                                                                    participants produced a single vs. multiple gestures to
                                                                    describe a referent across conditions. After removing passes
                                                                    and wrong targets (e.g., the target word ‘to sieve’ zeven
                                                                    often elicited the gesture ‘seven’ zeven) we can see that the
                                                                    vast majority of actions with tools elicited a single gesture,
                                                                    which often depicted how the action is executed (see Figure
                                                                    2 for the gesture ‘to-drink’). In contrast, manipulable objects
                                                                    were predominantly depicted with more than one gesture
                                                                    (see Figure 2 for the gesture ‘lighter’). Non-manipulable
                                                                    objects have a split with an almost equal proportion of items
                                                                    being depicted with a single or multiple gestures.
                                                                        Table 1: Proportion of concepts depicted with a single or
                                                                             multiple gestures across conditions (N=200)
    Figure 1: Examples of participants using different modes                                                           Non-
 of representation (Müller, 2013) and deictics. A) The acting                      Action with     Manipulable      manipulable
 technique represents how an object is manipulated (e.g., ‘to                        objects          objects          object
 drink’); B) in representing the hands recreate the shape and         Single          0.91             0.35             0.45
  form of an object (e.g., ‘telephone’); C) drawing traces the
                                                                      Multiple        0.09             0.61             0.46
    outline or three dimensional features of an object (e.g.,
‘table’), and D) deictics like points, showing or eye-gaze are        Wrong           0.01             0.05             0.10
used to highlight features of a gesture (e.g., pointing at a fist                     1.00             1.00             1.00
                  holding an imaginary mug).
                                                                       In order to explore whether the gestural forms are
   After the whole dataset was annotated and categorised            restricted by the affordances of the referent, we looked at
according to the gestures’ mode of representation, we               the mode of representation used across semantic categories
calculated the number of gestures produced per item per             (acting, representing or drawing). We focused on the
participant across the three semantic categories (actions with      instances in which a single gesture had been elicited to
an object, manipulable objects, and non-manipulable                 represent a concept. Table 2 shows that actions with objects
objects). Then, we calculated the proportion of the different       and manipulable objects use predominantly the acting
modes of representation per semantic category; and finally,         strategy (i.e., how an object is used). In contrast, non-
we calculated the proportion of decitics used in the three          manipulable objects resort more often to a drawing
different categories.                                               technique.
                                                                         Table 2: Proportion of concepts depicted with different
                            Results                                    modes of representations across conditions (one-gesture
                                                                                             depictions only)
We calculated the number of gestures produced per item per                                                               Non-
participant across the three semantic domains. We found                        Action w/object      Manipulable      manipulable
that actions with objects elicited the least number of                            (N=181)          object (N=70)    object (N=89)
gestures (range: 1-2 gestures; mean: 1.1 gestures, SD =            Acting:          0.86                0.81             0.20
0.12), followed by non-manipulable objects (range 1-4 Drawing                       0.00                0.01             0.57
gestures; mean: 1.49 gestures, SD = 0.33), and manipulable
objects elicited the highest number of gestures (range: 1-4Representing             0.14                0.17             0.22
gestures; mean: 1.77 gestures, SD = 0.39). On the arcsine                            1.0                 1.0              1.0
                                                                  1185

   Finally we looked at the instances in which participants     Crucially, we observed that manipulable objects elicited
included a deictic (i.e., pointing, showing, ostensive eye-     significantly more deictics than the other two categories.
gaze) to refer to a specific feature of their gesture. We       That is, participants would pantomime an event (e.g., eating
observed that out of the whole data set, actions with objects   soup) and then highlight part of this gesture with a deictic
(N=199) and non-manipulable objects (N=180) elicited a          (e.g., pointing at an imaginary spoon).
small proportion of deictics (0.04 and 0.09 respectively). In      The present data replicates earlier findings that speakers
contrast, manipulable objects (N=191) elicited significantly    tend to rely on the acting mode of representation in their
more deictics (0.25). For instance, to represent ‘lighter’      gestures (Padden et al., 2013, 2015; van Nispen, van de
participants would perform the action of lighting a cigarette   Sandt-Koenderman, Mol, & Krahmer, 2014). However, we
and then they would point at an imaginary lighter (See          also find that this mode of representation falls out of favour
Figure 2). Similarly, for ‘toothbrush’ they would pretend to    when the referent does not allow an effective way of
be brushing their teeth with a handling handshape (i.e.,        depiction. Gesturers seem to switch from one strategy to the
closed fist) and then they would raise it and show it to the    other depending on whether the referent allows for certain
camera.                                                         modes of representation (i.e., drawing is favoured in the
                                                                depiction of non-manipulable objects). These findings go in
                                                                line with recent research showing that the shape of an object
                                                                and the possible ways to interact with it modulate the form
                                                                of co-speech gestures (Masson-Carro et al., 2015). These
                                                                findings also resonate work showing that gesture production
                                                                relates to simulation of actions (Cook & Tanenhaus, 2009).
                                                                It is possible that speakers default to an acting strategy in
                                                                their gestures because they are simulations of their
                                                                experiences with objects. However, when an object does not
                                                                lend itself to a clear form of manipulation or the affordances
                                                                of the object does not permit the use an acting strategy,
                                                                individuals will turn to an alternative strategy to represent it.
                                                                   When we look at the different strategies adopted to make
                                                                distinctions between actions with objects and manipulable
      Figure 2: Examples of the modes of representation in      objects we see that gesturers do not align different modes of
  pantomimes across different semantic categories. Actions      representation to a specific category, as has been shown for
 with object were depicted with a single gesture representing   established or emerging sign languages (Johnston, 2001;
 how to manipulate an object (e.g., ‘to smoke’); manipulable    Kimmelman, 2009; Supalla & Newport, 1986). Instead, we
    objects were represented with the gesture of an action      see that gesturers complement their acting strategies with
    followed by a deictic (e.g., lighter was depicted with a    deictics to highlight the focus of their gesture. That is,
  pantomime of lighting a cigarette and then pointing at an     gesturers feel the communicative need to inform the
   imaginary lighter). Non-manipulable objects were more        addressee that the intended referent is not the action they are
      frequently depicted with drawing depictions (e.g.,        depicting, but the object at hand.
                          ‘pyramid’).                              This study adds to our current understanding of gesture
                                                                production, and the factors that drive their form. However,
                        Discussion                              we should be cautious about the generalisation of these
                                                                results given that most research in this domain has focused
In this study we investigated whether certain modes of          on the gestures produced by Dutch speakers. Future work
representations were typically bound to a specific semantic     should investigate whether speakers of different languages
domain and whether there were generalisable patterns            adopt the same strategies in silent gesture regardless of their
observed across different participants. We also looked into     native language. By looking at communication in the
the different strategies deployed to distinguish different      absence of speech we see gesturers devise strategies to
word types such as actions and objects. The results from a      express complex notions such as action-object distinctions.
pantomime elicitation task revealed that pantomimes show        These strategies operate in tandem with individuals’
systematic patterns when speakers are asked to represent a      knowledge of the world and the available strategies to
referent in silent gesture. Actions with objects tend to be     represent a referent. These strategies may be the raw
expressed with a single gesture using an acting mode of         materials of emerging sign languages and the foundations of
representation (i.e., representing how an object is             a conventionalised manual linguistic system.
manipulated). Non-manipulable objects in contrast tend to
be represented with a drawing strategy and with more than                            Acknowledgments
one gesture. Interestingly, manipulable objects elicited
significantly more gestures than the other two categories       This work was supported by a Veni grant by the
and the most common strategy used was also acting.              Netherlands Organisation for Scientific Research (NWO)
                                                                awarded to the first author. We would like to thank Deniz
                                                              1186

Cetin and Renske Schilte for their collaboration in the       Masson-Carro, I., Goudbeek, M., & Krahmer, E. (2015).
annotation of the data.                                             Can you handle this? The impact of object affordances
                                                                    on how co-speech gestures are produced. Language,
                        References                                  Cognition        and        Neuroscience,        1–11.
Carrol, J. B. (1956). Language, Thought and Reality:                doi:10.1080/23273798.2015.1108448
      Selected Writings of Benjamin Lee Whorf. Cambridge,     McNeill, D. (1992). Hand and mind: What gestures reveal
      MA: MIT Press.                                                about thought. Chicago: University of Chicago Press.
Cook, S. W., & Tanenhaus, M. K. (2009). Embodied              Müller, C. (2013). Gestural modes of representation as
      communication: speakers’ gestures affect listeners'           techniques of depcition. In C. Müller, A. Cienki, S.
      actions.       Cognition,       113(1),      98–104.          Ladewig, D. McNeill, & J. Bressem (Eds.), Body -
      doi:10.1016/j.cognition.2009.06.006                           Language - Communication: An International
Flecken, M., Von Stutterheim, C., & Carroll, M. (2014).             Handbook on Multimodality in Human Interaction
      Grammatical aspect influences motion event                    (pp. 1687–1701). Berlin: De Gruyter Mouton.
      perception: findings from a cross- linguistic non-      Özçalişkan, Ş., Lucero, C., & Goldin-Meadow, S. (2016).
      verbal recognition task. Language and Cognition,              Does language shape silent gesture? Cognition, 148,
      6(01), 45–78. doi:10.1017/langcog.2013.2                      10–18. doi:10.1016/j.cognition.2015.12.001
Goldin-Meadow, S., So, W. C., Ozyürek, A., & Mylander,        Özyürek, A., Kita, S., Allen, S. E. M., Furman, R., &
      C. (2008a). The natural order of events: how speakers         Brown, A. (2005). How does linguistic framing of
      of different languages represent events nonverbally.          events influence co-speech gestures?: Insights from
      Proceedings of the National Academy of Sciences of            crosslinguistic variations and similarities. Gesture,
      the United States of America, 105(27), 9163–8.                5(1), 219–240. doi:10.1075/gest.5.1.15ozy
      doi:10.1073/pnas.0710060105                             Padden, C., Hwang, S.-O., Lepic, R., & Seegers, S. (2015).
Goldin-Meadow, S., So, W. C., Ozyürek, A., & Mylander,              Tools for Language: Patterned Iconicity in Sign
      C. (2008b). The natural order of events: how speakers         Language Nouns and Verbs. Topics in Cognitive
      of different languages represent events nonverbally.          Science, 7(1), 81–94. doi:10.1111/tops.12121
      Proceedings of the National Academy of Sciences of      Padden, C., Meir, I., Hwang, S.-O., Lepic, R., Seegers, S., &
      the United States of America, 105(27), 9163–9168.             Sampson, T. (2013). Patterned iconicity in sign
      doi:10.1073/pnas.0710060105                                   language lexicons. Gesture, 13(3), 287–305.
Hall, M. L., Mayberry, R. I., & Ferreira, V. S. (2013).       Sapir, E. (1921). Language. New York: Harcourt, Brace &
      Cognitive constraints on constituent order: evidence          World.
      from elicited pantomime. Cognition, 129(1), 1–17.       Supalla, T., & Newport, E. L. (1986). How many sits in a
      doi:10.1016/j.cognition.2013.05.004                           chair? The derivations of nouns and verbs in
Johnston, T. (2001). Nouns and verbs in Australian sign             American Sign Language. In P. Siple (Ed.),
      language: An open and shut case? Journal of Deaf              Understanding language through sign language
      Studies and Deaf Education, 6(4), 235–257.                    research (pp. 91–132). New York: Academic Press.
      doi:10.1093/deafed/6.4.235                              van Nispen, K., van de Sandt-Koenderman, M., Mol, L., &
Kimmelman, V. (2009). Parts of speech in Russian Sign               Krahmer, E. (2014). Pantomime Strategies: On
      Language: The role of iconicity and economy. Sign             Regularities in How People Translate Mental
      Language and Linguistics, 12(2), 161–186.                     Representations into the Gesture Modality. In
      doi:10.1075/sl                                                Proceedings of the 36th Annual Conference of the
Kita, S., & Özyürek, A. (2003). What does cross-linguistic          Cognitive Science Society (CogSci 2014) (pp. 3020–
      variation in semantic coordination of speech and              3026). Austin, TX: Cognitive Science Society, Inc.
      gesture reveal?: Evidence for an interface
      representation of spatial thinking and speaking.
      Journal of Memory and Language, 48(1), 16–32.
      doi:10.1016/S0749-596X(02)00505-3
Langus, A., & Nespor, M. (2010). Cognitive systems
      struggling for word order. Cognitive Psychology,
      60(4), 291–318. doi:10.1016/j.cogpsych.2010.01.004
Lausberg, H., & Sloetjes, H. (2009). Coding gestural
      behavior with the NEUROGES--ELAN system.
      Behavior Research Methods, 41(3), 841–9.
      doi:dx.doi.org/10.3758/brm.41.3.841
Majid, A., & Burenhult, N. (2014). Odors are expressible in
      language, as long as you speak the right language.
      Cognition,              130(2),             266–270.
      doi:10.1016/j.cognition.2013.11.004
                                                            1187

