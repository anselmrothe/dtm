                     Social Cues Modulate Cognitive Status of Discourse Referents
                                            Kara Hawthorne (khawthor@olemiss.edu)
                               Department of Communication Sciences and Disorders, 304 George Hall
                                          University of Mississippi, University, MS 38677 USA
                                         Anja Arnhold (anja.arnhold@uni-konstanz.de)
                                               Department of Linguistics, Post Box D 186
                                          University of Konstanz, 78457 Konstanz GERMANY
                                               Emily Sullivan (esulliva@ualberta.ca)
                                 Department of Communication Sciences and Disorders, Corbett Hall
                                       University of Alberta, Edmonton, AB T6G 2G4 CANADA
                                             Juhani Järvikivi (jarvikiv@ualberta.ca)
                                             Department of Linguistics, 4-55 Assiniboia Hall
                                       University of Alberta, Edmonton, AB T6G 2E7 CANADA
                              Abstract
                                                                       Linguistic and Cognitive Biases
  We use visual world eye-tracking to test if a speaker’s eye
  gaze to a potential antecedent modulates the listener’s              Pronoun resolution is constrained by the relative salience or
  interpretation of an ambiguous pronoun. Participants listened        prominence of potential antecedents in the discourse
  to stories that included an ambiguous pronoun, such as “The          representation (e.g., Gordon, Grosz, & Gilliom, 1993;
  dolphin kisses the goldfish… He….” During the pre-                   Gundel, Hedberg, & Zacharski, 1993). Salience modulates
  pronominal context, an onscreen narrator gazed at one of the
  two characters. As expected, participants looked more at the
                                                                       the listener’s attention to potential referents and the degree
  subject character overall. However, this was modulated by the        to which s/he expects each referent to be talked about in the
  narrator’s eye gaze and the amount of time the participant           upcoming discourse (Ariel, 1990; Arnold, 1998).
  spent looking at the gaze cue. For trials in which participants         There are several linguistic and cognitive biases that
  attended to the narrator’s eye gaze for > 500ms, participants        rapidly affect referent salience during online pronoun
  were significantly more likely to interpret the pronoun as           processing. Linguistic factors include pronoun gender
  referring to the object if the narrator had previously looked at     (Arnold, Eisenband, Brown-Schmidt, & Trueswell, 2000),
  the object. Results suggest that eye gaze – a social cue – can
  temper even strong linguistic/cognitive biases in pronoun            verb type (Koornneef & Van Berkum, 2006; Pyykkönen &
  resolution, such as the subject/first-mention bias.                  Järvikivi, 2010), and parallel syntactic structure and
                                                                       syntactic function. Subjecthood, in particular, strongly
  Keywords: Ambiguous pronoun resolution, visual world                 increases the salience of a discourse entity (Järvikivi,
  paradigm, eye-tracking, reference, social cues, eye gaze.
                                                                       Hyönä, Bertram, & Van Gompel, 2005; Kaiser & Trueswell,
                                                                       2008).
                         Introduction                                     Perhaps the most widely known cognitive bias concerns
In this paper, we test if a social cue – the speaker’s eye gaze        the order in which the referents are introduced in the pre-
to potential referents – impacts the listener’s interpretation         pronominal context: first-mentioned entities are preferred
of ambiguous pronouns in a discourse context where there               over later-mentioned entities. This finding has been
are two characters who could serve as the pronoun’s                    replicated often since Gernsbacher & Hargreaves (1988;
antecedent. For example, in “The dolphin kisses the goldfish           e.g., Carreiras, Gernsbacher, & Villa, 1995), including in
behind the lake. He…” he could refer to either the dolphin             visual world studies of pronoun resolution (Arnold, et al.,
or the goldfish. Unlike previous work on the effect of a               2000; Järvikivi et al., 2005). Unlike in languages with freer
narrator’s attention on offline pronoun interpretation (Nappa          word order (Järvikivi et al., 2005; 2014), subjecthood and
& Arnold, 2014), we manipulate the narrator’s eye gaze                 first-mention are difficult to tease apart in English; we will
during the pre-pronominal context, which is the time period            primarily use the term subject bias in this paper,
in which speakers naturally look at their intended referent            acknowledging that order-of-mention and syntactic function
(Griffin & Bock, 2000). We test if the narrator’s eye gaze             both contribute to the observed effects.
modulates the listener’s assumptions about the narrator’s
focus of attention by using the visual world eye-tracking              Social Biases
paradigm to monitor online processing of ambiguous
                                                                       In addition to linguistic and cognitive effects, social cues
pronouns.
                                                                       impact discourse processing (e.g., Van den Brink et al.,
                                                                       2012; Jiang & Zhou, 2015) and conversational success. For
                                                                   562

example, two people engaged in a cooperative task are               social – in other words, cues that are not indicative of the
much slower when they are not able to use social cues such          speaker’s intentions or attention to discourse referents – do
as pointing, eye gaze, and head nodding (Clark & Krych,             not automatically impact language comprehension.
2004). Social cues also impact pronoun resolution: a                   In this paper, we ask if a speaker’s eye gaze during the
coreferential gesture at pronoun onset tempers the subject          pre-pronominal context influences how listeners interpret an
bias when each of the potential antecedents has previously          ambiguous pronoun.
been associated with a particular location in the speaker’s
gestural space (Goodrich & Hudson Kam, 2012).                                                          Methods
   Eye gaze is a salient way for a speaker to signal their
attention to the listener (Langton, Watt, & Bruce, 2000).           Participants
Interlocutors attend closely to each other’s faces (Argyle &        Participants were 86 native English speakers. Data from
Cook, 1976), and a speaker will even restart an utterance if        additional participants were excluded because of poor
the listener is not visually attending (Goodwin, 1981). In          calibration (n = 27), corrupted results file (n = 5), or
production, speakers fixate characters before they name             experimenter/equipment/participant error (n = 1/8/2).
them when describing an image (Griffin & Bock, 2000), so
attending to the speaker’s eye gaze could have processing           Materials
payoffs. For example, Hanna and Brennan (2007) report that
                                                                    Experimental stimuli consisted of 20 mini-stories involving
listeners can use a speaker’s gaze to figure out which object
                                                                    one animal character performing an action on the other at a
in a hidden array the speaker is referring to even before the
                                                                    particular location (Table 1), as well as a visual display
speaker has reached the point of linguistic disambiguation.
                                                                    (Figure 1). The visual display contained both characters, the
Moreover, the attentional effects of eye gaze are reflexive
                                                                    location, and a hedgehog narrator, who introduced herself as
and occur even when eye gaze is manipulated to not be an
                                                                    such at the beginning of the experiment (cf. Staudte &
informative cue (e.g., Firesen & Kingstone, 1998).
                                                                    Crocker, 2011 for evidence that listeners attend to an
   Only recently have researchers begun to explore the role
                                                                    artificial speaker’s gaze similarly to a human’s gaze).
of eye gaze in pronoun resolution. Nappa and Arnold (2014)
tested the influence of several social cues in the moment                                        Table 1: Example mini-story.
when the pronoun is heard. They found that when a narrator                   The letters (a)-(d) represent the four experimental conditions.
turns her head and looks at a character while producing an             Sentence	      Audio	                                   Narrator’s	  Gaze	  
ambiguous pronoun (with or without a pointing gesture),                Intro (a,b)     There are the dolphin and the goldfish.   forward
listeners were more likely to interpret the pronoun as the             Intro (c,d)     There are the goldfish and the dolphin.   forward
character being deictically cued.                                      Action (a)      The dolphin kisses the goldfish           dolphin (subject)
   When a speaker turns to look at a character right at the            Action (b)      The dolphin kisses the goldfish           goldfish (object)
moment of pronoun production, it is perhaps not surprising             Action (c)      The goldfish kisses the dolphin           dolphin (object)
that it influences pronoun interpretation, since the speaker is        Action (d)      The goldfish kisses the dolphin           goldfish (subject)
directly highlighting a potential referent. However, gaze              Location        behind the lake.                          forward
cues are typically less overt, and they usually occur during           Pronoun         He wants to play on the playground.       forward
the preceding discourse context rather than during the                 Probe           Who wants to play on the playground?      n/a
pronoun itself. Griffin and Bock (2000) report that speakers
look at a character close to a full second before referring to
it with a full noun phrase. Speakers look at the referent
before producing a pronoun as well, though at a somewhat
reduced rate (van der Meulen, Meyer, & Levelt, 2001).
   While eye gaze serves as a visual cue that increases the
salience of one potential referent, recent evidence suggests
that not all visual cues have such an effect on ambiguous
pronoun interpretation. Arnold and Lao (2015, Exp. 2) had
participants listen to stories of two characters, e.g., “Birdy
picked apples with Doggy near the farmhouse. He….” while            Figure 1. Example visual display. The animal in the center of each image is
they briefly (200ms) flashed a halo around one of the               the narrator throughout the experiment. The image on the left appeared
                                                                    during the intro, location, and pronoun sentences (see Table 1). The image
characters. This cue did not affect participants’ gaze              on the right, in which the narrator is gazing at the goldfish, appeared only
behaviour or their antecedent selection preferences. A              during the action sentence. During the probe question, only the two animal
further study (Järvikivi & Pyykkönen-Klauck, submitted),            characters (e.g., the dolphin and the goldfish) appeared on the screen.
shows that absence of one of the referents at the pronoun
onset (i.e., if a potential referent had walked out of the          Each story began with an introduction to the two characters.
visual scene) did not affect adult listeners’ pronoun               The subject of the action sentence was always named first to
resolution preferences. This suggests that visual cues that         control for effects of the first-mention and subject biases.
are coincidental with linguistic information but that are not       Next was the action sentence, in which one animal
                                                                    performed an action on the other. This sentence was
                                                                563

manipulated in two ways – which animal was the subject of            to in the pronoun sentence by pressing a key on the
the sentence (e.g., dolphin or goldfish) and which animal            keyboard.
was gazed at by the narrator (subject or object) – to create
four versions of the story (a-d, Table 1). After the action, the     Equipment
narrator’s gaze returned to the front for the location               Participants were tested on either an EyeLink 1000 or
sentence; the location was mentioned to draw participants’           1000+ eye-tracker. The experiment was run using
eyes away from the animals before the ambiguous pronoun              Experiment Builder (SR-Research Ltd) and a 500 Hz
in the pronoun sentence. Finally, the participants heard a           sampling rate. Stimuli were played through Bose SoundLink
new voice asking for an overt judgment on the referent of            Mini speakers, and testing was done in a quiet room.
the pronoun (the probe sentence).
   An additional ten mini-stories were recorded as filler            Design
items. The fillers were structurally the same as the
                                                                     Each participant was assigned to one of four experimental
experimental stories, except they did not have an ambiguous
                                                                     lists, with twenty experimental and ten filler trials per list.
pronoun. Instead, one of the characters was referred to by
                                                                     Each list included each story in one of the four conditions
name. The named animal was the subject of the action
                                                                     (e.g., 2a-d, Table 1). The lists were counterbalanced, so that
sentence half of the time and the object of the action
                                                                     the narrator’s gaze was on the subject and object of the
sentence half of the time.
                                                                     action sentence for an equal number of trials. In order to
   The stories were recorded by a 21-year-old female, and
                                                                     maximize the number of trials in which the participant
the probe questions were recorded by a 19-year-old male.
                                                                     noticed the narrator’s change of eye gaze during the action
Both were native English speakers. The speakers were asked
                                                                     sentence, we included all eligible participants, even though
to read the stories in a happy, animated voice, and care was
                                                                     the number of participants on each list varied from 20-25.
taken that neither animal character was prosodically more
prominent. Recordings were done in a sound-attenuated
booth using a head-mounted CountryMan microphone and
                                                                                                Results
Korg MR-2000S Studio Recorder. Each story was recorded               Offline responses and eye-tracking data from all 1718 trials
individually, and a 1-second pause was inserted at the               were analyzed with linear mixed effects modelling, using R
sentence boundaries.                                                 (R Core Team, 2013) and the glmer and lmer functions from
   The visual displays were created using Adobe Photoshop            the package lme4 (Bates, Maechler, & Bolker, 2012). For all
CS5.1 software. Most of the images were previously used in           analyses, the best fit model was determined using
Pyykkönen et al. (2010) and Järvikivi et al. (2014) and              backwards stepwise model comparisons. Models were
others were drawn by hand to match the style of the existing         compared with likelihood ratio tests; only factors that
images. Each image fit into an area of 426 by 341 pixels.            significantly improved the model fit at a p < .05 level were
The images were counterbalanced, such that the subject               retained for the fixed and random intercept effects (see
appeared on the left side of the screen half of the time.            Baayen, 2008, Bates et al. 2015). Random slopes were
                                                                     checked but omitted from our final analyses due to
Procedure                                                            convergence errors.
The session began with a brief familiarization to the animals           Gazed at role (whether the narrator looked to the subject
using Microsoft Office PowerPoint. Each animal was                   or object character) and earlier attention to the narrator’s
displayed one at a time, and the participant was asked to            gaze (how long the participant looked at the narrator during
label it. If the participant provided a label different from the     the action sentence) were the factors of interest. Trials were
one used in the mini stories, s/he was told the label that           considered to have no attention to the narrator if the
would be used in the experiment.                                     participant looked at the narrator < 200ms during the action
   The experiment used eye-tracking and the visual world             sentence (57% of trials). If the participant looked at the
paradigm (Tanenhaus, Spivey-Knowlton, Eberhard, &                    narrator between 200 and 500ms during the action sentence,
Sedivy, 1995; Arnold et al., 2000). The experimenter first           this was considered short attention (25% of trials), while
calibrated the eye-tracking equipment. Next, the narrator            looks longer than 500ms were considered long attention
hedgehog appeared at the center of the screen and                    (18%). Results from offline responses and eye-tracking
introduced herself by saying “Hi, my name is Hailee! I’m             analyses are summarized in Tables 2 and 3. For the
going to tell you some stories about the animals you just            intercept, “no,” “short,” and “long” indicate duration of
saw. Are you ready?” This was done so that it was clear that         fixation to the narrator and “S” and “O” indicate whether
the hedgehog was the one telling the stories.                        the narrator was gazing at the subject or object animal. The
   A drift correction was performed before each trial to             intercept values were releveled and models were re-run to
ensure that the equipment remained properly calibrated.              examine all possible comparisons. Redundant comparisons
Then the participant heard one of the stories while his or her       have been omitted.
eye gaze was tracked. After the probe question, the
participant was asked to indicate which animal was referred
                                                                 564

Offline Responses                                                                looking at the narrator and location. Data points in which
The dependent variable for the offline analysis was whether                      the participant did not look at either the subject or object
the participant selected the subject or object character in                      during the time window were dropped.
response to the probe question. Responses are presented in                          There were no three way interactions of time by gazed at
Figure 2.                                                                        role by earlier attention to narrator’s gaze (p-values > .1).
                                                                                 We next tested a model with all 2-way interactions. There
                                                                                 were no gazed at role by attention to narrator’s gaze or time
                                                                                 by gazed at role interactions, so these were checked and
                                                                                 removed one at a time (p-values > .1).
Figure 2. Percentage of object and subject responses, split by participants’
earlier attention to the narrator.
   Data were evaluated with binomial generalized linear
mixed effects models. A model containing an interaction
between gazed at role (subject versus object) and earlier
attention to narrator’s gaze (long, short, no) significantly
outperformed a model containing only main effects (χ2(1) =
7.43, p = .024), so the full model was retained as the final
model. When comparing the short versus no attention to
narrator trials, there were no interaction or simple effects (p-
values > .1). Results from the long versus short attention to
narrator trials are presented in Table 2. If the participant had
previously attended for a long time to the narrator while the
narrator was looking to the object, s/he was significantly
more likely to make an “object” response than if the narrator
was looking at the subject or if the participant had only paid                   Figure 3. Proportion of participant looks to the interest areas from pronoun
                                                                                 onset.
short attention to the narrator.
                                                                                    The final model contains a main effect of gazed at role,
      Table 2. Response results for the model: response ~ GazedAtRole*
         EarlierAttentnToNarr + (1|participant) + (1| item) + (1|trial).
                                                                                 with participants spending less time looking at the subject
                                                                                 relative to the subject plus object for trials in which the
   Offline Responses: Short vs. Long Attention to Narrator
                                                                                 narrator had previously gazed at the object (Figure 3). This
   Fixed Effect             Intercept Estimate (SE) z- value p-value
                                                                                 suggests that the narrator’s earlier eye gaze cue influenced
   2-way interaction        short, S -2.05 (.87)        -2.34     .019
                                                                                 participants’ eye movements after the onset of the
   GazedAtRole              short, S .060 (.62)         -.10      n.s
   GazedAtRole              long, S   -1.99 (.62)       -3.22     .0013
                                                                                 ambiguous pronoun. The model also contains an interaction
   EarlierAttentnToNarr short, S .34 (.69)              .49       n.s            of time by earlier attention to the narrator’s gaze, suggesting
   EarlierAttentnToNarr short, O -1.71 (.55)            -3.14     .0017          that the participants’ previous attention or lack of attention
                                                                                 to the narrator influenced the timing with which they settled
Eye-Tracking Analysis                                                            on a referent for the ambiguous pronoun.
                                                                                    The effects of time for no, short, and long attention to
Eye-tracking data for each trial were aggregated into 300ms                      narrator’s gaze are presented in Table 3. Simple effects of
windows, starting at the onset of the ambiguous pronoun                          attention to narrator are not included, since they were not
through 1500ms post-onset. Aggregation mitigates the auto-                       significant at any time window. However, looking behavior
correlation that is inherent to time-course data. Time                           across time was different across these conditions. For trials
window was included as a fixed factor in the models, along                       with no earlier attention to the narrator, participants looked
with gazed at role (subject vs. object) and previous attention                   increasingly more at the subject through the 300-599ms
to the narrator’s gaze cue (long, short, no). The dependent                      window, then leveled off. For trials with short attention to
variable was the logit transformed proportion of looks to the                    the narrator, looks to the subject leveled off even earlier,
subject divided by the proportion of looks to the subject plus                   with no significant differences in proportion looks to the
object. This allows us to look at the strength of the subject                    subject for 300-599ms with any subsequent time windows.
bias while controlling for different amounts of time spent                       The proportion of looks to the subject increased most slowly
                                                                             565

for trials with long earlier attention to the narrator, with                                                    Discussion
significant differences between 600-899ms and the
                                                                                      Results suggest that a narrator’s eye gaze to a character
subsequent time windows.
                                                                                      impacts the listener’s resolution of a subsequent ambiguous
Table 3. Response results for the model: Looks to S/(S+O) ~ GazedAtRole               pronoun, but that the effect is modulated by the listener’s
+ EarlierAttentnToNarr *Time + (1|participant) + (1| item) + (1|trial).               attention to the narrator’s gaze. As predicted, when the
                                                                                      narrator looked at the character that served as the
Eye-Tracking Results: Effects of GazedAtRole for adjacent time
windows, split by degree of attention to the narrator’s earlier gaze cue
                                                                                      grammatical object, the listener was more likely to interpret
Fixed Effect                    Intercept            Est. (SE) t-value                the pronoun as referring to the object, but only if the
GazedAtRole                     long                 -.18 (.09) -2.03                 participant had attended closely to the narrator’s gaze cue.
             NO	  ATTENTION	  TO	  NARRATOR’S	  GAZE	  CUE	                     In contrast to previous work, in which the narrator both
Time (vs 300-599ms)	           0-299ms	            .50 (.17)	   2.85*	            looked at and turned her head toward one of the referents
Time (vs 600-899ms)	           0-299ms	            .78 (.17)	   4.51*	  
Time (vs 900-1199ms)	          0-299ms	            .94 (.17)	   5.46*	            during production of the pronoun itself (Nappa & Arnold,
Time (vs 1200-1500ms)	         0-299ms	            .99 (.17)	   5.71*	            2014), we found (1) that eye gaze alone and (2) that an eye
Time (vs 600-899ms)	           300-599ms	          .39 (.17)	   1.68	             gaze cue that occurs during the pre-pronominal discourse
Time (vs 900-1199ms)	          300-599ms	          .45 (.17)	   2.65*	            context are sufficient to temper the subjecthood and first-
Time (vs 1200-1500ms)	         300-599ms	          .50 (.17)	   2.92*	  
Time (vs all later windows) 600-899ms                --               all < 2
                                                                                      mention biases. The latter is an important finding, since the
Time (vs 1200-1500ms)	         900-1199ms	         .05 (.17)	   0.30	             timing with which the narrator gazed at one of the potential
          SHORT	  ATTENTION	  TO	  NARRATOR’S	  GAZE	  CUE	                     referents in the present study closely approximates the time
Time (vs 300-599ms)	           0-299ms	            .88 (.30)	   2.96*	            period in which speakers are likely to provide such cues in a
Time (vs 600-899ms)	           0-299ms	            1.25 (.29)	   4.35*	           real discourse context (Griffin & Bock, 2000). Thus, a
Time (vs 900-1199ms)	          0-299ms	            1.16 (.29)	   3.99*	  
Time (vs 1200-1500ms)	         0-299ms	            1.21 (.28)	   4.24*	  
                                                                                      social cue – the speaker’s gaze to a potential referent before
Time (vs all later windows)	   300-599ms	          --	             all < 2	       the listener even hears the pronoun – can modulate other
Time (vs all later windows)	   600-899ms	          --	             all < 2	       linguistic and cognitive biases at the point of pronoun
Time (vs 1200-1500ms)	         900-1199ms	         .05	  (.28)	   0.18	          disambiguation.
           LONG	  ATTENTION	  TO	  NARRATOR’S	  GAZE	  CUE	  
Time (vs 300-599ms)	           0-299ms	            .56 (.43)	   1.32	  
                                                                                         Another notable finding relates to attention to the narrator
Time (vs 600-899ms)	           0-299ms	            .85 (.42)	   2.02*	            herself after the pronoun was produced. The longer the
Time (vs 900-1199ms)	          0-299ms	            1.66 (.41)	   4.02*	           participant attended to the narrator during the time when her
Time (vs 1200-1500ms)	         0-299ms	            1.82 (.41)	   4.48*	           eyes were cueing one of the potential referents, the more the
Time (vs 600-899ms)	           300-599ms	          .28 (.41)	   .69	  
Time (vs 900-1199ms)	          300-599ms	          1.10 (.40)	   2.71*	  
                                                                                      participant continued to look at the narrator after the onset
Time (vs 1200-1500ms)	         300-599ms	          1.25 (.40)	   3.15*	           of the pronoun, perhaps anticipating further informative eye
Time (vs 900-1199ms)	          600-899ms	          .81 (.39)	   2.06*	            movements that could help disambiguate it. Indeed, for
Time (vs 1200-1500ms)	         600-899ms	          .97 (.39)	   2.49*	            trials in which the participant paid long attention to the
Time (vs 1200-1500ms)	         900-1199ms	         .16 (.38)	   0.41	  
                                                                                      narrator’s gaze cue, the participant looked even longer at the
                                                                                      narrator after pronoun onset if the narrator had previously
   Visual inspection of Figure 3 reveals a potential effect of                        looked at the object (vs. the subject), even though the
earlier attention to the narrator on the proportion looks to                          location was the last item mentioned before the pronoun.
the narrator after the pronoun onset, despite the fact that the                       Thus, participants appear to particularly look to the narrator
location was mentioned last before the pronoun. To examine                            for ‘help’ when she had gazed at the object and the
this effect, we conducted a secondary analysis in which the                           participant was therefore more likely to be entertaining the
dependent variable was logit transformed proportion looks                             object as a potential referent for the pronoun.
to the narrator, aggregated into 300ms windows.                                          The present results, together with other work on social
   There were several three way interactions of time by                               and other visual cues to pronoun resolution (Arnold & Lao,
gazed at role by earlier attention to the narrator (t-values >                        2015; Järvikivi & Pyykkönen-Klauck, submitted; Nappa &
2), so the 2-way interactions of gazed at role by earlier to                          Arnold, 2014) suggest that visual context impacts discourse
narrator were tested separately for each time window. There                           processing, but only when that visual information is relevant
were no 2-way interactions or effects of gazed at role for the                        to language comprehension. In that vein, many studies have
0-1199ms time windows (all t-values < 2). The proportion                              demonstrated that the visual environment can help to rapidly
of looks to the narrator during each of those time windows                            resolve temporary referential ambiguities in sentences, even
was greater the longer the participant had attended to the                            overriding linguistically-based parsing preferences (e.g.,
narrator during the action sentence (long > short > no). For                          Tanenhaus et al., 1995; Chambers, Tanenhaus, &
the 1200-1500ms window, there was a 2-way interaction of                              Magnuson, 2004; Knoeferle & Crocker, 2006). The present
gazed at role by earlier attention to the narrator. Participants                      study shows that listeners are sensitive to visual cues in
who had previously paid long attention to the narrator while                          reference resolution as well, at least when the cue is social
the narrator gazed at the object looked more to the narrator                          (i.e., eye gaze) and is therefore potentially informative about
during the 1200-1500ms window than if the narrator had                                the speaker’s intentions. Social visual cues can increase the
looked at the subject.                                                                salience of a potential referent even when the cue occurs in
                                                                                      the pre-pronominal discourse context.
                                                                                  566

                    Acknowledgments                               Järvikivi, J., Van Gompel, R. P. G., Hyönä, J., & Bertram,
                                                                     R. (2005). Ambiguous pronoun resolution: Contrasting
Thank you to University of Alberta Support for the
                                                                     the first-mention and subject-preference accounts. Psych.
Advancement of Scholarship (SAS/EFF) and Undergraduate
                                                                     Science, 16, 260-264.
Research Initiative (URI) for funding that supported this
                                                                  Järvikivi, J., & Pyykkönen- Klauck (submitted). Visual
project. Thank you also to Lauren Rudat and the other
                                                                     context influences the representation of discourse
members of the Centre for Comparative Psycholinguistics.
                                                                     referents in 4-year-olds.
                                                                  Järvikivi, J., Pyykkönen-Klauck, P., Schimke, S., Colonna,
                        References                                   S., & Hemforth, B. (2014). Information structure cues for
Argyle, M. & Cook, M. (1976). Gaze and mutual gaze.                  4-year olds and adults: Tracking eye movements to
  Cambridge, MA: Cambridge University Press.                         visually presented anaphoric referents. Language,
Arnold, J. E. (1998). Reference form and discourse patterns          Cognition and Neuroscience, 29, 877- 892.
  (Doctoral dissertation). Stanford University, California.       Jiang, X. & Zhou, X. (2015). Who is respectful? Effects of
Arnold, J.E., Eisenband, J.G., Brown-Schmidt, S., &                  social context and individual empathic ability on
  Trueswell, J.C. (2000). The rapid use of gender                    ambiguity resolution during utterance comprehension.
  information: Evidence of the time course of pronoun                Frontiers in Psychology, 6, 1588.
  resolution from eyetracking. Cognition, 76, B13–B26.            Kaiser, E. & Trueswell, J. C. (2008). Interpreting pronouns
Arnold, J. E. & Lao, S. Y. C. (2015). Effects of                     and demonstratives in Finnish: Evidence for a form-
  psychological attention on pronoun comprehension.                  specific approach to reference resolution. Language and
  Language, Cognition and Neuroscience, 30(7), 832-852.              Cognitive Processes, 23, 709-748.
Bates, D., Maechler, M., & Bolker, B. (2012). lme4: Linear        Konopka, A. E. (2012). Planning ahead: How recent
  mixed-effects models using S4 classes. R package version           experience with structures and words changes the scope
  0.999999-0. http://CRAN.R-project.org/package=lme4.                of linguistic planning. J. of Memory and Language, 66(1),
Bates, D., Kliegl, R., Vasishth, S., & Baayen, R. H. (2015).         143-162.
  Parsimonious       Mixed     Models,    Retrieved      from     Koornneef, A. W. & Van Berkum, J. J. A. (2006). On the
  http://arxiv.org/abs/1506.04967                                    use of verb-based implicit causality in sentence
Carreiras, M., Gernsbacher, M. A., & Villa, V. (1995). The           comprehension: Evidence from self-paced reading and
  advantage of first mentioned in Spanish. Psychonomic               eye tracking. J. of Memory and Language, 54, 445-465.
  Bulletin Review, 2, 124-129.                                    Kuznetsova, A., Brockhoff, P.B., & Christensen, R.H.B.
Crawley, R., Stevenson, R., & Kleinman, D. (1990). The               (2015). lmerTest: Tests in linear mixed effects models. R
  use of heuristic strategies in the interpretation of               package version 2.0-29.
  pronouns. J. of Psycholinguistic Research, 19, 245-264.         Langton, S. R., Watt, R. J., & Bruce, V. (2000). Do the eyes
Friesen, C. K. & Kingstone, A. (1998). The eyes have it!             have it? Cues to the direction of social attention. Trends
  Reflexive orienting is triggered by nonpredictive gaze.            in Cognitive Sciences, 4(2), 50-59.
  Psychonomic Bulletin and Review, 5(3), 490-495.                 Nappa, R. & Arnold, J. E. (2014). The road to
Gernsbacher, M. A., & Hargreaves, D. J. (1988). Accessing            understanding is paved with the speaker’s intentions:
  sentence participants: The advantage of first mention. J.          Cues to the speaker’s attention and intentions affect
  of Memory and Language, 27, 699–717.                               pronoun comprehension. Cognitive Psych., 70, 58-81.
Goodrich Smith, W. & Hudson Kam, C. L. (2012).                    Pyykkönen, P. & Järvikivi, J. (2010). Activation and
  Knowing ‘who she is’ based on ‘where she is’: The effect           persistence of implicit causality information in spoken
  of co-speech gesture on pronoun comprehension.                     language comprehension. Experimental Psych., 57, 5-16.
  Language and Cognition, 4(2), 75-98.                            Snodgrass, J. G. & Yuditsky, T. (1996). Naming times for
Goodwin, C. (1981). Conversational organization:                     the Snodgrass and Vanderwart pictures. Behavior
  Interaction between speakers and hearers. New York:                Research Methods, Instruments, & Computers, 28(4),
  Academic Press.                                                    516-536.
Gordon, P. C., Grosz, B. J., & Gilliom, L. A. (1993).             Staudte, M. & Crocker, M. W. (2011). Investigating joint
  Pronouns, names, and the centering of attention in                 attention mechanisms through spoken human–robot
  discourse. Cognitive Science, 17, 311-347.                         interaction. Cognition, 120(2), 268-291.
Griffin, Z. M., & Bock, K. (2000). What the eyes say about        Van den Brink, D., Van Berkum, J. J., Bastiaansen, M. C.,
  speaking. Psych. Science, 11(4), 274-279.                          Tesink, C. M., Kos, M., Buitelaar, J. K., & Hagoort, P.
Gundel, J. K., Hedberg, N., & Zacharski, R. (1993).                  (2012). Empathy matters: ERP evidence for inter-
  Cognitive status and the form of referring expressions in          individual differences in social language processing.
  discourse. Language, 69, 274-307.                                  Social Cognitive and Affective Neuroscience, 7(2), 173-
Hanna, J. E. & Brennan, S. E. (2007). Speakers’ eye gaze             183.
  disambiguates referring expressions early during face-to-       Van der Meulen, F. F., Meyer, A. S., & Levelt, W. J.
  face conversation. J. of Memory and Language, 57(4),               (2001). Eye movements during the production of nouns
  596-615.                                                           and pronouns. Memory & Cognition, 29(3), 512-521.
                                                              567

