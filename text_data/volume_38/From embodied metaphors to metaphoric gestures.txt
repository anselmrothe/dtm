                             From embodied metaphors to metaphoric gestures
                                              Margot Lhommet (m.lhommet@neu.edu)
                                                 Stacy Marsella (s.marsella@neu.edu)
                                               College of Computer and Information Sciences
                                                            Northeastern University
                                                            Boston, MA 02115 USA
                               Abstract                                  domains to concrete domains (see for example Grady’s list of
                                                                         Primary Metaphors (1997).
      Humans turn abstract referents and discourse structures               There is evidence that these conceptual metaphors also
      into gesture using metaphors. The semantic relation be-
      tween abstract communicative intentions and their phys-            shape gestures (see (Cienki, 2008) for a review). Our previ-
      ical realization in gesture is a question that has not been        ous work proposed a computational model that maps commu-
      fully addressed. Our hypothesis is that a limited set of           nicative intentions to two highly expressive image schemas
      primary metaphors and image schemas underlies a wide
      range of gestures. Our analysis of a video corpus sup-             (C ONTAINER and O BJECT) that are common to a wide range
      ports this view: over 90% of the gestures in the corpus are        of metaphoric gestures (Lhommet & Marsella, 2014). Al-
      structured by image schemas via a limited set of primary           though it uses only two image schemas and a restricted set
      metaphors. This analysis informs the extension of a com-
      putational model that grounds various communicative in-            of metaphors to guide the mapping, this model supports the
      tentions to a physical, embodied context, using those pri-         generation of gestures that convey a wide range of commu-
      mary metaphors and image schemas. This model is used               nicative intentions. In particular, gestures communicate in-
      to generate gesture performances for virtual characters.
                                                                         formation about the referent (e.g. depicting a big object to
      Keywords: embodied cognition; gesture; metaphor;                   suggest an important idea) and structure the discourse itself
      nonverbal behavior; human-computer interaction
                                                                         (e.g. contrasting facts by assigning them opposite locations
                                                                         in space). This suggests that it is possible to model a large
                           Introduction                                  range (if not the whole range) of gestures using a restricted
Metaphoric gestures turn abstract ideas and discourse struc-             set of image schemas and primary metaphors.
tures into the visual and the embodied. For example, holding                More specifically, such a model of gesture generation:
or weighting a large object can suggest the importance of an                – allows for a large space of communicative intentions to
idea. Metaphoric gestures also structure the discourse, for                    be mapped to a comparatively small space of concrete
example by putting ideas in distinct locations in the physi-                   elements (image schemas).
cal space to allow referring to them later on or to emphasize               – can convey complex communicative intentions via com-
their difference. The chosen locations can have a metaphor-                    position over this small set of image schemas.
ical meaning as well: for example, events located on the left               – guides how properties in abstract propositions (such as
are understood as being in the past while events on the right                  “important idea”) can be conveyed by manipulations of
are in the future (Calbris, 2011).                                             the gesture property (size of the gesture).
   When modeling how speakers select gestures to realize a                  In this paper, we systematically investigate and extend the
communicative intention, a key challenge arises: how can                 coverage of our previous model by using a corpus to study
gestures, that are actions inherently specified in physical              how communicative intentions are mapped to gesture ele-
terms such as size, location or path, communicate meaningful             ments via primary metaphors. The first section gives an
information about abstract elements that do not have physical            overview of the computational model. The second section
features? In other words, where does the semantic relation               presents the analysis of the corpus. We then describe the im-
between abstract referents (such as an important idea) and               plementation by focusing on two examples. Finally, we con-
their gesture portrayal (a big object) comes from?                       clude by mentioning the advances and limits of this approach
   There is evidence that the human conceptual system is em-             as well as discussing future work.
bodied and structured by metaphors (Tversky & Hard, 2009).
We understand abstract concepts by mapping them to image                                             Model
schemas (embodied experiential concepts) (Lakoff & John-                 This work builds on a previous model of gesture generation
son, 1980). Reasoning processes are actions taken on these               that maps communicative intentions (CIs) to a mental space
image schemas (Barsalou, 2009). For example, we make                     structured by image schemas (Lhommet & Marsella, 2014).
sense of the sentence “the price rises” by our understanding             This mapping is guided by Grady’s list of primary metaphors
that an increase in quantity often correlates with an increase           (1997), referred to as PMs in the rest of this paper.
in height. Lakoff and Johnson (1980) and other researchers                  This process is illustrated in Figure 1. First, a CI is
have studied how conceptual metaphors are reflected on the               grounded, i.e. mapped to image schemas that have physical
verbal channel via verbal metaphors. One outcome of their                properties using PMs. These properties then inform the gen-
research is lists of conventional metaphors that link abstract           eration of a gesture plan that conveys the desired meaning.
                                                                     788

                                                                                                     Corpus
                                                                        To help quantify the PMs and image schemas that play a sig-
                                                                        nificant role in the generation of metaphoric gestures, we cre-
                                                                        ated an annotated corpus of human gesturing. Several criteria
                                                                        were taken into account: 1. the gesturers should be “good
                                                                        gesturers”, 2. have both of their hands visible and free, 3. the
Figure 1: Our model maps CI to concrete elements using                  discussion topic should be abstract to elicit metaphoric ges-
PMs to generate gestures.                                               tures and 4. the discussion should be improvised instead of
Communicative Intentions Gesture can express a wide                     rehearsed.
range of information that can complement, reinforce or con-
tradict the information communicated via other modalities
(Kendon, 2000). Our model takes as input a CI that describes            Description We used a video2 from the footage of the
the meaning that a speaker wants to convey via gesture. This            Working Families Summit (Washington D.C., June 23rd
CI contains the minimal set of information required to gen-             2014). 6 female speakers (a journalist, a politician, two pro-
erate a gesture performance that communicates the intended              fessors, a CEO and an activist) discuss abstract concepts such
meaning. For example, a speaker wants to give information               as time, flexibility, income and social status. The 50 min-
about the social status of an individual.                               utes video was chunked into segments that portray only one
                                                                        speaker at a time. Pauses and segments where the journalist
Grounded Conceptualizer The Grounded Conceptualizer                     holds a pen and a notebook were discarded, leaving a total of
maps the elements of the CI to image schemas. PMs system-               22 videos with a mean duration of 1min 42s (SD=50s), for a
atically project the objects, properties and relations from one         total of 37min 32s.
domain to another1 . For example, the PM S OCIAL STATUS
IS V ERTICAL E LEVATION links the social status of an indi-
vidual (or entity) to a location on a vertical scale. Individuals       Annotations 2 coders annotated the corpus with
with a lower social status will have a lower location in space,         VideoAnt3 .        Coders could freely annotate what they
while climbing up the ladder means that they improve their              consider as a gesture, then select the CI reflected by the
social status.                                                          gesture from the following list:
                                                                           – Generic reference: simple reference to an object or fact
Grounded Mental Space A grounded mental space is                           – Specialized reference: reference to an object or fact and
structured by image schemas and actions taken on them. This                    depiction of one or several of its properties
is in line with the work of Barsalou (2009) and others, that               – Action: reference to an action
show that the brain regions responsible for perception and ac-             – Discourse structure: enumeration, contrast or causal re-
tion coordinate during meaning creation and comprehension                      lationship
to create “embodied simulations” of linguistic content. This               – Other: none of the previous categories seems appropri-
suggests that thought and reasoning processes are actually ac-                 ate
tions taken on the objects of the grounded mental space. Us-               They also annotated which element(s) of the gesture con-
ing our previous example, we can move individuals up and                vey the desired meaning (e.g. the size of the object depicted,
down the social status scale and infer how it impacts their             the shape of the motion) and selected the primary metaphor(s)
social status.                                                          that underlies this association (from Grady’s list of 100 pri-
   Since the grounded mental space informs the generation of            mary metaphors).
gesture, it should contain elements that have gesture corre-               The coders were trained using a video segment that was
lates. For example, the representation of an individual on a            discarded from the corpus. They both carried the analysis
social status scale suggests the existence of a concrete O B -          on the whole dataset. Inter-coder agreement was .69 using
JECT with a physical elevation in space, and actions of mov-            Cohen’s kappa (a kappa value above .61 indicates substantial
ing up or down.                                                         agreement (Landis & Koch, 1977)). Further analysis indi-
                                                                        cated that most disagreements were caused by two situations:
Gesture Planner Finally, the Gesture mapper combines                    one coder annotated a movement as a gesture while the other
elements of a grounded mental space into a gesture plan.                did not consider it as a gesture, or gestures were not perfectly
This FML-like output (Heylen, Kopp, Marsella, Pelachaud,                aligned in time. After discussing these cases, a kappa value
& Vilhjálmsson, 2008) can be interpreted by a nonverbal be-            of .91 was obtained.
havior generator (such as (Marsella et al., 2013)) to generate
                                                                            2 https://www.youtube.com/watch?v=cQBlciBr           3w
a multimodal performance.
                                                                            3 VideoAnt  is a web-based annotation tool developed by the Col-
    1 This process can be seen as a simplified blending (Fauconnier     lege of Education & Human Development at the University of Min-
& Turner, 2008)                                                         nesota, available at http://ant.umn.edu
                                                                    789

         Figure 2: Distribution of CIs in the corpus.
Analysis
The final dataset consists of 740 gestures (with an average of
one gesture every 3 seconds). Figure 2 describes the list of         Figure 3: Distribution of the PMs underlying metaphoric ac-
CIs that results from the analysis of the corpus.                    tions in the corpus.
                                                                     mimic an actor acting in the physical space (such as a woman
Generic references 40% of the gestures are known to ges-             lifting a brick over her head).
ture researchers as “Conduits” (Reddy, 1979). The PM A B -              The reader familiar with gesture studies may notice that
STRACT IS C ONCRETE instantiates an object in space to rep-          the distribution between concrete and abstract actions dif-
resent a concrete or an abstract object or an element of the         fers from what is typically reported, with comparatively few
discourse. The hand, facing up with an open palm, presents           concrete actions and a lot of metaphoric actions. Our view
an immaterial object for the viewer to see. The type of the ref-     is that this difference is largely due to the nature of the
erent has little impact on the gesture shape (McNeill, 2005).        corpora used. Most research on gesture have used corpora
                                                                     about physical phenomena (e.g. retelling a scene from a car-
Specialized references 15% of CIs consist in illustrating            toon (McNeill, 1992) or explaining how to navigate a city
abstract properties of referents. The following PMs are used         (Bergmann & Kopp, 2009)). Therefore, gestures in these cor-
in the corpus to map abstract properties to physical properties      pora reflect concrete actions. Our corpus focuses on abstract
expressed with gestures:                                             topics that do not have concrete features, so most gestures
   – Object location (46%): location of the object in the            depict metaphoric actions.
     physical space
     – S OCIAL STATUS IS VERTICAL ELEVATION (25%)                    Discourse structures 15% of the gestures structure and or-
     – M OMENT IN TIME IS LOCATION (15%)                             ganize the discourse. Among them, enumerations, contrasts
     – K NOWLEDGE IS LOCATED IN THE HEAD (6%)                        and expression of causality are equally distributed. Half of
   – Object size (25%): e.g. the distance between two hands          the enumerations in the corpus are represented as objects se-
     or the size of the gap between two fingers                      quentially taken out of a container. The other half by count-
     – Q UANTITY IS SIZE (15%)                                       ing on fingers. Expression of causality relies on the primary
     – I MPORTANCE IS SIZE (10%)                                     metaphor E FFECTS ARE O BJECTS WHICH EMERGE FROM
   – Object shape (29%): the shape of the hands reflects the         CAUSES . Contrasting objects over a property relies on the
     shape of the referent                                           metaphor S IMILARITY IS P ROXIMITY where the distance be-
     – E SSENTIAL IS INTERNAL (23%): e.g. palms oriented             tween objects represents how much they differ regarding this
        towards the speaker                                          property. The property itself can influence elements of the
     – C ERTAIN IS FIRM (6%): e.g. hand shape is a fist              gesture; for example, comparing the social status of two in-
                                                                     dividuals uses the vertical scale while comparing events in
Depicting actions 25% of the gestures represent actions.             time uses the horizontal scale. Our previous work offers ad-
20% are metaphoric actions, i.e. prototypical actions that           ditional detail on discourse structures and their relation to pri-
have meaning based on a underlying metaphor (such as de-             mary metaphors (Lhommet & Marsella, 2014).
picting improving one’s social status by moving an object up
in the physical space). Figure 3 represents the distribution of      Others 2% of the gestures communicate intentions that are
primary metaphors that underly the generation of metaphoric          not covered by the annotation scheme (6 occurrences over
gesture in the corpus. 5% of the CIs are concrete actions that       740 gestures). These are gestures that express uncertainty
                                                                 790

                                                                      Script 1 Communicative intentions to depict actions
                                                                      (a) Depict a continuing action: “We have to continue to do
                                                                      that”
                                                                       (intention depictAction a)
                                                                       (isa Continuation a)
                                                                      (b) Depict the shape of an action: “Mores are suppressing
       (a) A continuing action       (b) The shape of an action       women”
                                                                       (intention depictAction b)
        Figure 4: Gestures can depict actions at two levels            (isa ExercisingAuthoritativeControl b)
                                                                       (performedBy b mores) (objectControlled b women)
(shrugs combined to stereotyped facial expressions) as well
as emblem gestures (in particular, the corpus counts two oc-
                                                                      Primary metaphors are modeled as inference rules that
currences of “quotes” traced in the physical space).
                                                                      map terms from the CIs to concrete terms that represent im-
                                                                      age schemas, using Cyc’s forward chaining engine. During
                        Implementation                                the grounding phase, all primary metaphors rules are tested
This computational model is implemented into a framework              against the contents of a given CI. If the condition side of the
that leverages the Cyc architecture4 . Cyc embeds a first-            rule (i.e. the tuples before the ’->’ symbol) matches the in-
order logic reasoning engine that runs forward and back-              put, then the predicates in the action side of the rule (i.e. the
ward inferences. The knowledge is hierarchically organized            tuples after the ’->’ symbol) are set as true. The grounded
so properties and rules can be propagated along the inher-            mental space is created with all the predicates that are true
itance links. The previous version of the framework, pre-             when quiescence occurs (i.e. no rule matches anymore).
sented in (Lhommet & Marsella, 2014), can derive gesture                 Script 2 details the implementation of the primary
performances for several communicative intentions: (a) de-            metaphor B EING IN C ONTROL IS B EING ABOVE. Ap-
picting generic referents, (b) depicting properties of object         plying this rule to the CI defined by Script 1b) results in
using elaborate metaphors and (c) realizing enumerations and          adding to the grounded mental space two Concrete Objects
(d) contrasts .                                                       that represent the mores and the women, and assigning them
   In the rest of this section, we extend this framework to gen-      locations on a vertical scale such as the object represent-
erate gestures that communicate information about actions.            ing the mores is located above the object representing the
Our corpus analysis showed that gestures can communicate              women. Another rule, not depicted here, matches with the
two kinds of information about actions: (a) the status of an ac-      fact that the action is a PurposefulPhysicalAction and adds
tion: the speaker on Figure 4a says “In this country we have          a (shape act forceful) predicate to the grounded mental
to continue to do that” while making a loop in the physical           space.
space. (b) the physical shape of an action: another speak-
ers says “a lot of countries have horrible cultural mores that
                                                                      Script 2 Primary metaphor: B EING IN CONTROL IS B EING
are suppressing women” while making the gesture depicted
                                                                      ABOVE
by Figure 4b. This gesture suggests a force applied down-
wards that represents the control applied on women. It seems           (isa ControllingSomething act)
driven by the primary metaphor B EING IN CONTROL IS B E -              (performedBy act actor) (isa actor Agent)
                                                                       (objectControlled a object) (isa object Thing)
ING ABOVE .                                                            ->
Communicative intentions are specified using Cyc’s first-              (isa ConcreteObject actor2)
                                                                       (isa ConcreteObject object2)
order logic declarative language. Script 1 represents the CIs          (location actor2 locA) (location object2 locO)
associated to the gestures depicted in Figures 4a-4b, using            (> locA locO s) (isa s VerticalScale)
pseudocode for clarity.
   Cyc’s high-level term Action, and specializations of this
term with more refined meanings, are used to model the CIs.           Gesture plans are derived by another set of inference rules.
In Script 1(a), Continuation specifies that an action previ-          They convert the grounded mental space into a gesture plan
ously initiated continues. In Script 1(b), the action is typed as     that reflects the physical properties using a FML-like formal-
ExercisingAuthoritativeControl, a specialization of Control-          ism (Heylen et al., 2008). The gesture plans for the mentioned
lingSomething, which itself inherits from PurposefulPhysi-            examples are described by Script 3. The system proposed
calAction. The actor (the mores) and object (the women) of            by Xu, Pelachaud, and Marsella (2014) converts this formal-
the action are associated to the action using predicates.             ism into the standard BML format (Kopp et al., 2006) to
                                                                      be rendered by the SmartBody animation system (Thiebaux,
    4 http://www.cyc.com                                              Marsella, Marshall, & Kallmann, 2008).
                                                                  791

Script 3 Gesture plans                                                 A possible application of this model is the automatic gen-
(a) Depict a continuing action                                      eration of multimodal performances for virtual humans. Vir-
                                                                    tual humans engage users in face-to-face interactions, ide-
 <goal=depictShape shape=cycle/>
                                                                    ally using the same verbal and nonverbal behaviors as hu-
                                                                    mans (Cassell, 2000) have proven to be effective in a wide
(b) Depict the shape of an action: “Mores are suppressing           range of applications such as health to training simulations
women”                                                              (e.g. (DeVault et al., 2014)). Metaphoric gestures improve
 <goal=depictShape shape=force source=locA target=locB              message understanding and impact how a speaker is per-
 scale=vertical constraints=[locA>locB]/>                           ceived, in particular in terms of persuasiveness and compe-
                                                                    tence (Beaudoin-Ryan & Goldin-Meadow, 2014). This may
                       Related Work                                 be another reason why metaphoric gestures dominate in this
                                                                    corpus since all the speakers are professional public speak-
Researchers have explored several techniques to automate the        ers. Given that good communication skills, persuasiveness
generation of virtual humans’ nonverbal behaviors that real-        and competence are critical in health interventions and train-
ize communicative intentions. Earlier systems used manual           ing, metaphoric gestures should be an important capability of
annotations of the information to convey nonverbally (e.g.          virtual humans designed for these applications.
(Kopp & Wachsmuth, 2002)). Some systems learn the map-
                                                                       Furthermore, this computational model provides a more
ping from speech input to specific classes of nonverbal be-
                                                                    controlled yet flexible methodology to experiment with social
haviors (e.g. prosody to beat gestures (Levine, Krähenbühl,
                                                                    and psychological constructs; for example, virtual humans
Thrun, & Koltun, 2010), text to head movements (Lee &
                                                                    can serve as confederates in psychology and social psychol-
Marsella, 2010) or text to gesturing style (Neff, Kipp, Al-
                                                                    ogy experiments to study the impact of nonverbal behaviors.
brecht, & Seidel, 2008). Other approaches rely on expert
rules that infer information from the speech. BEAT infers              A limit to the broad application of this work is the need
rheme and theme from the text to generate intonation and em-        to manually specify the gesture communicative intent of the
phasis (Cassell, Nakano, Bickmore, Sidner, & Rich, 2001).           speaker. A promising avenue here is the Embodied Construc-
NVBG detects communicative intentions in the text (e.g. af-         tion Grammar (ECG) framework (Bergen & Chang, 2005)
firmation, emphasis, disfluencies) using a keywords map-            that represents a speaker’s intended meaning based on image
ping (Lee & Marsella, 2006). Cerebella integrates acoustic,         schemas, along with the mental simulation of these represen-
syntactic and semantic analyses to infer communicative in-          tations using executing schemas (S. S. Narayanan, 1997). Our
tentions and elements of the mental state (emotional state,         future work will investigate the integration of our computa-
energy, emphasis,. . . ) (Marsella et al., 2013; Lhommet &          tional model into the ECG framework, in particular applying
Marsella, 2013). Approaches that take speech as input gen-          the work of S. Narayanan (1999) on inferring and reasoning
erate nonverbal behavior that is limited in the range of what       on conceptual metaphors from speech onto gesture.
can be inferred from the speech utterance only.
   Some work address the production of speech and ges-                                       References
ture from a joint representation. Bergmann, Kahl, and Kopp          Barsalou, L. W. (2009). Simulation, situated conceptual-
(2013) studied how linguistic and cognitive constraints im-            ization, and prediction. Philosophical Transactions of the
pact the coordination of speech and gesture. Lascarides and            Royal Society B: Biological Sciences, 364(1521), 1281-
Stone (2009) formalize the relation of gesture and speech              1289.
with a logical form of multimodal discourse, in particular be-      Beaudoin-Ryan, L., & Goldin-Meadow, S. (2014). Teaching
tween discourse elements and deictic gestures. In the Ges-             moral reasoning through gesture. Developmental Science,
tures as Simulated Action framework, perceptual and motor              17(6), 984-990.
representations automatically become active during language         Bergen, B. K., & Chang, N. (2005). Embodied construction
production and, under certain conditions are sources of ges-           grammar in simulation-based language understanding. In
tures (Hostetter & Alibali, 2008).                                     J.-O. Östman & M. Fried (Eds.), Construction grammars:
                                                                       Cognitive grounding and theoretical extensions (p. 147-).
                         Discussion                                    John Benjamins Publishing.
In this paper, we presented a computational model of gesture        Bergmann, K., Kahl, S., & Kopp, S. (2013). Modeling the
generation informed by embodied cognition that turns various           semantic coordination of speech and gesture under cogni-
communicative intentions into gesture by grounding them in             tive and linguistic constraints. In Intelligent virtual agents
a physical, embodied context. Using the analysis of a video            (p. 203-216). Edinburgh, UK.
corpus, we showed that most CIs present in the corpus can           Bergmann, K., & Kopp, S. (2009). Increasing the expressive-
be conveyed using a very limited set of PMs (at the exception          ness of virtual agents: autonomous generation of speech
of stereotyped gestures that could easily be integrated by pro-        and gesture for spatial description tasks. In Proceedings
viding a direct mapping from specific CIs to these emblem              of the 8th international conference on autonomous agents
gestures.)                                                             and multiagent systems - volume 1 (p. 361-368). Richland,
                                                                792

  SC: International Foundation for Autonomous Agents and               nods and the effects of affective information. Multimedia,
  Multiagent Systems.                                                  IEEE Transactions on, 12(6), 552-562.
Calbris, G. (2011). Elements of meaning in gesture (Vol. 5).         Levine, S., Krähenbühl, P., Thrun, S., & Koltun, V. (2010).
  John Benjamins Publishing.                                           Gesture controllers.       In Acm siggraph 2010 papers
Cassell, J. (2000). Embodied conversational agents. MIT                (p. 124:1-124:11). New York, NY, USA: ACM.
  Press.                                                             Lhommet, M., & Marsella, S. (2014). Metaphoric gestures:
Cassell, J., Nakano, Y., Bickmore, T., Sidner, C., & Rich,             Towards grounded mental spaces. In Intelligent virtual
  C. (2001). Annotating and generating posture from dis-               agents (Vol. 8637, p. 264-274). Boston, MA: Springer In-
  course structure in embodied conversational agents. In               ternational Publishing.
  Workshop on representing, annotating, and evaluating non-          Lhommet, M., & Marsella, S. C. (2013). Gesture with mean-
  verbal and verbal communicative acts to achieve contex-              ing. In Intelligent virtual agents (Vol. 8108, p. 303-312).
  tual embodied agents.                                                Edinburgh, UK: Springer Berlin Heidelberg.
Cienki, A. (2008). Why study metaphor and gesture. In                Marsella, S., Xu, Y., Lhommet, M., Feng, A., Scherer,
  A. Cienki & C. Müller (Eds.), Metaphor and gesture (p. 5-           S., & Shapiro, A. (2013). Virtual character perfor-
  25). Amsterdam; Philadelphia: John Benjamins Pub. Co.                mance from speech. In Proceedings of the 12th acm
DeVault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer,        siggraph/eurographics symposium on computer animation,
  A., . . . Morency, L.-P. (2014). Simsensei kiosk: A vir-             anaheim, ca (p. 25-35). New York, NY: ACM.
  tual human interviewer for healthcare decision support. In         McNeill, D. (1992). Hand and mind: What gestures reveal
  Proceedings of the 2014 international conference on au-              about thought. University of Chicago Press.
  tonomous agents and multi-agent systems (p. 1061-1068).            McNeill, D. (2005). Gesture and thought. Chicago: Univer-
  Richland, SC: International Foundation for Autonomous                sity of Chicago Press.
  Agents and Multiagent Systems.                                     Narayanan, S. (1999). Moving right along: A computa-
Fauconnier, G., & Turner, M. (2008). The way we think:                 tional model of metaphoric reasoning about events. In In
  Conceptual blending and the mind’s hidden complexities.              proceedings of the national conference on artificial intelli-
  Basic Books.                                                         gence (aaai’99. Orlando, FL.
Heylen, D., Kopp, S., Marsella, S., Pelachaud, C., &                 Narayanan, S. S. (1997). Knowledge-based action repre-
  Vilhjálmsson, H. (2008). The next step towards a function           sentations for metaphor and aspect (karma). Unpublished
  markup language. In Intelligent virtual agents (p. 270-280).         doctoral dissertation, UNIVERSITY of CALIFORNIA.
  Tokyo, Japan.                                                      Neff, M., Kipp, M., Albrecht, I., & Seidel, H. P. (2008). Ges-
                                                                       ture modeling and animation based on a probabilistic re-
Hostetter, A. B., & Alibali, M. W. (2008). Visible embodi-
                                                                       creation of speaker style. ACM Transactions on Graphics
  ment: Gestures as simulated action. Psychonomic bulletin
                                                                       (TOG), 27(1).
  & review, 15(3), 495-514.
                                                                     Reddy, M. J. (1979). The conduit metaphor: A case of frame
Kendon, A. (2000). Language and gesture: Unity or dual-
                                                                       conflict in our language about language. In A. Ortony (Ed.),
  ity. In D. McNeill (Ed.), Language and gesture (p. 47-63).
                                                                       Metaphor and thought (Vol. 2, p. 164-201). Cambridge:
  Cambridge University Press.
                                                                       Cambridge University Press.
Kopp, S., Krenn, B., Marsella, S., Marshall, A., Pelachaud,
                                                                     Thiebaux, M., Marsella, S., Marshall, A. N., & Kallmann,
  C., Pirker, H., . . . Vilhjálmsson, H. (2006). Towards a com-
                                                                       M. (2008). Smartbody: behavior realization for embodied
  mon framework for multimodal generation: The behavior
                                                                       conversational agents. In Proceedings of the 7th interna-
  markup language. In Intelligent virtual agents (p. 205-217).
                                                                       tional joint conference on autonomous agents and multia-
  Marina del Rey, CA.
                                                                       gent systems (Vol. 1, p. 151-158). Richland, SC: Interna-
Kopp, S., & Wachsmuth, I. (2002). Model-based animation                tional Foundation for Autonomous Agents and Multiagent
  of co-verbal gesture. In Computer animation, 2002. pro-              Systems.
  ceedings of (p. 252-257). Geneva, Switzerland.                     Tversky, B., & Hard, B. M. (2009). Embodied and disem-
Lakoff, G., & Johnson, M. (1980). Metaphors we live by                 bodied cognition: Spatial perspective-taking. Cognition,
  (2003rd ed.). Chicago: University of Chicago Press.                  110(1), 124-129.
Landis, J. R., & Koch, G. G. (1977). The measurement of              Xu, Y., Pelachaud, C., & Marsella, S. (2014). Compound
  observer agreement for categorical data. Biometrics, 33(1),          gesture generation: A model based on ideational units. In
  159-174.                                                             T. Bickmore, S. Marsella, & C. Sidner (Eds.), Intelligent
Lascarides, A., & Stone, M. (2009). A formal semantic anal-            virtual agents (p. 477-491). Springer International Pub-
  ysis of gesture. Journal of Semantics, 26(4), 393-449.               lishing.
Lee, J., & Marsella, S. C. (2006). Nonverbal behavior gen-
  erator for embodied conversational agents. In 6th interna-
  tional conference on intelligent virtual agents. Marina del
  Rey, CA.
Lee, J., & Marsella, S. C. (2010). Predicting speaker head
                                                                 793

