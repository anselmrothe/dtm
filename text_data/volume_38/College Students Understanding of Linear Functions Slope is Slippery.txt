College Students’ Understanding of Linear Functions: Slope is Slippery
Marta K. Mielicki (mmieli2@uic.edu)
Department of Psychology, University of Illinois at Chicago

Jennifer Wiley (jwiley@uic.edu)
Department of Psychology, University of Illinois at Chicago
Abstract
A common obstacle for students in the transition from arithmetic
to algebra is developing a conceptual understanding of equations
representing functions. Two experiments manipulated
isomorphic problems in terms of their solution requirements
(computation vs. interpretation) and format to test for
understanding of linear functions. Experiment 1 provided
problems in a story context, and found that performance on slope
comparison problems was low, especially when problems were
presented with equations.
Experiment 2 tested whether
performance on slope comparison problems improves when
problem prompts include explicit mathematical terminology
rather than just natural language consistent with the problem
story. Results suggest that many undergraduate students fail to
access the mathematical concept of slope when problem prompts
are presented with natural language. Overall, the results suggest
that even undergraduate students lack understanding of the slope
concept and equations of linear functions, both which are
foundational for advanced algebraic thinking.
Keywords: algebraic problem solving, slope, linear functions

Introduction
A common obstacle for students in the transition from
arithmetic to algebra is developing a conceptual
understanding of equations representing functions. Prior
work has demonstrated that students can persist in procedural
approaches rather than conceptual approaches (RittleJohnson & Alibali, 1999; Rittle-Johnson, Siegler, & Alibali,
2001); process-based approaches rather than object-based
approaches (Kieran, 1992); operational or computational
approaches rather than relational approaches (Chesney &
McNeil, 2014; Kaput, 2000; McNeil & Alibali, 2005) even
after algebra instruction. Although much of the research on
the transition from arithmetic to algebraic thinking has
focused on younger students (middle school and high
school), even college students may continue to experience
difficulties and lack a mature understanding of linear
functions (Hall et al., 1989; Wollman, 1983).
Prior work has suggested that problem presentation plays
an important role in solution success. Mevarech and Stern
(1997) found that context can affect performance on linear
equation problems that are presented graphically.
Importantly, the problems that Mevarech and Stern (1997)
administered all pertained to the mathematical concept of
slope. They found that both younger students (around 12 year
olds) and undergraduates performed better when problems
were embedded in sparse contexts than when problems were
presented in realistic contexts (e.g. graphs depicting how two
hoses fill a pool at different rates). Mevarech and Stern

(1997) suggested that presenting problems in realistic
contexts may overload the problem solver with extraneous
information which obscures the underlying mathematical
concept and leads to poor performance.
Other work has also found that presentation format can
affect undergraduate performance on solving linear equation
problems.
Mielicki and Wiley (2016) presented
undergraduate students with isomorphic problems pertaining
to linear functions either in graphical format or with a set of
equations. Problems either required computation of a point
on a single line (solve for x, solve for y) or required relational
reasoning (comparing slopes or comparing points across
several linear functions). A main finding was that slope
comparison problems were most difficult for students overall,
and that these problems were especially difficult when
presented in equation format. This finding conforms to the
interpretation that Mevarch and Stern (1997) proposed for
their findings, and suggests that students may have difficulty
accessing relevant mathematical knowledge when slope
problems are presented in equation format. Taken together,
these findings of significant difference in performance due to
problem presentation highlight specific deficits that many
undergraduates possess in their understanding of equations
representing linear functions.

Experiment 1
The goal of Experiment 1 was to further test the hypothesis
that undergraduate students may lack a mature understanding
of linear functions expressed as equations, and particularly
the mathematical concept of slope. As in Mielicki and Wiley
(2016), students were asked to solve isomorphic problems
presented either with graphs or with equations. The problems
entailed either computation or interpretation across a set of
linear functions. Both problem types featured distinct
subtypes: computation problems either entailed solving for x
or solving y and interpretation problems either entailed
comparing the slopes of three linear functions or comparing
y values of three linear functions along some range of x
values. Examples of each problem type are shown in Figure
1.
Based on a cognitive task analysis, it was expected that the
four subtypes of problems would have different cognitive
demands in equation and graph format. Overall, computation
problems were expected to have higher solution rates than
interpretation problems because the former only require
consideration of a single linear function whereas the latter
require comparing three functions. Between the two subtypes
of computation problems, solving for x was expected to be

1811

more demanding than solving for y in equation format, since
solving for x requires additional computational steps to
isolate the variable (all problems were presented in y = mx +
b format). For interpretation problems, the cognitive
demands for problems requiring the comparison of slopes
should not vary by presentation format if students understand
the conceptual meaning of what the quantities in the y = mx
+ b equation represent. In either format, little calculation is
necessary – the solver could easily compare the visual trends
of the three lines with a graph, or compare the three values of
“m” across equations. In contrast, comparing points might
be easier to do in graphical format because in equation format
multiple calculations are required to compare y values for
three equations. These calculations may introduce additional
opportunities for error which are not present when point
comparison problems are presented with graphs. It was
expected that these differences in computational demand
would be reflected in solution accuracy.

Method
Participants
A sample of 32 (21 female) undergraduate students from the
University of Illinois at Chicago participated in exchange for
course credit.
Participants were mostly first year
undergraduate students (ages ranging from 17 to 23), and had
taken 1 math course on average since starting college. Many
participants (91%) reported a science (Biology, Chemistry,
Psychology, Engineering) or health-related (Pre-med, Prenursing, Kinesiology) major. No participants reported
pursuing a mathematics major.

Materials
Each participant completed 12 interpretation and 12
computation problems. Computation problems either entailed
solving for x or solving for y. Interpretation problems either
entailed comparing the slopes or comparing the y values of
the three linear functions over a range of x values. Of the 24
problems, half were presented with graphs and half were
presented with equations (always in y = mx + b format).
In addition to these manipulations, several other
presentation features were either varied in the same way for
each participant to reduce monotony, or counterbalanced in
order to control for order effects. Each problem was
presented individually, but pairs of problems were presented
with one format (graphs or equations) and the format for each
pair was switched for the second half of the problems so that
each participant saw three instances of each problem subtype
(solve for x, solve for y, slope comparison, point comparison)
in each format (graph, equations). Six configurations of
linear functions (one for each block of 4 problems) were used
in the same order for each participant. Computation
problems requiring solving for x were always paired with
slope comparison interpretation problems, and computation
problems requiring solving for y were always paired with
point comparison interpretation problems. Pairs of problems
were alternated, and graph versus equation format was
alternated between each pair of problems. In addition, each
pair of problems was presented with one of two problem
scenarios (i.e., real-world contexts such as comparing cab
companies).

Solve for x Problem in Graph Format
Malik is comparing three cab companies. Each company has a
different fare structure for charging customers.

Solve for y Problem in Symbolic Format
Bob is participating in a walkathon, and he has gotten three sponsors to
donate money to charity for every kilometer he walks. Each sponsor has
a different pledge plan for how much money they will donate.

Use the graph below to answer the following questions.

Here are the equations for each sponsor’s pledge where y is the amount of
money donated in dollars and x is the distance walked in kilometers.
Sponsor A: y = 3x + 5
Sponsor B: y = 2x + 10
Sponsor C: y = x + 15

If company C charges Malik $25, how many miles did he travel?

How much will Sponsor C donate if Bob walks 10 kilometers?

1812

Slope Comparison Problem in Graph Format

Point Comparison Problem in Symbolic Format

Malik is comparing three cab companies. Each company has a
different fare structure for charging customers.

Bob is participating in a walkathon, and he has gotten three sponsors to
donate money to charity for every kilometer he walks. Each sponsor has
a different pledge plan for how much money they will donate.

Use the graph below to answer the following questions.

Here are the equations for each sponsor’s pledge where y is the amount of
money donated in dollars and x is the distance walked in kilometers.
Sponsor A: y = 3x + 5
Sponsor B: y = 2x + 10
Sponsor C: y = x + 15

Which company has the lowest rate per mile?

Which sponsor will donate the least if Bob walks over 5 kilometers?

Figure 1: Examples of interpretation problems (slope comparison, point comparison) and computation problems (solve for x,
solve for y) in either equation or graphical format.
The following were counterbalanced across participants:
order of format presentation (graph first versus equation
first), order of scenario (scenario A with graph and B with
equations versus scenario A with equations and B with
graph), order of pair presentation (solve for x/slope
comparison pair first versus solve for y/point comparison
pair first), and order of problem subtype presentation within
pairs of problems (computation first versus interpretation
first). This 2x2x2x2 counterbalancing design led to 16
versions, and 2 participants completed each version.

Procedure
All problems were presented one at a time on a computer
screen, but participants wrote their responses in an answer
booklet that was provided. The answer booklets also
included the graphs or equations for each problem so that
participants could annotate and interact with the
representations as needed. After completing the problems,
participants were asked to rephrase a subset of the problems
with the prompt, “In your own words, please tell me what you
think the problem is asking you to do.”

Results
A 2x2 within-subjects ANOVA was conducted with format
(graph, equation) and problem type (interpretation,
computation) as independent variables and proportion correct
as the dependent variable. As shown in Figure 2, the analyses
revealed a main effect of representation, F(1,31) = 27.56., p
< .001, ηp2 = .47. Participants solved both types of problems
more successfully when problems were presented with
graphs than when they were presented with equations. The
analysis also revealed a main effect of problem type, F(1,31)
= 68.46, p < .001, ηp2 = .69. Participants solved computation

problems more successfully than interpretation problems,
regardless of presentation format. There was a significant
interaction, F(1,31) = 4.93, p < .05, ηp2 = .14. Follow up
analyses revealed no differences in accuracy for computation
problems in different formats, t(31) = 1.83, p = .08, and
higher accuracy for interpretation problems presented in
graphical format relative to equation format, t(31) = 4.51, p
< .001.
Additional 2x2 within-subjects ANOVAs were conducted
separately for each problem type because the nested subtypes
were not orthogonal. For computation problem subtypes,
there was no effect of format, F(1,31) = 3.36, p = .08, or
problem subtype, F(1,31) = 3.14, p = .09, and no interaction,
F < 1. For interpretation problem subtypes, there was a main
effect of format in favor of graphs, F(1,31) = 20.31, p < .001,
ηp2 = .40, and a main effect of problem subtype with higher
accuracy on point comparison problems than slope
comparison problems, F(1,31) = 43.36, p < .001, ηp2 = .58.
The interaction was not significant, F < 1.
Participants’ rephrasing responses for slope comparison
problems were coded based on reported solution methods.
Most participants (31% for both formats) rephrased the
question without providing any indication of a solution
method. Some participants referenced the representation, but
did not provide a solution method (6% for graphs, 9% for
equations), and others mentioned a method but did not
provide enough information to determine whether the method
was correct or not (6% for graphs, 3% for equations). The
remaining responses were coded as either incorrect solution
method, or correct solution method/reference to the
underlying concept (slope). For slope comparison problems
presented with equations, 38% of participants reported an
incorrect solution method relative to 25% of participants for
problems presented with graphs. When slope comparison

1813

problems were presented with equations, common incorrect
strategies were “plugging in a number” for the x value of all
three functions and comparing the results. For slope
comparison problems presented with graphs, incorrect
strategies were often some variation on “I just looked at the
graph to see which line was highest.” This approach indicates
that students often experienced slope/height confusion
(Leinhardt, Zaslavsky, & Stein, 1990). Conversely, 32% of
participants reported a correct solution method or actually
referenced the concept of slope when problems were
presented with graphs relative to 18% when problems were
presented with equations.

Proportion Correct

Graph

Equations

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Solve for x Solve for y

Slope
Point
Comp.
Comp.
Problem Subtype
Figure 2: Mean proportion correct for the four problem
subtypes presented in graphical and equation format. Error
bars represent standard error.

Discussion
One striking result from Experiment 1 was the low overall
accuracy on slope comparison problems in both formats, but
particularly for slope comparison problems presented with
equations. This pattern of results replicates the findings of
Mielicki and Wiley (2016).
Participants’ rephrasing responses suggest that graphs and
equations may make different solution methods more
accessible. Importantly, although the solution methods that
students used when solving graphical slope problems
sometimes led to a correct solution, these solution methods
were not always indicative of conceptual understanding. For
instance, it was possible for students to confuse slope with
height when problems were presented with graphs
(Leinhardt, Zaslavsky, & Stein, 1990) and still answer the
problem correctly because the line with the highest height (y
value) also had the highest slope.
However, even though performance was better on the slope
comparison problems presented graphically, performance
was still lowest overall on this problem type. It is possible
that the overall low accuracy on slope comparison problems
can be traced to difficulty during the problem comprehension
phase. In previous work, it has been demonstrated that
students often struggle with translating between stories,
equations, and mathematical concepts (Cummins et al, 1988;
Mayer, 1982; Nathan, Kintsch, & Young, 1992). In many
contexts, students seem to fail to identify relevant

mathematical principles. The results of Experiment 1 could
be attributed to students not making the connection between
the mathematical concept of slope and the demands of the
task. If this is the case, then altering the language of the
problem prompt to make the mathematical principles more
clear should improve performance.

Experiment 2
The main goal of Experiment 2 was to test whether students
would be able to solve equations requiring comparisons of
slopes more successfully when the comprehension phase of
problem solving is supported by presenting problem prompts
with explicit mathematical terminology as opposed to natural
language (as in Experiment 1).
This study focused specifically on only the two
interpretation problem subtypes (point comparison, slope
comparison) from Experiment 1. Manipulating the linguistic
form of the problem prompt was not expected to have an
effect on performance for point comparison problems. In
Experiment 1, performance on point comparison problems
benefitted from graphical format. This graphical advantage
was consistent with the predictions from the cognitive task
analysis that point comparison problems presented with
equations were more computationally demanding than those
presented with graphs. Thus the same pattern of results was
expected for point comparison problems presented with
mathematical terminology in Experiment 2.
If the graphical advantage for slope comparison problems
found in Experiment 1 was due to graphs making different
(though not necessarily correct) strategies accessible to
participants, then supporting the comprehension phase
should eliminate this advantage because participants should
rely less on incorrect strategies if they can better access the
underlying mathematical concept of slope. Thus, it was
predicted that the graphical advantage found in Experiment 1
would be replicated when problems were presented with
natural language, but that this advantage would be eliminated
when problems were presented with explicit mathematical
terminology. In addition, an overall main effect of linguistic
form was expected because problem performance should
improve overall when the comprehension phase is supported.

Method
Participants
A sample of 32 (20 female) undergraduate students from the
University of Illinois at Chicago participated in exchange for
course credit.
Participants were mostly first year
undergraduate students (ages ranging from 17 to 29), and had
taken 0 to 3 math courses since starting college. Many
participants (84%) reported a science (Biology, Chemistry,
Psychology, Neuroscience) or health-related (Pre-dental,
Pre-nursing, Kinesiology, Occupational Therapy) major. No
participants reported pursuing a mathematics major.

1814

A subset of slope comparison and point comparison problems
from Experiment 1 was used for Experiment 2, and a second
version of each problem was created in which the problem
prompts were rephrased using explicit mathematical
terminology instead of natural language. For example,
prompts like “which cab company charges the most per
mile?” were changed to “which line has the highest slope?”
Each participant completed 8 problems, which were divided
evenly between format (graphs, equations), type (point
comparison, slope comparison), and linguistic form (natural
language, mathematical terminology). These were the main
manipulations of interest.
In addition, several presentation features were
counterbalanced across participants. Items were blocked by
linguistic form, and the order of the blocks was
counterbalanced across participants with half completing
natural language problems first and half completing
mathematical terminology problems first. Within each block,
the first and fourth problems were presented with one
representation, and the second and third problems were
presented with the other representation. Slope comparison
and point comparison problems were alternated within each
block. The order of problem type presentation and the order
of format presentation were counterbalanced across
participants. This 2x2x2 design resulted in 8 versions of the
task, and 4 participants completed each version.

Procedure
The procedure was the same as the procedure in Experiment
1 except that rephrasing responses were not collected.

Results
A 2x2x2 within-subjects ANOVA was conducted with
format (graph, equation); problem type (slope comparison,
point comparison); and linguistic form (natural language,
mathematical terminology) as independent variables and
proportion correct as the dependent variable. As shown in
Figure 4, the analysis revealed a main effect of linguistic form
with problem prompts presented with mathematical
terminology being solved more accurately than problem
prompts presented with natural language, F(1,31) = 8.03, p <
.01, ηp2 = .21. There was also a main effect of format, with
higher accuracy on problems presented with graphs than
equations, F(1,31) = 6.55, p < .05, ηp2 = .17. There was no
main effect of problem type, F < 1. The linguistic form by
representation and representation by problem type
interactions were not significant, F < 1, and the three way
interaction also did not reach significance, F(1,31) = 2.99, p
= .09.
However, there was a linguistic form by problem type
interaction, F(1,31) = 7.79, p < .01, ηp2 = .20. Follow up
paired-sample t-tests collapsing across representation
revealed no difference in performance on point comparison
problems based on linguistic form, t < 1; however, presenting
problems in mathematical language significantly improved

performance on slope comparison problems, t(31) = 4.45, p
< .001.
Because it was predicted a priori that the results from
Experiment 1 would be replicated for slope comparison
problems presented in natural language form, and that
mathematical language should eliminate the graphical
advantage, paired-samples t-tests were conducted to compare
performance on slope comparison problems presented with
graphs with performance on problems presented with
equations for each linguistic form.
As predicted,
performance was better on slope comparison problems
presented with graphs than presented with equations when
problems were in natural language form, t(31) = 2.29, p < .05.
There was no difference in performance on slope comparison
problems when presented in mathematical terminology, t < 1.

Proportion Correct

Materials

Graph

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Slope
Comp.

Slope
Comp.

Equations

Point
Comp.

Point
Comp.

Natural
Math
Natural
Math
Problem Type and Context
Figure 4: Mean proportion correct for slope comparison and
point comparison problems presented in graph and equation
format and in natural language or mathematical terminology
form. Error bars represent standard error.

Discussion
The main result from Experiment 2 was that accuracy on
slope comparison problems, particularly when presented with
equations, improved when problems were presented in
mathematical language. In addition, the graphical advantage
found for slope comparison problems presented with natural
language was eliminated when problems were presented with
mathematical terminology.

General Discussion
The findings from Experiment 2 demonstrate that students
are capable of solving slope comparison problems under
certain conditions. Students do possess some understanding
of the slope concept, but the limitations of this understanding
are brought to light when problems are presented with natural
language and particularly in equation format.
The graphical advantage for slope comparison problems
found in Experiment 1 could be attributed to graphical format
facilitating solution methods that lead to a correct answer
without engaging the appropriate mathematical concept.

1815

Student responses to the rephrasing prompts provide some
support for this interpretation, but future research will need
to address this possibility further by collecting trace data
using think-aloud or eye-tracking methodology in order to
better understand the ways that students are solving slope
comparison problems in both formats.
Taken together, these results suggest that many
undergraduates have not made the shift from procedural to
conceptual understanding of slope. Students’ difficulty
recognizing or accessing the slope concept during problem
solving highlights specific weaknesses in undergraduates’
algebraic understanding.
Slope has been widely
acknowledged as a fundamental mathematical concept, with
important implications for achievement in mathematics.
Understanding of slope has been identified as central to
success in precalculus and calculus (Carlson, Oehrtman, &
Engelke, 2010), which in turn are required for many STEM
career paths. Although slope is an important mathematical
concept, it is also a notoriously difficult one for students to
understand (Stump, 2001). Because linear equations are
foundational, understanding and addressing weaknesses in
students’ conceptions of functions and slope represents an
important step towards mending the leaky STEM pipeline.

Acknowledgments
Many thanks to James W. Pellegrino and Mara V. Martinez
for their valuable feedback on this project.

References
Carlson, M., Oehrtman, M., & Engelke, N. (2010). The precalculus
concept assessment: A tool for assessing students’ reasoning
abilities and understandings. Cognition and Instruction, 28, 113–
145.
Chesney, D. L., & McNeil, N. M. (2014). Activation of operational
thinking during arithmetic practice hinders learning and transfer.
The Journal of Problem Solving, 7, 24-35.
Cummins, D. D., Kintsch, W., Reusser, K., & Weimer, R. (1988).
The role of understanding in solving algebra word problems.
Cognitive Psychology, 20, 405–438.

Hall, R., Kibler, D., Wenger, E., & Truxaw, C. (1989). Exploring
the Episodic Structure of Algebra Story Problem Solving.
Cognition and Instruction, 6, 223–283.
Kaput, J. J. (2000). Teaching and learning a new algebra with
understanding. Dartmouth, MA: National Center for Improving
Student Learning and Achievement in Mathematics and Science.
Kieran, C. (1992). The learning and teaching of school algebra. In
D. A. E. Grouws (Ed.) Handbook of research on mathematics
teaching and learning: A project of the National Council of
Teachers of Mathematics (pp 390–419). New York: Macmillan
Publishing Co., Inc.
Leinhardt, G., Zaslavsky, O., & Stein, M.K. (1990). Functions,
graphs, and graphing: Tasks,
learning and teaching.
Review of Educational Research, 60, 1-64.
Mayer, R. E. (1982). Different problem-solving strategies for
algebra word and equation problems. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 8, 448–462.
Mevarech, Z. R., & Stern, E. (1997). Interaction between knowledge
and contexts on understanding abstract mathematical concepts.
Journal of Experimental Child Psychology, 65, 68–95.
McNeil, N. M., & Alibali, M. W. (2005). Why won't you change
your mind? Knowledge of operational patterns hinders learning
and performance on equations. Child Development, 76, 883-899.
Mielicki, M. K. and Wiley, J. (2016) Alternative representations in
algebraic problem solving: When are graphs better than
equations? The Journal of Problem Solving, 9, 3-12.
Nathan, M. J., Kintsch, W., & Young, E. (1992). A theory of algebra
word problem comprehension and its implications for the design
of computer learning environments. Cognition and Instruction,
9,329–389.
Rittle-Johnson, B., & Alibali, M. W. (1999). Conceptual and
procedural knowledge of mathematics: Does one lead to the
other?. Journal of Educational Psychology, 91, 175-189.
Rittle-Johnson, B., Siegler, R. S., & Alibali, M. W. (2001).
Developing conceptual understanding and procedural skill in
mathematics: An iterative process. Journal of Educational
Psychology, 93, 346-362.
Stump, S. L. (2001). High school precalculus students’
understanding of slope as measure. School Science and
Mathematics, 101, 81–89.
Wollman, W. (1983). Determining the sources of error in a
translation from sentence to equation. Journal for Research in
Mathematics Education, 14, 169-181.

1816

