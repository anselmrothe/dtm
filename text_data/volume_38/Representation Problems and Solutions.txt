Representation: Problems and Solutions
Nancy Salay (salay@queensu.ca)
Department of Philosophy, Watson Hall
Kingston, ON CANADA

capacities, the abilities that really set us apart from other
animals, are our representational ones.
In the course of defending this view, I will argue that we
cannot draw inferences about our cognitive hardware from
the seemingly representational capacities of our minds, that
there are more important lessons to be gleaned from extended
mind debates besides metaphysical or conceptual ones about
the boundaries of minds, and that clarifying matters and,
consequently, carving a path for new, fruitful research, will
require a narrowing of our understanding of representation,
a narrowing that runs counter to recent suggestions from the
embodied/embedded approach, with which I have deep
sympathies.
In the first half of the paper, I rehearse the problems with
the current representational view; in the second, I defend and
give a positive sketch of a two-systems view of cognition – a
non-representational perceptual system coupled with a
representational language-dependent one – and look at some
consequences of the view.

Abstract
The current orthodoxy in cognitive science, what I describe as
a commitment to deep representationalism, faces intractable
problems. If we take these objections seriously, and I will
argue that we should, there are two possible responses: 1. We
are mistaken that representation is the locus of our cognitive
capacities — we manage to be the successful cognitive agents
in some other, non-representational, way; or, 2. Our
representational capacities do give us critical cognitive
advantages, but they are not fundamental to us qua human
beings. As Andy Clark has convincingly argued, antirepresentationalism, option one, is explanatorily weak.
Consequently, I will argue, we need to take the second option
seriously. In the first half of the paper I rehearse the problems
with the current representational view and in the second half of
the paper I defend and give a positive sketch of a two-systems
view of cognition – a non-representational perceptual system
coupled with a representational language-dependent one – and
look at some consequences of the view.
Keywords: representation; representation-hungry problem;
consciousness; animal cognition; perception; two-systems

Deep Representationalism

Introduction

The Representational Theory of the Mind (RTM) is the
view that a large range of human behaviour is best explained
by appeal to reasons rather than, for example, by descriptions
of neural activity. Reasons, on this view, come in the form
of propositional attitudes, beliefs, desires, fears, and the like,
to mental representations. Why did the chicken cross the
road? Because it wanted to get to the other side.
RTMs typically take it that all mental states are
representational: abstract ideas such as justice, occurrent
thoughts such as the cat is on the mat, and perceptions such
as my seeing this flower now, all count as mental
representations. Views might differ about how much
conceptual content a given mental representation has, about
the way in which perceptions get their representational
content, but, the sphere of the mental is taken to be
representational through and through. I will call this class of
views, Deep Representationalism, DR. Despite much
criticism, DR is still the prevailing view in cognitive science
today.
One of the challenges facing DR is to produce a naturalistic
account of the representation relation, of grounding it in some
relation that can be specified in non-intentional terms. This
has proved a difficult nut to crack. As C.S. Peirce pointed
out in his comprehensive analysis of representation (Peirce,
1998), for something to be a representation it must stand in
one sort of relation to the thing it represents and another sort
of relation to the interpretation of the signifying relation.
Smoke does not mean fire if there is no one around to
recognise the relationship between smoke and fire. Giving a

The current orthodoxy in cognitive science is that human
beings are fundamentally intentional beings, that what makes
us uniquely cognitive agents is our ability to think (and talk)
about our world. It is precisely this capacity, we generally
think, that is at the root of our cognitive superiority to even
our closest genetic cousins. But there are deep problems with
this view. If we take these objections seriously, and I will
argue that we should, there are two possible responses: 1. We
are mistaken that representation is the locus of our cognitive
capacities — we manage to be the successful cognitive agents
in some other, non-representational, way; or, 2. Our
representational capacities do give us critical cognitive
advantages, but they are not fundamental to us qua human
beings.
The first response should be fairly familiar by now to
anyone in cognitive science who has engaged with the
arguments from the embodied/embedded camp influenced by
the phenomenological work of people like Martin Heidegger
and Maurice Merleau Ponty. There is, surely, something
deeply right about these views. As Andy Clark has
convincingly argued, however, anti-representational
positions are explanatorily weak. Consequently, I will argue,
we need to take the second option seriously.
Once all the dust has settled, we will see that both camps
are partly right and partly wrong: our most fundamental
relation with the world is an experiential, not a
representational one; but, our paradigmatically cognitive

295

naturalistic account would involve explaining this
interpretant relation without appeal to intentionality at all.
Fred Dretske’s information theoretic account (1988) is
arguably the most comprehensive such attempt we have. On
his account, Peirce’s triadic relation is compressed into a
dyadic one: a state R of a system S is a representation of kind
O just in case R nomically covaries with the presence of O’s
and this co-variance relation explains R’s functional role
within S. On this view, the bi-metallic strip inside a
thermostat represents the ambient temperature of the
surrounding air because it is by virtue of the strip’s physical
properties, which nomically covary with the rise or fall in
temperature, that it has its functional role, namely, to turn the
furnace on when the temperature drops below a certain level
and off when it rises above it. In other words, it is in virtue
of its information carrying properties that it has its functional
role. At least this is what Dretske wants to conclude.
As Ramsey (2003) convincingly argues, however, this
account is not sufficient to justify our viewing such states as
representations. Dretske’s story would be a naturalistic
account of representation only if R’s functional role really
were a consequence of the information it carried via the
nomic co-variance relation actually used by the thermostat.
But in none of the examples that Dretske gives to support his
account does he successfully show this. The nomic covariance relation is playing a functional role in these systems,
but not qua information-carrying relations:
The functionality of the strip is to cause something
to happen in very specific conditions. But in this
respect, it is no different than many other devices
that we ordinarily treat as having no
representational function. The firing pin in a gun
similarly bridges a causal gap between the pulling
of the trigger and the discharge of the round. …
However, no one thinks the firing pin functions as
some sort of representational device. (Ramsey,
2003)
More is needed to justify the judgement that one such relation
is a consequence of the information it carries, while the other
is merely a consequence of the causal conditions that obtain.
The mistake, I think, is in supposing there is a difference
between the two cases at all1. A central problem for DR
views, then, is that thus far there has been no success in
providing a naturalistic account of the representation relation.
I take this to be a serious mark against such views.
There are positive reasons for being skeptical about DR
accounts as well. DR is not entailed by RTM; one can
consistently acknowledge that 1. RTM is true — a large range
of human behaviour is best explained by appeal to mental
representations, that 2. Not all human behaviour is best
explained by appeal to mental representations, and, that 3.
RTM is not reducible to a representational theory of the brain.
In other words, one could hold a version of RTM while
denying DR.

Or not. Eliminativist Materialism, EM, is a view that
rejects RTM altogether, although many of the arguments
made from that quarter are aimed at the reality and/or
usefulness of higher-level mental representations such as
beliefs, desires, and the like. More relevant to the current
discussion are the arguments Daniel Dennett offers to fuel his
more radical, low-level, eliminativism of representational
perception.
Dennett (1991) points out that mainstream accounts of
perception illusions, in which perception reports are
temporally incongruous with the actual presentation of
objects being perceived, all assume a Cartesian theatre in
which the sub-processes of the brain come together and either
rewrite the past, by altering our memories, or subpersonally
reconcile contradictory experiences into one final account
before they appear in consciousness. He argues that, since
there is no evidence to support either account over the other,
we should reject the central workspace hypothesis as
explanatorily defunct. Dennett concludes that the real
illusion is the Cartesian theatre itself; there are multiple
processes ongoing at any given moment and those that win
out or ‘rise to the top’ result in behaviour. Though we might
balk at this radical elimination of conscious experience,
Dennett’s powerful arguments against the necessity of a
representational view of perception cannot be ignored.
Finally, many from the embodied/embedded camp in
cognitive science have been developing accounts of
cognition that bottom out in completely non-representational
relations with the world. Antony Chemero (2009), for
example, argues that looking for and modelling the ways in
which the environment constrains and directs cognitive
behaviour is the best approach to developing a
comprehensive account of cognition. Detailed dynamical
systems analyses are on the rise, showing us that, contra
RTM, many factors besides mental representations have
behavioural explanatory force. (Noë,2010; Clark & Toribio,
1994; Beer, 2003; Haken, Kelso, Bunz, 1985)
These anti-representational approaches to cognition find
philosophical support in the work of Merleau-Ponty (1945)
and Heidegger (1927) both of whom argued that our most
fundamental relation with the world is experiential, not
representational. More recently, picking up these threads,
Hubert Dreyfus (2007) contends that the intractability of a
naturalistic account of intentionality should be a clue that any
view founded on DR is doomed.
Finally, neuroscientists such as Walter Freeman (2000)
argue that even were we to ignore the theoretical stumbling
blocks that plague DR accounts, neural activity lacks a
fundamental requirement of any representational vehicle: that
it serve as a constant, consistent, relation to what is
represented. Neural activity is so dynamic, he argues, that
there is nothing at the neural level stable enough to play this
role.

1 Practical realists such as Lynne Rudder Baker (2001) take this
approach as well.

296

language allows us to formulate inferences, make plans, think
about tasks in a linear fashion, and so on, all cognitive
activities our brains are not very good at doing. “Words and
linguistic strings are among the most powerful and basic tools
that we use to discipline and stabilize dynamic processes of
reason and recall.” (Clark, 2006).
More generally, usage-based theories take language to
emerge over time “through the interaction of cognition and
use.” (Ibbotson, 2013; Bybee, 2010; Tomasello, 2003)
From a rather different approach, Christiansen and Chater
(2008) argue (indirectly) against DR by rejecting
evolutionary accounts of language. Instead, they argue that
we should see languages as “‘organisms’; i.e., highly
complex systems of interconnected constraints, that have
evolved in a symbiotic relationship with humans.”
Finally, comprehensive accounts such as Terence Deacon
(2011) set up a wider theoretical framework in the context of
which we can develop the concepts we will need in order to
explain the dynamic co-development of language and our
representational cognitive capacities more completely.
Precisely what mechanisms underwrite our capacity to
develop/use language, how language use yields mental
representations, indeed, whether/how consciousness emerges
as a result of language use, are some of the core research
questions of this new view. As we’ve just seen, there is
already work being done on different aspects of these
questions, but the hard problem of accounting for the shift
from non-representational perception to language to
conscious self-reflection is still more of a chasm than a gap.
A good way to begin closing it is by clarifying the nature of
non-representational perception, since this is precisely the
point at which DR views begin to diverge.
Ironically, one of most compelling positive arguments for
a non-representational view of perception is suggested by a
debate firmly entrenched in the DR framework. In that
context, a distinction is drawn between non-conceptual and
conceptual representations: bare perceptions such as my
seeing a flower now are instances of the former, they do not
require a network of concepts in order to be had, while
judgements of perception such as my thought that flower is
lovely are instances of the latter, these do require conceptual
scaffolding in order to be had. Various arguments are offered
in support of this conceptual/non-conceptual divide, but the
one I will mention here, since it also motivates the nonrepresentational position, is the following set of observations
and inferences.
The perceptual hardware of many animals with whom we
share an evolutionary history is very like our own. It is
plausible, consequently, to suppose that our underlying
perceptual experiences are similar as well. In perception,
things in our environment appear to us in certain ways, e.g.
apples look red, taste sweet, and sound crunchy. For our
evolutionary cousins, though the phenomenal details will
vary with the sensory capacities of the animal in question,
these perceptual experiences are likely similar. It is
implausible, on the other hand, that animals share our
concepts — our conceptual capacity, after all, is what sets us

RTM is Partly Right
Clark, who takes these embodied, embedded objections
seriously, and, who agrees with the anti-representational
view that RTM is not as explanatorily useful as proponents
suppose, nevertheless argues that doing away with
representational explanations entirely won’t do either. (Clark
1997, 1994). Some problem situations are “representationhungry:” to solve them agents require information that is not
directly available from their immediate environment.
Remembering one’s credit card pin when paying for
groceries, mentally running through possible future
contingencies when making plans, feeling regret about past
actions, are all activities that require, ostensibly, a capacity
for mentally representing a situation to oneself. The antirepresentationalist can’t explain our ability to successfully
solve these representation-hungry problems because those
accounts explain all of our behaviour in terms of our direct,
experiential relation with our environments. What happens
when the relevant environment is not there to be experienced?
Motivated by these considerations, Clark (1997) and
Wheeler (2007) have developed a hybrid view in which
perception is a kind of action/representation mix, what they
have termed action-oriented representation (AOR): sensorymotor loops that develop in certain sorts of situations over
time as a result of experience. The fact that these are
idiosyncratic to an agent, to its particular sensory capacities,
and to its environment is meant to address many of the
challenges that traditional, objectivist, representational views
face. In particular, the problem of grounding these
representations in some direct experience with the
environment is met, on these accounts, via these base level,
action-oriented, sensory-motor loops.
But, as Dreyfus has recently pointed out (2007), so long as
perception is assumed to be a representation relation, whether
objective or action-oriented, the problem of intentionality
does not go away.

Language and Perception
The perceptual relation, then, must be nonrepresentational. At the very least, the objections to DR
militate against an out-of-hand dismissal of this view. But
thorough going anti-representationalism, as we’ve just seen,
is inadequate as a comprehensive theoretical framework,
since it cannot account for our ability to think and reason and
plan.
A nice middle ground view, that accommodates both of
these insights, is the hypothesis that language is not a
consequence of our innate, representational capacities – this
would be a DR view; rather, the development of language
makes those capacities possible. Many are developing such
accounts.
Clark, for example, argues that language is best viewed as
a cognitive niche construction, a tool that “transforms
problem spaces in ways that aid thinking and reasoning.”
(2006). On this view, language is a cognitive resource that
complements the capacities of our brains: since our brains are
pattern completers, but language has logic-like structure,

297

“sedimented” in how that city looks to us.
(Dreyfus, 2007)
Things are complicated in the human case, of course,
because we are also language users. Thus, while we are
responding to the world in a non-representational,
experiential way, at the same time, we are responding with
the representational capacities we have developed: we can
label our experiences with words, we can describe to
ourselves and to others various aspects of these experiences,
that is, we can analyse them rather than just see them as
experiential wholes, and we can reason and plan about better
or worse ways of moving away from and toward situations.
Stated in this way, we can see that this account aligns
closely with two-systems views of cognition (Butterfill &
Apperly, 2013; De Bruin & Newen, 2012; Apperly &
Butterfill 2009). Our cognitive capacity includes an older,
quick-response, system that we share with many animals —
instincts, perceptual experiences, and bottom-up motor
responses are governed by this mechanism — and a newer,
slow-response, system, unique to humans — our higher level
conceptual capacities are underwritten by this system.
On this view, contra the anti-representationalist, we do
reflect on our own experiences, that is, represent them to
ourselves. But, contra the proponent of DR, this is a much
more recent cognitive capacity that we’ve acquired, perhaps
as a result of, and with the representational help of, language
development.
Of course there are objections to the two-systems view.
Peter Carruthers, for example, has argued in a number of
different places (Carruthers 2011, 2013) against it, but he
does so within a DR framework. For all the reasons against
DR I’ve presented here thus far, we need to explore twosystems views before rejecting them out of hand.

apart, cognitively speaking. Perception, therefore, involves a
re-presentation of the sensed features of an animal’s
environment, but these re-presentations do not require prior
concepts: an animal can see a red apple as red without having
the concept red. (Peacocke 2001A, 2001B, Bermúdez 1998,
1994)
The problem with this reasoning is that it begins the story
too high up, at personal-level perception. Not only do humans
engage in sub-personal perception, we know this from the
myriad perception illusions that continue to be uncovered; it
is likely that the majority of our perceptions are of this subpersonal sort. From this vantage point, taking the features of
the relatively small set of personal-level perceptions as the
baseline for theoretical analysis seems unwarranted. A more
cautious conclusion of the reasoning above would be that we
share a sub-personal, non-representational, perceptual
capacity with our evolutionary cousins.

Non-Representational Perception
When I perceive something, I am merely experiencing. I
am not, as the DR story goes, responding to a representation
of my experience. Such an idea takes hold when we take
perception to be of a representation on the Cartesian theatre
of the mind, rather than a direct relation to something in the
world. As Dennett says, “… the brain does not bother
"constructing" any representations … That would be a waste
of time and (shall we say?) paint!” (Dennett, 1991)
An example might help make the distinction clearer.
Suppose I am faced by an angry, barking dog. Immediately
I begin to move away. I don’t move away because I’ve
compared my mental representation of this dog with others I
have in my memory, because I’ve concluded that this is a
potentially dangerous dog, because I believe that I ought to
move away, and so on. I move away from the barking dog
because the barking dog is threatening me, or perhaps parts
of me, because the situation is compelling me to move away.
The experience of the barking dog, which includes my
becoming aware of the dog through various sensory channels,
the adrenaline rushing through my body, my increased heart
rate, and so on, all happen while I am, at the same time,
moving away.
Merleau Ponty develops many such examples, describing
how, in moving, I am also re-orienting myself so that I can
get a ‘maximal grip’ on my situation, that is, be in a position
to more accurately perceive what is salient to me now.
(Merleau-Ponty, 1945). Dreyfus sums up this nonrepresentational alternative like this:
According to Merleau-Ponty, as an agent acquires
skills, those skills are “stored,” not as
representations in the agent’s mind, but as the
solicitations of situations in the world. What the
learner acquires through experience is not
represented at all but is presented to the learner as
more and more finely discriminated situations. …
For example, what we have learned from our
experience of finding our way around in a city is

Representation-Hungry Problems Revisited
If our representational capacities are grounded, at least
partly, in something external like language, which is the view
being suggested here, aren’t language-naïve animals who are
nevertheless capable of solving ‘representation-hungry
problems,’ clear counter-examples to the claim?
Some ground-breaking studies of scrub jays (Correia,
Alexis, Dickinson, Clayton, 2007; Clayton & Dickinson,
1998) show that they appear to be among the hallowed group
capable of responding to features of the environment that
were once present, but are no longer: they are able to access
the “what”, “when” and “where” of past experience and thus
pass Endel Tulving’s litmus test for episodic memory. Not
only are they able to remember what kind of food they have
cached in a specific location, but they seem to be sensitive to
how old the food is as well. More recent studies seem to
show, in addition, a capacity for future planning, another
aspect of the episodic memory system. (Clayton, Russell,
Dickinson, 2009) We know that when humans access this
future-directed aspect of episodic memory, they mentally
rehearse past actions in possible future situations. Intuitively
this seems like a paradigmatically representational activity —
we are mentally presenting to ourselves possible situations.

298

If the way in which scrub jays manage this future thinking is
similar to this, then they must also have a capacity for
representation. Or so such reasoning goes.
But on the view of perception I am exploring here,
experience is not a representational activity. If that’s the
case, then re-experiencing past experiences shouldn’t be seen
as a representational activity either. That is, to re-experience
what happened in the past or what might happen in the future
is, at base, to experience, however the experiences are caused.
A scrub jay is compelled to move this way rather than that
way, to dig here rather than there. Nothing in this ability
requires that we adduce a representational capacity, though it
does of course require some form of memory, which need not
be seen as a representational capacity either. When we talk of
‘body memory’, for example, we mean quite explicitly the
sort of memory that does not require representation.

both chimpanzees (Boysen et al. 1996, 1999) and capuchin
monkeys (Addessi and Rossi 2011) are able to maximise
their own reward more consistently.
These studies demonstrate a clear cognitive advantage to
being able to reason in this aloof way: agents are able to make
better long-term decisions for themselves when they have a
tool for over-riding their quick-response, perception-based,
primary cognitive system. There are many other contexts we
could describe in which this ability confers an advantage, but
due to space considerations, I will leave that for another
paper.

Conclusion
As with any new theory, old questions disappear and new
ones emerge: here is a brief look at some of the interesting
changes that flow from this view.
The biggest payoff of this two-systems account is that it
makes the problem of intentionality go away. Perception is
not representation, so there is nothing to naturalise there.
Thinking about and talking are representational activities, but
their representational aspect derives from language itself:
words and sentences are, paradigmatically, symbols.
New theoretical scaffolding will be required at the neural
level: if our fundamental relation with the world is an
experiential, not a representational, one, neurons can no
longer be seen to ‘represent,’ ‘detect,’ or ‘mean’ anything at
all. This is a radical shift, at the level of description and
interpretation of results, for neuroscience.
At the level of language, our understanding of how and
why it developed will change as well. On the DR framework,
it is natural to see language development as growing out of
our desire to communicate our rich, internal representational
lives to one another. But when we let go of this Cartesian
picture, we also let go of this communication motivation for
language. Researchers are already working on developing an
alternative view of why and how language developed in the
first place, but there are many directions we might fruitfully
explore.
One sign of a good theory is that it yields new questions
that open up new lines of research. There isn’t space here to
discuss any of these in detail, but here are just a few of the
less obvious avenues of inquiry that seem to open up once we
shift from DR to this hybrid view:
— What role, if any, does language learning play in the
development of ‘self’?
— Does level of literacy co-relate with amount of time spent
in self-reflective thought?
— If language is a tool that makes thinking about and talking
possible, how much of our mental life is a result of an overuse
of this tool? We know that overuse of our modern social
media technologies, for example, can decrease one’s capacity
for mental focus. Perhaps some of the features of the
contemporary human mind are side-effects of overuse of the
language tool? An inability to be present to experience, which
in turn can lead to many emotional and psychological
problems such as depression, existential angst, feelings of
loneliness, might be fruitfully explored from this angle.

Representation-Hungry Problems Refined
Seen in this way, rather than serving as a counter-example
to the two-systems view being explored here, the example of
the scrub jay shows us that not all seemingly representationhungry problems need be solved in representational ways.
Consequently, we might rename the category more
perspicuously to “experience or memory-hungry” problems
and refine the original representation-hungry category to
include only those problems whose solutions require the
explicit use of representations, not just past learning. But if
recalling past experiences does not require representation,
what does we might wonder.
Arguably one of the greatest advantages of a capacity for
representation is the ability it entails to reason in the absence
of emotionally charged situations. Indeed, it is precisely
when we seem incapable of rising above the emotional
challenges of a particular situation, that we need such tools
most. Representations, because they are stand-ins for the
situations or things they represent, are stripped of the
contextual details we experience in perception. In other
words, representations, such as the thought, the cat is on the
mat, are amodal in a way that perceptions are not:
entertaining the thought, the cat is on the mat feels differently
from actually seeing the cat on the mat. Some recent studies
demonstrate that access to amodal representations allows an
agent to make choices, maximising ones, that would not
otherwise be possible.
Reverse Contingency Tasks are a set of problems that
require agents to make a choice on behalf of some other
agent; the choosing agent then receives whatever is left over.
In standard tasks, a choice is offered between large and small
groups of desirable objects, e.g. bananas or candies. When a
very desirable selection is placed in front of an agent, it is
very difficult for the agent to overcome the pull to pick the
largest group. But picking the largest group is not
maximising since the choosing agent ends up with whatever
was not chosen, namely, the smallest group. Studies have
shown that when the same task is repeated with tokens (that
the subjects have been trained to associate with the relevant
class of desirable objects) rather than the objects themselves,

299

— Following from the previous thought, we might
investigate the effects of meditation as a cognitive enhancing
technique from a new perspective: mindfulness meditation
might be such an effective skill to develop, not because it
yields a new state of awareness, but because it brings us back
into touch with our experiential relation with our
environment, an awareness we are capable of pre-language,
but that is generally over-ridden by our representational
system. On this view, language is the boon that makes this
deeper awareness possible, but it is also the bane that makes
meditation as an ongoing practise necessary. Meditation
teaches us how to keep the flood of words and thoughts where
they are — out there — and frees us from their bondage.

Clayton, N., & Dickinson, A. (1998). Episodic-like memory
during cache recovery by scrub jays. Nature 395: 272–274.
Deacon, T. Incomplete Nature: How Mind Emerged from
Matter. New York: W.W. Norton & Company. 2011.
De Bruin, L., & Newen, A. (2012). An association account of
false belief understanding. Cognition, 123(2), 240-259.
Dennett, D. (1991). Consciousness explained. Boston: Little,
Brown.
Dretske, F. (1988). Explaining Behavior. Cambridge: MIT
Press.
Dreyfus, H. Why Heideggerian AI failed and how fixing it
would require making it more Heideggerian. Artificial
Intelligence 171 (2007) 1137–1160.
Freeman, W. (2000). How brains make up their minds. New
York: Columbia University Press.
Haken H, Kelso JA, Bunz H. (1985). A theoretical model of
phase transitions in human hand movements. Biol Cybern,
51(5):347-56.
Heidegger, M. (1927). Being and Time, (Trans.) J.
Macquarrie & E. Robinson. New York: Harper & Row.
[1962].
Ibbotson, P. (2013). The scope of usage-based theory.
Frontiers in Psychology, 4, 255.
Merleau-Ponty, M. (1945). Phenomenology of Perception,
(Trans.) C. Smith. London: Routledge and Kegan Paul
[1962].
Noë, A. (2010). Vision without representation. In (Eds) N.
Gangopadhyay, M. Madary, & F. Spicer. Perception,
action, and consciousness: sensorimotor dynamics and two
visual systems. New York: Oxford University Press.
Peacocke, C. (2001A). Does perception have a
nonconceptual content? JPhil., 98: 239–264.
Peacocke, C. (2001B). Phenomenology and nonconceptual
content. Phil.Phenomen.Research, 62(3): 609–615.
Peirce, C.S. (1998). The essential peirce. volume 2. (Eds.)
Peirce edition Project. Bloomington: Indiana University
Press.
Ramsey, W. (2003). Are receptors representations? Journal
of Exp.& Theoretical Artificial Intelligence, 15:2, 125-141.
Rudder Baker, L. (2001). Practical realism defended: replies
to critics. In (Ed) A. Meijers. Explaining Beliefs: Lynne
Rudder Baker and her Critics. Stanford: CSLI
Publications, 183-218.
Tomasello, M. (2003). Constructing a language: A usagebased theory of language acquisition. Cambridge: Harvard
University Press.
Wheeler, M., (2004). Is language the ultimate artefact?
Language Sciences, 26, 693–715
Wheeler, M., (2007). Reconstructing the cognitive world: the
next step. Cambridge, MA: A Bradford Book.

References
Addessi, E., Rossi. S. (2011). Tokens improve capuchin
…Proc. of the Royal Society B: Biological Sciences, 278,
1707, 849–854.
Apperly, I, & Butterfill, S. (2009). Do humans have two
systems to track beliefs and belief-like states?
Psychological Review, 116, 4, 953–970.
Beer, R.D., (2003). The Dynamics of active categorical
perception in an evolved model agent. Ad.Beh. 11:209.
Bermúdez, J. (1998). The Paradox of Self-Consciousness.
Cambridge MA: MIT Press.
Boysen, S., Mukobi, K., Berntson, G. (1999). Overcoming
response bias…An.Learn.& Behav.,27, 2, 229–235.
Boysen, S., Berntson.G., Hannan,M., Cacioppo.J. (1996).
Quantity-based interference and symbolic representations
….Journal of Experimental Psychology: Animal Behavior
Processes, 22, 1, 76–86.
Butterfill, S., & Apperly, I. (2013). How to construct a
minimal theory of mind. Mind & Language, 28, 5, 606–
637.
Bybee, J. (2010). Language, usage and cognition.
Cambridge: Cambridge University Press.
Carruthers, P. (2013). Animal minds are real, (distinctively)
human minds are not. Amer.Phil. Quarterly, 50, 233–247.
Carruthers, P. (2011). The Opacity of Mind: An Integrative
Theory of Self-Knowledge. Oxford: Oxford University
Press.
Chemero, A. (2009). Radical embodied cognitive science.
Cambridge: MIT Press.
Christiansen, M. & Chater, N. (2008). Language as shaped
by the brain." Behav.and Brain Sciences, 31.5, 489-509.
Clark, A. (2006). Language, embodiment, and the cognitive
niche. Trends in Cognitive Sciences, 10 (8):370-374.
Clark, A. (1997). Being there: Putting brain, body, and world
together again. Cambridge: MIT Press.
Clark, A., & Toribio, J. (1994). Doing without representing?
Synthese, 101: 401–431.
Correia S., Alexis D., Dickinson A., Clayton. N. (2007).
Western scrub-jays …. Current Biology, 17: 856–861.
Clayton, N., Russell, Dickinson, A. (2009). Are animals
stuck in time or are they chronesthetic creatures? Topics in
Cognitive Science, 1 (2009) 59–71.

300

