                         Modeling sampling duration in decisions from experience
Nisheeth Srivastava, Johannes Müller-Trede                       Paul Schrater                             Edward Vul
        UC San Diego, 9500 Gilman Drive                      University of Minnesota              UC San Diego, 9500 Gilman Drive
              La Jolla, CA 92093 USA                      Minneapolis, MN 55455 USA                    La Jolla, CA 92093 USA
                                Abstract                                   ing, and an overt decision to choose the risky or the safe op-
                                                                           tion, based on the learned information.
     Cognitive models of choice almost universally implicate se-
     quential evidence accumulation as a fundamental element of               Efforts to model the overt decision about which option to
     the mechanism by which preferences are formed. When to                choose have been relatively successful (Erev et al., 2010).
     stop evidence accumulation is an important question that such         Little attention has been paid, however, to modeling the ear-
     models do not currently try to answer. We present the first cog-
     nitive model that accurately predicts stopping decisions in in-       lier latent decision about how long to sample information (or
     dividual economic decisions-from-experience trials, using an          when to stop learning). Research on DFE has used simple
     online learning model. Analysis of stopping decisions across          statistical approaches as place-holders, assuming an under-
     three different datasets reveals three useful predictors of sam-
     pling duration - relative evidence strength, how long it takes        lying probability distribution over sampling lengths and fit-
     participants to see all rewards, and a novel indicator of con-        ting this distribution to the empirical distribution of sampling
     vergence of an underlying learning process, which we call pre-        lengths observed in the data (Gonzalez & Dutt, 2011). Re-
     dictive volatility. We quantify the relative strengths of these
     factors in predicting observers’ stopping points, finding that        cently, Markant et al. (2015) proposed a model that jointly
     predictive volatility consistently dominates relative evidence        predicts choices and sampling length distribution. However,
     strength in stopping decisions.                                       since their model uses known lottery stakes, it cannot speak
     Keywords: response time; decision-making; evidence accu-              to the effects of the specific characteristics of the actual, re-
     mulation; sequential sampling; decisions from experience              alized samples that comprise individual learning experiences
                                                                           in the DFE paradigm.
                            Introduction                                      In this paper, we investigated variables that, on theoretical
  In orienting decision research from analyzing static economic            grounds, are expected to predict sampling lengths in DFE,
  choices towards more dynamic decisions akin to those people              without assuming a priori knowledge of lottery stakes and
  face in everyday life, the decisions-from-experience (DFE)               probabilities. Our analyses of three different datasets re-
  paradigm presents an important step forward (Hertwig, Bar-               vealed the influence of two important variables on sampling
  ron, Weber, & Erev, 2004). The DFE paradigm may be                       duration. One is the difference in the options’ expected val-
  thought of as a modification of the classic certainty equiva-            ues during sampling. The second is a measure of outcome
  lence method commonly used procedure to elicit utility func-             uncertainty we call predictive volatility, which tracks abrupt
  tions for money (see von Winterfeldt & Edwards, 1993). Par-              changes in the magnitude of prediction error an observer ex-
  ticipants in typical certainty equivalence experiments choose            periences while learning about a DFE decision. We further
  between a risky option that pays H with a probability p and L            developed a computational model of sequential sampling for
  with probability 1 − p and a safe option that always pays M,             DFE that uses these predictors to make accurate sampling
  where H > M > L. They learn about the two options’ payouts               length predictions for individual DFE trials.
  and the associated probabilities from explicit descriptions.
     Decisions from experience modify this protocol: Partici-                          Predictors of sampling duration
  pants are not shown payouts or probabilities, and must learn             While largely neglected in the context of DFE, sampling du-
  about them experientially. Several interesting observations              rations have played a key role in research on perceptual de-
  emerge from research on DFE. Subjects sample more variable               cision tasks. Several of the leading theories in this domain
  options and options with higher stakes for longer, for exam-             utilize drift-diffusion models (Forstmann, Ratcliff, & Wagen-
  ple (Lejarraga, Hertwig, & Gonzalez, 2012). They also ap-                makers, 2016). In such models, the principal variable of in-
  pear to underestimate the probability of rare events (Hertwig            terest tends to be the relative evidence strength in favor of
  et al., 2004), though much less so with increasing experi-               either outcome (Bitzer, Park, Blankenburg, & Kiebel, 2014),
  ence (Zhang & Maloney, 2012).                                            measured in log posterior odds. The larger the log odds fa-
     In the particular variety of DFE we consider throughout               voring a particular option, the more decisive–and quicker–
  this paper, typically known as the sampling paradigm, partic-            the evidence accumulation in its favor. In DFE, relative evi-
  ipants are permitted to sample each of two options without               dence strength corresponds to the difference between the im-
  consequence as long as they like, before finally committing              puted value of the two options. Theories of perceptual deci-
  to a binding choice. This protocol is particularly interesting           sions applied to DFE thus suggest that smaller differences in
  since it closely mirrors the flow of information in many ev-             the options’ imputed values should be associated with longer
  eryday settings–learn from the environment ad libitum, then              sampling durations.
  make a choice. Importantly, such choices are actually com-                  Formally, we track the expected value difference (EVD)
  posed of two decisions: a latent decision to terminate learn-            between the two gambles, measured at every sample for each
                                                                       2285

DFE trial,                                                           rationally treat such episodes of volatility as evidence that
                 EV D = pH + (1 − p)L − M,                   (1)     learning has not yet completed, and respond by sampling for
                                                                     longer.
               |H|
where p = |H|+|L|  , and | · | is the number of times an outcome        Formally, we model learning in DFE as a statistically ef-
has occurred in the sequence up to the time at which the mea-        ficient observer sequentially updating estimates of the mean
surement is taken. In the following, we refer to this quantity       parameter Λ of a Poisson distribution tracking the frequency
as the EVD predictor.                                                with which the high outcome of the risky option occurs in the
   Information theory, we suggest, points to a second, com-          sampling sequence. With every new sample, the parameter
plementary factor that might influence sampling durations.           estimate shifts by some quantity ∆Λ. In absolute values, this
From an information-theoretic perspective, the DFE ob-               quantity is mathematically–and, we argue, psychologically–
servers’ goal is to efficiently learn the reward rate of the gam-    expected to decay over time, so that |∆Λt | < |∆Λt−1 |. De-
ble(s) they are sampling. The decision to terminate infor-           viations from this trend constitute predictive volatility. Such
mation gathering may then be seen as an agent’s rational re-         deviations suggest to an observer that some aspects of the task
sponse to a learning procedure that has saturated. In practice,      may remain unlearned, and therefore justify continued sam-
observers, while trying to learn useful models of their envi-        pling. In the case of human observers, the deviations must be
ronment, have access to the prediction errors in such mod-           sufficiently large to be noticeable, which suggests that volatil-
els. Unexpected increases in prediction error magnitude (as          ity is perhaps best thought of as a binary variable which is ei-
illustrated in Figure 1) signal the presence of unlearned envi-      ther present or absent. This led us to formally operationalize
ronmental dynamics, stimulating rational observers to sample         volatility as
more.
                                                                         v(t) = 1 iff |∆Λt | > κ × |∆Λt−1 |, and 0 otherwise.     (2)
          1                                                          The constant κ > 1 determines the smallest noticeable devi-
  Λ      0.5                                                         ation. All our analyses use κ = 2; substantially larger values
                                                                     would degrade the information present in this signal (since
           0                                                         such large fluctuations are statistically infeasible in DFE re-
            0      2         4         6          8        10
         0.5                                                         ward rate estimation, where the set of possible outcomes is
                                                                     very limited); substantially smaller values would add noise
  ΔΛ      0                                                          to the signal, in the form of volatility false positives. Across
                                                                     an entire sampling sequence, the cumulative effect of such
    −0.5
        0          2         4         6          8        10        episodes is measured by the trial volatility load
     0.4
  |ΔΛ|
                                             Volatility                                       V = ∑ v(t),                         (3)
         0.2                                                                                         t
          0                                                          and is referred to, in our following analysis, as the volatility
           0       2        4      6              8        10        predictor.
                           Sample count
                                                                        Finally, observers who know (i.e., have learned) that the
                                                                     standard DFE paradigm pits a safe option against a risky op-
Figure 1: An intuitive view of predictive volatility. When           tion (see above) may want to see all three reward outcomes at
the prediction error in a sequential learning process increases      least once before terminating sampling. Depending on how
abruptly, it is reasonable to infer that the process has yet to      skewed the risky option’s odds are, this can take a relatively
converge. This indicator of the need to keep learning is what        long time. The number of samples it takes to see all three
we call predictive volatility.                                       reward outcomes at least once thus also contains valuable in-
                                                                     formation about the length of the sampling sequence. It en-
   To understand the learning process, we can track the evolu-       ters our predictive model in the form of a counting predictor,
tion of the learned parameter in a simple parametric observer        counting the number of samples it took a participant to see all
model over individual sampling sequences. If a learning pro-         three options at least once.
cedure is efficient, the prediction error is expected to show
an asymptotic gradual decrease, reflecting that estimation is                                   Results
increasingly precise as more data are sampled. Critically, we        We present two sets of results. We first demonstrate, using a
assume that human observers are intuitive statisticians in this      proportional hazards regression analysis, that both the magni-
particular sense – they are implicitly aware that when learning      tude of difference in expected value and the amount of volatil-
is efficient, prediction error gradually declines. But in indi-      ity seen in the sampling sequence influence sampling dura-
vidual learning sequences, this decline is not always mono-          tions as predicted by our theory. Model selection reveals that
tonic. We call deviations from the prediction error’s expected       volatility plays a more influential role in this process.
trajectory episodes of predictive volatility. Observers who are         These results, however, are calculated using post hoc pre-
sensitive to the expected trajectory of prediction error may         dictors that an actual observer would not have access to in
                                                                  2286

real-time. Our second set of results uses sequential counter-                    (A)                       TE                  TC                 LM
                                                                                 Number of participants
parts to these predictors to develop a sequential model that
simulates the trajectory of the stopping probability of any
DFE trial, sensitive to the influence of both differences in ex-
pected value and episodes of volatility experienced in real-
time.
Data
We procured data from two sources: the decisions-by-
                                                                                                                         Z statistic
sampling condition from the Technion Prediction Tourna-                              (B)
ment, which involved two sets (an estimation and a compe-                                                                                     EVD
                                                                                                          LM
tition set) of 40 participants each solving 30 such problems,                                                                                 Volatility
and a sample of 37 participants solving 19 different DFE
                                                                                                          TC
problems we collected in the DFE condition of a different ex-
periment (Experiment 2 in Lejarraga & Müller-Trede, 2016).
We refer to the Technion estimation dataset as TE, the Tech-                                              TE
nion competition dataset as TC, and our own sample as LM.
    Experimental protocols were largely identical across the                                                   -0.4   -0.2          0   0.2            0.4
                                                                                                                             β weight
datasets.1 Participants could sample both options in each lot-
tery pair as often as they liked, and subsequently committed
                                                                          Figure 2: (A) Histograms of subject-wise Z-statistics ob-
to one final draw that would correspond to their actual pay-
                                                                          tained by Cox regression of predictors against sampling se-
out. All participants were compensated via a random incen-
                                                                          quence lengths. Negative Z-statistics indicate that the predic-
tive scheme, and earned real money corresponding to their
                                                                          tor reduces the hazard rate, yielding longer sampling dura-
payout in one randomly selected choice problem. We note
                                                                          tions than baseline expectations. (B) Coefficients from Cox
that participants in LM revisited each choice problem in a
                                                                          multiple regressions using normalized EVD and volatility
group setting between individual trials (for details, see Lejar-
                                                                          predictors for all three datasets.
raga & Müller-Trede, 2016), whereas participants in TE and
TC did not.
                                                                          three datasets tested. Panel B in Figure 2 compares the regres-
Volatility matters more
                                                                          sion coefficients obtained when we use both predictors–EVD
What can the expected value difference between options tell               and volatility–normalized and combining all participants in
us about the decision to stop sampling? Recall that small                 each dataset. In all three cases, the normalized predictors
EVDs may trigger further sampling, whereas large EVDs                     are uncorrelated (r < 0.05, p > 0.25), so the regression co-
supply a reason to choose one option over the other (and thus             efficients (β-weights) are informative about the relative im-
to terminate sampling). The average EVD predictor, defined                portance of the two predictors (Nathans, Oswald, & Nimon,
as T1 ∑tT |EV Dt | for sequences of duration T , should then be           2012). Volatility consistently dominates EVD as a predictor
negatively correlated with sampling lengths. If observers use             across all three datasets.
the weight of economic evidence to decide when to termi-
nate information search, greater average magnitudes of the
expected value difference should correspond to earlier sam-               Table 1: Model selection using BIC. Lower values are better
pling termination and vice versa.                                         within individual datasets. ∆BIC from best model reported in
   We tested this hypothesis by running a Cox proportional                brackets.
hazards regression, assessing the direction and magnitude of                                               TE                  TC                  LM
effect the average expected value difference measured during                  EVD                          14312 (+165)        14643 (+177)        7090 (+63)
a sampling sequence has on the hazard rate across all trials per              Volatility                   14157(+10)          14529 (+63)         7031(+4)
subject. The top panels in Figure 2(A) show that, as expected,                Both                         14147               14466               7027
EVD consistently increases hazard rates across participants in
all three datasets.
   We ran a similar proportional hazard regression using                     A similar conclusion can be drawn by computing the
volatility load as a predictor of sampling sequence lengths.              Bayesian Information Criterion (BIC) for regressions using
As the bottom row in Figure 2(A) demonstrates, volatility                 the two predictors indvidually, and then together. Not only is
load consistently retards hazard rates in participants across all         the full model preferable by BIC, corresponding ∆BIC values
                                                                          show that the volatility-alone model is considerably closer to
   1 Participants in the LM experiment “chose” by alloting fractions      the full model than the EVD-alone model, suggesting that it is
of an allocation budget to either option; TE and TC used binary
choices. Importantly for our purposes, the sampling procedure was         a more powerful predictor. Together, these analyses demon-
the same in all three studies.                                            strate (i) that EVD and volatility are independent sources
                                                                       2287

of information for predicting sampling duration and (ii) that         actual sampling length inflates its correlation with the inde-
volatility is a more informative predictor for sampling dura-         pendent variable. Hence, while the counting predictor prima
tions than EVD.                                                       facie adds substantial predictive value to our model, it does
                                                                      so for reasons that need not be theoretically insightful.
DFE sampling durations are post hoc predictable
How well can our account predict actual sampling durations
                                                                      Real-time stopping point prediction
in the DFE paradigm? A simple additive model combining                While we show that sampling lengths in DFE are substan-
these two predictors,                                                 tially predictable post hoc using objectively observable pre-
                                                                      dictors, not all these predictors are available to decision-
                 duration = volatility + β EVD                        makers at the time of making their decisions. Neither the
                                                                      average EVD magnitude nor the cumulative volatility load
yields correlations r = {0.56, 0.53, 0.45} with human sam-            across the complete sequence is available to an observer who
pling lengths for the TE, TC and LM datasets respectively,            is currently sampling. In the following analyses, we used
suggesting that these predictors can explain around 20-30%            elements of our predictors that are available to observers in
of the variance in sampling durations for human observers in          real-time, and test how well they predict eventual stopping
DFE.2 For lack of competitors–to the best of our knowledge,           decisions.
ours is the first model for predicting DFE sampling durations            To do so, we use computational models that perform the
at the individual trial level–we cannot assess this performance       same sampling task as the observer, stepping through each
comparatively.                                                        trial sample by sample, predicting sequence lengths indirectly
   To further improve predictive ability, we can add the count-       by estimating stopping probabilities λt at each sample. To
ing predictor to the model. Its incorporation yields an aug-          make this analysis feasible, we make the simplifying assump-
mented linear model                                                   tion that there are no individual differences across partici-
                                                                      pants within datasets. Doing so yields multiple data points
            duration = count + α volatility + β EVD                   for each DFE problem, instead of just one per problem-by-
                                                                      participant pair. This allows us to construct a stopping point
which improves the correlations with human data to r =                distribution for each problem.
{0.56, 0.69, 0.71} for the TE, TC, and LM datasets respec-               We then use these stopping point distributions to fit a basic
tively.3                                                              piece-wise constant hazard model that assumes the stopping
   Note that adding the counting predictor did not improve            probability increases linearly with the sampling count t, i.e.,
the data-model correlation for the TE dataset. This is because
participants in this dataset strongly violated the expectation                                                  λt+1 − λt = δ,                                              (4)
that participants would want see all three outcomes at least          and fit {λ0 , δ} for each unique problem using a grid search,
once. Of the 1200 total trials in this dataset (40 participants       maximizing the statistical indistinguishability (measured us-
× 30 problems), as many as 742 trials (62%) were termi-               ing a two-sided T test; typical values p > 0.95) between the
nated without having seen all three outcomes, including 192           empirical stopping point distributions and the model’s pre-
(16%) that were terminated after drawing just two samples             dicted stopping point distribution, averaged across multiple
altogether. For comparison, participants in the TC and LM             simulations (N=1000). We kept these {λ0 , δ} values fixed in
datasets terminated 41% and 14% of all trials before seeing           the subsequent models we describe below, fitting only the ad-
all three possible outcomes, respectively. We suspect that the        ditional parameters.
higher sampling effort in the LM dataset may reflect addi-
                                                                                       40                                                       100
                                                                                                                              Model sequence length
tional intrinsic motivation participants in that study derived
                                                                     Sequence length
from the repeated social interactions between choice prob-                             35                                                             80
lems.                                                                                                                                                 60
                                                                                       30
   In the other two datasets, adding the counting predictor
boosts the data-model correlation to ≈ 0.7, so the augmented                           25                                                             40
model explains around 50% of the variance in those data. The                           20                             Data                            20
large improvement in predictive ability somewhat overstates                                                           Model
                                                                                       15                                                             0
the predictor’s true explanatory value, however. To see why,                             0   0.25      0.5     0.75       1                            0    20   40   60          80
                                                                                                    Quantile                                               Human sequence
note that the sample count at which all three options have
been seen once, by definition, cannot exceed the overall sam-
pling sequence length. The counting predictor is thus upper-          Figure 3: While simple statistical models of sampling lengths
bounded by the independent variable it is used to predict. The        can reproduce population-level statistics (left), they (right)
resulting absence of counting predictor values greater than the       fail to predict sampling sequence lengths for individual tri-
                                                                      als. Results shown for LM dataset.
   2 Best
        fit β = 0, −0.1, −0.4.
   3 For best fit values of α = {3.8, 5.9, 2.6} and β =                 This simple model theoretically and empirically resembles
{−0.2, −0.4, −0.9} respectively.                                      previous sampling length models proposed in the literature,
                                                                  2288

which assess model fit by testing whether it produces the                  Finally, when we incorporated the counting predictor into
same statistical distribution of sampling lengths as the un-            our model in the form of a real-time decision threshold–if
derlying data (Gonzalez & Dutt, 2011; Markant, Pleskac,                 all options seen at sample t, terminate with probability λt ,
Diederich, Pachur, & Hertwig, 2015). Figure 3 illustrates               otherwise, terminate with probability λ0 –the correlations im-
that our baseline model closely approximates the empirical              proved substantially, to {0.44, 0.38, 0.41}, for the same pa-
distribution of sampling lengths, much like existing models             rameter values as in the previous model. Unlike in the aggre-
(compare left panel with Figure 1 in Markant et al., 2015). It          gate analysis, the effect of the counting predictor in sample-
is a poor predictor of sampling lengths at the individual trial         by-sample data does not necessarily suffer from the problem
level (r = 0.03, right panel), however, which illustrates a ba-         of artifactual inflation of correlation. These numbers thus
sic limitation of this modeling approach.                               present a fair picture of the predictability of sampling dura-
                                                                        tions using only real-time information. Empirical estimates
                                                                        of the test-retest reliability of participants’ sampling lengths
Table 2: Best fit correlations of sampling durations predicted
                                                                        would be required to assess how well our model’s perfor-
by sequential models with human data in all three datasets.
                                                                        mance matches the best possible performance.
   Models                                    TE       TC     LM
   Baseline                                  -0.04    0.02   0.03                                 Discussion
   Baseline + Vol                            0.20     0.11   0.19
                                                                        This paper develops theory and algorithms to predict sam-
   Baseline + EVD                            0.15     0.11   0.06
                                                                        pling durations in economic decisions from experience in
   Baseline + EVD + Vol                      0.26     0.18   0.21
                                                                        which observers freely sample options before committing to
   Baseline + EVD + Vol + Counting           0.44     0.38   0.41
                                                                        a binding choice. We argue and then empirically demonstrate
                                                                        that a combination of evidence strength, predictive volatility,
    Next, we added a volatility predictor to the model. In              and simply tracking how long it takes participants to observe
particular, we assumed that the baseline stopping probabil-             the entire reward structure of the particular DFE problem they
ity would increase by ∆ every time the observer encounters              are solving goes a considerable way in explaining individ-
volatility in the sampling sequence,                                    ual decisions to stop sampling. Previous attempts to mod-
                                                                        eling information search in DFE succesfully reproduced dis-
                      λt+1 − λt = δ + v(t)∆.                    (5)
                                                                        tributions of sampling duration but were effectively random
    Here, volatility refers to single episodes of volatility within     in trial-level predictions. Our account matches these previ-
a sampling sequence as defined in Equation 2, not the cumu-             ous attempts in distribution-level performance and surpasses
lative quantity (“load”) measured across the entire sequence.           them in making reasonably accurate trial level predictions.
If volatility retards the termination probability as predicted,         Finally, since it yields direct stopping point predictions, our
negative values of ∆ will yield greater correlations of the             model could easily be combined with choice models that re-
model’s sample sequences with human data. As Figure 4                   spect the epistemic limitations of sampling-based DFE such
illustrates, observer models that reduce stopping probability           as primed sampling or natural means (Erev et al., 2010) to
when encountering volatility (∆ < 0) indeed provide the best            make joint predictions of choice and sampling duration.
fit to the data in all three datasets. Our hypothesis about the            Of the three predictors we examine, one–the number of
influence of volatility thus finds clear support in the data.           samples required to observe all possible outcomes–is spe-
    We ran a similar analysis to measure the sample-by-sample           cific to DFE. Its predictive power is substantial, which is in-
impact of the EVD predictor. We assumed that incoming                   teresting because it suggests that participants in DFE exper-
signals of greater relative evidence strength would affect the          iments both discern an aspect of the task structure not ex-
stopping probability following a logistic relationship, with            plicitly described to them (i.e., that each choice is between a
larger values having a disproportionally larger effect. Thus,           safe option and a risky option with exactly two possible out-
                   λt             λt0                                   comes), and adaptively react to it. The other two predictors–
             log         = log          + k log |dt + 1|,       (6)     evidence strength and volatility–are substantially more gen-
                 1 − λt         1 − λt0
                                                                        eral and may thus be used to predict sampling duration in
where λt0 is obtained from Equation 4, k is fitted to the data          other experimental modalities. For example, Juni et al. have
to maximize the model-data correlation, and dt is the EVD               demonstrated that observers sample for longer when encoun-
calculated using the sequence up to the t th sample. Table 2            tering noisier stimuli in a visuomotor estimation task (Juni,
provides a summary of the results.                                      Gureckis, & Maloney, 2011). In this modality, greater stim-
    To combine the influence of volatility and EVD, we revis-           ulus noise corresponds directly to lower evidence strength,
ited Equation 6 with λ0 calculated via Equation 5, and with             and as in our case, lower evidence strength is associated with
{∆, k} as free parameters. The best overall model fit yielded           longer sampling.
weakly positive correlations across the three datasets.4                   Our discovery of the significant influence of predictive
    4 Best fit parameter values for all three datasets:        ∆ =      volatility on sampling duration warrants further investigation.
{−0.20, −0.15, −0.125}, k = {0.02, 0.02, 0.02}.                         Predictive volatility is a highly accessible information signal
                                                                    2289

                                                     TE                                                               TC                                                                LM
         Data-model correlation                                        Data-model correlation                                             Data-model correlation
                             0.2                                                                0.2                                                                0.2
                             0.1                                                                0.1                                                                0.1
                                  0                                                              0                                                                  0
                        -0.1                                                                -0.1                                                             -0.1
                                      -0.1   -0.05    0   0.05   0.1                                  -0.1   -0.05     0     0.05   0.1                                  -0.1   -0.05   0    0.05   0.1
                                                     Δ                                                                Δ                                                                 Δ
Figure 4: Model-data correlations for observer models fitted using different increments to stopping probability when encoun-
tering volatility.
that observers could draw on in a variety of real-world deci-                                                              Friston, K., Shiner, T., FitzGerald, T., Galea, J., Adams, R.,
sions from both experience and memory. To date, researchers                                                                  Sporns, O., et al. (2012). Dopamine, affordance and active
have modeled response durations as arising from either ev-                                                                   inference. PLoS Comput Biol, 8(1), e1002327.
idence accumulation rising to a fixed threshold (Forstmann                                                                 Gonzalez, C., & Dutt, V. (2011). Instance-based learning: In-
et al., 2016), or from a time-sensitive threshold collapsing                                                                 tegrating sampling and repeated decisions from experience.
to meet accumulating evidence (Thura, Beauregard-Racine,                                                                     Psychological Review, 118(4), 523.
Fradet, & Cisek, 2012). Our results suggest that thresholds                                                                Hertwig, R., Barron, G., Weber, E. U., & Erev, I. (2004).
need not stay fixed or fall over time. Instead, they could                                                                   Decisions from experience and the effect of rare events in
rise and fall adaptively within trials in response to sequence-                                                              risky choice. Psychological Science, 15(8), 534–539.
dependent predictive volatility. Volatility’s representational                                                             Juni, M. Z., Gureckis, T. M., & Maloney, L. T. (2011). Dont
generality, alongside our demonstration of its consistent and                                                                stop til you get enough: adaptive information sampling in a
considerable impact on DFE stopping point decisions, invites                                                                 visuomotor estimation task. In 33rd Annual conference of
further exploration in other experimental designs.                                                                           the cognitive science society (pp. 2854–2859).
   The role of predictive volatility in determining when to ter-                                                           Lejarraga, T., Hertwig, R., & Gonzalez, C. (2012). How
minate sampling could also streamline the functional inter-                                                                  choice ecology influences search in decisions from experi-
pretation of cortico-striatal dopaminergic activity in decision-                                                             ence. Cognition, 124(3), 334–342.
making (Schultz, Dayan, & Montague, 1997). Dopamine has                                                                    Lejarraga, T., & Müller-Trede, J. (2016). When experience
been experimentally associated with encoding both reward                                                                     meets description: How dyads integrate experiential and
and prediction error. The latter association appears to be more                                                              descriptive information in risky decisions. Management
robust, however, in that it is congruent with a larger literature                                                            Science (in press).
on the role of prediction error in multiple motor, cognitive                                                               Markant, D., Pleskac, T. J., Diederich, A., Pachur, T., & Her-
and perceptual functions (Friston et al., 2012). Our account                                                                 twig, R. (2015). Modeling choice and search in decisions
provides a rationale for why dopaminergic activity could be                                                                  from experience: A sequential sampling approach. In 37th
temporally correlated with the choice process without actu-                                                                  annual conference of the cognitive science society.
ally encoding reward: It may instead play a critical role in the                                                           Nathans, L. L., Oswald, F. L., & Nimon, K. (2012). Inter-
latent decision to make a choice, and to terminate information                                                               preting multiple linear regression: A guidebook of variable
search.                                                                                                                      importance. Practical Assessment, Research & Evaluation,
                                                                                                                             17(9), 1–19.
                                                 References                                                                Schultz, W., Dayan, P., & Montague, P. R. (1997). A neu-
                                                                                                                             ral substrate of prediction and reward. Science, 275(5306),
Bitzer, S., Park, H., Blankenburg, F., & Kiebel, S. J. (2014).                                                               1593–1599.
  Perceptual decision making: drift-diffusion model is equiv-                                                              Thura, D., Beauregard-Racine, J., Fradet, C.-W., & Cisek, P.
  alent to a bayesian model. Frontiers in human neuro-                                                                       (2012). Decision making by urgency gating: theory and ex-
  science, 8.                                                                                                                perimental support. Journal of Neurophysiology, 108(11),
Erev, I., Ert, E., Roth, A. E., Haruvy, E., Herzog, S. M., Hau,                                                              2912–2930.
  R., . . . Lebiere, C. (2010). A choice prediction competi-                                                               Von Winterfeldt, D., & Edwards, W. (1993). Decision analy-
  tion: Choices from experience and from description. Jour-                                                                  sis and behavioral research. Cambridge, MA (USA) Cam-
  nal of Behavioral Decision Making, 23(1), 15–47.                                                                           bridge Univ. Press.
Forstmann, B., Ratcliff, R., & Wagenmakers, E.-J. (2016).                                                                  Zhang, H., & Maloney, L. T. (2012). Ubiquitous log odds:
  Sequential sampling models in cognitive neuroscience:                                                                      a common representation of probability and frequency dis-
  Advantages, applications, and extensions. Annual review                                                                    tortion in perception, action, and cognition. Frontiers in
  of psychology, 67, 641–666.                                                                                                Neuroscience, 6.
                                                                                                                     2290

