                                               Vector Space Semantic Models
                   Predict Subjective Probability Judgments for Real-World Events
                                            Sudeep Bhatia (bhatiasu@sas.upenn.edu)
                                        Department of Psychology, University of Pennsylvania
                                                            Philadelphia, PA.
                              Abstract                                 are valuable, as they allow for rigorous tests of scientific
                                                                       hypotheses. However, in order for association-based
   We examine how people judge the probabilities of real-world
   events, such as natural disasters in different countries. We        heuristics to be considered good models of subjective
   find that the associations between the words and phrases that       probability judgment, they should be able to predict the
   constitute these events, as assessed by vector space semantic       specific probabilities individuals assign to the occurrence of
   models, strongly correlate with the probabilities assigned to       real-world events, that is, the types of events that
   these events by participants. Thus, for example, the semantic       individuals encounter and evaluate on a day-to-day basis.
   proximity of “earthquake” and “Japan” accurately predicts           Thus we should not only be able to state that individuals
   judgments regarding the probability of an earthquake in             place a higher probability on Linda being a feminist bank
   Japan. Our results suggest that the mechanisms and                  teller compared to a bank teller, but also predict the explicit
   representations at play in language are also active in high-
                                                                       probabilities individuals attach to, for example, various
   level domains, such as judgment and decision making, and
   that existing insights regarding these representations can be       outcomes in current affairs or popular culture. These types
   used to make precise, quantitative, a priori predictions            of events are often of the form “X happens to Y” (e.g. an
   regarding the probability estimates of individuals.                 earthquake occurs in Japan), and associative heuristics
                                                                       predict that the association between X and Y (e.g.
   Keywords: Judgement and decision making; Subjective
                                                                       “earthquake” and “Japan”) is used by individuals to judge
   probability; Semantic representation; Semantic space models
                                                                       the probabilities of these types of events.
                                                                           Predicting real-world judgments is not trivial: Although
                          Introduction                                 associative heuristics are easy to apply, the information that
      Subjective probability judgment plays an important role          these heuristics utilize is fairly complex. Thus, even though
in everyday cognition and behavior. Our interactions with              decision makers may use the strength of association
the world around us are guided by the probability estimates            between “earthquake” and “Japan” to predict the probability
we place on its largely uncertain events. These estimates, in          of there being an earthquake in Japan, it is not immediately
turn, stem from our knowledge of the world, and the                    clear what determines these associations, and in turn what
cognitive mechanisms that we possess for learning,                     the decision maker’s actual probability judgment about an
representing, and applying this knowledge.                             earthquake in Japan will be.
     The study of subjective probability judgment has yielded              Associative processing is also of interest in the study of
a number of valuable insights regarding how individuals                language, and there have been many recent advances in
assign probabilities to uncertain events (Kahneman &                   understanding the determinants of association, or more
Tversky, 1973; Lichtenstein, Fischhoff & Phillips, 1977;               generally, semantic relatedness, as it applies to people’s
Tversky & Koehler, 1994; Wallsten & Budescu, 1983). One                comprehension and use of words (Bullinaria & Levy, 2007;
of the most important of these insights involves the use of            Griffiths, Steyvers, & Tenenbaum, 2007; Jones & Mewhort,
simple heuristics, such as those relying on associations               2007; Landaur & Dumais, 1997; Lund & Burgess, 1996).
between the various objects or concepts involved in the                The key insight underlying these advances is that the
judgment task (Kahneman & Frederick, 2002; Sloman,                     representation of words depends on the statistical structure
1996). The use of association-based heuristics is relatively           of the environment in which these words occur (see also
effortless, though it can lead to biases in specific settings.         Firth, 1957 and Harris, 1954). Studying the distribution of
This is one reason why, for example, individuals commit the            words in the types of settings people encounter on a day-to-
conjunction fallacy in the Linda problem (Tversky &                    day basis can uncover the representations that people have
Kahneman, 1983), which asks them to judge whether Linda,               of everyday words, and in turn the semantic relationships
a female activist concerned with issues of social justice, is          and associations between these words, and the objects and
more likely to be a bank teller or a feminist bank teller. Here        concepts they represent.
the description of Linda is strongly associated with                       Models that build semantic representations using the
feminism, making participants believe that the probability of          distribution of words often characterize each word in their
Linda being a feminist bank teller is higher than her being a          vocabulary as a vector in a highly multidimensional space.
bank teller, despite the fact that all feminist bank tellers are       The proximity between the vectors of two words
in fact also bank tellers.                                             corresponds to the relatedness or association of the words,
     The events considered in most research on associative             so that synonyms and other closely related words are
judgment are abstracted or artificial. These types of tasks            frequently located near each other. Vector space semantic
                                                                  1937

models are typically trained on very large natural language        numbers that allowed us to obtain a sufficient number of
text corpora, and subsequently have large vocabularies,            estimates for each event.
which can be used to make predictions regarding judgments
of word similarity, the strength of word priming, and related      Materials and Procedure
psycholinguistic phenomena, for nearly all the words                    The first four of our studies asked participants to judge
commonly used in a given language. The predictions of              the probability that various man-made and natural disasters
these models have been shown to be highly accurate,                would happen in the different countries of the world. For
suggesting that the representations recovered by these             each of the countries offered to the participants, they were
models provide a good characterization of the                      asked to assess the probability that the country would
representations underlying semantic processing in language         experience a terrorist attack in the next week (Study 1), be
use. For this reason, these models are also popular in             in a state of war at the start of 2016 (Study 2), experience an
machine learning and artificial intelligence, particularly in      earthquake over the next year (Study 3), or experience an
applications related to computer processing of natural             epidemic over the next year (Study 4). Each participant in
language (see Turney & Pantel, 2010).                              each study was given a list of 30 countries chosen at random
    Hare, Jones, Thomson, Kelly, and McRae (2009) have             from the 193 countries that were members of the United
shown that the word associations captured by vector space          Nations when the studies were run.
approaches are able to account for priming effects regarding            The remaining four studies asked participants to make
event representation. Relatedly, Paperno, Marelli, Tentori,        judgments about various famous people in the United
and Baroni (2014) have found that word association                 States. For each person offered to the participant, he or she
correlates very strongly with explicit probability judgments       was asked to assess the probability that the person would be
of word co-occurrence. These results suggest that the              the U.S. president in 2020 (Study 5), win a Nobel Prize in
representations and associations that guide word use and           2020 (Study 6), win a Grammy Award in 2020 (Study 7), or
comprehension may also be the ones involved in making              win an Academy Award in 2020 (Study 8). The list of
probability judgments for real-world events, and that vector       famous people used in this study was obtained from a
space semantic models could in turn be used to predict these       separate pool of MTurk participants (mean age = 36.81,
probability judgments. Thus, for example, we could obtain          56% male) who were each asked to write the names of ten
an estimate of the actual probability individuals assign to        highly recognizable people in the United States that were
there being an earthquake in Japan by examining the                still alive. The 50 most frequent names generated by these
(linguistic) association between “earthquake” and “Japan”          participants were used in Studies 5-8. Again, each
generated by vector space semantic models.                         participant in Studies 5-8 was asked to make judgments
    In this paper we test this idea by studying subjective         about 30 people chosen randomly from our list of 50 people.
probability judgments about different countries and different           Probability judgments for each of the countries in
famous people. Our tests utilize vector representations            Studies 1-4 and each of the people in Studies 5-8 were made
released by Google Research, which are based on the                on a slider scale between 0-100%. The 30 events offered to
recurrent neural network methods proposed by Mikolov and           each participant were presented one after the other, on
coauthors (Mikolov, Chen, Corrado, & Dean, 2013;                   separate screens, in a random order. With the 30 judgments
Mikolov, Sutskever, Chen, Corrado, & Dean, 2013).                  for each of the 200 participants, we obtained approximately
Across eight studies we ask participants to assign                 30 probability estimates for each of the events considered in
probabilities to various natural events happening in these         Studies 1-4. Likewise, with the 30 judgments for each of the
countries (e.g. earthquake in Japan) and to these people (e.g.     100 participants, we obtained approximately 60 probability
Jon Stewart becoming president), and we predict judged             estimates for each of the events considered in Studies 5-8.
probabilities using the distance between the vectors for the
various words and phrases that make up the events.                 Overview of Analysis
                                                                        In this paper we utilize a set of pretrained vector
                          Methods                                  representations recently released by Google Research
                                                                   (code.google.com/p/word2vec). These vectors have been
Participants
                                                                   trained on a 100 billion word subset of the Google News
    Our tests involve eight distinct studies with 200              corpus, by continuous bag-of-words (CBOW) and skip-
participants each in Studies 1-4 and 100 participants each in      gram techniques of Mikolov et al. (2013a, 2013b). This
Studies 5-8, leading to a total of 1,200 participants (overall     approach relies on a recurrent neural network that, for the
mean age = 34.81, 51% male). These participants were               CBOW technique, attempts to predict words using other
recruited from Amazon Mechanical Turk, and performed               words in their immediate context, and for the skip-gram
the studies online, for which they were each compensated           technique, attempts to the do the inverse of this. These
$0.50. Our studies included an attention check question and        representations have a vocabulary of 3 million words and
we excluded the 31 participants who failed this attention          phrases, including countries and names with two or more
check across the studies. The number of participants in the        component words, such as “United States” and “Jon
above studies was determined prior to running the studies,         Stewart”. The recent successes of Mikolov et al.’s methods,
and the specific numbers were chosen as they were round
                                                               1938

the large amount of training data and resulting vocabulary          Studies 7 and 8. In these studies, the average probabilities
used in the word representations, and the fact that these           assigned to different people winning these awards appear to
representations have been obtained from a news corpus,              be roughly uniformly distributed between 0% and 70%. In
make them particularly valuable for the tests we are                contrast we observe the lowest dispersion in average
conducting.                                                         estimates of epidemic and earthquake probabilities in
    Each of the 3 million vectors we use is described on 300        Studies 3 and 4, in which average event probabilities are
dimensions, and the linguistic association between any two          clustered between 20% and 40%.
words or phrases can be computed using the distance                     The main independent variable in this paper will be the
between their corresponding vectors in this 300 dimensional         linguistic association between the word and phrases in an
space. In this paper we use the distance between                    event. Again, this measure is the cosine similarity between
“terrorism”, “war”, “earthquake”, and “epidemic” and the            the disasters and countries (in Studies 1-4) or the awards
words corresponding to the 193 countries to predict the             and people (in Studies 5-8). Although cosine similarity can
probabilities that participants assign to the disasters             vary between -1 and +1, associations between the words in
happening in the countries in Studies 1-4. Likewise we use          941 out of the 968 events in our studies were positive. The
the distance between “president”, “Nobel Prize”, “Grammy            distributions of these associations were, as with probability
Award”, and “Academy Award” and the names of the 50                 estimates, most dispersed for events involving Grammy and
famous people to predict the probabilities that participants        Academy awards in Studies 7 and 8, and least dispersed for
assign to the people winning these awards in Studies 5-8.           events involving epidemics and earthquakes in Studies 3
Thus for example, we can calculate the association of               and 4. The distribution of average event probabilities and
“earthquake” and “Japan” or of “President” and “Jon                 word associations for the different events in our studies can
Stewart” using the distance between each of these pairs of          be observed in Figures 1A-1H.
vectors, and in turn use this distance to predict the
probability people assign to there being an earthquake in           The Predictive Power of Word Associations
Japan, or to Jon Stewart becoming president. The metric of              Can associations predict event probabilities? Recall that
distance we consider is cosine similarity, so that the distance     for each of the 968 events across our studies we have both
between any two vectors a and b is given by dist(a,b) =             the average probability assigned to the event by our
a∙b/(||a||∙||b||). This metric varies between -1 and +1 (with -1    participants, and the association (or, more formally, cosine
capturing orthogonal vectors and +1 capturing vectors with          similarity) between the words in the event, specified by our
identical directions). Additional details about Mikolov et          set of vector representations. A first step in our analysis is
al.’s Word2Vec training techniques can be found in                  examining the correlation between word associations and
Mikolov et al (2013a, 2013b). Note that in analyzing                the average estimates of participants. A standard test using
Studies 5 and 6, we remove famous people who have                   Pearson’s correlation reveals positive, significant
previously won Nobel Prizes or have previously served two           correlations between these two variables in each of our
terms as the president of the United States (these awards or        studies (p < 0.001). Overall our approach does best in
positions cannot be won again in the future). We also               Studies 7 and 8, which involve judgment of popular culture,
exclude participant judgments regarding St. Vincent and             particularly the probability of various people winning
Grenadines, as this country is not represented in the set of        Grammy Awards and Academy Awards. Here word
word vectors released by Google Research.                           associations and average participant probability estimates
                                                                    have correlations of 0.89 and 0.90 respectively. Our
                               Results                              approach is also highly successful at predicting judgments
                                                                    of terrorism and war in different countries, in Studies 1 and
Overview of Data                                                    2, with correlations of 0.62 and 0.64 respectively.
    Recall again that there are about 30 participant                Predictions regarding judgments of presidential victories
judgments of event probability for each of the 193 events in        and Nobel Prizes for different people in Studies 5 and 6
Studies 1-4, and about 60 participant judgment of event             achieve correlations of 0.59 and 0.48 respectively. The
probability for each of the 50 events in Studies 5-8. In this       model does worst in predicting judgments of natural
paper our main dependent variable will be the probability           disasters in different countries, with correlations for
estimate for an event obtained by averaging all the                 earthquakes in Study 3 and epidemics in Study 4, being 0.44
probability estimates made by participants for that event.          and 0.57. Scatter plots displaying the relationship between
We find that these average probability estimates vary               word associations and participant judgments can be seen in
substantially with the event that participants are required to      Figures 1A-1H , and the correlations outlined here are
judge, with, for example, the average probability assigned to       summarized in Table 1.
there being an earthquake in Japan over the next year being             It is interesting to note the above analysis does not
55.03% (N = 33, SD = 25.24) and the average probability             involve any model fitting, and the word associations we use
assigned to there being an Earthquake in Norway being only          are already built in to the vector representations released by
11.88% (N = 18, SD = 16.78).                                        Google Research. Ultimately, the results discussed here
    Average event probabilities are highly dispersed for            (such as correlations of 0.89 and 0.90 between word
judgments regarding Grammy and Academy awards in
                                                                1939

associations and participant probability judgments for                      vary between 0.19 (for earthquake judgments in Study 3)
popular culture events) emerge from what is essentially a                   and 0.80 (for Academy Award judgments in Study 8). More
zero parameter model.                                                       details about these fits are provided in Table 1.
                                                                                The differences in the correlations and fits across the
                                                                            eight studies could be attributed to varying uses of
                                                                            association-based heuristics in different domains. Perhaps
                                                                            participants are just more likely to apply associative
                                                                            processing when making judgments of pop culture, as in
                                                                            Studies 7 and 8, compared to judgments regarding natural
                                                                            disasters in different foreign countries or winners of Nobel
                                                                            Prizes, as in Studies 3, 4, and 6. Alternately, it is possible
                                                                            that we have the highest correlations in Studies 7 and 8
                                                                            because our participants have more knowledge about
                                                                            popular culture than they do about natural disasters or Nobel
                                                                            Prizes. Due to their increased knowledge they are more
                                                                            likely to make fine grained probability assessments in
                                                                            Studies 7 and 8, allowing for a cleaner dataset on which to
                                                                            predict probability judgments. Indeed, as discussed above,
                                                                            average probability estimates for the events in Studies 7 and
                                                                            8 have a much higher spread than average estimates in
                                                                            Studies 3 and 4.
                                                                                The above analysis has only attempted to predict the
                                                                            average probability estimate placed on the events by our
                                                                            participants. This type of aggregation is desirable for many
                                                                            reasons (see e.g. Wallsten, Budescu, Erev & Diederich,
                                                                            1997 for a review). However it ignores the variance across
                                                                            participants in their judgments of the probabilities. Do word
                                                                            associations provide a good account of probability judgment
                                                                            when we allow for participant-level heterogeneity? We can
                                                                            test this on participant-level data using a linear regression
                                                                            model with participant-level random intercepts. As many
                                                                            individual participant estimates, unlike aggregate estimates,
                                                                            lie at the boundaries of the probability scale (i.e. at 0% and
                                                                            100%) the regression we use permits a censored dependent
                                                                            variable using the Tobit method (Tobin, 1958). With these
                                                                            controls we find that cosine similarity has a strong positive
                                                                            significant relationship with probability estimates in each
                                                                            study (p < 0.001 for each study), showing that associations
                                                                            can predict not just aggregate probability judgments but also
                                                                            probability judgments on an individual level.
Figures 1A-H: Scatter plot of the word associations (in terms of cosine
similarity) generated by the model and average participant probability
estimates (in terms of percentage) for the events in Studies 1-8
respectively.
     Some model fitting could, however, help us better
understand the properties of the approach we are proposing.
For this purpose we first consider a simple linear model,
which transforms the cosine similarity measure of word
association, which ranges from -1 to 1, into a probability
judgment scale, which ranges from 0 to 100. Note that such
a linear fit would not change correlations or their
significance levels, but would allow for a better                           Table 1: Summary of correlations (ρ) and R2 values from linear,
                                                                            logarithmic, and logistic model fits for the events in Studies 1-8. Note that
understanding of the degree of variance in the data                         all model fits involve two free parameters, and that the correlations
explained by our approach. After fitting linear models for                  correspond to those displayed in Figures 1A-H. All of these correlations are
the eight studies, using a basic linear regression, we                      highly significant (p < 0.001).
unsurprisingly find highly significant relationships between
word associations and participant judgments (p < 0.001 for
each of the studies). Overall the R2 statistics for these fits
                                                                        1940

Testing Non-linear Relationships                                                   Discussion and Conclusion
    Psychophysical judgments are often characterized by                 In this paper we find that vector semantic space
non-linear relationships, as with the Weber-Fechner law,            approaches can predict the probability judgments that
and it is possible that the associations decision makers            people make about various events in the world. More
perceive between the words in the event at hand are                 specifically, the associations between words and phrases, as
transformed non-linearly before being mapped onto                   assessed by a set of vector representations released by
probability judgments. We can test this by comparing the            Google Research and trained using the recurrent neural
fits of the above linear model with a group of similarly            network methods proposed by Mikolov et al. (2013a,
parameterized non-linear models. The first model we                 2013b), correlates very heavily with the probabilities that
consider takes a natural-log transformation of the                  people assign to natural events described using those words
associations for each event. These transformed values are           and phrases. Furthermore, model fitting indicates that this
then fit by minimizing mean-squared error. As with the              relationship is linear, rather than logarithmic or sigmoidal.
untransformed linear regression, this is a two parameter                There are some limitations to the approach we have
model. Thus if we write the average probability estimates as        proposed. For example, vector space semantic models
y and the word associations for an event as x, our                  cannot by themselves modify their output to control for the
logarithmic model would attempt to find parameters β 0 and          length of time the events are supposed to occur. Thus, the
β1 to fit y = β0 + β1 ln(x). Note that the log transform cannot     approach described above would give the same probability
be used on negative numbers. A very small minority the              estimate for an earthquake in Japan in the next one year, as
cosine similarity values for the events are in fact negative.       it would for a similar earthquake in the next five years.
These have been ignored in our analysis (none of the results        There is some evidence that human probability judgment
change if we use more complex log-based functions for               doesn’t sufficiently account for magnitudes, such as
transforming these negative numbers).                               durations of the events (see Fredrickson & Kahneman,
    The second model we consider is a logistic curve. Such          1993), but there is no doubt that our predictions could be
sigmoidal (s-shaped) curves are frequently used to obtain           improved by allowing for a secondary system that adjusts
choice probability estimates in discrete choice experiments,        the estimates obtained through semantic relatedness based
as their outputs are bounded by 0 and 1, and the logistic           on event duration, as well as other non-sematic features of
curve is perhaps the most commonly used of all of these             the event at hand.
(E.g. with Luce’s choice rule). We fit the two-parameter                Performance could also be improved by fitting the
logistic curve by minimizing mean-squared error, with the           vector space models to the data. Recall that the above
cosine similarity values as our independent variable and the        analysis only performs a transform of cosine similarity to
average participant probability estimates as our dependent          predict probability judgment. It alters neither the number of
variable. Here if we write the average probability estimates        dimensions used in the model, nor the size of the context
as y and the word associations for an event as x, our logistic      window to train the models, nor the weights placed on these
model would attempt to find parameters β0 and β1 to fit y =         dimensions to judge semantic distance (both of which are
1/(1+exp{-β0 - β1 x}).                                              specified a priori). A more sophisticated approach that trains
    As both our logarithmic and our logistic models involve         the vector space models on the probability estimates of
two parameters, their predictive accuracy can be directly           participants, would no doubt provide better predictions
compared with those of the linear model described above.            regarding their subjective probability estimates.
Ultimately we find that the logistic and the linear models              There are also boundary conditions. For example, it is
perform about equivalently, providing nearly identical              unlikely that the approach outlined in this paper would be
correlations and R2 values. The logarithmic model, in               able to successfully describe probability judgments
contrast provides a much more inferior fit than the linear          involving symbolic reasoning or more complex delilberative
and logistic models, with correlations and R2 values as low         processing. However, despite these limitations, our results
as 0.41 and 0.17 for the Nobel Prize judgments in Study 6.          have some important implications. Firstly they provide new
Despite this fact, the predictions of all models have               techniques for predicting real-world judgments. These
statistically significant relationships with the judgments of       predictions are quantitative, in that they attempt to capture
participants (p < 0.001 for all models in all studies).             the exact numerical probability assigned to an event. These
    A brief examination of the parameter values generated           predictions are also domain-general, in the sense that they
by our logistic fits explains why they perform as well as the       can be applied to a number of different types of real-world
linear models. These parameters are typically such that the         events. Ultimately, the vector space models that we use
inputs to the logistic function fall within its middle, linear      have very large vocabularies, and are able to provide a
range, implying that the logistic function behaves roughly          precise measure of association between any two words or
like a linear model. Ultimately, it seems that our measure of       phrases in their vocabularies, and subsequently precise
word association maps linearly onto the probability                 probability judgments for simple events composed of these
judgments of our participants. A summary of the fits for the        words and phrases. Existing judgment models do not have
logarithmic and logistic models is provided in Table 1.             this important property.
                                                                1941

    In addition to numerous practical applications to areas           episodes. Journal of Personality and Social
such as risk perception and communication (Slovic, 2000),             Psychology,65(1), 45-68.
these quantitative predictions can be used to more                 Griffiths, T. L., Steyvers, M., & Tenenbaum, J. B. (2007).
rigorously study the processes already known to                       Topics in semantic representation. Psychological
characterize probability judgment (Kahneman & Tversky,                Review, 114(2), 211-235.
1974; Lichtenstein et al. 1977; Tversky & Koehler, 1994;           Hare, M., Jones, M., Thomson, C., Kelly, S., & McRae, K.
Wallsten & Budescu, 1983), and also potentially uncover               (2009). Activating event knowledge. Cognition, 111(2),
novel effects and regularities. They can also be used to              151-167.
predict everyday decisions involving these events, such as,        Harris, Z. (1954). Distributional structure. Word, 10, 146 –
for example, the purchasing of insurance. These types of              162.
real-world decisions are of considerable scholarly interest.       Jones, M. N., & Mewhort, D. J. (2007). Representing word
    Our results also highlight the power of association-based         meaning and order information in a composite
heuristics in making probability judgment (Kahneman &                 holographic lexicon. Psychological Review, 114(1), 1.
Frederick, 2002; Sloman, 1996). Though the descriptive             Kahneman, D., & Frederick, S. (2002). Representativeness
power of these heuristics is accepted, this paper is the first        revisited. In Heuristics and Biases: The Psychology of
to show that a semantic instantiation of these heuristics can         Intuitive Judgment.
be used to predict the actual probabilities that decision          Kahneman, D., & Tversky, A. (1973). On the psychology of
makers assign to natural everyday events. Likewise, these             prediction. Psychological Review, 80(4), 237.
results illustrate the power of vector semantic space models.      Landauer, T. K., & Dumais, S. T. (1997). A solution to
These approaches not only predict judgments of word                   Plato's problem: The latent semantic analysis theory of
meaning and use in linguistic domains, but also judgments             acquisition, induction, and representation of knowledge.
involving complex events in the real-world. It is important           Psychological Review, 104(2).
to note that many of the results could not be obtained by          Lichtenstein, S., Fischhoff, B., & Phillips, L. D. (1977).
simpler approaches that use, for example, only the co-                Calibration of probabilities: The state of the art (pp. 275-
occurrence of words to judge associations. “Jay Z” and “Joe           324). Springer Netherlands.
Biden” may never directly co-occur with “Academy                   Lund, K., & Burgess, C. (1996). Producing high-
Award”, but participants nonetheless ascribe a higher                 dimensional semantic spaces from lexical co-occurrence.
probability to Jay Z, a musician, winning an Academy                  Behavior Research Methods, 28(2), 203-208.
Award, relative to the Joe Biden, a politician.                    Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013).
    Finally, the link between the representations and                 Efficient estimation of word representations in vector
associations used to assess word meaning and the                      space. arXiv preprint arXiv:1301.3781.
representations and associations used to make probability          Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., &
judgments, observed in this paper, suggests the existence of          Dean, J. (2013). Distributed representations of words
a single system of learning, storing, and retrieving                  and phrases and their compositionality. In Advances in
knowledge for both language use and for high-level                    Neural Information Processing Systems.
judgment. Subjective probability judgment does not rely on         Paperno, D., Marelli, M., Tentori, K., & Baroni, M. (2014).
knowledge that is fundamentally different from the type of            Corpus-based estimates of word association predict
knowledge used to understand and generate language. This              biases in judgment of word co-occurrence likelihood.
in turn implies a close connection between two important              Cognitive Psychology, 74, 66-83.
and influential areas in psychology. Future work should            Sloman, S. A. (1996). The empirical case for two systems of
attempt to build more general models of semantic cognition;           reasoning. Psychological Bulletin, 119(1), 3.
models which are not only able to explain how people               Turney, P. D., & Pantel, P. (2010). From frequency to
acquire the knowledge of word meanings, but also how                  meaning: Vector space models of semantics. Journal of
people use these word meanings to form their beliefs about            Artificial Intelligence Research, 37(1), 141-188.
the objects and events they encounter in the world.                Tversky, A., & Kahneman, D. (1983). Extensional versus
                                                                      intuitive reasoning: the conjunction fallacy in probability
                         References                                   judgment. Psychological Review, 90(4), 293.
Bullinaria, John A., and Joseph P. Levy. "Extracting               Tversky, A., & Koehler, D. J. (1994). Support theory: a
    semantic representations from word co-occurrence                  nonextensional representation of subjective probability.
    statistics: A computational study." Behavior Research             Psychological Review, 101(4), 547.
    Methods 39.3 (2007): 510-526.                                  Wallsten, T. S., & Budescu, D. V. (1983). State of the art—
Firth, J. R. (1957). A synopsis of linguistic theory 1930 –           Encoding subjective probabilities: A psychological and
    1955. In Studies in linguistic analysis (pp. 1–32).               psychometric review. Management Science, 151-173.
    Oxford, England: Blackwell Publishers.                         Wallsten, T. S., Budescu, D. V., Erev, I., & Diederich, A.
Fredrickson, B. L., & Kahneman, D. (1993). Duration                   (1997). Evaluating and combining subjective probability
    neglect in retrospective evaluations of affective                 estimates. Journal of Behavioral Decision Making,
                                                                      10(3), 243-268.
                                                               1942

