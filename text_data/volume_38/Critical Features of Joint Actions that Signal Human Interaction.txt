                 Critical Features of Joint Actions that Signal Human Interaction
                  Tianmin Shu 1 Steven Thurman 1 Dawn Chen Song-Chun Zhu Hongjing Lu
            {tianmin.shu, sthurman}@ucla.edu sdawnchen@gmail.com sczhu@stat.ucla.edu hongjing@ucla.edu
                           Departments of Psychology and Statistics, University of California, Los Angeles
                              Abstract                                  recent efforts to interpret an agent’s behavior via the inten-
                                                                        tional stance required to understand joint actions. For exam-
   We examined the visual perception of joint actions, in which
   two individuals coordinate their body movements in space and         ple, Baker et al. (2009) developed a computational model for
   time to achieve a joint goal. Animations of interacting action       reasoning about intentions within a sprite world inspired by
   pairs (partners in human interactions) and non-interacting ac-       the seminal work of Heider and Simmel (1944), in which sim-
   tion pairs (individual actors sampled from different interaction
   sequences) were shown in the experiment. Participants were           ple shapes (e.g., red circles or blue triangles) move around in
   asked to rate how likely the two actors were interacting. The        a constrained environment. Although these studies illustrate
   rating data were then analyzed using multidimensional scaling        the potential fruitfulness of applying high-level constraints to
   to recover a two-dimensional psychological space for repre-
   senting joint actions. A descriptive model based on ordinal          reason about the goal underlying observed actions, the inves-
   logit regression with a sparseness constraint was developed to       tigations have been limited to simplified environments and
   account for human judgments by identifying critical features         movements of rigid objects. Relatively few psychological
   that signal joint actions. We found that identification of joint
   actions could be accomplished by assessing inter-actor correla-      studies have used whole-body movements of humans as the
   tions between motion features derived from body movements            visual input to examine the mechanisms underpinning joint
   of individual actions. These critical features may enable rapid      actions.
   detection of meaningful inter-personal interactions in complex
   scenes.                                                                 On the other hand, Marsh et al. (2009) proposed that social
   Keywords: joint action; feature selection; human interaction         interaction through joint actions can be understood as emerg-
                                                                        ing from dynamical principles across individuals, rather than
                           Introduction                                 relying on explicit reasoning on intention, at least in some sit-
Humans actions provide critical information for understand-             uations. For example, Richardson et al. (2007) showed that
ing other people’s intentions and reacting accordingly. Be-             connections between humans can arise through synchroniza-
yond recognition of individual actions, the ability to engage           tion of action patterns (e.g., rocking together when sitting on
in joint action (i.e., when two or more individuals coordinate          rocking chairs side-by-side), rather than mental state attribu-
their actions in space and time) paves the way for other social         tion. This line of work suggests the possibility that bottom-
interactions (Sebanz, Bekkering, & Knoblich, 2006; Thur-                up feature-based mechanisms may play an important role in
man & Lu, 2014). In everyday life, we constantly coordi-                signaling joint actions. However, the related studies have
nate our own actions with those of others to achieve a joint            been limited to uninstructed coordination of simple inciden-
outcome involving a change in the environment (e.g., lifting            tal rhythmic movements, which only cover a small range of
a box together and moving it to a different location), or to            possible human actions, and did not aim to probe the impor-
achieve a social goal through human interaction (e.g., walk-            tant features underpinning meaningful interactions between
ing towards one another and giving a “high-five” as a greet-            actors. In the literature of action recognition, there is rich
ing). Carpenter (2009) provided evidence that the ability to            evidence showing that humans are sensitive to some signa-
participate in joint action is already fairly developed after the       ture movements to enable efficient action detection (Casile
first year of life.                                                     & Giese, 2005; Troje & Westhoff, 2006; van Boxtel & Lu,
   However, it is by no means a trivial task to identify whether        2015, 2012). Hence, it is conceivable that some critical fea-
two persons are interacting in a meaningful manner solely               tures of coordinated movements between actors can facilitate
from visual input. There are many circumstances in which                the perception of joint actions.
individuals incidentally intersect the orbit of other people’s
body movements, creating a scene that might be confusable                  The present study investigated people’s mental representa-
with potential interactivity coordinated by the two people.             tions of joint actions and how well features measuring differ-
Hence, it is important to examine what specific information             ent types of movement coordination between individual ac-
in a visual input signals engagement in joint action, and to de-        tors can capture human judgments of interaction. We col-
termine the conditions under which joint action emerges from            lected human ratings of the degree to which two actors seem
body movements of individuals.                                          to be interacting with each other for different video clips.
   In the literature, both reasoning-based and feature-based            These data were then used to derive a psychological space
mechanisms have been proposed to support the recognition                representing joint actions between two individuals. Compu-
and planning of actions when interacting with the environ-              tational models were developed to pinpoint critical features
ment or other people. In particular, there have been several            of coordinated movements used in constructing a represen-
                                                                        tation space for joint actions by fitting the models to human
    1 These two authors contributed equally.                            interactivity ratings.
                                                                    574

                     The Experiment                                                                                                                                                       1
                                                                                                                                                                                                                                                        6.5
The experiment was designed to investigate perception of                                                                                                                                  2
                                                                                                                                                                                                                                                        6
                                                                                                                                                                                          3
joint actions between two human actors using naturalistic                                                                                 (a)                                             4                                                             5.5
                                                                           Mean Interaction Rating
                                                                                                     8
stimuli. Two human actors were recorded engaging in var-
                                                                                                                                                                                Actor 1
                                                                                                                                                                                          5                                                             5
                                                                                                     6                                                                                    6
ious forms of social interaction, such as shaking hands, pass-                                                                                                                            7
                                                                                                                                                                                                                                                        4.5
ing a water bottle, and salsa dancing. We then generated the                                         4                                                                                    8
                                                                                                                                                                                                                                                        4
                                                                                                                                                                                                                                                        3.5
full set of stimuli by pairing each actor not only with their                                        2                                                                                    9
                                                                                                                                                                                          10                                                            3
true interaction partner, but also with each of the other ac-                                        0                                                                                         1         2    3     4      5 6       7     8   9   10
                                                                                                         Interacting                             Non−interacting                                                          Actor 2
tors involved in different recorded joint actions (e.g., a salsa
                                                                                                                                          (b)                                                                                 (c)
dancer on the left with a person shaking hands on the right).
We sought to determine the extent to which subjects would                 Figure 1: (a) Frames of two confusing stimuli: 1)
recognize true interpersonal interactions through joint action,           arm wrestling and shaking hands, 2) threatening and arm
and also whether the stimulus properties of non-interacting               wrestling. (b) Mean interactivity ratings for truly interacting
stimulus pairs would result in coincidental visual cues that              and non-interacting stimuli, represented by collapsing across
signal attribution of social interaction in joint action.                 action types. (c) The matrix of mean interactivity ratings for
                                                                          all pairs, highlighting the variable ratings given to different
                           Method                                         non-interacting stimuli.
Stimuli                                                                                                                                  0.4
Action stimuli were generated from the CMU Mocap                                                                 (Low)                                                           give drink
                                                                                                                                         0.3
database (http://mocap.cs.cmu.edu) and processed by
                                                                                                                                                   arm wrestle
                                                                                                                 Kinematic activeness
the Biological Motion Toolbox (van Boxtel & Lu, 2013). We                                                                                0.2                                                                       throw catch
selected ten paired interactions in which two human agents                                                                               0.1                            shake hands
                                                                                                                                                  threaten
were engaged in various social interactions (see Table 1). A                                                                              0
                                                                                                                                                                                                                              high five
total of 100 stimuli with paired actions were presented in the                                                                                             salsa dance
                                                                                                                                        −0.1                       pull arm
study, including 10 truly interacting with coupled partners
and 90 not interacting. The point-light stimuli were rendered                                                                           −0.2
                                                                                                                                                                                                             argue
as stick figures with lines connecting the joints, and videos                                                    (High)                                         360 whip
                                                                                                                                        −0.3
                                                                                                                                          −0.5    −0.4   −0.3    −0.2    −0.1             0        0.1       0.2        0.3    0.4   0.5
lasted 3.67 seconds (110 frames presented at 30 fps).                                                                                          (Aggressive)              Social aspects                             (Cooperative)
Procedure                                                                 Figure 2: MDS solution derived from human interactivity
Participants first viewed two videos, one of a single stick fig-          ratings. The vertical dimension captures activeness of body
ure walking and another running, and were asked to write a                movements involved in joint action, whereas the horizontal
description of what each person was doing. This was to en-                dimension associates with social aspects of joint actions with
sure that they understood the format of the videos and were               the exception of “argue” sequence, in which the social con-
sufficiently competent in English to complete the remainder               tent in the point-light display is ambiguous (as this joint ac-
of the experiment. Participants then viewed 25 videos, 5 of               tion can be interpreted either as an argument or as a normal
which were chosen from the 10 interacting pairs and 20 of                 conversation between two people).
which were the non-interacting pairs formed from the remain-
ing 5 actors. For each video, participants were asked to “rate            cal Turk (Mturk). We excluded 26 participants because they
the degree to which the actors appear to be interacting” on a             failed one or more of the attention checks during the exper-
scale from 1 (Definitely NOT) to 7 (Definitely).                          iment. Furthermore, we included two additional exclusion
   In addition to the 25 videos of interest, participants viewed          criteria to remove participants who did not pay attention to
two videos that were presented on randomly selected trials                the task. The first measure was the standard deviation of each
among the other videos in order to check whether they were                participant’s interactivity ratings across all the testing trials.
paying attention to the task. These were videos of a single               We excluded 5 participants based on the standard deviation
actor walking or running. Participants were asked to use a                of their ratings being less than 2 z-scores below the mean
slider (as in the rating questions) to choose the action depicted         standard deviation for all participants. Finally, 4 participants
in each video. Participants who failed either of these attention          were excluded for mistakenly providing higher average inter-
checks were excluded from the data analysis.                              activity ratings for the non-interacting pairs than for the inter-
   After the video rating task, participants completed the                acting pairs. Data from the remaining 160 participants were
Autism Quotient (AQ) questionnaire (Baron-Cohen et al.,                   analyzed.
2001), where an attention check was also included.                           As shown in Figure 1b, human participants yielded sig-
                                                                          nificantly higher mean ratings for interacting pairs (mean =
Results                                                                   6.21 ± 0.82) than for non-interacting pairs (mean = 4.38 ±
195 participants were recruited and paid $0.80 for participa-             0.27), demonstrating that Mturk participants were sensitive to
tion in the 5-10 minute experiment on Amazon’s Mechani-                   true joint actions supporting meaningful human interactions
                                                                    575

(see Figure 1b). Figure 1c showed the mean interactivity rat-                                         The Model
ing for each of the 100 pairs of actors. These results can
be visualized as an interactivity-rating matrix in which the           In order to determine what visual features play important
diagonal elements represent mean ratings for the true inter-           roles in guiding human judgments regarding meaningful in-
action stimuli, and the off-diagonals represent mean ratings           teractions between individuals, we developed a descriptive
for non-interacting stimuli. There was substantial variability         model based on ordinal logit regression, coupled with a
in interactivity ratings for the set of non-interacting stimuli,       sparseness constraint to encourage selection of a relatively
with some pairs (e.g., two examples in Figure 1a) yielding             small number of discriminative features. We first describe
high ratings, and other pairs (e.g., giving a high-five and arm        the model used to predict interactivity judgments for experi-
wrestling) yielding relatively lower ratings.                          mental stimuli, and its selection of critical features. We will
   We analyzed the matrix of mean interactivity ratings using          then provide details on the computation of five different types
multidimensional scaling (MDS). MDS is usually applied to              of features from body movements.
similarity data, and the rated interactivities for different pairs
of actions can be viewed as analogous to similarities. The             Rank Prediction and Feature Selection
MDS algorithm requires that the input matrix is symmetric
and that its diagonal elements are all ones (i.e., items are max-      The model predicts a rank order of interactivity judgments for
imally similar to themselves). We therefore divided every el-          each pair of actions shown in the stimulus based on the 2D
ement in the rating matrix by the maximum rating along the             coordinates of joints involved in individual actions. To train
diagonal, then set all diagonal elements to 1, and finally took        the model, human interactivity ratings were converted to rank
the average of the upper and lower triangles of the matrix to          order. We clustered average human ratings from the entire
form a symmetric input matrix.                                         experiment into four rank levels, with equal numbers of cases
   Figure 2 shows the results of applying multidimensional             assigned to each level. After training, the model predicts the
scaling to the rating matrix. Because we used interactivity            rank order of the interactivity judgment y for a given unseen
rather than similarity ratings, actions that are closer in this        pair of actions, y = 1, · · · , 4, based on the visual features x
space are more likely to be rated as interactive when paired           derived from the input video. Based on the logit link, we can
together. Note that “shake hands”, “salsa dance”, and “pull            write the conditional probability for a rank j = 1, · · · , 4 as
arm”, which are close to one another, are all actions with sus-                                                         exp(ψ j + x > β)
                                                                           π j (xx) = p(y = j | y ≤ j, x ) =                               , (1)
tained touch. In addition, the two dimensions appear to re-                                                         1 + exp(ψ j + x > β)
veal distinct psychological variables. The vertical dimension          where {ψ j } j=1,··· ,4 , thresholds for the rank j, and β, the coef-
corresponds to the levels of activity involved, ranging from           ficients for the features are the parameters to be learned. We
highly active actions (e.g., “play 360 whip”, in which two                                            j
                                                                       use a dummy variable yi ∈ {0, 1} to indicate whether the rank
people hold hands and jump while rotating 360 degrees) to              of the i-th instance in the data is j. Then for each instance,
less active actions (e.g., “give drink”, in which one standing         we define a vector y i = (y1i , · · · , y4i )> . Let Y = (yy1 , · · · , y n )>
person passes a can of soft drink to another person standing           be the reconstructed responses of the training instances. For
next to him). The horizontal dimension appears to be asso-             n training instances, the log-likelihood is defined as
ciated with social aspects of joint actions, ranging from ag-
                                                                                   `(β, {ψ j } j=1,··· ,4 |X,Y )
gressive, threatening actions (e.g., one person holds an invis-                     n   4                               4      0
ible object and appears to threaten another person), to more                =      ∑ ∑ yij log π j (xxi ) + (1 − ∑           j
                                                                                                                          yi ) log(1 − π j (xxi )).
friendly and cooperative joint actions (e.g., two people walk-                     i=1 j=2                            0
                                                                                                                     j =j
ing towards each other to give a high five). One exception was                                                                                    (2)
the “argue” joint action, in which two people presumably in               Since a large number of features are included in the anal-
argument raise their arms, but never touch each other. When            ysis, the model selects the critical features according to a
this action sequence is converted into a point-light display, the      sparseness constraint that includes an `1 norm penalty for the
social content becomes ambiguous (as this joint action can be          coefficients β. Hence, for n instances with p-dimensional fea-
interpreted either as an argument or as a normal conversation          ture vectors X and labels Y , we maximize
between two people). This is confirmed by the result that the                           `(β, {ψ j } j=1,··· ,4 |X,Y ) − λ ∑ |βk |.                (3)
interactivity rating for the “argue” joint action was also the                                                                 k
lowest among all the true interactions.                                Finally, given learned model parameters (i.e., β and ψ) and
   In addition, we found a statistically significant correla-          the features of a new test stimuli x , the estimated rank ŷ of
tion between AQ score and discrimination score, r = −0.17,             interactiveness for the test stimuli can be obtained based on
p = .024. This relationship suggests that participants with            the following probability for each j = 1, · · · , 4:
                                                                                           
more autistic traits were less able to distinguish between in-
                                                                                           π4 (xx)
                                                                                                                                 if j = 4
teracting and non-interacting stimuli than participants with              p(y = j|xx) = ∏4j0 =2 (1 − π j0 (xx))                   if j = 1        (4)
fewer autistic traits. This finding is consistent with other evi-                           x 4
                                                                                           
dence of impaired social cognition in autism.                                                π j (x ) ∏ j0 = j+1 (1 − π j0 (xx)) otherwise
                                                                   576

                       135°
                            1
                                 45°
                                                                      over time, but the arm movements change when actions un-
                          2   4                                       fold over time. To quantify this, for each limb we compute
                            3  -45°
                      -135°
                                                                      entropy based on the histogram of moving directions of joints
                                                                      in two-dimensional space. We first equally quantize joint mo-
                ...                ...        ...                     tion directions into 4 bins as shown in Figure 3, and then
                                                                      count the frequency of moving directions of each joint on that
                        t+1            t+ T 1                         limb at each frame in the given temporal window ∆T = 6. To
Figure 3: Illustration of motion entropy for the right limb. In a     ensure sensitivity to the influence of joint movement speed,
time window of ∆T , we compute the moving directions of the           the frequency counts are weighed by velocity magnitude of
three joints on the right limb at each frame, and compute the         joint movements. If the joints move in a similar direction over
histogram of moving directions, which is re-weighted by the           time or remain static, the entropy measure during this period
magnitude of the velocities. The entropy of the histogram is          is low. In contrast, the entropy is high when the joints move
the motion entropy of the right limb within the time window.          in varied directions and speeds over time. Because actions
                                                                      progress over time, we obtain a time series of motion entropy
                                                                      for each limb of individual actors in stimuli. To capture the
Features of Coordinated Body Movements                                coordination of body movements in joint actions, we com-
A total of 172 features were provided for the model to select.        pute the correlation of motion entropy sequences between the
The features are derived from the coordination of limb move-          two actions for each limb pair, resulting in 16 features (i.e., all
ments between two actors. We grouped the features into five           possible combination of four limbs in each actor). In addition,
types according to their functional roles.                            we include another feature to capture the temporal correlation
   Type I: Touching. When viewing a pair of actions, one              of whole-body motion entropy sequences for the two actors,
actor touching the other actor could signal potential joint ac-       where entropy is calculated by pooling motion from all joints.
tion with interactive activity (e.g., Shake Hands, Give Drink,        In total, set III has 17 features.
etc.). The feature of touching can be quantified using spatial           Type IV: Correlation of motion trajectories. Two actors
distance of two joints, each from one actor in the stimulus.          engaged in joint action often perform the same movements at
The spatial distance of joints can be denoted as dit j , where i      the same time, e.g., raising arms together to give a high-five.
and j denote index of body joints from the two individuals            To capture this kind of limb movement coordination, we cal-
respectively, and t indicates the frame number. An auxiliary          culated the inter-actor correlation of the motion trajectories
variable Ti j = ∑t 1(dit j < D) is introduced to count the num-       for the centers of mass of the four limbs and for the center of
ber of frames when a pair of joints between the two actors are        mass of the entire body, yielding a total of 17 features.
closer than a threshold, i.e., D = 8 pixels. The two joints are          Type V: Motion correlation with temporal shifts. A
considered to be “touching” each other if Ti j is longer than         characteristic of joint actions is that one person acts in re-
τ = 30 frames (i.e., 1 second), which can be denoted as a             sponse to the other person’s actions. In some situations, limbs
dummy variable si j = 1(Ti j > 30). Then we can obtain the            move in a synchronized manner (e.g., each actor lifting arms
total number of “touching” pairs of joints by S = ∑i j si j . To      in synchrony to give a high-five greeting), which is capture by
eliminate accidental spatial overlap of joints when viewing           feature set IV. In other situations, however, one person moves
the action pairs from a particular viewpoint, the two actors          their limbs first to initiate an interaction (e.g., a person pass-
are defined to be touching at certain point if and only if one or     ing an object to the other person). To capture these temporal
two pairs of joints between them are considered to be touch-          relations in coordinated movements, we introduced a range
ing, i.e., 1 ≤ S ≤ 2. The touching variable is set as 1 if the        of relative temporal shifts (-1.6s, -0.8s, 0.8s, 1.6s) of motion
two actors’ joints satisfy this criterion.                            trajectories between two actors to calculate the correlation in-
   Type II: Passing. In some joint actions supporting human           dices defined in sets III and IV, yielding 136 features in set V.
interactions, two actors can pass each other, producing spatial          Finally, all features were standardized to fix the mean at 0
overlap of the two actors. The second type of features aim to         and the variance at 1 across all training stimuli. Any feature
capture spatial relations between two actors in the stimulus.         values within 1.2 standard deviations of the mean were set to
Similar to the touching feature, we can also count S using            the mean value in order to remove insignificant feature values
the same method as defined in the previous paragraph with             and to facilitate the feature selection process.
thresholds D = 13 and τ = 30. The binary passing variable is
coded as 1 indicating the presence of this feature if S ≥ 3.                                  Model Results
   Type III: Temporal correlation of body movements.
The third type of features aims to capture the variability of         Rank Predictions for Unseen Interactions
limb movements over time. Here we define four limbs for an            To evaluate whether the model can generalize its learned fea-
actor (left arm, right arm, left leg and right leg), with each        tures to new joint actions, we split the 100 stimuli into two
limb including 3 joints. For example, if a person only moves          sets for each of the 10 joint actions: a training set with 81
the upper body in joint action (e.g., passing an object while         pairs formed from the other 9 actions, and a testing set with
sitting on a chair), there is no variability of leg movements         the remaining 19 pairs, one of which is the truly interacting
                                                                  577

                                               Illustrative                                                                                                                                            Illustrative
         ID   Name                                                       Mean Interaction Ranks                                                                       ID            Name                                               Mean Interaction Ranks
                                               Frame                                                                                                                                                   Frame
                                                                                                    4                                                                                                                                                              4
                                                                         Mean Interaction Ranking                                                                                                                                       Mean Interaction Ranking
                                                                                                    3                                                                                                                                                              3
         1    Shake Hands                                                                           2                                                                 2             Pull by Arm                                                                    2
                                                                                                    1                                                                                                                                                              1
                                                                                                    0                                                                                                                                                              0
                                                                                                    4                                                                                                                                                              4
                                                                         Mean Interaction Ranking                                                                                                                                       Mean Interaction Ranking
                                                                                                    3                                                                                                                                                              3
         3    High Five                                                                             2                                                                 4             Give Drink                                                                     2
                                                                                                    1                                                                                                                                                              1
                                                                                                    0                                                                                                                                                              0
                                                                                                    4                                                                                                                                                              4
                                                                         Mean Interaction Ranking                                                                                                                                       Mean Interaction Ranking
                                                                                                    3                                                                                                                                                              3
         5    Arm Wrestle                                                                           2                                                                 6             Argue                                                                          2
                                                                                                    1                                                                                                                                                              1
                                                                                                    0                                                                                                                                                              0
                                                                                                    4                                                                                                                                                              4
                                                                         Mean Interaction Ranking                                                                                                                                       Mean Interaction Ranking
                                                                                                    3                                                                                                                                                              3
              Play           360
         7    Whip
                                                                                                    2                                                                 8             Salsa Dance                                                                    2
                                                                                                    1                                                                                                                                                              1
                                                                                                    0                                                                                                                                                              0
                                                                                                    4                                                                                                                                                              4
                                                                         Mean Interaction Ranking                                                                                                                                       Mean Interaction Ranking
                                                                                                    3                                                                                                                                                              3
         9    Threaten                                                                              2                                                                 10            Play Catch                                                                     2
                                                                                                    1                                                                                                                                                              1
                                                                                                    0                                                                                                                                                              0
Table 1: Comparison between mean human interactivity ranks and model predictions for each type of interaction. An illustrative
frame from each interaction video is also shown. The gray and red bars are the average ranks based on human ratings and model
predictions respectively. Solid bars denote the ranks for interacting pairs and blank bars denote the average ranks for the non-
interacting pairs in that testing set.
                 0.4                                                                                                       0.4                                                                          0.4
                                 throw catch                                                                                                                                   high five
                                                       give drink                                                                                                                                                                                                      give drink
                 0.3                                                                                                       0.3                                                                          0.3
                                                                                                                                    give drink
                 0.2                                                                                                       0.2                                              throw catch                 0.2
                                                                                                                                           shake hands
                                                                                                                                                                                                                arm wrestle                                                                       high five
                                                                                                                                                                                                                          shake hands
                 0.1                      pull arm                                                                         0.1                                                                          0.1
                                                                 argue                                                                                                                                                                                                                    argue
                                         salsa dance                                                                                                                                                                           salsa dance
                                                                                                                                   arm wrestle              pull arm
                  0                                                                                           high five     0                                                                            0    threaten
                −0.1
                         arm wrestle                                                                                      −0.1             salsa dance                                                 −0.1
                                                      shake hands                                                                                                                           argue
                              threaten                                                                                                                                                                                                 pull arm
                −0.2                                                                                                      −0.2                                                                         −0.2
                                                      360 whip                                                                                                       360 whip                                                                                                              throw catch
                                                                                                                                                    threaten                                                                   360 whip
                −0.3                                                                                                      −0.3                                                                         −0.3
                  −0.5    −0.4   −0.3   −0.2   −0.1    0   0.1    0.2         0.3                       0.4     0.5         −0.5    −0.4   −0.3   −0.2   −0.1    0    0.1     0.2   0.3    0.4   0.5     −0.5    −0.4   −0.3    −0.2      −0.1                          0   0.1     0.2     0.3   0.4   0.5
                  (a) The first three feature sets.                                                                          (b) The first four feature sets.                                                                  (c) All features.
                                 Figure 4: MDS results of fitted ranks from models trained with different feature sets.
pair performing the joint action of interest and 18 of which                                                                                                           entropies of the right leg of actor 1 and the left arm of ac-
are non-interacting pairs formed from the partners in the joint                                                                                                        tor 2 with an 0.8s temporal shift, 3) correlation between the
action of interest coupled with actors from different joint ac-                                                                                                        trajectories of the left leg of actor 1 and the left leg of ac-
tions. The final model for each of the 10 joint actions is fitted                                                                                                      tor 2 with a -1.6s temporal shift, 4) correlation between the
to select 22 critical features, which yielded the highest corre-                                                                                                       whole-body motion entropies of the two actors, and 5) cor-
lation between predicted ranks and human ranks.                                                                                                                        relation between the trajectories of the right arm of actor 1
   Table 1 depicts the model’s prediction when tested on each                                                                                                          and the left arm of actor 2, which were all chosen on at least
interactive pair, in comparison to rank orders from human rat-                                                                                                         8 test runs with positive coefficients. In particular, touching
ings. The overall correlation between model predictions and                                                                                                            was selected on all test runs, showing its generalization to a
human judgments is strong, with r = .85, p < 10−5 . The aver-                                                                                                          large range of joint actions. These results regarding the fea-
age root-mean-square error (RMSE) of rank order was 0.47.                                                                                                              tures commonly selected by the model are robust, as feature
The best fitted joint actions are Play Catch, Play 360 Whip,                                                                                                           rankings do not change significantly across different sets of
and Arm Wrestle, which yielded low RMSE (0.08, 0.20, and                                                                                                               model parameters.
0.24 respectively), and the worst fitted actions were High
Five, Argue, and Threaten with high RMSE (0.90, 0.73, and                                                                                                              MDS from fitted ranks
0.71 respectively). These differences in RMSE across various                                                                                                           We trained the model with all 100 action pairs and let the
joint actions suggest that the descriptive model using features                                                                                                        model predict the interactiveness of any pair of actions so
of coordinated movements is able to predict the rank order of                                                                                                          that we can derive the model-fitted rating matrix, which was
joint actions which can be defined with strong visual cues,                                                                                                            used to recover the psychological space of joint actions by the
while the model shows its limitation to other joint actions                                                                                                            multidimensional scaling algorithm. The joint action space
which are rich in social content (such as threaten) but less                                                                                                           derived from the model-simulated matrix makes it possible
informative in terms of coordinated movements.                                                                                                                         to examine how different types of features impact similar-
   The five features commonly selected across different train-                                                                                                         ity between different joint actions. We fit the rating matrix
ing sets are 1) touching, 2) correlation between the motion                                                                                                            using the first three feature sets, first four feature sets and
                                                                                                                                                                578

all features in the five sets, respectively. The resulting MDS        tions. Our findings shed light on how humans achieve ef-
results are shown in Figure 4. The comparison of model-               ficient detection of meaningful inter-personal interactions in
derived joint action space with human results shows that set          complex scenes, paving the way for a deeper understanding
V features play the most important role in mimicking human            of social cognition.
judgments, as one dimension corresponds to the amount of
visual motion information in observed action pairs, and the                                Acknowledgments
other dimension is associated with social aspects of joint ac-        This research was funded by a NSF grant BCS-1353391 to
tion. Given that the model is solely based on visual informa-         HL and DARPA MSEE project FA 8650-11-1-7149 and ONR
tion, without explicitly modeling reasoning of social content         MURI project N00014-16-1-2007 for SZ.
beyond the observed joint actions, the recovery of a socially-
relevant dimension is intriguing. Note that this dimension                                       References
only emerges after introducing the set V features with tempo-         Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action
ral shift between movement of the two actors. This dimension             understanding as inverse planning. Cognition, 113(3), 329-
may be strongly associated with the degree of synchroniza-               349.
tion of body movements between two actors. For example,               Baron-Cohen, S., Wheelwright, S., Skinner, R., Martin, J., &
the friendly impression of the joint action of “walking to-              Clubley, E. (2001). he autism-spectrum quotient (aq): Ev-
wards each other to give a friendly high-five greeting” results          idence from asperger syndrome/high-functioning autism,
from the harmonious body movements created by two actors                 males and females, scientists and mathematicians. Journal
in cooperation. In contrast, the perceived aggression of the             of Autism and Developmental Disorders,, 31, 5-17.
joint action of “a person holding an object moves toward the          Carpenter, M. (2009). Just how joint is joint action in in-
other actor who follows with an avoiding move” results from              fancy? Topics in Cognitive Science, 1(2), 380-392.
the temporal relation of movements between the two actors.            Casile, A., & Giese, M. A. (2005). Critical features for the
                                                                         recognition of biological motion. Journal of Vision, 5(4),
                         Conclusions                                     6.
                                                                      Heider, F., & Simmel, M. (1944). An experimental study of
The experiment reported in this paper showed that human                  apparent behavior. American Journal of Psychology, 57(2),
interactivity ratings provide a tool to gauge the psychologi-            243-259.
cal space for representing joint actions. A similar approach          Marsh, K. L., Richardson, M. J., & Schmidt, R. C. (2009).
has been employed in previous research on perceiving emo-                Social connection through joint action and interpersonal
tion from arm movements in individual actions (Pollick et                coordination. Topics in Cognitive Science, 1(2), 320-339.
al., 2001). Our study shows that humans represent ma-                 Pollick, F. E., Paterson, H. M., Bruderlin, A., & Sanford, A. J.
jor two dimensions of joint actions, one concerning visual               (2001). Perceiving affect from arm movement. Cognition,
motion information and the other concerning social aspects               82(2), B51-61.
of joint actions. To further understand the representational          Richardson, M. J., Marsh, K. L., & Isenhower, R. W. (2007).
space of joint actions, we assessed the role of critical features        Rocking together: Dynamics of intentional and uninten-
of coordinated movements in signaling human interactions.                tional interpersonal coordination. Human Movement Sci-
Research on recognition of individual actions has identified             ence, 26(6), 867-891.
critical features involved in the processing of action stimuli        Sebanz, N., Bekkering, H., & Knoblich, G. (2006). Joint
(Casile & Giese, 2005; van Boxtel & Lu, 2015). However,                  action: bodies and minds moving together. Trends in Cog-
few previous studies have systematically examined critical               nitive Sciences, 10(2), 70-76.
features of coordinated movements in joint actions. Accord-           Thurman, S., & Lu, H. (2014). Perception of social inter-
ingly, the present study fills an important gap in research on           actions for spatially scrambled biological motion. PLOS
action perception.                                                       ONE, 9(11), 1-12.
   Humans can perceive activities jointly performed by two            Troje, N. F., & Westhoff, C. (2006). The inversion effect in
actors from very impoverished stimuli such as point-light                biological motion perception: evidence for a life detector?
displays (actions depicted by discrete joints in a motion se-            Current Biology, 16(8), 821-824.
quence). Observers can identify whether actors interact in            van Boxtel, J., & Lu, H. (2012). Signature movements lead to
a meaningful way to achieve a shared outcome involving a                 efficient search for threatening actions. PLOS ONE, 7(5),
change in the environment or the fulfillment of a social goal.           e37085.
An important question concerns how the visual system can              van Boxtel, J., & Lu, H. (2013). A biological motion toolbox
generalize action perception to point-light stimuli, which are           for reading, displaying and manipulating motion capture
rarely observed in the visual world. The present findings sug-           data in research settings. Journal of Vision, 13(12), 1-16.
gest that a robust ability to identify joint actions may involve      van Boxtel, J., & Lu, H. (2015). Joints and their relations
the extraction of critical features of coordinated body move-            as critical features in action discrimination: Evidence from
ments between two actors, and making relational connections              a classification image method. Journal of Vision, 15(1),
between these motion features based on inter-actor correla-              1-17.
                                                                  579

