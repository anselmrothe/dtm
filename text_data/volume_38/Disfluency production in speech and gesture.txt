Disfluency production in speech and gesture
Niloofar Akhavan (nakhavan13@ku.edu.tr)
Department of Psychology, Koç University
Rumelifeneri Yolu Sariyer 34450, Istanbul – TURKEY

Tilbe Göksun (tgoksun@ku.edu.tr)
Department of Psychology, Koç University
Rumelifeneri Yolu Sariyer 34450, Istanbul – TURKEY

Nazbanou Bonnie Nozari (nozari@jhu.edu)
Department of Neurology, Department of Cognitive Science,
Johns Hopkins University
1629 Thames Street, Suite 350, Baltimore, MD 21231, USA

Abstract
The current study investigates the interaction between
language and gesture production systems, but within a
different framework than that of the previous studies. We
examined the relationship between disfluency and gesture
production in healthy adults to address two questions: 1) Do
gesture and language reflect operations of a single system or
two separate systems? 2) Does gesture support the language
system? In order to better understand the relationship
between gesture and speech, we also analyze the temporal
relationship between speech and gesture problems.

The cognitive architecture and function of co-speech gesture
has been the subject of a large body of research. We investigate
two main questions in this field, namely, whether language and
gesture are the same or two inter-related systems, and whether
gestures help resolve speech problems, by examining the
relationship between gesture and disfluency in neurotypical
speakers. Our results support the view of separate, but interrelated systems by showing that speech problems do not
necessarily cause gesture problems, and on many occasions,
gestures signal an upcoming speech problem even before it
surfaces in overt speech. We also show that while gestures are
more common on fluent trials, speakers use both iconic and
beat gestures on disfluent trials to facilitate communication,
although the two gesture types support communication in
different ways.

Do gestures help language production?
One way to examine whether gestures benefit language
production is to look at individuals with aphasia who have a
variety of difficulties in speech production. The results are
mixed. Some report that individuals with Broca’s aphasia do
not necessarily produce gestures to clarify their incomplete
speech (Goodglass & Kaplan, 1963; Cicone et al., 1979;
McNeill, 1985; Glosser et al., 1986). In contrast, others
demonstrated that they produce more meaning-laden gestures
when they have trouble retrieving words than when their
production is fluent (Hadar et al., 1998; Lanyon & Rose,
2009; Raymer et al., 2006; Rose & Douglas, 2001; Göksun et
al., 2013, 2015).
A second population for studying the benefits of gesture
for language production is people who stutter. Gesture
production is halted during bouts of stuttering and fluent
gesture production is linked to fluent speech production
(Mayberry & Jaques, 2000). This close correspondence
between fluency and gesture production in this population
suggests that gestures simply accompany speech and do not
have a compensatory role when speech is problematic.
Finally, the potential role of gestures for helping language
production has been studied in healthy individuals, using
gesture prevention paradigms. Performance on language
production tasks usually deteriorates when gestures are
prevented (Hostetter, Alibali, & Kita, 2007, but see Beattie &
Coughlan, 1999). However, these paradigms require active
inhibition of gestures that would have otherwise been

Keywords: gesture, speech production, disfluency

Introduction
People spontaneously produce gestures when they talk. It has
been widely accepted that gesture and speech are
semantically and temporally coordinated. However, there is
mixed evidence on whether speech and gesture form a tightly
integrated communication system originating from the same
representational system, or whether they are two separate, but
interrelated systems (Butterworth & Hadar, 1989;
McNeill, 1992, 2005; Alibali, Kita, & Young, 2000;
Kita, 2000; Krauss, Chen, & Gottesman 2000; GoldinMeadow, 2003; Kita & Özyürek, 2003; de Ruiter, 2007;
Hostetter & Alibali, 2008; Goldin-Meadow & Alibali, 2013;
Pouw et al., 2014). McNeill (1992, 2005) argues that the
coordination between speech and gesture arises from the fact
that the two emerge from the same system. Others have
proposed language and gesture as separate, but
interdependent systems. Gesture may influence language
(Krauss et al., 2000; de Ruiter, 2000), or gesture can be
influenced by language (Hostetter &Alibali, 2008, 2010; Kita
& Özyürek, 2003). Even in the absence of overt speech,
phonological representations can influence gestures (Nozari
et al., 2015).

716

naturally produced. Implementing such inhibition may divert
attention from the main task of speaking and cause the
increased error rates under circumstances when gesturing is
prohibited.
In summary, investigation of the potential benefits of
gesture for language production has yielded inconclusive
results. Here, we propose a new approach to the same issue
by exploring the relationship between disfluency and gesture
in neurotypical speakers. Disfluency is an excellent tool for
this purpose, because (a) it is a surefire of a glitch in the
language production system, and (b) unlike overt errors that
are infrequent in speech of neurotypical adults, disfluency
rate is estimated to be between 6 (Bortfel et al., 2001) to 26
(FoxTree, 1995) per 100 spoken words in healthy individuals.
These characteristics allow us to investigate the relationship
between language and gesture in healthy adult speakers
without imposing unusual demands on either language or
gesture production.
Maclay and Osgood (1959) originally classified disfluency
into four categories: (1) Filled pauses are verbal interruptions
that do not relate to the proposition of the main message (e.g.
uh and um, er and ah), (2) Silent pauses are periods of silence
longer than the pauses in an equivalent fluent utterance, (3)
Repeats are unmodified repetitions of a word, a part of a
word, or a string of words (e.g., The girl is running around
the around the tree). 4) Fillers and Comments that can be in
the form of question asking the listener to rehearse the
missing words (e.g., what is this called?). Disfluency can also
entail corrections or repairs to produced words or phrases.
Levelt (1989) divides repairs into two main categories: (1)
Error repairs, where the original utterance was wrong (e.g.,
error = “dog”, repair = “cat”, or error = “cap”, repair = “cat”),
and (2) appropriateness repairs, where the original utterance
was not wrong, but was considered by the speaker to be
incomplete or ambiguous (e.g., original utterance = “the
pen”, repair = “the red pen”). Using a task that elicits
production of sentences and gestures, we examine the
relationship between these types of disfluency and gesture.
We also examine the timeline of gesture interruption
compared to speech interruption. Seyfeddinipur and Kita
(2001) found that gesture suspension and resumption points
took place before speech disfluency. They interpreted the
early interruption of gestures compared to speech as a sign
that speakers knew that there was a problem in speech but
delayed the interruption until a repair was available.

It has been suggested that producing an iconic gesture, for
instance drawing a circle in the air, helps speakers produce
the word (cartwheel in this case). Different hypotheses have
been proposed for how iconic gestures facilitate production.
Some have proposed that gesture helps lexical retrieval
(Krauss, 1998), some have posited that gesturing helps
packaging of conceptual information (Alibali, Kita, &
Young, 2000), and some have argued that it helps create a
mental image of the word’s referent during lexical search
(Wesp, Hesse, Keutmann, & Wheateon, 2001). Regardless of
the exact mechanism, all of these accounts maintain that
iconic gestures benefit language by helping the retrieval of
information from the lexical-semantic system.
On the other hand, beat gestures are believed to be free of
semantics and as such, are unlikely to be directly involved in
retrieving information from the lexical-semantic system
(Krauss & Hadar, 1999, but see Lucero, Zaharchuk, &
Casasanto, 2014). Instead, they may have a communicative
role by engaging the listener until the speech problem is
resolved. Thus, beat gestures may “hold the conversational
floor” during speech problems, similar to what has been
proposed for filled pauses (e.g., Maclay and Osgood, 1959;
but see Clark & Fox Tree, 2002). Given the different roles
that iconic and beat gestures play, in examining the role of
gesture in compensating for speech problems, we inspect
these two types of gesture separately.

Predictions
Regarding our two main questions we have the following
predictions. (1) If speech and gesture arise from the same
system, we would expect problems in the two to co-occur.
But, if gesture and speech are separate systems, at least past
the conceptualization point, speech problems may emerge in
the absence of gesture problems. (2) To explore the role of
gesture for resolving speech problems, we posed two
questions: (a) is the primary role of gestures to help when
there is a problem in speech? If so, we would expect gestures
to mainly arise during disfluent -- compared to fluent -- trials.
(b) If gestures’ primary role is not to help with speech
problems, do they play any role in resolving language
problems? If yes, we would expect more disfluent trials with
than without gestures. Note that for (a) we divide trials
primarily based on the presence or absence of gesture and
then inspect which proportion of gesture trials also included
a disfluency. On the other hand, in (b) we divide the trials
primarily based on the presence of absence of disfluency, and
then inspect which proportion of disfluent trials contained a
gesture. We also analyze the temporal relationship between
speech problems and gesture addresses the question of
whether the two systems are highly synchronized (McNeill,
1992; Mayberry & Jaques, 2000) or whether gesture
problems foreshadow speech problems (Seyfeddinipur, &
Kita, 2001).

Iconic vs. beat gestures
Co-speech gestures are classified into several categories.
Two of these categories that have received attention for their
role in compensating for speech problems are iconic and beat
gestures. Iconic gestures are used as symbols to reenact
actions (e.g., drawing a circle in the air to represent doing
cartwheel) or to represent concrete objects (e.g., bending the
index finger to represent a hook). Beat gestures are flicks of
the hand that follow the speech prosody without the gesture
conveying semantics (McNeill, 1992).

Methods

717

interrupted at the time of preparation or at the time of a stroke
before the action was completed (holding the hand or being
retracted back into its preparation position). The resume point
was coded when the gesture that was at the static-hold
position started a dynamic phase and was completed. Last,
the time gap between the onset of a speech problem and
gesture, as well as the gap between resumption of fluent
speech and gesture were coded in milliseconds.

Participants
Twenty monolingual native Farsi speakers (9 females)
between the ages of 18 and 30 were tested. Participants lived
in Iran, were all right-handed, had normal hearing and vision.
All participants gave their written consent for participation in
accordance with the guidelines approved by the IRB
committee of the Koç University. Two participants’ data was
excluded. One of these person’s gestures were out of the
camera frame and the other person’s video recording crashed
during the coding.

Results
A total of 356 trials were included in the analyses.
Participants produced 307 iconic and 61 beat gestures, and
174 instances of disfluency. Each subject produced at least
one gesture of one instance of disfluency. There were only
three instances of overt errors and repairs. The rest of the
disfluency cases comprised 53.4% filled pause, 27.0%
appropriateness repairs, 12.6% comments, and the 7.0%
repetitions. On 126 occasions, disfluency was accompanied
by 105 iconic gestures and 21 beat gestures.
To test whether gesture and language reflect operations of
a single system or two separate systems, we examined how
often disfluent speech was accompanied by gestures that also
showed a problem, as opposed to problem-free gestures. This
analysis was conducted only on iconic gestures for which a
problem can be objectively defined. We found that disfluent
speech was accompanied by gestures that showed no
problems on many occasions (45 instance or 42.9% of the
time; X2 (1, N = 105) = 2.14, p = 0.14). This finding shows
that speech problems can occur without any problems in
gesture, supporting the view that the two arise from different
systems, at least past the conceptual level.
To investigate whether gesture can help resolve speech
problems, we first asked if the primary goal of gestures was
to help repair speech problems. If true, we would expect
reliably more gestures when speech was disfluent, compared
to when speech was fluent. Results indicated otherwise; there
were significantly more gestures when speech was fluent than
disfluent, (242 vs. 126; X2 (1, N = 368) = 36.57, p < .001).
These findings imply that gestures’ primary function may not
to resolve speech problems.
We then asked whether gesture has any role in resolving
speech problems. To answer this question, we looked only at
trials where there was speech disfluency. If speakers use
gestures to resolve speech problems, we would expect
significantly more disfluent speech trials that contain a
gesture than those in without a gesture. This was the case for
disfluent speech, (126 vs. 48, X2 (1, N = 174) = 34.97, p <
.001).
Next, we examined the pattern of iconic and beat gestures
separately on disfluent cases. Of the 126 disfluent cases that
were accompanied by gestures, 105 (i.e., 83.4%) were iconic,
and the rest (16.6%) were beat gestures. Thus, speakers
mainly produced iconic gestures with speech problems, X2 (1,
N = 126) = 56.0, p < .001. A closer examination of the data
showed that beat gestures were produced mostly with filled
pauses and comments (80.9%), and only in a few cases with

Materials
Participants watched 20 dynamic movie clips, depicting
different motion events. Each movie lasted for 3–4 seconds.
The clips were previously developed and used in English and
Persian (Göksun et al., 2015; Akhavan et al., 2015). All
actions were performed by a woman in an outdoor area.

Procedure
All participants were tested individually in their home
environment in a silent room. They were instructed to watch
each clip and then describe what they saw. No explicit
instruction regarding gesture use was provided. Test stimuli
were displayed on a Dell laptop in three different randomized
orders across participants. Participants received no feedback
throughout the testing sessions. The testing sessions were
both audio- and videotaped. The camera was set in a position
to capture the hands and the body of the participants but not
the heads.

Coding
Speech. Participants’ speech was transcribed by a native
Farsi speaker (first author), and coded for disfluency. The
following were coded as disfluency: a) filled pauses (e.g., uh
and um, er and ah), b) repetitions (e.g., the girl is running,
running around the tree), 3) fillers and comments (e.g.,
What’s the word I need … when used in the middle of a
sentence while searching for a word), 4) appropriateness
repairs when the speaker repaired an utterance to make it
more complete (e.g., the girl is running around the tree …
elaborating this by saying, she is running very fast around the
tree).
Gesture. Gestures were coded as iconic or beat gestures.
Gesture coding was done manually by the first author of the
study using the ELAN software package (Brugman & Russel,
2004). Gesture abnormalities were coded as interruption
(suspension of an ongoing gestural unit), repetition
(immediate repetition of a gestural unit) and change
(suspension of an ongoing gestural unit with an immediate
initiation of a new gestural phase).
Speech-gesture relation. Parallel to the speech start-stop,
gestures’ re-start and interruption points were identified. The
start point was coded when the hand started to move. The
suspension was coded when an ongoing gestural unit was

718

repetitions and repairs. These findings show that on the
majority of disfluent trials, speakers employed iconic
gestures that, as reviewed earlier, have links to the lexicalsemantic system. The use of beat gestures, on the other hand,
was confined to cases where the nature of the disfluency
implied that the speaker was cueing the listener that they are
not done speaking. Together, these results suggest that while
the primary role of gestures may not be to resolve problems
in speech, speakers often use them when such problems arise.
In the following analysis, we examined the temporal
pattern for the 126 cases of disfluent speech accompanied by
the gestures, where 60 of the gestures manifested an
abnormality and the other 66 gestures emerged normally at
the time of the speech disfluency. First, we looked at the 60
cases when the gesture showed abnormality and coincided
with the speech disfluency. We had 22 interrupted and 38
repeated gestures. Of the interrupted gestures, 91% cooccurred with filled pauses and fillers. We examined the
temporal relation between the gesture interruption point and
the disfluency starting point. The results revealed that
gestures stopped either simultaneously or before the starting
point of speech disfluency. There were significantly fewer
cases, in which speech disfluency starting point preceded
gesture interruption, X2 (2, N = 20) = 23.72, p < .001 (see
Table 1)
Next, we examined the temporal relationship between
when speech was resumed and when gesture was resumed.
Gestures were either resumed the same time as the speech
was resumed (7 cases) or before speech resumption (7 cases)
by an average of 237 ms. Importantly, gestures were never
resumed after speech resumption.

occurred before or simultaneously with problems in the
speech.
Recall that among the 126 cases of gestures accompanying
disfluent speech, 45 of the gestures were iconic and problemfree. These iconic gestures preceded their semantically
targeted speech with the average of 1036 ms gap. Finally, out
of 126, the remaining 21 were beat gestures, where 70.3%
were produced before the starting point of the speech
disfluency. The rest were simultaneously produced with
speech disfluency.

Discussion
To our knowledge, this is the first controlled study examining
the speech and gesture interaction in the light of disfluency in
neurotypical adult speakers. We first asked if language and
gestures come from the same of separate -- but related -systems. Our results supported the latter: on many occasions
when there was a problem in speech, gestures showed no
trace of the problem. This finding is incompatible theories
that propose a tight co-expression of gesture and speech
(McNeill, 1992, 2005), and is better aligned with separate but
interrelated models of speech and gesture (Krauss et
al., 2000; de Ruiter, 2000; Hostetter & Alibali, 2008, 2010;
Kita & Özyürek, 2003).
We then turned to a question that has been a focus of
many past studies: Do gestures have a supporting role for
speech production? This questions has been addressed by
examining various populations (e.g., individuals with
aphasia, individuals who stutter), but the results have been
mixed. The only investigation of this question in neurotypical
adults have been through the use of the gesture inhibition
paradigm, which poses unusual cognitive demands on the
speaker, making the interpretation of the results difficult. By
examining the relationship between disfluency during normal
speech production, we were able to address this issue from
two angles: we first showed that the main role of gesture was
not to remedy speech problems: gestures were reliably more
prevalent on the fluent than disfluent sentences. Without
independently assessing the fluency of speech, it is not
possible to predict the exact link between gesture and fluency
from correlational data. However, from this data, we can
conclude that when speakers did encounter problems, they
showed evidence of using gestures to help resolve speech
problems: significantly more disfluent trials were with than
without gesture. Moreover, the majority of these gestures
were iconic gestures that are linked to lexical-semantic
system. Thus, it is likely that speakers used these gestures to
increase the activation of that system and to facilitate lexical
retrieval (see also Cook, Yip, & Goldin-Meadow, 2012).
Another explanation could be that gesturing may lighten
the verbal working memory (VWM) load (Goldin-Meadow
et al., 2001). Speakers were better able to remember verbal
items when they gestured during intervening speech than
when they did not. Additional evidence in support of this
hypothesis showed that speakers with lower VWM capacities

Table 1: The timeline of speech disfluency start point and
gesture interruption point
Percentage

Speech disfluency precedes
gesture interruption
Gesture interruption precedes
speech disfluency
Speech disfluency and
gesture interruption occur
simultaneously

5.0%

Average
time gap
(in ms)
893.33

40.0%

380

55.0%

0

It should be noted that out of 38 cases of gesture repetition,
95% co-occurred with repetition type of disfluency or
appropriateness repairs. Further, the repeated units of the
gesture occurred either simultaneously or before the repeated
or repaired section of the speech (average of 104 ms gap), (20
vs. 14, X2 (1, N = 34) = 1.06, p = 0.30). There were only 2
cases where speech repetition preceded gesture repetition. In
sum, the analysis of both interrupted and repeated gestures
showed that in the majority of cases, changes in the gesture

719

produce gesture more often than those having higher VWM
capacities (Gillespie et al., 2014).
Although beat gestures were not the most common type
of gestures to accompany disfluent speech, they accompanied
some of the trials with filled pauses and comments. These are
cases where speakers most clearly signal to the listener that
the speech problems are temporary and that speech will be
soon resumed. As such, beat gestures, while they may not
play a direct role in supporting lexical retrieval (e.g., Lucero
et al., 2014), seem to play a social role in communication.
This finding explains the prevalence of such gestures during
speech (e.g., Beattie & Coughlan, 1999), in the absence of
semantic meaning (see also Krauss & Hadar, 1999, Lucero,
Zaharchuk, & Casasanto, 2014).
Finally, we examined the temporal relationship between
speech and gestures, and found that in most cases gesture
interruption of repetition preceded or coincided with the
onset of the speech problem. Critically, there were only two
instances where gesture problem manifested after the speech
problem. These findings imply that speech and gestures are
not always temporally synchronized as suggested (McNeill,
1992, 2005; Mayberry et al., 2000) Moreover, it suggests that
the two systems are closely connected, such that speech
problems can be reflected in gestures even before they
surface in speech.
Collectively, these results support a model of separate,
but interrelated systems for speech and gesture. In addition,
it sheds light on the functional role of gestures: while not
specialized for resolving overt problems in speech, both
iconic and beat gestures are used by speakers when speech
shows problems, although in different capacities.

Brugman, H., & Russel, A. (2004, May). Annotating
Multimedia/ Multi-modal Resources with ELAN. In
LREC.
Butterworth, B. (1975). Hesitation and semantic planning in
speech. Journal of Psycholinguistic research, 4(1), 75-87.
Butterworth, B., and Hadar, U. (1989).Gesture, speech, and
computational stages: a reply to McNeill. Psychol.Rev.
96,168–174.doi:10.1037/0033-295X.96.1.168
Cicone, M., Wapner, W., Foldi, N., Zurif, E., & Gardner, H.
(1979). The relation between gesture and language in
aphasic communication. Brain and Language, 8(3), 324–
349.
Clark, H. H., & Tree, J. E. F. (2002). Using uh and um in
spontaneous speaking. Cognition, 84(1), 73-111.
Cook, S. W., Yip, T. K., & Goldin-Meadow, S. (2012).
Gestures, but not meaningless movements, lighten
working memory load when explaining math. Language
and cognitive processes, 27(4), 594-610.
de Ruiter, J. (2000). The production of gesture and speech.
In D. McNeill (Ed.), Language and gesture (pp. 284-311).
Cambridge: Cambridge University Press.
de Ruiter, J. P. (2007). Postcards from the mind: The
relationship between speech, imagistic gesture, and
thought. Gesture, 7(1), 21–38.
Fox Tree, J. E. (1995). The effects of false starts and
repetitions on the processing of subsequent words in
spontaneous speech. Journal of Memory and Language,
34, 709–738.
Fraundorf, S. H., & Watson, D. G. (2014). Alice's
adventures in um-derland: psycholinguistic sources of
variation in disfluency production. Language, Cognition
and Neuroscience, 29(9), 1083-1096.
Gillespie, M., James, A. N., Federmeier, K. D., & Watson,
D. G. (2014). Verbal working memory predicts co-speech
gesture: Evidence from individual
differences. Cognition, 132(2), 174-180.
Glosser, G., Wiener, M., & Kaplan, E. (1986).
Communicative gestures in aphasia. Brain and Language,
27(2), 345–359.
Göksun, T., Lehet, M., Malykhina, K., & Chatterjee, A.
(2013). Naming and gesturing spatial relations: Evidence
from focal brain-injured individuals. Neuropsychologia,
51(8), 1518–1527.
Göksun, T., Lehet, M., Malykhina, K, & Chatterjee, A.
(2015). Spontaneous gesture and spatial language:
Evidence from focal brain-injury. Brain and Language,
150, 11-13.
Goldin-Meadow, S., Nusbaum, H., Kelly, S.D., & Wagner,
S. (2001). Explaining math: Gesture lightens the load.
Psychological Science, 12, 516-522.
Goldin-Meadow, S., So, W. C., Özyürek, A., & Mylander,
C. (2008). The natural order of events: How speakers of
different languages represent events nonverbally.
Proceedings of the National Academy of Sciences,
105(27), 9163 - 9168.

References
Akhavan, N., Nozari, N., & Göksun, T. (2015). Motion
event expressions in language and gesture: Evidence from
Persian. In D. C. Noelle, R. Dale, A. S. Warlaumont,
J. Yoshimi, T. Matlock, C. D. Jennings, & P. P. Maglio
(Eds.), Proceedings of the 37th Annual Conference of the
Cognitive Science Society (pp. 60–65). Austin, TX:
Cognitive Science Society.
Alibali, M. W. (2005). Gesture in spatial cognition:
Expressing, communicating, and thinking about spatial
information. Spatial Cognition and Computation, 5(4),
307-331.
Alibali, M. W., Kita, S., & Young, A. J. (2000). Gesture and
the process of speech production: We think, therefore we
gesture. Language and Cognitive Processes, 15(6), 593613.
Beattie, G., & Coughlan, J. (1999). An experimental
investigation of the role of iconic gestures in lexical
access using the tip‐of‐the‐tongue phenomenon. British
Journal of Psychology, 90(1), 35-56.
Bortfeld, H., Leon, S. D., Bloom, J. E., Schober, M. F., &
Brennan, S. E. (2001). Disfluency rates in conversation:
Effects of age, relationship, topic, role, and
gender. Language and speech, 44(2), 123-147.

720

Goldin-Meadow, S. (2003). Hearing gesture: How our
hands help us think. Cambridge, MA: Harvard University
Press.
Goldin-Meadow, S., & Alibali, M. W. (2013). Gesture’s
role in speaking, learning, and creating language. Annual
Review of Psychology, 64, 257.
Goodglass, H., & Kaplan, E. (1963). Disturbance of gesture
and pantomime in aphasia. Brain, 86(4), 703–720.
Hadar, U., Burstein, A., Krauss, R., & Soroker, N. (1998).
Ideational gestures and speech in brain damaged subjects.
Language and Cognitive Processes, 13(1), 59–76.
Hostetter, A. B., & Alibali, M. W. (2008). Visible
embodiment: Gestures as simulated action. Psychonomic
Bulletin & Review, 15(3), 495–514.
Hostetter, A. B., & Alibali, M. W. (2010a). Language,
gesture, action! A test of the Gesture as Simulated Action
framework. Journal of Memory and Language, 63(2),
245-257.
Hostetter, A. B., Alibali, M. W., & Kita, S. (2007). Does
sitting on your hands make you bite your tongue? The
effects of gesture prohibition on speech during motor
descriptions. In Proceedings of the 29th annual meeting
of the Cognitive Science Society (pp. 1097-1102).
Mawhah, NJ: Erlbaum.
Kita, S. (2000). How representational gestures help
speaking. In D. McNeill (Ed.), Language and gesture (pp.
162-185). Cambridge: Cambridge University Press.
Kita, S., & Özyürek, A. (2003). What does cross-linguistic
variation in semantic coordination of speech and gesture
reveal? Evidence for an interface representation of spatial
thinking and speaking. Journal of Memory and Language,
48(1), 16-32.
Krauss, R. M., Chen, Y., & Gottesman, R. F. (2000).
Lexical gestures and lexical access: A process model. In
D. McNeill (Ed.), Language and gesture (pp. 261-283).
Cambridge: Cambridge University Press
Krauss, R. M., & Hadar, U. (1999). The role of speech
related arm/hand gestures in word retrieval. Gesture,
speech, and sign, 93-116.
Lanyon, L., and Rose, M.L.(2009).Do the hand shave it?
The facilitation effects of arm and hand gesture on word
retrieval in aphasia. Aphasiology 23,809–822.
doi:10.1080/02687030802642044
Levelt, W. J. (1989). Speaking: From intention to
articulation. ACL. MIT Press Series in Natural- Language
Processing. MIT Press, Cambridge, Massachusetts.
Lucero, C., Zaharchuk, H., & Casasanto, D. (2014). Beat
gestures facilitate speech production. In P. Bello, M.
Guarini, M. McShane, & B. Scassellati (Eds.),
Proceedings of the 36th Annual Conference of the
Cognitive Science Society (pp. 898-903). Austin, TX.
Maclay, H., Osgood, Charles E. 1959. Hesitation
Phenomena in Spontaneous English Speech. Word 15, 1944.
Mayberry, R., & Jaques, J. (2000). Gesture production
during stuttered speech: insights into the nature of speechgesture integration. Language and Gesture, 199-215.

McNeill, D. (1985).So you think gestures are nonverbal?
Psychol. Rev. 92,350–371. doi:10.1037/0033295X.92.3.350
McNeill, D. (1992). Hand and Mind: What Gestures Reveal
about Thought. Chicago, IL: University of Chicago Press.
McNeill, D. (2005). Gesture and Thought. Chicago, IL:
University Of Chicago Press.
Nozari, N., Göksun, T., Thompson-Schill, S.L., &
Chatterjee, A. (2015). Phonological similarity affects
production of gestures, even in the absence of
speech. Frontiers in Psychology, 6 (1347). doi:
10.3389/fpsyg.2015.0134
Pouw, W. T., de Nooijer, J. A., van Gog, T., Zwaan, R. A.,
& Paas, F. (2014). Toward a more embedded/extended
perspective on the cognitive function of gestures.
Frontiers in Psychology. doi: 10.3389/fpsyg.2014.00359.
Raymer, A. M., Singletary, F., Rodriguez, A., Ciampitti, M.,
Heilman, K. M., & Rothi, L. J. G. (2006).Effects of
gesture+ verbal treatment for noun and verb retrieval in
aphasia. Journal of the International Neuropsychological
Society, 12(06), 867–882.
Rose, M., & Douglas, J. (2001). The differential facilitatory
effects of gesture and visualization processes on object
naming in aphasia. Aphasiology, 15(10-11), 977–990.
Seyfeddinipur, Mandana and Kita, Sotaro (2001) 'Gesture as
an indicator of early error detection in self-monitoring of
speech.' Proceedings of the ISCA (International Speech
Communication Association) Tutorial and Research
Workshop. DiSS’01:Disfluency in spontaneous speech’
University of Edinburgh, Scotland .
Wasp, R., Hesse, J., Keutmann, D., & Wheaton, K. (2001).
Gestures maintain spatial imagery. The American journal
of Psychology, 114, 591-600.

721

