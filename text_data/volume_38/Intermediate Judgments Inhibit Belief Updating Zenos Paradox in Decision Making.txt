Intermediate Judgments Inhibit Belief Updating: Zeno’s Paradox in Decision
Making
James M. Yearsley (james.m.yearsley@vanderbilt.edu)
Department of Psychology, Vanderbilt University, Nashville TN, USA

Emmanuel M. Pothos (emmanuel.pothos.1@city.ac.uk)
Department of Psychology, City University London, London, EC1V 0HB UK
Abstract
Rational agents should update their beliefs in the light of new
evidence. Equally, changes in belief should depend only on
the quality of the evidence, and not on factors such as the order in which the evidence is acquired, or whether intermediate judgements are requested during evidence acquisition. In
contrast we show that requests for intermediate judgments can
inhibit belief updating for real decision makers, which represents a new type of decision making fallacy. This behaviour is
paradoxical from the point of view of classical Bayesian models, but we show that it is consistent with an a priori, parameter
free prediction of a cognitive model based on quantum theory.
Keywords: cognition; decision making; quantum probability.

Introduction
That decision makers should update their beliefs in the light
of new evidence is one of the cornerstones of what it means
to be rational (Anand, 1993). Equally, for rational agents,
the degree of belief change should depend only on the quality
of the new evidence acquired and not on other factors such
as the order of evidence acquisition or requests for intermediate judgements (Oaksford & Chater, 2009). However it is
known that real decision makers do not always conform to
the strictest standards of rationality (Tversky and Khaneman,
1974). One notable example of this are order effects, where
presenting the same evidence in different orders can have a
large influence on the change in belief generated (Trueblood
& Busemeyer, 2011).
In this contribution we examine another effect, which is
that of requests for intermediate judgments during the process
of evidence acquisition. Since requesting such a judgment
does not provide a decision maker with any extra relevant information about the problem, making intermediate judgments
should have no effect on the process of belief updating for a
rational decision maker. Thus at least the simplest classical
Bayesian cognitive models should predict no effect of intermediate judgments on the final belief state.
In contrast, in cognitive models where judgment is considered a constructive process, intermediate judgments may
well have an effect on belief updating (Schwarz, 2007; White,
Pothos & Busemeyer, 2014). One such class of models,
which have received much attention recently, are those based
on the mathematics of quantum theory (Busemeyer & Bruza,
2011). These models not only predict an effect of intermediate judgments on belief updating, but allow us to make a
priori, parameter free predictions of the precise relation between the change in belief and the number of intermediate
judgments which can be tested by a suitable experiment. The

startling conclusion is that in quantum models, requests for
intermediate judgments can strongly inhibit belief updating.
In physical systems this singular phenomena is called the
quantum Zeno effect, because of the (loose) analogy with
Zeno’s second paradox; for this reason we term this effect
Zeno’s paradox in decision making.
In one experiment, we compare the predictions of the quantum model with a simple matched classical Bayesian model
and find that the quantum model outperforms the Bayesian
one by a large margin. Indeed, the predictions of the Bayesian
model are shown to be qualitatively inconsistent with the
data. We briefly discuss whether allowing probabilities in a
classical model to depend on the memory of a previous judgment can reproduce the quantum behavior.

Experimental Investigation
We performed two identical experiments as a replication exercise. We report only the first experiment here, the conclusions of the second were the same and are reported in full in
Yearsley & Pothos (2016).
We recruited 450 experimentally naı̈ve participants, from
Amazon Turk. Participants were 49% male and 50% female
(1% did not respond to the gender question). Most participants’ first language was English (98%) and the average age
was 34.8. The experiment lasted approximately 10 minutes;
participants were paid $0.50 for their time.
The experiment was implemented in Qualtrics. Our
paradigm extends one of Tetlock (1983), which was designed
to test for primacy effects in decision making. After some
initial screens regarding ethics information and consent, all
participants saw the same initial story, regarding Smith, a hypothetical suspect in a murder:
“Mr. Smith has been charged with murder. The victim is
Mr. Dixon. Smith and Dixon had shared an apartment for
nine months up until the time of Dixon’s death. Dixon was
found dead in his bed, and there was a bottle of liquor and a
half filled glass on his bedside table. The autopsy revealed
that Dixon died from an overdose of sleeping pills. The
autopsy also revealed that Dixon had taken the pills sometime between midnight and 2am. The prosecution claims
that Smith slipped the pills into the glass Dixon was drinking
from, while the defense claim that Dixon deliberately took an
overdose.”
Participants were then given a short set of questions regarding some details of what they had just read, in order to
check that they were engaging with the task. These questions

2339

were intended to reinforce memory of the story details and
to check for participants who were not concentrating on the
experiment. The small number of participants who failed to
correctly answer these questions were excluded from subsequent analysis. Participants were subsequently asked whether
they thought Smith was likely to be guilty or innocent, based
on the information provided in the vignette, and to provide
a brief justification for their response, as a further check that
they were adequately concentrating on the task and to reinforce memory for the response. The first response is critical,
since all model predictions are based on knowledge of the initial (mental) state. Most participants (95%) initially assumed
innocence, and so we excluded participants who initially assumed guilt. Participants then saw a screen reminding them
of their response.
Participants were split into six groups. The first group was
presented with 12 pieces of evidence suggesting that Smith
was guilty (participants were told they would only see evidence presented by the prosecution and not by the defense).
Each piece of evidence was designed (and pilot tested) to
be individually weak, but cumulatively the effect was quite
strong. For example one piece of evidence read “Smith had a
previous conviction for assault.” After reading all 12 pieces of
evidence, participants were again asked whether they thought
Smith was guilty or innocent, and again asked to justify their
choice. Participants in the other five groups were shown the
same evidence in the same way, and asked to make the same
final judgment, but were also asked to make intermediate
judgments (and justify their responses). These intermediate
judgments were worded in the same way as the initial and final ones, and were requested at intervals of either 1, 2, 3, 4
or 6 pieces of evidence. A small number of participants gave
justifications for their judgments that suggested they were not
properly engaging with the task, and were therefore excluded
from the analysis. Together with those who failed to correctly
answer the questions about vignette, and those excluded from
the present analysis because they initially judged ‘Guilty,’ this
left 425 good participants.
The order of presentation of the evidence was partly randomized. The pieces of evidence were split into four blocks
of three pieces of evidence each. The order of the blocks
was fixed, but the order of the pieces of evidence within each
block was randomized. The reason we randomized evidence
order in this way, rather than say simply randomizing the order of presentation of all pieces of evidence, is that there are
a total of 12!, or about 480 million, possible orderings of the
evidence, so it is impossible to capture a representative sample of the orderings by simple randomization.
After the main part of the experiment, participants were
shown a list of the pieces of evidence they had encountered,
and were asked to rate the strength of each piece of evidence
on a (1-9) scale. (The full list of pieces of evidence is presented is Yearsley & Pothos, (2016.))

Zeno’s paradox in quantum decision making
We want to explain why the Zeno effect arises in quantum
models of decision making using a simple example. In a realistic decision making scenario, such as the experiment we
discussed above, the modeling is necessarily more complex
and this can make the origin of the effect harder to see.
Consider a 2D quantum system, with a state space spanned
by two orthogonal states I and G, corresponding to the beliefs that Smith is either Innocent or Guilty. Presentation of
evidence is represented by a rotation of the state such that an
initial state I evolves towards G, with pieces of evidence.
We are interested in the probability that a measurement
of the state will reveal I, at each of N ≥ 1 judgments at
T /N, 2T /N...T is (where T is the total number of pieces of
evidence) In analogy with the physics case, this may be called
the survival probability after N judgments. For a typical time
independent Hamiltonian we have;
Prob(0 Survival,0 N) =

γ

2T
T
...I at T |I at 0 = cos2N
Prob I at , I at
N
N
N

(1)

Here γ is a constant encoding the effect of the evidence in
the absence of intermediate judgments. As the number of
judgments, N, increases, there is a decreasing probability that
the system will change from I to G. As N → ∞, the probability that the system will change state vanishes, even after
large number of pieces of evidence. This is the famous QZ
effect (Misra & Suarshan, 1977), often described informally
as proof that ‘a watched pot never boils’.)
The derivation leading to Eq.(1) involves a number of assumptions that will not hold in realistic decision making settings. However we can still predict a weakened QZ effect,
as a slowing down (in a specific way) of the evolution of the
measured opinion state, even under more realistic conditions.
We will outline the argument below, full details are given in
Yearsley & Pothos (2016).
Two assumptions need to be relaxed. First, realistic measurements are not perfectly reliable. For each measurement,
there is a small probability that a participant will incorrectly provide a response not matching his/her cognitive state.
This is problematic when several identical measurements are
made, since error rates may compound. Imperfect measurements require the use of positive-operator valued measures
(POVMs), instead of projection operators. Instead of freezing
as N → ∞, some evolution may still occur, but it will depend
only on details of the imperfect measurements (Anastopoulos & Savvidou, 2006). The effect of imperfect judgments is
encoded by a simple POVM operator with one free parameter, ε. The parameter 0 ≤ ε ≤ 1 reflects how error-less measurements are. For example, if a participant considers Smith
innocent, then the probability of responding innocent is only
1 − ε, leaving a probability to respond guilty of ε.
Second, evolution of cognitive variables is better modeled
by a time dependent unitary evolution to capture the fact that
the weight given by participants to a piece of evidence de-

2340

pends on its position in the sequence of evidence, implying a
primacy or recency effect. We must also take account of the
fact that not all pieces of evidence will be regarded as equally
strong by participants.
A form for the time dependent unitary evolution general
enough for our purposes is
U(tm ,tn ) = exp(−iσx B(tm ,tn )),

(2)

where σx is one of the Pauli matrices and
n

B(tm ,tn ) = α

∑

2

ai e−β(i−m−1)

(3)

i=m+1

with α and β real numbers.
The function B(tm ,tn ) specifies the angle a participant’s
cognitive state is rotated through when presented with pieces
of evidence tm through tn . Here the ai represent the strengths
of the individual pieces of evidence, as measured in isolation. Thus the first piece of evidence in a sequence is given a
weight a1 the second is given weight a2 e−β , and so on. Depending on the value of β this form for B(tm ,tn ) can encode a
primacy (β > 0) or a recency (β < 0) effect. Using the above,
we can show that:
Prob(I at t|I at 0) =(1 − ε)2 cos2 (B(0,t))
+ ε(1 − ε) sin2 (B(0,t))

(4)

Eq(4) allows us to determine ε and B(0,t), from empirical
classical data on the probability of judging Smith’s innocence, assuming innocence initially, and varying the number
of pieces of evidence presented (without intermediate judgments). We can also use Eq(4), together with some assumptions about the way judgments change the cognitive state classically, to construct a Bayesian model of the same decision
making process. We will do this below, but note that in the
case of no intermediate judgments the QT and Bayesian models will coincide. This means that we can use data obtained
in the absence of any intermediate judgments to fix all the parameters in both the QT and Bayesian models. Our central
predictions, of the specific way in which intermediate judgments affect opinion change, will therefore be parameter free.

Specifically, the expression for the survival probability is:


2T
T
ProbQ (0 survival 0, N) = Prob I at , I at
, ...|I at T
N
N
 

N−1
iT
(i
+
1)T
= (1 − ε)N+1 ∑ cos2 B
,
N
N
i=0

 
(5)
(N − 1)T
N
2
,T
+ ε(1 − ε) sin B
N
 

N−2
iT (i + 1)T
× ∑ cos2 B
,
+ O(ε2 )
N
N
i=0
The first term in this expression corresponds to the probability that the cognitive state is always consistent with innocent,
and all the judgments reflect this. The second term corresponds to possibility that the state does change between the
second to last and final judgments, but the participant nevertheless responds ‘innocent’ due to the imperfect measurements. Further terms would correspond to more judgments
not matching the cognitive state, or the state changing back
from innocent to guilty, these terms are negligible compared
to those included in Eq.(5). If ε = 0, β = 0 and the ai ’s are
equal then Eq(5) reduces to Eq(1).

Constructing a matched classical model
The QT model assumes evidence changes the opinion state
(determined by Eq(4)), judgments may be imperfect, and
judgments are constructive. The third property is the characteristically quantum one, so with the first two elements, we
constructed an alternative, Bayesian model for survival probability. It is helpful to denote by IB the event where a participant believes Smith is innocent, and by IR the event where a
participant responds Smith is innocent, similarly for guilty.
The expression we are interested in is the Bayesian analogue of Eq.(5); the survival probability after T pieces of evidence have been presented, given that N judgments have been
made. This is
ProbC (0 survival 0 , N) =


T
(N − 1)T
, IR at |IR at 0
Prob IR at T, IR at
N
N

(6)

We want to construct this so that it matches the quantum expression in the case of no intermediate judgments (N=1). We
will sketch how to do this here, full details are given in Yearsley & Pothos (2016).
As already noted, because Eq(4) does not involve any intermediate judgments it may be interpreted classically. We
can therefore read off,

The Quantum Model

Prob(IB at t|IB at 0) = cos2 (B(t, 0))
Prob(GB at t|IB at 0) = sin2 (B(t, 0))

We now state the prediction of a QZ effect in this decision
making setting, the full derivation is presented in Yearsley
& Pothos (2016). The result is that a participant deciding
Smith’s innocence will be less likely to change his/her initial
opinion as the number of intermediate judgments increases.

Prob(IR at t|IB at t) = (1 − ε)
Prob(GR at t|IB at t) = ε
Prob(GR at t|GB at t) = (1 − ε)
Prob(IR at t|GB at t) = ε

2341

(7)

The probabilities involving transitions from Guilty cognitive
states to Innocent ones are assumed to be 0. Eq.(4) is therefore also our Bayesian survival probability for the case of no
intermediate judgments.
To compute the survival probability when there are intermediate judgments made we need to know the appropriate
function for the evolution of the state. The natural classical
analogue of Eq.(3), BC (tm ,tn ), is given by
n

BC (tm ,tn ) =

∑

2

ai e−β(i−1)

(8)

i=m+1

This differs from B(tm ,tn ) only in the fact that the function multiplying the evidence strength depends only on how
many pieces of evidence have been presented before it, and
not on whether any intermediate judgments have been made.
Note that BC (0,tm ) = B(0,tm ) since the quantum and classical models agree in the absence of intermediate judgments.
In particular this means fitting either function to the data in
the absence of intermediate judgments produces the same set
of parameters, α, β.
In fact we could use the function B(tm ,tn ) in the Bayesian
analysis if we desire, despite the fact it is poorly motivated. It
turns out that the Bayesian models perform better when using
BC (tm ,tn ), so we will work exclusively with this.
We can use the information above to derive a prediction
for the Bayesian survival probability. Doing so involves two
assumptions, first that ε is small, and secondly that the probabilities involving transitions from Guilty cognitive states to
Innocent ones are negligible. We can then show (Yearsley &
Pothos, 2016;

1
0.9
0.8
0.7
0.6
p(I at t|I at 0)

ProbC (0 survival 0, N) = (1 − ε)N+1 cos2 (BC (0, T ))
  (N − 1)T 
,T
+ ε(1 − ε)N sin2 BC
(9)
N
  (N − 1)T 
+ O(ε2 )
× cos2 BC 0,
N

In order to determine B(t1 ,t2 ), we first need to know the
ai ’s for each piece of evidence. These are the parameters indicating the relative strength of each piece of evidence and
they were fixed directly, using the participant ratings for each
piece of evidence at the end of the task.
The best fit parameters were obtained by minimizing the
sum of the squared deviations between the predictions of
Eq(4) and the data. Considering the t = 3 data point an outlier,
the best fit for Eq(4) is obtained with α = 0.091, β = 0.010
and ε = 0.030, giving an R2 of .996 and a BIC of -27.8. (BICs
computed following Jarosz & Wiley (2014).) The results of
the fitting are shown in Fig(1).
Since the data can be thought of as arising from a binomial
distribution the most informative way to display a confidence
interval is to imagine using the data to update an initially uniform prior for the value of the survival probabilities, and plot
the 95% Highest Density Interval (HDI) of the resultant posterior. Error bars in all figures therefore refer to these HDIs.
For small t, Prob(I at t|I at 0) is non-linear and (extrapolated) not equal to 1 at t = 0. This result justifies our assumption of imperfect measurements. In Fig(1), for large t,
Prob(I at t|I at 0) is close to linear with increasing t. Linearity implies that belief change is proportional to the number
of pieces of evidence, which seems an obvious expectation
for a rational participant (while the belief state is far from
guilty). Note that the best fit value of β is positive, confirming our expectation of diminishing returns (equivalently, there
is a primacy effect, regarding evidence strength.)
Now that the model parameters have been fixed for both
the QT and Bayesian models, we can use Eq(3) and Eq(4) to
compute survival probabilities, for different numbers of intermediate judgments.

We are now ready to test the Bayesian and QT predictions in
a realistic decision making scenario.

Data

0.5
0.4

Best ﬁt quantum
and Bayesian
models

0.3

Results and model fits

0.2

Empirical assessment involved two steps. First, without intermediate judgments (ie at the first judgment made after having
seen some evidence) the data is classical and simply informs
us how opinion changes with evidence. Using Eq(4), we can
determine ε and B(t1 ,t2 ) i.e., the parameter specifying the
POVMs for Smith’s innocence, guilt and the function specifying the way evidence alters the opinion state (the same parameter values are used in the Bayesian and QT models). Second, we examined whether intermediate judgments produce
the QZ effect (slowing down of opinion change, as predicted
by the QT model, Eq(5)) or not (in which case the Bayesian
model should fit better). The predictions about intermediate
judgments from the models were assessed after parameter fixing, the first step; they are a priori and parameter free.

0.1
0
0

2
4
6
8
10
Number of pieces of evidence a8er which 1st Judgment occurs

12

Figure 1: Setting the parameters (opinion change without intermediate judgments): Prob(I at t|I at 0), for the first judgment a participant made, after having seen different numbers
of pieces of evidence. Note the obvious outlier at three pieces
of evidence. Data points are the probability computed as an
average over participant choices (Number of Participants =64,
71, 70, 73, 71, 76 for each data point) and error bars show the
95% HDI of the posterior.
Empirical results for Prob(0 survival 0 , N) show a QZ effect,
as survival probability increases with small N (Fig(2)). The

2342

classical intuition is reduction of survival probability with
more intermediate judgments, because of a probability of error at each judgment. The data clearly favor the QT model:
the Bayes factor is 3.4 × 105 (Bayes Factor computed following Jarosz & Wiley (2014).) The dip in the survival probability for large N is an effect of the imperfect judgments.
There is an alternative test of the QT vs Bayesian models.
We can employ Eq(5) and Eq(9) to compute survival probabilities for the condition where there is a judgment after every
piece of evidence (number of pieces of evidence presented T ,
and number of judgments N, vary, but T /N fixed to 1). Again,
the data clearly favor the QT model (Fig(3)). The Bayes Factor in this case is 8.2 × 109 .

Probability of no change of of ini1al judgment

0.9
0.8
0.7
0.6
0.5

Data

0.4

Quantum
predic:on

0.3

Bayesian
predic:on

0.2

Classical Models with Memory Effects
We can use the behavior of the QT model to learn about
the structure of any classical model which aims to reproduce
these results. Such a model could be constructed by introducing extra variables not directly measured, but that have
an effect on the judgment probabilities. This would be post
hoc from the point of view of our experimental set up, but it
might be possible to motivate the existence and behavior of
these extra variables from other considerations. One natural
possibility is the memory of any previous judgments taken.
This might be motivated by arguing decision makers wish to
appear consistent in their judgments, so there is a bias towards aligning a judgment with any previous one1 . Note that
although such a model may be constructed in a classical way,
it is still manifestly non-Bayesian, since belief updating depends on factors other than the evidence seen.
We can use the predictions of the QT model to explore how
such a model would behave. It is useful to look at the idealized case, Eq(1) and focus on the case of a single intermediate judgment. With T pieces of evidence and no intermediate
judgment the survival probability is,
Prob(I at T |I at 0) = cos2 (T ).

0.1
0
0

2

4
6
8
Number of intermediate judgments

10

Figure 2: Evaluating the models: Survival probability for N
intermediate judgments, for the QT, Bayesian models, against
empirical results ; Data points are the probability computed as
an average over participant choices (Number of Participants
=76, 71, 73, 70, 71, 64) and error bars show the 95% HDI of
the posterior.

1
0.9
0.8

Survival Probability

0.7
0.6

Data

0.5
Quantum
Predic:on

0.4
0.3

Bayesian
Predic:on

0.2
0.1
0
0

2

4

6
Judgment

8

10

12

Figure 3: Evaluating the models: Survival probability after
each judgment, for the condition with 12 judgments. Data
points are the probability computed as an average over participant choices (Number of participants =64 for all data points)
and error bars show the 95% HDI of the posterior.
In summary, the data show a clear QZ effect, with survival
probability generally increasing with the number of intermediate judgements. Furthermore the behavior is in excellent
quantitative agreement with the predictions of the QT model.

(10)

and this must hold for the classical and quantum models.
With a single intermediate judgment the QT probability is,

T 

T
ProbQ I at T, I at |I at 0 = cos4
2
2



T
T
Q
Q
= Prob I at T |I at
Prob I at |I at 0 (11)
2
2
h

i2
T
= ProbQ I at |I at 0 .
2
In order that any classical model agree with the predictions
of the QT one, Eq.(11) would have to hold for this model.
Suppose we have a classical model containing an extra variable that plays the role of the ‘memory’ of the judgment made
at T /2. Then this memory variable would have to ‘screen
off’ the prior evidence so that transition probabilities between
T /2 and T are identical to those between 0 and T /2 before
any evidence has been seen. In other words, to agree with the
QT model predictions, a classical model incorporating memory cannot simply have the memory function an additional
piece of evidence. Instead the memory must override any evidence seen prior to the judgment.
There is a second property less often discussed but also
necessary for the QZ effect. Proof that Eq.(1) tends to 1 as
the number of judgments increases is based on the following,

γ

T
2T
lim Prob I at , I at
...I at T = lim cos2N
N→∞
N→∞
N
N
N
1
= lim (1 − (γ/N)2 + O(N −4 ))2N
N→∞
2


= lim 1 − γ2 /N + O(N −3 ) = 1
N→∞

(12)
1 This

2343

possibility was first suggested to us by Gordon Logan.

Crucially this depends on the transition probabilities being
non-linear for small amounts of evidence. In other words, the
QZ effect holds in part because in the QT model beliefs are
‘sticky.’ That is, is takes more evidence to change a belief
state that is close to a definite state than it does to change
a belief that is highly uncertain. We allowed our Bayesian
model to mimic this property in the model comparison, but
this ‘stickiness’ of beliefs is in itself a fundamentally nonBayesian property that must be incorporated into any model
aiming to reproduce the QZ effect.
To summarise this section, there is no doubt that one could
construct a classical model of belief updating that would
mimic the predictions of the QT model (and so fit at least
this data and the second set reported in Yearsley & Pothos
2016) by considering the effects of remembering previous
judgments. However in addition to any concerns about such
a model being post hoc, it would also have to have the two
features outlined above; that memories of intermediate judgments screen off evidence, and that beliefs are sticky. It would
be interesting to try and construct a classical model wth these
properties, although one wonders to what extent this would
simply amount to redescrbiing the QT model.

Concluding remarks
Understanding the way beliefs change as a result of accumulating evidence is essential for modeling decision making.
Our results suggest that opinion change depends not just on
the evidence, but can also be strongly effected by making intermediate judgments, a phenomena we call Zeno’s paradox
in decision making. This behavior is at odds with Bayesian
models of cognition, but agrees quantitatively with the predictions of a model based on QT. Because the QT model was
fixed with classical data, this striking prediction follows from
a structural feature of quantum theory, the collapse postulate,
and not from parameter fixing. Our results show models of
decision making need to incorporate influences arising from
the process of making judgments.
They also have practical implications. The paradigm we
employed, albeit simplified, does have analogies with realistic assessment of evidence; if e.g. juries are expected to reach
unbiased conclusions, then the effect of requests for intermediate opinions should be factored in. Likewise, the advent of
interactive news web sites (e.g., bbc.co.uk) means that readers can express opinions on news items while reading them,
directly and through social media. We raise the possibility
that this sort of overlap between acquiring information and
expressing an opinion may prevent change in opinion, even
in the presence of compelling evidence.
More generally, behaviors paradoxical from Bayesian perspectives have often been interpreted as boundaries in the applicability of probabilistic modeling. Strictly speaking this is
not true, since one can always augment Bayesian models with
extra variables or interactions, however such models may lack
predictive power, or simply be too post hoc. The QT cognition program provides an alternative: perhaps some of these

paradoxical findings reveal situations where cognition is better understood using QT, without the need to introduce extra
unobserved degrees of freedom. Evidence for the collapse
postulate in decision making constitutes a general test of the
applicability of QT principles in cognition and adds to the
growing body of such demonstrations (Pothos & Busemeyer,
2013). An important future direction will be to understand
whether the adaptive arguments used to motivate Bayesian
models of cognition (Oaksford & Chater, 2009) need to be
adapted to account for phenomena such as the Zeno effect.

Acknowledgments
EMP and JMY were supported by Leverhulme Trust grant
RPG-2013-00. Further, JMY was supported by an NSF grant
SES-1556415 and EMP was supported by Air Force Office
of Scientific Research (AFOSR), Air Force Material Command, USAF, grants FA 8655-13-1-3044. The U.S Government is authorized to reproduce and distribute reprints for
Governmental purpose notwithstanding any copyright notation thereon.

References
Anand, P. (1993). Foundations of Rational Choice under
Risk. Oxford: OUP.
Anastopoulos, C. and Savvidou, N. (2006). Time-of-arrival
probabilities and quantum measurements. J. Math.
Phys. 47, 122106.
Busemeyer, J. R. & Bruza, P. (2011). Quantum models of
cognition and decision. CUP: Cambridge, UK.
Jarosz, AF and Wiley, J (2014). What are the odds? A practical guide to computing and reporting Bayes factors.
Journal of Problem Solving, 7, 2-9.
Misra, B. & Sudarshan, E.C.G. (1977). The Zeno’s paradox
in quantum theory. Journal of Mathematical Physics,
18, 756-763.
Oaksford, M. & Chater, N. (2009). Prcis of Bayesian rationality: the probabilistic approach to human reasoning.
Behavioral and Brain Sciences, 32, 69-120.
Pothos, E.M. & Busemeyer, J.R. (2013). Can quantum probability provide a new direction for cognitive modeling?
Behavioral & Brain Sciences, 36, 255-327.
Schwarz, N. (2007). Attitude construction: Evaluation in context. Social Cognition, 25, 638-656.
Tetlock, P.E. (1983). Accountability and the Perseverance of
First Impressions. Soc. Psych. Quarterly, 46, 285-292.
Trueblood, J. S. & Busemeyer, J. R. (2011). A comparison
of the belief-adjustment model and the quantum inference model as explanations of order effects in human
inference. Cognitive Science, 35, 1518-1552.
Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heuristics and biases. Science, 185, 1124-1131.
White, L. C., Pothos, E. M., & Busemeyer, J. R. (2014).
Sometimes it does hurt to ask: the constructive role of
articulating impressions. Cognition 133, 48.
Yearsley JM & Pothos EM (2016). Zeno’s paradox in decision making. Proc. R. Soc. B, 283, 20160291.

2344

