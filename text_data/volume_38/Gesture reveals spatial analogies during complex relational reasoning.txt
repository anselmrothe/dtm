              Gesture reveals spatial analogies during complex relational reasoning
                                            Kensy Cooperrider (kensy@uchicago.edu)
                                         Department of Psychology, 5848 S. University Avenue
                                                          Chicago, IL 60637 USA
                                          Dedre Gentner (gentner@northwestern.edu)
                                            Department of Psychology, 2029 Sheridan Road
                                                         Evanston, IL 60208 USA
                                           Susan Goldin-Meadow (sgm@uchicago.edu)
                                         Department of Psychology, 5848 S. University Avenue
                                                          Chicago, IL 60637 USA
                              Abstract                                  the representations that people form as they develop such
   How do people think about complex relational phenomena
                                                                        abilities. What are these representations like and how do
   like the behavior of the stock market? Here we hypothesize           they differ from people’s representations of other kinds of
   that people reason about such phenomena in part by creating          systems?
   spatial analogies, and we explore this possibility by                  Possible clues may come from research on how people
   examining people’s spontaneous gestures. Participants read a         understand systems more generally. Much previous research
   written lesson describing positive and negative feedback             has investigated how people understand mechanical
   systems and then explained the key differences between them.         processes with multiple causal components, such as sets of
   Though the lesson was highly abstract and free of concrete
   imagery, participants produced spatial gestures in abundance         gears and pulleys. A major finding of this line of work is
   during their explanations. These spatial gestures, despite           that people often develop mental models of the system that
   being fundamentally abstract, showed clear regularities and          are visuospatial in nature (Hegarty, 2004). One line of
   often built off of each other to form larger spatial models of       evidence for the visuospatial character of these models is
   relational structure—that is, spatial analogies. Importantly,        that when reasoning about such systems, people often
   the spatial richness and systematicity revealed in participants’     produce diagrams (Forbus, Usher, Lovett, & Wetzel, 2011;
   gestures was largely divorced from spatial language. These
                                                                        Novick, 2001; Tversky, 2011) or gestures (e.g. Schwarz &
   results provide evidence for the spontaneous use of spatial
   analogy during complex relational reasoning.                         Black, 1996; Nathan & Martinez, 2015). Based on such
                                                                        observations, it seems plausible that people develop mental
   Keywords: analogy; relational reasoning; gesture; complex            models of other types of complex systems, such as the
   systems; spatial cognition
                                                                        causal patterns under consideration here. However, there is
                                                                        a crucial difference between mechanical systems and
                          Introduction                                  positive and negative feedback systems. Positive feedback
Ecosystems in flux. Seesawing financial markets. Shifting               and negative feedback are consummate abstractions. They
climate patterns. What these diverse phenomena have in                  are relational patterns that may sometimes be instantiated in
common is that they are all examples of complex relational              mechanical or concretely spatial systems—e.g. a flush valve
systems: they involve multiple causal factors that change               toilet is an example of a negative feedback system—but
over time and bring about changes to other factors in the               their relational essence transcends any one concrete
system. Such systems underlie phenomena throughout the                  instantiation. It might thus seem unhelpful, or even
natural and social world, in all domains and at all scales.             counterproductive, to recruit visuospatial reasoning
Yet, despite the ubiquity and importance of these systems,              processes when thinking about such pure abstractions.
much remains to be learned about the cognitive processes                  At the same time, a separate line of research has
involved in understanding them.                                         investigated how people recruit space when talking and
   Current evidence suggests that complex relational                    thinking about purely abstract ideas. This tendency can be
reasoning presents challenges even for adults. For example,             seen in everyday language, for instance in the spatial words
undergraduates have considerable difficulty detecting                   and grammatical structures people draw on to talk about
higher-order causal patterns such as positive feedback and              time (e.g. Clark, 1973; Traugott, 1978), or in the extension
negative feedback, the focus of the present paper (Rottman,             of spatial prepositions to describe abstract relations of other
Gentner, & Goldwater, 2012). Expertise in identifying such              kinds (Jamrozik & Gentner, 2015). In fact, evidence has
patterns does develop, either through exposure to the same              now accumulated that this is not just a linguistic
patterns across a range of domains (Rottman, Gentner, &                 phenomenon—people use spatial representations when
Goldwater, 2012) or through a scaffolded process of                     reasoning online about abstract concepts, whether or not
comparing examples (Goldwater & Gentner, 2015). An                      language is involved (Boroditsky, 2001; Casasanto &
interesting open question, however, concerns the nature of              Bottini, 2014). One clear source of evidence for the use of
                                                                    692

space in abstract reasoning comes from the gestures people           previously by Rottman, Gentner, & Goldwater (2012) and
produce (Cienki, 1998). To date, the best-studied cases of           Goldwater & Gentner (2015). In this type of sorting task,
abstract spatial gesture have involved relationally simple           participants are given a set of vignettes printed on index
concepts, such as the representation of a temporal sequence          cards and are asked to sort them into categories. Each
as a line (Cooperrider, Núnez, & Sweetser, 2014).                    vignette is an example of one of several types of causal
Nonetheless, such findings raise the intriguing possibility          systems (e.g. positive feedback) instantiated in one of
that people might create more complex spatial structures in          several domains (e.g. economics). Participants are also
gesture to represent more complex relational structures.             given seed cards—vignettes just like those that need to be
  The above observations lead us to the following                    sorted but which serve as anchors for the categories to be
hypothesis about how people reason about complex                     used. A key feature of the task is that the seed cards leave
relational patterns like positive and negative feedback: they        the relevant categories open to interpretation: a participant
may do so, at least in part, by creating abstract spatial            may categorize the vignettes according to the type of causal
models of the relational structures involved—that is, spatial        system described or, more superficially, by the domain in
analogies. Furthermore, if this hypothesis is correct, then          which that system is couched. In the adaptation of the AST
gesture should provide a powerful window onto this                   used here, participants were presented with three seed cards:
phenomenon. Gesture is well suited to the expression of              a first unlabeled card describing the phenomenon of stock
spatial ideas (Alibali, 2005), and it has been shown to reveal       market bubbles (a positive feedback system), a second
implicit aspects of understanding that people have difficulty        unlabeled card describing predator-prey relationships (a
verbalizing (Goldin-Meadow, 2003; Broaders, Cook,                    negative feedback system), and a third card simply labeled
Mitchell, & Goldin-Meadow, 2007). Moreover, the spatial              ‘other.’ Participants were then given 11 new vignettes and
information revealed in people’s abstract gestures often goes        were given 5 minutes to sort them.
beyond what is found in the language co-produced with                   After the sorting was complete, the experimenter removed
those gestures (Cienki, 1998).                                       the materials and prompted the participant to explain the
  In the present study, we explore this spatial analogy              main difference between the different categories involved in
hypothesis by having people read a lesson contrasting two            the sorting task. This phase is the pre-lesson explanation.
types of complex relational patterns—positive and negative           Together the sorting task and the pre-lesson explanation
feedback—and then explain the key differences between                serve to familiarize participants with causal systems, which
them. The most interesting possibility is that gesture might         they will go on to learn more about and explain.
reveal spatial analogies—that is, systematic spatial models             Next, participants were given a one-page written lesson
of relational patterns that are not inherently spatial. We also      (‘Causal Systems Lesson’) explaining the differences
considered other possible outcomes, however. For one,                between positive and negative feedback systems (though
people might not spatialize much of anything in their                without using those labels). The lesson was grounded in the
explanations. After all, gesture is thought to stem from vivid       seed cards used in the sorting task. It explained how the
visuospatial or motoric imagery (e.g. Hostetter & Alibali,           stock market vignette exemplifies one type of causal system
2008), which our lesson lacks. Another possibility is that           and how the predator-prey vignette exemplifies a different
people might spatialize in gesture, but in a piecemeal               type. The lesson also moved beyond the particular
fashion. That is, they may occasionally produce abstract             examples, characterizing in more abstract terms how each
spatial gestures (e.g. an upward gesture when describing             type of system involves different relationships between
“increasing”) but these gestures will not cohere into a larger       causal factors. Importantly, the lesson used no concrete
model.                                                               spatial imagery and very little spatial language. Participants
                                                                     were instructed to study it for 3 minutes and were told that
                           Methods                                   they would later be asked to explain it to another participant.
                                                                        When the 3 minutes were up, the experimenter removed
Participants                                                         the lesson and brought in the other participant (who was
23 adults from the University of Chicago community                   actually a confederate). The experimenter then prompted the
participated for course credit or cash. Four participants were       participant as follows: “Please explain the lesson you just
excluded from the analyses: three because their gestures             read. Go into as much detail as possible, but focus on the
were largely occluded on the video; one for producing no             differences between the two types of causal systems.” The
gestures at all. In all, data from 19 participants (10 female;       instructions made no mention of gesture. This phase is the
mean age = 20.8 years) are reported in the analyses.                 post-lesson explanation, and it is the focus of our analyses.
Materials and procedure                                              Analysis
                                                                     Participants’ performance on the sorting task was analyzed
After giving consent to participate and to be videotaped,
                                                                     but is not discussed in the present report. Videos of
participants carried out a series of activities that served both
                                                                     participants’ pre- and post-lesson explanations were
to familiarize them with causal systems and to assess their
                                                                     transcribed and analyzed using ELAN video annotation
understanding of them. First, participants completed an
                                                                     software (https://tla.mpi.nl/tools/tla-tools/elan/). The gesture
adaptation of the Ambiguous Sorting Task (AST) used
                                                                 693

 Figure 1: Examples of the different gesture types, taken from two participants’ explanations. Factor reference gestures
 (A, E) represent the factors as locations in space, depicted by the yellow circles. Factor change gestures (B,F) represent
 increases and decreases as movements, depicted by the straight yellow arrows. Causal relation gestures (C,G) represent
 causation as movement, depicted by the curved arrows. Whole system gestures (D, H) represent the behavior of the system
 as a whole and often involve multiple movement phases, as depicted by the multiple arrows.
analyses reported here focus on participants’ post-lesson
explanations.                                                                                  Results
   A first step in the analysis was to identify all gestures in
the explanations that were “representational” (e.g. Chu et          Gesture rates and types
al., 2013). Representational gestures depict some property          Participants produced a mean of 24.12 (SD=4.39)
of a referent (commonly called “iconic” or “metaphoric”             representational gestures per minute speaking. The abstract,
gestures), or point to a referent’s location (commonly called       textual nature of the Causal Systems Lesson thus did not
“deictic” gestures). In the present data, the representational      stand in the way of eliciting representational gestures.
gestures were abstract in nature—that is, they used location,          Based on pilot studies involving similar materials, a
movement, and spatial arrangement to depict ideas that              system was developed for categorizing the recurring ways
themselves had no concrete location, did not actually move,         people gesture to represent elements of feedback systems.
and had no visible spatial properties. Once representational        First, people locate the factors (e.g. the predator and prey
gestures were identified, they were then categorized into           populations in the negative feedback example) by placing
gesture types (see below). Reliability was assessed by              their gestures in space or by pointing to locations. These we
having a second coder categorize the representational               call factor reference gestures (see Fig. 1). Second, people
gestures in 5 randomly selected explanations (26% of the            represent changes to the factors (e.g. an increase in the
data). The coders agreed 83% (N=220) of the time in                 predator population) as movements. These we call factor
whether a gesture fit into the categorization system (i.e.          change gestures. Third, people represent causal relations in
belonged to one of the four categories). For those gestures         the system (e.g. how the change in the predator population
that both coders agreed fit into the system, they assigned the      causes a change in the prey population) as movements,
gesture to the same category in 85% (N=142) of cases.               sometimes between previously established locations. These
Finally, we analyzed the gestures’ spatial properties and           we call causal relation gestures. Fourth, people use
relationships to other gestures in the same explanation, as         movements to characterize the behavior of the system as a
well as the language that was co-produced with them. Each           whole (e.g. the equilibrium that is reached in the predator-
of these analyses is described in more detail as the results        prey system). These we call whole system gestures. The
are presented.                                                      majority (71%) of participants’ representational gestures fell
                                                                    into one of the above four types. However, not all
                                                                    participants produced all four gesture types: 19 (100%)
                                                                    produced factor reference gestures, 18 (95%) produced
                                                                694

factor change gestures, 13 (68%) produced causal relation           established locations of the two factors, the gesture would
gestures, and 9 (47%) produced whole system gestures.               be considered model-integrated (see Fig. 1, panel C).
                                                                    Alternatively, if the gesture represented causation as a
Spatial properties                                                  movement in neutral space, it would not be considered
Spatial axes We next analyzed the spatial characteristics of        model-integrated. Note that factor reference gestures, which
people’s gestures, considering each gesture type separately.        serve to establish such locations in the first place, cannot be
96% of factor reference gestures located the factors on the         model-integrated and are excluded from the analysis.
left-right axis, most often with the first-mentioned factor on      Further, we did not expect whole system gestures, which
the left and the second-mentioned factor on the right. Factor       depict a high-level summary of the whole system, to be
change gestures were more variable, with 21% depicting              closely integrated with the detailed causal patterns depicted
increases and decreases as movements along the left-right           in the other gestures. Overall, 50% of participants’ factor
axis, 29% along the front-back axis, 26% along the up-down          change gestures were model-integrated, as were 72% of
axis, and the rest involving either some combination of             their causal relation gestures. 84% of participants produced
these axes or a more complex movement. Causal relation              at least one model-integrated factor change gesture, and
gestures most commonly (75%) depicted causation as                  47% produced at least one model-integrated causal relation
movement along the left-right axis. Whole system gestures           gesture.
varied considerably across participants in their use of space
and in other qualitative characteristics, but they tended to        Relationship to language
use multiple movement phases (see Fig. 1, panels D and H)           Finally, we analyzed the relationship between participants’
and often involved two hands.                                       gestures and the language with which they were co-
                                                                    produced. Most often, in 93% of cases, the gestures
Spatial consistency We next examined how consistent                 represented aspects of the system that were simultaneously
participants’ gestures were in their spatial properties over        mentioned in speech. For example, a participant would
the course of the explanation. To assess this kind of within-       produce a factor reference gesture while referring in speech
participant consistency, we used a measure developed in the         to “the first factor” or a factor change gesture while
study of spatial grammatical devices in signed languages            mentioning an “increase.” Interestingly, however, gestures
(Senghas & Coppola, 2001). For every gesture, we asked              sometimes filled in where speech left off—especially when
whether it represented a system element (e.g. a particular          characterizing the behavior of the system as a whole. For
factor) for the first time or represented a system element that     example, a speaker describing a positive feedback system
had been previously represented. If the gesture repeated an         said “it’s sort of…” trailing off in speech but providing a
element, we coded whether it used space in the same way             complex spatial characterization in gesture. These cases
(consistent) or a different way (inconsistent) as the               may stem from the difficulty of verbalizing the overall
immediately preceding gesture. For this analysis, we                system dynamics.
focused on factor reference and factor change gestures                 Finally, we investigated how common it was for gestures
because causal relation and whole-system gestures, when             to be co-produced with overtly spatial language. Table 1
they occurred, often only occurred once or twice in an              provides examples of both spatial and non-spatial language
explanation. Overall, participants were highly spatially            that was co-produced with the different gesture types. Note
consistent: the majority of factor reference gestures were
spatially consistent (mean percentage=87%), as were the                 Table 1: Examples of spatial and non-spatial language
majority of factor change gestures (mean percentage=69%).                              co-produced with gestures
Model integration Finally, we analyzed whether
                                                                                       non-spatial                 spatial
participants’ gestures were integrated with a larger spatial
                                                                                        language                 language
model built up over the explanation, or were more
piecemeal in nature. Use of model-integrated gestures
varied across participants. If, for instance, a participant            factor         “first factor”
                                                                                                           “external variable”
produces a gesture representing an increase to a factor that         reference     “certain variable”
incorporates the previously established location of the factor
involved, the gesture would be considered model-integrated.            factor         “increase in”                “rise”
As an example of a model-integrated gesture, a participant            change            “change”                  “go up”
may locate the first factor on the left and then later show an
increase in that factor as an upward movement in left space            causal         “influences”              “rebounds”
(see Fig. 1, panel B). If, on the other hand, the increase was        relation          “causes”              “turns around”
depicted in neutral space or right space, the gesture would
not be considered model-integrated. Similarly, if a                    whole        “self-correcting”        “negative loop”
participant produces a gesture representing a causal relation         system     “regulate each other” “building on each other”
between two factors as a movement between the previously
                                                                695

that words such as “increase” which have a general                  is a purely abstract set of entities and relations—factors,
definition that is not specifically spatial, were not               changes, and causation—that is mapped to a set of spatial
considered spatial. Strikingly, overall, only 17% of the            relations—locations, movements, and movements between
gestures were co-produced with overtly spatial language.            locations. Prior work has demonstrated that people are able
For example, factor reference gestures, though consistently         to understand and reason with spatial analogies of this
exploiting the left-right axis of space, were not once co-          abstract type (Gattis, 2004), but little work to date has
produced with a reference to left or right.                         examined whether the spatial analogies are spontaneously
                                                                    created or recruited on the fly. Informal observations, in
                        Discussion                                  addition to our own data, suggest that spatial analogies may
We investigated the possibility that people would                   constitute a powerful strategy in both cognition and
spontaneously use spatial analogies when reasoning about            communication. The ubiquity of abstract spatial models like
positive and negative feedback, relational patterns that are        Venn diagrams, family trees, and cladograms, for example,
complex, widespread, and fundamentally abstract. As a               hints at the wider utility of spatial analogy in relational
potential window into such hypothesized analogies, we               reasoning, far beyond our chosen test case of positive and
examined the gestures people produced as they tried to              negative feedback patterns (Novick, 1996; Tversky, 2011).
articulate the main characteristics of these patterns and the       Interestingly, the phenomenon of model-integrated gestures
differences between them. Despite the paucity of concrete           we have described also resembles a phenomenon in
spatial imagery or language in the lesson we provided, when         established signed languages sometimes described as
people explained the patterns, they gestured at strikingly          “spatial modulation” (Senghas & Coppola, 2001). In
high rates. These gestures did not represent the actual             American Sign Language, for example, a verb may be said
locations or movements of objects—rather, the gestures              to be “spatially modulated” if it incorporates spatial
used space abstractly to represent the different factors in the     information that was previously established for one or more
system, the changes to those factors, the causal relations          of its arguments. As our data show, hearing gesturers do
between them, and the overall dynamics of the systems               something very similar under the right circumstances (see
being described. Over the course of people’s explanations,          also So, Coppola, Licciardello & Goldin-Meadow, 2005).
the gestures were highly consistent in where they were                 Analogy is often thought of as an effortful process in
placed in space, and they were often integrated into larger         which someone, struggling to capture a new idea, alights on
spatial models that were built up over time. Finally, the           an apt comparison. However, empirical work has shown that
spatial richness we observed in gesture was largely divorced        this formulation is, at least in some cases, misleading:
from spatial language, and sometimes divorced from                  analogical mapping can occur unintentionally, without any
language altogether. In sum, the gestures we observed               effort (Day & Gentner, 2007). We suggest a similar
provided vivid evidence that people draw on spatial                 unintentional deployment of analogy may be at work here.
analogies during complex relational reasoning, evidence that        Participants very rarely referred to their gestures—or to the
would have been scarce in a verbal transcript.                      spatial information contained therein—explicitly (e.g.
   One limitation of the present study is that, although the        “Imagine the system is like this”). Nor did they show signs
lesson was largely devoid of rich imagistic content, it did         of engaging in an effortful process of design and
include a sprinkling of abstractly spatial words. For               development, as might be signaled by restarts or
example, the phrase “opposite direction” was used to                amendments to the spatial structure. Rather, we suggest that
describe the change from increasing to decreasing. It               participants constructed these spatial models fluidly and
remains possible that subjects took these words as cues to          more or less unconsciously as they articulated the relational
build larger spatial models. However, the scarcity of spatial       structure they were describing.
language overall in participants’ explanations makes this              A related issue is whether the abstract gestures we
possibility somewhat doubtful. Nonetheless, further study           observed were helpful to the speaker over and above any
will be needed to determine whether excluding such words            role they may have served in communication. Prior work
would have a significant impact on the extent to which              has shown that gesturing can help speakers by reducing
people create spatial models in gesture.                            cognitive load (Goldin-Meadow, Nusbaum, Kelly, &
   As we have argued, the gestures we observed revealed the         Wagner, 2001). To our knowledge, though, cognitive
spontaneous use of sophisticated spatial analogies—that is,         benefits of this sort have not been shown for abstract spatial
spatial models of relational structure. Spatial analogy is          gestures of the type described here. In fact, if spatial
likely a ubiquitous process in human reasoning. Perhaps the         analogy is an effortful process, as is sometimes assumed,
best-studied examples to date have involved reasoning about         then producing gestures like those documented here would
maps and scale models (e.g. Uttal & Wellman, 1989). In              actually increase cognitive load rather than lightening it.
such cases, a set of concrete spatial relations in the world is     Testing these possibilities is a direction for future work.
mapped in schematic fashion to some spatial representation             Complex relational patterns underlie diverse phenomena
of that world. The analogical mapping is thus between one           across the natural and social worlds. While earlier work has
spatial format and another spatial format. By contrast, in the      demonstrated the difficulties of reasoning about such
spatial analogies under examination here, the base concept          patterns, less is known about the kinds of representations
                                                                696

people bring to bear during such reasoning. Here we provide        Goldin-Meadow, S., Nusbaum, H. C., Kelly, S. D., &
evidence for the role of spontaneous spatial analogy in this         Wagner, S. M. (2001). Explaining math: Gesturing
kind of reasoning, and for gesture as one means of                   lightens the load. Psychological Science, 12, 516–522.
externalizing such analogies. Though we have barely                Goldin-Meadow, S. (2003). Hearing gesture: How our
scratched the surface of this arena, it remains plausible that       hands help us think. Cambridge, MA: Harvard U. Press.
spatial analogies will prove to be a central ingredient in the     Goldwater, M. B., & Gentner, D. (2015). On the acquisition
human ability to understand complex relational phenomena.            of abstract knowledge: Structural alignment and
                                                                     explication in learning causal system categories.
                    Acknowledgments                                  Cognition, 137, 137–153.
Funding for this study was provided by the NSF Spatial             Hegarty, M. (2004). Mechanical reasoning by mental
Intelligence and Learning Center (SBE 0541957, Gentner               simulation. Trends in Cognitive Sciences, 8(6), 280–5.
and Goldin-Meadow are co-PIs) and NICHD (R01-                      Hostetter, A. B., & Alibali, M. W. (2008). Visible
HD47450 to Goldin-Meadow). We thank Ishara Ruffins and               embodiment: Gestures as simulated action. Psychonomic
Erin Richard for research assistance.                                Bulletin & Review, 15(3), 495–514.
                                                                   Jamrozik, A., & Gentner, D. (2015). Well-hidden
                                                                     regularities: Abstract Uses of in and on retain an aspect of
                        References
                                                                     their spatial meaning. Cognitive Science.
Alibali, M. W. (2005). Gesture in Spatial Cognition:               Novick, L. R. (2001). Spatial diagrams: Key instruments in
  Expressing, Communicating, and Thinking About Spatial              the toolbox for thought. In D. L. Medin (Ed.), The
  Information      Information.    Spatial    Cognition     &        psychology of learning and motivation, Vol. 40. San
  Computation, 5(4), 307–331.                                        Diego, CA: Academic Press.
Boroditsky, L. (2001). Does language shape thought?                Nathan, M. J., & Martinez, C. V. J. (2015). Gesture as
  Mandarin and English speakers’ conceptions of time.                model enactment: the role of gesture in mental model
  Cognitive Psychology, 43(1), 1–22.                                 construction and inference making when learning from
Broaders, S. C., Cook, S. W., Mitchell, Z., & Goldin-                text. Learning: Research and Practice, 1(1), 4–37.
  Meadow, S. (2007). Making children gesture brings out            Rottman, B. M., Gentner, D., & Goldwater, M. B. (2012).
  implicit knowledge and leads to learning. Journal of               Causal systems categories: Differences in novice and
  Experimental Psychology: General, 136(4), 539–50.                  expert categorization of causal phenomena. Cognitive
Casasanto, D., & Bottini, R. (2014). Spatial language and            Science, 36(5), 919–32.
  abstract concepts. Wiley Interdisciplinary Reviews:              Schwartz, D. L., & Black, J. B. (1996). Shuttling Between
  Cognitive Science, 5(2), 139–149.                                  Depictive Models and Abstract Rules: Induction and
Chu, M., Meyer, A., Foulkes, L., & Kita, S. (2013).                  Fallback. Cognitive Science, 20(4), 457–497.
  Individual Differences in Frequency and Saliency of              Senghas, A., & Coppola, M. (2001). Children Creating
  Speech-Accompanying Gestures: The Role of Cognitive                Language: How Nicaraguan Sign Language Acquired a
  Abilities and Empathy. Journal of Experimental                     Spatial Grammar. Psychological Science, 12(4), 323–328.
  Psychology. General.                                             So, C., Coppola, M., Licciardello, V., & Goldin-Meadow, S.
Cienki, A. (1998). Metaphoric gestures and some of their             (2005). The seeds of spatial grammar in the manual
  relations to verbal metaphorical expressions. In J.-P.             modality. Cognitive Science, 29, 1029-1043.
  Koenig (Ed.), Discourse and cognition: Bridging the gap.         Traugott, E. C. (1978). On the Expression of Spatio-
  Stanford, California: CSLI.                                        Temporal Relations in Language. In Universals of Human
Clark, H. H. (1973). Space, time, semantics, and the child.          Language. Volume 3: Word Structure. Stanford, CA:
  In T. E. Moore (Ed.), Cognitive development and the                Stanford.
  acquisition of language. New York: Academic Press.               Tversky, B. (2011). Visualizing thought. Topics in
Cooperrider, K., Núñez, R., & Sweetser, E. (2014). The               Cognitive Science, 3(3), 499-535.
  conceptualization of time in gesture. In C. Müller, A.           Uttal, D. H., & Wellman, H. M. (1989). Young children’s
  Cienki, E. Fricke, S. Ladewig, D. McNeill, & J. Bressem            representation of spatial information acquired from maps.
  (Eds.), Body-Language-Communication (vol. 2). New                  Developmental Psychology, 25(1), 128–138.
  York: Mouton de Gruyter.
Day, S. B., & Gentner, D. (2007). Nonintentional analogical
  inference in text comprehension. Memory & Cognition,
  35(1), 39–49.
Forbus, K., Usher, J., Lovett, A., & Wetzel, J.
  (2011). CogSketch: Sketch understanding for Cognitive
  Science Research and for Education. Topics in Cognitive
  Science, 1-19.
Gattis, M. (2004). Mapping relational structure in spatial
  reasoning. Cognitive Science, 28, 589–610.
                                                               697

