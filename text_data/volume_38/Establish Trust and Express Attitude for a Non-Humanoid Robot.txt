                Establish Trust and Express Attitude for a Non-Humanoid Robot
                                                           Mei Si (sim@rpi.edu)
                                    Department of Cognitive Science, Rensselaer Polytechnic Institute
                                                             Troy, NY 12180 USA
                                            Joseph Dean McDaniel (mcdanj2@rpi.edu)
                                   Department of Computer Science, Rensselaer Polytechnic Institute
                                                             Troy, NY 12180 USA
                               Abstract                                  to create a positive experience with trust and comfort. Fur-
                                                                         thermore, we want to have the capacity of creating different
   In recent years, there has been an increasing interest in design-
   ing social robots to interact with people to provide therapy and      “personalities for the robot. Here we do not necessarily need
   companionship. Most social robots currently being used are            to build an active or intriguing character, but rather to present
   light-weight and much smaller in size compared to people. In          meaningful and consistent behavior patterns that the user can
   this work, we investigate designing interactions for larger and
   more physically capable robots as they have more potential to         infer from the robots actions for enhancing the believabil-
   assist people physically. A modified version of Baxter robot          ity of the robot as a human-like character. Breazeal studied
   was used, by sitting Baxter on top of an electronic wheelchair.       the requirements to “promote the illusion of a socially aware
   Two experiments were designed for studying the role of facial
   expressions and body movements in establishing trust with the         robotic creature and found that to socially engage a human,
   user and for expressing attitudes. Our results suggest that the       its behavior must address issues of believability such as con-
   robot is capable of expressing fine and distinguishable attitudes     veying intentionality, promoting empathy, being expressive,
   (proud vs. relaxed) using its body language, and the coupling
   between body movements and speech is essential for the robot          and displaying enough variability to appear unscripted while
   to be viewed as a person.                                             remaining consistent” (Breazeal, 2000). Similar arguments
   Keywords: Robot Human Interaction; Gesture; Trust                     have been given for creating digital companions (Bickmore
                                                                         & Rosalind, 2005), and for assistant robot. It has been found
                           Introduction                                  that even though assistant robot does not need to represent a
In recent years, there has been an increasing interest in de-            social character, having a “personality helps the user to under-
signing social robots to interact with people, as a tutor or             stand and predict its behaviors (Severinson-Eklundh, Kerstin
a companion. For example, Sony’s AIBO robotic dog has                    and Green, Anders and Httenrauch, Helge , 2003).
been used for improving autistic children’s play, reasoning,                Both facial expressions and non-verbal behaviors play im-
and affective skills (François, Powell, & Dautenhahn, 2009).            portant roles in social interactions. In particular, it has been
Autom is a humanoid robot, which is capable of establish-                shown that for human-like robots, showing appropriate non-
ing eye contact with the user and making small talk. It was              verbal behaviors such as gaze, head nod, and gestures can
used for helping people keep track of their weight loss his-             improve people’s performance in a collaborative task because
tory (Kidd & Breazeal, 2008). Nao and Hanson robots have                 people can better understand the robot’s intention (Breazeal,
also been widely used for research, tutoring, and entertain-             Kidd, Thomaz, Hoffman, & Berlin, 2005). Many robots used
ment purposes.                                                           by rescue teams, law enforcement, and the military are de-
   Most social robots currently being used are light-weight              signed with functionality as a higher priority, and thus, they
and much smaller in size compared to people. This makes                  do not appear humanlike and have limited means to support
them naturally look non-threatening. On the other hand, they             natural human-robot interaction. While these robots are often
have limited movability and physical strength, which limits              modified to have a facial display to express affect, researchers
their potential for physically interacting with and assisting            have found that their body movements may play a more im-
people. In this work, we want to investigate designing in-               portant role (Bethel & Murphy, 2008). Our modified Baxter
teractions for robots, which are larger and more physically              robot belongs partially to this category. We face the challenge
capable. We start this exploration using a modified version              of the robot not having an exact human-like shape. Because
of Baxter, a dual-arm robot by Rethink Robotics. The robot               of the robot’s physical strength and size, potential negative
by itself is 3’1” (93.98 cm) in height. With modification, the           misinterpretations of the robot’s intentions will become par-
robot sits on top of an electronic wheelchair. Its actual height         ticularly problematic.
is similar to an adult sitting on a chair. The robot’s arm can              In this work, we designed two experiments for studying
reach 41” (104 cm). Its body looks sturdy, with a weight of              the expression of attitudes using the robot’s body movements.
165 lbs (75 kg).                                                         In the first experiment, we examined how using human-
   To enable long-term natural interaction between robots                informed gestures and social dialogue, and having a digital
and users, we strive to not only rely on safe, dependable                face can make people feel more comfortable to interact with
robotic movements but also leverage existing research study-             the robot. In the second experiment, we further investigated
ing human-computer interaction and human social interaction              expressing two different attitudes relaxed and proud using
                                                                     860

                                                                         Guided by research in proxemics (Hall et al., 1968), we po-
                                                                      sitioned the participants within the social zone of Baxter, be-
                                                                      tween 4’ and 12’ away: specifically, 9’ (2.7 m) away. When
                                                                      the participants approached Baxter to shake hands, they left
                                                                      the social zone and entered the intimate zone. For safety rea-
                                                                      sons, the experimenter was in the same room during the in-
                                                                      teraction.
                                                                         Two control groups were used: one in which participants
                                                                      saw no arm movement during the routine (No Gestures, N =
                                                                      9) and one in which participants saw arbitrary arm move-
           Figure 1: Baxter with Virtual Human Face                   ments at the start of the routine, not tied to any particular be-
                                                                      havior or gesture (Arbitrary Gestures, N = 8). Neither control
                                                                      group saw a virtual face on Baxter. The first control group is
the robot’s body movements.                                           a baseline to compare against all other groups that add a form
                                                                      of gesture to the routine. The second control group is used
                        Experiment 1                                  to determine whether any arm movement elicits the same re-
In this experiment, we examined how placing Baxter’s move-            sponse as arm movements that are performed to couple with
ments into a social context with its dialogue affects people’s        the dialogue.
perceptions of its safety and friendliness. We studied the im-           Two experimental groups were used: one in which partic-
portance of having meaningful gestures and a face display. In         ipants saw meaningful gestures without a face (Meaningful
particular, it is natural that people feel more comfortable in-       Gestures, N = 13), and one in which participants saw mean-
teracting with a novel device after seeing how it operates or         ingful gestures accompanied by a virtual human face (Mean-
moves. To study whether there is a difference between this            ingful Gestures with Face, N = 13).
phenomenon and the effect of viewing the robot as a person,              We adopted a between-group design, and the participants
we designed an experimental condition in which the robot’s            were randomly assigned to one of four different groups. For
arm movements are not coupled with its speech and compared            dependent variables, we measured a categorical dependent
the participants’ responses in this condition against other con-      variable, “hesitation,” which represents how much the par-
ditions.                                                              ticipant hesitated before approaching Baxter when prompted
                                                                      to shake hands. A score of “low” was given to the partici-
Experiment Design and Subjects                                        pants who waited less than one second to approach Baxter. A
Forty-three undergraduate students from Rensselaer Poly-              score of “medium” was given to the participants who waited
technic Institute were recruited to participate. Their partic-        between one and two seconds, and a score of “high” was
ipation was compensated by giving course credits. The in-             given when the participants waited more than two seconds
dependent variable is the way the robot interacted with the           or looked to the experimenter for clarification that they could
participants, which has four conditions.                              approach Baxter if needed. This measurement was taken by
    Common to all the conditions, we designed an interaction          the experimenter.
routine in which the robot talked about the research projects            For the participants’ subjective reports about the robot,
it is involved with and its various capabilities. Baxter’s intro-     we used three dependent variables. During the interaction,
ductory statements consisted of fifteen sentences. Baxter then        one of the questions asked by Baxter was how friendly it
asked the participants ten questions about his/her personal in-       was (“friendliness”). After the interaction, all participants
terests, e.g. what kind of music do they like (to which they          responded to two additional questions asked by the experi-
replied verbally on 7-point Likert scales) and commented on           menter during the debriefing phase: how comfortable would
the participants’ responses after all questions had been an-          the participant be interacting with Baxter at a close distance
swered. The interaction with each participant lasted approx-          (“comfortability closeness”), and how comfortable would the
imately five minutes. Afterward, Baxter prompted the par-             participant be letting Baxter touch them with one of its arms
ticipant to approach it and shake its right hand but assured          (“comfortability touch”). Similar to answering Baxter’s ques-
the participant that he/she could decline to shake hands if           tions, the participants answered these two questions using a
he/she felt uncomfortable doing so. Then as the participant           7-point Likert scale.
approached, Baxter extended its arm towards him/her. Be-
fore this gesture, the participant had not physically touched         Implementation
or been touched by the robot. Therefore, though extending             Figure 2 shows the system architect we used to create the
one’s arm towards the other person is natural for handshakes,         Baxter “character” in this experiment. The robot’s gestures
it could be perceived as an unexpected event from the robot.          were created manually to complement each line of the dia-
We expected the participants to feel less apprehension – mea-         logue, informed by human nonverbal behaviors, in particu-
sured by how much hesitation they had to continue the hand-           lar, McNeill’s work on hand gestures (McNeill, 1992). Bax-
shake – if they treated the robot like another person.                ter uses deictic gestures such as pointing to the participant
                                                                  861

                                                                                Figure 3: Hesitation before Handshake
                   Figure 2: System Architect
or pointing to the general gesture space. Baxter uses iconic
gestures when talking about activities. For instance, Baxter
asks the participants, ”To what extent do you enjoy work-
ing on pieces of art, or writing?” and moves its left hand in
small circles as if it is writing on imaginary paper. It uses
metaphoric gestures when discussing concepts like creating          Figure 4: Mean Ratings of “Comfortability Closeness”,
and expanding by bringing its hands together and then mov-          “Comfortability Touch”, and “Friendliness”
ing them apart. Finally, beat gestures are used with greetings
and exclamations to punctuate Baxter’s emotional intent.
   We recorded Baxter’s arm movements using ROS “Robot                 Of the standardized residual values, shown in Table 1, the
Operating System” and Robot Raconteur, a communication              differences were significant at the 0.05 level between the
library for robotic systems (Wason & Wen, 2011). A ROS              “Meaningful Gestures” condition and “No Gestures” and “Ar-
service records the joint positions of Baxter’s arms as we          bitrary Gestures” conditions for participants in the low and
manually manipulate the positions of the arms. We then sys-         medium hesitation categories. Overall, participants in the
tematically reduced the recording files down to keyframes to        “Meaningful Gestures” condition hesitated least in approach-
reduce any jittery movement, and stored the result of inter-        ing Baxter, and participants in the control groups “No Ges-
polating joint positions between key frames to be used for          tures” and “Arbitrary Gestures” hesitated more. A compari-
driving the robot’s movements during the interaction.               son of hesitation measures of all conditions is shown in Fig-
   In the condition which included a virtual face on Baxter’s       ure 3.
display screen, we utilized the Virtual Human Toolkit (VHT)            One-way analysis of variance(ANOVA) tests were con-
(Hartholt et al., 2013). We used the face of a female charac-       ducted to evaluate the differences between all groups on three
ter named Rachel, shown on Baxter as in Figure 1. During            ordinal measures: comfortability interacting with Baxter at
the interaction, Rachel’s facial expressions remained mostly        a close distance (“comfortability closeness”), comfortability
neutral. Rachel’s voice was generated using Text-to-Speech.         letting Baxter use its arm to touch the participant (“comforta-
   We created a custom Windows Forms application written            bility touch”), and how friendly the robot seemed during the
in C#/.NET as a driver for VHuman and Baxter during the             routine (“friendliness”). A summary of the ANOVA tests can
interaction. It sent arm movement, speech, and facial ex-           be found in Table 2, and the mean scores for each condition
pression commands to their respective destinations for each         in all measures can be seen in Figure 4.
segment of the routine. This system also allowed the exper-            There was a significant difference among groups on how
imenters to utilize a “Wizard of Oz -style approach. When           comfortable the participants would be interacting with Baxter
the participants were asked questions by Baxter, the exper-         at a close distance after having seen the routine, F(3, 39) =
imenters could enter their answers into the application for         3.154, p < 0.05. Post hoc comparisons using the Fisher LSD
Baxter to comment on later in the routine.                          test indicated that the mean score for the “No Gestures”
                                                                    group (M = 4.67, SD = 1.12) was significantly lower than
Results                                                             the “Meaningful Gestures” group (M = 5.77, SD = 1.09),
A chi-square test of independence was conducted to examine          p < 0.05. The mean score for the “Meaningful Gestures”
the relation between the experiment condition and amount of         group was significantly higher than the “Meaningful Gestures
time that participants hesitated before approaching Baxter to       with Face” group (M = 4.38, SD = 1.33), p < 0.01.
shake hands. The test showed a significant relationship be-            Groups differed significantly with how comfortable the
tween which version of the routine participants observed and        participants would be letting Baxter touch them with one of
their amount of hesitation to approach Baxter, X 2 (6) = 15.46,     its arms after having seen the routine, F(3, 39) = 3.865, p <
p = 0.02. No participants declined to shake hands with Bax-         0.05. Post hoc comparisons using Fisher LSD indicated that
ter, but they differed significantly in the amount of time to       the mean score for the “Meaningful Gestures” group (M =
approach Baxter after the request.                                  5.46, SD = 0.88) differed significantly from the “No Ges-
                                                                862

                                                                       Finally, the participants rated Baxter as being friendlier
Table 1: Standardized Residual Values of Participants Hesi-
                                                                    when they saw meaningful gestures instead of arbitrary ges-
tation in Experiment 1
                                                                    tures or when the virtual face was not present. There are many
                                    Low Medium High
                                                                    possible explanations for this result. The digital human like
   No Gestures                       -1.5         1.8    -0.4
                                                                    face might introduce the uncanny valley effect. Moreover, be-
   Arbitrary Gestures                -1.3         1.0     0.6       cause the rest of the robot’s body is not human like, the par-
   Meaningful Gestures                1.4        -0.9    -0.8       ticipants might experience a disconnection between the face
   Meaningful Gestures w. Face        0.9        -1.4     0.6       and the body. Combining with the fact that displaying the
                                                                    virtual face did not help reduce the participants’ hesitations
                                                                    to approach Baxter, this result suggests that we should use
           Table 2: ANOVA Tests for Experiment 1
                                                                    caution when using a 3D realistic virtual face for this robot.
     Measure                      df MS       F       p
     comfortability closeness 3        4.54 3.15      .035
     comfortability touch         3    4.51 3.86      .017                                 Experiment 2
     friendliness                 3    4.45 3.74      .019
                                                                    This experiment evaluates whether people can differentiate
                                                                    and appropriately label the robot’s attitudes based on the
tures” group (M = 4.22, SD = 0.67), p = 0.01, and from the          robot’s body movements. Unlike in Experiment 1, we utilized
“Arbitrary Gestures” group (M = 4.00, SD = 0.76), p < 0.01.         the software CrazyTalk Animator by Reallusion to create the
   The final ANOVA test revealed a significant difference           facial animations. An original face was drawn as a boxy, out-
among groups with how friendly participants perceived Bax-          lined appearance that is much less realistic than the human
ter to be, F(3, 39) = 3.742, p < 0.05. Post hoc compar-             face in Experiment 1.
isons using Fisher LSD indicated that the mean score for the
“No Gestures” group (M = 5.67, SD = 1.00) was significantly         Experiment Design and Subjects
higher than the “Meaningful Gestures with Face” group (M =
4.69, SD = 1.18), p < 0.05. Additionally, the mean score for        We modeled two routines for Baxter: a Proud routine (sterner
the “Meaningful Gestures” group (M = 5.85, SD = 1.07) was           and more bragging) and a Relaxed routine (more relaxing
significantly higher than the mean scores for both the “Arbi-       and soothing). We picked these two attitudes because they
trary Gestures” group (M = 4.63, SD = 1.06), p < 0.05, and          are likely to be useful in health care, and educational do-
the “Meaningful Gestures with Face” group, p = 0.01.                mains. Moreover, the difference between these two attitudes
                                                                    is subtler than more commonly perceived emotions like hap-
Discussion                                                          piness or anger, and therefore, the success of this experiment
                                                                    will provide us more confidence in using the modified Baxter
In this study, the participants were more likely to approach
                                                                    robot to express emotions and attitudes in the future. Similar
Baxter without hesitation when they witnessed gestural arm
                                                                    to Experiment 1, in these routines, Baxter talked about stu-
movement beforehand, with or without the addition of a vir-
                                                                    dent life on campus and the many things that the university
tual human face on Baxter’s display screen. Introducing ir-
                                                                    offers.
relevant, arbitrary arm movement in the second control group
demonstrated either no impact (when comparing to the first             Twenty-four undergraduate students were recruited to par-
control group) or a negative impact (when compared to the           ticipate. This time, we used a within-group design. The par-
two experiment groups) on the participants’ hesitations, sug-       ticipants observed the dual-arm Baxter robot equipped with
gesting that meaningful arm movement was key in reducing            a cartoonish face discuss a topic twice, using different non-
the participants’ hesitations. This confirms our hypothesis         verbal behaviors in each routine. Each participant saw both
that gestures associated with a social context are most effec-      routines in random order. Each routine lasted approximately
tive in increasing people’s trust and feeling of comfort in in-     one and a half minutes. Baxter’s speech was controlled to be
teracting with the robot. We want to point out that the pos-        similar between routines, with the main differences being the
itive impact of accompanying speech with meaningful ges-            displayed nonverbal behavior and facial expressions.
tures took place after just a few minutes of interaction. This         For each routine, the participants need to pick the most ap-
provides strong evidence for the benefit of embodying a robot       propriate emotion/attitude label from a list. HUMAINE Emo-
as a social character.                                              tion Annotation and Representation Language (EARL) con-
   Although the “Arbitrary Gestures” group reported a mean          solidates emotion labels into ten categories (Schröder, Pirker,
score for “comfortability closeness” similar to the experimen-      & Lamolle, 2006). Pride and Relaxed belong to the “Posi-
tal groups, this behavior negatively impacted ratings of how        tive Thoughts” and “Quiet Positive” categories respectively.
likely participants would be to let Baxter make physical con-       We also picked one relevant label from each other categories.
tact with them. Participants in both control groups reported        The ten options for the participants are anger, fear, relaxation,
lower scores for “comfortability touch” than participants in        frustration, sadness, shock, happiness, affection, pride, and
the “Meaningful Gestures” group.                                    surprise.
                                                                863

                                                                         The test showed a significant difference for which emo-
                                                                     tions were chosen for each routine based on the Pearson Chi-
                                                                     Square value, X 2 (7) = 22.80, p = 0.002. Of the standardized
                                                                     residual values, the differences were significant at the 0.05
                                                                     level among the three labels – pride, affection, and anger.
                                                                     Pride accounted for the largest amount of difference in the
                                                                     distribution, with affection second and anger third.
                                                                         Figure 6 shows the distribution of chosen emotions for
                                                                     each routine among the twenty-four participants. The par-
       Figure 5: Baxter with CrazyTalk Cartoonish Face               ticipants mostly matched the Proud routine to the intended
                                                                     proud emotion at 41.70% (10 participants), with happiness
                                                                     second at 20.80% (5 participants) and anger coming in third
                                                                     at 16.70% (4 participants). For the Relaxed routine, partic-
                                                                     ipants mostly matched the routine to both happiness and af-
                                                                     fection at 29.20% (7 participants) each, with relaxation and
                                                                     sadness at 16.70% (4 participants) each.
                                                                     Discussion
                                                                     The spread of participant labels for Baxter’s emotional intent
          Figure 6: Emotion Labels for Each Routine                  was more even for the Relaxed routine than for the Proud
                                                                     routine. In the Proud routine, the gestures were firmer and
                                                                     more aggressive and were more tightly coupled with precise
Implementation                                                       moments in the dialogue, which may have contributed to this
As in Experiment 1, we recorded Baxter’s arm movements us-           result. In post-experiment interviews, many participants re-
ing ROS and Robot Raconteur (Wason & Wen, 2011). When                ported that Baxter spoke about itself and the university with
modeling pride, we want the robot to seem highly aroused             high praise and that the audience should agree with Baxter’s
and actively engaging the participant during most of the rou-        comments – as opposed to the perceived inclusive, friendly
tine (Ekman & Friesen, 1967). Therefore, in the Proud rou-           tone of the Relaxed routine. Also, being relaxed can often be
tine, gestures using Baxter’s arms were more focused toward          a secondary element of another perceived primary emotion
the observing human participant. For example, during the             such as joy (Ekman & Friesen, 1967). Relaxed and calmness
initial introduction, Baxter says, “Hello, I am Baxter, one of       is conveyed through slow, flowing movements, often associ-
the amazing robots in the robotics department, raises its right      ated with voice tone in ratio to the face and body (Ekman
arm, and pats its torso in a highly precise, confident manner.       & Friesen, 1967, 1969). Pride, on the other hand, can be
In contrast, the Relaxed routine was associated with positiv-        displayed more readily through use of nonverbal behavior.
ity (Ekman & Friesen, 1967). Movements for the Relaxed               Therefore, the relaxed attitude may have been too vague to be
routine included sweeping the arms in slow arcs and keeping          successfully identified. In our previous work using a Turtle-
the hands rotated inwardly toward Baxter’s body, with more           Bot, we have observed that the noise made by the robot when
frequent pauses and less overall movement than the Proud             it is moving can intensify the expression of negative and high
routine. For example, the initial greeting includes a small,         dominance emotions such as anger, and affect the expression
tentative wave of the hand.                                          of low dominance emotions such as shyness (Barron & Si,
   Similarly as in Experiment 1, we identified keyframes for         2013). Though the participants did not specifically comment
each recorded file and interpolated the joint positions for cre-     on the noise as a factor affecting their impressions about the
ating smoother animations. Figure 5 shows Baxter with one            robot, we suspect the noise played a similar role in this study,
of the faces from CrazyTalk. This face has limited capac-            i.e. lead some participants to believe the robot was angry.
ity of expressing emotions with subtle differences. Also, we             We also observed an interesting ordering effect. The par-
wanted to prevent the participants from forming their judg-          ticipants were more likely to see a greater contrast when they
ments mainly based on the robot’s face. Therefore, the facial        saw the Relaxed routine first and then labeled the Proud rou-
expressions remained mostly neutral for both routines. We            tine with a negative emotion. Feedback from these partici-
used a male Text-to-Speech voice for the robot.                      pants mentioned that Baxter seemed less friendly in the sec-
                                                                     ond routine. Labels applied to the Relaxed routine were more
Results                                                              consistent regardless of the ordering of the routines.
A chi-square test of independence was performed to examine               Another interacting observation was that several partici-
the relation between the designed routine and the attitude as-       pants mentioned hearing a change in the voice inflection be-
sociated with it by participants. The labels shock and surprise      tween the two routines even though we used the same Text-to-
were not chosen by participants for either routine, so we do         Speech engine. Though not exactly the same as the McGurk
not include them in the results.                                     effect, this also demonstrates what people see can affect what
                                                                 864

they hear, even in such a brief and simple social interaction          C: Applications and Reviews, IEEE Transactions on, 38(1),
scenario.                                                              83–92.
                                                                     Bickmore, T., & Rosalind, J. (2005). Establishing and main-
            Conclusions and Future Work                                taining long-term human-computer relationships. ACM
In this work, we examined the effects of designing meaning-            Transactions on Computer-Human Interaction (TOCHI),
ful arm movements for a modified version of Baxter robot.              12(2), 293-327.
Our results suggest that it is feasible to create a social char-     Breazeal, C. (2000). Sociable machines: Expressive social
acter using this robot even though it does not have an ex-             exchange between humans and robots. Unpublished doc-
act human-like shape. We demonstrated that designing body              toral dissertation, Massachusetts Institute of Technology.
movements that are timely coupled with the robot’s speech            Breazeal, C., Kidd, C. D., Thomaz, A. L., Hoffman, G., &
makes people more likely to trust the robot and feel comfort-          Berlin, M. (2005). Effects of nonverbal communication
able in its presence comparing to demonstrating the robot’s            on efficiency and robustness in human-robot teamwork.
arm movements independently from its speech or not demon-              In Intelligent robots and systems, 2005.(iros 2005). 2005
strating how the robot movements at all. Moreover, this dif-           ieee/rsj international conference on (pp. 708–713).
ference takes place in just a few minutes. Finally, the Baxter       Cassell, J., Gill, A., & Tepper, P. (2007). Coordination in
robot can use body language in a similar way as humans for             conversation and rapport. In Proceedings of the workshop
expressing distinguishable attitudes, more specifically, being         on embodied language processing (p. 41-50).
either proud or relaxed. However, its proud manner has the           Ekman, P., & Friesen, W. V. (1967). Head and body cues in
danger of being misinterpreted as anger, and its relaxed atti-         the judgment of emotion: A reformulation. Perceptual and
tude is very easily confused with other positive emotions such         motor skills, 24(3), 711–724.
as happy and affection.                                              Ekman, P., & Friesen, W. V. (1969). The repertoire of nonver-
   Future work would further examine how using meaning-                bal behavior: Categories, origins, usage, and coding. Semi-
ful arm and face movements to express emotional intent af-             otica, 1(1), 49–98.
fects people’s willingness to approach and interact with Bax-        François, D., Powell, S., & Dautenhahn, K. (2009). A long-
ter in close proximity and over a longer period. Right now             term study of children with autism playing with a robotic
the robots body movements are planned independently from               pet: Taking inspirations from non-directive play therapy to
the participants. In real life, when two conversational part-          encourage children’s proactivity and initiative-taking. In-
ners have established rapport, their body movements are of-            teraction Studies, 10(3), 324–373.
ten coupled (Cassell, Gill, & Tepper, 2007). For example, one        Hall, E. T., Birdwhistell, R. L., Bock, B., Bohannan, P.,
will often nod when the other pauses in his/her speech. One            Diebold Jr, A. R., Durbin, M., . . . Vayda, A. P. (1968).
of our future directions is to enable such interactions for the        Proxemics [and comments and replies]. Current anthro-
robot. Secondly, we want to observe how people’s attitudes             pology, 83–108.
toward the robot change over longer terms of interaction, and        Hartholt, A., Traum, D., Marsella, S. C., Shapiro, A., Stratou,
at moments when the robot makes a seemingly threatening                G., Leuski, A., . . . Gratch, J. (2013). All together now. In
action. In the latter case, we want to investigate whether the         Intelligent virtual agents (pp. 368–381).
same techniques people use for recovering trust can be ap-           Kidd, C. D., & Breazeal, C. (2008). Robots at home: Under-
plied to the robot. Finally, compared to digital characters,           standing long-term human-robot interaction. In Intelligent
when working with a physical robot, there is always the addi-          robots and systems, 2008. iros 2008. ieee/rsj international
tional challenge of synchronizing the movements of its vari-           conference on (pp. 3230–3235).
ous parts, such as the two arms, or between the face and the         McNeill, D. (1992). Hand and mind: What gestures reveal
arms. Even with the same set of commands, it is possible               about thought. University of Chicago Press.
the movements become out of sync for a variety of reasons,           Schröder, M., Pirker, H., & Lamolle, M. (2006). First sug-
which may break the image of the robot as a social charac-             gestions for an emotion annotation and representation lan-
ter. We are interested in developing a software framework              guage. In Proceedings of lrec (Vol. 6, pp. 88–92).
for helping with this challenge. When the robots body move-          Severinson-Eklundh, Kerstin and Green, Anders and Htten-
ments are delayed, we can also slightly delay its facial ex-           rauch, Helge . (2003). Social and collaborative aspects of
pressions and speech, or replan for another set of body move-          interaction with a service robot. (Tech. Rep.). Royal Insti-
ments, facial expressions, and speech.                                 tute of Technology (KTH).
                                                                     Wason, J. D., & Wen, J. T. (2011). Robot raconteur: A
                         References                                    communication architecture and library for robotic and au-
Barron, M., & Si, M. (2013). Augment interactive story-                tomation systems. In Automation science and engineering
   telling with cognitive robot. In Proceedings of the 6th dig-        (case), 2011 ieee conference on (pp. 761–766).
   ital games research association (digra) conference.
Bethel, C. L., & Murphy, R. R. (2008). Survey of
   non-facial/non-verbal affective expressions for appearance-
   constrained robots. Systems, Man, and Cybernetics, Part
                                                                 865

