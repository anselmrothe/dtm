                   Do additional features help or harm during category learning?
                 An exploration of the curse of dimensionality in human learners
                                         Wai Keen Vong (waikeen.vong@adelaide.edu.au)
                                Andrew T. Hendrickson (drew.hendrickson@adelaide.edu.au)
                                           Amy Perfors (amy.perfors@adelaide.edu.au)
                                    School of Psychology, University of Adelaide, SA 5005, Australia
                                          Daniel J. Navarro (dan.navarro@unsw.edu.au)
                                          School of Psychology, University of New South Wales
                               Abstract                                  to impair learning (Edgell et al., 1996), to facilitate learning
                                                                         (Hoffman & Murphy, 2006), or to not impact learning at all
   How does the number of features impact category learning?
   One view suggests that additional features creates a “curse of        (Minda & Smith, 2001).
   dimensionality” - where having more features causes the size             How can we resolve this apparent discrepancy? One possi-
   of the search space to grow so quickly that discovering good          bility is that the studies differ in the kinds of categories being
   classification rules becomes increasingly challenging. The op-
   posing view suggests that additional features provide a wealth        learned. After all, the curse of dimensionality stems from
   of additional information which learners should be able to use        having so many possible stimuli configurations in a high di-
   to improve their classification performance. Previous research        mensional space that it is difficult to figure out which features
   exploring this issue appears to have produced conflicting re-
   sults: some find that learning improves with additional features      are the most important ones. This should lead to the greatest
   (Hoffman & Murphy, 2006) while others find that it does not           inefficiency when most of the possible features are not diag-
   (Minda & Smith, 2001; Edgell et al., 1996). Here we inves-            nostic of category membership and only one or a few matter,
   tigate the possibility that category structure may explain this
   apparent discrepancy – that more features are useful in cate-         as in Edgell et al. (1996). By contrast, if all features are di-
   gories with family resemblance structure, but are not (and may        agnostic to some degree – especially if they are not perfectly
   even be harmful) in more rule-based categories. We find while         correlated with each other – then additional features should be
   the impact of having many features does indeed depend on cat-
   egory structure, the results can be explained by a single unified     beneficial, or at least not hurtful (Hoffman & Murphy, 2006;
   model: one that attends to a single feature on any given trial        Minda & Smith, 2001).
   and uses information learned from that particular feature to             This reasoning is sensible, but no studies to date have tested
   make classification judgments.
                                                                         it by manipulating category structure and number of features
   Keywords: Category learning; supervised learning; curse of            while holding other factors constant. The goal of the current
   dimensionality
                                                                         paper is to do this. Our results suggest that people’s ability to
                                                                         evade the curse of dimensionality in natural categories occurs
                           Introduction
                                                                         because of the family resemblance structure of natural cat-
Category learning can become increasingly difficult as the               egories – but that in rule-based categories the curse defeats
number of object features increases. This “curse of di-                  us. We also show that although people’s performance qual-
mensionality” occurs because the learner must in some way                itatively varies depending on the nature of the categories to
search over the large number of features in order to deter-              be learned, it can be accounted for by a single unified model
mine how to weight the importance of each during classifi-               with limited attentional abilities.
cation (Sutton & Barto, 1998). Despite this difficulty, people
– even small children – easily learn natural categories com-                                       Experiment
posed of objects with a very large number of features (Rosch,            Our experimental design involves systematically manipulat-
1973). How do people overcome the curse of dimensionality                ing the number of features and the category structure in a
when they learn high-dimensional categories such as these?               simple categorization task. We were interested in how perfor-
In this paper we present simulations and empirical results that          mance changed with increasing numbers of features, and how
show that susceptibility to the curse depends on what is be-             this depended on the nature of the categories being learned
ing learned: whether the categories involved follow a family-            (family resemblance, intermediate or rule-based). As pre-
resemblance structure or are more rule-based.                            dicted, learning decreased when there were additional fea-
   Category learning experiments have traditionally avoided              tures when category structure was rule-based, but did not
the curse of dimensionality by using stimuli that consist of             when it was more of a family resemblance structure.
only a few highly salient features, generally between two and
four (e.g., Medin & Schaffer, 1978; Minda & Smith, 2001;                 Method
Nosofsky, 1986; Shepard, Hovland, & Jenkins, 1961). Al-                  Participants 442 participants (238 male) were recruited via
though these experiments have substantially contributed to               Amazon Mechanical Turk. Participants ranged in age 19 to
our understanding of category learning, it remains largely an            76 (mean 34.2). They were paid US$2.00 for completion of
open question how learning changes (if at all) when there                the experiment, which took roughly 12 minutes to complete.
are a large number of features. The few studies that have                14 participants failed to complete the task, and 5 participants
investigated this empirically have yielded conflicting results.          had participated in a pilot version of this study; these data
Increasing the number of features has been variously found               were excluded from further analyses.
                                                                     2471

                                                                         theoretically possible to achieve better performance by using
                                                                         all of the features in concert.
                                                                         Procedure The experiment consisted of five blocks of 20
                                                                         learning trials each, for a total of 100 trials. On each trial
                                                                         people were presented with an amoeba2 and were asked to
                                                                         classify it as either a bivimia or a lorifen. They received points
                                                                         both for answering correctly and quickly. To make it more
                                                                         game-like each trial was associated with a countdown bar that
                                                                         decreased in size over time. After responding, feedback was
                                                                         given by displaying the true category label for three seconds.
                                                                         In addition, the circular base of the amoeba lit up with the
                                                                         appropriate category colour (blue for bivimias and purple for
                                                                         lorifens). There was a one second delay after the feedback
                                                                         before the presentation of the next stimulus. At the end of
Figure 1: Six example stimuli, displaying two examples from
                                                                         each block, participants were presented with a short summary
each of the three possible Dimensionality conditions (left: 4,
                                                                         of their performance across each completed block.
middle: 10, right: 16). Features were binary and correspond
to the legs of the amoebas. Together, the two examples from
the 16-FEATURE condition show all possible feature values.
                                                                         Results
                                                                         Before addressing the main question of how learning is influ-
                                                                         enced by Dimensionality and Structure, it important to ver-
Design The task was a supervised category learning exper-                ify that learning in fact took place. As Figure 2 illustrates,
iment in which people learned to classify amoeba as either               participants in all nine conditions showed evidence of learn-
bivimias or lorifens. Each amoeba consisted of a circular base           ing. We evaluate this quantitatively using a Bayesian mixed
with a set of distinct binary features (legs). The full set of 16        effects model with block as a continuous variable, and Di-
unique pairs of features are shown on the two stimuli in the             mensionality and Structure as discrete variables.3 Across all
right column of Figure 1.                                                conditions, accuracy increased during training: the model that
   The nine experimental conditions were created by manip-               included block was strongly preferred over a model that only
ulating two factors (the Dimensionality of the stimuli and the           included a random effect for each participant (BF > 1044 : 1).
category Structure), each with three levels, in a between-
                                                                            How did the number of features and the structure of the cat-
participant design. The three levels of Dimensionality re-
                                                                         egories affect learning? As is evident from Figure 2, learning
flect the number of binary features present on the stimuli (4-
                                                                         was fastest in the FAMILY condition, slowest in the RULE con-
FEATURE , 10- FEATURE , or 16- FEATURE conditions). For the
                                                                         dition, and intermediate in the INTERMEDIATE condition; the
lower-dimensionality conditions, the set of displayed features
                                                                         corresponding main effect of Structure yielded a Bayes factor
chosen were randomly selected from a subset of the features
                                                                         of more than 700:1 in favor of a difference. It is also evident
used in the 16-FEATURE condition. The position of features
                                                                         that performance was affected by the number of features, with
on the amoeba and the mapping from feature values to cate-
                                                                         the main effect of Dimensionality yielding BF > 47 : 1.
gory labels were randomized differently for each participant.
   The three category Structures defined the relationship be-               The main effects are sensible, but the main prediction was
tween feature values and category labels. For all three struc-           that we expected the effect of Dimensionality to be different
tures, one dimension was 90% predictive of the correct cat-              for different Structures. Was such an interaction observed?
egory label (meaning that on 90% of trials, categorizing ac-             Figure 2 suggests there was one, with performance decreas-
cording to that dimension would lead to a correct label). The            ing with additional features in the INTERMEDIATE and RULE
different category structures were defined by the diagnostic-            conditions, but not in the FAMILY conditions. Supporting this,
ity of the other features in the category. In one condition, the         a Bayesian mixed effects model containing block, structure,
other features were 50% predictive of the category label;1 we            dimensionality and the interaction between structure and di-
call this the RULE condition because maximum performance                 mensionality was strongly preferred over a model without the
can be achieved by finding the one highly-diagnostic feature             interaction term (BF > 103 : 1). Overall, these results suggest
and ignoring all of the rest. In another condition, all of the           that high dimensionality is only a curse as categories grow
features were 90% predictive of the category label (though               more rule-based; if they are not, the high informativeness of
all were generated independently, so none were perfectly cor-            every feature renders the search problem less of an issue.
related with each other). We called this the FAMILY condi-
tion because this imposes a family resemblance structure with                2 The stimuli for each person was generated randomly according
many highly coherent and predictive features. Finally, in the            to the appropriate category structure, rather than pre-generating 100
INTERMEDIATE condition the other features were 70% diag-                 specific stimuli and showing the same ones to everybody.
                                                                             3 All mixed effects models in this paper assume a random in-
nostic: thus, one feature was most diagnostic but it would be            tercept for each subject. Bayes factors were calculated using the
                                                                         BayesFactor package 0.9.12-2 (Morey & Rouder, 2015) in R 3.2.3.
    1 Since there were two categories, this means they were not pre-     Because it is typical to obtain a range of possible factors within a
dictive at all.                                                          confidence interval, for simplicity we report the approximate factor.
                                                                     2472

                                                                                                           Category Structure
                         Number of Features                                     Family                           Intermediate                      Rule
                                                                                                          1 feature 90% predictive      1 feature 90% predictive
                                   4 Features                  4 features all 90% predictive
                                                                                                          3 features 70% predictive     3 features 50% predictive
                                                                                                          1 feature 90% predictive      1 feature 90% predictive
                                   10 Features                10 features all 90% predictive
                                                                                                          9 features 70% predictive     9 features 50% predictive
                                                                                                         1 feature 90% predictive      1 feature 90% predictive
                                   16 Features                16 features all 90% predictive
                                                                                                         15 features 70% predictive    15 features 50% predictive
Table 1: The nine different conditions tested in the experiment. For all of the Intermediate and Rule conditions where only 1
feature was 90% predictive, this 1 feature was chosen at random.
                                    Family            Intermediate                      Rule              dimensionality of the stimulus and each xi is a binary feature
                        1.0                                                                               (xi ∈ {0, 1}). The predicted category response (ŷ ∈ {0, 1})
                                                                                                          for the nth trial is defined by the feature information from the
                                   ●    ●●
                                             ●   ●●                                                       nth trial along with the representation learned by the model
                                   ●         ●    ●
   Proportion correct
                                        ●
                                             ●                                                            based on the previous N − 1 trials. The two learning models
                        0.8 ●       ●
                               ●                                            ●                      ●
                                                                                                          we consider differ according to the representation they learn
                                                               ●                             ●
                                                                    ●                                     from experience.
                              ●                                             ●            ●
                                                          ●     ●       ●
                                                                                    ●
                                                          ●     ●
                                                      ●
                                                      ●                 ●
                                                                            ●
                                                                                ●
                                                                                                   ●      Naive Bayes
                        0.6                               ●                                    ●
                                                      ●                             ●    ●         ●
                                                                                         ●     ●          The first model we consider is the Naive Bayes classifier,
                                                                                ●   ●
                                                                                ●                         which uses information about every feature to determine cat-
                                                                                                          egory predictions. The model tracks the diagnosticity of each
                        0.4                                                                               feature (p(xi |y)) across all previous trials to compute an esti-
                               1    2   3    4   5    1   2     3       4   5   1   2    3     4   5      mated probability of each category label (y) for a given stim-
                                                              Block
                                                                                                          ulus (x). The model assumes each of these features are in-
                                             Dimensionality         ●   4 ● 10 ● 16                       dependently diagnostic of the category label and combined
                                                                                                          as in Equation 1. The predicted category response (ŷ) of the
Figure 2: Mean human performance across the three Dimen-                                                  model on each trial is the category with the highest estimated
sionality and Structure conditions. While learning within the                                             probability (Equation 2).
FAMILY -resemblance categories was unaffected by the num-
ber of features, more features meant that learning was poorer                                                                           D
in the RULE-based and INTERMEDIATE categories. Error bars                                                                    p(y|x) ∝ ∏ p(xi |y)p(y)                   (1)
reflect 95% confidence intervals, and the dotted line reflects                                                                         i=1
chance performance.                                                                                                                ŷ = arg max p(y|x)                 (2)
                                                                                                                                             y
                                                                                                          Hypothesis Testing
                              Two models of human performance                                             The second model is a Hypothesis Testing model which as-
The intuitive reasoning motivating this experiment was based                                              sumes that categories are defined by a single binary fea-
on the insight that if people approach category learning by                                               ture. On each trial, the model maintains a single hypothe-
searching among all possible features, then the curse of di-                                              sis hia that consists of a simple rule for determining the pre-
mensionality should hurt performance only when one or few                                                 dicted category response. All rules in the hypothesis space
features are useful (as in rule-based categories) but not if most                                         share the same format: if xi = a then ŷ = 0, otherwise
or all of them are (as in family-resemblance categories). The                                             ŷ = 1. The space of hypotheses is defined by a, indicating a
empirical results support our predictions, but another impor-                                             particular feature value (a ∈ 0, 1), and the feature xi where:
tant test is whether a search-based model qualitatively repro-                                            (i ∈ {1, . . . , D}). As an example, a particular hypothesis the
duces human performance while a model that uses all of the                                                model might use is: “If the third feature dimension is 0 (i.e.
information from all features does not. In this section we im-                                            x3 = 0), then respond ŷ = 0, otherwise respond ŷ = 1.”
plement such a test by modeling people’s behavior with two                                                   The probability of staying with the current hypothesis after
different learning models. Both models were simulated on                                                  each trial is given by the utility u of the current hypothesis.
nine conditions that exactly paralleled the conditions in the                                             The utility is proportional to prediction accuracy for previous
experiment, with three levels of dimensionality (4, 10, and                                               trials on which it was the current hypothesis; it is equal to 1
16) and the same three category structures (FAMILY, INTER -                                               for those hypotheses that have never been the current hypoth-
MEDIATE and RULE -based).                                                                                 esis (Equation 3). On trials in which the current hypothesis is
   The structure and notation of the learning environment is                                              discarded, a new hypothesis is selected from the set of all pos-
identical for both models. The input for each trial is a D-                                               sible hypotheses. New hypotheses are selected in proportion
dimensional stimuli vector x = (x1 , x2 , . . . , xD ), where D is the                                    to their utility, as in Equation 4.
                                                                                                       2473

                                  Family            Intermediate                Rule                 additional features does exist for Naive Bayes, because when
                      1.0         ●   ●   ●     ●                                                    all information is used, information from enough additional
                            ●
                                  ●   ●         ●       ●   ●   ●   ●       ●    ●     ●   ●         features can improve performance even above the 90% possi-
                                  ●   ●   ●
                                          ●     ●
                      0.8 ●                         ●
                                                            ●       ●   ●              ●   ●         ble from any single one.
                                                            ●   ●
                                                                ●   ●            ●              4
                                                        ●                   ●    ●     ●   ●
                                                    ●                   ●                               The models have similar qualitative outcomes in the RULE
                      0.6
                                                                                                     condition, doing worse with additional features. In the Hy-
 Proportion correct
                      0.4                                                                            pothesis Testing model this occurs because of the increased
                      1.0 ● ● ● ● ●
                                                        ●   ●   ●   ●                                difficulty in finding the most useful feature. Naive Bayes
                                                    ●                            ●     ●   ●
                              ● ● ●
                                  ●                                         ●
                      0.8 ● ●
                            ●                                                                        shows a very small performance decrement with more fea-
                            ●
                                                        ●
                                                            ●
                                                            ●
                                                                ●
                                                                ●
                                                                    ●
                                                                    ●
                                                                        ●                       10   tures because it does not set the feature weights of the unpre-
                                                    ●                                      ●
                      0.6                           ●                       ●    ●
                                                                                 ●     ●   ●
                                                                        ●
                                                                        ●
                                                                                                     dictive features to precisely zero; this effect, however, is tiny
                      0.4                                                                            and also diminishes with time.
                      1.0 ● ● ● ● ●                     ●   ●   ●   ●                                   That said, the models make qualitatively different predic-
                                      ●   ●     ●   ●                                  ●   ●
                      0.8 ●
                                  ●
                                  ●   ●   ●     ●                           ●
                                                                                 ●                   tions in the INTERMEDIATE category structure: Naive Bayes
                          ●
                                                                        ●                       16   predicts that additional features should improve prediction
                                                        ●   ●
                                                            ●   ●   ●
                                                                    ●
                      0.6                           ●   ●
                                                                            ●    ●
                                                                                 ●     ●   ●
                                                                                           ●         accuracy while the Hypothesis Testing model predicts the op-
                                                                        ●   ●
                                                                                                     posite. This qualitative difference emerges because of the
                      0.4
                            1     2   3     4   5   1   2   3   4   5   1   2    3     4   5         utility of the less-predictive features in each model. The
                                                        Block                                        Naive Bayes model combines the information from the ad-
                            ●   Human ● Hypothesis Testing ● Naive Bayes                             ditional less-predictive features with the more-predictive fea-
                                                                                                     ture to make judgments in the INTERMEDIATE condition. As
                                                                                                     a result, it makes better judgments where there are more fea-
Figure 3: Predicted performance from the Hypothesis Test-                                            tures. By contrast, because the Hypothesis Testing model
ing and Naive Bayes models across the nine conditions. Each                                          only uses one feature, it does not improve category predic-
data point is the average of 10,000 simulations. Naive Bayes                                         tion by adding additional feature information. In fact, as the
systematically overestimates performance, while the Hypoth-                                          number of less-useful features grows, the less likely it is for
esis Testing model provides a much better fit. However, it                                           the model to switch to the hypothesis containing the most pre-
fails to capture more subtle aspects of human performance,                                           dictive feature; its performance therefore worsens.
like the gradual learning curves.                                                                       Overall, the Hypothesis Testing model captures human per-
                                                                                                     formance much better than Naive Bayes, especially as the
                                                                                                     structure of the categories become more rule-based. How-
                                                                                                     ever, the Hypothesis Testing model fails to capture some of
                                          1 + (correct predictions with hia )                        the more subtle qualitative effects found in the human data.
                                u(hia ) =                                                      (3)   Most interestingly, the Hypothesis Testing model shows a
                                                 1 + (trials with hia )
                                                                                                     sharp increase in prediction accuracy after the first block of
                                            u(hia )                                                  training but does not continue to improve prediction accuracy
                                p(hia ) =                                                      (4)
                                          ∑x,y u(hxy )                                               beyond the second block. This results in a systematic under-
                                                                                                     estimation of prediction accuracy in the final block across all
Simulations                                                                                          conditions. These patterns suggest that people might be using
                                                                                                     information about more than one feature when making deci-
Both models were run 10,000 times in each of the experi-
                                                                                                     sions or shifting between rules. In the following section we
mental conditions. Each simulation mimicked one 100-trial
                                                                                                     introduce a new model to try to account for these effects.
experiment. On each trial a new stimulus was generated as
in the experiment, the model made predictions, feedback was
                                                                                                            A hybrid model of category learning
provided, and the models were updated.
   Figure 3 shows the average prediction accuracy of the two                                         Both the Hypothesis Testing and Naive Bayes models fail to
models and the human data, broken down into subplots for                                             capture all of the qualitative trends in human performance. In
each of the nine learning environments. The most striking                                            this section we propose a hybrid model framework that com-
finding is that Naive Bayes systematically overestimates hu-                                         bines elements from both previous models. Like the Naive
man performance, especially for rule-based categories. This                                          Bayes model it represents categories by assigning each fea-
qualitative effect is mirrored in the root-mean-squared error                                        ture a diagnosticity value and assumes that features are inde-
of each model with the Naive Bayes model producing much                                              pendent, but it learns in a much more limited way: on any
larger overall error (0.226) than the Hypothesis Testing model                                       given trial it updates the diagnosticity only for a single fea-
(0.033). That said, both models capture many of the qualita-                                         ture. The mechanism in the Hybrid model for determining
tive patterns in the human data, including the advantage for                                         which feature weight to update follows the same switching
learning the FAMILY category structure relative to the RULE                                          rule as the Hypothesis Testing model (Equation 4).
structure. In the FAMILY condition, both find very little effect                                        We also consider two variants of the model, corresponding
of increasing feature dimensionality because all of the fea-                                         to two different ways to incorporate feature information when
tures are equally very predictive. A small positive effect of                                        making decisions about category membership. Both versions
                                                                                                 2474

                                Family            Intermediate                Rule                additional features were less predictive than the best ones, as
                      1.0                    ●
                                                                                                  in rule-based or intermediate categories. This effect was cap-
                                ●   ●    ●
                            ●
                                ●   ●
                                    ●    ●
                                         ●   ●
                                                          ●   ●   ●
                                                                               ●     ●   ●        tured best by models that attend to single features for learn-
                      0.8   ●                         ●       ●   ●
                            ●                         ●   ●
                                                          ●       ●       ●              ●        ing and prediction, rather than models that attended to or up-
                                                              ●                ●
                                                                               ●     ●
                                                  ●   ●                   ●
                                                                          ●                  4
                                                  ●                   ●
                                                                      ●                           dated all features at once. These constraints are consistent
                      0.6
                                                                                                  with known limitations on working memory and attention in
 Proportion correct
                      0.4                                                                         humans (e.g., Atkinson & Shiffrin, 1968).
                      1.0                ●   ●
                                ●   ●                                                                The critical role of category structure and feature diagnos-
                                ●   ●    ●
                                         ●   ●
                                             ●                    ●
                            ●       ●                     ●   ●
                      0.8       ●                     ●                                           ticity may explain the existing disagreements in the litera-
                            ●                                                            ●
                            ●
                                                  ●   ●
                                                          ●   ●
                                                              ●   ●            ●     ●       10   ture concerning the impact of feature dimensionality on cate-
                                                  ●                       ●    ●     ●   ●
                      0.6                         ●                       ●    ●     ●
                                                                      ●
                                                                      ●
                                                                      ●
                                                                                                  gory learning. Edgell et al. (1996) used a category structure
                      0.4                                                                         in which additional features were not diagnostic of category
                      1.0                ●   ●                                                    membership and found that increasing the number of feature
                                ●   ●
                                    ●    ●
                                         ●   ●
                                             ●
                            ●   ●   ●
                                                          ●   ●   ●                               dimensions decreases category learning accuracy. We repli-
                      0.8   ●                         ●
                            ●
                                                                  ●                          16   cated this effect in our rule-based category structure, and both
                                                  ●       ●   ●   ●                  ●   ●
                                                      ●       ●                ●
                      0.6                         ●   ●                   ●
                                                                          ●    ●     ●
                                                                                     ●   ●        the Hypothesis Testing and 1-Hybrid model captured it. They
                                                                      ●
                                                                      ●   ●    ●
                                                                                                  do so because in them, increasing the number of less-useful
                      0.4
                            1   2   3    4   5    1   2   3   4   5   1   2    3     4   5        dimensions increases the chance of switching to a less useful
                                                      Block                                       hypothesis and thus making a poor prediction.
                                    ●   Human ● 1−Hybrid ● Full Hybrid                               In contrast, Hoffman and Murphy (2006), who used a cat-
                                                                                                  egory structure in which the new features were predictive
                                                                                                  of category membership, found that increasing the number
Figure 4: Predicted performance of the 1-Hybrid and Full-                                         of feature dimensions actually improved accuracy. Finally,
Hybrid models, compared against the human data across the                                         Minda and Smith (2001) found no effect of number of fea-
nine conditions. Each data point is the average of 10,000 sim-                                    tures in a similar category structure. Performance in our fam-
ulations. The 1-Hybrid model captures performance better                                          ily resemblance condition replicated the results of Minda and
than all of the other models considered.                                                          Smith (2001), showing no improvement in learning (but also
                                                                                                  no decrement) with additional features in a family resem-
                                                                                                  blance structure.5 This is captured by the Hypothesis Testing
implement the same decision rule as the Naive Bayes model                                         and 1-Hybrid models because learning about any feature is
(Equation 2), but differ in terms of how many features they in-                                   equally useful, so switching does not hurt performance.
clude. The Full Hybrid model, like Naive Bayes, incorporates                                         The 1-Hybrid model accounts for the empirical data bet-
information from all of the features; by contrast, the 1-Hybrid                                   ter than the other three models. The Naive Bayes and Full
model incorporates information only from the current feature                                      Hybrid models use a decision rule that produces performance
when determining the category assignment.4                                                        that is much more accurate than human performance across
   As Figure 4 shows, both Hybrid models produce learning                                         all conditions, suggesting the humans do not make decisions
curves whose shape closely matches that of human perfor-                                          based on information from all of the features. (Other aug-
mance. However, the 1-Hybrid model captures the overall                                           mentations of the models are possible as well, e.g., using a
level and magnitude of performance much better than the Full                                      probabilistic choice rule instead of a maximizing strategy, but
Hybrid model; indeed, of all of the models we considered, it                                      it is unlikely that this would change this qualitative aspect
has the tightest quantitative fits to human data (RMS = 0.026,                                    of performance). The 1-Hybrid model slightly outperforms
vs 0.033 for Hypothesis Testing and 0.107 for Full Hybrid).                                       the Hypothesis Testing model because it produces accuracy
The poor performance of both the Full Hybrid and Naive                                            curves that continue to improve over time, while the Hypoth-
Bayes models suggests that human learners probably do not                                         esis Testing model underestimates improvement after the sec-
make decisions based on combining information from all fea-                                       ond block. This gradual improvement throughout training
tures. The improved performance of 1-Hybrid over the pure                                         seems to be due to an advantage from maintaining a represen-
Hypothesis Testing model, however, suggests that people do                                        tations of the diagnosticity of previous feature hypotheses. In
maintain information about the diagnosticity of all features,                                     future work we will investigate this issue more precisely.
even if only one feature is used to make category judgments                                          Another interesting future direction of research is to com-
at any given time.                                                                                pare the 1-Hybrid model to other learning mechanisms that
                                                                                                  have been proposed to address the curse of dimensionality.
                                                 Discussion                                       These methods have focused on reducing the number of di-
This paper demonstrates that the effect of additional features                                    mensions via manifold learning (Tenenbaum, 1998) or struc-
on category learning depends a great deal on the category                                         tured inference (Kemp & Tenenbaum, 2009; Tenenbaum,
structure, as reflected by the diagnosticity of the additional                                    Kemp, Griffiths, & Goodman, 2011; Lake, Salakhutdinov,
features. We found that more features hurt learning when the
                                                                                                      5 Our results probably did not replicate Hoffman and Murphy
                4 We also considered versions that included information from two                  (2006), because, like Minda and Smith (2001) but not it, our ad-
to four features, but do not include these results for space reasons.                             ditional features were not perfectly correlated with existing features.
                                                                                              2475

& Tenenbaum, 2015), rather than preserving the true dimen-             and stimulus complexity. Journal of Experimental Psychol-
sionality of the stimuli but limiting the learning mechanism           ogy: Learning, Memory, and Cognition, 27(3), 775.
by focusing on a reduced set of features on each trial. We can       Morey, R. D., & Rouder, J. N. (2015). BayesFactor:
compare our models to such methods in the kinds of learn-              Computation of Bayes Factors for Common De-
ing environments explored in this paper, as well as those that         signs [Computer software manual].           Retrieved from
they have already been shown to successfully account for. It           http://CRAN.R-project.org/package=BayesFactor
is, of course, possible that human learning is versatile enough        (R package version 0.9.12-2)
to incorporate the fundamental insights from both types of           Nosofsky, R. M. (1986). Attention, similarity, and the
models, and apply each appropriately where it is called for.           identification–categorization relationship. Journal of Ex-
This is all a matter for future work.                                  perimental Psychology: General, 115(1), 39.
   Overall, this research suggests that the “curse of dimen-         Rosch, E. H. (1973). Natural categories. Cognitive psychol-
sionality” negatively impacts category learning mainly in en-          ogy, 4(3), 328–350.
vironments in which a single (or a few) features are predictive      Shepard, R. N., Hovland, C. I., & Jenkins, H. M. (1961).
of the category, but there are many features that are not. Envi-       Learning and memorization of classifications. Psychologi-
ronments that contain many features, in which all or most of           cal Monographs: General and Applied, 75(13), 1.
them are diagnostic of category membership, do not appear to         Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning:
harm performance. People’s behavior can be explained by a              An introduction (Vol. 1) (No. 1). MIT press Cambridge.
computational model that attends to and updates a single fea-        Tenenbaum, J. B. (1998). Mapping a manifold of perceptual
ture at a time, shifting between features based on diagnostic-         observations. Advances in Neural Information Processing
ity; by contrast, models that integrate information from many          Systems, 682–688.
features or models that do not learn feature weights at all do       Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
more poorly. These results suggest that in the real world, peo-        N. D. (2011). How to grow a mind: Statistics, structure,
ple may be able to overcome the “curse of dimensionality”              and abstraction. Science, 331(6022), 1279–1285.
not because we are optimal learners, but rather because the
structure of most natural categories is more similar to family
resemblance structures in which most features are predictive
of category membership.
                     Acknowledgments
AP was supported by grants from the Australian Research
Council (DP110104949 and DP150103280, with salary sup-
port from DE12010378). The salary of AH was supported by
DP110104949.
                          References
Atkinson, R. C., & Shiffrin, R. M. (1968). Human memory:
   A proposed system and its control processes. The Psychol-
   ogy of Learning and Motivation, 2, 89–195.
Edgell, S. E., Castellan Jr, N. J., Roe, R. M., Barnes, J. M.,
   Ng, P. C., Bright, R. D., & Ford, L. A. (1996). Irrele-
   vant information in probabilistic categorization. Journal of
   Experimental Psychology: Learning, Memory, and Cogni-
   tion, 22(6), 1463.
Hoffman, A. B., & Murphy, G. L. (2006). Category dimen-
   sionality and feature knowledge: When more features are
   learned as easily as fewer. Journal of Experimental Psy-
   chology: Learning, Memory, and Cognition, 32(2), 301.
Kemp, C., & Tenenbaum, J. B. (2009). Structured statisti-
   cal models of inductive reasoning. Psychological Review,
   116(1), 20.
Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015).
   Human-level concept learning through probabilistic pro-
   gram induction. Science, 350(6266), 1332–1338.
Medin, D. L., & Schaffer, M. M. (1978). Context theory of
   classification learning. Psychological review, 85(3), 207.
Minda, J. P., & Smith, J. D. (2001). Prototypes in category
   learning: the effects of category size, category structure,
                                                                 2476

