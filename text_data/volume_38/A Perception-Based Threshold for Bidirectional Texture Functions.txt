               A Perception-Based Threshold for Bidirectional Texture Functions
                                      Banafsheh Azari (banafsheh.azari@uni-weimar.de)
           CogVis/MMC, Faculty of Media, Bauhaus-Universität Weimar, Bauhausstraße 11, 99423 Weimar, Germany
                                             Sven Bertel (sven.bertel@uni-weimar.de)
     Usability Research Group, Faculty of Media, Bauhaus-Universität Weimar, Bauhausstraße 11, 99423 Weimar, Germany
                                 Charles A. Wuethrich (charles.wuethrich@uni-weimar.de)
           CogVis/MMC, Faculty of Media, Bauhaus-Universität Weimar, Bauhausstraße 11, 99423 Weimar, Germany
                              Abstract
    For creating photorealistic images, Computer Graphics re-
    searchers introduced Bidirectional Texture Functions (BTFs),
    which use view- and illumination-dependent textures for ren-
    dering. BTFs require massive storage, and several proposals
    were made on how to compress them, but very few take into
    account human perception. We present and discuss an exper-
    imental study on how decreasing the texture resolution influ-
    ences perceived quality of the rendered images. In a visual
    comparison task, observer quality judgments and gaze data
    were collected and analysed to determine the optimal down-
    sampling of BTF data without significant loss of their per-
    ceived visual quality.
    Keywords: Perceived image quality; realistic rendering;
    threshold in image perception; eye tracking.
                           Introduction
One of the main aims of Computer Graphics is the simulation
of the complex reflection behaviour of real world materials.
Among different types of materials, particular importance is
given to fabrics. Graphical simulations of fabrics are used not
only in interior design and architecture, but also increasingly
in the clothing, car, film, and computer gaming industries.
    Fabrics possess highly complex reflection behaviour, as re-       Figure 1: Above: Meso- and micro-structures of a woollen
flection of the incoming light changes dramatically from ma-          fabric. Below: An example of the stimuli used in our study.
terial to material, depending, among other factors, on meso-
and micro-structures of the thread, an example of which is
shown in Figure 1, on the type of weaving, which influences              In practical use, BTFs rely on large collections of digitally
the position of the thread in the fabric, on the interreflections     acquired pictures of a material (e.g., of a woollen fabric) that
between the components of the fabric, and on surface and              were taken for ranges of discretely varied illumination and
subsurface scattering of light. Fabrics exhibit not only sim-         viewing angles. When a simulation of the material needs to
ple reflection characteristics, such as diffuse and specular re-      be computed to texturise a virtual object’s surface, viewer and
flection, but are characterised also by thread-dependent high-        illuminant vectors are used to pick the matching pictures from
lights and self shadowing, as well as anisotropic reflection.         this collection. The texture of an object then results from an
    To exactly simulate the correct reflection behaviour of fab-      interpolation of these (Nicodemus et al. (1977)).
rics, the paths of light within and on the surface of the mate-          A severe disadvantage of BTFs lies in the sheer size of pic-
rial would have to be computed. Given the number of indi-             ture collections needed, as they contain one photograph for
vidual components of a thread, such task is computationally           each combination of viewing and illumination angles. The
not feasible. Bidirectional Texture Functions (BTFs; Dana et          disadvantage is particular acute for the purposes of real time
al. (1999)) represent an alternative solution to this problem.        rendering, as the entire collection of pictures needs to be kept
A BTF contains reflectance information of points on a sur-            in the computer memory. Various past projects have therefore
face under fixed lighting and viewing conditions. It involves         focussed on efficient compression methods for BTFs (includ-
a function which depends on coordinates in texture space (x p ,       ing reflectance models based on linear factorization and pix-
y p ) on the surface of a simulated object, as well as the spher-     elwise bidirectional reflection distribution functions, in short
ical angles of a vector from the viewer to the surface (θo , φo )     BRDFs, which are the general reflection model from which
and a vector to the illuminant (θi , φi ).                            BTFs are derived, Filip and Haindl (2009)).
                                                                  462

   While the existing approaches are often technically well              Few of the existing approaches include an investigation of
motivated, we believe that, before starting to choose how and         viewers’ gaze behavior while viewing the rendered images. A
how strongly to compress BTF data, it makes sense to first            notable exception is the work by Filip et al. (2009) in which
take a step back and see how the human observer perceives             location, duration, and frequency of fixations were recorded.
and judges compressed and non-compressed BTF textures in              Fixation data was used to analyze strategies of the subjects
comparison tasks. Specifically, we look at BTF-based syn-             over the course of the experiment (e.g., did locations and du-
thetic renderings of three–dimensional objects and ask: when          rations of fixations change as the study progressed? Both
does using high-resolution textures make sense because the            were found to be the case.).
high resolution leads to a perceived increase in texture qual-           In short, previous work focussed on the influence of light,
ity? And when can one do just as well with lower resolution           viewing, material reflectance, shape, and angular sampling
textures without perceived loss in quality? In this contribu-         density of BTF data. In this contribution, we investigate the
tion, we present and discuss an investigation aimed at locat-         influence on perceived image quality that the size of the indi-
ing a robust threshold for downsampling BTF images without            vidual BTF texture pictures has, based on which a synthetic
loosing perceptual quality. Information about the location of         object’s texture is interpolated. This variable has not been ad-
such a threshold is not only of importance to a better under-         dressed previously. Our aim is to find a threshold for down-
standing of visual perception of textures, especially in ob-          sampling BTF resolution — that is, for reducing the image
ject comparison tasks, but also of importance for developing          size of the individual BTF textures — without any perceived
novel data compression methods in synthetic rendering.                degradation in the quality of the rendered image. Similar to
   In the next section, we will review relevant related work.         the procedure by Filip et al., we will collect gaze data to aid
We will then describe our method of experimentation, which            the detection of visual strategy and its change.
involves quality comparison tasks with pairs of texturized
objects of varying BTF quality levels and varying exposure                                           Method
times. Gaze data was collected to aid visual comparison strat-        In a pilot study using different self shadowing fabrics, like
egy detection. The presentation of study results is then fol-         corduroy and wool, available in the BTF database of the Uni-
lowed by a discussion, conclusions, and an outlook.                   versity Bonn1 we established that there are no differences in
                                                                      gaze behavior or perceived quality jugments between fabrics.
                       Previous work                                  We therefore decided to here focus on the corduroy dataset,
                                                                      which we will refer to as Cord-256, as its texture pictures are
Compression methods for BTF data have been studied for
                                                                      256x256 pixels.
many years in order to accelerate rendering and to compress
                                                                         We then generated two new datasets by downscaling the
data. However, only rarely the focus was on the perceived
                                                                      Cord-256 set through bilinear interpolation to respective res-
quality of the results of compression. Fleming et al. (2003)
                                                                      olutions of 128x128 pixels (Cord-128) and 64x64 pixels
studied how humans perceive reflections on surfaces, while
                                                                      (Cord-64). For each of the three texture data sets, a three-
Lawson et al. (2003) demonstrated the importance of view
                                                                      dimensional textured model of a sofa was rendered through
changes in synthetic picture matching tasks. te Pas and Pont
                                                                      the standard BTF rendering method at a screen resolution of
(2005a) showed that differences in the microstructure of a
                                                                      1920x1084 pixels (compare Figure 1, below). The sofa model
material are hard to distinguish from differences in the illumi-
                                                                      was oriented for display to the viewer to present textured parts
nation, and that light source direction estimation depends on
                                                                      across a large range of picture depth.
the material’s bidirectional reflection distribution functions or
                                                                         We chose a sofa object model for three main reasons: first,
BDRFs (te Pas and Pont (2005b)).
                                                                      to present an everyday object that viewers are familiar with
   Work by Pellacini et al. (2000) introduced a new light re-
                                                                      and instantly recognize. Second, to have an object with a
flection model for image synthesis based on experimental
                                                                      structured surface and composition (e.g., individual buttons,
studies of surface gloss perception. Two experiments were
                                                                      cushions, etc.). This is important in order to ensure that
conducted to explore the relationships between the physi-
                                                                      a large set of fitting BTF pictures will be selected as basis
cal parameters used to describe the reflectance properties of
                                                                      for the object’s texture, with widely varying illumination and
glossy surfaces and perceptual dimensions of glossy appear-
                                                                      viewing angles. And, third, a sofa is a type of object for which
ance. Psychophysical tests by Mcmillan et al. (2003) showed
                                                                      a cord texture would be commonly found.
consistent transitions in perceived properties between inter-
polate and extrapolate BRDFs in the space of acquisition.             Stimulus Pairs
   The accurate reproduction of material structures that can          Pairs of the rendered images displayed in full screen, native
be achieved by using measured BTFs was investigated in                resolution mode were used as experimental stimuli. Each pair
Meseth et al. (2006), while Filip et al. (2008) performed a           consisted of a sequentially presented rendering using two of
psychophysical study to optimize sparse sampling of BTFs              the three texture resolutions as shown in Table 1. A total of
data. In a further study, Filip et al. (2009) assessed different      72 image pairs were shown to test subjects.
uniform reduced samplings of BTF data based on azimuthal
angles of view and illumination as well as on elevation angles.           1 http://btf.cs.uni-bonn.de/.
                                                                  463

                                                                     pixels, which means a subtended angle for a viewer of about
         Table 1: Image pairs as experimental stimuli.
                                                                     6 cycles per minute of a degree of arc.
                  First Image    Second Image                           An SMI RED250 remote eye tracking system was used in
                  Cord-256       Cord-64                             binocular mode with 250 Hz fixation detection, in order to
                  Cord-256       Cord-128                            record subjects’ fixation behavior. SMI BeGaze 2.4 software
                  Cord-128       Cord-256                            was used for subsequent analysis of gaze data.
                  Cord-128       Cord-64                                Subjects. A total number of 20 subjects, 12 males and 8
                  Cord-64        Cord-256                            females, participated in the experiment. Subjects were un-
                  Cord-64        Cord-128                            dergraduate or graduate students or department members in
                                                                     Computer Science or Civil Engineering, and they were not
                                                                     informed about the purpose of the experiment prior to con-
                                                                     ducting it. The age of the test subjects ranged from 22 to 39
                  Table 2: Answer posibilities.
                                                                     years (mean = 30.5). Subjects had normal or corrected-to-
         1        First image has higher quality.                    normal visual acuity.
         2        Second image has the higher quality.                  Procedure. Test subjects were seated in front of the mon-
         =        The images have the same quality.                  itor and eye tracker, introduced to the setup and to the ex-
         None     Subject is not sure.                               perimental procedure, including the answer options. Before
                                                                     the start of the experiment, subjects were asked to read and
                                                                     sign a declaration of informed consent. Subjects could abort
                                                                     the experiment at any time and were guaranteed anonymous
   The experiment was performed in three blocks of 24 im-            treatment of all collected data. They were familiarized with
age pairs each, between which image exposure time was var-           the used sofa images through a preliminary test round with
ied. Exposure time per image was either 1000, 2000, or 3000          eight image pair comparisons, the results of which were dis-
milliseconds (ms), respectively labeled as short, medium and         carded for the subsequent analysis. Then, the subjects were
long test conditions. Presentation order of the three blocks         calibrated on the eye tracker and the first of the three test
was balanced across subjects based on a Latin square design.         blocks was presented. Calibration was repeated before each
Our rationale behind introducing variation of image exposure         subsequent block. Each subject needed about 30 minutes to
time was to test for effects it may have on comparative per-         complete all three blocks.
ceived image quality. It seems possible that, for pairs of dif-
ferent images, longer exposures could lead to higher frequen-                                   Results
cies of detecting that a difference exists.
                                                                     The section consists of two parts: an analysis of subject per-
   Presentation of images in each pair was separated by 200          formance (i.e., the subjects’ ability to judge image quality dif-
ms. After the presentation of the second image in a pair, sub-       ferences for the six pairs of Table 1) and an analysis of gaze
jects had 3000 ms to make a decision about the comparative           data (locations, frequencies, and durations of fixations).
image quality within the pair: was the first or second image of
better visual quality? Or were the two images of the same vi-        Subject Performance Analysis
sual quality? Responses were given on a three-key keyboard           The first three columns of Table 3 illustrate the numbers
and were possible at any time after the start of the presenta-       of correct and incorrect answers given for each of the six
tion of the second image. Subjects were also instructed that         image pairs. Incorrect answers are provided as incorrect
they could choose not to press any button if they felt unsure        equal answers and as other incorrect answers. Looking at
about the comparison. Please see Table 2 for an overview.            the numbers suggests that differences exist between the six
When looking at the six image pairs in Table 1, it becomes           pair conditions for numbers of correct answers. A Fried-
clear that all pairs are different and that, consequently, any       man ANOVA confirms the existence of significant differences
judgment that a pair shows that same image quality will be           (χ2 (2) = 41.989, p < 0.001, r = 0.952). Two groups of pair
incorrect. However, subjects were not previously instructed          comparisons exist, irrespective of presentation order: as a first
that no same-quality pairs would be shown. After the deci-           group, Cord-256 and Cord-128 with lower performance, as
sion time of 3000 ms had lapsed, the next image pair was             a second group Cord-256 and Cord-64 as well as Cord-128
automatically presented.                                             and Cord-64, with higher performance. The same groups
                                                                     can be formed for the number of incorrect equal answers
Experimental Setup                                                   (χ2 (2) = 73.935, p < 0.001, r = 0.920). The first group has
The images were presented on a 24-inch monitor with a res-           many more incorrect equal answers than the second. A break-
olution of 1920x1080 pixels at a distance of 70 cm from the          down of performance and incorrect equal counts for the three
viewer. The screen measured 22.35x15.80 inches and sub-              exposure duration conditions (short, medium, long) revealed
tended approximately 33 degrees of visual angle. Due to the          no significant differences.
texture pattern, the minimal texture detail (i.e., for the parts        In order to check for training effects, we compared num-
of the sofa at the greatest depth in the image) had a cycle of 4     bers of correct answers for the three blocks (first: 268, sec-
                                                                 464

Table 3: Frequencies of correct answers, incorrect equal-quality answers, and other incorrect answers (accumulated over all 20
subjects; sum of answers per pair: 240); average fixation durations and average fixation frequencies per image pair presentation.
                                    # correct   # equal (incorrect)    # other (incorrect)    av. fix. dur. [ms]  av. fix. freq.
       Cord-256 / Cord-128              24              167                     49                  386.48             2.32
       Cord-128 / Cord-256              39              156                     45                  398.51             2.25
       Cord-64 / Cord-256              195              25                      20                  404.14             2.21
       Cord-256 / Cord-64              193              24                      23                  412.01             2.20
       Cord-64 / Cord-128              193              25                      22                  418.08             2.14
       Cord-128 / Cord-64              196              19                      25                  407.59             2.20
ond: 274, third: 297). For each block, a total of 480 answers
                                                                     Table 4: Average Fixation Duration[ms] (AFD) and Fixation
were collected across all 20 participants. A Friedman test
                                                                     Frequency (FF) for different image quality levels, first and
revealed significant differences between the blocks (χ2 (2) =
                                                                     second images, and for blocks.
6.195, p < 0.05, r = 0.952). A comparisons of means shows
a positive training effect.                                                                          AFD[ms]          FF
                                                                                  Cord-256             429.78        2.24
Gaze Fixation Analysis
                                                                                  Cord-128             436.45        2.23
We next analyzed subjects’ gaze fixation distributions across                     Cord-64              444.90        2.17
the sofa image in order to assess whether differences exist for                   First Image          422.43        2.38
different exposure durations and for different image pair com-                    Second Image         493.09        2.05
parisons. Fixation counts for cells in an overlaid 16x16 grid                     First Block          375.08        2.33
are shown in Figure 2 (upper part) for nine conditions. Fixa-                     Second Block         405.25        2.30
tion count patterns between any pair of these nine conditions                     Third Block          448.71        2.02
are significantly correlated with all r > 0.850 and p < 0.001.
   Table 4 shows average fixation duration (AFD, in ms) and
fixation frequencies (FF). For the three BTF resolution con-
                                                                     Table 5: Correlations between VDP results and fixations in-
ditions, a Friedman ANOVA shows significant differences in
                                                                     dependently of exposure durations and presentation order.
FF (χ2 (2) = 6.495, p = 0.039, r = 0.697) and AFD (χ2 (2) =
7.777, p < 0.03, r = 0.649). AFDs decrease and FFs increase                                                   r        p
from lower to higher resolution textures. For first and sec-                     Cord-256 Cord- 64          0.808  0.0001
ond images, a Wilcoxon test shows a significantly lower FF                       Cord-128 Cord- 64          0.753  0.0001
on the second image (Z = 3.062, p < 0.003, r = 0.684) and a                      Cord-256 Cord-128          0.015  0.0175
longer AFD on the second (Z = 2.420, p = 0.025, r = 0.541).
For the first, second, and third blocks we find an increase in
AFDs (χ2 (2) = 8.527, p = 0.045, r = 0.623) and a decrease
                                                                     Cord-64. Lastly, existence of the two groups is further sup-
in FFs (χ2 (2) = 8.954, p = 0.011, r = 0.608).
                                                                     ported by average fixation durations and fixation frequencies
   In order to check whether the subjects’ fixation loca-
                                                                     for the individual image pairs as seen in the right-hand part of
tion patterns were driven by visually perceivable differ-
                                                                     Table 3. AFDs in the first group are significantly lower than
ences between images in our BTF image pairs, we em-
                                                                     in the second (χ2 (2) = 73.935, p < 0.001, r = 0.920), while
ployed the Visible Difference Predictor (VDP) (Mantiuk,
                                                                     FFs are significantly higher (χ2 (2) = 41.989, p < 0.001, r =
Daly, Myszkowski, and Seidel (2005)). VDP simulates low
                                                                     0.952).
level human perception for known viewing conditions (in our
case: a resolution of 1920x1080 pixels at an observer’s dis-
tance of 0.7m). The last row of Figure 2 shows the visually                                    Discussion
perceivable differences per image pair (irrespective of presen-      The results show that two groups of image comparisons exist
tation order) as predicted by VDP. Correlations between VDP          in our study. The first group consists of comparisons between
results and respective fixation location patterns can be seen in     Cord-256 and Cord-128. For this group, subjects are largely
Table 5 (as averaged over exposure durations; displayed in the       unable to perceive existing differences between the images.
columns above each VDP result in Figure 2). The results con-         Instead, they frequently judge the pair to consist of the same
firm the two groups of image pairs found in the subject per-         image. The higher average FFs and lower AFDs in this group
formance analysis: (1) a weak correlation for Cord-256 and           suggest more visual search for existing differences. The VDP
Cord-128 pairs and (2) strong correlations for the pairs within      model predicts few visually perceivable differences for image
the group of Cord-256 and Cord-64 as well as Cord-128 and            pairs in this group.
                                                                 465

      Figure 2: Fixation count in different test duration and responses of visual difference predictor for tested image pairs.
   The second group consists of comparisons between Cord-            interpret this as evidence for subjects’ ability to pick up on
256 and Cord-64 as well as between Cord-128 and Cord-64.             differences in the second group and use information about
For this group, subjects are largely able to see the differences     the location of these differences for image comparisons. A
among the pairs. Occurrences of incorrectly labeling pairs as        significant, albeit very weak, correlation exists for the first
equal are few. The lower FF counts and higher AFDs suggest           group.
that subjects are better able to concentrate on informative lo-         When comparing AFDs and FFs between the three BTF
cations (i.e., on locations at which the images within a pair        image qualities, it seems likely that low image quality leads
differ). The VDP model predicts a higher number of differ-           to less visual search, suggesting that subjects are fast at dis-
ences which are also detectable with higher probability.             cerning features that hint at low quality.
   A comparison between the fixation location patterns be-              AFD was lowest for the first block and then increased over
tween the first and the second group reveals that, irrespective      the course of the experiment, while the average FF decreased.
of group, subjects seem to fixate on similar locations, and do       This pattern is in line with the one presented in (Over et al.
so with similar frequencies. One conclusion is that they em-         (2007)) and suggests that subjects may have applied a coarse-
ploy similar strategies while inspecting image pairs of any of       to-fine approach during visual search. Within the first com-
the six types. VDP predictions differ markedly between the           parisons, subjects may notice locations at which differences
groups. We observed strong correlations between locations of         between images of different visual quality are located, lead-
predicted visually perceivable differences and observed fixa-        ing to more fixations at them. This may differ for behav-
tion patterns only for the second group of comparisons. We           ioral patterns in the beginning, when subjects spend more
                                                                 466

time carefully searching for differences among image pairs,                                     References
resulting in shorter and a larger number of fixations.                 Dana, K. J., Van Ginneken, B., Nayar, S. K., & Koenderink,
   Longer AFDs in the second image in a pair compared to                  J. J. (1999). Reflectance and texture of real-world surfaces.
the first indicate that by the time subjects look at the second           ACM Transactions on Graphics (TOG), 18(1), 1–34.
image they already have formed hypotheses about where to               Filip, J., Chantler, M. J., & Haindl, M. (2008). On optimal
look for differences.                                                     resampling of view and illumination dependent textures. In
   There were no differences in performance and gaze fixation             Proceedings of the 5th symposium on applied perception in
for different exposure durations.                                         graphics and visualization (pp. 131–134).
   The main purpose of this study was to locate a threshold for        Filip, J., Chantler, M. J., & Haindl, M. (2009). On uni-
robust, effective BTF compression based on a downsampling                 form resampling and gaze analysis of bidirectional texture
of BTF pictures. Above the threshold, differences between                 functions. ACM Transactions on Applied Perception (TAP),
pictures are not visually perceivable by a human observer.                6(3), 18.
Our results clearly indicate that differences between Cord-            Filip, J., & Haindl, M. (2009). Bidirectional texture func-
256 and Cord-128 lie above such threshold, while differences              tion modeling: A state of the art survey. Pattern Analysis
between Cord-256 and Cord-64 as well as between Cord-128                  and Machine Intelligence, IEEE Transactions on, 31(11),
and Cord-64 lie below it.                                                 1921–1940.
   The results are likely to apply to all self shadowing fabrics.      Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-
                                                                          world illumination and the perception of surface reflectance
                         Conclusion                                       properties. Journal of Vision, 3(5), 3.
The results of our study narrowed the bracket in which the             Lawson, R., Bulthoff, H. H., & Dumbell, S. (2003).
threshold is located that separates visually perceivable dif-             Interactions between view changes and shape changes
ferences in BTF renderings from those that are not. Conse-                in picture-picture matching. PERCEPTION-LONDON-,
quently, we can now suggest a perception-based criterion for              32(12), 1465–1498.
downscaling BTFs. A result for image synthesis is that, above          Mantiuk, R., Daly, S. J., Myszkowski, K., & Seidel, H.-
the threshold, the lowest texture resolution available can be             P. (2005). Predicting visible differences in high dynamic
used without visually perceivable degradation of image qual-              range images: model and its calibration. In Electronic
ity. This allows to significantly reduce computer memory us-              imaging 2005 (pp. 204–214).
age in BTF rendering.                                                  Mcmillan, L., Smith, A. C., Matusik, W., & Matusik, W.
   A logical next step would be to conduct a localized search             (2003). A data-driven reflectance model. In in proc. of
within this established bracket, that is, between Cord-128                siggraph.
on one side and Cord-64 on the other, since our study                  Meseth, J., Müller, G., Klein, R., Röder, F., & Arnold, M.
showed that observers cannot distinguish between Cord-256                 (2006). Verification of rendering quality from measured
and Cord-128.                                                             btfs. In Proceedings of the 3rd symposium on applied per-
   In the future, we also plan to look for ability- and/or skill-         ception in graphics and visualization (pp. 127–134).
dependent differences in the ability to distinguish BTFs at dif-       Nicodemus, F. E., Richmond, J. C., Hsia, J. J., Ginsberg,
ferent quality levels. We have already conducted pilot studies            I. W., & Limperis, T. (1977). Geometrical considerations
with groups of engineers and artists.                                     and nomenclature for reflectance (Vol. 160). US Depart-
   In general, there are few studies on perceptual measures of            ment of Commerce, National Bureau of Standards Wash-
rendering algorithms. This study is a first step in this direc-           ington, DC, USA.
tion.                                                                  Over, E., Hooge, I., Vlaskamp, B., & Erkelens, C. (2007).
   Also, this study could open up new research insights for               Coarse-to-fine eye movement strategy in visual search. Vi-
the field of perception of textures of real objects, especially in        sion Research, 47(17), 2272–2280.
object comparison tasks. For example, future questions that            Pellacini, F., Ferwerda, J. A., & Greenberg, D. P. (2000). To-
can be addressed could relate to the categorization of textures           ward a psychophysically-based light reflection model for
in object perception, either general or with regard to group-             image synthesis. In Proceedings of the 27th annual confer-
dependent or individual differences, to effects of attention in           ence on computer graphics and interactive techniques (pp.
object texture perception, or to effects of expertise which may           55–64).
be acquired through completing series of object texture com-           te Pas, S. F., & Pont, S. C. (2005a). A comparison of
parisons similar to the ones employed in this study.                      material and illumination discrimination performance for
                                                                          real rough, real smooth and computer generated smooth
                     Acknowledgments                                      spheres. In Proceedings of the 2nd symposium on applied
                                                                          perception in graphics and visualization (pp. 75–81).
We would like to thank our test subjects for participating,            te Pas, S. F., & Pont, S. C. (2005b). Estimations of light-
Jakob Gomoll for helping in implementing and conducting                   source direction depend critically on material brdfs. Per-
the pilot study and Stefanie Wetzel for the constructive dis-             ception ECVP abstract, 34, 0–0.
cussions.
                                                                   467

