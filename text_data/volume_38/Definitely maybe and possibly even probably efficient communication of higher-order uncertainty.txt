         Definitely maybe and possibly even probably: efficient communication of
                                                    higher-order uncertainty
                                       Michele Herbstritt (michele.herbstritt@gmail.com)
                                              Michael Franke (mchfranke@gmail.com)
                                            Department of Linguistics, University of Tübingen
                                               Wilhelmstrasse 19, 72070 Tübingen, Germany
                               Abstract                                  is equal to 0 or 1. This represents the first layer of uncertainty,
                                                                         where having perfect information about how the world is like
   Possibility and probability expressions, like possibly or prob-
   ably, are frequently assumed to communicate that the proba-           is not enough to perfectly predict how the world will be.
   bility of a proposition is above a certain threshold. Most pre-          A second, higher-order, level of uncertainty comes into the
   vious empirical research on these expressions has focused on          picture when the true objective chance is uncertain. Imag-
   cases of known objective chance: if the true objective proba-
   bility is given, would a speaker use possibly, probably or one        ine an agent who has only imperfect information about the
   of their kin? Here, we investigate the use of probability expres-     urn: the agent knows that it contains 10 balls of two differ-
   sions when speakers have subjective uncertainty about objec-          ent colors, but the agent is only allowed to draw (and look
   tive chance, i.e., higher-order uncertainty. Experimental data
   suggest that speakers’ choices of a probability expression is a       at) a certain number of balls. The agent might observe that
   complex function of their state of higher-order uncertainty. We       none, some or all of the drawn balls are red and form an un-
   formulate a computational probabilistic model of pragmatic            certain belief about the content of the urn. Clearly, the lower
   speaker behavior that explains the experimental data.
                                                                         the number of drawn balls, the less precise the agent’s belief.
   Keywords: uncertainty; probability; experimental pragmatics;
   computational modeling                                                   This work is about uncertainty of this higher-order kind.
                                                                         In the remainder of this section we summarize some relevant
                                                                         ideas from the linguistic literature on possibility and proba-
                           Introduction
                                                                         bility expressions. The following section reports on an ex-
Real-world reasoning, decision-making and communication                  periment that investigates choices of probability expressions
tasks take place almost invariably under uncertainty. From               under higher-order uncertainty. Standard regression model-
everyday future planning and small talk about the weather                ing suggests that higher-order uncertainty may affect lexical
to scientific practices and financial or legal reports, we rea-          choices in complex ways. We therefore turn to a computa-
son, decide and speak about things that we do not know for               tional model of a pragmatic speaker that aims to predict lexi-
sure. It is not surprising that possibility and probability ex-          cal choice in a natural way. We compare model variants and
pressions are ubiquitous in communication. To mention only               scrutinize the predictions of the most credible variant.
a recent example, a quick search within ‘The Litvinenko In-
quiry’, delivered by Sir Robert Owen to the Home Secretary
of the United Kingdom on January 19, 2016 (329 pages),1                  Previous work The amount of previous linguistic research
resulted in 84 instances of probable/probably/(un)likely and             about possibility expressions such as might, possible, possi-
103 instances of might/possibly/it is possible that.                     bly (best known as “epistemic modals”) is gigantic.2 Here we
                                                                         refer to the milestone work by Kratzer (1991), which puts for-
                                                                         ward a uniform analysis of possibility and probability expres-
Higher-order uncertainty This paper reports experimen-                   sions as quantifiers over possible worlds. It is a purely quali-
tal and modeling work on the meaning and use of the English              tative analysis, with no reference to probability measures.
expressions probably and possibly. These expressions (and
                                                                            Much less research has appeared in linguistics specifically
variations thereof) have been extensively investigated in lin-
                                                                         about probably. However, Kratzer’s picture has been chal-
guistics (Kratzer, 1991; Egan & Weatherson, 2011; Yalcin,
                                                                         lenged on many grounds by several authors in recent years.
2010; Lassiter, 2011) and psychology (Beyth-Marom, 1982;
                                                                         Oversimplifying, there seems to be a consensus about the
Brun & Teigen, 1988; Teigen, 1988; Windschitl & Wells,
                                                                         need of a semantics which incorporates probability measures
1996, 1998). What sets our work apart from most of the lit-
                                                                         (Yalcin, 2010; Lassiter, 2011; Moss, 2015). The simplest im-
erature is that we investigate the use of probably and possibly
                                                                         plementation of this semantics postulates that the meaning of
in situations of what we call “higher-order uncertainty”.
                                                                         a sentence of the form Probably, p is that the probability of p
   To illustrate, imagine an urn containing 10 balls of two dif-
                                                                         exceeds a certain threshold θ.
ferent colors (e.g. red and blue). The proportion of red balls
                                                                            Recent work considers complex nested cases as well
out of 10 expresses the objective chance that a random draw
                                                                         (Moss, 2015; Lassiter & Goodman, 2015):
will result in a red ball. Knowing the objective chance means
knowing the exact content of the urn, and yet it is not enough           (1)      It might be probable that Alice is wearing green.
to be sure about what will happen, unless the objective chance
                                                                             2 See (Egan & Weatherson, 2011) for an introduction to the con-
    1 Available online at https://www.litvinenkoinquiry.org.             temporary debate.
                                                                     2639

(2)      Alice is definitely likely to be wearing green.              Material The setup of the experiment is the urn scenario
                                                                      introduced above. The urn contains 10 balls of two differ-
Suppose that Bob is Alice’s friend and has witnessed her              ent colors. Observations of the content of the urn are made
wearing green 5 times on 8 consecutive days. On the other             by drawing a certain number of balls (referred to as “ac-
hand, Carol is Alice’s mum and has observed that Alice was            cess”) and counting how many of them are red (“observa-
wearing green 500 times on 800 consecutive days. Despite              tion”). Each trial showed a picture representing the urn sce-
the fact that the objective proportion of green observations is       nario with various access and observation. A sample stimulus
the same for both, only Carol is in the position to utter (2),        is shown in Figure 1. A short description that came with every
while Bob should limit himself to (1). These examples raise           picture reminded participants that they had to imagine draw-
the question —most often left unanswered— of what kind of             ing a certain number of balls, looking at them, and putting
uncertainty is in play when speakers use possibility and prob-        them back in the urn; then, they would draw another ball and
ability expressions. If the objective proportion is not enough        make a prediction about its color.
to distinguish between (1) and (2), then what is needed?
    This is relevant also for simple, non-nested, uses of possi-
bility and probability expressions, which are way more fre-                                                                     ?
quent than nested cases. Consider a more extreme version of
the urn scenario. There are 100 balls in the urn, of two dif-
ferent colors. Imagine drawing 8 balls and observe that 5 of                         ?                                     ? ?
                                                                                ? ?
                                                                                    ? ?           ?                        ? ? ?
                                                                                 ?
them are red. Then (3) is a very appropriate thing to say and                 ?
                                                                                 ?
                                                                                   ?
                                                                                      ?
                                                                                              ?
                                                                                                 ? ?
                                                                                                          ?
                                                                                                            ? ? ?
                                                                                                                         ?
                                                                                                                            ? ? ?
(4) is not. But imagine drawing 80 balls and observe that 50
of them are red: the proportion of observed red balls is the                 You draw 6 balls and observe that 3 of them are red.
same, but, intuitively, (4) is more appropriate than before.
                                                                                          Figure 1: Sample stimulus.
(3)      A randomly drawn ball might be red.
(4)      A randomly drawn ball will probably be red.                     We selected seven proportions of observed red balls,
                                                                      namely 0, 0.25, 0.33, 0.5, 0.67, 0.75, 1. Each proportion is ob-
It seems that in the case of uncertainty about objective chance,      tained in two different ways: one encoding what we call
the maximum likelihood guess about the latter is not all that         “low” uncertainty (access> 5) and one what we call “high”
matters. If 50 out of 80 observed balls are red, we can be            uncertainty (access< 5). Crossing proportions and uncer-
much more certain about the objective chance level, than              tainty levels resulted in 14 experimental conditions (Table 1).
when 5 out of 8 balls are observed. This difference may give
rise to complex nested uses of probability expressions, but
does it have to? It seems that higher-order uncertainty is fre-                        Table 1: Experimental conditions.
quent in life. If there is an objective chance of rain, we do not                      0    0.25    0.33 0.5   0.67     0.75      1
know it, but still we do not hear the neighbor say that it will            high       0/2    1/4     1/3 2/4    2/3      3/4     2/2
                                                                            low      0/10    2/8     3/9 4/8    6/9      6/8    10/10
definitely maybe and possibly even probably rain.
    There are two options to reconcile higher-order uncertainty
with the use of simple probability expressions. One is to                The experiment consisted of expression and likelihood tri-
assume that an agent who is uncertain about the objective             als. Expression trials probe into the lexical choice of prob-
chance of a proposition p, flattens his higher-order belief into      ability expressions. We asked the participants to complete a
a single probabilistic belief about p. Simple probability ex-         sentence of the form The next ball will [. . . ] be red by select-
pressions do not communicate genuine higher-order uncer-              ing the most appropriate expression from a drop-down menu
tainty, but simple one-dimensional uncertainty about p. An-           containing certainly not, probably not, possibly, probably,
other possibility is that higher-order uncertainty plays a role       certainly. In likelihod trials participants had to answer the
in our choice of probability expressions. The question, to be         question How likely do you think it is that a randomly drawn
addressed by a computational model below, would then be:              ball will be red? by adjusting a slider ranging from 0 to 100
how exactly would different layers of uncertainty affect the          with a step of 5. Answers from likelihood trials hint at partic-
choice of probability expressions? In any case, since the map-        ipants’ beliefs about the probability of the crucial proposition
ping from higher-order certainty to flattened one-dimensional         The next draw will be red in each condition.
beliefs is many-to-one, it should be possible to find experi-
mental evidence to decide between these rival options.                Procedure Each participant completed 12 trials, one for
                                                                      each of 12 conditions randomly picked from the 14 total con-
                          Experiment                                  ditions. Half of the trials were expression trials, the other half
Participants 50 (self reported) English native speakers               likelihood trials. Prior to the main experimental phase, partic-
with US IP-addresses were recruited via Amazon’s Mechani-             ipants completed a training phase that contained the following
cal Turk.                                                             introduction:
                                                                  2640

   “This experiment is an interactive two player game of
   chance. The players cooperate to guess the content of
   an urn. Both players know that the urn always contains
   10 balls of different colors (for example, red and blue).
   But only one player (the sender) is allowed to draw a
   certain number of balls from the urn and look at them.
   The sender puts the balls back into the urn and gives
   it a nice shake, then the sender draws a new ball from
   it. Before looking at it, the sender sends a message to
   the other player (the receiver). The receiver reads the
   message and tries to guess the exact content of the urn.”
The motivation for this was to avoid potential confounds, as          Figure 3: Observed and predicted expected likelihood of the
much as possible, about the purpose of conversation when              prejacent in each condition.
choosing between probability expressions. Previous research
has established that contextual questions under discussion,           We also consider an interaction model that contains the
i.e., ways of classifying what counts as important to a con-          latter factors’ interaction as well.
versation, may affect the use and interpretation of probability
expressions (Teigen, 1988; Windschitl & Wells, 1998; Las-                                     Table 2: AIC scores.
siter, 2011; Herbstritt, 2015). Moreover, by introducing the
participants to a fictive interactive game context we hoped                                 simple     complex     ineraction
to suggest that they should reason about the effect of their                       AIC      662.78      646.69       635.93
choices on another agent.
                                                                         AIC scores of best-fits of these regression models are given
                                                                      in Table 2. Despite added complexity, complex seems a bet-
Results & analysis Figure 2 shows results from the expres-            ter model than simple, and interaction seems to be the
sion trials, i.e., the percentages of choices for each message in     best. This suggests that there might be more to the use of
each condition, grouped by uncertainty level. Figure 3 shows          probability expressions than just the level of belief in the pre-
mean answers from the likelihood trials, alongside the poste-         jacent; the result suggests that higher-order uncertainty may
rior beliefs that an ideal Bayesian agent should hold.                affect choice of expressions in more subtle ways.3
                                                                         How do speakers choose expressions under higher-order
                                                                      uncertainty? What exactly is the role of observation and ac-
                                                                      cess? Can we predict the speakers’ choices by assuming that
                                                                      possibility and probability expressions have a simple seman-
                                                                      tics but the speakers use them pragmatically? To answer these
                                                                      questions we developed a probabilistic model based on a ver-
                                                                      sion of the Rational Speech Acts model (henceforth, RSA)
                                                                      proposed by Goodman and Stuhlmüller (2013) (G&S).
                                                                                          Computational model
                                                                      Probabilistic modeling is arguably better suited for capturing
                                                                      the subtleties of (pragmatic) language use than the standard
                                                                      formal semantics framework. RSA has proven to be a suc-
       Figure 2: % of message choices in each condition.
                                                                      cessful modeling tool when it comes to complex usage pat-
   We want to test whether choice of probability expression is        terns (or pragmatic effects) on the basis of simple semantics
governed (i) only by participants’ probabilistic beliefs about        and largely shared insights from rational choice theory and
the prejacent The next draw will be red, or (ii) by the more          information theory.4 The version of RSA developed by G&S
complex higher-order uncertainty state, expressed as a func-              3 This result holds also if the factor observation is uniformly
tion of accessed and observed balls. To do so, we formu-              replaced in the models with a factor containing the proportions of
late and compare two kinds of multinomial logistic regres-            observed red balls over accessed balls and, more importantly, if we
                                                                      restrict the data to cases of genuine high-order uncertainty, i.e. re-
sion models. The first and simple model seeks to predict the          moving condition a = 10. Moreover, AIC score of the simple model
five-level categorical factor answer (certainly not, probably         using ideal beliefs instead of measured ones as predictor becomes
not, possibly, probably, certainly) with a single metric factor       better than the model using measured beliefs, but is still worse than
                                                                      the complex model.
belief which is the participants’ mean answers in the rele-               4 See recent works by Degen, Tessler, and Goodman (2015), Kao
vant likelihood trials. The second and complex model con-             and Goodman (2015) and Hawkins, Stuhlmüller, Degen, and Good-
siders metric factors observation and access as predictors.           man (2015) among others.
                                                                  2641

deals with exactly the kind of uncertain beliefs that we are               speaker’s behavior is to soft-maximize the expected utility of
interested in, although for a different purpose.                           the message in the current situation:
                                                                                      speaker.prob(m|o, a) ∝ exp(λ ∗ EU(m; o, a))         (3)
Basic model The basic setup of the model mirrors the setup
of the experiment. The urn contains 10 balls, any number of                   EU is multiplied by a rationality parameter λ (free in the
which can be red. The set of natural numbers S = {0, . . . , 10}           model) that modulates “how rational” the choice is.6 EU
represents the state space: each s ∈ S is a possible quantity              is defined as negative Hellinger distance (HD) between the
of red balls in the urn. The set A = {0, . . . , 10} contains the          speaker’s beliefs and the beliefs of a “literal listener”:
possible access values. Given a state s and access value a, the
number of red balls observed by the agent is denoted o, and                  EU(m; o, a) = −HD[speaker.bel(s|o, a), literal.bel(s|m)] (4)
upper-bounded by min(s, a).
                                                                              The literal listener is a theoretical construct needed to
   The first level of uncertainty is determined by the state:
s/10 is the objective chance that a randomly drawn ball will
                                                                           ground the otherwise infinite process implied in a recursive
                                                                           model of pragmatic reasoning. It is a dummy agent who does
be red. Crucially, the agent does not know this value. In-
                                                                           not perform any kind of pragmatic reasoning and simply in-
stead, the agent observes o red balls out of a. Based on this
                                                                           terprets every message m according to the literal semantics:
observation the agent forms an uncertain belief over the state
space, modeled as the Bayes-inverted conditional probability
                                                                                       literal.bel(s|m) = P(s|m is true) ∗ prior(s)       (5)
of observing o red balls out of a drawn balls in state s:
             speaker.bel(s|o, a) ∝ P(o|a, s) ∗ prior(s)            (1)     Parameters estimation The basic version of the model, M0
                                                                           has two free parameters: the threshold θ and the rationality λ.
   In turn, P(o|a, s) is given by the hypergeometric model of              It assumes flat prior beliefs over the state space. We also con-
the urn:                                                                   sidered three more complex versions of the model: a model
                                                                           where the prior beliefs are expressed by a symmetric beta-
              P(o|a, s) = hypergeometric(o; a, s, 10)              (2)     binomial distribution with free shape parameters α = β (M1 );
                                                                           a model with two (possibly) different free rationality param-
   Equation 1 defines the beliefs of a speaker, as we aim to               eters, λlow and λhigh , one for each level of uncertainty (M2 );
model the behavior of message-sending agents. As such, a                   finally, a model combining these two variations (M3 ).
crucial component of the model is the set of available mes-                   Each model was implemented in JAGS (Plummer, 2003)
sages together with their meaning. In the spirit of RSA, we                and the posterior likelihoods of the free parameters given the
assume a simple literal semantics, expressed as follows in the             experimental data were estimated by Bayesian inference via
standard notation of formal semantics:                                     MCMC sampling. We remained uncommitted on the prior
                                                                           distributions over the parameters, except for fixing sensible
   Jcertainly(p)Ks = 1 iff P(p) = 1 in s                                   intervals:
   Jprobably(p)Ks = 1 iff P(p) > θ in s                                         θ ∼ U (0, 1) λ, λlow , λhigh ∼ U (0, 20) α ∼ U (0, 20)
   Jpossibly(p)Ks = 1 iff P(p) > 0 in s
                                                                              We gathered two chains of 5000 samples for each model
The threshold θ is a free parameter in the model (more about               after an initial burn-in phase of 5000. Convergence was con-
this below). The variable p is to be instantiated with (some               firmed via R̂ (Gelman & Rubin, 1992). The results were in-
sentence equivalent to) The next ball will be red.                         teresting for at least three reasons.
   An important assumption in RSA modeling —loosely                           First, the mean value inferred for θ was always equal to
based on Paul Grice’s Maxim of Quantity, is that the com-                  0.55, regardless which model we simulated. This is an im-
municative goal of the speaker is to maximize the information              portant result: our data provide evidence that an objective
transferred to the listener. There are several ways of formaliz-           chance bigger than 55% is enough to consider probably as
ing the maximization of information. We think of it as bring-              an appropriate expression. This is in line with intuition and
ing the listener’s beliefs as close as possible to the speaker’s           previous experimental results. It speaks in favor of the model
beliefs, i.e. minimizing the (Hellinger) distance between the              that data-driven inference recovers this intuitive value for θ
probability distributions representing those beliefs.5                     without stipulating it from the start.
   RSA models the behavior of (imperfectly) rational agents.                  Second, the estimation of α in M1 resulted in a mean value
Adopting the terminology of rational choice theory, the                    of 2.81 (HDI: 1.26-4.78).7 Notice that α = 1 would imply
                                                                           flat prior beliefs over the state space, which can thus reason-
    5 We depart from the informativity criterion adopted by G&S be-        ably be excluded given our data (more about this below). This
cause it does not allow the speaker to send messages that are liter-           6 As
ally false; however, we want to allow some pragmatic slack to the                    λ → ∞, the choice approaches perfect rationality.
speaker: it is plausible to think that, for example, chances around            7 All  HDIs (highest density intervals) reported here comprise
97% or bigger are certain enough for us to say certainly, even if this     95% of the posterior density, such that no point outside the inter-
expression is literally true only when the odds are 100%.                  val has higher density than any point within.
                                                                       2642

can be perhaps explained by looking again at the introductory               to distinguish the two models on the basis of the data. Sum-
text of the experiment: it is written that “[...] the urn always            ming up, allowing our model to use two different rationality
contains 10 balls of different colors” and it is reasonable to              parameters for the two different uncertainty levels invariably
assume that this might have caused a number of the partici-                 results in a definitely more credible model.
pants to neglect the possibility that the urn contained 0 or 10
red balls (which results in non uniform prior beliefs).                     Correlation and model criticism Model comparison
   Third, the estimation of λlow and λhigh in M2 resulted                   based on Bayes factors tells us if/how much a model is better
respectively in mean values of 7.36 (HDI: 6.03-8.79) and                    than another, but does not give us an absolute measure of how
3.49 (HDI: 2.75-4.24). The fact that the difference between                 good a model is. Having picked M3 as the best model at our
λlow and λhigh is different from zero with completely non-                  disposal, we correlated the experimental observations with
overlapping HDIs suggests that our data provide evidence for                the predictions made by the model fitted with the maximum-
assuming different rationality parameters for different uncer-              likelihood estimated values of its free parameters. The results
tainty level (more about this below).8                                      of Pearson’s product-moment correlation provide us with a
   Finally, the mean values for the free parameters of M3 and               measure of goodness of fit for the model as its best:
their HDIs are reported in Table 3.
                                                                                 d f = 68; r = 0.927; 95% ci : 0.885-0.954; p < 0.001
              Table 3: Estimated parameters of M3 .                             By that (frequently used) measure, predictions of the model
                                                                            look quite good. A more stringent criterion for goodness of
                    θ               α              λlow        λhigh        fit are posterior predictive checks (PPC) (Kruschke, 2014).
      mean         0.55           2.81             6.11         3.16
      HDI       0.50-0.59      1.04-5.42        4.75-7.45    2.39-3.95
                                 M0
                                 θ, λ
                                  •
                       M1 •              • M2
                   θ, λ, α                   θ, λlow , λhigh
                                  •
                                 M3
                          θ, λlow , λhigh , α
          Figure 4: Nesting relations between models.
Model comparison Our four models are nested. M0 is a
special case of both M1 and M2 , which are special cases of
M3 , as depicted in Figure 4. This allows for model compar-
isons based on Bayes factors (BF) with the Savage-Dickey
method (Wagenmakers, Lodewyckx, Kuriyal, & Grasman,
2010). As expected, both M1 and M2 are more credible mod-
els given our data. The Bayes factor in favor of M1 against
M0 is substantial (approximately BF = 8.68). More strik-
ingly, the Bayes factor in favor of M0 against M2 is so low
that it cannot be computed with normal float precision levels,
which in turn means that M2 is definitely more credible than
M0 . Moving to M3 , we get a similarly striking result when                 Figure 5: Posterior predictive checks. Red circles highlight
we compare it to M1 : the Bayes factor in favor of M1 ap-                   discrepancies between observed data and credible values pre-
proaches zero. On the other hand, the Bayes factor in favor of              dicted by the model.
M3 against M2 is only equal to 1.40 which is barely enough
    8 An                                                                        PPCs look at hypothetical data generated from a model
         intuitive explanation of this result may be that the more pre-
cise the participants’ belief, the easier it was for them to behave         when parameters are randomly drawn from their posterior
more rationally. In other words, the participants’ choice behavior          distribution (i.e., conditional on the data). By visual means,
becomes more noisy as their uncertainty increases. As pointed out           we then check whether any actually observed data point is
by a reviewer, in light of this explanation it would seem more prin-
cipled to allow λ to vary smoothly with the access value. We leave          “surprising” in the sense that it lies outside of the 95% HDI
the investigation of such a model for another occasion.                     of the hypothetically generated data. Figure 5 shows the mean
                                                                        2643

frequencies of posterior predictive message choices of M3 (in          are odd. In D. C. Noelle et al. (Eds.), Proceedings of
light blue), together with their 95% HDIs. The pink dots               CogSci37.
represent observed data. Ideally, all observations should lie        Egan, A., & Weatherson, B. (2011). Epistemic modality.
within the posterior HDIs. Visual inspection of the plots al-          Oxford University Press.
lows us to recognize several critical points where the posterior     Gelman, A., & Rubin, D. B. (1992). Inference from itera-
predictions of the model diverge from the observed data (cir-          tive simulation using multiple sequences (with discussion).
cled in red). We observe that most critical points are found           Statistical Science, 7, 457–472.
in the high uncertainty condition, plausibly where most noise        Goodman, N. D., & Stuhlmüller, A. (2013). Knowledge
occurred in the data. It is also mostly at these points where          and implicature: Modeling language understanding as so-
participants’ mean answers in the likelihood trials diverged           cial cognition. Topics in cognitive science, 5(1), 173–184.
from idealized Bayesian belief update (see Figure 3). This           Hawkins, R. X. D., Stuhlmüller, A., Degen, J., & Goodman,
suggests that failures in PPCs might not be the fault of the           N. D. (2015). Why do you ask? good questions provoke
pragmatic part of the model, but the belief update part of             informative answers. In D. C. Noelle et al. (Eds.), Proceed-
the model. In other words, it might be that the pragmatic              ings of CogSci37.
reasoning which lead to participants’ message choices was            Herbstritt, M. (2015). Experimental investigations of proba-
based on uncertain beliefs different from those of an ideal-           bility expressions: a first step in the (probably) right direc-
ized Bayesian reasoner.                                                tion. In M. Kaeshammer & P. Schulz (Eds.), Proceedings
                                                                       of ESSLLI 2015 student session.
                         Conclusion                                  Kao, J. T., & Goodman, N. D. (2015). Let’s talk (ironically)
We presented experimental evidence suggesting that the                 about the weather: Modeling verbal irony. In D. C. Noelle
speakers’ use of possibility and probability expressions de-           et al. (Eds.), Proceedings of CogSci37.
pends not only on the objective chance of the event in ques-         Kratzer, A. (1991). Modality. In A. von Stechow & D. Wun-
tion but also on the speakers’ state of higher-order uncer-            derlich (Eds.), Semantics: An international handbook of
tainty. We formulated a computational model based on RSA               contemporary research (pp. 639–650). de Gruyter.
that explains the experimental data in terms of simple seman-        Kruschke, J. (2014). Doing bayesian data analysis, 2nd edi-
tics and standard pragmatic reasoning. Despite its simplicity,         tion: A tutorial with r, jags, and stan. Academic Press.
the predictions of the model are quite good. Comparing AIC           Lassiter, D. (2011). Measurement and modality: the scalar
scores for the best-fits of the interaction regression model           basis of modal semantics. Unpublished doctoral disserta-
and our theory-driven computational model reveals a striking           tion, NYU Linguistics.
preference for the latter (AIC: 635.93 vs 270.90).                   Lassiter, D., & Goodman, N. D. (2015). Nested and infor-
   Future work will attempt to refine the model by measuring           mative epistemics in a graphical models framework. Talk
participants’ full posterior beliefs about the urn and using the       given at Bridging Logical and Probabilistic Approaches to
measured distributions in the model instead of the Bayesian            Language and Cognition, ESSLLI 2015, Barcelona.
beliefs. Another line of empirical research will be to inves-        Moss, S. (2015). On the semantics and pragmatics of epis-
tigate speakers’ use of nested possibility and probability ex-         temic vocabulary. Semantics and Pragmatics, 8(5), 1–81.
pressions under higher-order uncertainty: if given the choice,       Plummer, M. (2003). Jags: A program for analysis
would speakers prefer a nested construction over a simple one          of bayesian graphical models using gibbs sampling. In
to communicate their uncertain beliefs? Moreover, a natural            K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of
continuation of this work will be to investigate listeners’ in-        DSC3 (Vol. 124, p. 125).
terpretation of (simple and nested) possibility and probability      Teigen, K. H. (1988). When are low-probability events
expressions.                                                           judged to be ‘probable’? effects of outcome-set character-
                                                                       istics on verbal probability estimates. Acta Psychologica,
                    Acknowledgments                                    6(2), 157–174.
Financial support by the Institutional Strategy of the Univer-       Wagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., & Gras-
sity of Tübingen (Deutsche Forschungsgemeinschaft, ZUK                man, R. (2010). Bayesian hypothesis testing for psychol-
63) is gratefully acknowledged.                                        ogists: A tutorial on the savage–dickey method. Cognitive
                                                                       psychology, 60(3), 158–189.
                          References                                 Windschitl, P. D., & Wells, G. L. (1996). Measuring psycho-
Beyth-Marom, R. (1982). How probable is probable? a nu-                logical uncertainty: Verbal versus numeric methods. Jour-
   merical translation of verbal probability expressions. Jour-        nal of Experimental Psychology: Applied, 2(4), 343.
   nal of forecasting, 1(3), 257–269.                                Windschitl, P. D., & Wells, G. L. (1998). The alternative-
Brun, W., & Teigen, K. H. (1988). Verbal probabilities: am-            outcomes effect. Journal of Personality and Social Psy-
   biguous, context-dependent, or both? Organizational Be-             chology, 75(6), 1411–1423.
   havior and Human Decision Processes, 41(3), 390–404.              Yalcin, S. (2010). Probability operators. Philosophy Com-
Degen, J., Tessler, M. H., & Goodman, N. D. (2015). Wonky              pass, 5(11), 916–37.
   worlds: Listeners revise world knowledge when utterances
                                                                 2644

