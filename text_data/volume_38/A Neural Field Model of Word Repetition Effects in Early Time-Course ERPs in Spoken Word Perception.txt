  A Neural Field Model of Word Repetition Effects in Early Time-Course ERPs in
                                                  Spoken Word Perception
                                          Andrew P. Valenti (andrew.valenti@tufts.edu)
                                Human-Robot Interaction Laboratory, Tufts University, 200 Boston Ave.
                                                        Medford, MA 02155 USA
                                            Michael Brady (michael.brady@tufts.edu)
                                Human-Robot Interaction Laboratory, Tufts University, 200 Boston Ave.
                                                        Medford, MA 02155 USA
                                        Matthias J. Scheutz (matthias.scheutz@tufts.edu)
                                Human-Robot Interaction Laboratory, Tufts University, 200 Boston Ave.
                                                        Medford, MA 02155 USA
                                            Phillip J. Holcomb (pholcomb@tufts.edu)
                                      Department of Psychology, Tufts University, 490 Boston Ave.
                                                        Medford, MA 02155 USA
                                                       He Pu (he.pu@tufts.edu)
                                      Department of Psychology, Tufts University, 490 Boston Ave.
                                                        Medford, MA 02155 USA
                               Abstract                                (Elman, 1990; Norris, 1995) which represent time through
   Previous attempts at modeling the neuro-cognitive mecha-            cyclical, recurring connections from one state to an earlier
   nisms underlying word processing have used connectionist ap-        state in the network. One popular method by which learning
   proaches, but none has modeled spoken word architectures as         is incorporated in these networks is through a gradient decent
   the input is presented in real-time. Hence, such models rely on
   the ingenuity of the modeler to establish a mapping of real-        regression using backpropagation.
   time stimulus to the model’s input which may not preserve              While these models can account for many aspects of how
   processing that happens during each time step. We present a         humans comprehend spoken and written words, none of these
   neural field model which successfully replicates the effect of
   immediate auditory repetition of monosyllabic words and fits        architectures model speech perception using real-time, hu-
   it to a component of a well-studied mechanism for analyzing         man input. We present a neural field model with an efficient
   language processing, the event-related potential (ERP). This        learning mechanism which dynamically responds to the spo-
   represents a new modeling approach to studying the neuro-
   cognitive processes, one that is based on the bottom-up inter-      ken word process as it unfolds over time. A neural field sits
   action of real-time sensory information with higher-level cate-     in an equilibrium state waiting for a pattern it has tuned it-
   gories of cognitive processing.                                     self to detect, and this detection takes the form of a perturba-
   Keywords: dynamic neural fields; event-related potential            tion. Learning associates the equilibrium state of a field with
   (ERP); spoken word perception; mental workload; computa-
   tional modeling; word repetition                                    its environment. Primary fields tune themselves to fall into
                                                                       systematic equilibrium states in response to combinations of
                          Introduction                                 sensory input. Deeper-processing, secondary neural fields are
By “spoken word perception”, we mean the cognitive pro-                then enabled to tune themselves in response to their environ-
cesses that entail the sensory intake of an acoustic waveform          ments once primary fields have settled into predictable behav-
until the words contained in it are identified. Some early             iors. With experience, the network forms representations as
connectionist models of speech perception processes were               each neural field systematically responds to its environment
driven by research in generalized automatic speech recog-              through time.
nition and have shown, for example, that a good deal of
phonemic information is present in the auditory signal and             Word Repetition Effects and ERPs
can be extracted from the statistical generalization of the            An event-related potential (ERP) is an electrical voltage asso-
model. Among the best-known models of speech percep-                   ciated with an event such as a stimulus or response. ERPs are
tion is TRACE (McClelland & Elman, 1986) which has mod-                believed to reflect the summation of post-synaptic potentials
eled several lexical effects (e.g., phonemic restoration in a          occurring in many thousands of neurons. The time course of
noisy environment) and the time-course of word recogni-                ERPs in auditory processing can be traced starting from stim-
tion. TRACE has been criticized for its biologically unre-             ulus onset and continuing for approximately 800 ms. Our
alistic handling of time and the lack of a learning mecha-             study focused on a particular ERP known as the P200 (P2)
nism (Protopapas, 1999). As a result, models were developed            which occurs in the interval from 145 ms to 225 ms after
                                                                   2765

Figure 1: ERP repetition effects, seen in the difference between the first presentation (black line) or a word and the immediate
repetition (red line) of that word
stimulus onset and is classically associated with top-down            this paper did not set out to explore these questions in depth,
attention processes on early sensory processing (Hillyard &           we address some of them in the context of our results.
Anllo-Vento, 1998). Of particular interest, the P2 has also
been associated with a word repetition effect (Luck, 2014;                    Human Experiments and ERP Data
Molfese, Key, Maguire, Dove, & Molfese, 2005) where the
                                                                      Empirical ERP Data
P2 showed a reduced positivity (i.e., a larger negativity) to
primed versus unprimed targets. Word repetition is frequently         We collected ERP data from 12 Native English speakers from
used as an investigative tool in psycholinguistic and memory          Tufts University (mean age 19.6, 7 male), of which 2 were ex-
research. It is a simple empirical procedure which demon-             cluded due to excessive ocular artifacts. All participants self-
strates that subjects are usually faster in their response to the     reported as monolingual and right-handed (Oldfield, 1971),
second presentation of words than the first; such responses           with normal or corrected-to-normal vision/hearing and nor-
may be captured via reaction time (RT) measures across a va-          mal neurological profile. Participants provided written in-
riety of experimental paradigms such as lexical decision or           formed consent and were monetarily compensated, as ap-
semantic categorization.                                              proved by the Tufts University Institutional Review Board.
   Prior research in which participants read short texts con-
taining repeated words has found three distinct ERP compo-
                                                                      Materials and Design
nents to be sensitive to repetition: a positive component peak-       During ERP recording, participants completed a dual-task
ing around 200 ms post-stimulus, a negative component at              paradigm with a primary task of playing a video game (i.e.,
400 ms (N400) and a later positivity (van Petten, Kutas, Klu-         “Breakout”: breaking pre-arranged blocks by bouncing a ball
ender, Mitchnier, & McIsaac, 1991). However, van Petten et            from a controllable paddle) and a secondary task of listen-
al. (1991) note that the early P2 repetition effect has not been      ing to words through a set of headphones. The dual-task
consistently found in other studies, at times appearing with an       paradigm was important for our ERP modeling task because
opposite polarity. Due to the paucity of research using real-         we attempted to reduce any explicit episodic memory ef-
time speech signals and the conflicting early results cited, it       fect so that we could focus on more implicit repetition pri-
appears that the processes which control this early component         mary effects by introducing the primary task of playing a
are not well-understood. Among the research questions that            video game. For the primary task, we utilized a JavaScript
remain open are to what extent does deeper lexical processing         variant of Breakout. Three game levels were chosen based
and explicit memory influence the word repetition effect and          on pilot results, indicating them to be similar in difficulty.
what particular cognitive processes elicit this effect? While         For the secondary task, a female experimenter recorded 300
                                                                  2766

monosyllabic English words to be used in stimuli genera-
tion. These 300 words were split into two lists (of 150 words
each) matched for psycholinguistic properties (e.g., bigram
frequency, length, phonological and orthographic frequency,
familiarity, and concreteness). An additional list was created
from the two split lists (half from each) so that a total of three
lists of 150 words were created. From each of the 3 lists, 50 of
the 150 words were randomly selected to be repeated so that
each list contained a total of 200 words. None of the repeated
words were redundant across lists.
EEG Recording
Participants engaged in the dual-task paradigm in a dark,
sound-attenuated room while their EEG was recorded using a             Figure 2: Neural field training. The training vector at the
29-channel electrode cap. Loose electrodes recorded from 1)            word representation layer develops an input signal s = mi
below the left eye (LE) to monitor for blinks and vertical eye         through the modulator filter to each processing unit ui in the
movements, 2) at the right temple (HE) to monitor for hori-            neural field as a random sound exemplar of the same training
zontal eye movements, and 3) behind each mastoid (left: A1,            vector category is played to the input nodes.
right: A2) for referencing (A1) and monitoring differential
mastoid activity (A2). Electrode impedances were kept under
5 k for all scalp electrodes, 10 k for both eye electrodes, and 2      weighted connections using an on-center, off-surround “Mex-
k for both mastoid electrodes. We sampled the EEG at 200Hz             ican hat” distance function (Brady, 2014). The input nodes
while an SA Bioamplifier (SA Instruments, San Diego, CA)               carry sensory information which is refreshed with new data
amplified the signal with bandpass of 0.01 and 40 Hz.                  at each time step. This input is passed through a “driver”
                                                                       filter to develop a bottom-up input signal to the field. The
Experimental Results                                                   category nodes carry persistent labeling information which is
Averaged ERPs were formed for each spoken word (using                  passed through a “modulator” filter to provide a top-down in-
-100 and 0 ms baseline) after artifact rejection (15.67% of            put signal to the field. The labeling information is also used
the trials were rejected due to ocular artifacts) and collapsed        as the training target for a “read-out” filter.
into conditions (first presentation or repeated) for compari-              A neural field in our model is a “sheet” of processing units.
son. The ERPs were then low-pass filtered at 15 Hz. Individ-           If given no input and random initial conditions, all units of the
ual participant ERPs were then averaged into a grandmean               field are guaranteed to quickly fall into a stable equilibrium
of 10 participants, allowing for the analysis of overall audi-         state with respect to each other such that the entire field may
tory language processing effects. Of particular interest is the        be considered to fall into an equilibrium. Different equilib-
repetition effect on particular ERP components such as the             rium states of the field are associated with different input pat-
P2 (van Petten & Kutas, 1991; Rugg, 1987) with an ante-                terns. The field is updated once every 10 ms (i.e., a time step)
rior scalp distribution, sensitive to lexical processing and im-       using Equation 1 which computes the change in its activation.
plicated in word recognition processes (Dambacher, Kliegl,             This general equation and its variations are widely used in
Hofmann, & Jacobs, 2006). Such repetition effects mani-                dynamical systems models, (e.g., Amari, 1977; Beer, 2000;
fest in the form of attenuated amplitudes to repeated items            Brady, 2014; Grossberg, 2005; Hopfield, 1982; Schöner &
compared to their first presentation, reflecting the ease of pro-      Spencer, 2015).
cessing for the former relative to the latter. Results indicate
the presence of a P2 repetition effect, seen clearly in anterior                    u̇i = −ui + si + h + n + ∑ λ(i, j) · σ(u j )     (1)
electrodes between 200 and 400 ms (Figure 1).                                                                 j
                                                                           The change in activation of a unit, ui at a given time step is
                     Model Description                                 computed as the sum of influence to the unit at that time step
We modeled a single layer of the hierarchical process gen-             minus the activation of the unit from the previous time step.
erally regarded to represent the architecture of speech per-           Influence to a unit at a time step comes from an input signal,
ception (Grossberg, 2005; McClelland & Elman, 1986; Nor-               si , the field’s slightly negative bias, h, a noise term, n, and
ris, 1995). In Figure 2, the model architecture consists of            from other units within the field. Influence from other units
(1) a vector of auditory input nodes, (2) a vector of cate-            within the field is computed to be the sum of the squashed ac-
gory nodes, (3) a grid of processing units called a neural             tivations of neighboring units multiplied through correspond-
field, and (4) three fully connected sets of weights to be             ing within-field connection weights w. A stepwise squashing
trained called adaptive filters. The field processing units are        function, σ, is used such that only units with non-negative ac-
reciprocally connected to each other through non-adjustable            tivations can influence their neighborhoods. Within-field con-
                                                                   2767

nection weights are specified as on-center off-surround by a               Neural Field Model Simulations and Results
Mexican hat weighting function, λ(D). Input to the function             The model’s read-out filter is trained in order to evaluate how
D is the Euclidean distance between two units, ui and u j ; the         well the neural field categorizes its input. The weights of
output of the function specifies their connection strength.             this read-out filter are updated using the “delta rule” as in
                                                                        Equation 4. Training vectors oy are converted to target vectors
Neural Field Learning
                                                                        Ty by setting the negative values of the training vectors all to
We implemented a learning mechanism in which the driver                 zero. The generated output is notated as ô.
and modulator filters are trained together that works as fol-
lows. The filter weights are initialized with random values                                ∆wyi = η · ui · (Ty − σ(ôy ))            (4)
which are then updated across training cycles. A training cy-
cle consists of iterations in which the neural field is initialized        Where:
with random unit activations simulating the passage of time                                      ôy = ∑ wyi · mi
                                                                                                       i
between learning patterns. Then, a training vector is used to
generate an input signal si through the filters to each unit of            We selected a subset of five monosyllabic words from the
the neural field using Equation 2, and a random sound exem-             stimuli used in the empirical experiment: “beach”, “dog”,
plar of the same category as the training vector is played to           “soup”, “bog”, and “tend”. Four exemplars of each word
the input nodes as time unfolds. In our experiment, the train-          were recorded separately by a male speaker as male voices
ing vector represents a monosyllabic word. Here, oy is the              span a lower frequency range making for easier speech pro-
activation of a category node, ox is the activation of an input         cessing by the model. The recordings were transformed into
node, and g1 , g2 , g3 are gain terms; d˙i is the change in activa-     the 26 coefficients shown in Figure 2 and were provided as
tion of the driver signal, ui is the running average of the unit        input to the model in 10 ms time steps. The model was
being updated, and mi is the running average of the modulator           trained on three target words from this set, “beach”, “dog”,
signal to a unit.                                                       and “soup”. How well the model learned was measured by
                                                                        computing the error as the sum of the differences between
                     si = g1 |d˙i | · (g2 mi − g3 ui )           (2)    “readout” vector generated as output by the model and the
                                                                        corresponding target word.
                                                                        Modeling the ERP Measure
                           mi = ∑ wiy · oy
                                     y                                  We chose to model the ERP as the difference between the
                                                                        modulator signal and the field activation. This can be thought
                           d˙i = ∑ wix · ox                             of as analogous to error values or implicit prediction error.
                                     x                                  Implicit prediction error at multiple levels of language pro-
   The weights of the modulator and driver filters are adjusted         cessing is thought to play a critical role in language com-
following Equation 3, a variant of the delta training rule.             prehension (Kuperberg & Jaeger, 2015). Within probabilis-
                                                                        tic frameworks, implicit prediction error has been linked to
                                                                        other language-related components such as the N400 ERP
                    ∆wix = η · ōx · (ui − d˙i ) · |u̇i |        (3)
                                                                        (Kuperberg, 2013; Xiang & Kuperberg, 2014; Kuperberg,
                   ∆wiy = η · ōy · (ui − mi ) · |u̇i |                 2016), as well as non-linguistic ERP components (e.g., Fris-
                                                                        ton, 2005; Wagongne, Changeux, & Dehane, 2005). More-
Learning proceeds as the training vector persists for the du-           over, the N400 ERP component has recently been simulated
ration of the input sound as the neural field adjusts itself in         as cross-entropy error at a semantic level within a connection-
response to its input, updating the modulator and driver fil-           ist model (Rabovsky & McRae, 2014).
ters at each time step. Subsequently, a new iteration begins               The ERP at time t is computed as shown in Equation 5; mi
by initializing the field to a new random state and associat-           and ui are each unit’s modulator and field activation respec-
ing the transformation of that state through time with the next         tively:
input training vector (i.e., new word), and so on. A cycle is                                  ERPt = ∑ |mi − ui |                   (5)
completed when all training vectors have been exposed to the                                             i
model in random order, at which point a new training cycle
begins.                                                                 Modeling Results
   In Equation 3, η is the learning rate, (ui − d˙i ) and (ui −         The words from the test input were presented in the following
mi ) are the errors to be minimized; cyclic training continues          order: “soup”, “dog”, “dog”, “dog”, “beach”, “dog”, “bog”,
until the learning error is reduced to asymptote. The last term         “tend”. The neural field was trained on “soup”, “dog”, and
of the equation, |u̇i |, is an innovation which allows learning         “beach”; “bog” and “tend” were novel stimuli the field was
to occur only if there is a change in the target neural field           not trained on. Figure 3 shows that the model replicates the
and therefore important associations are maintained even as             repetition effects, i.e., the maximum ERP values at a t af-
learning proceeds over time.                                            ter the first exposure of the word “dog” are all smaller than
                                                                    2768

                                                                     We took the area under the ERP curve within an interval for
                                                                     the first presentation of the word “dog” and divided it by the
                                                                     identical interval contained under the repeated presentation to
                                                                     calculate its proportion. Referring to Figure 3, we also took
                                                                     the area under the ERP curve generated by the model and per-
                                                                     formed the same calculation. As shown in Table 1 we found
                                                                     that the 112 ms interval around 200 ms (i.e., from 145 ms to
                                                                     255 ms) showed both proportions to be identical i.e., 1.53,
                                                                     thus demonstrating it is possible to find a good model fit to
                                                                     the experimental data.
                                                                                               Discussion
                                                                     We designed our model to be a single neural field reflect-
                                                                     ing processing in the auditory cortex and hypothesized that
                                                                     this forms a “layer” of phonological processing. In order to
                                                                     provide a modulator signal, we simulated the existence of a
Figure 3: Modulator-Field difference for repetitions of the          deeper word-form layer by “clamping” the modulator signal
word “dog”                                                           to the three words the model was trained on (i.e., “beach”,
                                                                     “dog”, “soup”) and this was fed “down” to the neural field
                                                                     as its modulator signal. We did not presuppose which ERP
the first peak, until a different word is presented. At this         correlates would occur using only one neural field layer and
time, the neural field is perturbed into a different state, re-      did not set as a goal to identify all possible auditory effects;
leasing it from the effect. A subsequent presentation of “dog”       we were not concerned with capturing non-speech auditory
no longer elicits a repetition effect, producing a larger peak       processing at all.
as the field resettles into the equilibrium state for “dog”. In         The model succeeded in capturing the repetition effect
Equation 5, the modulator signal, mi , can be thought to “pre-       noted in the experimental results as can be seen in Figure 1,
dict” the next equilibrium state the neural field ui is likely to    most notably in the central scalp ERPs e.g., Cz. Figure 3
settle to. This suggests that a smaller amount of perturbation       shows a diminished response to the initial presentation of the
is required to “nudge” the settled field into a new equilibrium      word “dog” at 75 ms with the repetition effect occurring at
state upon presentation of a repeated word. The presentation         150 ms and 225 ms. Note that the typical convention is to
of untrained, novel stimulus, i.e., “bog” and “tend”, does not       plot the ERP, with the area above the x-axis as negative and
show the repetition effect as these words are not predicted by       the area below as positive. Thus the model and ERP wave-
the modulator signal.                                                forms covary in amplitude and polarity with the repetition
                                                                     (i.e., in the model the repetition effect is “more negative” than
                                                                     the initial presentation).
                     Table 1: Model Fitting                             The model demonstrated the immediate word repetition ef-
                                                                     fect using a single neural field sheet, without modulator in-
              Interval      Model        ERP Data
                                                                     put from deeper lexical and semantic processing layers. This
              Width       Proportion Proportion
                                                                     suggests that the ability of a single neural field layer to learn
              100 ms         1.41          1.60
                                                                     sound patterns (i.e., phonemes, monosyllabic words) alone
              112 ms         1.53          1.53
                                                                     appears to be sufficient to account for the immediate word
              120 ms         1.66          1.58
                                                                     repetition effect and the release from repetition. We believe
               Best fit (112 ms) 144 ms - 256 ms                     this to be among the first computational models to match the
                                                                     time course of ERP events on real-world, real-time data, and
   We note that model does not aim to fit the polarity of the P2     the first model to do so using spoken word perception i.e.,
ERP as what gives rise to the polarity is not well-understood        we used the same data that was presented to the experiment’s
and as there have been inconsistent reports on the word rep-         participants and validated the model fit. These results sug-
etition effect as mentioned earlier (van Petten et al., 1991).       gest that our neural field approach can now be used to build
Furthermore, it is the nature of ERP measurement that the in-        additional layers and thus model later ERPs.
terval within which a given effect is manifested varies some-
what between experimental paradigms. However, the model
                                                                                               Conclusion
should fit the magnitude and the duration of the human ERP           We have developed a dynamic neural field model of phono-
data. Thus, to compute the model fit, we looked at the ERP           logical processing of monosyllabic spoken words and com-
data intervals centered around 200 ms as this interval con-          pared it with a separately designed experiment which mea-
tains the P2 effect and computed the proportion as follows.          sured ERP responses of participants to spoken words. We
                                                                 2769

found a good fit between the model and the human ERP data.              ing comprension. In B. Miller, L. Cutting, & P. McCar-
The model succeeded at replicating the word repetition effect           dle (Eds.), Unraveling the behavioral, neurobiological, and
showing a positive correlation with the experiment’s P2 mea-            genetic components of reading comprehension (pp. 176 –
surements. This suggests that a minimal neural field model              192). Paul Brookes Publishing.
can perform some components of auditory processing (e.g.,             Kuperberg, G. R. (2016). Separate streams or probabilistic
detect immediate word repetition) and generate a correlated             inference? What the N400 can tell us about the compre-
ERP effect. Future work will explore modeling deeper lexi-              hension of events. Language, Cognition and Neuroscience.
cal and semantic processing and related mid-to-late ERP ef-             doi: 10.1080/23273798.2015.1130233
fects by connecting additional neural field layers in a hierar-       Kuperberg, G. R., & Jaeger, T. F. (2015). What do we mean
chy which will allow feedback from the deeper processes to              by prediction in language comprehension? Language,
affect computations at earlier layers.                                  Cognition and Neuroscience. doi: 10.1080/23273798.2015
                                                                        .1102299
                     Acknowledgments                                  Luck, S. J. (2014). An introduction to the event-related poten-
Research was sponsored by the U.S. Army Natick Sol-                     tial technique (2nd ed.). Cambridge, MA: The MIT Press.
dier Research, Development, and Engineering Center and                McClelland, J., & Elman, J. (1986). The TRACE model of
was accomplished under Cooperative Agreement Number                     speech perception. Cognitive Psychology, 18(1), 1–86.
W911QY-15-2-0001. The views and conclusions contained                 Molfese, D., Key, A. P. F., Maguire, M. J., Dove, G., &
in this document are those of the authors and should not be in-         Molfese, V. (2005). Event-related potentials (ERPs) in
terpreted as representing the official policies, either expressed       speech perception. In D. Pisoni & R. Remez (Eds.), The
or implied, of the U.S. Army Natick Soldier Research, De-               handbook of speech perception. Blackwell Publishing.
velopment, and Engineering Center, or the U.S. Government.            Norris, D. (1995). A dynamic-net model of human speech
The U.S. Government is authorized to reproduce and dis-                 recognition. In G. Altmann (Ed.), Cognitive models of
tribute reprints for Government purposes notwithstanding any            speech processing. Cambridge, MA: MIT Press.
copyright notation hereon.                                            Oldfield, R. (1971). The assessment and analysis of hand-
                                                                        edness: the edinburgh inventory. Neuropsychologia, 9(1),
                         References                                     97–113.
Amari, S. (1977). Dynamics of pattern formation in lateral-           Protopapas, A. (1999). Connectionist modeling of speech
   inhibition type neural fields. Biological cybernetics, 27(2),        perception. Psychological Bulletin, 125(4), 410–436.
   77–87.                                                             Rabovsky, M., & McRae, K. (2014). Simulating the N400
Beer, R. D. (2000). Dynamical approaches to cognitive sci-              erp component as semantic network error: insights from a
   ence. Trends in Cognitive Science, 4(3), 91–99.                      feature-based connectionist attractor model of word mean-
Brady, M. (2014). A bi-directional graphical model for                  ing. Cognition, 132, 68–89.
   babble-feedback learning in speech. Procedia Computer              Rugg, M. (1987). Dissociation of semantic priming, word
   Science, 41, 220–225.                                                and non-word repetition effects by event-related potentials.
Dambacher, M., Kliegl, R., Hofmann, M., & Jacobs, A.                    The Quarterly Journal of Experimental Psychology, 39(1),
   (2006). Frequency and predictability effects on event-               123–148.
   related potentials during reading. Brain Research, 1084(1),        Schöner, G., & Spencer, J. (2015). Dynamic thinking: a
   89–103.                                                              primer on dynamic field theory. New York, NY: Oxford
Elman, J. (1990). Finding structure in time. Cognitive Sci-             University Press.
   ence, 14(2), 179–211.                                              van Petten, C., & Kutas, M. (1991). Electrophysiological ev-
Friston, K. (2005). A theory of cortical responses. Philo-              idence for the flexibility of lexical processing. In G. Simp-
   sophical Transactions of the Royal Society London, Series            son (Ed.), Understanding word and sentence. Amsterdam:
   B, Biological Sciences, 360(1456), 815–836.                          North-Holland Press.
Grossberg, S. (2005). Adaptive resonance theory. In L. Nadel          van Petten, C., Kutas, M., Kluender, R., Mitchnier, M., &
   (Ed.), The encyclopedia of cognitive science (1st ed.). Wi-          McIsaac, H. (1991). Fractionating the word repetition
   ley.                                                                 effect with event-related potentials. Journal of Cognitive
Hillyard, S., & Anllo-Vento, L. (1998). Event-related brain             Neuroscience, 3(2), 131–150.
   potentials in the study of visual selective attention. Pro-        Wagongne, C., Changeux, J.-P., & Dehane, S. (2005). A
   ceedings of the National Academy of Sciences of the United           theory of cortical responses. Philosophical Transactions of
   States of America, 95(3), 781–787.                                   the Royal Society of London. Series B, Biological Sciences,
Hopfield, J. (1982). Neural networks and physical systems               360(1456), 815 – 836.
   with emergent collective computational abilities. In Pro-          Xiang, M., & Kuperberg, G. R. (2014). Reversing expec-
   ceedings of the national academy of sciences (Vol. 79, pp.           tations during discourse comprehension. Language, Cog-
   2554–2558).                                                          nition and Neuroscience. doi: 10.1080/23273798.2014
Kuperberg, G. R. (2013). The proactive comprehender: What               .995679
   event-related potentials tell us about the dynamics of read-
                                                                  2770

