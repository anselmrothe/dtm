Talking with tact: Polite language as a balance between kindness and informativity
                   Erica J. Yoon*, Michael Henry Tessler*, Noah D. Goodman, and Michael C. Frank
                                            {ejyoon, mtessler, ngoodman, mcfrank} @stanford.edu
                                                Department of Psychology, Stanford University
                                                    *Authors contributed equally to this work.
                                 Abstract                                  the record. As the degree of face-threat becomes more se-
                                                                           vere, however, a speaker will choose to be polite by producing
   Conveying information in a false or indirect manner in consid-          more indirect utterances.
   eration of listeners’ wants (i.e. being polite) seemingly contra-
   dicts an important goal of a cooperative speaker: information              In the current paper, we formalize a version of Brown and
   transfer. We propose that a cooperative speaker considers both          Levinson (1987)’s theory, exploring the idea that cooperative
   epistemic utility, or utility of providing the listener new and ac-     speakers attempt to balance two goals, epistemic and social.
   curate information, and social utility, or utility of maintaining
   or boosting the listener’s self-image (being polite). We for-           The Rational Speech Act (RSA) framework (Frank & Good-
   malize this tradeoff within a probabilistic model of language           man, 2012; Goodman & Stuhlmüller, 2013) describes lan-
   understanding and test it with empirical data on people’s infer-        guage understanding as recursive probabilistic inference be-
   ences about the relation between a speaker’s goals, utterances
   and the true states of the world.                                       tween a pragmatic listener and an informative speaker. This
                                                                           framework has been successful at capturing the quantitative
   Keywords: Politeness; computational modeling; communica-
   tive goals; pragmatics                                                  details of a number of language understanding tasks, but it
                                                                           neglects the social goals a speaker may pursue. Here we ex-
                                                                           tend RSA to take into account a speaker with both the usual
                            Introduction                                   epistemic goal and a competing social goal: be kind. We test
Your friend gives a terrible presentation and asks for your                this model by gathering data about utterance interpretations
opinion. Must you admit, “Your talk was terrible,” or is it                and goal attributions in settings where the true state of the
acceptable to say: “Your talk was fine”? The latter is poten-              world carries affective consequences for the hearer.
tially misleading but gives the listener what she might want
to hear—-in other words, it would be polite.                                                   Computational Model
   Politeness violates a critical principle of cooperative com-            Politeness poses a challenge for formal models of pragmatic
munication: exchanging information efficiently and accu-                   language understanding, which assume that speakers’ goals
rately (Grice, 1975). If information transfer was the only                 are to communicate informatively about some aspect of the
currency in communication, a cooperative speaker would                     world (Frank & Goodman, 2012; Goodman & Stuhlmüller,
find polite utterances undesirable because they are potentially            2013). RSA models a listener as reasoning about a speaker,
misleading. People are polite, however, and speakers do pro-               who chooses utterances approximately optimally given a util-
duce polite utterances. Adults and even young children spon-               ity function. Goodman and Stuhlmüller (2013) define speaker
taneously produce requests in polite forms (Clark & Schunk,                utility by the amount of information a literal listener would
1980; Axia & Baroni, 1985). Speakers exhibit politeness                    still not know about world state s after hearing a speaker’s ut-
strategies even while arguing, preventing unnecessary offense              terance w (i.e. surprisal), what we will call epistemic utility:
to their interactants (Holtgraves, 1997). Listeners even at-               Uepistemic (w; s) = ln(PL0 (s | w)), where the literal listener is a
tribute ambiguous speech to a polite desire to hide a truth that           simple Bayesian agent that takes the utterance to be true:
could hurt another’s self-image (e.g. Bonnefon, Feeney, &                                       PL0 (s | w) ∝ [[w]](s) · P(s).                  (1)
Villejoubert, 2009). In fact, it is difficult to imagine human
                                                                           Here, [[w]](s) is the truth-functional denotation of the utter-
speech that efficiently conveys only the truth. Intuitively, po-
                                                                           ance w (i.e. the utterance’s literal meaning): It is a function
liteness is one prominent characteristic that differentiates hu-
                                                                           that maps world-states s to Boolean truth values. The literal
man speech from stereotyped robotic communication, which
                                                                           meaning is used to update the literal listener’s prior beliefs
may try to follow rules to say “please” or “thank you” yet still
                                                                           over world states P(s).
lack genuine politeness.
                                                                              We propose there is a second component to the speaker’s
   Does this mean people are not cooperative communica-
                                                                           utility related to the intrinsic value of the state in the eyes of
tors? Brown and Levinson (1987) recast the notion of a co-
                                                                           the listener1 , what we will call social utility. We define the
operative speaker as one who has both an epistemic goal to
                                                                           social utility of an utterance to be the expected utility of the
improve the listener’s knowledge state as well as a social goal
                                                                           state the listener would infer given the utterance w:
to minimize any potential damage to the hearer’s (and the
speaker’s own) self-image, which they called face. In their                                   Usocial (w; s) = EPL  (s|w) [V (s)],
                                                                                                                  0
analysis, if the speaker’s intended meaning contains no threat                 1 At this point, we do not differentiate state value to the listener
to the speaker or listener’s face, then the speaker will choose            from state value to the speaker, though in many situations these
to convey the meaning in an efficient manner, putting it on                could in principle be different.
                                                                       2771

where V is a value function that maps states to subjective util-
ity values—this captures the affective consequences for the
listener of being in state s. We take the overall speaker utility
to be a weighted combination of epistemic and social utilities:
              ˆ = βepistemic ·Uepistemic + βsocial ·Usocial .
      U(w; s; β)
The speaker chooses utterances w softmax-optimally (deter-
mined by speaker rationality parameter λ) given the state s
                     ˆ
and his goal weights β:
                                                          ˆ ∝ exp(λ · E[U(w; s; β)])
                                              PS1 (w | s, β)                    ˆ                      (2)
The pragmatic listener, denoted L1 , infers the world state
based on this speaker model. We will assume the listener
                                                                                                                               Figure 2: Example of a trial in Experiment 1.
does not know exactly how the speaker weights his compet-
ing goals, however. Following the treatment of RSA using
lifted variables (Goodman & Lassiter, 2015; Bergen, Levy, &                                                        behavioral results to our model predictions, that people’s in-
Goodman, in press; Kao, Wu, Bergen, & Goodman, 2014),                                                              ferences are based on a speaker model with two utilities, epis-
we assume the pragmatic listener jointly infers the state s and                                                    temic and social.
the utility weights of the speaker, βepistemic and βsocial :
                                                                                                                                   Experiment 1: Literal semantics
                                         PL1 (s, βˆ | w) ∝ PS1 (w | s, β)
                                                                       ˆ · P(s) · P(β)
                                                                                    ˆ                  (3)
                                                                                                                   Experiment 1 measured judgments of literal meanings of our
   Within our experimental domain, shown in Figure 2 and                                                           target words. Responses in this experiment will be used to set
described in more detail below, we assume there are five pos-                                                      expected literal meanings of words in our formal model.
sible states of the world corresponding to the value placed
on a particular referent (e.g. the presentation the speaker is                                                     Method
commenting on): S = {s1 , ..., s5 }. We further assume a uni-                                                      Participants 30 participants with IP addresses in the United
form prior distribution over possible states of the world. The                                                     States were recruited on Amazon’s Mechanical Turk.
states have subjective numerical values V (si ) = α · i, where                                                     Stimuli and Design We created 13 different context items, in
α is a scaling parameter (later inferred from data). The set                                                       which someone (e.g. Ann) gave a performance of some kind
of utterances is {terrible, bad, okay, good, and amazing}.                                                         (e.g. gave a talk, performed a cello solo, baked a cookie, etc.),
We implemented this model using the probabilisitic program-                                                        and another person (e.g. Bob) evaluated it. For example, in
ming language WebPPL (Goodman & Stuhlmüller, 2014)                                                                one of the contexts, Ann baked a cake, and Bob’s true feelings
and a complete implementation can be found at http://                                                              toward Ann’s cake (“true state”) were shown on a scale out
forestdb.org/models/politeness-cogsci2016.html.                                                                    of five hearts. The question of interest was “Do you think
   In what follows, we measure the literal semantics in Ex-                                                        Bob thought Ann’s cake was [terrible, bad, okay, good, or
periment 1, then use these to predict performance in two ex-                                                       amazing]?” Each participant read 25 scenarios (5 true states
periments. In Experiment 2, we explore listeners’ inferences                                                       and 5 words). The order of context items was randomized.
about the world s given an utterance and a speaker’s goal.                                                         Procedure Participants read scenarios and indicated their an-
In Experiment 3, we investigate inferences about speakers’                                                         swer to each question by answering ‘No’ or ‘Yes’ (see Fig-
goals given an utterance and a state. Then we compare the                                                          ure 2 for a screenshot of an example trial). The experiment
      proportion accepting utterance
                                                    utterance: terrible           utterance: bad             utterance: okay              utterance: good           utterance: amazing
                                       1.00
                                       0.75
                                       0.50
                                       0.25
                                       0.00
                                                1     2     3      4      5   1   2     3     4    5   1      2    3     4     5      1    2    3     4     5   1     2     3    4       5
                                                                                                           state (1=worst)
Figure 1: Results from Experiment 1. Proportion of acceptances of words (shown in different colors) given the true state
represented on a scale of hearts. Error bars represent 95% confidence intervals.
                                                                                                            2772

can be viewed at: http://langcog.stanford.edu/expts/                                                                                     indicated their answer on a scale of five hearts. The exper-
EJY/polgrice/L2 J/polgrice L2 J.html.                                                                                                    iment can be viewed at: http://langcog.stanford.edu/
Results In this and all subsequent experiments, we analyze                                                                               expts/EJY/polgrice/L2 S/polgrice L2 S.html.
the data by collapsing across contexts. Meanings of the words
as judged by participants were as one would expect (see Fig-                                                                             Behavioral results
ure 1). Proportion of acceptances for a word given the true                                                                              Inferences of the actual rating for hearer’s performance, or
state peaked where the degree of positivity, neutrality and                                                                              the true state, varied depending on speaker’s goal and utter-
negativity of the state matched that of the word. The frac-                                                                              ance (Figure 3). Consistent with intuition, when the speaker
tion of participants that endorsed utterance w for state s will                                                                          was trying to be honest, utterances accurately mapped onto
be used as the literal meaning [[w]](s) in Eq. 1.                                                                                        inferred states (Figure 3, left, red line). For utterances consis-
                                                                                                                                         tent with the speaker’s goals (e.g. saying positive utterances
                             Experiment 2: True state inference                                                                          when the speaker was trying to be nice; negative utterances
In Experiment 2, we examined listeners’ inferences about the                                                                             when trying to be mean), the results are also consistent with
likely state of the world s given a speaker’s utterance (e.g. “It                                                                        intuition. Knowing that the speaker was trying to be nice,
was good”) and a description of the speaker’s intentions (e.g.                                                                           participants inferred a true state appreciably lower than the
the speaker wanted to be nice).                                                                                                          state inferred given honesty (green line). The reverse was
                                                                                                                                         true when the speaker was trying to be mean (blue).
Method                                                                                                                                      For utterances inconsistent with the speaker’s goals, we ob-
Participants 35 participants with IP addresses in the United                                                                             serve an interesting asymmetry. When the speaker was trying
States were recruited on Amazon’s Mechanical Turk.                                                                                       to be nice and said a negative utterance (e.g. “it was bad”),
Stimuli and Design We designed scenarios in which a per-                                                                                 participants inferred that the true state really was bad (no dif-
son (e.g. Ann) asked for another person (e.g. Bob)’s opinion                                                                             ference between an honest “bad” and a nice “bad”), perhaps
on her performance. The same context items and true states                                                                               because of a floor effect or owing to the fact that one can
as Experiment 1 were used. Additionally, we provided infor-                                                                              be nice by being honest. When the speaker was trying to be
mation on Bob’s goal (to be honest, nice, or mean) and what                                                                              mean, however, and said a positive utterance (e.g. “it was
Bob actually said to Ann (e.g. “It [your cake] was okay”),                                                                               amazing”), participants inferred a state that is worse com-
where Bob used one of the five possible words: terrible, bad,                                                                            pared to the states based on honesty and niceness goal. This
okay, good, or amazing. Then we asked participants to infer                                                                              is likely due to participants attributing sarcasm or irony to the
the true state of the world (e.g. how Bob actually felt about                                                                            speaker who was trying to be mean.
Ann’s cake). Each participant read 15 scenarios (3 goals and
5 words). The order of context items was randomized.                                                                                     Model predictions
Procedure Participants read each story (e.g. Ann baked a                                                                                 Model fitting In this experiment, participants were told the
cake and asked Bob about it) followed by a prompt that said,                                                                             speaker said w and described what the speakers’ intentions
e.g., “Bob wanted to be nice: “It was okay,” he said. How do                                                                             were (e.g. Bob wanted to be nice). We want to explore in-
you think Bob actually felt about Ann’s cake?” Participants                                                                              ferences both when speaker wanted to be nice and when he
                                           experiment                                                        experiment        model                                                                 model
                      5                                                       5
                                                                                                                                                                                              0.75
                                                                                                                                                                 Human proportion responses
                      4                                                       4
Inferred true state                                     Inferred true state
                                                                                                                                                                                                                                                          Goal
                                                                                                                                                                                              0.50
                      3                                                       3                                                                                                                                                                              honest
                                                                                                                                                                                                                                                             nice
                                                                                                                                                                                                                                                             mean
                      2                                                       2                                                                                                               0.25
                      1                                                       1
                          terrible   bad     okay           good                     terrible
                                                                                       amazing     bad terrible okay bad   good okayamazinggood   terrible
                                                                                                                                                    amazing     bad 0.00 okay                                  good       amazing
                                                                                            Utterance                                    Utterance
                                                                                                                              Goal      honest    nice   mean                                           0.00            0.25         0.50          0.75
                                                                                  Goal    honest      nice      mean
                                                                                                                                                                                                                      Model posterior predictive
Figure 3: Results from Expt. 2 (left) and model predictions (center) for average states inferred based on a speaker’s goal and
utterance. Right: Full distribution of human responses vs. model predictions. Error bars represent 95% confidence intervals for
the data and 95% highest density intervals for the model.
                                                                                                                                  2773

                                wanted to be mean: For ease of comparison to the experimen-              est” condition, the model infers the speaker was using a non-
                                tal data, we assume each β ∈ [0, 1] and separate βsocial into a          zero weight on honesty, while the overall social weight is zero
                                positive component (βnice ) and a negative component (βmean ),           (since niceness and meanness are inferred to be the same val-
                                writing the utility function now as                                      ues and they inverses of each other). For “trying to be nice”,
                                                                                                         the model puts a high weight on niceness but also some ap-
                                  U(w; s; β) = βepistemic ·Uepistemic + (βnice − βmean ) ·Usocial        preciable weight on honesty. The model fits are worse for the
                                                                                                         “trying to be mean” case; all that the model infers is that the
                                We assume that the intentions (e.g. wanted to be nice)
                                                                                                         speaker was not honest.
                                notified the listener of a particular set of goal-weights
                                                                                                            The predictions of the expectations of the listener model
                                {βnice , βhonest , βmean } that the speaker was using. We put un-
                                                                                                         for the true state (Eq. 3) are shown in Figure 3 (center). The
                                informative priors on these weights (β ∼ Uniform(0, 1)) and
                                                                                                         model’s expected posterior over states when the speaker is
                                infer their credible values separately for each goal condition
                                                                                                         trying to be honest increases as a function of the positivity
                                (“trying to be X”) using Bayesian data analytic techniques
                                                                                                         implied by the utterances (e.g. “amazing” means a very high
                                (Lee & Wagenmakers, 2014).
                                                                                                         state). When it knows the speaker was trying to be nice, the
                                   There are 2 additional parameters of the cognitive model:
                                                                                                         pragmatic listener is more conservative in how it interprets
                                the speaker optimality parameter λ in Eq. 2 and the value
                                                                                                         positive utterances, with the difference between an honest ut-
                                scale parameter α in the utility function. We put unin-
                                                                                                         terance and a nice utterance increasing as the utterance be-
                                formative priors on these (λ ∼ Uniform(0, 20) and α ∼
                                                                                                         comes more positive. For example, the difference between a
                                Uniform(0, 5)) and infer their posterior credible values from
                                                                                                         nice “amazing” and an honest “amazing” is greater than the
                                the data. We ran 2 MCMC chains for 100,000 iterations,
                                                                                                         difference between a nice “okay” and an honest “okay”. In-
                                discarding the first 50,000 for burnin. The Maximum A-
                                                                                                         ferences when the speaker is trying to be mean display the
                                Posteriori (MAP) estimate and 95% Highest Probability Den-
                                                                                                         associated opposite behavior when the utterance is indeed
                                sity Interval (HDI) for λ is 1.4 [0.9, 8.5]; for α is 6.4 [1.9,
                                                                                                         negative (e.g. “terrible”). Overall, the expected values of
                                9.9]. To generate predictions, given our cognitive model and
                                                                                                         the model explain a lot of the variance in the average data
                                the inferred parameters, we evaluated the posterior predictive
                                                                                                         r2 (15) = 0.91. The main discrepancies are with the goal
                                distribution, marginalizing out all parameters.
                                                                                                         “trying to be mean”, as noted above. Among the other 2
                                Results The inferred weights for each goal condition were
                                                                                                         goal conditions, the model explains almost all of the variance
                                largely as expected (Figure 4). For the “trying to be hon-
                                                                                                         r2 (10) = 0.97.
                                                                                                            The model makes predictions not only for the average data
                                                 3                                                       but also for the full distribution of responses (Figure 3, right).
                                                                                                         The model predicts the full distribution with relatively high
                                                 2                                                       accuracy r2 (75) = 0.74.
                                                                                                            honest
                                                                                                            In sum, the model captured key aspects of our empirical
                                                 1                                                       findings. The largest discrepancies appear in the experimen-
                                                                                                         tal condition of the goal to be mean. Participants thought that
                                                 0                                                       a mean speaker saying “[your cake] was amazing” meant the
                     3
                                                 3                                                       true state was below average, which the model was unable
                                          posterior density
                     2                                                                     Goal          to accommodate. This deviation is likely due to the effect
                                                 2                                   honest     honesty of irony: making an extremely positive remark about an ex-
                     1                                                                          niceness    nice
                                                                                                         tremely bad performance is perceived to be sarcastic and ill-
                                                 1                                                       intentioned (Colston, 1997). Our model does not include sar-
                                                                                                meanness
                     0                                                                                   castic interpretation though other models in the RSA family
                                                 0                                                       do (Kao & Goodman, 2015), and future work should address
                     3
posterior density
                                                                        Goal                             the delicate interplay of politeness and sarcasm.
                     2                                                                         honesty
                                                              20                                                                   Experiment 3: Goal inference
                                                                                     nice      niceness
                     1                                                                                      mean        Experiment 3 probed listeners’ inferences of the speaker’s
                                                              10                               meanness
                                                                                                                        goals, given an utterance (e.g. “It was good”) and a true state
                     0                                                                                                  (e.g. 2 out of 5 hearts).
                                                               0
                                                                   0.00     0.25      0.50    0.75   1.00               Method
                    20                                               Inferred speaker goal weight                       Participants 45 participants with IP addresses in the United
                                                                                     mean
                                                                                                                        States were recruited on Amazon’s Mechanical Turk.
                    10
                                Figure 4: Inferred goal weights β for Expt. 2. Facets are dif-                          Stimuli and Design We presented the same context items and
                                ferent experimental conditions (trying to be X). Density plots                          utterances as Experiment 2. But instead of goals, we pro-
                                show likely weights used in the speaker’s utility function.                             vided information on the true states (i.e. how Bob actually
                     0
                         0.00      0.25          0.50                0.75     1.00
                           Inferred speaker goal weight
                                                                                                                     2774

                                  utterance: terrible           utterance: bad           utterance: okay             utterance: good       utterance: amazing
                       1.00
                       0.75
                                                                                                                                                                experiment
                       0.50
 likelihood for goal
                       0.25                                                                                                                                                  Goal
                                                                                                                                                                                honest
                       0.00
                       1.00                                                                                                                                                     nice
                                                                                                                                                                                mean
                       0.75
                       0.50                                                                                                                                     model
                       0.25
                       0.00
                              1      2    3     4       5   1    2    3    4     5   1     2    3      4   5     1     2   3    4      5   1   2   3    4   5
                                                                                               state
Figure 5: Results from Expt. 3 (top) and model predictions (bottom). Attribution of speaker’s goals: honest, nice and mean
(colors) based on the true state and utterance. Error bars represent 95% CIs for the data and 95% HDIs for the model.
felt towards Ann’s performance). Then we asked participants                                                the true state of the world given in the experimental condi-
to infer the likelihood of Bob’s goals to be honest, nice, and                                             tion, and compare the marginal distribution of the speaker’s
mean. Each participant read 25 scenarios (5 true states and 5                                              goals β to the empirical ratings. We separate βsocial into βnice
words). The order of context items was randomized.                                                         and βmean , as in Expt. 2. With no prior knowledge about the
Procedure Participants read each scenario followed by a                                                    speaker’s intentions, we assume a uniform prior over the goal-
question that read, “Based on what Bob said, how likely                                                    weights in the speaker’s utility function: β ∼ Uniform(0, 1).
do you think that Bob’s goal was to be: honest; nice;                                                         We put the same priors over the speaker optimality param-
mean,” with the three goals placed in a random order be-                                                   eter λ and the value scale parameter α. We ran 2 MCMC
low three slider bars, on which the participant could in-                                                  chains for 40,000 iterations, discarding the first 20,000 for
dicate each goal’s likelihood. The experiment can be                                                       burnin. The MAP estimate and 95% HDI for λ is 3.8 [3.1,
viewed at: http://langcog.stanford.edu/expts/EJY/                                                          4.9]; for α is 1.4 [1.23, 1.53].
polgrice/L2 G/polgrice L2 G.html.
                                                                                                           Results The predictions of the model are shown in Fig-
Behavioral results                                                                                         ure 5 (bottom). Like our participants, the model believes the
Participants rated speaker’s goals differentially depending on                                             speaker to be more honest when the utterance matches the
the true state and utterance (see Figure 5, top). Honesty was                                              true state of the world, as given by the literal semantics data
rated highest when the true state was most consistent with the                                             (Figure 5, red lines). Further, the model increases its ratings
literal semantics. As utterances became more positive, partic-                                             of niceness as the utterance better matches states with higher
ipants rated the speaker’s niceness higher and meanness dis-                                               values (green lines, main effect of panel). The goal to be
played the reverse pattern. Ratings for niceness and meanness                                              mean displays the opposite behavior, increasing as the utter-
goals were strongly anti-correlated r = −.78.                                                              ance matches states with lower values (blue lines). Overall,
   Interestingly, we observe an asymmetry in how positive                                                  the model displays a strong quantitative fit to the goal infer-
and negative utterances map onto the goals of niceness and                                                 ence data r2 (75) = 0.82.
meanness, respectively. Participants reported that truthfully                                                 The model successfully captured the key patterns in the
saying “amazing” is both honest and nice, while truthfully                                                 data: changing goal likelihoods based on the degree of match,
saying something is “terrible” is honest and not that mean.                                                and positivity/negativity bias of mismatch, between the ut-
Here, meanness can decrease in likelihood (i.e. be explained                                               terance and true state. The biggest mismatch seems to be
away) because of honesty. And yet honesty does not explain                                                 that the model under-predicts the goal to be honest for every
away niceness when the speaker says a truthful “amazing”.                                                  utterance except okay. This may be because explicitly posi-
                                                                                                           tive/negative utterances can also be explained by a social goal
Model predictions                                                                                          in the model. The model also does not capture the interaction
Model fitting The model in Eq. 3 specifies a joint-belief dis-                                             that a truthful positive utterance is both honest and nice, while
tribution over the speaker’s goals β and possible states of the                                            a truthful negative utterance is honest and not that mean. The
world s. To compare to the empirical data, we condition on                                                 model treats niceness and meanness as perfectly opposite to
                                                                                                       2775

each other, while there is an interesting asymmetry in partic-                           Acknowledgments
ipants’ behavior. This asymmetry may be because listeners             This work was supported by NSF grant BCS #1456077 to
expect honesty and niceness to be correlated a priori, and            MCF, ONR grant N00014-13-1-0788 and a James S. McDon-
anti-correlated with meanness, rather than independent as as-         nell Foundation Scholar Award to NDG, NSF Graduate Re-
sumed by the model.                                                   search Fellowship DGE-114747 to MHT, and NSERC post-
                                                                      graduate doctoral scholarship PGSD3-454094-2014 to EJY.
                           Discussion
                                                                                              References
Why would a speaker ever say something that is not maxi-              Axia, G., & Baroni, M. R. (1985). Linguistic politeness at
mally truthful and informative? Communication is often ex-              different age levels. Child Development, 918–927.
amined from the perspective of successful information trans-          Bergen, L., Levy, R., & Goodman, N. D. (in press). Prag-
fer from speaker to listener. In the social realm, however,             matic reasoning through semantic inference. Semantics &
communication also can serve the social function of making              Pragmatics.
the listener feel good and saving her face.                           Bonnefon, J.-F., Feeney, A., & Villejoubert, G. (2009). When
   We proposed here that intuitively “polite” utterances arise          some is actually all: Scalar inferences in face-threatening
from the desire to be kind (i.e. save face). A cooperative              contexts. Cognition, 112(2), 249–258.
speaker then tries to balance the goals to be kind and to be in-      Brown, P., & Levinson, S. C. (1987). Politeness: Some uni-
formative, and produces utterances of varying degrees of po-            versals in language usage (Vol. 4). Cambridge Univ. Press.
liteness that reflect this balance. To test this proposal, we ex-     Clark, H. H., & Schunk, D. H. (1980). Polite responses to
amined inferential judgments on a speaker’s utterance, which            polite requests. Cognition, 8(2), 111–143.
was a potentially face-threatening evaluation of the listener’s       Colston, H. L. (1997). Salting a wound or sugaring a pill:
performance. As we predicted, participants’ inferences about            The pragmatic functions of ironic criticism. Discourse Pro-
the true state of the world differed based on what the speaker          cesses, 23(1), 25–45.
said and whether the speaker’s intended goal was to be hon-           Frank, M. C., & Goodman, N. D. (2012). Predicting prag-
est, nice or mean (Expt. 2). We were also able to predict               matic reasoning in language games. Science, 336(6084),
participants’ attributions of different social goals to speakers        998–998.
depending on how well the literal utterance meaning matched           Goodman, N. D., & Lassiter, D. (2015). Probabilistic seman-
the actual rating the performance deserved (Expt. 3).                   tics and pragmatics: Uncertainty in language and thought.
   The model presented here relates to other work done in               In S. Lappin & C. Fox (Eds.), The handbook of contempo-
game-theoretic pragmatics. Van Rooy (2003) uses a game-                 rary semantic theory, 2nd edition. Wiley-Blackwell.
theoretic analysis of polite requests (“Could you possibly take       Goodman, N. D., & Stuhlmüller, A. (2013). Knowledge
me home?”) to argue the purpose of polite language is to align          and implicature: Modeling language understanding as so-
the preferences of interlocutors. Our notion of social utility          cial cognition. Topics in Cognitive Science, 5.
Usocial is similar in that it motivates speakers to signal worlds     Goodman, N. D., & Stuhlmüller, A. (2014). The Design and
that make the listener feel good. Van Rooy’s analysis, how-             Implementation of Probabilistic Programming Languages.
ever, relies on the notion that polite language is costly (in a         http://dippl.org.
social way e.g., by reducing one’s social status or incurring         Grice, H. P. (1975). Logic and conversation. In Readings in
social debt to one’s conversational partner) but it’s not clear         language and mind. Blackwell.
how the polite behaviors explored in our experiments (not po-         Holtgraves, T. (1997). Yes, but... positive politeness in con-
lite requests) would incur any cost to speaker or listener. Our         versation arguments. Journal of Language and Social Psy-
model derives its predictions by construing the speaker utility         chology, 16(2), 222–239.
as a collection of possible goals (here, epistemic and social         Kao, J. T., & Goodman, N. D. (2015). Let’s talk (ironically)
goals). The speech-acts themselves are not costly.                      about the weather: Modeling verbal irony. In Proceedings
                                                                        of the 37th annual conference of the Cognitive Science So-
   Will machines ever be polite? Politeness requires more
                                                                        ciety.
than merely saying conventionalized words (please, thank
                                                                      Kao, J. T., Wu, J. Y., Bergen, L., & Goodman, N. D. (2014).
you) at the right moments; it requires a balance of informa-
                                                                        Nonliteral understanding of number words. Proceedings of
tivity and kindness. Politeness is not an exception to ratio-
                                                                        the National Academy of Sciences, 111(33), 12002–12007.
nal communication; it is one important element of rational
                                                                      Lee, M. D., & Wagenmakers, E. J. (2014). Bayesian cognitive
communication, serving a key social function of maintaining
                                                                        modeling: A practical course. Cambridge Univ. Press.
relationships. We extended the Rational Speech Acts frame-
                                                                      Van Rooy, R. (2003). Being polite is a handicap: Towards a
work to include social utility as a motive for utterance pro-
                                                                        game theoretical analysis of polite linguistic behavior. In
duction. This work takes a concrete step toward quantita-
                                                                        Proceedings of the 9th conference on theoretical aspects of
tive models of the nuances of polite speech. And it moves us
                                                                        rationality and knowledge (pp. 45–58).
closer to courteous computation—to computers that commu-
nicate with tact.
                                                                  2776

