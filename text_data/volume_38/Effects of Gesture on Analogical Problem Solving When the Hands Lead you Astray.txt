Effects of Gesture on Analogical Problem Solving:
When the Hands Lead You Astray
Autumn B. Hostetter (Autumn.Hostetter@kzoo.edu)
Department of Psychology, 1200 Academy Street
Kalamazoo, MI 49006 USA

Mareike B. Wieth (mwieth@albion.edu) and Katlyn D. Foster
Department of Psychological Science,
Albion, MI USA

Keith Moreno and Jeffery Washington
Department of Psychology, 1200 Academy Street
Kalamazoo, MI 49006 USA

Abstract
We investigated the role of speech-accompanying gestures in
analogical problem solving. Participants attempted to solve
Duncker’s (1945) Radiation Problem after reading and retelling a
story that described an analogous solution in a different domain.
Participants were instructed to gesture, instructed not to gesture, or
given no instructions regarding gesture as they retold the story.
Participants who were instructed to gesture as they retold the
analogous story were more likely to mention perceptual details in
their description and less likely to apply the analogous solution to
the problem than participants who were instructed not to gesture.
These results suggest that gestures can be detrimental to analogous
problem solving when the perceptual elements of a story are
irrelevant to its schematic similarity with a problem.
Keywords: gesture; analogical reasoning; problem solving

Introduction
Analogical problem solving involves using an analogous
source, such as a military story about a general overtaking a
fortress by dividing his troops, to solve a target problem,
such as Duncker’s (1945) Radiation problem in which rays
are divided to bombard a tumor (e.g., Gick & Holyoak,
1980). One of the most difficult steps in analogical problem
solving is noticing that there is a connection between the
source story and target problem. Noticing the connection is
particularly difficult when the source and the target are from
different domains (e.g., a military story and a medical
problem) and involve very different objects (e.g., armies and
fortresses vs rays and tumors) (see Anolli, Antonietti,
Crisafulli, & Cantola, 2001). In order to notice the
connection despite such differences, problem solvers must
schematitize the goals and relations between objects in each
(Gentner & Smith, 2013). A military story can be applied
more easily to a medical problem if both are being
considered as instances where there are similar goals (e.g.,
overcoming a centrally located target) and possible means
(e.g., dividing).
Such schema formation is more likely the less problem
solvers focus on the objects involved in any particular

source. Encountering multiple source stories, for example,
increases the likelihood that a schema will be formed (Gick
& Holyoak, 1983) as does seeing an informative diagram
depicting the important features of the schema (Beveridge &
Parkins, 1987; Chen, 1995). Moreover, pictures depicting a
solution to a target problem are only helpful to problem
solvers when they contain the same objects as those
involved in the problem (Chen, 1995), perhaps because they
cue participants that there is a similarity and encourage the
formation of a schema that can apply to both target and
source. In contrast, when the objects in the source are
different from those in the target problem, focusing on those
objects deters from noticing the connection with the target
(Chen, 1995; Keane, 1987) and prevents participants from
forming a schema that is applicable to both target and
source.
While focusing on the objects in a source can be
detrimental to problem success in a different domain,
activating kinesthetic information that embodies the relevant
schema (e.g., dividing, converging) can be beneficial.
Catrambone, Craig, and Neressian (2006) found that acting
out the military story with wooden blocks increased the
likelihood of noticing the connection to the radiation
problem. They argue that acting out the story with blocks
encouraged the formation of a schema that included
kinesthetic information about converging forces, and was
therefore more general than a direct representation of the
objects involved in the military story. Further, kinesthetic
information can encourage schema formation even when
there is no source story at all (Thomas & Lleras, 2007;
2009). Thomas and Lleras (2007) found that participants
were more likely to solve the radiation problem when they
produced eye movements in an unrelated task that mirrored
the problem’s solution (crossing in and out from the skin to
the tumor many times, as multiple smaller rays would do)
than when they produced unrelated eye movements.
It appears then that body movements can affect whether
a problem solver forms a schema that can be applied to the
radiation problem. In the present study, we explore the

1685

effects of a very specific kind of body movement in
analogical problem solving – representational gestures.
Representational gestures, hereafter simply gestures, are
movements of the hand and body that coincide with speech.
Gestures are actions, in that they involve the movement of
the body; however, as has been argued by Goldin-Meadow
and Beilock (2010), they are more than actions, too, because
they represent ideas in a way that actions often do not.
Gestures have been described as outward manifestations of
mental representations that are deeply rooted in the
sensorimotor system (Hostetter & Alibali, 2008). When
speakers produce gestures, they are using their motor system
to represent an idea that is already drawing on the
perceptual system (Hostetter & Skirving, 2011). Thus,
producing gestures is a natural consequence of the high
involvement of the sensorimotor system in concept
representation (e.g., Glenberg, 2010).
Further, there is increasing evidence that producing a
gesture is not only epiphenomenal, but can actually
strengthen underlying perceptual representations in the
speaker’s mind (e.g., Cook, Yip, & Godin-Meadow, 2010)
and make it more likely that gesturers will focus on
perceptual information as they solve problems. For example,
children who gesture as they solve Piagetian conservation
problems are more likely to describe perceptually present
aspects of the stimuli (e.g., the height of the objects) than
when they do not gesture (Alibali & Kita, 2010). In
addition, Alibali, Spencer, Knox, and Kita (2011) found that
adults who gestured while solving problems about gear
movements were more likely to perseverate on perceptual
and motor strategies than speakers who did not gesture.
Because gestures strengthen underlying perceptual
representations in the speaker’s mind, they have the
potential to help or hurt schema formation, just as focusing
on objects more generally can either help or hurt (Chen,
1995). When the objects being gestured about are relevant
to a problem, gestures may strengthen problem solvers’
focus on those objects, thereby making it more likely that
they will notice a connection with the problem and form a
schema that can be applied to both. On the other hand, when
the objects being gestured about are irrelevant to a problem,
strengthening the perceptual representations of those objects
may make it harder for participants to look past the
differences between the source and the target in order to
form a schema that can be applied to both (i.e., a fortress
and a tumor).
In support of this, Beilock and Goldin-Meadow (2010)
found that participants who gestured about the weight of the
discs during an explanation of their solution to the Tower of
Hanoi had more trouble solving a new version of the
problem when the disc weights had been changed than
participants who did not gesture. Although the solution
process is the same regardless of the weight of the discs
involved, by gesturing about the disc weights, problem
solvers strengthened the representation of weight in their
mind, thereby making it more difficult to generate a schema
about how to solve the Tower of Hanoi that was

independent of this perceptual element. Similarly,
Cooperrider and Goldin-Meadow (2014) found that
speakers who gestured during an explanation of a source
story were less likely to solve an analogous problem than
those who did not gesture. However, they did not directly
manipulate gesture in their study, making it difficult to
know if the presence of gesture was a side effect of already
rich perceptual representations or actually a causal
mechanism that focused speakers’ representations on
perceptual elements.
In the present experiment, we examine whether
gesturing about a source story affects the likelihood that a
problem solver will notice the connection to a target
problem in a different domain. If gestures are much like
other kinds of actions, then they should encourage a
representation of the source story that is schematic, thereby
improving the likelihood of noticing the connection between
the source and the problem. Much like the eye movements
studied by Thomas and Lleras (2007) and the acting-onblocks movements studied by Catrambone et al. (2006),
producing speech accompanying gestures about the military
story could encourage speakers to form a schematic
representation of converging forces that in turn makes it
easier to notice the similarity with a medical problem. On
the other hand, if gestures are different from actions because
of their tight connection to perceptual ideas (e.g., GoldinMeadow & Beilock, 2010; Hostetter & Alibali, 2008),
gesturing about the military story could encourage a
representation that is less schematic and more focused on
the specific objects present in the source story. Under this
view, gesturing may make it less likely that speakers will
schematitize the source story, and thus less likely that they
will notice its similarity with the problem.
To examine these two competing hypotheses, we gave
participants multiple attempts to solve Duncker’s (1945)
Radiation problem. In between attempts, participants read
and retold an analagous military story, under the ruse of
participating in an unrelated study. Participants were either
instructed to gesture, instructed not to gesture, or given no
instructions regarding gesture during their retells.

Method
Participants
The final sample consisted of 72 undergraduates (44
female) at two small colleges who volunteered to participate
in exchange for extra credit. An additional 20 participants
were not included because the participant solved the
radiation problem during the pre-check (before having a
chance to tell the story), the experimenter made a mistake in
the protocol, or the camera was not positioned well enough
to capture the participants’ gestures during the retells.

Stimuli
The military story. The story, taken from Gick and
Holyoak (1980), describes a general who raises an army to
overtake a fortress located in the center of a town. The

1686

general learns that there are mines on all of the roads
approaching the fortress. The mines will detonate if any
large group of people crosses, but small groups of people
can pass safely. The general splits his army into smaller
groups that approach the fortress via different roads. The
groups are not large enough to detonate the mines, but
together, they are large enough to overtake the fortress when
they converge in the center. Because speakers are more
likely to gesture when they have seen an image of what they
are describing (e.g., Hostetter & Skirving, 2011), the story
was printed with a picture underneath the text of the fortress
surrounded by roads.
The medical problem. Each participant was presented
with Duncker’s (1945) radiation problem. Briefly, the
problem describes an inoperable tumor that can be
destroyed with a certain kind of ray. However, at sufficient
intensities to destroy the tumor, the ray will also destroy the
healthy tissue around the tumor. Participants are asked to
think of possible ways to destroy the tumor with the ray
without affecting the healthy tissue. Although there are
several possible solutions to the problem, we were only
interested in the convergence solution that is suggested by
the military story. Specifically, the ray can be split into
several smaller rays that can pass safely through the healthy
tissue, but still converge on the tumor with enough intensity
to destroy it.

Procedure
Participants arrived individually and were told that the
study was about the effects of taking breaks on problem
solving. Participants first had 3 minutes to attempt to solve
the medical problem as a pre-check to make sure that they
did not already know the solution, either because others had
told them about it or because they had encountered it in a
course or in another study. Participants who generated the
convergence solution during the pre-check were not
included in the study.
Following the pre-check, those participants who had not
generated the convergence solution were told that they
would be given a break before attempting the problem
again. During the break, they would be involved in another
study about how people remember and communicate
information. Participants were told that they would retell a
story in their own words to a video camera. They then spent
two minutes reading the military story.
Participants were then randomly assigned to one of three
conditions. In the Instructed Gesture condition, participants
were told to include hand gestures to depict important
aspects of the story. In the Restricted Gesture condition,
participants were told that, while they might be tempted to
include hand gestures to depict important aspects of the
story, they should not do so. The experimenter suggested
that participants sit on their hands to remind themselves not
to gesture. In the No Instruction condition, the experimenter
did not mention gesture in the instructions and simply told
participants to include important aspects of the story as they
retold it. In all three conditions, the experimenter produced

the same scripted hand gesture when delivering the
instructions.
In all conditions, participants took as long as they
wanted to retell the story. When they were finished, they
were given another 3 minutes to generate solutions to the
medical problem. The experimenter left the room during this
time.
Upon returning, the experimenter asked the
participants to explain their solutions to the problem. If
participants described the convergence solution, their
experimental session was ended and they were debriefed.
If they did not describe the convergence solution, they
were told that they would have one more opportunity to
solve the problem after taking another short break, during
which they would retell the military story a second time to
the video camera. Participants were reminded of their
gesture instructions before beginning. Participants were then
given three more minutes to generate solutions to the
medical problem. Although this procedure differs from the
original protocol pioneered by Gick and Holyoak (1980),
giving participants multiple opportunities to retell the story
and work on the problem is similar to the procedure of other
studies that have found an effect of movement on problem
solving (e.g., Thomas & Lleras, 2009).

Results
All participants who were instructed to gesture as they
retold the military story produced at least one
representational gesture (n = 25). In addition, 20 of the 22
participants who were given no instructions regarding
gesture spontaneously gestured as they retold the story, and
3 of the 25 participants who were told not to gesture
produced at least one representational gesture despite having
been asked not to. For all analyses reported here, the three
individuals who did not follow the gesture restriction
instructions have been excluded. We had hoped that more
participants in the no instruction condition would
spontaneously choose not to gesture, thereby allowing a
comparison of those who gesture

Figure 1. The proportion of participants in each condition
who successfully generated the convergence solution to the
Radiation problem after each retelling of the General story.

1687

Table 1. Percentage of participants in each condition who mentioned each spatial element in their retelling of the story
Element
Gesture Instructed Spontaneous Gesture Gesture Restricted
χ2
Fortress is centrally located
68
45
32
6.34*
Roads radiate outward
52
40
54
1.00
Army is large
52
15
27
7.36*
Army split into smaller groups
84
85
82
0.08
Groups come from different directions
68
70
32
8.29*
Groups meet in the middle
11
0
14
2.84
Note. * p < .05
spontaneously and those who do not. However, given that
all but two participants in the no instruction condition
gestured, such an analysis is not possible. We have therefore
eliminated the two individuals who did not gesture in the no
instruction condition from further analysis. Thus, the
comparisons reported here are between participants who did
not gesture after being instructed not to (n = 22),
participants who gestured after being instructed to (n = 25),
and participants who gestured spontaneously with no
gesture instructions (n = 20).
Figure 1 shows the cumulative proportion of
participants in each condition who generated the
convergence solution to the medical problem following each
retell. We analyzed the data in a mixed logistic regression
model that included condition (Instructed Gesture,
Restricted Gesture, No Instruction) as a fixed factor and
college as a random intercept. Because gesture condition
was manipulated between subjects and each participant only
solved one problem, subject is not included as a random
effect. We included a random intercept for college but not
slope because the model failed to converge when slope was
included.
For solution success after the first retell, there was no
significant effect of condition, χ2(2, N = 67) = 4.78, p = .09.
However, there was a significant effect of condition when
considering success rate overall, χ2(2, N = 67) = 6.75, p =
.03. Participants who were instructed not to gesture were
twice as likely (68%) to generate the convergence solution
to the medical problem by the end of the experiment than
participants who were instructed to gesture (32%), β = 1.64,
SE = 0.65, z = -2.51, p = .01. Participants who gestured
spontaneously had a solution rate (50%) intermediate to and
not significantly different from the other two groups.
Our hypothesis is that participants who gesture are less
likely to solve the problem because of an increased focus on
spatial and perceptual aspects of The General Story. To test
this hypothesis, we coded each participant’s retells for
whether they mentioned six specific perceptual details
regarding the spatial layout of the story (see Table 1). A
one-way analysis of variance revealed significant
differences in the total number of spatial details mentioned
by participants during their retells across the three
conditions, F(2, 66) = 3.89, p = .025. Participants who were
instructed to gesture included significantly more spatial
details in their retells than participants who were instructed
not to gesture or participants who gestured spontaneously.
As can be seen in Table 1, participants who were instructed

to gesture were more likely than other participants to
mention that the fortress was centrally located, that the army
was large, and that the small armies approached the fortress
from different roads. As predicted, instructing participants
to gesture appears to increase the attention they pay to
spatial details of the story as they are retelling it.
Interestingly, however, participants who chose to gesture
spontaneously, without specifically being told to gesture,
did not focus on spatial details any more than participants
who were told not to gesture.
Given that participants who were instructed to gesture
were also the most likely to describe spatial details in their
story, could their decline in success on the problem be due
to their spatially rich descriptions, rather than to the gestures
that accompanied them? In particular, two of the spatial
details are analogous to the key transformations involved in
the dispersion solution to The Radiation Problem: the army
is split into multiple smaller armies and the smaller armies
approach the fortress from different roads. To examine the
possibility that it is mentioning these details, rather than
gesturing about them per se, that affects problem success,
we ran mixed logistic regression models predicting problem
success based on whether each detail was mentioned. There
was no effect for either detail (split: χ2(1, N = 67) = 0.53, p
= .47; approach: χ2(1, N = 67) = 0.06, p = .80). It appears
that mentioning these details is not predictive of problem
success.
Finally, we more closely examined the gestures produced
by participants to see if gesturing about particular concepts
affected problem success. We coded the gestures produced
by participants for whether they represented one of two
concepts that are important to the dispersion solution:
multiplicity and convergence. A gesture was coded as
representing multiplicity when it indicated multiple places
in space either by using two hands simultaneously or
alternately or by using one hand sequentially to indicate
three or more points in space. Such gestures typically
occurred in the context of describing the multiple roads
around the fortress or the many small army groups. A
gesture was coded as representing convergence if it
indicated moving towards the center from multiple radial
locations, either by moving two hands inward
simultaneously, by moving one hand from radial to center
multiple times, or by drawing the fingers of one hand
inward. These gestures occurred most often with speech
about the armies moving towards the fortress along the
different roads.

1688

We considered whether each participant produced a
gesture about multiplicity or about convergence in separate
mixed logistic regression models. Although not significant
by conventional standards, participants who gestured about
the concept of multiplicity were less likely to solve the
problem than participants who did not, χ2(1, N = 67) = 3.68,
p = .06. Specifically, participants who gestured about
multiplicity as a result of being told to gesture had worse
performance than participants who were told not to gesture,
χ2(1, N = 47) = 4.92, p = .03. In contrast, participants who
gestured about multiplicity spontaneously did not differ
from those who were told not to gesture, χ2(1, N = 42) =
1.32, p = .25. The same pattern emerged when convergence
gestures were considered; participants who gestured about
the concept of convergence were significantly less likely to
solve the problem than participants who did not, χ2(1, N =
67) = 4.32, p = .04, but the effect is specific to individuals
who were told to gesture compared to those who were told
not to gesture, χ2(1, N = 47) = 7.23, p = .007. There is no
difference in solution rate between those individuals who
spontaneously gestured about convergence and those who
were told not to gesture, χ2(1, N = 42) = 0.72, p = .40.

Discussion
Being instructed to gesture about the military story
reduced the likelihood that participants would generate the
convergence solution to the medical problem. We posit that
this effect occurred because speakers who were told to
gesture were particularly likely to focus on the objects
involved in the military story, a focus that made it more
difficult to form a schema that could also be applied to the
medical problem. Indeed, speakers who were told to gesture
were more likely to mention specific spatial details about
the objects in their description than other participants.
The difference between spontaneously producing a
gesture and producing a gesture after being instructed to do
so is noteworthy. Previous research showing the effects of
gesture on problem solving has not specifically compared
the effects of gestures that were instructed with those that
were spontaneous, though in many of these studies,
participants were specifically instructed to use their hands
during the explanation task (e.g., Beilock & GoldinMeadow, 2010). It appears that, at least in the case of
analogical problem solving studied here, being instructed to
gesture produces or exaggerates the effect. There are several
reasons why this could occur.
First, being told to gesture likely makes participants
more consciously aware of their gestures. Having the
conscious intention to produce a gesture could strengthen
the underlying mental simulation that gives rise to gesture
(e.g., Hostetter & Alibali, 2008). As a result, speakers who
intentionally gesture may have richer mental representations
that are more strongly grounded in perceptual and motor
simulations than speakers who avoid gesturing or who
gesture without thinking about it. Alternatively, there may
be differences in the cognitive effects after the gesture is

produced. Goldin-Meadow and Beilock (2010) argue that
gestures bring perceptual information to the forefront of
speakers’ thinking; this may only occur when speakers are
consciously aware of their gestures, as when they have
specifically been told to produce them.
Regardless of why being told to gesture hurts, the
present results suggest that speech-accompanying gestures
do not have the same effect on problem solving as the
movements studied by Thomas and Lleras (2007, 2009) or
the actions studied by Catrambone et al. (2006).
Specifically, Thomas and Lleras found that eye movements,
movements that did not represent any particular concept,
aided problem solving in their studies. However, speechaccompanying gestures are different from these movements
because gestures are meaningful to the speaker; in order to
be produced, they must represent something. When a
speaker produces a gesture about the concept of multiple
roads radiating outward from the fortress, the gesture
corresponds to the specific mental image the speaker has in
mind. Thus, as Goldin-Meadow and Beilock (2010) argue,
gestures are a special kind of action. By virtue of
representing images, gestures act to strengthen those images
in the speaker’s mind, and can make it more difficult to
form a general schema that transcends the objects
represented in those particular images.
Our results are also different from the findings of
Catrambone et al. (2006), who found that acting out the
military story using blocks aided analogical problem solving
over simply retelling the story. In contrast, acting out the
story using gestures in the present study impaired analogical
problem solving. There are of course many methodological
differences between the two studies that could account for
the difference in findings, but there may also be a
meaningful difference between the gestures studied here and
the block movements studied by Catrambone et al. Using
blocks to act out the story requires that the storytellers think
abstractly about how the story elements can be represented
with blocks, which may encourage thinking schematically
about the relational elements of the story rather than the
objects. In contrast, producing gestures about the story
elements may not require the storyteller to engage in an
abstract mapping between story and hand because gestures
are used so ubiquitously and automatically to express
meaning (e.g., Hostetter & Alibali, 2008).
Finally, it is possible that rather than gestures being
detrimental to problem success, the act of not gesturing was
beneficial. That is, perhaps being told not to gesture freed
up cognitive resources that could then be used to think
schematically about the story (e.g., Waltz, Lau, Grewal, &
Holyoak, 2000). It is difficult for us to rule this possibility
out definitively. However, we find the explanation
untenable for two reasons. First, when given no instructions
regarding gesture, most participants spontaneously produced
them, suggesting that gesturing while retelling the story was
natural. Thus, refraining from gesturing was likely more
difficult than gesturing. Second, previous research has
shown that producing gestures reduces cognitive load in

1689

other tasks (e.g., Goldin-Meadow, Nusbaum, Kelly, &
Wagner, 2001). Thus, there is no evidence to support the
idea that gesture production utilizes more resources than
speech alone. Rather than utilizing cognitive resources, we
argue that producing gestures focused speakers’ attention on
the concrete perceptual and motor elements of the story,
thereby reducing their likelihood of forming an abstract
schema that could be applied to the problem.
This explanation suggests several possible avenues for
future research. First, whether gestures about the source
help or hurt should depend on the similarity of objects and
perceptual features between the source and target. Focusing
on the objects involved in the source is not always
detrimental; when there are similar objects involved in the
source and target, thinking about the objects can actually
help problem solvers notice the connection (e.g., Chen,
1995). Thus, gesturing about a source story that involves
rays might actually improve the likelihood of noticing the
connection with a target problem that is also about rays. We
are currently testing this prediction.
Second, the participants in the present study read only a
single source story. Previous research has shown that being
exposed to multiple source stories increases the chances that
problem solvers form a schema that can be applied more
generally to a problem (e.g., Gick & Holyoak, 1983).
Perhaps if problem solvers gestured about multiple source
stories, they would notice the similarity in their gestures
across stories and be more likely to form the abstract
schema of converging forces. Cooperrider and GoldinMeadow (2014) tested this prediction, but found no
evidence to support it. In fact, they found that speakers who
gestured about multiple source stories were less likely to
generate the convergence solution than speakers who did
not gesture, paralleling the effect we found here.
In conclusion, gestures have been shown to play a role in
solving problems of various types (e.g., Alibali et al., 2011;
Beilock & Goldin-Meadow, 2010). We have extended this
work to examine the role of gesture in analogical problem
solving and provided evidence that gestures make it more
difficult to notice a similarity between a source and target
that are in different domains. These findings suggest that
when it is more important to focus on schematic
relationships rather than perceptual properties, problem
solvers may be best off keeping their hands still. For
example, in a Physics problem involving physical forces on
particular objects, gesturing about the objects in the problem
may focus participants’ attention on those particular objects,
rather than on the more general forces at work that are
essential to understanding how to solve the problem.

References
Alibali, M. W., & Kita, S. (2010). Gesture highlights perceptually
present information for speakers. Gesture, 10, 3-28.
Alibali, M. W., Spencer, R. C., Knox, L., & Kita, S. (2011).
Spontaneous gestures influence strategy choices in problem
solving. Psychological Science, 22, 1138-1144.

Anolli, L., Antonietti, A., Crisafulli, L., & Cantoia, M. (2001).
Accessing source information in analogical problem-solving.
The Quarterly Journal of Experimental Psychology Section
A: Human Experimental Psychology, 54, 237-261.
Beilock, S. L., & Goldin-Meadow, S. (2010). Gesture changes
thought by grounding it in action. Psychological Science.
Beveridge, M., & Parkins, E. (1987). Visual representation in
analogical problem solving. Memory & Cognition, 15, 230237.
Catrambone, R. C., Craig, D. L., & Nersessian, N. J. (2006). The
role of perceptually represented structure in analogical
problem solving. Memory & Cognition, 34, 1126-1132.
Chen, Z. (1995). Analogical transfer: From schematic pictures to
problem solving. Memory & Cognition, 23, 255-269.
Cook, S. W., Yip, T. K., & Goldin-Meadow, S. (2010). Gesturing
makes memories that last. Journal of Memory and
Language, 63, 465-475.
Cooperrider, K., & Goldin-Meadow, S. (2014). The role of gesture
in analogical problem solving. In P. Bello, M. Guarini, M.
McShane, & B. Scassellati (Eds.), Proceedings of the 36th
Annual Meeting of the Cognitive Science Society (pp. 20682072). Austin, TX: Cognitive Science Society.
Duncker, K. (1945). On problem solving. Psychological
Monographs, 58, 270.
Gentner, D., & Smith, L. A. (2013). Analogical learning and
reasoning. In D. Reisberg (Ed.) The Oxford Handbook of
Cognitive Psychology, (pp. 668-681). New York, NY:
Oxford University Press.
Glenberg, A. M. (2010). Embodiment as a unifying perspective for
psychology. Wiley Interdisciplinary Reviews: Cognitive
Science, 1, 586-596.
Gick, M. L., & Holyoak, K. J. (1980). Analogical problem solving.
Cognitive Psychology, 12, 306-355.
Gick, M. L., & Holyoak, K. J. (1983). Schema induction and
analogical transfer. Cognitive Psychology, 15, 1-38.
Goldin-Meadow, S., & Beilock, S. L. (2010). Action's influence on
thought: The case of gesture. Perspectives on Psychological
Science, 5, 664-674.
Goldin-Meadow, S., Nusbaum, H., Kelly, S., & Wagner, S. (2001).
Explaining math: Gesturing lightens the load. Psychological
Science, 12, 516-522.
Hostetter, A. B., & Alibali, M. W. (2008). Visible embodiment:
Gestures as simulated action. Psychonomic Bulletin &
Review, 15, 495-514.
Hostetter, A. B., & Skirving, C. J. (2011). The effect of visual vs.
verbal stimuli on gesture production. Journal of Nonverbal
Behavior, 35, 205-223.
Keane, M. (1987). On retrieving analogues when solving
problems. The Quarterly Journal of Experimental
Psychology Section A: Human Experimental Psychology, 39,
29-41.
Thomas, L. E., & Lleras, A. (2007). Moving eyes and moving
thought: On the spatial compatibility between eye
movements and cognition. Psychonomic Bulletin & Review,
14, 663-668.
Thomas, L. E., & Lleras, A. (2009). Swinging into thought:
Directed movement guides insight in problem solving.
Psychonomic Bulletin & Review, 16, 719-723.
Waltz, J. A., Lau, A., Grewal, S. K., & Holyoak, K. J. (2000). The
role of working memory in analogical mapping. Memory &
Cognition, 28, 1205-1212.

1690

