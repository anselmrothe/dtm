                      A Hierarchical Probabilistic Language-of-Thought Model
                                          of Human Visual Concept Learning
                                       Matthew C. Overlan (moverlan@bcs.rochester.edu)
                                           Robert A. Jacobs (robbie@bcs.rochester.edu)
                                      Steven T. Piantadosi (spiantadosi@bcs.rochester.edu)
                                                Department of Brain and Cognitive Sciences
                                                            University of Rochester
                                                              Rochester, NY USA
                              Abstract                                    artificial intelligence, the natural language processing com-
                                                                          munity has long used models that use statistics to infer struc-
   How do people rapidly learn rich, structured concepts from
   sparse input? Recent approaches to concept learning have               tured, arguably rule-based representations of syntax (Man-
   found success by integrating rules and statistics. We describe a       ning & Schütze, 1999). Within the cognitive sciences, the
   hierarchical model in this spirit in which the rules are stochas-      Rational Rules model (Goodman, Tenenbaum, Feldman, &
   tic, generative processes, and the rules themselves arise from
   a higher-level stochastic, generative process. We evaluate this        Griffiths, 2008) showed how we can account for human per-
   probabilistic language-of-thought model with data from an ab-          formance by considering rule learning as Bayesian statistical
   stract rule learning experiment carried out with adults. In this       inference over a structured rule space. Hybrid statistical/rule-
   experiment, we find novel generalization effects, and we show
   that the model gives a qualitatively good account of the exper-        based models are sometimes referred to as “probabilistic lan-
   imental data. We then discuss the role of this kind of model in        guage of thought” models.
   the larger context of concept learning.
                                                                             Work in developmental psychology has strongly suggested
   Keywords: Probabilistic language of thought, Bayesian infer-
   ence, abstract rule learning, computational model, induction,          that even infants generalize in ways that go beyond sim-
   generalization, behavioral experiment                                  ple statistical co-occurrences. Marcus, Vijayan, Bandi Rao,
                                                                          & Vishton (1999) showed that seven-month-old infants can
                          Introduction                                    learn to recognize sequences of syllables that follow an ABA
A foundational question about human cognition is how we                   pattern like “ga ti ga” and “wo fe wo”, where the first and
learn as much as we do from input that is often extremely                 third syllables are the same but differ from the middle syl-
limited. From a few or even just one example, we can make                 lable. Gerken (2006) later showed that when infants are ex-
powerful and accurate generalizations. In language learning,              posed to stimuli that are consistent with both a broader (e.g.,
for example, there have long been debates about how we learn              ABA) and a narrower generalization (e.g., AxA where x is a
the complex grammatical structures that we do, given input                specific syllable, not a class or set of syllables), the infants
that is relatively sparse. The ability to learn complex mental            tend to prefer the narrower generalization. This ability to
representations on the basis of small data sets is also at work           seemingly learn abstract rules from small data sets has even
in other cognitive domains such as visual perception (Marr                been glimpsed in non-human animals (van Heijningen, Chen,
& Nishihara, 1978) and causal reasoning (Gopnik & Sobel,                  van Laatum, van der Hulst, & ten Cate, 2013).
2000) . These mental representations are important because                   To account for these types of experimental findings, Frank
they abstract and summarize the regularities in our environ-              & Tenenbaum (2011) modeled rule-like patterns with strings
ment. By generalizing knowledge gained in specific settings,              that have a symbol for each token in the pattern. The symbols
they allow us to act in novel settings. For the field of cogni-           indicate whether the token in a given position is a particular
tive science, a key question is, since there are infinitely many          token x, (isx ), the same as another token at position n (=n ),
generalizations that are consistent with a finite input, why and          or a wildcard (i.e., the symbol could be any token). They
how do we generalize in the ways that we do?                              modeled learning as Bayesian inference over these structures:
   To understand people’s generalizations, cognitive scientists           P(h|D) ∝ P(D|h) P(h), where h is a hypothesis representing
often debate the merits of statistical versus rule-based ap-              a specific choice of symbols and D is the observed data. The
proaches. Statistical approaches are appealing because the                likelihood P(D|h) is the probability of obtaining the exem-
statistical regularities of data can often be learned relatively          plars in D via independent random draws from the set of all
easily. Advocates of rule-based approaches argue however,                 strings consistent with h. Importantly, this likelihood follows
that statistical regularities are inadequate and that, without            the “size principle” (Tenenbaum & Griffiths, 2001). If h is a
explicit rules, it is difficult to explain the full richness and          broad hypothesis that is consistent with many possible sets of
complexities of people’s generalizations (Marcus, 1999).                  strings, then obtaining the specific set D from h is small (i.e.,
   As pointed out by others, statistical and rule-based ap-               P(D|h) is small). In contrast, if h is a focused hypothesis that
proaches are not mutually exclusive, but rather can be prof-              is consistent with relatively few possible sets of strings, then
itably combined (Tenenbaum, Kemp, Griffiths, & Goodman,                   obtaining D from h is large (i.e., P(D|h) is large). Conse-
2011; Aslin & Newport, 2012). For example, in the field of                quently, likelihood functions that follow the size principle fa-
                                                                     1259

vor focused hypotheses over broad hypotheses. In Frank and           here we incorporate stochasticity into the rules themselves.
Tenenbaum’s model, hypotheses were a priori equally likely           The remainder of the paper is an exploration of this idea in an
(i.e., P(h) was a uniform distribution).                             abstract rule learning task in a visual domain.
   Their model gives an impressive account of findings in the
literature for abstract rule learning across several domains.                                 Experiment
Although this work is an important early step in developing a        We conducted an experiment with adults to test their ability to
probabilistic language-of-thought account of human general-          learn rule-based visual concepts from a small number of ex-
ization, it leaves open many important questions. Their model        amples. Our visual stimuli were part-based 3D objects where
is limited in the sense that it only includes the bare machinery     the parts act as tokens in an abstract rule (see Figure 1). There
necessary to account for the specific findings that they con-        were two groups of subjects (30 subjects per group). For one
sider. To what extent can their model, or rather their general       group of subjects, the experiment used the rule ABA (as in the
theoretical framework, serve as a foundation for a richer and        experiment by Marcus et al. discussed above). For the other
more broadly-applicable model providing a more comprehen-            group, the experiment used the rule xBB (as in the experiment
sive account of generalization? What is the full range of rules      by Gerken discussed above; x is a specific token that is iden-
that people might learn and that cognitive models will need          tical in all exemplars).
to account for? As noted by Frank and Tenenbaum, people
have built-in biases for certain hypotheses over others. What
are those biases, and how can they be included in a cognitive
model?
   In light of these outstanding questions, we developed a
new probabilistic language-of-thought model for rule learn-
ing. This model uses a two-level generative process for ex-
plaining items in a data set. At the top level is a stochastic
generative process for generating rules. As explained below,
the generative process in our model is a probabilistic context-
free grammar, and this grammar generates rules. At the bot-
tom level, each rule is a stochastic generative process for gen-
erating data items. An innovative aspect of our model is that
rules are themselves stochastic generative processes. Because
data items are generated stochastically from rules, and be-
cause rules are generated stochastically from a probabilistic
grammar, the overall generative process forms a hierarchy.
   To our knowledge, only one other computational model of           Figure 1: On top, the five parts used in the experiment. Par-
concept learning employs such a structure. Lake, Salakhut-           ticipants viewed these during the instructions phase. On the
dinov, & Tenenbaum (2015) created a model of handwritten             bottom are the training exemplars for ABA and xBB condi-
character recognition that employed a two-level generative           tions.
model. The top level defined a distribution over the abstract,
symbolic representation of a character (the type), and then             The experiment was web-based, carried out on Amazon
given that specification, the bottom layer defined a distribu-       Mechanical Turk. All subjects were US residents over the
tion over concrete instances of that character as visual strokes     age of 18. To eliminate the possibility of order and experi-
(the token). Our work relates to and extends this work by cast-      ence effects, each subject participated in only a single condi-
ing a hierarchical model in a more general context. The Lake         tion. The experiment consisted of three stages: an instruction
et al. model is highly customized for its domain, so it is un-       stage, a training stage, and a testing stage. As part of the in-
clear how to apply insights from that work to other domains,         struction stage, participants were shown all five possible part
except at the broadest conceptual level. Our model, however,         shapes. Following the instruction stage, subjects participated
is built upon the more general Language of Thought frame-            in a training stage where they were shown three exemplars
work. Since this framework has already been successfully             from a category. Each subject was allowed to view the exem-
applied to other domains, and since models in this framework         plars for as long as he or she wished. Training was followed
only require the specification of very general primitives, our       by testing. During testing, subjects were shown an array of 24
work is much more readily adaptable to other domains. This           test items. Test items had the same general structure as train-
also makes for a much more plausible cognitive explanation,          ing exemplars (three parts arranged linearly), but differed in
as the learning system requires far less manual engineering.         which parts occupied each position in an item. Participants
   The model is a natural evolution of prior work on rule            chose ‘yes’ or ‘no’ for each test item to indicate whether it
learning. Previously, theoretical progress was made by in-           belonged to the same category as the training exemplars. The
corporating stochasticity into the rule-learning process, and        exemplars remained available for viewing at the top of the
                                                                 1260

web page for the duration of the test stage. At least one ex-
emplar was present in the test items. If a participant answered
‘no’ to that item, his or her results were excluded from the
analysis (1 and 2 subjects were excluded in the ABA and xBB
conditions, respectively).
                     Cognitive Model
In our implementation, concepts or hypotheses begin as
lambda calculus expressions. Lambda calculus is a form of
logic that is a universal model for computation (i.e., it is
equivalent in power to a Turing machine). It characterizes
computation using function abstraction and application via
variable binding and substitution. For ease of readability,
we present these expressions here as procedural “computer
programs”. These programs construct objects by sampling
parts from a fixed alphabet and then combining those parts
in a spatial order. They do so using simple set operations,
such as removing an element from a set. They can also
abstract over parts by assigning them to variables which can
be reused. An example program is the following:
        let x1 = sample(A)
        let x2 = sample(A − x1 )
                                                                    Figure 2: Parse tree for the example program discussed in the
        output x1 → x2 → x1
                                                                    main text.
This program generates the set of objects following an
ABA pattern. The object is constructed by first randomly               The prior distribution P(h) is the prior probability of hy-
sampling part x1 from the full alphabet, then randomly              pothesis h. By employing the language-of-thought frame-
sampling x2 from the set consisting of all parts except x1 ,        work, it too has a natural interpretation. Consistent with ear-
and finally combining those parts in the order x1 → x2 → x1 .       lier language-of-thought models, our model implements the
The arrows specify the spatial relationship between parts.          idea that hypotheses are language-like in that they are com-
Although repetition detection is not explicitly built in, it        positional. Just as sentences are structures built out of words,
arises as a natural consequence of the ability to form variable     our model’s hypotheses are structures built out of primitives.
abstractions.                                                          This structure is specified by a probabilistic context-free
   We model learning by assuming that people select the most        grammar G which defines the syntax for how primitives can
probable rule or hypothesis h given the set of training exem-       be combined. For this experiment, we provided primitive
plars D: argmaxh P(h|D). The posterior distribution over h          functions sample(SET) which samples uniformly from a set,
can be calculated using Bayes’ Rule: P(h|D) ∝ P(D|h)P(h).           set minus(SET, PART) which removes a part from a set,
This expression has a natural interpretation in our framework,      and concatenate(STR, STR, ...) which concatenates strings
with the two probabilities corresponding to the two levels of       (which are in turn made up of parts). These primitives are in
the hierarchy.                                                      addition to variable abstraction, which is an inherent property
   The likelihood P(D|h) is the probability that hypothesis h       of hypotheses by virtue of their lambda calculus core.
generated the training exemplars in data set D. Assuming the           Because the grammar is probabilistic, it defines a distri-
exemplars are drawn independently with replacement (known           bution over the structures it generates. Each non-terminal
as the “strong sampling hypothesis” (Tenenbaum & Griffiths,         in the grammar has an associated distribution that specifies
2001)),                                                             the probability that a production rule will be used to expand
                      P(D|h) = ∏ P(d|h)                             that non-terminal. The prior probability of hypothesis h is the
                                d∈D                                 product of the probabilities for each of the production rules
where d is an individual exemplar. Note that each h, as in the      used in constructing h. In other words, if T is the parse tree
example above, is itself a stochastic generative model. There-      for h and ri is a rule in this tree, then
fore it naturally defines a distribution over its outputs. Con-
sider “running” the example program repeatedly. Each run
                                                                                           P(h) =    ∏ P(ri |G).
                                                                                                    ri ∈T
produces an independent output that depends on the randomly
sampled tokens. P(d|h) is the limiting distribution over those      Note that this prior distribution implements a form of Oc-
outputs.                                                            cam’s Razor. Since each probability P(ri |G) is less than one,
                                                                1261

                                                               ABA
                                                               xBB
Figure 3: For each test item, the graphs show the probability that subjects judged the item to be from the same category as
the training exemplars (plotted by the gray bars in each graph) compared to the probability predicted by our model (labeled
H-LOT) and the GCM model. The top and bottom graphs are for the ABA and xBB conditions, respectively.
hypotheses with short derivations tend to have higher proba-
bility than those with long derivations. The parse tree for the                    P(h, θ|D) ∝ P(D|h, θ)P(h)P(θ).
example program discussed above is shown in Figure 2.
                                                                       We estimated this distribution in two steps. First we fixed
                                                                    P(θ) and sampled the discrete variables h and θ using a
   Finally, each hypothesis has an associated vector of vari-       Metropolis-Hastings sampling algorithm (a type of Markov
ables θ which allow us to model additional factors that influ-      chain Monte Carlo algorithm). Because we are sampling
ence generalization. For this experiment, we used two vari-         in a discrete space, we can approximate the full distribu-
ables. One indicated that the hypothesis should be orienta-         tion by saving unique samples and then normalizing. In our
tion invariant, so that an expression that produced the object      Metropolis-Hastings algorithm, we used a slightly modified
a → d → d would also produce d → d → a. The other in-               version of the standard tree regeneration proposal distribu-
dicated that the alphabet should only contain parts that have       tion by Goodman et al. (2008). Next, since we have no a
been seen in the training exemplars rather than the full alpha-     priori information or theory to indicate how strong the prior
bet of parts. Each of these parameters has an associated prior      tendency to generalize to novel parts or to show invariance to
probability, making the full posterior                              orientation should be, we fit P(θ) via gradient descent. Since
                                                                1262

our search space is tractable enough for the initial sampling                                         ABA
step to obtain an approximately complete set of samples, we               p     hypothesis                            extension set size
do not need to do any more sampling after fitting θ.
                                                                                let x1 = sample(A)
                             Results                                            let x2 = sample(A − x1 )
                                                                          .4                                                  20
The results are shown in Figure 3. For each test item, these                    output x1 → x2 → x1
graphs show the probability that subjects judged the item to
be from the same category as the training exemplars (plotted                    let x1 = sample(AR )
by the gray bars in each graph) as well as the probabilities pre-               let x2 = sample(AR − x1 )
dicted by two different models. For our model, its prediction            .24                                                   6
                                                                                output x1 → x2 → x1
for a given test item was calculated by summing the posterior
probabilities for all hypotheses that produce that item:
                                                                                let x1 = sample(A)
                 P(t|D) = ∑ P(h, θ|D)Iext(hθ ) (t)                              let x2 = sample(A)
                                                                         .15                                                  25
                            h,θ                                                 output x1 → x2 → x1
where I is the indicator function and ext(hθ ) is the extension
of (the set of objects generated by) hypothesis h given param-
eters θ.                                                                                               xBB
   We also show results for the Generalized Context Model                 p     hypothesis                            extension set size
(GCM) (Nosofsky, 1986), an exemplar model of category
learning that is commonplace in the cognitive science liter-                    let x1 = "a"
ature. The GCM is a similarity-based model; it determines                       let x2 = sample(A)
                                                                         .39                                                   5
the category membership of a test item based on its similarity                  output x1 → x2 → x2
(or inverse of distance) to the exemplars. For this domain, a
natural distance function would be one that assigns low dis-                    let x1 = "a"
tances (and thus high similarities) to pairs of objects that have               let x2 = sample(A − x1 )
many parts in common, and high distances to those that have              .21                                                   4
                                                                                output x1 → x2 → x2
parts that differ. This distance function would serve as a use-
ful comparison because, unlike our model, its representation
is relatively unstructured, and it does not have internal vari-                 let x1    = "a"
ables. We chose the Levenshtein string edit distance, which                     let x2    = sample(A)
gives the minimum number of insertions, deletions, or substi-            .18    output     x1 → x2 → x2                        5
tutions needed to transform one string into another. We gave                    or         x2 → x2 → x1
this distance function a string representation of the objects.
For test item t, the predicted proportion of responses is given        Figure 4: The three top scoring hypotheses for each condition
by                                                                     as given by the model, along with their posterior probability
                     P(t|D) = ∑ e−c · Lev(t,d)                         (p) and the number of objects each hypothesis generates. A is
                                d∈D
                                                                       the set of all parts, and AR is the set of parts that are present in
where c is a scaling parameter that we fit via gradient descent.       any of the exemplar objects. The model predicts that learned
   Subjects’ responses in our experiment showed large vari-            hypotheses should not strictly follow the size principle, as
ability, as illustrated by the fact that many subject probabili-       shown by the non-monotonic set sizes.
ties (see gray bars in Figure 3) are not near 0 or 1. Despite this
variability, our model provides a reasonably good account of
subjects’ responses, particularly in the ABA condition. The            In addition, the model and subjects may or may not general-
GCM model performs poorly; people’s generalizations in this            ize to the linear reversal of patterns (e.g., BBx instead of xBB).
task reflect the latent structure present in the objects, thereby      These creative generalizations suggest that people’s concept
going beyond simple similarities.                                      space may be rich in ways that have only rarely been explored
   The tables in Figure 4 show the three hypotheses with the           by computational models in the cognitive science literature.
highest probabilities according to our model. These results               An interesting finding is that people often generalize in
suggest that the model correctly infers the target rules (ABA in       ways that violate the “size principle” discussed above. For
the top table of Figure 4 and xBB in the bottom table). How-           instance, subjects in the xBB condition seem to often infer
ever, people often deviate from the exact patterns given by            the rule ABB. That is, despite the fact that the same token ap-
these rules, sometimes in interesting ways. For example, the           peared in the leftmost position of all training exemplars, sub-
model and subjects may or may not generalize to test items             jects seemed to infer that the leftmost token can be any part
containing parts beyond those used by the training exemplars.          so long as it differs from the tokens appearing in the other po-
                                                                   1263

sitions. In general, the set sizes that people learned are highly                         Acknowledgments
variable. This tells us that people are being strongly influ-         This work was supported by AFOSR (FA9550-12-1-0303)
enced by the biases and structure of their hypothesis space,          and NSF (BCS-1400784) research grants.
which is captured reasonably well by the biases and structure
of the language-of-thought prior.                                                              References
                                                                      Aslin, R. N., & Newport, E. L. (2012). Statistical learning:
                          Discussion                                    From acquiring specific items to forming general rules.
We have shown how our theory of rule-based concepts as                  Current directions in psychological science, 21(3), 170–
structured, generative models provides a framework which                176.
can profitably model concept learning in the domain of ab-            Frank, M. C., & Tenenbaum, J. B. (2011). Three ideal ob-
stract rules. Our approach has several features that make it            server models for rule learning in simple languages. Cog-
attractive as a general paradigm for theorizing in this domain.         nition, 120, 360–371.
First, it operates as an ideal observer (Geisler, 2003)—that          Geisler, W. S. (2003). Ideal Observer Analysis. The visual
is, it defines optimal behavior under a set of assumptions.             neurosciences, 10(7), 12–12.
The language-of-thought framework has the attractive prop-            Gerken, L. (2006). Decisions, decisions: infant language
erty that the modeler is forced to make those assumptions ex-           learning when multiple generalizations are possible. Cog-
plicit; they must be encoded directly in the rules, choices of          nition, 98(3), B67–B74.
primitives, and probabilities of the grammar. For instance, the       Goodman, N. D., Tenenbaum, J. B., Feldman, J., & Griffiths,
model in this paper assumed two computational primitives: a             T. L. (2008). A rational analysis of rule-based concept
uniform sample operation and an operation to remove an ele-             learning. Cognitive science, 32(1), 108–154.
ment from a set. Furthermore, these assumptions are psycho-
                                                                      Gopnik, A., & Sobel, D. M. (2000). Detecting blickets: how
logically interpretable. The modeling choices afforded by the
                                                                        young children use information about novel causal powers
framework, such as the production probability of a rule, can
                                                                        in categorization and induction. Child development, 71(5),
typically be mapped directly onto psychological phenomena.
                                                                        1205–1222.
For instance, we saw that in our experiment, subjects only
mildly penalized the complexity added by the use of set op-           Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015).
erations. Because the framework allows us to decompose the              Human-level concept learning through probabilistic pro-
structure of concepts in these ways, we can identify the rele-          gram induction. Science, 350(6266), 1332–1338.
vant dimensions along which to aim further work.                      Manning, C. D., & Schütze, H. (1999). Foundations of statis-
   As an example of how the framework gives us a lens                   tical natural language processing (Vol. 999). MIT Press.
through which we can frame analyses, we identify several av-          Marcus, G. F. (1999). Do Infants Learn Grammar with Alge-
enues for further investigation both in the domain of abstract          bra or Statistics? Science, 284(5413), 436–437.
rule learning and in wider concept learning. The data hinted          Marcus, G. F., Vijayan, S., Bandi Rao, S., & Vishton, P. M.
that people may be incorporating primitives other than those            (1999). Rule Learning by Seven-Month-Old Infants. Sci-
that we included in our model, perhaps ones that arbitrarily            ence, 283(5398), 77–80.
permute or shuffle tokens, or ones that invert them, swapping         Marr, D., & Nishihara, H. K. (1978). Representation
parts A and B. Would the incorporation of such primitives               and Recognition of the Spatial Organization of Three-
improve model performance in this domain, and would those               Dimensional Shapes. Proceedings of the Royal Society B:
primitives be relevant in other domains? There are several              Biological Sciences, 200(1140), 269–294.
dimensions of variation that may influence generalization—            Nosofsky, R. M. (1986). Attention, similarity, and the
the number of training exemplars, the number of tokens in               identification-categorization relationship. Journal of ex-
an object, the number of unique tokens across all exemplars,            perimental psychology. General, 115(1), 39–61.
etc. The probabilistic basis of the model allows it to make
                                                                      Tenenbaum, J. B., & Griffiths, T. L. (2001). Generalization,
predictions along all of these dimensions, but further empiri-
                                                                        similarity, and Bayesian inference. The Behavioral and
cal data is needed to test those predictions. More broadly, as
                                                                        brain sciences, 24, 629–640; discussion 652–791.
the framework allows us to identify potential representational
biases, we can then ask why people have those biases? Are             Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
they the result of some deeper computational principle? And             N. D. (2011). How to grow a mind: statistics, structure, and
do they need to be innate or can those biases be learned?               abstraction. Science (New York, N.Y.), 331(6022), 1279–
   The work presented here is a proof of concept that a two-            85.
level hierarchy of generative models can be a powerful frame-         van Heijningen, C. a. a., Chen, J., van Laatum, I., van der
work for modeling and interpreting human rule-learning phe-             Hulst, B., & ten Cate, C. (2013). Rule learning by zebra
nomena. Thinking of concepts as structured, stochastic rules            finches in an artificial grammar learning task: which rule?
has promising potential to be a general theoretical tool for in-        Animal cognition, 16(2), 165–75.
vestigating concept learning in many contexts and domains.
                                                                  1264

