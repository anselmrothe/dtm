 Integrating identification and perception: A case study of familiar and unfamiliar
                                                              face processing
      Kelsey R. Allen (krallen@mit.edu), Ilker Yildirim (ilkery@mit.edu), Joshua B. Tenenbaum (jbt@mit.edu)
                      Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139
                                Abstract
    We are very familiar with certain objects; we can quickly rec-
    ognize our cars, friends and collaborators despite heavy occlu-
    sion, unusual lighting, or extreme viewing angles. We can also
    determine if two very different views of a stranger are indeed
    of the same person. How can we recognize familiar objects
    quickly, while performing deliberate, perceptual inference on
    unfamiliar objects? We describe a model combining an iden-
    tity classification network for familiar faces with an analysis by
    synthesis approach for unfamiliar faces to make rich inferences
    about any observed face. We additionally develop an online
    non-parametric clustering algorithm for recognition of repeat-
    edly experienced unfamiliar faces, and show how new faces
    can become familiar by being consolidated into the identity
    recognition network. Finally, we show that this model predicts
    human behavior in viewpoint generalization and identity clus-                  Figure 1: How many people are depicted here?
    tering tasks, and predicts processing time differences between
    familiar and unfamiliar faces. Keywords: face recognition;             neural networks and have not yielded practical object identi-
    analysis-by-synthesis; neural networks; computational                  fication or recognition systems.
                                                                              However, object identification and object perception are
                            Introduction                                   not separate. For example, extensive research on face percep-
Walking to work in the morning, we may encounter familiar                  tion has studied familiar face recognition, unfamiliar face per-
faces, buildings in which we regularly have meetings, or the               ception, and the dynamics of how new faces are recognized
passing car of a colleague on their way to the office. Glanc-              differently as they become increasingly familiar (O’Toole,
ing at these objects, we can effortlessly perceive details of              Edelman, & Bülthoff, 1998; Burton, Bruce, & Hancock,
their shape and appearance; we can also recall associated                  1999). Our goal is to build models of these two aspects
identity-specific content (like which colleague owns that car,             of vision and their interaction in the domain of faces, and
or the name of that office building). These two abilities can              more generally to integrate object perception and identifica-
be thought of as object perception and identification respec-              tion, learning to see objects differently as they become famil-
tively. Thus, perception is noticing the shape, texture and                iar to us.
expression of a face, even if the person is a stranger. Iden-                 There is a wealth of experimental data, including neu-
tification is recognizing a close friend even if she has had a             rophysiological, fMRI, and behavioral studies, investigating
dramatic hair cut and is wearing a new pair of large, dark                 the differences between familiar and unfamiliar face pro-
sunglasses.                                                                cessing (Eifuku, De Souza, Nakata, Ono, & Tamura, 2011;
    Recent work in machine vision has made significant                     Natu & O’Toole, 2011). Many behavioral studies have
progress on both of these problems, but very different tech-               found dramatic differences in processing, including differ-
niques have been applied to each problem. Dramatic gains                   ences in viewpoint generalization, reaction times for recog-
in object identification have come from deep neural networks               nition tasks, and a shift from external to internal facial fea-
(Simonyan & Zisserman, 2014). These methods learn to be                    ture processing as faces become more familiar (Johnston &
invariant to certain object transformations and small differ-              Edmonds, 2009). As a quick example: looking at Figure 1,
ences in appearance. However, they require large amounts of                how many identities do you see? Do you recognize any of the
training data, and do not generalize to novel objects without at           individuals?
least re-training the top classification layers. Rich object per-             One of the early conceptual models seeking to capture
ception has become possible using an alternative approach to               some of these behavioral differences was proposed by Bruce
vision, known as “analysis by synthesis” or “inverse graph-                and Young (1986). They suggested that face recognition be-
ics”. This approach posits that the perceptual system models               gins with a structural encoding of the face, regardless of fa-
the generative processes that form images from scenes, and                 miliarity. The structural encoding is compared to stored rep-
works backwards from an observed image to infer the scene                  resentations for familiar faces, and a face recognition unit
most likely to have generated it (Kulkarni, Kohli, Tenenbaum,              is activated if a similarity threshold is reached. The associ-
& Mansinghka, 2015). Inverse graphics methods can often                    ated ‘person identity nodes’ can interface with other identity-
recover the fine-grained geometrical and physical properties               specific semantic modules. Quantitative implementations
of objects in an image, but are much slower than feed-forward              of just the structural encoding aspect of this model include
                                                                       2495

O’Toole et al.’s RBF model (1998) and others (Leibo, Mutch,          fine-tuning. The generative process, inference procedure, and
& Poggio, 2011).                                                     learned recognition models are described below.
   Moving beyond structural encoding, we implement a mod-
ified version of the Bruce and Young system capturing no-            Generative Model
tions of familiarity and identity. Our model suggests that
‘person identity nodes’ are recognized in a holistic way that        We consider the 3D Morphable Face Model as described in
depends on learned individual invariances rather than by a           (Blanz & Vetter, 1999). This model is obtained from a set of
comparison of structural encodings. Recognition is accom-            200 laser scanned heads, providing a mean shape and texture
plished by a ‘long term memory’ which is represented by a            vector for the eyes, nose, mouth and outline of a face, as well
neural network trained to predict identities from face images.       as a covariance matrix to generate new faces by eigendecom-
These identities are associated with latent parameters describ-      position. The shape and texture are Gaussian distributed, with
ing the 3D structure of that person’s face (our structural en-       N(µshape , Σshape ) and N(µtexture , Σtexture ).
coding). With this representation of a person identity node,            Each of the shape and texture vectors are 200 dimensional,
the set of familiar identities need not be fixed, and can be ex-     such that a given face lives in a 400 dimensional latent space.
panded over time. Thus we provide a computational account            An identity can be thought of as a cluster in this latent repre-
of how we become familiar with a new face, which also ex-            sentation, with a corresponding mean vector µi and isotropic
plains how the processing of familiar faces differs from those       variance Σ. Here Σ has been set to 0.01 to represent perceptu-
we have only seen a few times.                                       ally indistinguishable identities. An image can be created by
   The rest of the paper describes the model in more detail,         sampling a latent vector for a given facial identity, and ren-
including its accuracy and inference curves, as well as an on-       dering it at a specific pose and lighting, as seen in Figure 2b.
line clustering algorithm for unfamiliar faces. We validate the      Figure 3 shows some example faces drawn from this model.
model on three different behavioral experiments, and suggest
directions for future research.
                             Model
Our model represents one way of combining the richness of
generative models with the speed of neural networks. In-
spired by the Helmholtz machine (Dayan, Hinton, Neal, &
Zemel, 1995), we describe an efficient analysis-by-synthesis
approach by training a recognition model to approximate the
latent parameters of a generative model in a fast, feed-forward       Figure 3: Pairs of images drawn from the generative model.
way. The approximated parameters provide initializations for
top-down inference in a generative model, allowing for some
Figure 2: Pipeline used for recognizing an observed image. (a) shows our modified model, using the identity recognition
network to determine familiarity, and then initializing with a draw from either the identified familiar cluster or an unfamiliar/new
cluster as appropriate. (b) shows the standard generative model operating only over the base distribution in latent space.
                                                                 2496

Recognition models                                                   seen person k before:
Latents recognition network The first recognition net-                                   (
                                                                                             nk
                                                                                            i+α   (nk > 0, old cluster)
work (Figure 2a, network labeled “Latents”) is trained to pre-                  P(k) =       α
dict the 400 dimensional latent vector that generated a given                               i+α ,  (nk = 0, new cluster)
image of a face. This allows for an efficient, approximate,
                                                                     α is chosen to be 1 for the following experiments, but this
guess for the latent parameters of a face. The details of this
                                                                     choice has little effect on the results.
network are described in (Yildirim, Kulkarni, Freiwald, &
                                                                        The likelihood of a specific cluster k for the current obser-
Tenenbaum, 2015). Yildirim et al. use the top convolutional
                                                                     vation is computed in image space. We use the generative
and first fully connected layers of a convolutional neural net-
                                                                     model to obtain an image from each cluster, rendered at the
work (CNN) (pre-trained on ImageNet) to train a linear model
                                                                     same pose and lighting as the observed image. While the
to predict the shape, texture, pose and lighting variables of a
                                                                     likelihood for already existing clusters is trivial to compute
set of generated faces. Here we assume that pose and lighting
                                                                     (Gaussian in pixel space), determining the likelihood of a new
are observed, so only shape and texture need to be predicted.
                                                                     cluster is more complex. We approximate it using an image
Since the generative model created all training data for the
                                                                     rendered with the latent parameters from the latents recogni-
network, it is self-supervised. This recognition model will be
                                                                     tion network (Ilrn ). Thus the likelihood can be described by a
referred to as the ‘latents recognition model’.
                                                                     Gaussian with mean Ik for old clusters, and mean Ilrn for the
Familiar identity recognition network To mimic long-                 new cluster (and noise σ = 0.01).
term memory, we include a classification network for famil-             We choose as our estimate the local MAP, which gives
iar identities (Figure 2a, network labeled “Identity”). We use       us a good initialization for the latent parameters of the new
the first fully connected layer of the network (Simonyan &           face, even when we are unfamiliar with the observed individ-
Zisserman, 2014) (also pre-trained on ImageNet) as input             ual. After forward inference, the cluster means in latent space
to a linear model, which outputs a probability for each fa-          are updated, reflecting the potential addition of a new cluster
miliar identity. Two versions of this network, an ‘old’ net-         member. This learning procedure is the critical contribution
work which knows 80 identities (80 output class labels), and         of our approach: it presents an account of how we may be-
a ‘young’ network (30 familiar identities/class labels), were        come familiar with a previously unfamiliar face, even without
trained using 400 different viewing conditions for each famil-       any supervised training data.
iar identity.
                                                                     Inference
Processing Pipeline                                                  In order to fine-tune the latent parameters for a given im-
An observed image ID generated with the Morphable Face               age, we iterate through a few sweeps of forward inference
Model is fed to both the identity recognition network and            as described in (Yildirim et al., 2015) and (Kulkarni et al.,
the latents recognition network. The system first determines         2015). After initializing the latent parameters for either a fa-
whether this is a familiar person by calculating the entropy         miliar face or an unfamiliar face as above, multi-site ellip-
across the familiar identities (Figure 2a, entropy/threshold).       tical slice sampling (Murray, Adams, & MacKay, 2009), a
                                                                     form of MCMC, is performed on the vectors for shape and
Familiar faces If the entropy falls below a learned thresh-          texture (Figure 2a, Approximate Renderer → Observation).
old, the face is classified as familiar and the identity is set      At each MCMC sweep, we iterate a proposal-and-acceptance
to the most probable class. The latent parameters are then           loop on the shape and texture vectors. Proposals are images
initialized by sampling from the stored representation asso-         that are rendered based on a set of latent parameters, a set
ciated with the determined familiar identity, rather than from       pose, and a set lighting using a standard graphics engine.
the general purpose latents recognition network (Figure 2a,          The log-likelihood with respect to the observed image is then
Familiar box).                                                       computed (and assumed to be Gaussian in pixel space).
Unfamiliar faces If the entropy falls above the threshold,
the face is unfamiliar and we disregard the familiar identities.                      Simulation experiments
There are then two possible cases for unfamiliar faces: ei-          We analyze the performance of our model in several differ-
ther the face is completely novel, or it is the same face as one     ent scenarios. We first generated a set of 100 identities, each
which we have only seen a few times before (Figure 2a, Un-           of which was rendered under 500 different pose and light-
familiar box). This can be viewed as a non-parametric clus-          ing conditions. We then trained an output layer on the last
tering problem. The very first unfamiliar person we see will         fully connected layer in the network from (Simonyan & Zis-
generate their own cluster. Each unfamiliar face we see after-       serman, 2014) to predict either a set of 30 identities (the
wards will either be clustered with a previously encountered         young network) or 80 identities (the old network). For each
identity, or form its own cluster. We therefore model this           identity, 400 views were used for training, leaving 100 view-
process using a sequential clustering algorithm with a Chi-          points for testing. On the test set, the young network achieves
nese Restaurant Process (CRP) prior on cluster assignments           98.72% accuracy while the old network achieves 98.42% ac-
for observation i, where nk is the number of times you have          curacy. Training was performed using stochastic gradient de-
                                                                 2497

                  (a) Familiar faces                     (b) Unfamiliar faces                  (c) Faces observed once before
Figure 4: Inference traces for (a) 20 familiar (b) 20 unfamiliar and (c) observed once before, faces. The addition of the identity
recognition network improves performance for familiar identities, and doesn’t hurt performance for unfamiliar faces.
scent with a learning rate of 0.001 and a maximum number of           previous network for the familiar identities, and randomly
iterations of 1000.                                                   initialized the weights for the unfamiliar identities. After
                                                                      training, we achieve 89.84% accuracy on the old faces, and
Familiarity classification At the first stage of the pipeline,        89.70% on the new faces, reflecting reasonable memory con-
an incoming face is deemed to be familiar or unfamiliar based         solidation.
on the entropy over the network class labels. To determine
an appropriate threshold, we maximize accuracy on a famil-                Comparisons with behavioral experiments
iar/unfamiliar task using 400 views of 20 familiar faces and
400 views of 20 unfamiliar faces in the young network. This           Experiment 1 In the first experiment, we show the power
results in an accuracy of 91.3% for the young network. Using          of the unfamiliar face processing component of the model by
the same threshold for the old network yields an accuracy of          reproducing results from O’Toole et al. (1998). In this exper-
94.1%. The older network slightly outperforms the younger             iment, participants were trained on 36 unfamiliar faces from
network, which qualitatively matches the behavioral findings          one of three views: frontal, 3/4 or profile. Participants were
of (Germine, Duchaine, & Nakayama, 2011), who showed                  then shown 72 images from any of the three viewing condi-
that face recognition ability increases with age (up to a cer-        tions, and asked to classify each image as depicting an indi-
tain point).                                                          vidual in the training set (‘old’), or a new individual (‘new’).
                                                                      D prime measures were then calculated for each individual in
Inference We check whether including the identity network             the task.
yields a better initial estimate of the latent parameters for fa-        We simulated this task by collecting 36 random identities
miliar faces compared to random initializations or initializa-        using the Morphable Face Model. Each individual was ren-
tions taken from the latents recognition network. For this ex-        dered under a profile, 3/4 and frontal view, with identical
periment, we randomly sampled 20 known and 20 unknown                 lighting conditions. We then used the latents recognition net-
faces rendered at 3 different viewing conditions. Each face           work to predict the latent parameters for each of the 36 unfa-
was presented to the identity model pipeline as described ear-        miliar faces, with all faces shown in the same viewing condi-
lier, but without the added “online clustering” for unfamiliar        tion (either profile, 3/4 or frontal). This results in 36 distinct
faces. The resulting log likelihood trajectories are shown in         clusters for 36 individuals. In the test phase, the model ob-
Figures 4a and 4b.                                                    serves a face at one of the three views. We then compute the
Online clustering 6 identities were chosen, each with a               likelihood for each of the 36 learned identities (in pixel space)
frontal view under random lighting and a 1/4 side view un-            by rendering its associated latent parameters in the same pose
der random lighting. The model was first presented with the           as the test image. These are compared to the likelihood com-
6 frontal views, and correctly made 6 new clusters for these          puted with the latents predicted from the latents recognition
faces. The 6 side views were then presented in scrambled or-          network. If the likelihood of one of the learned clusters is
der, and the clustering scheme was able to successfully cluster       higher than the likelihood from the latents recognition net-
4/6 of the secondary views. The average likelihood traces are         work, the face is classified as ‘old’. Otherwise, it is classified
shown in Figure 4c.                                                   as ‘new’. The results from both the psychophysics experi-
                                                                      ment and from our simulations are shown in Figure 5.
Expanding the set of familiar identities Finally, we tested              Overall, our model is much more accurate within view-
how well the network consolidated new faces into long-term            points than humans on this task, but follows the general trend
memory. We sampled 20 views from 3 novel identities, as               for viewpoint-transfer generalization. The model provided
well as 5 views from each of our previous 30 familiar identi-         by O’Toole in the paper (based on radial basis functions) also
ties as our training set (which might reflect dreaming of new         predicts this trend, although the old/new classification task
faces, for example). We initialized the weights of the linear         would need to incorporate a learned threshold (with one free
layer in the identity recognition network to those from the           parameter), which we do not need. The most major discrep-
                                                                  2498

             (a) Experimental results from (O’Toole et al., 1998)                          (b) Model results
Figure 5: Results from experiment performed by O’Toole et al.        showing viewpoint generalization compared with results from
our model.
ancy lies in the relative inability of our model to generalize        test images are shown in either frontal or 3/4 view. As in the
from a 3/4 view to a profile view. This may be mitigated by           original experiment, each identity is used as a cue 4 times,
running a few sweeps of forward inference during the train-           giving 36 trials for the familiar cases and 36 for the unfamil-
ing phase (in the model) to more accurately determine latent          iar. For 8/9 familiar identities, the model correctly identifies
parameters for faces viewed from the 3/4 and frontal views.           the individual and classifies both the cue image and one of
Experiment 2 We next show that our model can account                  the two test images as familiar. This requires only two passes
for differences in processing speed for familiar and unfamiliar       through the feed-forward identity recognition network. In the
faces, even in very easy tasks with near ceiling performance.         last case, the cue was classified as unfamiliar, but the correct
Balas, Cox, and Conwell (2007) performed a delayed match-             judgment was still made when choosing the image with the
to-sample task for identity, where participants were cued with        highest likelihood to the cued face.
a profile of either a familiar or unfamiliar person, and then            For the unfamiliar faces, the model correctly matched the
asked to choose which of two individuals (shown at either a           cued individual on each run. It also correctly classified ev-
3/4 or frontal view) matched the cue. They found that reaction        ery cued image as “unfamiliar” which meant that a projection
times for personally familiar individuals was approximately           back to image space was performed. In future work, we will
100 ms faster than for unfamiliar individuals, even though            run further controlled experiments looking at reaction times,
performance in both conditions was above 95%.                         and quantitatively compare the model’s performance to hu-
   It is not obvious how models that rely on stored viewpoints        man performance in recognition tasks for familiar and unfa-
for both familiar and unfamiliar faces could account for this         miliar individuals.
difference in processing speed. Thus, the RBF models pre-             Experiment 3 In this experiment, Jenkins et al. showed
sented by O’Toole or those provided by Leibo et al. (2011)            that there are massive differences between familiar and unfa-
do not immediately explain the results of this experiment.            miliar face recognition by asking participants to cluster im-
   Our model can account for this difference regardless of            ages of two famous Dutch actresses (20 images for each indi-
whether a likelihood measure for the unfamiliar case is done          vidual) into identities (Jenkins, White, Van Montfort, & Bur-
in image or latent space. In latent space, the perceptual sys-        ton, 2011). The experimenters did not specify how many
tem may require a certain confidence in the latent parameters         identities were depicted in the collection. Strikingly, they
of a face before making a judgment. Therefore, in the test            found that participants who were unfamiliar with the ac-
phase, if the images are detected as unfamiliar, they will need       tresses clustered the set of images into 6-10 identities (mode
more MCMC inference steps to achieve the same likelihood              9, range 3-16), while those who were familiar with the ac-
as in the familiar case.                                              tresses correctly clustered the space into two individuals
   Alternatively, if likelihood is computed in image space, the       (mode 2, range 2-5). Interestingly, the rate of misidentifi-
pose and lighting of the test face need to be inferred (which         cation (ie. sorting the two different individuals into the same
requires at least one pass through the latents recognition net-       pile) was very rare for both groups.
work). The cue face must then be rendered in the appropriate             We simulated this task in a sequential clustering experi-
viewpoint in order to compute likelihoods. This extra projec-         ment, with two individuals rendered under 20 different view-
tion step could account for the longer reaction times.                ing conditions each. We used our ‘old’ network which was
   To ensure that our model achieves comparable accuracy for          trained on 80 identities, but varied whether or not the two
this task, we trained it on 80 familiar faces, and then randomly      individuals were included in the training set (giving an unfa-
chose 9 of these as well as 9 unfamiliar faces for the exper-         miliar condition as well as a familiar condition).
iment. The model is first shown a cue face (in the profile               In the unfamiliar condition, the model created 5 distinct
view), and then shown two faces during the test phase. The            clusters for the two identities with memberships of 7, 3, 9, 7
                                                                  2499

                                                                      is only necessary for unfamiliar faces. This cannot be imme-
                                                                      diately predicted by standard view-dependent models. Third,
                                                                      we show a major difference in the processing of familiar and
                                                                      unfamiliar identities by replicating the findings of Jenkins et
                                                                      al.’s clustering experiment (albeit in an online fashion). Our
                                                                      model over-clusters the space when faces are unfamiliar, but
                                                                      correctly clusters the space (with minor errors) when the faces
                                                                      are familiar.
                                                                         We propose that this framework presents a general way of
                                                                      integrating identification and perception. One future line of
Figure 6: Clusters discovered by the model in the unfamiliar          work will investigate whether the same architecture might be
condition (left) and familiar condition (right).                      applied to familiar and unfamiliar objects. We also plan to
                                                                      examine other methods of non-parametric clustering, run ex-
and 12 images (selections from clusters are shown in Figure           periments using the face stimuli we generated, and do a more
6), while 2 faces were incorrectly classified as familiar (into       thorough model comparison. We will also investigate how
two separate identities). In the familiar condition, the model        much exposure you need with an individual in order for them
correctly identified the first individual (with all 20 images be-     to be consolidated in long-term memory, and whether or not
ing classified as the correct familiar person), while mostly          this requires sleep.
correctly classifying the second individual (with 17/20 im-                                        References
ages). There were three minor misclassifications for the sec-         Balas, B., Cox, D., & Conwell, E. (2007). The effect of real-world
ond individual, resulting in a third cluster being formed.               personal familiarity on the speed of face information processing.
    These results seem to reflect those found by Jenkins et al.          PloS One, 2(11), e1223.
                                                                      Blanz, V., & Vetter, T. (1999). A morphable model for the synthesis
(2011). Namely, the model also over-clusters the space when              of 3d faces. In Proceedings of the 26th annual conference on
the identities are unfamiliar, but makes only three mistakes             computer graphics and interactive techniques (pp. 187–194).
when the identities are familiar. In the latents recognition          Bruce, V., & Young, A. (1986). Understanding face recognition.
                                                                         British journal of psychology, 77(3), 305–327.
network, the inferred latents depend substantially on pose            Burton, A. M., Bruce, V., & Hancock, P. J. (1999). From pixels to
and lighting, and thus are not successfully ignored in clus-             people: A model of familiar face recognition. Cognitive Science,
tering unfamiliar faces. In the familiar network, these invari-          23(1), 1–31.
                                                                      Dayan, P., Hinton, G. E., Neal, R. M., & Zemel, R. S. (1995). The
ances are successfully learned, allowing for accurate cluster-           helmholtz machine. Neural Computation, 7, 889–904.
ing. Additionally, matching humans, the model never forms             Eifuku, S., De Souza, W. C., Nakata, R., Ono, T., & Tamura, R.
clusters which have images from the two different identities             (2011). Neural representations of personally familiar and unfa-
                                                                         miliar faces in the anterior inferior temporal cortex of monkeys.
in either the familiar or unfamiliar conditions.                         PLoS One, 6(4), e18913.
                                                                      Germine, L., Duchaine, B., & Nakayama, K. (2011). Where cog-
                          Discussion                                     nitive development and aging meet: Face learning ability peaks
                                                                         after age 30. Cognition, 118, 201–210.
The model that we have described is both computationally              Jenkins, R., White, D., Van Montfort, X., & Burton, A. (2011).
powerful, and also qualitatively and quantitatively captures             Variability in photos of the same face. Cognition, 3, 313–323.
                                                                      Johnston, R. A., & Edmonds, A. J. (2009). Familiar and unfamiliar
human behavior across a wide range of different experiments.             face recognition: A review. Memory, 17(5), 577–596.
To our knowledge, this is the first model that learns new iden-       Kulkarni, T. D., Kohli, P., Tenenbaum, J. B., & Mansinghka, V.
tities in both an unsupervised and supervised way, and can               (2015). Picture: An imperative probabilistic programming lan-
                                                                         guage for scene perception. Computer Vision and Pattern Recog-
account for both effects of familiar and unfamiliar face recog-          nition.
nition.                                                               Leibo, J. Z., Mutch, J., & Poggio, T. (2011). Why the brain separates
                                                                         face recognition from object recognition. In Advances in neural
    First, we showed how the unfamiliar component of the                 information processing systems (pp. 711–719).
model can predict the patterns of viewpoint generalization            Murray, I., Adams, R. P., & MacKay, D. J. (2009). Elliptical slice
found by O’Toole et al. (1998), even with no explicit view-              sampling. arXiv preprint arXiv:1001.0175.
                                                                      Natu, V., & O’Toole, A. J. (2011). The neural processing of familiar
point dependence built in. Although the model is 3 dimen-                and unfamiliar faces: A review and synopsis. British Journal of
sional, the reconstruction accuracy is constrained by the fact           Psychology, 102(4), 726–747.
that there may be multiple sets of generative parameters that         O’Toole, A. J., Edelman, S., & Bülthoff, H. H. (1998). Stimulus-
                                                                         specific effects in face recognition over changes in viewpoint. Vi-
give rise to the same 2D view, which leads to this viewpoint             sion research, 38(15), 2351–2363.
dependent generalization. Second, we show how recognition             Simonyan, K., & Zisserman, A. (2014). Very deep convolu-
of familiar faces can proceed significantly faster than for un-          tional networks for large-scale image recognition. arXiv preprint
                                                                         arXiv:1409.1556.
familiar faces, predicting the experimental results from Balas        Yildirim, I., Kulkarni, T., Freiwald, W., & Tenenbaum, J. (2015).
et al. (2007). We discussed how this could result either from a          Efficient analysis-by-synthesis in vision: A computational frame-
comparison in the latent space (where a good estimate of the             work, behavioral tests, and comparison with neural representa-
                                                                         tions. In Proceedings of the thirty-seventh annual conference of
latents may be required, and the estimates get better faster for         the cognitive science society.
familiar faces) or by a projection back to image space, which
                                                                  2500

