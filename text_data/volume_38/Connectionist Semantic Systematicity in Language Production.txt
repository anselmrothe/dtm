                 Connectionist Semantic Systematicity in Language Production
                                          Jesús Calvillo (jesusc@coli.uni-saarland.de)
                                       Harm Brouwer (brouwer@coli.uni-saarland.de)
                                     Matthew W. Crocker (crocker@coli.uni-saarland.de)
                                                      Saarland University, Germany
                             Abstract                                  language production, and present a connectionist production
                                                                       model that generates sentences from these rich situation mod-
   A novel connectionist model of sentence production is pre-
   sented, which employs rich situation model representations          els. We show that our model successfully learns to produce
   originally proposed for modeling systematicity in comprehen-        sentences from these rich meaning representations. Crucially,
   sion (Frank, Haselager, & van Rooij, 2009). The high overall        we demonstrate that this model is able to describe unseen
   performance of our model demonstrates that such represen-
   tations are not only suitable for comprehension, but also for       situations, demonstrating semantic systematicity similar to
   modeling language production. Further, the model is able to         Frank et al. (2009), as well as produce alternative encodings
   produce novel encodings (active vs. passive) for a particular       (e.g. active/passive) for a given situation, that were not seen
   semantics, as well as generate such encodings for previously
   unseen situations, thus demonstrating both syntactic and se-        during training and thus demonstrate syntactic systematicity.
   mantic systematicity. Our results provide yet further evidence
   that such connectionist approaches can achieve systematicity,                                  Method
   in production as well as comprehension.
   Keywords: systematicity; sentence production; connectionist;        We employ an extended Simple Recurrent Neural Network
   semantics; syntax; neural networks                                  architecture (SRN) (Elman, 1990) to generate sentences from
                                                                       rich semantic representations, called Distributed Situation
                         Introduction                                  Space (DSS) vectors. The DSS model (Frank, Koppen, No-
A defining characteristic of human language is systematicity:          ordman, & Vonk, 2003; Frank et al., 2009) is a distributed
“the ability to produce/understand some sentences is intrin-           scheme for meaning, in which the meaning of a situation—a
sically connected to the ability to produce/understand certain         state of affairs—is represented as a situation vector in a high-
others” (Fodor & Pylyshyn, 1988, p. 37). Further, Fodor                dimensional “situation-state space”.
and Pylyshyn (1988) argue that connectionist models are not               This section is organized as follows: first, we introduce
able to display systematicity without implementing a classi-           the Distributed Situation Space as described by Frank et al.
cal symbol system.                                                     (2003, 2009); then, we explain the vectors that we use as well
   The connectionist comprehension model developed by                  as the architecture of the model; afterwards the training and
Frank et al. (2009), however, challenges this highly debated           evaluation schema is presented; and finally we present the
assertion, by developing a connectionist model of compre-              results obtained from the evaluation.
hension which is argued to achieve relevant levels of system-
aticity. Their model constructs a a situation model (see Zwaan         Distributed Situation Space
and Radvansky (1998)) of the state-of-affairs described by a           The DSS model defines a microworld in terms of a fi-
sentence that also incorporates world knowledge-driven in-             nite set of basic events (e.g., play(charlie, chess) and
ferences. When the model processes a sentence like ‘a boy              place(heidi, bedroom))—the smallest meaning-discerning
plays soccer’, for instance, it not only recovers the explicit,        units of propositional meaning in that world. While these
literal propositional content, but also constructs a more com-         basic events can be defined in several ways, we adopt the
plete situation model in which a boy is likely playing outside         microworld presented by Frank et al. (2009). Situations
on a field, with a ball, with others, and so forth. In this way it     in a microworld are represented in terms of these basic
differs from other connectionist models of language compre-            events, which can be conjoined to form complex events (e.g.,
hension and production, that typically employ simpler mean-            play(charlie, chess) ∧ win(charlie)). Not all conjunctions of
ing representations, such as case-roles (Chang, Dell, & Bock,          basic events are, however, possible or equally likely. That
2006; Mayberry, Crocker, & Knoeferle, 2009; Brouwer,                   is, world knowledge can pose both hard (e.g., physical)
2014, among others). Crucially, Frank et al. (2009)’s model            and probabilistic (e.g., preferential) constraints on event co-
generalizes to both sentences and situations that it has not           occurrence. A situation-state space is a large set of m situa-
seen during training, exhibiting different levels of semantic          tions defined in terms of n basic events, effectively yielding
systematicity and is argued to provide an important step in            an m × n matrix (see Table 1). Each of the m situations in this
the direction of psychologically plausible models of language          matrix is encoded by setting basic events that are the case
comprehension.                                                         in a given situation to 1 (True) and those that are not to 0
   In the present paper, we examine whether the approach               (False). A situation-state space matrix is constructed by sam-
developed by Frank et al. (2009), is equally well suited to            pling m situations (using a non-deterministic sampling proce-
                                                                   2555

                                                                                                        to the sentence.1 In other words, each dimension represents
                Table 1: Situation-state space.
                                                                                                        how likely each basic event is to be true, given the situation
                                                                                                        that is expressed by the sentence.
                                   basic event1   basic event2   basic event3         basic eventn
                                                                                                        The Model
                                                                                ...                     Our model architecture, as we can see in Figure 1, is broadly
   situation1                       1              0               0            ...     1               similar to the one used by Frank et al. (2009), with the main
   situation2                       0              1               1            ...     1               difference being that the inputs and outputs are reversed; it
   situation3                       1              1               0            ...     0               maps DSS representations onto sequences of localist word
                                                                                                        representations. Similar to Frank et al. (2009), we stress that
   ...                              .              .               .            ...     .
                                                                                                        it is not intended to model human language development.
   situationm                       0              1               0            ...     0
                                                                                                            The model consists of a 45-unit input layer, a 120-unit re-
                                                                                                        current hidden (tanh) layer, and a 43 unit (softmax) output
                                                                                                        layer. The dimensionality of the input layer corresponds to
dure) such that no situation violates any hard world knowl-                                             the 44 basic events in the microworld, plus one extra binary
edge constraints, and such that the m situations approximate                                            unit that indicates whether the model must output an active
the probabilistic nature of the microworld in terms of the (co-                                         sentence (1), or a passive one (0). The dimensionality of the
)occurrence probability of the n basic events. The resulting                                            output layer matches the number of available words in the
situation-state space matrix is then effectively one big truth                                          grammar (42), plus the end-of-sentence marker.
table, in which each column represents the situation vector                                                 Time in the model is discrete. At each time-step t, acti-
for an individual basic event; that is, each column of the                                              vation propagates forward following the trajectory: input →
matrix encodes the meaning of a basic event in terms of its                                             hidden → output. The activation of the output layer yields a
co-occurrence with all other basic events. The situation vec-                                           probability distribution over the available words. We define
tors of complex events (combinations of basic events) can be                                            the word produced at time-step t as the one with highest prob-
found through propositional logic, allowing to capture phe-                                             ability (highest activation). The model stops producing words
nomena such as negation, conjunction and disjunction; con-                                              when an end-of-sentence marker has been produced.
versely, complex events also allow us to capture aspects of                                                 The hidden layer also receives a copy of its own activation
modality and quantification.                                                                            pattern at the previous time-step t −1, through a 120-unit con-
   This situation-state space encodes all knowledge about the                                           text layer, which is set to zero at the beginning of each sen-
microworld, and situation vectors capture dependencies be-                                              tence. These units help to preserve some memory of what has
tween situations in this space, thereby allowing for ‘world                                             been produced expanding several time steps in the past, and
knowledge’-driven inference.                                                                            allow the model to generate sentences of variable length.
   DSS representations have been successfully used in a con-                                                In addition, the hidden layer receives the identity of the
nectionist comprehension model (Frank et al., 2009). That                                               word that was produced at time-step t − 1 (zeros at t = 0)
is, Frank et al. (2009) defined a small microworld (see sec-                                            through monitoring units that connect the output layer to the
tion two of their paper), consisting of 44 basic events, cen-                                           hidden layer, where only the output unit corresponding to the
tred around three people, and a few games, toys, and places.                                            produced word at time-step t − 1 is activated (set to 1), while
They constructed a situation-state space by sampling 25, 000                                            all other units are set to 0.
situations in this microworld, and reduced the dimensional-                                                 Finally, the hidden and output layers also receive input
ity of the resulting 25k-dimensional situation vectors to 150-                                          from a bias unit (with a constant activation value of 1).
dimensions using a competitive layer algorithm. Using these
reduced vectors, they show that their model is not only able                                            Examples Set
to comprehend sentences that it has seen during training, but                                           The examples set consists of a set of pairs
that is also able to comprehend sentences and situations that it                                        {(DSS1 , ϕ1 ), . . . , (DSSn , ϕn ))} where each DSSi ∈ [0, 1]45
has never seen before (i.e., it shows semantic systematicity).                                          corresponds to a DSS representation plus an extra bit indi-
   The vectors that we use for production are slightly differ-                                          cating whether the system must produce an active sentence
ent. Namely, the dimensionality of the situation-space was                                              (1) or a passive one (0); and ϕi = {sent1 , . . . , sentk } where
not reduced, since its reduction involves some loss of infor-                                           sent j is a sentence, a sequence of words word1 , . . . , wordn ,
mation. Rather, for each 25k-dimensional situation vector as-                                           expressing the information contained in DSSi . Each set
sociated to a particular sentence, which in turn is associated                                          ϕi represents all the possible sentences that express the
to a (complex) event; we compute a belief situation vector,
whose dimensionality is equal to the number of basic events                                                 1 This vector is computed by calculating the dot product between
in the microworld (44 in this case) and the value of each di-                                           the situation-state matrix and the original 25k-dimensional situation
                                                                                                        vector, and then normalizing each dimension of the resulting vec-
mension is equal to the conditional probability of the corre-                                           tor by the sum over the dimensions of the original 25k-dimensional
sponding basic event, given the (complex) event associated                                              situation vector.
                                                                                                     2556

                                                                      • Condition 1: Situations for which the model has seen only
                                                                         active sentences, and a passive is queried.
                                                                      • Condition 2: Situations for which the model has seen only
                                                                         passive sentences, and an active is queried.
                                                                      • Condition 3: Completely new situations (not seen during
                                                                         training), passive and active sentences are queried.
                                                                         The second set (setA) allowed for two different testing con-
                                                                      ditions:
                                                                      • Condition 4: Situations for which the model has seen only
                                                                         active sentences, and a passive is queried.
                                                                      • Condition 5: Completely new situations (not seen during
                  Figure 1: Model architecture.
                                                                         training), passive and active sentences are queried.
                                                                         These conditions represent different levels of generaliza-
information contained in the corresponding DSSi and in the
                                                                      tion or systematicity. In all cases, the queried sentence type
expected voice.
                                                                      has never been seen by the model. For conditions 1, 2 and 4
   The sentences that we use are those generated by the mi-
                                                                      the model has seen the situation but not in the queried voice.
crolanguage defined by Frank et al. (2009) (see their Tables
                                                                      Importantly, for conditions 3 and 5, the model has never seen
5–8). This microlanguage consists of 40 words that can be
                                                                      the situation itself. Finally, for conditions 4 and 5, where pas-
combined into 13556 sentences according to its grammar. We
                                                                      sives are queried, not only the system has not seen the passive
minimally modified this grammar. First, we introduced the
                                                                      sentences, but also they are not defined by the grammar.
determiners that were missing (a, the); and second, we added
                                                                         SetAP was randomly shuffled and split into 10 folds of
an end-of-sentence marker (a period) to the sentences. Leav-
                                                                      90% training and 10% testing DSS representations, meaning
ing a total of 43 words that were encoded at the output layer
                                                                      per fold 382 training and 42 testing situations. For each fold,
as localist vectors.
                                                                      the testing DSS representations were further split into the 3
   Sentences that expressed unlawful situations according to
                                                                      conditions, rendering 14 different testing DSS representations
the microworld rules, and therefore whose DSS belief vec-
                                                                      per condition, per fold.
tors were empty, were discarded; leaving a total of 8201 law-
                                                                         SetA was also shuffled and split into 10 folds, but in order
ful sentences. From these, 6782 sentences were in active
                                                                      to preserve uniformity, for each fold and for testing, 14 DSS
voice and 1419 in passive. Note that this set contains sen-
                                                                      representations were drawn per condition; meaning that each
tences with simple semantics (e.g., “charlie plays chess .” →
                                                                      fold contained 28 testing and 330 training DSS representa-
play(charlie, chess)), as well as sentences with complex se-
                                                                      tions.
mantics (e.g., “a girl plays chess .” → play(heidi, chess) ∨
                                                                         Finally, for condition 1 the DSS representations were cou-
play(sophia, chess)).
                                                                      pled with their corresponding active sentences and incorpo-
   There were a total of 782 unique DSS representations,
                                                                      rated into the training set (while the passive sentences re-
from which 424 were related to both passive and active sen-
                                                                      mained in the testing set); vice-versa for condition 2. Sim-
tences. The rest (358) corresponded to situations that could
                                                                      ilarly, for condition 4 the active sentences were incorporated
only be expressed by active sentences according to the gram-
                                                                      into the training set, while during testing the system will be
mar. More concretely, the grammar presented in Frank et al.
                                                                      queried for a passive construction, even though there is none
(2009) does not define passive sentences for situations where
                                                                      according to the grammar.
the object of the action is either a person (e.g. “Heidi beats
Charlie.”) or undefined (e.g. “Charlie plays.”).                      Training Procedure We trained the model using cross-
                                                                      entropy backpropagation (Rumelhart, Hinton, & Williams,
Training and Evaluation                                               1986) with weight updates after each word in the sentence
In order to asses the performance of the model in terms of            of each training item. Prior to training, all weights on the
accuracy and generalization, we employed a 10-fold cross-             projections between layers were initialized with random val-
validation schema. First, we divided the DSS representations          ues drawn from a normal distribution N (0, 0.1). The weights
into two sets: the first one (setAP) corresponding to those           on the bias projections were initially set to zero.
associated to both active and passive sentences and the second           During training, the monitoring units were set at time t to
one (setA) corresponding to DSS representations that were             what the model was supposed to produce at time t − 1 (ze-
related only to active sentences.                                     ros for t = 0). This reflects the notion that during training
   The first set (setAP) allowed for three different testing con-     the word contained in the training sentence at time-step t − 1
ditions:                                                              should be the one informing the next time step, regardless of
                                                                  2557

                                                                      different set of weight matrices. The scores reported below
       Table 2: Similarity scores for each test condition.
                                                                      are averaged over these instances.
  Cond.      Query        Similarity (%)        PerfectMatch (%)         On the training set, the model achieved an average simi-
     1         pas               97.66                  87.86         larity score of 99.43% (and 98, 23% perfect matches). This
     2         act               97.58                  92.86         shows that the model is able to learn to transform a DSS situ-
     3         act               98.35                  93.57         ation vector into a sequence of words describing the state-of-
     3         pas               96.79                  83.57         affairs that the vector represents.
     5         act               95.08                   85.0            Regarding the test conditions, Table 2 shows the average
                                                                      similarity scores for each of them. For conditions 4 and 5,
                                                                      where passives are queried but there are no example sentences
the previously produced (and possibly different) word. Dur-           given by the grammar, no similarity scores can be computed
ing testing, the monitoring units are set to 1.0 for the word         and in exchange a qualitative analysis will be presented.
that was actually produced and 0.0 everywhere else.                      We can notice a slight drop of similarity scores for con-
   The model was trained for a maximum of 200 epochs, each            dition 5. This could be explained because setA in general
epoch consisting of a full presentation of the training set,          contained fewer sentences per DSS, and thus fewer training
which was randomized before each epoch. Note that each                items.
item of this set consisted of a DSSi paired with one of the pos-         The average similarity score across all conditions is of
sible sentence realizations describing the state of affairs rep-      97.1%, with 88.57% of perfect matches. This translates into
resented in DSSi . Hence, during each epoch, the model saw            roughly one to three mistakes per condition and per fold. The
all the possible realizations of DSSi contained in the training       nature of these mistakes is addressed in the next section, how-
set for a given fold. We employed an initial learning rate of         ever we can observe that the performance in terms of similar-
0.124 which was halved each time there was no improvement             ity is very high and almost perfect in several cases.
of performance on the training set during 15 epochs. No mo-
mentum was used. Training halted if the maximum number                Qualitative Analysis Although the performance is quite
of epochs was reached or if there was no performance im-              high, the model elicits a number of systematic mistakes that
provement on the training set over a 40-epoch interval.               provides us with some insight into the internal mechanism
                                                                      that is implemented by the network. Examples of these are
Sentence Level Evaluation For a given DSS representa-                 shown in Table 3.
tion DSSi , the model produces a sequence of words sˆi con-              Taking a qualitative look into the produced sentences, it
stituting a sentence describing the state-of-affairs represented      is evident that, with literally a couple of exceptions, all the
in DSSi . Because a DSSi can be described by one or more              sentences produced are syntactically correct and semantically
sentence(s), we assume that the output of the model is perfect        felicitous. The vast majority of the elicited mistakes oc-
if the sentence produced sˆi is part of the set ϕi of all possible    cur when the model produces a sentence that is semantically
realizations of DSSi in the queried voice.                            highly similar to the one expected. This pattern can be seen
   However, sometimes the output of the model sˆi for a DSSi          already during training, where the mistakes correspond to sit-
does not perfectly match any of the sentences in ϕi . As such,        uations that are closely related, so the model is unable to
we also compute the similarity between the output of the              distinguish them, even though it has already seen the situa-
model sˆi , and each sentence in ϕi . This similarity is derived      tions/sentences (examples 1-3 in Table 3).
from their Levenshtein distance (Levenshtein, 1966); which               For the conditions shown in Table 2, the errors elicited dur-
is the number of insertions, deletions or substitutions that are      ing 5 folds were manually inspected in order to see their regu-
needed in order to transform one string into another. More            larities. The errors observed (38 in total) can be classified into
formally, Levenshtein similarity sim(s1 , s2 ) between two sen-       2 main categories: the first one (63.2%) being errors concern-
tences s1 and s2 is defined as:                                       ing over and underspecification, and the second one (31.6%)
                                                                      corresponding to situations that because of the design of the
                                      distance(s1 , s2 )
         sim(s1 , s2 ) = 1 −                                   (1)    microworld are remarkably similar, differing only in one as-
                               max(length(s1 ), length(s2 ))          pect.
where distance is the Levenshtein distance. This similarity              Concerning the first category, the errors can be further split
measure is 0 when the sentences are completely different and          into location under- (21.05%) and over- (7.9%) specification
1 when they are the same. Thus, for each item i in the training       (examples 4-5 in Table 3), subject under- (15.8%) and over-
and test set, we obtain a similarity value:                           (10.5%) specification (examples 6-7 in Table 3), and object
                                                                      under- (2.6%) and over- (5.2%) specification (examples 8-9
                       sim(sˆi ) = max sim(sˆi , s)            (2)    in Table 3).
                                    s∈ϕi
                                                                         The errors contained in the second category (examples 10-
Results                                                               12 in Table 3) correspond to sentences that at first glance
We trained 10 instances of the model, corresponding to each           seem correct, it is only after taking a deep look into the mi-
fold as described above. Each instance was initialized with a         croworld that one can see the mistake. First, according to this
                                                                  2558

                                                Table 3: Examples of representative output errors.
                                               Output                                                     Expected
                1   someone plays with a ball outside .                      a girl plays with a ball outside .
                2   someone loses in the bedroom .                           someone wins in the bedroom .
                3   a girl loses to someone in the bedroom .                 someone beats a girl at a game in the bedroom .
                4   Sophia beats Heidi with ease at hide and seek .          Sophia beats Heidi with ease at hide and seek in the bedroom .
                5   Sophia wins with ease at a game in the street .          Sophia wins with ease at a game outside .
                6   a girl plays with a doll inside .                        Heidi plays with a doll inside .
                7   a game is won with ease by a girl in the bathroom .      a game is won with ease by someone in the bathroom .
                8   someone plays .                                          someone plays with a toy .
                9   Charlie plays a game in the street .                     Charlie plays in the street .
                10  someone wins in the bedroom at hide and seek .           someone loses in the bedroom at hide and seek .
                11  Heidi loses to someone in the bedroom at hide and seek . someone beats Heidi in the bedroom at hide and seek .
                12  Sophia beats someone at hide and seek in the bedroom .   someone loses to Sophia at hide and seek in the bedroom .
microworld, whenever there is a winner, there is also a loser,                and that this object is never a person. Therefore, for each
which means that sentences that are apparently contradictory                  situation it tries first to find this object and then it tries to
(“someone loses.” vs “someone wins.”) actually have the                       describe the rest of the situation.
same implications within the microworld and therefore are                         Concerning winning/losing situations (examples 1-2 in Ta-
semantically identical. Second, in general whenever there is                  ble 4), which conform 92.9% of the analyzed situations, the
a winner/loser, the loser is usually situated in the same loca-               object is always a game because in the microworld win-
tion as the winner. However, only for the game hide and seek                  ning/losing can only happen while playing a game. Thus,
and when the participants are inside, the loser can be in the                 the model produces the specific name of the game when it is
bedroom, while the winner could be in the bathroom, or vice-                  known (e.g. “soccer is...”), otherwise the sentence starts with
versa. Finally, whenever there is a prepositional phrase (“in                 “a game is...”. Then one of the players is mentioned (one
the bedroom”), it is attached to the subject of the sentence                  omitted) and the rest of the situation is portrayed.
according to the grammar, which means that in “Heidi beats                        For the case of situations with an underspecified object
Sophie in the bedroom”, Heidi is in the bedroom while So-                     (7.1%, examples 3-4 in Table 4), it is unknown whether the
phie could be in either the bedroom or the bathroom, while in                 subject is playing a game or with a toy, so the model is forced
“Sophie loses to Heidi in the bedroom”, it is Sophie who stays                to choose one. In all cases the model chooses a toy, which
in the bedroom while Heidi could also be in the bathroom.                     seems reasonable because mostly the DSS representations of
Apart from this detail, the situations are almost identical.                  the underspecified sentences are more similar to situations
   According to the errors so far analyzed, we can conclude                   where a toy is played with. For example, the DSS representa-
that the nature of these is primarily related to situations that              tion of “someone plays.” is more similar to the one of “some-
are highly similar.                                                           one plays with a toy.” (99.36% cosine similarity) than to the
   With regard to the test conditions 4 and 5 where a passive                 representation of “someone plays a game.” (97.73% cosine
sentence is queried but the grammar does not properly define                  similarity).
its characterization, Table 4 presents examples of output sen-                    Similar to the other conditions, errors regarding over and
tences and the situations that they were supposed to portray.                 underspecification occur in conditions 4 and 5, but are rare
As mentioned before, these situations can be of two types:                    (example 5 in Table 4). And finally one type of error that ap-
the first one involving a winning/losing situation where both                 pears only for these situations corresponds to the interchange
actors are explicitly mentioned, and the second type being sit-               of the winner/loser in game situations (example 6 in Table 4).
uations where the object of the action is not defined. We took                    In sum, one can see from the output that the model is able
also a closer look into the output of the model for these condi-              to take the linguistic elements learned during training in or-
tions by manually making an analysis of the output of 3 folds                 der to characterize situations for which it has no experience,
(84 situations), whose results we will now present.                           while being as informative as possible. The only difficulty
   Even though in condition 4 the model has not seen the type                 appears to be the distinction of situations that are highly sim-
sentences that are queried, and that in condition 5 the model                 ilar. However, the performance of the model is very high in
has no experience with the queried situations, the sentences                  general and even for the sentences that do present a mistake,
produced by the model are mostly correct and coherent with                    the output is largely correct.
the semantic information that is given to it. One can see that
some information is omitted, however, this is expected since                                                    Discussion
the grammar itself does not contain rules that allow to fully                 The model learns to generate sentences from rich situation
encode these situations.                                                      representations, and furthermore, it generalizes to novel sen-
   In general, the model learns during training that passive                  tences and situations.
sentences always start by mentioning the object of the action,                    We can see that the model is able to learn the syntactic
                                                                          2559

                        Table 4: Examples of passive output sentences for situations with no passive examples.
                                                Output                                                    Active Sentence
                 1  hide and seek is won with ease by Heidi in the playground . Heidi beats Sophia with ease in the playground at hide and seek .
                 2  a game is won with ease by Sophia .                         Sophia beats Charlie with ease .
                 3  a toy is played with .                                      someone plays .
                 4  a toy is played with in the playground by Sophia .          Sophia plays in the playground .
                 5  a game is lost with difficulty by Charlie .                 a girl beats Charlie with difficulty in the street .
                 6  chess is lost by Heidi in the bedroom .                     the boy loses to Heidi at chess in the bedroom .
patterns of the microworld and does not just memorize sen-                                                          Conclusion
tences, thus showing syntactic generalization. This was ob-                       We presented a novel connectionist model of sentence pro-
served in all test conditions, where the model was capable                        duction that uses the rich semantic representations described
of producing sentences that it had never seen before. This                        in Frank et al. (2009). This model is able to take such repre-
means that the model is able to generate new combinations                         sentations and produce sentences that accurately describe the
of words in such a way that the new combinations are in or-                       associated situations. The model is also able to produce al-
der with the syntactic rules of the grammar associated to the                     ternative encodings (e.g. active vs. passive) for a particular
microworld, while at the same time being coherent with the                        semantics, showing an overall high performance and demon-
semantic structures to which they are related.                                    strating that these semantic representations are not only suit-
    Crucially, the model also generalizes semantically, as                        able for comprehension, but also for modeling language pro-
demonstrated in test conditions 3 and 5, since the semantic                       duction. And furthermore, the model is able to generate novel
representations given to the model are completely novel to                        sentences for previously unseen situations, thus demonstrat-
it, so any correct output can be regarded as arising from the                     ing syntactic and semantic systematicity.
regularities within the microworld from which the DSS rep-
resentations are derived—cf. the comprehension results by                                                           References
Frank et al. (2009).                                                              Brouwer, H. (2014). The electrophysiology of language com-
    We hypothesize that the fact that the model has difficul-                        prehension: A neurocomputational model. Unpublished
ties with highly similar situations means that the model is                          doctoral dissertation, University of Groningen.
able to roughly reconstruct the topography of the microworld                      Chang, F., Dell, G., & Bock, K. (2006). Becoming syntactic.
semantic space, putting together situations that are semanti-                        Psychological review, 113(2), 234.
cally related. At the same time, the model assigns linguistic                     Elman, J. L. (1990). Finding structure in time. Cognitive
structures to each area in this semantic space such that se-                         Science, 14(2), 179–211.
mantically similar situations are assigned linguistically simi-                   Fodor, J. A., & Pylyshyn, Z. W. (1988). Connectionism and
lar realizations. Given that in practice the semantic space is a                     cognitive architecture: A critical analysis. Cognition, 28(1-
continuous 44-dimensional space, in theory the model should                          2), 3–71.
be able to generate sentences for unseen areas as long as it is                   Frank, S. L., Haselager, W. F. G., & van Rooij, I. (2009).
given enough information during training in order to recon-                          Connectionist semantic systematicity. Cognition, 110(3),
struct the semantic space and the mapping between semantics                          358–379.
and linguistic realizations, as proposed by Frank et al. (2009).                  Frank, S. L., Koppen, M., Noordman, L. G. M., & Vonk,
    The results of the test conditions show that it is indeed the                    W. (2003). Modeling knowledge-based inferences in story
case. Conditions 3 and 5 demonstrated that the model is able                         comprehension. Cognitive Science, 27(6), 875–910.
to generate sentences for unseen areas in the semantic space,                     Levenshtein, V. I. (1966). Binary codes capable of correct-
therefore showing semantic systematicity. Conditions 1 and                           ing deletions, insertions, and reversals. In Soviet physics
2 demonstrated that the model is able to generate sentences                          doklady (Vol. 10, pp. 707–710).
for semantically known situations but with a different voice                      Mayberry, M. R., Crocker, M. W., & Knoeferle, P. (2009).
(active/passive), showing syntactic systematicity. Conditions                        Learning to attend: A connectionist model of situated lan-
4 and 5, where passive sentences are queried, demonstrated                           guage comprehension. Cognitive Science, 33(3), 449–496.
that it is able to produce coherent sentences even if the gram-                   Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986).
mar that was used to construct the training/testing sets does                        Learning representations by back-propagating errors. Na-
not associate passive constructions with these situations.                           ture, 323(6088), 533–536.
    As it is now, the semantic space related to the microworld                    Zwaan, R. A., & Radvansky, G. A. (1998). Situation models
that we use is finite, however we were able to show different                        in language comprehension and memory. Psychological
levels of systematicity for unknown areas of this space, which                       Bulletin, 123(2), 162–185.
was our main objective. In principle, the microworld can be
extended by adding elements to the set of basic events, and
words to its vocabulary.
                                                                             2560

