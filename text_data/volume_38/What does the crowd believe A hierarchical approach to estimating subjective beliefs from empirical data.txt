   What does the crowd believe? A hierarchical approach to estimating subjective
                                                   beliefs from empirical data
                                       Michael Franke, Fabian Dablander, Anthea Schöller
                                {michael.franke, fabian.dablander, anthea.schoeller}@uni-tuebingen.de
                                                 Department of Linguistics, Wilhelmstraße 19
                                                           72074 Tübingen, Germany
                  Erin Bennett, Judith Degen, Michael Henry Tessler, Justine Kao, Noah D. Goodman
                                     {ebennett, jdegen, mtessler, justinek, ngoodman}@stanford.edu
                                                Department of Psychology, Stanford University
                                                   450 Serra Mall, Stanford, CA 94305 USA
                               Abstract                                   about everyday events (Griffiths & Tenenbaum, 2006), refer-
                                                                          ential reasoning (Frank & Goodman, 2012), strength of prag-
   People’s beliefs about everyday events are both of theoreti-
   cal interest in their own right and an important ingredient in         matic enrichments (Degen, Tessler, & Goodman, 2015), or
   model building—especially in Bayesian cognitive models of              quantifier interpretation (Schöller & Franke, 2015).
   phenomena such as logical reasoning, future predictions, and
   language use. Here, we explore several recently used methods              Many methods have been used to build prior distributions
   for measuring subjective beliefs about unidimensional contigu-         used in Bayesian cognitive models. One method of getting at
   ous properties, such as the likely price of a new watch. As            subjective beliefs is to take actual frequencies as an approx-
   a first step towards a way of assessing and comparing belief
   elicitation methods, we use hierarchical Bayesian modeling for         imation to subjective beliefs (e.g. Griffiths & Tenenbaum,
   inferring likely population-level beliefs as the central tendency      2006). Unfortunately, frequency data may be unavailable
   of participants’ individual-level beliefs. Three different depen-      (e.g., one-shot events) or deviate from participants’ subjec-
   dent measures are considered: (i) slider ratings of (relative)
   likelihood of intervals of values, (ii) a give-a-number task, and      tive beliefs in crucial respects.
   (iii) choice of the more likely of two intervals of values. Our           Another common approach is to empirically measure sub-
   results suggest that using averaged normalized slider ratings          jective beliefs by give-a-number tasks. The simplest version
   for binned quantities is a practical and fairly good approxima-
   tor of inferred population-level beliefs.                              would be this: being told that John just bought a new watch,
   Keywords:        subjective beliefs, hierarchical modeling,            participants are asked for a single numerical estimate of its
   Bayesian data analysis, Bayesian cognitive models                      price. This task is easy to comprehend and implement, but
                                                                          a single number does not provide much information about
                            Motivation                                    the subjective belief that it is a manifestation of. One solu-
                                                                          tion is to infer which parameterized distribution best explains
When trying to understand observed behavior we readily as-
                                                                          the observed number choices, either at the individual level
cribe beliefs and desires to fellow agents. This happens in-
                                                                          (Manski, 2004) or at the population level (Tauber & Steyvers,
tuitively, in folk psychology, but also in science. Scientific
                                                                          2013). More sophisticated give-a-number tasks give more in-
ascription of latent mental states plays an important role in
                                                                          formation, but can be difficult to implement and analyze.
many explanations of higher-order cognition: decision mak-
ing, reasoning, language use, etc. It is therefore vital to have             More complex elicitation methods include scoring rules
methods for validating explanatory mental state ascriptions.              (Savage, 1971; Andersen, Fountain, Harrison, & Rutström,
   A family of models where this is particularly pressing are             2014; Schlag, Tremewan, & van der Weele, online first),
Bayesian models of cognition which seek to explain task be-               prominent in economics, and the iterated learning paradigm
havior in a variety of domains as partially informed by what              (Lewandowsky, Griffiths, & Kalish, 2009). These methods
participants believe about mundane events—their prior be-                 are powerful but difficult to implement, and often assume
liefs. Take interpretation of language. “That watch cost a                very specific behavior from participants—such as optimal de-
million dollars,” tends to be interpreted as hyperbole: convey-           cision making under perfect knowledge of the payoff scheme.
ing affect rather than literal truth. Empirical data on whether              In sum, there is a tradeoff between simplicity of paradigms
similar statements are understood as hyperbole can be ex-                 and their information content. Ideally, we would like to have
plained well by a Bayesian model of utterance interpretation              an experimental method for measuring subjective beliefs that
(Kao, Wu, Bergen, & Goodman, 2014). This model assigns a                  (i) provides sufficient and reliable-enough information about
crucial role to an empirical measure of participants’ expecta-            subjective beliefs to derive testable predictions from cognitive
tions about the likely or normal price of a watch—only when               models that rely on such information, (ii) is easy to under-
the uttered price is sufficiently unlikely a priori will hyper-           stand by participants, (iii) is easy to implement, and that (iv)
bolic interpretation be possible. Other examples of domains               does not require sophisticated means of data analysis. More-
in which empirically successful models have included a mea-               over, the ideal method would be (v) flexible enough to allow
sure of participants’ prior beliefs include making predictions            inferred subjective belief distributions beyond standard pa-
                                                                     2669

    Item        Bins       ({min,   Context sentence      GAN question                    BH frame                 PC frame
                max} step; units)
    coffee      {<44, >200} 2;      X has just fetched    What do you think the tem-      His coffee was the fol-  The temperature of
                degrees             himself a cup of      perature of his coffee is?      lowing temperatures      his coffee is N de-
                                    coffee from the of-                                                            grees.
                                    fice vending ma-
                                    chine.
    commute     {0, >98} 7; min-    X commuted to         How many minutes do you         She commuted for the     She spent N min-
                utes                work yesterday.       think she spent commuting       following numbers of     utes commuting.
                                                          yesterday?                      minutes yesterday
    joke        {0, 14} 1; chil-    X told a joke to 14   How many of the kids do         The following number     N of the children
                dren                kids.                 you think laughed?              of kids laughed          laughed.
    laptop      {0, >7500} 500;     X bought a laptop.    How much do you think it        The laptop cost the fol- The laptop cost $N.
                dollars                                   cost?                           lowing numbers of dol-
                                                                                          lars
    marbles     {0, 14} 1; mar-     X threw 14 marbles    How many of the marbles         The following number     N of the marbles
                bles                into a pool.          do you think sank?              of marbles sank          sank.
    movies      {0, > 210} 16;      X just went to the    How many minutes long do        The movie was the        The movie was N
                minutes             movies to see a       you think the movie was?        following numbers of     minutes long.
                                    blockbuster.                                          minutes long
    TV          {0, >43}       3;   X watched TV last     How many hours do you           He watched TV for the    He spent N hours
                hours               week.                 think he spent watching TV      following numbers of     watching TV.
                                                          last week?                      hours last week
    watch       {0, >750} 50;       X bought a watch.     How much do you think it        It cost the following    The watch cost $N.
                dollars                                   cost?                           numbers of dollars
         Table 1: Experimental items. X was a randomly generated name (different on each trial). N was one of the bins.
rameterized distributions and (vi) would provide a good ap-             these issues by collecting data in a within-subject paradigm
proximation of the central tendency or average of subjective            from three task types: (i) binned histograms, (ii) give-a-
beliefs in a given population. The latter would allow using             number and (iii) paired comparisons. The latter asks par-
one set of participants for measuring prior beliefs and another         ticipants for a direct comparison of two bins from the binned
for whatever other task is of interest, so as to avoid potential        histograms task, and was included as a further consistency
cross-over effects.                                                     check. We used a Bayesian hierarchical model to analyze this
                                                                        data jointly. The model infers latent subjective beliefs, where
   A simple technique that seems to fit this bill is the binned
                                                                        each subjective belief is, intuitively, a noisy perturbation of
histogram task that has recently been used with apparent suc-
                                                                        a population-level belief. We find that mean a posteriori
cess (e.g. Kao, Wu, et al., 2014; Kao, Bergen, & Goodman,
                                                                        population-level beliefs are approximated well by mean slider
2014; Tessler, 2015; Schöller & Franke, 2015). Participants
                                                                        ratings from the binned-histograms task, suggesting that this
adjust sliders to express (relative) subjective beliefs about
                                                                        may indeed be a sound and easy measure of what the crowd
how likely it is that the value of an uncertain contiguous quan-
                                                                        believes. Moreover, the model is able to capture participants’
tity lies in some interval of possible values (a bin). E.g., to re-
                                                                        behavior in all three task types reasonably well, suggesting
port beliefs about a watch’s price, participants adjust sliders
                                                                        that what mean slider ratings measure is what we think it is: a
whose endpoints are labelled “extremely likely” and “impos-
                                                                        population-level central tendency of latent subjective beliefs.
sible.” Each slider corresponds to one of 15 bins that partition
the range of plausible values (established by a pre-test), such               Experimental elicitation of prior beliefs
as “$0-$50”, “$50-$100”, etc. up to “$700-$750” and “more
                                                                        Participants, procedure and materials We recruited 20
than $750.” Each participant’s slider ratings are normalized
                                                                        self-reported English native speakers over Mechanical Turk
and the results averaged across participants. The resulting
                                                                        and collected responses for eight different items (listed in
mean slider ratings look like plausible population-level be-
                                                                        Table 1) using the three different dependent measures men-
liefs and give good results when fed into cognitive models
                                                                        tioned above. Each participant rated each item using each
that predict task behavior based on prior expectations.
                                                                        dependent measure. Trial order was randomized.
   Explanatory success aside, the question remains whether                 On give-a-number (GAN) trials, participants saw the con-
mean slider ratings measure what we would like them to.                 text sentence and GAN question for each item (see Table 1)
Are these good approximations of a central tendency of par-             and provided one number by adjusting a slider with endpoints
ticipants’ individual beliefs? Are these measures consistent            labeled as the lowest and highest number for that item. Min
with participants’ behavior in other tasks, such as give-a-             and max numbers are shown in Table 1 and were taken from
number? To scrutinize the binned histogram task we address              previous studies that had used these items (Degen et al., 2015;
                                                                    2670

Schöller & Franke, 2015; Kao, Wu, et al., 2014). The se-
                                                                                                                                                                coffee                                                commute
lected number appeared above the slider so participants knew                                                                       0.4
                                                                                                                                                                                     0.3
exactly what the value of the slider would be.                                                                                     0.3                                               0.2
                                                                           mean slider rating / bin proportion of number choice
   On binned histogram (BH) trials, participants saw an                                                                            0.2
                                                                                                                                   0.1                         ● ● ● ● ●
                                                                                                                                                                                     0.1
                                                                                                                                                                                                ●
                                                                                                                                                                                                     ●
                                                                                                                                                                                                         ● ● ●
                                                                                                                                                                                                                      ●
                                                                                                                                                                                                                          ● ●
                                                                                                                                                                                                                              ● ●
                                                                                                                                                                         ● ●
item’s context sentence and were asked to Please rate how
                                                                                                                                                           ●                                                                      ● ●
                                                                                                                                             ● ● ● ●                         ● ●                                                      ● ● ●
                                                                                                                                                                                 ●
                                                                                                                                   0.0                                               0.0
likely it is that Y (where Y came from the corresponding BH                                                                       0.25
                                                                                                                                                                 joke
                                                                                                                                                                                     0.4
                                                                                                                                                                                                                          laptop
frame in Table 1). They adjusted 15 continuous sliders, one                                                                       0.20                                               0.3
                                                                                                                                  0.15
per bin, with five points labeled impossible, not very likely,                                                                    0.10                         ● ● ● ● ● ●
                                                                                                                                                                                     0.2
                                                                                                                                                                                                ●
                                                                                                                                                                                                     ●
                                                                                                                                                                                                         ●
                                                                                                                                                                                                             ●
neutral, very likely, and extremely likely. Bins were deter-                                                                                             ● ● ●             ●         0.1                          ●
                                                                                                                                  0.05           ● ● ● ●                                                              ●
                                                                                                                                             ●                                                                            ● ●
                                                                                                                                                                                                                              ● ● ● ● ● ●
                                                                                                                                  0.00                                               0.0                                                  ●
mined by dividing the interval spanned by the item’s mini-                                                                                                     marbles                                                    movies
mum and maximum value into equally sized bins (Table 1).                                                                          0.75
                                                                                                                                                                                     0.4
                                                                                                                                                                                     0.3
   On paired comparison (PC) trials, participants saw an                                                                          0.50                                               0.2
item’s context sentence and had to click on one of two op-
                                                                                                                                                                                                                              ● ●
                                                                                                                                  0.25                                           ●                                    ● ●           ●
                                                                                                                                                                                     0.1                                                 ●
                                                                                                                                                                                                                  ●                          ● ●
tions shown side by side – whichever one they thought was                                                                                    ● ● ● ● ● ● ● ● ● ● ● ● ● ●                                                                         ● ●
                                                                                                                                                                                                ● ● ● ●
                                                                                                                                  0.00                                               0.0
                                                                                                                                                                  tv                                                      watch
more likely. Each option used the appropriate PC frame in                                                                          0.3                                               0.3
Table 1 and numbers were filled in by comparing the follow-                                                                        0.2                                               0.2
ing bins: 1 vs 2, 2 vs 6, 6 vs 11, 11 vs 14, and 14 vs 15.                                                                         0.1       ●
                                                                                                                                               ●
                                                                                                                                                 ● ● ●
                                                                                                                                                       ●
                                                                                                                                                         ●                           0.1        ● ● ● ● ● ●
                                                                                                                                                                                                                          ●
Paired comparison trials always occurred as a block of five
                                                                                                                                                           ● ●                                                                ● ● ●
                                                                                                                                                               ● ● ●                                                                ● ● ●
                                                                                                                                                                     ● ● ●                                                                ● ●
                                                                                                                                   0.0                                               0.0
trials, with order of comparisons randomized within block.                                                                               0                 5             10     15          0                    5                  10            15
                                                                                                                                                                                     bin
Results Fig. 1 shows mean slider ratings alongside the fre-             (a) Red: proportion of bins corresponding to number choices on
                                                                        give-a-number trials. Black: mean slider ratings on binned his-
quencies of number choices in the give-a-number task. It                togram trials.
looks like the latter could be samples from the former, with
a tendency to modal choices. But some give-a-number re-                                                                           1.00
                                                                                                                                                                coffee
                                                                                                                                                                                     1.00
                                                                                                                                                                                                                      commute
sults seem influenced by a tendency towards round or salient                                                                      0.75
                                                                                                                                  0.50
                                                                                                                                                                                     0.75
                                                                                                                                                                                     0.50
numbers. E.g., in item coffee more than 40% of partici-                                                                           0.25
                                                                                                                                  0.00
                                                                                                                                                                                     0.25
                                                                                                                                                                                     0.00
pants guessed that a coffee from the vending machine was                                                                                                         joke                                                     laptop
                                                                           choce prop. higher bin
                                                                                                                                  1.00
ca. 150◦ F (bin 10). The results from the paired comparison                                                                       0.75
                                                                                                                                  0.50
                                                                                                                                                                                     0.75
                                                                                                                                                                                     0.50
seem consistent with the mean slider ratings as well, albeit                                                                      0.25                                               0.25
                                                                                                                                  0.00                                               0.00
not as straightforwardly as one might think. This is clearest                                                                                                  marbles                                                    movies
                                                                                                                                  1.00                                               1.00
from the marbles case. While the mean slider ratings suggest                                                                      0.75                                               0.75
that bins 2, 6 and 11 were considered roughly equiprobable                                                                        0.50
                                                                                                                                  0.25
                                                                                                                                                                                     0.50
                                                                                                                                                                                     0.25
on average, almost every participant chose the higher bin in                                                                      0.00
                                                                                                                                                                  tv
                                                                                                                                                                                     0.00
                                                                                                                                                                                                                          watch
direct bin comparisons 2 vs 6 and 6 vs 11. A potential ex-                                                                        1.00
                                                                                                                                  0.75
                                                                                                                                                                                     1.00
                                                                                                                                                                                     0.75
planation for this, which we will implement formally in the                                                                       0.50
                                                                                                                                  0.25
                                                                                                                                                                                     0.50
                                                                                                                                                                                     0.25
data-generating model, is that the paired comparison condi-                                                                       0.00
                                                                                                                                         1v           2v   6    11    14             0.00
                                                                                                                                                                                                1v           2v     6    11    14
                                                                                                                                                 s2     s 6 vs 11 vs 1 vs 1                         s2           s 6 vs 11 vs 1 vs 1
tion invited participants to think about what they thought was                                                                                                        4     5                                                  4     5
mostly likely the case (usually: bin 15 in the marbles case)                                                                                                                     condition
and to choose the bin that is closest to that.
                                                                           (b) Proportion of higher bin choices on paired comparison trials.
                             Model                                                    Figure 1: Average data. Bars are bootstrapped 95% CIs.
The data we would like to explain are: (i) the normalized               also because otherwise data from items with smaller domains
slider ratings si jk ∈ [0; 1] of participant i ∈ {1, . . . , 20} for    of plausible numbers would get more weight than data from
item j ∈ {1, . . . , 8} and bin k ∈ {1, . . . , 15} from the binned     items with a wider range of number choices. (Future work
histogram task; (ii) the bins ni j ∈ {1, . . . , 15} in which partic-   should investigate the relation to an explicit give-a-bin task.)
ipant i’s number choice for item j was in the give-a-number
                                                                           All three pieces of data are to be explained as functions
task; and (iii) the binary choices ci jl ∈ {0, 1} of whether par-
                                                                        of subjective beliefs Pi j , with Pi jk being participant i’s belief
ticipant i selected the higher bin for item j in the paired com-
                                                                        about the relative likelihood of bin k for item j. Each Pi j de-
parison task for each comparison l. There are two simpli-
                                                                        fines a likelihood for our data, via appropriate link functions.
fications in need of commenting. In (i), we focus on slider
                                                                        Variance in subjective beliefs is harnessed by a population-
ratings after normalizing for each participant, because we as-
                                                                        level hyper-prior with central tendency Q j . The structure of
sume that slider adjustments reflect relative, not absolute es-
                                                                        this model is pictured in Fig. 2.
timates of subjective beliefs. In (ii), we focus on bin choices,
not actual number choices, in order to avoid, as much as pos-              To fill the structure in Fig. 2 with life, we need to spell out
sible, considerations of salience of particular numbers, and            three parameterized link functions, one for each task type,
                                                                    2671

and the relation between population-level belief Q j and in-
                                                                                  bin k ∈ {1, . . . , 15}
dividual beliefs Pi j . Let’s start with the latter. The idea is
that Pi j are noise-perturbed variants scattered around Q j , with
                                                                                                Q jk             w
some parameter w to determine how much perturbation we
should expect. To realize this, the model assumes that Pi j are
distributed according to a Dirichlet distribution with weights
given by wQ j :
                                                                                               Pi jk            κ, σ       a          b
         Q j ∼ Dirichlet(1, . . . , 1)         w ∼ Gamma(2, 0.1)
         Pi j ∼ Dirichlet(wQ j )
The higher w, the more likely it is that Pi j is “close” to Q j .
                                                                                                si jk            ni j               ci jl
    The link function for the slider rating data uses a logit
transformation to project observed slider ratings si jk and la-
tent probabilities Pi jk , which are bound to lie between 0 and 1,                                                     item j ∈ {1, . . . , 8}
to the reals. The likelihood of logit-transformed observation                                                         subject i ∈ {1, . . . , 20}
si jk is given by a Gaussian with standard deviation σ around
the logit-transformed predictor Pi jk . On top of that, there is a     Figure 2: The data-generating model as a probabilistic graph-
parameter κ, the steepness of the logit transform of Pi jk , that      ical model, following conventions of Lee and Wagenmakers
allows response likelihoods to capture end-point affinity for          (2015). Shaded nodes are observed, white nodes are latent
κ > 1 (values of Pi jk close to 0 or 1 are likely mapped to 0 or       variables. Square nodes represent categorical, round nodes
1) or end-point aversion for κ < 0 (values of Pi jk are likely to      continuous variables. Boxes indicate scope of indices.
be realized as more median), with a prior that expects κ = 1.
                                                                                                          Inference
  logit(si jk ) ∼ Norm(logit(Pi jk , κ), σ)
              σ ∼ Gamma(0.0001, 0.0001) κ ∼ Gamma(5, 5)                The model was implemented in JAGS (Plummer, 2003).
                                                                       50,000 samples were obtained from two chains with a thin-
    The link function for number choice data treats each bin           ning rate of 2 after a burn-in of 100,000 that ensured conver-
ni j as a draw from a categorical distribution where the prob-         gence according to R̂ (Gelman & Rubin, 1992).
ability of bin k is proportional to exp(aPi j ), i.e., a soft-max         Means and bounds of 95% high-density intervals (HDIs)
choice from Pi j . The higher parameter a, the more likely ni j        of the posteriors for model parameters are in Table 2. Poste-
is the mode of Pi j . For a → 0, all bins become equiprobable.         rior credible levels of w allow for a limited amount of slack
        ni j ∼ Categorical(exp(aPi j ))          a ∼ Gamma(2, 1)       around Q j . Values for κ indicate that, on average, partici-
                                                                       pants had no preference for or against extreme slider ratings.
    Finally, consider the link function for bin comparisons.           Relatively high values of a indicate that participants, on av-
We are interested in the likelihood with which participant i           erage, had a strong tendency to choose modal values in the
selects the higher bin for item j in bin comparison condition          give-a-number task.
l. Suppose l is about comparing the lower bin bl to the higher
bh . Perhaps the most natural approach would be to link the                                   w            κ       σ        a               b
likelihood of choosing bh over bl to the difference between                      lower        14.65        0.98    0.26     22.04           1.11
Pi jbh and Pi jbl . However, as discussed above, this does not                    mean        15.55        0.99    0.28     27.43           1.27
appear to be what participants were doing. Indeed, a model                       upper        16.48        0.99    0.31     32.95           1.42
that implements this idea blatantly fails to capture the relevant         Table 2: Summary statistics for posteriors on parameters
regularities in the data. Another plausible link function is to
assume that what matters is the distance to the mode of Pi j :
                                                                          Posterior estimates of Q j are the most relevant. Fig. 3
soft-max prefer the bin that is closer to the mode of Pi j ; select
                                                                       shows their means with their 95% HDIs, alongside the mean
randomly if both bins are equally far from the prototype.1
                                                                       slider ratings. The latter provide a very good approxima-
                                          high
   ci jl ∼ Bern((1 + exp(2b(1 − pi jl )))−1 ) b ∼ Gamma(2, 1)          tion of the inferred population-level beliefs. Inspection of
                                                                       posteriors of individual Pi j shows that there is ample varia-
             2 if mode(Pi j ) is closer to higher
             
                                                                      tion between participants. Still, the way the model suggests
                   bin of l than to lower bin                          we should think about harnessing the individual Pi j s under
             
  high
             
pi jl =                                                                a population-level central tendency is closely approximated
             1 if equal distance
                                                                       by mean slider ratings. Although the match is not perfect,
             
             
               0 otherwise
             
                                                                       it is good enough to say that the latter are a practical way
                                                                       of approximating what the crowd believes despite individual
     1 (1 + exp(2b(1 − x)))−1            exp(bx)
                                =    exp(bx)+exp(by)
                                                     if x = 2 − y.     differences.
                                                                   2672

                                                                      coffee                                        commute
 mean posterior Q_{ijk} / average slider rating
                                                  0.15               ● ●
                                                                         ●                     0.12         ●
                                                                                                            ●
                                                                                                              ● ●
                                                                                                                                                                                                                       coffee                                                                                 commute
                                                                   ● ● ●                                            ●
                                                  0.10                                                  ●
                                                                   ●     ● ●
                                                                           ● ●                 0.08   ● ●
                                                                                                                        ● ●
                                                                                                                        ● ● ●                                                                                        ●                                                                         ●
                                                                 ●                                                          ● ● ● ●                                                                                ● ● ● ● ●
                                                                                                                                                                                                                   ●                                                                         ● ● ●
                                                  0.05                       ● ●
                                                                               ● ● ●           0.04                           ● ● ● ●                                              0.10
                                                         ● ● ● ●                 ● ● ●
                                                                                                      ●                               ●
                                                                                                                                    ● ● ●
                                                                                                                                        ●
                                                                                                                                                                                                                           ●                                       0.10                  ●
                                                                                                                                                                                                                                                                                                              ●
                                                                                                                                                                                                               ●                         ●
                                                                                                                                                                                                                                         ●                                                                         ●
                                                                                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                             ● ●                                 ●                                             ●
                                                                       joke                                             laptop                                                     0.05          ●                                                                 0.05                                                            ● ● ●
                                                                                                                                                                                           ● ● ●                                                      ●
                                                                                                                                                                                                                                                          ●                                                                                      ● ●
                                                  0.12                                                                                                                                                                                                                                                                                               ●
                                                                                                        ●
                                                  0.09                       ● ●
                                                                                 ● ●
                                                                                     ●
                                                                                                0.2     ● ●                                                                                                                joke                                                                                   laptop
                                                                                                          ● ●
                                                                 ●   ● ● ●               ● ●
                                                                                           ●
                                                                                                      ●     ●
                                                  0.06       ● ● ● ●
                                                             ● ●   ●
                                                                     ●
                                                                                         ●      0.1   ●       ●                                                                    0.10                                                                            0.20                  ●
                                                                                                                                                                                                                                                                                         ●
                                                                                                              ● ●                                                                                                                  ● ● ●
                                                                                                                                                                                                                                       ●                                                     ●
                                                                                                                                                                                                                                                                                             ●
                                                  0.03   ●
                                                         ●
                                                                                                                  ●
                                                                                                                  ● ●
                                                                                                                    ● ●
                                                                                                                      ● ● ● ● ● ● ●
                                                                                                                                                                                   0.08                    ●
                                                                                                                                                                                                                                 ●       ●
                                                                                                                                                                                                                                                      ● ●          0.15          ●
                                                                                                                                                                                                                                                                                 ●                ●
                                                                                                                                                                                                         ●
                                                                                                0.0                                                                                0.06            ● ●
                                                                                                                                                                                                       ●                                                           0.10                                   ●
                                                                                                                                                                                                                                                                                                          ●
                                                                                                                                                         slider rating
                                                                                                                                                                                               ● ●                                                                                                            ●
                                                                     marbles                                            movies                                                     0.04    ●
                                                                                                                                                                                                                                                                   0.05                                            ● ●
                                                                                                                                                                                                                                                                                                                       ● ● ● ● ●
                                                  0.25                                     ●
                                                                                               0.20                                                                                0.02                                                                            0.00                                                          ● ●
                                                  0.20                                     ●                            ●
                                                                                                                        ● ●                                                                                            marbles                                                                                    movies
                                                  0.15                                         0.15                   ●   ●
                                                                                                                            ●
                                                                                                                    ●       ●
                                                                                               0.10                 ●
                                                                                                                                 ●                                                 0.25                                                                   ●
                                                                                                                                                                                                                                                          ●
                                                  0.10     ●   ● ● ●               ●
                                                                                                                                 ●
                                                                                                                                     ●                                             0.20                                                                            0.15                                            ●
                                                                                                                                                                                                                                                                                                                       ●
                                                                                                                                                                                                                                                                                                                               ●
                                                  0.05   ● ● ● ● ● ● ● ● ● ● ● ● ● ●           0.05           ●                           ●
                                                                                                                                          ● ● ●                                                                                                                                                               ●                    ●
                                                         ●                                              ● ● ●
                                                                                                      ● ●
                                                                                                      ●     ● ●                                                                    0.15                                                                            0.10                                                                 ●
                                                                                               0.00
                                                                        tv                                              watch                                                      0.10                              ●                                             0.05                                   ●                                 ●
                                                                                                                                                                                                                                                                                                                                                 ● ●
                                                                                                                                                                                                               ●
                                                                                                                                                                                   0.05    ● ● ● ● ● ● ● ● ● ● ● ● ●                                                             ● ● ●
                                                                                                                                                                                                                                                                                       ●                                                             ●
                                                               ●
                                                                                                                                                                                                                                                                   0.00
                                                  0.12       ●
                                                             ●
                                                               ● ●
                                                                 ● ●                           0.10   ● ●
                                                                                                          ●
                                                                                                          ● ●
                                                                                                            ● ●
                                                                                                              ● ●
                                                                                                                ● ●                                                                                                         tv                                                                                     watch
                                                           ●                                          ●
                                                                     ●                                            ●                                                                0.15                                                                        0.125
                                                  0.08   ●
                                                         ●             ●
                                                                       ●
                                                                                                                          ●
                                                                                                                          ● ●                                                                        ●                                                                               ●
                                                                         ●
                                                                         ● ● ●                 0.05                         ● ● ●                                                                  ● ● ●                                                       0.100               ● ● ●
                                                  0.04                     ● ●
                                                                                   ● ● ●                                        ● ●
                                                                                                                                  ● ● ●
                                                                                                                                      ● ●                                          0.10        ●                   ●                                                             ●
                                                                                                                                                                                                                                                                                 ●       ● ●
                                                                                                                                                                                                                                                                                                                   ●
                                                                                     ●   ●
                                                                                         ●                                                                                                 ●                            ●
                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                               0.075                                                   ●
                                                                4       8         12                         4            8          12                                            0.05                                          ●
                                                                                                                                                                                                                                     ● ●                       0.050                                                           ● ●
                                                                                                                                                                                                                                                                                                                                   ● ●
                                                                                                                                                                                                                                             ● ● ●                                                                                     ● ● ●
                                                                                               bin                                                                                                                                                 ●           0.025
                                                                                                                                                                                                       4                    8                12                                                   4                    8                    12
Figure 3: Means of posteriors over Q j in black with gray area                                                                                                                                                                                                     bin
indicating 95% HDIs. Red: mean slider ratings.                                                                                                                                                                                  (a) Binned histogram task.
                                                                             Model criticism                                                                                                                           coffee                                                                                 commute
                                                                                                                                                                                                                                     ●
Inferences based on the model are only as reliable as the                                                                                                                          7.5                                                                              6                        ●
                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                   5.0                                 ●                                            4                             ●
model itself is plausible. Model criticism is therefore im-                                                                                                                        2.5                             ●
                                                                                                                                                                                                                   ●
                                                                                                                                                                                                                       ●
                                                                                                                                                                                                                            ● ●
                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                         ● ● ●
                                                                                                                                                                                                                                                                    2          ●
                                                                                                                                                                                                                                                                                             ●        ● ●
                                                                                                                                                                                                                                                                                                      ● ●
                                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                                                  ● ● ●   ●
                                                                                                                                                                                                  ●                           ●                                              ●                                        ● ● ●
portant. Fig. 4 shows posterior predictive checks at the                                                                                                                                  ● ● ●
                                                                                                                                                                                          ● ● ● ●                                              ●
                                                                                                                                                                                                                                               ● ●                                                                          ●
                                                                                                                                                                                                                                                                                                                            ● ●
                                                                                                                                                                                                                                                                                                                              ● ●
                                                                                                                                                                                                                                                                                                                                ● ●
                                                                                                                                                                                   0.0          ●                           ●            ● ●     ●                  0        ● ●                                        ●         ●
                                                                                                                                                                                                                        joke                                                                                      laptop
population-aggregate level for all of our three task types. For                                                                                                                     5                                                        ●                 10.0
                                                                                                                                                                                    4                                                                           7.5                  ●
the binned histogram task, posterior predictions are spot-on.                                                                                                                       3                         ●
                                                                                                                                                                                                              ● ●
                                                                                                                                                                                                                  ● ●
                                                                                                                                                                                                                                                                5.0
                                                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                                                             ●
                                                                                                                                                                                    2                     ● ●
                                                                                                                                                                                                            ●     ● ● ●
For the give-a-number task, some of the data is surprising de-                                                                                                                                          ●
                                                                                                                                                         frequency
                                                                                                                                                                                    1       ● ● ● ● ● ● ● ●           ●                                         2.5          ●
                                                                                                                                                                                                                                                                             ●                    ●
                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                                      ● ● ●
                                                                                                                                                                                          ●
                                                                                                                                                                                    0     ● ● ● ●   ● ●                                                         0.0                                     ● ● ●
                                                                                                                                                                                                                                                                                                            ● ● ● ● ● ● ● ●
spite the model being trained on this very data. This could                                                                                                                                                        marbles                                                                                        movies
                                                                                                                                                                                                                                                                    8
have various reasons: (i) the give-a-number data does not
                                                                                                                                                                                                                                                          ●                                                            ●
                                                                                                                                                                                   15                                                                               6
                                                                                                                                                                                                                                                          ●                                                            ●
have a huge influence on the posterior likelihood, (ii) num-                                                                                                                       10
                                                                                                                                                                                    5
                                                                                                                                                                                                                                                                    4
                                                                                                                                                                                                                                                                    2                                         ●
                                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                                                  ●        ●
                                                                                                                                                                                                                                                                                                                           ●
                                                                                                                                                                                                                                                                                                                                   ●
                                                                                                                                                                                                                                                                                                                                   ●
ber choices may be influenced by saliency and/or roundness
                                                                                                                                                                                                                                                                                                                                       ● ●
                                                                                                                                                                                          ● ●
                                                                                                                                                                                            ● ●
                                                                                                                                                                                              ● ●
                                                                                                                                                                                                ● ● ● ●
                                                                                                                                                                                                  ● ●   ● ●
                                                                                                                                                                                                      ● ●   ● ● ●
                                                                                                                                                                                                          ● ●       ●
                                                                                                                                                                                                                  ● ●
                                                                                                                                                                                                                ● ●                                                                  ●
                                                                                                                                                                                                                                                                                   ● ●                                                   ● ● ● ●
                                                                                                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                    0                                                                               0        ● ● ● ●                                                       ● ●
of numbers after all (and thus, not accurately reflect the true                                                                                                                                                             tv
                                                                                                                                                                                                                                                                    6                        ●
                                                                                                                                                                                                                                                                                                                  watch
                                                                                                                                                                                    6                  ●
beliefs Q j ). Finally, there is one condition in the paired com-                                                                                                                   4                  ●               ●                                            4
                                                                                                                                                                                                                                                                                     ● ● ● ●
                                                                                                                                                                                                           ●
parison task that the model definitely got wrong. This is the
                                                                                                                                                                                              ●            ●                                                                 ●             ●
                                                                                                                                                                                    2     ● ● ●                    ●
                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                         ●                                          2                    ●   ● ●
                                                                                                                                                                                                                                                                                                   ●
                                                                                                                                                                                          ●                        ●   ● ● ● ●                                               ●                   ●
                                                                                                                                                                                                                                                                                                 ● ● ● ●
                                                                                                                                                                                                                                                                                                       ● ● ● ● ●
                                                                                                                                                                                    0       ●                          ●   ● ● ●
                                                                                                                                                                                                                               ● ●
                                                                                                                                                                                                                                 ● ●
                                                                                                                                                                                                                                   ● ●
                                                                                                                                                                                                                                     ●                              0                        ● ●     ●   ● ● ● ●
choice of what is more likely: that one or that none of 14 mar-                                                                                                                                        4                    8                12                                                   4                    8                    12
bles thrown into a pool would sink. The model predicts that                                                                                                                                                                                                     bin
almost everybody should answer that it is more likely that one
                                                                                                                                                                                                                                 (b) Give-a-number task.
marble sank. But that is not what we observe. It may be that
participants revise beliefs about “normality” of the marbles,                                                                                                                                      coffee                                commute                                         joke                                          laptop
while holding on to an assumption that all marbles behave in                                                                                                                       1.00            ●                                                                             ●
                                                                                                                                                                                           ●       ●                                 ●
                                                                                                                                                                                                                                     ●                                   ●       ●
                                                                                                                                                                                                                                                                                             ●                             ●
                                                                                                                                                                                           ●                                                                             ●                   ●
                                                                                                                                                                                   0.75                                                                                                                                    ●
                                                                                                                                                         choice prop. higher bin
the same way (Degen et al., 2015).                                                                                                                                                 0.50
                                                                                                                                                                                                           ●
                                                                                                                                                                                                           ●
                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                             ●
    Posterior predictive checks indicate that the trained model                                                                                                                    0.25                            ●
                                                                                                                                                                                                                                                                                                      ●
                                                                                                                                                                                                                                                                                                              ●
                                                                                                                                                                                                                                                                                                              ●
                                                                                                                                                                                                                                                                                                                                   ●
captures patterns of answers at the aggregate population level
                                                                                                                                                                                                                            ●
                                                                                                                                                                                                                            ●                     ●       ●    ●
                                                                                                                                                                                                                                                               ●                                                                            ●    ●   ●
                                                                                                                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                  ●                                                                                         ●    ●
                                                                                                                                                                                   0.00                                                                   ●                                                                        ●
well. To have a more fine-grained measure of model fit, we                                                                                                                         1.00
                                                                                                                                                                                                   marbles
                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                             movies
                                                                                                                                                                                                                                             ●
                                                                                                                                                                                                                                                                         ●
                                                                                                                                                                                                                                                                                             tv                                        watch
                                                                                                                                                                                                                                     ●       ●
also looked at posterior predictive p-values (Gelman, Car-                                                                                                                                 ●       ●       ●
                                                                                                                                                                                                           ●       ●
                                                                                                                                                                                                                   ●        ●                                            ●                                                 ●
                                                                                                                                                                                                                            ●                                                                                              ●
                                                                                                                                                                                   0.75
lin, Stern, & Rubin, 2014) at the level of participants and                                                                                                                        0.50    ●
                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                 ●
                                                                                                                                                                                                                                                                                 ●
                                                                                                                                                                                                                                                                                                                                   ●
items. We look at the binned histograms task, because this is
                                                                                                                                                                                                                                                                                                                                   ●
                                                                                                                                                                                   0.25                                                                        ●                                                                            ●
                                                                                                                                                                                                                                                          ●    ●                             ●
                                                                                                                                                                                                                                                                                             ●                ●                                  ●   ●
                                                                                                                                                                                                                                                                                                      ●
                                                                                                                                                                                                                                                                                                      ●       ●
our main focus here and population-level posterior predictive                                                                                                                      0.00
                                                                                                                                                                                          1& 2& 6& 11& 14& 1& 2& 6& 11& 14& 1& 2& 6& 11& 14& 1& 2& 6& 11& 14&
                                                                                                                                                                                            2 6 11 14 15 2 6 11 14 15 2 6 11 14 15 2 6 11 14 15
checks for BH revealed no systematic deviance. Fixing a par-
ticipant and an item, observations and replicates are probabil-                                                                                                                                                                                               condition
ity vectors of length 15. In a first analysis, we used the mean
                                                                                                                                                                                                                             (c) Paired comparison task.
of these probability vectors as a test statistic. The minimum
                                                                                                                                                     Figure 4: Posterior predictive checks for aggregate data. Red
posterior predictive p-value over all 20 (participants) times 8
                                                                                                                                                     lines give empirical observations. Black lines are means of
(items) cases was 0.13, suggesting that the means of observed
                                                                                                                                                     posterior predictive samples, gray areas are 95% HDIs.
si j are non-surprising to the trained model. In a second analy-
sis, we used entropy as a test statistic. Two cases gave poste-
                                                                                                                                                  2673

rior predictive p-values lower than 0.05. These were from the                                   References
two participants who gave a very extreme slider rating for the        Andersen, S., Fountain, J., Harrison, G. W., & Rutström, E. E.
“marbles” item, basically assigning all “mass” to the last bin.         (2014). Estimating subjective probabilities. Journal of Risk
What this suggests is that the model can cope reasonably well           and Uncertainty, 48, 207–229.
also with individual-level data, but, somewhat unsurprisingly,        Degen, J., Tessler, M. H., & Goodman, N. D. (2015). Wonky
has problems accounting for “extreme” choices, given that the           worlds: Listeners revise world knowledge when utterances
population-level hyper-prior on Pi j will lead to shrinkage.            are odd. In Proceedings of CogSci 37.
                                                                      Frank, M. C., & Goodman, N. D. (2012). Predicting prag-
                          Conclusion                                    matic reasoning in language games. Science, 336(6084),
The data and model presented here suggest that mean slider              998.
ratings are consistent with other measures of subjective be-          Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2014).
lief, namely from give-a-number and paired comparison                   Bayesian data analysis (3rd edition ed.). Boca Raton:
tasks. Future research should evaluate whether this holds for           Chapman and Hall.
other possible measures of subjective beliefs as well, such as        Gelman, A., & Rubin, D. B. (1992). Inference from itera-
iterated-learning or scoring-rule tasks.                                tive simulation using multiple sequences (with discussion).
   There are aspects of the data that the model does not cap-           Statistical Science, 7, 457–472.
ture well, but there are also natural explanations for these dis-     Griffiths, T. L., & Tenenbaum, J. B. (2006). Optimal predic-
crepancies. It therefore does not seem implausible that par-            tions in everyday cognition. Psychological Science, 17(9),
ticipants’ latent beliefs could have generated the data from all        767–773.
three task types roughly in the way assumed by the model’s            Kao, J. T., Bergen, L., & Goodman, N. D. (2014). Formaliz-
link functions, with each subjective belief being an expression         ing the pragmatics of metaphor understanding. In P. Bello,
of a population-level central tendency. If that is so, then mean        M. Guarini, M. McShane, & B. Scassellati (Eds.), Proceed-
slider ratings from the binned histogram task are a practical           ings of CogSci 36. Austin, TX: Cognitive Science Society.
and reliable approximation of what the crowd believes.                Kao, J. T., Wu, J. Y., Bergen, L., & Goodman, N. D.
   Future research should investigate whether and how our re-           (2014). Nonliteral understanding of number words. PNAS,
sults can be extended to other types of uncertain variables.            111(33), 12002–12007.
Here, guided by the needs of many previous Bayesian cog-              Lee, M. D., & Wagenmakers, E.-J. (2015). Bayesian Cog-
nitive models, we focused on uncertainty about unidimen-                nitive Modeling: A Practical Course. Cambridge, MA:
sional contiguous variables. It remains to be seen whether the          Cambridge University Press.
binned histogram task can be applied to higher-dimensional            Lewandowsky, S., Griffiths, T. L., & Kalish, M. L. (2009).
variables, like joint prior beliefs over, say, height and weight        The wisdom of individuals: Exploring people’s knowledge
of an individual or, more abstractly, different dimensions of           about everyday events using iterated learning. Cognitive
a multi-dimensional property like intelligence. Another chal-           Science, 33, 969–998.
lenge lies in devising means of eliciting prior expectations          Manski, C. F. (2004). Measuring expectations. Economet-
about properties that do not have clear and familiar measure            rica, 72(5), 1329–1376.
terms that can be used to label bins—again like intelligence.         Plummer, M. (2003). JAGS: A program for analysis of
   Finally, another aspect that our model has ignored so far            Bayesian graphical models using Gibbs sampling. In
are potential individual differences in the way subjective be-          K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of
liefs Pi j generate responses. It is not unlikely that there is         Distributed Statistical Computing 3.
individual variation in at least some link function parameters,       Savage, L. J. (1971). Elicitation of personal probabilities and
such as κ, which expresses end-point attraction or end-point            expectations. Journal of the American Statistical Associa-
aversion in the binned histograms task. A detailed investiga-           tion, 66(336), 783–801.
tion of such individual-level differences must be left to future      Schlag, K. H., Tremewan, J., & van der Weele, J. J. (online
work. Still, we believe that the model presented here is an im-         first). A penny for your thoughts: a survey of methods for
portant first step towards finding reliable and practical means         eliciting beliefs. Experimental Economics.
of measuring what the crowd believes.                                 Schöller, A., & Franke, M. (2015). Semantic values as la-
                                                                        tent parameters: Surprising few & many. In S. D’Antonio,
                     Acknowledgments
                                                                        M. Moroney, & C. R. Little (Eds.), Proceedings of SALT.
MF’s work was supported by the Institutional Strategy of the          Tauber, S., & Steyvers, M. (2013). Inferring subjective
University of Tübingen (DFG, ZUK 63). MF, FD, AS and                   prior knowledge: An integrative Bayesian approach. In
JD’s work was supported by the Priority Program XPrag.de                M. Knauff, M. Pauen, N. Sebanz, & I. Wachsmuth (Eds.),
(DFG Schwerpunktprogramm 1727). This work was further                   Proceedings of the CogSci 35 (pp. 3510–3515).
supported by ONR grant N00014-13-1-0788 and a James S.                Tessler, M. H. (2015). Understanding Belief bias by measur-
McDonnell Foundation Scholar Award to NDG and an SNF                    ing prior beliefs for a Bayesian model of syllogistic reason-
Early Postdoc.Mobility Award to JD. Thanks to three anony-              ing. In Proceedings of ESSLLI student session.
mous reviewers for helpful suggestions and criticism.
                                                                  2674

