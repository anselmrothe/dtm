                Choice adaptation to increasing and decreasing event probabilities
                                             Samuel Cheyette (sjcheyette@gmail.com)
                                  Dynamic Decision Making Laboratory, Carnegie Mellon University
                                                          Pittsburgh, PA. 15213
                                 Emmanouil Konstantinidis (em.konstantinidis@gmail.com)
                                         School of Psychology, University of New South Wales
                                                      Sydney, NSW 2052, Australia
                                               Jason L. Harman (jharman@lsu.edu)
                          Department of Psychology, Louisiana State University, Baton Rouge, LA. 70803
                                                 Cleotilde Gonzalez (coty@cmu.edu)
                                  Dynamic Decision Making Laboratory, Carnegie Mellon University
                                                          Pittsburgh, PA. 15213
                              Abstract                                 to this date behavioral work on how humans behave under
                                                                       changing conditions and how we adapt to change is
   A constant element of our modern environment is change. In          relatively limited.
   decision-making research however, very little is known about           About a decade ago, research started to shift from the
   how people make choices in dynamic environments. We
   report the results of an experiment where participants were
                                                                       overwhelmingly popular study of one-shot decisions to the
   asked to choose between two options: a dynamic and risky            study of repeated and consequential choice. In repeated
   option that resulted in either a high or a low outcome, and a       choice conditions, early decisions produce payoffs and
   stationary and safe option that resulted in a medium outcome.       information that may influence future choices. This is one of
   The probability of the high outcome in the risky option             the reasons that researchers have focused on experience and
   decreased or increased linearly over the course of the task         cognitive processes such as learning, memory, and
   while the probability of the medium outcome stayed the same         recognition as key psychological processes of dynamic
   throughout. We find that adaptation to change is related to the
   direction of that change, and that the way people adapt to          decision-making (Gonzalez, Lerch, & Lebiere, 2003).
   changing probabilities relates to their willingness to explore         The study of decisions from experience has expanded
   available options. A cognitive model based on Instance-Based        considerably in the past years, perhaps due to the
   Learning Theory reproduces the behavioral patterns.                 development of simple experimental paradigms (e.g.,
   Keywords: Change; Dynamic Decisions; Adaptation;                    “clicking paradigms”) which have been used to study choice
   Instance-Based Learning Theory; Decisions from Experience           in its most essential form: in binary conditions (Baron &
                                                                       Erev, 2003; Hertwig et al., 2004). These paradigms involve
                          Introduction                                 the selection between two options, in the absence of
More than ever before the world around us seems to be                  descriptions of possible outcomes and probabilities. For
changing rapidly. Technology has contributed to increasing             example, in a repeated consequential choice paradigm
availability of information and connectedness that                     (Baron & Erev, 2003), participants select between two
contribute to a sense of rapid change. We make decisions in            buttons a fixed number of times (e.g., 100 times). After each
constantly changing situations and our ability to detect and           selection, an outcome is displayed (i.e., feedback). This
adapt to those changes may determine the success of our                outcome is the realization of a probability distribution
choices. For example, a broker in the stock market must be             assigned to the button selected, which is unknown to
sensitive to the changes in the interest rates in an attempt to        participants. This paradigm is illustrated in Figure 1.
maximize the long-term investments gains. In the context of               Using this experimental paradigm, researchers have
reinforcement learning and restless bandit tasks, researchers          investigated a number of issues relevant to how humans
have investigated change in similar settings, such as                  adapt to change and make choices in dynamic settings. For
adaptation and detection of change, and exploration-                   example, Rakow and Miler (2009) investigated repeated
exploitation tradeoffs in dynamic environments (e.g.,                  binary choice in which the associated probabilities of the
Gureckis & Love, 2009). Yet, relatively little is known                outcomes could change over the sequence of trials.
about how humans detect change when the change occurs                  Specifically, the probability of one option would gradually
gradually, and particularly when making decisions from                 change over a set of trials. The information given to
experience while aiming at maximizing long-term gains.                 participants was manipulated by providing the outcomes
   Dynamic decision theory was first introduced by Ward                associated with each option or seeing a summary of the
Edwards (1962) who argued for the study of dynamic                     outcomes of previous trials. They observed a rapid
situations in which decision makers confront a sequence of             adaptation (quick identification of the best option) when the
decisions, and in which the environment changes while a                probability changed, but a slow adaptation when only the
decision maker is evaluating possible courses of action. Yet,          outcome changed. The historic feedback helped but only in
                                                                   614

early choices and not in later choices. Additionally, over all        paradigm in conditions of gradual positive and negative
of their experiments, Rakow and Miler found some                      change. Third, we analyze exploratory behavior to evaluate
evidence that people react more quickly to negative changes           how individuals explore the environment in order to detect
than to positive changes. Their studies concluded with the            gradual change. Fourth, we demonstrate the effects of
importance of the adaptive nature of human memory and                 human memory in these changing situations with an
speculated how forgetting and recency of information can              Instance-Based Learning model (Gonzalez et al., 2003),
play an important role in adaptation.                                 which relies on the ACT-R architecture’s memory decay
  Lejarraga, Dutt, and Gonzalez (2012) used Rakow and                 function (Anderson & Lebiere, 1998).
Miler’s (2009) data to demonstrate how an Instance-Based                 In addition to exploring gradual and continual change, the
Learning (IBL) cognitive model (Gonzalez et al., 2003)                paradigm we implement involves high reward outcomes that
could account for that data. They compared the predictions            change from very rare to near certain; analogous to a
from the IBL model to observed human choices suggesting               foraging animal in a changing environment once rich in
that adaptation occurs through the reliance on recent                 resources that gradually deplete or vice versa (Mehlhorn et
outcomes.        More recently, Lejarraga, Lejarraga, and             al., 2015). This design not only extends the results of
Gonzalez (2014) investigated whether groups make better               Rakow and Miler (2009) to gradual and continual change
choices than individuals in dynamic tasks using similar               but presents a test of boundary conditions in which
problems with changing probabilities over time. They found            exploration between options could be abandoned before
that decisions made in groups were better than individual             change is detected due to very rare or very frequent early
decisions in stable conditions, but groups were not superior          experiences. Accordingly, we expected better adaptation to
to individuals after a sudden change had occurred in the              change when the high risky outcome changes from very
probabilities. That is, groups had more difficulty in                 frequent to very rare.
detecting and adapting to a sudden change compared to
individuals. They also used an IBL model and a Bayesian                                           Methods
updating model with “perfect memory” to explain why                   Participants
groups were slower at changing their policies compared to                Two-hundred and forty participants (88 Female, Mage
individuals.                                                          =31.32) were randomly assigned to one of three conditions:
                                                                      increasing dynamic condition (N=76), decreasing dynamic
                                                                      condition (N=83), and stationary condition (N=81).
                                                                      Participants were recruited from Amazon Mechanical Turk
                                                                      for a “choice” experiment. They were paid $0.50 for
                                                                      participating and an additional bonus payment based on the
                                                                      points they accumulated over the course of the 100 trials, at
                                                                      a rate of 1 cent per 1000 points. The average bonus payment
                                                                      gained for the duration of the experiment of about 10
                                                                      minutes was $0.26.
                                                                      Design
                                                                      The experiment asked participants to choose repeatedly
                                                                      between two options, with the goal of maximizing their
                                                                      long-term earnings that accumulate from each of the choices
                                                                      they make over 100 trials. The two options available in each
                                                                      choice include one risky option that could result in a high
Figure 1: Repeated choice, consequential paradigm. The example        outcome (500 points) with probability p or a low outcome (0
shows that selecting the right button may result in an outcome of     points) with probability 1–p, and a safe option that could
1,000 with probability p=.2, 0 with p=.6 and 5,000 with p=.2,         result in a medium outcome (250 points) all the time. The
while the left button results in 1,000 with certainty (p=1). The      presentation of the safe and risky options (left/right) was
probabilities are unknown to the participants.                        counter-balanced.
                                                                         The main treatment involved the function of p which
  We advance this line of research in four ways: First, we            linearly increased, linearly decreased, or stayed stable as a
investigate how individuals adapt to gradual and continual            function of time (choice trial number). In the increasing
change rather than to sudden changes. This is relevant to             condition the probability of obtaining 500 points began at
test the role of human memory in adjusting to gradual                 0.01 and increased by 0.01 each trial, up to probability 1 at
changes by the slightly altering past experiences. Second,            trial 100. This condition represents an environment where
we are also interested in looking at the direction of change.         rewards change from extremely rare to certain as a function
In research related to control of dynamic systems,                    of time. In the decreasing condition the probability of
researchers have found that adapting to change and being              obtaining 500 points started at 1 and decreased by 0.01 each
able to control a dynamic system in the long term, depends            trial, ending at 0.01 at trial 100. This condition represents an
on whether the external environmental changes occur in a              environment where rewards change from certain to
positive (i.e., increasing amounts) or negative (i.e.,                extremely rare as a function of time. In the stationary
decreasing amounts) way (Gonzalez & Dutt, 2011). We
present results from an experiment in a repeated choice
                                                                  615

condition, the probability of obtaining 500 points stayed               increased probability in the non-stationary option. However,
stable at 0.5 throughout.                                               this adaptation seems to be slow. Initially, participants
   Importantly, the cumulative expected value (EV) for all              quickly favored the safe option as we observe from the
the options in all the conditions remains equal to 25,000               immediate drop of the P-Risky in the first 10 trials, but they
points over the course of the experiment. Thus, effectively             moved slowly towards preferring the risky option as per the
selecting the risky option consistently over the course of              increase in the probability of the high outcome.
100 trials would result in approximately 25,000                            Third, the P-risky in the decreasing condition reduced
accumulated points, the same overall accumulated outcome                rapidly over the course of 100 trials. Initially, choices
from selecting the safe option consistently over the course             quickly favored the risky option but they started to favor the
of 100 trials. However, the relative value of the two options           safe option more quickly as the probability of the high
changes over time. In the decreasing condition, the risky               option decreases, suggesting probability matching behavior
option is better than the safe option in the first 50 trials (i.e.,     (Erev & Barron, 2005). We observe that people were faster
it results in 500 points more often than 0 points) and then it          to cross the P-Risky = 0.50 threshold in the decreasing
becomes worse than the safe option in the last 50 trials. In            condition compared to the increasing condition. In the
the increasing condition, the risky option is worse than the            increasing condition, P-Risky did not reach 0.50 until the
safe option in the first 50 trials and it becomes better than           98th trial, whereas in the decreasing condition, P-Risky
the safe option in the last 50 trials. In the stationary                reached the 0.50 mark on the 50th trial, essentially tracking
condition the probability of getting 500 or 0 points in the             the probability function throughout (i.e., a demonstration of
risky option is always the same (0.5), so effectively the               probability matching behavior; see also Rakow & Miller,
risky option is relatively as valuable as the safe option over          2009).
the 100 trials.                                                            Participants seem to select the risky option that matches
Procedure                                                               the probability of the high outcome. That is, participants
After providing consent and answering demographic                       seem to select the maximizing option more accurately in the
questions, participants were given instructions for the game,           decreasing rather than the increasing condition. To test this,
and then they performed the choice task for 100 trials. Upon            we calculated the proportion of maximization choices (P-
completion of the task, participants were given a final                 Max) before and after the objective change of the relative
debriefing to determine whether they were aware of the                  goodness of the options (e.g. trial 50; see Figure 3, left
changing probabilities and the direction of change.                     panel). We found a significant difference in the P-Max
   Participants were given their total number of points                 across increasing and decreasing conditions, χ2(1) = 15.81, p
accumulated, translated into a monetary bonus they earned,              < .001. The P-Max was higher in the decreasing condition
and then thanked for their participation.                               (M = 0.66) than the increasing condition (M = 0.57). In
                                                                        addition, participants maximized more in the first period of
                           Results                                      the task, χ2(1) = 537.50, p < .001, and the interaction was
As a first step, we compared the proportion of risky choices            also significant, χ2(1) = 1,916.19, p < .001. The P-Max for
(P-Risky) (see Figure 2, left panel). We analyzed the data              the increasing condition was significantly higher in the first
using a generalized logit mixed-effects model with                      half (M = 0.83) than the second half (M = 0.33; χ2(1) =
condition and block (blocks of 20 trials) as fixed effects,             1,717.80, p < .001), whereas the order is reversed in the
and subject-specific random intercepts. We found a                      decreasing condition but to a lesser degree (Mfirst half = 0.61,
significant difference in the proportion of risky choices               Msecond half = 0.64; χ2(1) = 12.34, p < .001). The contrast is
participants made across conditions, χ2(2) = 33.11, p < .001.           quite stark: the maximizing rate never drops below 0.50 in
The P-Risky was higher in the decreasing condition (M =                 the decreasing condition, but it is on average 0.30 in the
0.48), followed by the stationary condition (M = 0.36), and             second half in the increasing condition. This is consistent
the increasing condition (M = 0.25). There was also a                   with the observation that people are adapting significantly
significant effect of block, χ2(4) = 229.09, p < .001, and a            more rapidly in the decreasing condition than in the
significant interaction between condition and block, χ2(8) =            increasing condition.
1,289.77, p < .001.                                                        A possible explanation for the different degrees of
   Looking at Figure 2 (left panel), the trends over time               adaptation between the increasing and decreasing conditions
reveal a decrease in the P-Risky for the stationary condition,          is the lack of exploration of the options. As we observe in
suggesting a general tendency to gradually select the safe              the stationary condition, participants’ choices drift towards
option over time, even when the options were objectively                the safe option over time, even when there is no change in
equal. This is explained by risk aversion (Kahneman &                   probabilities and values. In the increasing condition, people
Tversky, 1979), which has been investigated in decisions                might also have this tendency given that the safe option
from experience paradigms through IBL models (Lebiere,                  appears to provide higher payoffs more often than the risky
Gonzalez, & Martin, 2007). The frequency and recency of                 option in the first few trials. This might prevent participants
occurrence of the low outcome in the risky option creates an            form exploring the risky option in later trials. In contrast, in
imbalance of preference towards the safe option (Lebiere et             the decreasing condition, since the risky option provides
al., 2007).                                                             higher payoffs than the safe option in early trials, it is
   Second, the patterns suggest that although the P-Risky in            possible that people are more aware of the changes in the
the increasing condition was the lowest, the overall                    probability given that they are already selecting the risky
proportion of risky choices moved in the direction of the               option more often.
                                                                    616

Figure 2: The left panel shows human responses and the right panel shows model predictions for each of the three conditions, marked in
different colors, where the measure is the proportion of choosing the risky option across trials.
   To test for exploration, we used a measure proposed in                   completeness we reproduce it here. A choice between the
past research: the alternation rate (A-rate; Gonzalez &                     two options is made by using the blended value V which
Dutt, 2011; 2012). This is the proportion of switches from                  represents the value of option j in a particular trial t:
one option to another in consecutive trials. We performed
a similar analysis (mixed-effects logit model) and we
found a significant effect of condition, χ2(1) = 16.79, p
<.001, as participants switched more between options in
the decreasing (M = 0.30) than the increasing condition                     where xi refers to the payoff obtained in each option
(M = 0.21). The effect of period (before or after trial 50)                 stored in memory as instance i for the option j, and pi is
was not significant, χ2(1) = 0.43, p = .51, but the                         the probability of retrieving that instance from memory,
interaction between condition and period was significant                    which is relative to the activations of other instances in
(χ2(1) = 10.47, p = .001): while there was a difference in                  option j:
A-rate between periods in the increasing condition (p =
.003), this was not the case in the decreasing condition (p
= .12; Figure 4, left panel).
           Instance Based Learning Model                                    where τ is random noise defined as τ = σ2, and σ is a free
An IBL model designed to account for over-time effects                      noise parameter. The activation of instance i represents
of binary choice (Gonzalez & Dutt, 2011) is a generalist                    how readily available the information is in memory:
(it applies to a wide variety of tasks) instead of a
specialist (a model that is made for one particular task;
Lejarraga, et al., 2012) and it builds on the ACT–R
cognitive architecture (Anderson & Lebiere, 1998). It
proposes that a choice is a function of the accumulated
value (blended value) for each of the two options, through                  The activation is higher when instances are observed
experience. This value is a function of the outcomes                        frequently and more recently. When an instance is not
observed and the associated probability of retrieving the                   observed often, the memory will decay with the passage
corresponding instances from memory. Memory retrieval                       of time (the parameter d, the decay, is a non-negative free
depends on the activation of a value that reflects how                      parameter that defines the rate of forgetting). The noise
readily available this information is in memory. In this                    component σ is a free parameter that reflects noisy
IBL model, activation reflects the frequency (how many                      memory retrieval, γ is a random sample from a uniform
times an outcome has been observed in the past), recency,                   distribution (between 0 and 1), and tp denotes all the
and noise of the experience. The formulation of this                        previous trials that outcome i was observed.
model appears in multiple past publications (e.g.,
Gonzalez & Dutt, 2011; Lejarraga, et al., 2012), but for
                                                                     617

Figure 3: The left panel shows human data and the right panel shows model predictions of average maximization rates (P-Max) in the
changing probability conditions (increasing and decreasing) before and after the halfway point (50th trial).
   We produced predictions via simulations using this IBL
model with parameters from past research (d = 5 and σ =
1.5; see Lejarraga, et al., 2012). We simulated the choices
over time of 500 participants in each of the experimental
conditions. The right panels in Figures 2, 3, and 4, show the
model predictions that correspond to each of the results
observed from the human data.
   The model made predictions of choice behavior across
time that reflected similar trends in human data (right panel,
Figure 2). The model differed in how often it chose the risky
option on average across the three conditions. In the
decreasing condition, the mean P-Risky over the 100 trials
was 0.40; in the increasing condition the mean P-Risky was
0.32; in the stationary condition it was 0.33. This was                 Figure 4: Average observed (Data) and predicted (Model)
largely due to worse adaptation in the increasing condition,            alternation rates (A-rate) in the changing probability conditions
in which P-Risky does not reach 0.50 until the 77th trial (so           (increasing and decreasing).
27 trials after it would have been beneficial to do so). On
the other hand, in the decreasing condition, the model                     In contrast to human participants, the predictions of the
begins choosing the safer alternative in advance and P-                 model are more extreme: adapting better in the decreasing
Risky crosses the 0.50 mark on the 34th trial. In the                   than in the increasing condition and doing better in terms of
stationary condition, P-Risky drops to around 0.30 and                  maximizing choices in the second half than in the first.
remains around that level. In agreement with the                        However, these are good predictions given that this is an
observation in human participants, although the two options             “out of the box” model prediction, where the simulated data
have the same EV, the model chooses the safe option about               were produced in the complete ignorance of human data. In
two times more on average than the risky option.                        fact, when we calculated the mean squared difference
   The P-Max between conditions in the first and second                 (MSD) for each condition, we found that the predictions in
half of the experiment is shown in Figure 3 (right panel).              the stationary condition were the closest to observed data,
The average P-max in the first half (M = 0.83) is higher than           with an MSD of 0.006; the decreasing condition was the
in the second half (M = 0.48). However, in the decreasing               next closest with an MSD of 0.018, and the increasing
condition we observed a trend in the opposite direction. In             condition was the next one with an MSD of 0.020.
the decreasing condition we find that the average P-Max in
the first half (M = 0.60) is lower than the second half (M =                                       Discussion
0.81). Regarding A-rate (Figure 4), the model accurately                The main purpose of the current investigation was to
predicts more switching in the decreasing condition (M =                examine how people adapt their choices to gradual and
0.28) compared to the increasing condition (M = 0.23).                  continual change of event probabilities. Specifically, we
                                                                        were interested in whether the direction of change
                                                                   618

(increasing or decreasing probabilities of maximum                  fast at switching to a safe option in the decreasing condition.
outcomes) would have an effect on people’s choice                   Differences in exploration of the available options, joined
behavior. According to economic theory one should expect            with the dynamics of experience and the cognitive effects
no difference in choice across conditions, since the                involved (frequency and recency of experiences) provide an
cumulative EV of all options was the same in all                    explanation of this behavior.
experimental conditions. In contrast, as expected by                                   Acknowledgements
cognitive theories, results show that people are sensitive to
                                                                      This work was supported by the National Science
the dynamics of experienced outcomes and to the direction
                                                                    Foundation Award Number: 1154012 to Cleotilde
of change of the associated probabilities to these outcomes.
                                                                    Gonzalez.
   Three main phenomena emerged from this investigation:
1) risk aversion in experience, 2) slow adaptation to                                        References
increasing probabilities, and 3) fast adaptation to decreasing      Anderson, J. R., & Lebiere, C. (1998). The atomic components
probabilities. These patterns of risky choice are reinforced          of thought. Mahwah, NJ: Lawrence Erlbaum Associates.
by two observed behaviors: the maximization and the                 Barron, G., & Erev, I. (2003). Small feedback-based decisions
alternation behavior. In the increasing condition, people             and their limited correspondence to description-based
chose the best option in the first half of their experience but       decisions. Journal of Behavioral Decision Making, 16, 215-
they fell far below the average optimal behavior in the               233.
second half; while in the decreasing condition participants         Edwards, W. (1962). Subjective probabilities inferred from
                                                                      decisions. Psychological Review, 69, 109-135.
stayed above average optimal behavior throughout. The
                                                                    Erev, I., & Barron, G. (2005). On adaptation, maximization,
results suggest that participants explore the two options
                                                                      and reinforcement learning among cognitive strategies.
more in the decreasing than the increasing condition.                 Psychological Review, 112, 912-931.
   We observe that the IBL model provides close predictions         Gonzalez, C., Lerch, J. F., & Lebiere, C. (2003). Instance-based
to the observed behavior. Even though the performed                   learning in dynamic decision making. Cognitive Science, 27,
simulations were not exhaustively in line with what was               591-635.
observed in the task, the model provided insightful                 Gonzalez, C., & Dutt, V. (2011). Instance-based learning:
observations into the mechanisms of adaptation to change.             Integrating sampling and repeated decisions from
Introspecting into the IBL model’s mechanisms we observe,             experience. Psychological Review, 118, 523-551.
and it is also discussed in more detail in Lebiere et al.           Gonzalez, C., & Dutt, V. (2012). Refuting data aggregation
(2007), that the model naturally develops a preference for            arguments and how the IBL model stands criticism: A reply
the safe option rather than the risky option. This is due to          to Hills and Hertwig (2012). Psychological Review, 119,
the experiences of extreme outcomes in the risky option and           893-898.
the blending choice mechanism of the model that “blends             Gureckis, T. M., & Love, B. C. (2009). Short-term gains, long-
together” these outcomes, giving rise to a slight preference          term pains: How cues about state aid learning in dynamic
for the safe option (i.e., the stationary option). These              environments. Cognition, 113, 293-313.
predictions emerge from the activation of instances that            Hertwig, R., Barron, G., Weber, E. U., & Erev, I. (2004).
reflects the frequency and recency of the occurrence of               Decisions from experience and the effect of rare events in
outcomes. The stationary outcome develops initially a                 risky choice. Psychological Science, 15, 534-539.
                                                                    Kahneman, D., & Tversky, A. (1979). Prospect theory: An
higher probability of retrieval and a slightly higher blended
                                                                      analysis of decision under risk. Econometrica, 47, 263-291.
value. In the increasing condition, this tendency prevents the
                                                                    Lebiere, C., Gonzalez, C., & Martin, M. (2007). Instance-based
model from exploring the risky option, resulting in “lack of          decision making model of repeated binary choice. Paper
awareness” of the change. In contrast, in the decreasing              presented at the 8th International Conference on Cognitive
condition, because the low outcome of the risky option has            Modeling, Oxford, UK.
an extreme low probability of occurrence early on, the              Lejarraga, T., Dutt, V., & Gonzalez, C. (2012). Instance-based
model develops a preference for the risky over the safe               learning: A general model of repeated binary choice. Journal
option. This results in “awareness” of the change in the              of Behavioral Decision Making, 25, 143-153.
probability which helps the model being more successful at          Lejarraga, T., Lejarraga, J., & Gonzalez, C. (2014). Decisions
adapting to the probability decrease.                                 from experience: How groups and individuals adapt to
   In conclusion, the area of dynamic experience-based                change. Memory & Cognition, 42, 1384-1397.
decision-making has remained largely unexplored and this            Mehlhorn, K., Newell, B. R., Todd, P. M., Lee, M. D., Morgan,
study attempted to provide a deeper understanding of the              K., Braithwaite, V. A., … Gonzalez, C. (2015). Unpacking
factors that are involved in the adaptation to continuous             the exploration-exploitation tradeoff: A synthesis of human
dynamic change. We found that people were slower at                   and animal literatures. Decision, 2, 191–215.
adapting to changes in the outcome probability when a high          Rakow, T., & Miler, K. (2009). Doomed to repeat the
outcome changes from rare to frequent compared to a high              successes of the past: History is best forgotten for repeated
outcome changing from frequent to rare. People are slow at            choices with nonstationary payoffs. Memory & Cognition,
switching to a risky choice in the increasing condition and           37, 985-1000.
                                                                619

