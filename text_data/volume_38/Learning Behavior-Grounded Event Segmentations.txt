                             Learning Behavior-Grounded Event Segmentations
                              Christian Gumbsch (christian.gumbsch@student.uni-tuebingen.de)
                                           Jan Kneissler (jan.kneissler@uni-tuebingen.de)
                                           Martin V. Butz (martin.butz@uni-tuebingen.de)
      Chair of Cognitive Modeling, Department of Computer Science and Department of Psychology, Faculty of Science,
                                        Eberhard Karls University of Tübingen, Tübingen, Germany
                                Abstract                                strongly non-linear changes in the unfolding events. While
   The event segmentation theory (EST) postulates that humans           some of these changes seem to be strongly related to move-
   systematically segment the continuous sensorimotor informa-          ment variables, movement variables alone could not account
   tion flow into events and event boundaries. The basis for the        for all the segmentations that humans indicated (Zacks, Ku-
   observed segmentation tendencies, however, remains largely
   unknown. We introduce a computational model that grounds             mar, Abrams, & Mehta, 2009). We propose that event seg-
   EST in the interaction abilities of a system. The model learns       mentations may be grounded in, and develop from, own sen-
   events and event boundaries based on actively gathered senso-        sorimotor experiences.
   rimotor signals. It segments the signals based on principles of
   probabilistic predictive coding and surprise. The implemented           To investigate this proposition, we introduce a computa-
   model essentially simulates, anticipates, and learns event pro-      tional cognitive model implementation, which is based on
   gressions and event transitions online while interacting with
   the environment by means of dynamic, predictive Bayesian             Zacks et al. (2007)’s schematic EST model. The implemented
   models. Besides the model’s event segmentation capabilities,         system learns how it is able to manipulate objects solely by
   we show that the learned encodings can be used for higher-           actively processing sensorimotor interactions. The system es-
   order planning. Moreover, the encodings systematically con-
   ceptualize environmental interactions and they help to identify      sentially develops a predictive world model, which segments
   the factors that are critical for ensuring interaction success.      the gathered sensorimotor experiences into events and event
   Keywords: event models; object interaction; predictive encod-        transitions from scratch. Events are sets of forward models
   ing; event segmentation; higher order planning; factorization;       that are active over an extended period of time while inter-
   conceptualization                                                    acting with the environment. Event boundaries mark the be-
                           Introduction                                 ginning and ending of particular events. As a result, the in-
                                                                        dividual events characterize particular object manipulations
The embodiment turn in cognitive science has emphasized the
                                                                        or simple hand movements, while event boundaries identify
importance of simulating relevant aspects of the outside envi-
                                                                        types of contact onset and offset events. We show that the
ronment by means of perceptual symbol systems (Barsalou,
                                                                        developing structures are highly suitable (i) to predict the fu-
1999). To enable motor-grounded simulations, the inclusion
                                                                        ture sensorimotor progression, including when the next event
of actions was emphasized (Engel, Maye, Kurthen, & König,
                                                                        boundary is probably reached and which event can be ex-
2013). Moreover, the importance of explicit forms of predic-
                                                                        pected next, and (ii) to execute higher-order, goal-directed
tions and anticipations has been emphasized, supporting both,
                                                                        planning. We particularly show that the developing hierarchi-
cognitive development (Barsalou, Breazeal, & Smith, 2007)
                                                                        cally organized, event-oriented, behaviorally-grounded struc-
and adaptive, goal-directed behavior (M. Botvinick & We-
                                                                        tures are highly suitable for executing factorized, hierarchical
instein, 2014; Butz, Sigaud, & Gérard, 2003; Sigaud, Butz,
                                                                        reinforcement learning (RL) according to the options frame-
Pezzulo, & Herbort, 2013). In fact, recent treatises suggest
                                                                        work (M. M. Botvinick, Niv, & Barto, 2009; Sigaud, Butz,
that predictive coding and anticipations may form the foun-
                                                                        Kozlova, & Meyer, 2009; Sutton, Precup, & Singh, 1999).
dations that bring about embodied cognition (Clark, 2013;
Friston, 2009; Hohwy, 2013). In this paper, we present an
                                                                                                Architecture
algorithm that models an anticipatory learning system, which
develops suitable compositional structures to interact with the         According to EST, the processing of sensory inputs is influ-
environment adaptively and goal-directedly.                             enced by a set of event models, which predict future sensory
   The event segmentation theory (EST) (Zacks & Tversky,                input. Information about errors in these predictions is used
2001; Zacks, Speer, Swallow, Braver, & Reynolds, 2007)                  to adapt and switch between the available event models. We
suggests that humans tend to structure the stream of sensory            implement this approach by using forward models as event
perceptions into events and event transitions. Events were              models to generate sensory predictions. Additionally, to form
characterized as “a segment of time at a given location that            representations of events as a set of forward models, our sys-
is conceived by an observer to have a beginning and an end”             tem builds representation of event boundaries, marking the
(Zacks & Tversky, 2001, p. 3). In various studies that fo-              transition from a forward model to another.
cused on event structure perception, it was shown that events              The system consists of four main components. It is
are characterizable as relatively uniformly unfolding interac-          schematically shown in Figure 1. The Predictive System
tions, whereas event boundaries are characterized by sudden,            consists of a set of currently active event models, which pre-
                                                                   1787

 dict the next sensory information ~st+1 based on the current                                                   ∗
                                                                                       Error Detection                     Event Models M
 sensory input ~st and the executed motor action ~xt . The ac-                                               surprise
 tive event models are updated while interacting with the en-                         0
                                                                                   ~s t+1          ~et+1                           Mn,i , Mn, j
 vironment using the error ~et+1 between predicted ~s t+1  0   and                                                Mn, j
 actually encountered next sensory perceptions ~st+1 . Error
                                                                                 Predictive System M(t)               Event Boundary Models
 Detection mechanisms are used to keep track of the accuracy                                                 ∆~st+1
 of the predictions. If a significant prediction error is detected,
 which may be related to notions of surprise, event transitions            ~st+1         ~st          ~xt
 might be detected, leading to a change in the set of active
 event models. The Event Models-component contains all                            Sensors         Motor
 currently active event models and determines which ones are
                                                                                 Agent in Environment
 currently applicable. Moreover, the component learns new
 event models when necessary. Finally, the Event Boundary
 Model-components contain models that characterize event                Figure 1: Illustration of the system. Solid arrows symbolize
 transitions dependent on the currently active event models,            the information flow during forward modeling. In this path-
 the sensory information, and the surprise signal.                      way active forward models predict the next sensory input, are
    These four components essentially constitute the learning           improved by learning and exchanged if necessary. Dashed ar-
 and control architecture. The architecture encodes events in           rows symbolize the information flow during planning. Here
 the form of sets of temporal forward models. Event bound-              the required sensory change to trigger a desired event is com-
 aries are characterized by event boundary models, which ad-            puted and the forward models are used inversely to generate
 ditionally predict the state of the environment at particular          a suitable motor command.
 event transitions. While interacting with the environment,
 the system internally simulates the interaction with the envi-
 ronment and verifies these simulations given sensory obser-            Error detection and switching event models
 vations. Moreover, the system can be used to actively infer            To this point our architecture uses a set of active forward
 actions given desired goal states. Due to the event-based ar-          models to predict the sensory changes during the course of
 chitecture, higher-level inference-based planning is possible.         one event. However, if the system is confronted with an event
                                                                        boundary, marking the end of the current event and the begin-
 Predictive system
                                                                        ning of a new one, it should autonomously decide to switch
 While simulating the current changes in the environment,               its set of forward models.
 the predictive system holds N forward models M(t) =                        According to EST an event boundary is accompanied by
 (M1,i1 (t), ..., MN,iN (t)) at a certain point in time t. Each         a rising error in prediction (Zacks et al., 2007). It has been
 forward model predicts sensory changes given motor com-                shown that computational models can use prediction errors
 mands, that is, Mn,i :~x → ∆s. At a certain point in time t, each      to segment a stream of video sequences into separate events
 active forward model Mn,in (t) receives the motor command              (Reynolds, Zacks, & Braver, 2007) or to autonomously iden-
~xt as an input and predicts the sensory consequences ∆s0n,t+1 .        tify useful subgoals for higher level motor planning (Butz,
 The predictions of all N active forward models form the pre-           Swarup, & Goldberg, 2004). Our architecture uses the error
 dicted sensory change vector ∆~s t+1   0 . The predicted sensory
                                                                        in prediction as a criterion to detect a possible event bound-
 input of the next time step is thus:                                   ary. The prediction error en,t for the sensory dimension n at
                             0              0                           time step t is considered ‘surprising’ (Butz et al., 2004) if
                          ~s t+1 ←~st + ∆~s t+1 .               (1)
                                                                                                  en,t > ēMn,i + 2σMn,i ,                     (2)
    After executing ~xt the real sensory input ~st+1 is used to
 update the active forward models to improve the respective             with Mn,i being the currently active forward model of dimen-
 model predictions. Additionally, each forward model Mn,i               sion n.
 stores the moving average (over the 100 last steps) of its pre-            If a significant error signal is detected the architecture en-
 diction error ēMn,i and the variance of that prediction error         ters a searching period, during which the next active event
 σ2Mn,i , estimating the current accuracy of the model predic-          models are determined. All existing forward models Mn of
 tions.                                                                 dimension n and one newly generated forward model are con-
    Choosing sufficiently small step sizes, the velocity kine-          sidered. For a fixed number of time steps (10 time steps in
 matics of any dynamic system can be approximated arbitrar-             our simulations) each model predicts the next sensory input,
 ily well by a linear model. In the general case, the current           is updated, and the prediction error is recorded. Afterwards,
 velocity kinematics depend on the system state. Seeing that            the mean prediction errors of all models during this searching
 in our simple test scenario this was not the case, though, we          period are compared and the model Mn, j with the smallest
 assumed non-changing, linear velocity kinematics, which we             mean error is chosen as the new forward model for dimen-
 learned by means of Recursive Least Squares.                           sion n in the predictive system. If the winning model Mn, j
                                                                    1788

already existed prior to searching, the newly generated model             a reachable intermediate transition Mn,i → Mn,k . Although
is discarded. If Mn, j is new, it is added to the set of possible         in our simulation one intermediate transition always suffices,
models Mn for dimension n. All forward model updates on                   the principle can generally be applied for generating larger
existing models during a searching period are discarded.                  sequences of transitions. The approach is also closely related
                                                                          to model-based, hierarchical RL, where extended actions are
Learning event boundary models                                            described as ‘options’ (Sutton et al., 1999; M. M. Botvinick
The introduced components form a mechanism to detect                      et al., 2009).
event boundaries, which can be characterized by an exchange               Deriving the motor commands Let us assume that the nth
of at least one of the active forward models in the predic-               coordinate prediction is based on model i and the transition
tive system. For our architecture to be able to act goal-                 Mn,i → Mn, j is currently desired. The system is supposed to
directedly, a representation is necessary that describes at               reach a place ~s 0n in sensor space that maximizes the condi-
which situation one event boundary occurs. Assuming that                  tional probability of the desired transition:
an event boundary can be characterized by particular con-
stellations of event-boundary-relevant sensory inputs, we ap-                           ~s 0n := arg max P(Mn,i → Mn, j |~s).                (3)
proximate an event boundary by the probability density of                                                   ~s
sensory constellations that are experienced when a transition             This can be reformulated and solved using the Bayes theorem,
occurred. In other words, we are modeling the conditional                 assuming that also the prior of ~sn is a Gaussian distribution
probability P(~s | Mn,i → Mn, j ), making the assumption that             P(~sn ) = G~µn,i ,Σn,i (~sn ):
this probability distribution can be reasonably well approxi-
mated by a multidimensional normalized Gaussian function                      ~s 0n = (Σn,i ~µn,i→ j − Σn,i→ j ~µn,i ) (Σn,i − Σn,i→ j )−1 . (4)
G~µn,i→ j ,Σn,i→ j (~st ). This is equivalent to requiring that event
boundaries occur close to specific points in sensory space.                  Under the assumption that the prior is approximately uni-
This assumption holds well in the simple scenario consid-                 form (compared to the transition distribution), Σn,i→ j  Σn,i
ered. In the general case, other densities may be used such               this corresponds to the maximum of P(~st | Mn,i → Mn, j ). We
as Gaussian mixture models.                                               thus are making small steps in sensory space following the
                                                                          gradient of the transition model:
Planning
To be able to trigger desired events, our system can be used in                         ∆~s t0 = η W ∇P(~st | Mn,i → Mn, j ).                (5)
a backwards fashion to plan goal-directed behavior to reach
specific event boundaries. To do so, we approximate active                If the matrix W is the identity matrix this performs an ex-
inference (Friston et al., 2013) by means of the developing               act gradient ascend with step width constant η. However, we
event and event boundary models. As a result, planning con-               found better performance when choosing W such that dimen-
sists of two inference stages. First, a target event boundary,            sions with large variance are effectively suppressed. The sup-
or a sequence of event boundaries, is chosen. Next, the nec-              pression essentially focuses system behavior on the behav-
essary motor commands are inferred to reach the next desired              iorally relevant input dimensions.
event boundary.                                                              Finally, the desired displacement ∆~s t0 in sensory space can
                                                                          be translated directly into a motor command using the inverse
Selection of a target event boundary We assume that                       of the prediction model:
some of the event boundaries are coupled with positive re-
                                                                                                               −1
ward. In our model, event boundaries are characterized                                               ~x t0 := Mn,i (∆~s t0 ),                (6)
by event transitions, such that a particular event transition
Mn,i → Mn, j is chosen as the goal transition. As a result,               effectively making the system move towards an area where a
the system strives to achieve this transition by attempting to            desired event boundary is believed to be situated.
maximize P(Mn,i → Mn, j ,~st ). Higher-level, inference-based
planning is used to determine a sequence of event boundaries,                                                Evaluation
which is expected to lead from the current event to the desired           Our system was tested in a scenario, where multiple events
event transition.                                                         occur and thus the acquisition of different forward models
   When Mn,i to Mn, j is the only desired transition and Mn,i             is necessary to predict the sensory changes. We have there-
is the currently active model, then the system strives to maxi-           fore chosen a scenario in which a simulated agent interacts
mize P(Mn,i → Mn, j ,~st ). When multiple event transitions are           with different objects in continuous space. Figure 2 shows
considered desirable, that is, when transitions from the cur-             the hidden, conceptual structure of the environment, which
rently active model Mn,i to a set J of potential target mod-              the model uncovers by the detailed principles.
els (Mn, j ) j∈J are rewarding, then the transition to the clos-             The agent consists of a hand, able to move freely through a
est mean ~µn,i→ j of the associated Gaussian is chosen. When              limited workspace, and a stationary mouth area. Three types
Mn,i is currently active, but only transitions Mn,k → Mn, j are           of differently colored objects (1 type of ‘foe’ and 2 types of
expected to be rewarding (with k 6= i), the system chooses                ‘food’) occur in the simulation. Foe objects have no friction
                                                                      1789

                                                             object consumed
                                                                                                                               101
                                                                                                      mean prediction error
                                                                   heavy
                                                                   object
 Hand                                       moves normally                   moves slowly
                                                                  attached
                                                                                                                              10−2
Object       moves freely                      stays still                      dragged
                                  pushed                          attached
            object out of reach            new object generated              object consumed                                  10−5
Figure 2: Illustration of the different events (boxes) and event                                                              10−8
                                                                                                                                     hand touches object       object is removed
boundaries (arrows), which the introduced system uncovers.
The system’s ‘hand’ is able to attach to objects or to push                                                                                                t
objects, dependent on the object type. A pushed object moves
                                                                                                  Figure 3: Mean prediction error of all active forward mod-
away from the hand until it is out of reach. An attached object
                                                                                                  els for one exemplary interaction with a food object. The x-
moves with the hand until it is consumed. Hand movements
                                                                                                  axis displays time with event boundaries highlighted. Dashed
are slower when a heavy object is attached.
                                                                                                  lines mark the beginning and end of a searching phase
and slide away without friction when pushed by the hand.
They vanish when the distance of the object to the center of                                      Results
the agent’s workspace exceeds a threshold. Food objects stick                                     In a first test we evaluated the improvement of the forward
to the hand upon contact and afterwards move along with it.                                       models over time by monitoring the prediction error in ten
They vanish when they are dragged into the mouth. We use                                          independent simulations. The motor command ~xt was deter-
two types of food objects: Light food does not alter the hand                                     mined by an informed, hard-coded algorithm, which made
movement when attached to it, whereas heavy food slows the                                        the system touch an object with the hand, pushing it away or
hand movement down by a factor of 12 . If an object vanishes,                                     subsequently dragging it into its ‘mouth’. The average pre-
a new one is immediately generated at a different position.                                       diction error of all active forward models for one exemplary
   In every simulation step t one elementary movement of the                                      object interaction is plotted in Figure 3. In this example, the
hand, described by ~xt , is performed and a sensory input ~st                                     hand first moves to the food. After contact, the food sticks
is received, which contains all information necessary to pre-                                     to the hand and is moved alongside the hand into the mouth,
dict event boundary occurrences. In particular, ~st consists of                                   which results in ‘food consumption’ and thus food removal.
the position of the hand (s1,t , s2,t ∈ [0, 100]), the position of                                After that, a new object is generated randomly. At the event
the object (s3,t , s4,t ∈ [0, 100]), the position of the object in                                boundaries (hand touches object, object is removed) the pre-
a hand-centered frame of reference (s5,t , s6,t ∈ [−100, 100]),                                   diction error drastically increases. This ascent is particularly
the distance of the object to the center of the workspace                                         big when the object is removed, since a lot of sensory infor-
(s7,t ∈ [0, 50]) and the object’s color (s8,t ∈ {0, 100, 200}). ~xt                               mation changes in this single time step. For the following ten
contains the motor command, which determines the change                                           time steps, the system searches for new forward models, such
in hand position (with ∆s1,t , ∆s2,t ∈ [−0.5, 0.5]). Since the                                    that the prediction error remains large. After that, the best
forward models of our architecture must be able to linearly                                       adapted set of forward models is active. The prediction error
compute the change in sensor information based on ~xt , the                                       for all forward models decreases over time. Figure 4 shows
vector additionally contains sensory information describing                                       the prediction error for some of the forward models over their
the velocity of the hand during the last object contact (to pre-                                  time of activation. While the prediction errors strongly fluctu-
dict the position of the foe after pushing it) and the velocity                                   ate, they all logarithmically converge to 0. All forward mod-
of the object in reference to the center of the workspace (to                                     els that correctly predict no change in sensory information
predict changes in the object’s distance to the workspace cen-                                    immediately reach a prediction error of 0 (not shown).
ter). A small amount of Gaussian distributed motor noise was                                         In a second test we evaluated the planning capabilities of
added (σ = 0.05), such that an elementary movement was not                                        our system to use its event and event boundary models to per-
completely deterministic.                                                                         form goal-directed behavior. The system’s goal was to trigger
   In our scenario the event boundaries leading to the disap-                                     events resulting in the removal of the currently present object.
pearance of an object and the creation of a new one are re-                                       We ran ten simulations, whereas one simulation run consisted
warded. Therefore the system strives to drag food objects in                                      of 25 epochs, each consisting of a training and a testing phase.
the agent’s mouth and ’kill’ foes by pushing them out of the                                      During training, five objects of each type were presented con-
agent’s workspace. We chose to reward the event boundaries                                        secutively at random positions. The system was given a time
of the sensory dimension s3 , since the forward models for the                                    interval of 500 simulation steps to interact with the object.
object’s position need to change at every event boundary and                                      If the system failed to remove the object in the given time
is therefore considered most reliable.                                                            period, the hard-coded algorithm used above performed the
                                                                                               1790

                                                         s1,t                                                    Heavy food     100
                           10−1
                                                         s3,t for heavy food                400                  Light food
   mean prediction error
                                                         s3,t for light food                                     Foe
                                                         s3,t for foe
                           10−4
                                                                                                                                 50
                                                                                            200
                           10−7
                           10−10                                                             0                                    0
                                   0   200         400            600          800                0        10           20            0 2 4 6 8
                                             time of activation                                       # training epochs               # training epochs
                                                                                              (a) Mean number of time steps       (b) % successful
Figure 4: Mean prediction error of one forward model over
the time this model is active. Colors indicate the type of                              Figure 5: Goal-directed behavior during testing epochs; solid
the present object and the sensory dimension this forward                               lines show system performance; dotted lines show optimal
model predicts. Only the non-trivial cases, in which the ob-                            performance; a) mean and standard deviation of time steps
ject moves, are shown.                                                                  required to successfully interact with an object; b) mean per-
                                                                                        centage of successfully completed object interactions.
required movements. During testing, each object consecu-
tively appeared at four fixed positions. When removing an                               22.9, y-wise 19.3) and for global object position (x-wise 48.7,
object during testing the hand was reset to a starting position.                        y-wise 36.5). Here the color of the object is irrelevant because
Figure 5a shows the mean number of time steps the system                                both food objects can be consumed and they differ strongly in
needed to remove an object for the different testing epochs.                            color (color difference = 100 in our simulation). Instead, the
In the first two testing epochs the time required for the in-                           exact object position is relevant.
teractions drastically decreases. After ten training epochs,
the system performs the interactions in nearly minimum time                                                       Conclusion
(dashed lines indicate the optimum). Figure 5b shows the                                Inspired by the event segmentation theory and its schematic
percentage of objects removed by the system’s hierarchical,                             model put forward in Zacks et al. (2007), we have developed
goal-directed behavior. Already after the first epoch, the sys-                         a computational, motor-grounded event segmentation model.
tem successfully removes nearly all foe and light food ob-                              Previous work has shown that statistical analyses of visual
jects. From the fourth epoch onwards, the system removes all                            changes can be used to categorize segments of video se-
objects reliably within the allowed time frame.                                         quences into distinct events (Buchsbaum, Canini, & Griffiths,
   To analyze if the system was able to differentiate between                           2011; Shi, Wang, Cheng, & Smola, 2008; Niebles, Wang,
relevant and irrelevant sensory dimensions for the prediction                           & Fei-Fei, 2008). Additionally and partially in contrast,
of an event boundary, we analyzed the variances of the co-                              our model has analyzed spatial, motor-dependent changes by
variance matrices of each event boundary model after one ex-                            learning predictive forward models and by using the learned
emplary run. The mean difference over all Gaussian distribu-                            forward models to detect event transitions based on a rigorous
tions between biggest and smallest variance in between each                             statistical measure of ‘surprise’. Moreover, our system has
Gaussian distribution is 697 – implying that there are dras-                            shown that the learned predictive model cannot only be used
tic differences in relevance for the different sensory dimen-                           to segment sensorimotor time series, but also to plan hierar-
sions. A more detailed analysis shows that the largest and                              chically goal-directedly. In the still rather restricted but con-
smallest variance indeed depended on the event boundary.                                tinuous noisy environmental simulation, our system was able
For example, a model describing the event boundary ‘hand                                to identify events, which characterized particular object ma-
touches foe’ contains the biggest variances for the global po-                          nipulations including ‘moving without object contact’, ‘drag-
sition of the object (x-wise 296, y-wise 249) and small vari-                           ging a light object’, ‘dragging a heavy object’, and ‘moving
ances for the object’s color (0.007) and the position of the                            while an object is moving’. Identified event transitions char-
object in the hand-centered frame of reference (x-wise 19.9,                            acterized boundary conditions including ‘attaching to an ob-
y-wise 21.6). This implies that the object’s type and the dis-                          ject’, ‘kicking an object’, and ‘consuming an object’. Event
tance between hand and object are considered relevant for this                          boundary encodings identified those environmental factors
event boundary, while the exact position of the object is not.                          that were critical for causing particular event transitions, such
In contrast the event boundary ‘object is consumed’ has the                             that the encodings can be thought of as conceptualizations of
biggest variance for object color (3095) and small variances                            environmental interaction options, yielding object concepts,
for the object’s position in the hand-centered frame (x-wise                            such as ‘kickable’, ‘attachable’, or ‘draggable’.
                                                                                     1791

   Our model is closely related to advances in artificial intel-     Calinon, S., Guenter, F., & Billard, A. (2007). On learning,
ligence and cognitive robotics. Calinon, Guenter, and Billard          representing, and generalizing a task in a humanoid robot.
(2007) have put forward a system that learns a temporal Gaus-          Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE
sian Mixture Model from behavioral demonstrations. Imita-              Transactions on, 37, 286–298.
tions of observed environmental interactions were executed           Clark, A. (2013). Whatever next? predictive brains, situated
using Gaussian mixture regression, focusing control on the             agents, and the future of cognitive science. Behavioral and
relevant interaction aspects. Segmentation and higher level            Brain Science, 36, 181-253.
planning, however, were not addressed. Other work has pre-           Engel, A. K., Maye, A., Kurthen, M., & König, P. (2013).
defined partitions over continuous subspaces during which              Where’s the action? the pragmatic turn in cognitive sci-
a particular motor skill could be activated (Konidaris, Kael-          ence. Trends in Cognitive Sciences, 17, 202 - 209.
bling, & Lozano-Perez, 2014). Partitions were computed by            Friston, K. (2009). The free-energy principle: a rough guide
a global clustering algorithm. In contrast, our system learns          to the brain? Trends in Cognitive Sciences, 13, 293 - 301.
to partition its environment by means of local measures of           Friston, K., Schwartenbeck, P., Fitzgerald, T., Moutoussis,
surprise based on developing forward models. Moreover, our             M., Behrens, T., & Dolan, R. J. (2013). The anatomy of
system factorizes its developing model such that is becomes            choice: active inference and agency. Frontiers in Human
able to identify those environmental properties that are criti-        Neuroscience, 7(598). doi: 10.3389/fnhum.2013.00598
cal to bring a particular event about.                               Hohwy, J. (2013). The predictive mind. Oxford, UK: Oxford
   In sum, the proposed computational model offers an algo-            University Press.
rithm that can develop suitable event segmentations online           Konidaris, G., Kaelbling, L., & Lozano-Perez, T. (2014).
from sensorimotor experiences with the environment. The                Constructing symbolic representations for high-level plan-
model suggests that EST may be applied to structure own mo-            ning. Twenty-Eighth AAAI Conference on Artificial Intelli-
tor behavior and to identify those sensorimotor signals that           gence, 1273-1280.
are critical to accomplish particular environmental manipula-        Niebles, J. C., Wang, H., & Fei-Fei, L. (2008). Unsupervised
tions. We are currently working on extending the framework             learning of human action categories using spatial-temporal
to be able to also solve non-linear control challenges in more         words. International journal of computer vision, 79, 299–
complex scenarios in virtual realities.                                318.
                                                                     Reynolds, J. R., Zacks, J. M., & Braver, T. S. (2007). A
                         References                                    computational model of event segmentation from percep-
                                                                       tual prediction. Cognitive Science, 31, 613–643.
Barsalou, L. W. (1999). Perceptual symbol systems. Behav-            Shi, Q., Wang, L., Cheng, L., & Smola, A. (2008). Dis-
   ioral and Brain Sciences, 22, 577–600.                              criminative human action segmentation and recognition us-
Barsalou, L. W., Breazeal, C., & Smith, L. B. (2007). Cog-             ing semi-markov model. In Computer vision and pattern
   nition as coordinated non-cognition. Cognitive Processing,          recognition. cvpr 2008. ieee conference on (pp. 1–8).
   8, 79-91.                                                         Sigaud, O., Butz, M., Pezzulo, G., & Herbort, O. (2013). The
Botvinick, M., & Weinstein, A. (2014). Model-based hi-                 anticipatory construction of reality as a central concern for
   erarchical reinforcement learning and human action con-             psychology and robotics. New Ideas in Psychology, 31, 217
   trol.    Philosophical Transactions of the Royal Soci-              - 220.
   ety of London B: Biological Sciences, 369(1655). doi:             Sigaud, O., Butz, M. V., Kozlova, O., & Meyer, C. (2009).
   10.1098/rstb.2013.0480                                              Anticipatory learning classifier systems and factored rein-
Botvinick, M. M., Niv, Y., & Barto, A. C. (2009). Hierar-              forcement learning. In G. Pezzulo, M. V. Butz, O. Sigaud,
   chically organized behavior and its neural foundations: A           & G. Baldassarre (Eds.), Anticipatory behavior in adaptive
   reinforcement learning perspective. Cognition, 113, 262 -           learning systems (p. 321-333). Berlin: Springer.
   280.                                                              Sutton, R. S., Precup, D., & Singh, S. (1999). Between MDPs
Buchsbaum, D., Canini, K. R., & Griffiths, T. L. (2011).               and semi-MDPs: A framework for temporal abstraction in
   Segmenting and recognizing human action using low-level             reinforcement learning. Artificial Intelligence, 112, 181-
   video features. In Annual conference of the cognitive sci-          211.
   ence society (p. 3162-3167).                                      Zacks, J. M., Kumar, S., Abrams, R. A., & Mehta, R. (2009).
Butz, M. V., Sigaud, O., & Gérard, P. (2003). Internal                Using movement and intentions to understand human ac-
   models and anticipations in adaptive learning systems. In           tivity. Cognition, 112, 201–216.
   M. V. Butz, O. Sigaud, & P. Gérard (Eds.), Anticipatory          Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S., &
   behavior in adaptive learning systems: Foundations, theo-           Reynolds, J. R. (2007). Event perception: A mind-brain
   ries, and systems (pp. 86–109). Berlin: Springer.                   perspective. Psychological Bulletin, 133, 273–293.
Butz, M. V., Swarup, S., & Goldberg, D. E. (2004). Ef-               Zacks, J. M., & Tversky, B. (2001). Event structure in percep-
   fective online detection of task-independent landmarks. In          tion and conception. Psychological Bulletin, 127, 3–21.
   R. S. Sutton & S. Singh (Eds.), ICML’04 workshop on pre-
   dictive representations of world knowledge.
                                                                 1792

