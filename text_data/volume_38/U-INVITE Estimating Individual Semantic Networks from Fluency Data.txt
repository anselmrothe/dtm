         U-INVITE: Estimating Individual Semantic Networks from Fluency Data
                                              Jeffrey C. Zemla (jzemla@brown.edu)
                                           Yoed N. Kenett (yoed_kenett@brown.edu)
                            Department of Cognitive, Linguistic, and Psychological Sciences
                                       Brown University, Providence, RI 02912 USA
                                         Kwang-Sung Jun (kjun@discovery.wisc.edu)
                                                Wisconsin Institute for Discovery
                              University of Wisconsin-Madison, Madison, WI 53706 USA
                                   Joseph L. Austerweil (joseph_austerweil@brown.edu)
                            Department of Cognitive, Linguistic, and Psychological Sciences
                                       Brown University, Providence, RI 02912 USA
                              Abstract                                    The semantic fluency task (listing of items in a category)
  Semantic networks have been used extensively in psychology
                                                                       has a long history in cognitive psychology (Henley, 1969).
  to describe how humans organize facts and knowledge in               Typical subjects show a distinct behavioral pattern in this
  memory. Numerous methods have been proposed to construct             task, reporting items in clusters (sub-categories) and
  semantic networks using data from memory retrieval tasks,            switching to new clusters when subsequent items are hard to
  such as the semantic fluency task (listing items in a category).     retrieve (Troyer, Moscovitch, & Winocur, 1997). For
  However these methods typically generate group-level                 instance, when typical subjects list animals, they may list
  networks, and sometimes require a very large amount of               several farm animals before switching to zoo animals. This
  participant data. We present a novel computational method
  for estimating an individual‚Äôs semantic network using                clustering and switching behavior has been used to make
  semantic fluency data that requires very little data. We             inferences about the cognitive processes and representations
  establish its efficacy by examining the semantic relatedness of      underlying search through semantic memory.
  associations estimated by the model.                                    Abbott, Austerweil and Griffiths (2012, 2015) proposed a
   Keywords: semantic networks; memory retrieval; fluency;             model of semantic memory retrieval that accounts for this
   random walk; probabilistic modeling                                 clustering and switching behavior (though see Hills, Jones,
                                                                       & Todd, 2012 for an alternative model that also accounts for
                          Introduction                                 this behavior). Given a semantic network, data are generated
                                                                       by taking a censored random walk on that network: Starting
Semantic memory is the system of memory that stores
                                                                       from a category‚Äôs node, their model moves over random
concepts and facts. Although the way in which semantic
                                                                       edges, emitting the labels of any nodes (e.g., ‚Äúturkey‚Äù) in its
memory is organized into categories and subcategories
                                                                       path if they are in the target category and have not been
remains an open question (Jones, Willits, & Dennis, 2015),
                                                                       visited previously. The result is a fluency list that contains
one common approach is to represent it as a network
                                                                       no duplicate items and is arranged by the order in which the
comprised of nodes (a word or concept) and edges between
                                                                       items were first encountered. Jun et al. (2015) proposed a
nodes that signify that the two concepts are associated.
                                                                       computational method based on this process to infer a
However, how do we estimate a given individual‚Äôs semantic
                                                                       semantic network from fluency data. Their method, initial-
network?
                                                                       visit emitting random walk (INVITE) is based on the
  A growing body of work has related statistics of semantic
                                                                       principle that multiple fluency lists from the same network
networks (e.g., centrality) to cognitive phenomena, such as
                                                                       can be used to infer that semantic network.
language development, memory retrieval and creative
                                                                          In this paper, we build on the INVITE model to develop a
thinking (Baronchelli, Ferrer-i-Cancho, Pastor-Satorras,
                                                                       novel method for estimating an individual‚Äôs semantic
Chater, & Christiansen, 2013; Hills, Todd, Lazer, Redish, &
                                                                       network.. We begin by presenting a few possible methods to
Couzin, 2015). Most of this work has analyzed aggregated
                                                                       estimate semantic networks, including INVITE and our
group-based networks, which cannot be used to understand
                                                                       approach. Next we evaluate these approaches and show that
individual differences. Currently, only one study has
                                                                       our approach can efficiently recover a network from
examined individual differences in semantic networks
                                                                       simulated fluency data. Finally, we present an experiment
(Morais, Olsson, & Schooler, 2013). Here, we present a
                                                                       where we collected fluency data from participants and
novel probabilistic method to estimate an individual‚Äôs
                                                                       examined the semantic similarity of edges in networks
semantic memory structure efficiently using data from a
                                                                       generated by the different approaches.
semantic fluency task.
                                                                   1907

            Estimating Semantic Networks
To estimate a network from fluency lists, we assume items
are retrieved according to a censored random walk on a
network (Abbott et al., 2015) and invert this process using
Bayes‚Äô rule. Formally, let G be the participant‚Äôs semantic
network, ùëã ! be the mth list produced from the participant (a
censored random walk from the network), ùëÜ ! be the inter-
item response times (IRTs) of the mth list (so ùëÜ!! is the time
between response k and k-1 in list m), ùëç ! be the mth               Figure 1: Left: Graphical model representing our
uncensored random walk on G (all category members                   computational method. The box is a plate, which means
visited by the random walk regardless of whether they were          that the variables are copied and conditionally
previously said) and ùëê(ùëç ! ) be a censoring function applied        independent given the network G for each list m from one
to the uncensored random walk such that it returns the              to the total number of lists M. The shaded nodes are
censored walk, (i.e., ùëê ùëç ! = ùëã ! ). We assume that each            observed. The double circle denotes a deterministic
IRT ùëÜ!! is gamma-distributed (e.g., Luce, 1986) with                function. Right: The generative process for the model. iid
parameters ùúè!! ‚àí ùúè!!!
                    !
                        and ùõΩ. The former parameter reflects        means independent and identically distributed.
the number of censored items between two unique items in
the mth uncensored list, where ùúè!! is the index of the kth         this superscript for readability when it is clear from context.
unique item reported in the mth uncensored list. ùõΩ is a            The key to INVITE is to generate each item in a fluency list
parameter that controls the amount of variability in response      from a different random walk ‚Äì one that treats visited nodes
times. Intuitively, the first parameter increases the expected     as transient and unvisited nodes as absorbing. To form each
IRT (so as the number of censored items between two                random walk, we re-arrange the states in the transition
uncensored items increases, the expected IRT increases) and        matrix of G so that the rows and columns are in list order,
ùõΩ controls the variance (see Figure 1).                            e.g., G'12 denotes a transition from X1 to X2:
                                                                                                 ‚úì              ‚óÜ
   We examine this model as well as a restricted model that                                          Q     R
does not include response times, and a na√Øve random walk                               G0 =
model that assumes no censoring occurs.                                                               0     I
                                                                   where Q denotes transitions between previously emitted
The Na√Øve Random Walk Model                                        items (transient states), R denotes transitions from
The na√Øve random walk procedure (RW) ignores the                   previously emitted items to novel items (absorbing states),
censoring procedure and places edges between all                   and 0 and I (the identity matrix) ensure the random walk is
successive items in every fluency list as if there were no         absorbing. G' is updated after each step in a list and
censored items. For example, if we have a single list ‚Äúdog,        reconfigured after each list.
cat, mouse‚Äù, our network would consist of three nodes and             Thus, we calculate ‚Ñô(ùëã!!! |ùëã!:! ) as the probability of
two edges, dog-cat and cat-mouse. When few lists are               starting at Xk and being absorbed by Xk+1 given transient
available, the RW procedure is a close fit to the most likely      states X1:k and absorbing states Xk+1:Nm. This is computed
network. However, when many lists are available, a network         using the fundamental matrix (Doyle & Snell, 1984) of G',
estimated using this procedure quickly becomes over-               N=(I-Q)-1, where Nij denotes the expected number of times a
connected, resulting in a network that contains many false         walk starting from state i visits state j before being
edges. The RW procedure is inconsistent, meaning that it is        absorbed. Thus,
                                                                                             (P
not guaranteed to converge and, in fact, it will typically                                         k
become less accurate as the number of lists increases.
                                                                                                       Nki Ri1     if N exists
                                                                      P(Xk+1 |X1:k ) =             i=1
                                                                                                0                  otherwise
The INVITE Model
Jun et al. (2015) proposed a method to invert the generative       The U-INVITE Model
process used by Abbott et al. (2015): Given a participant‚Äôs        Our model, U-INVITE, improves performance of the
semantic fluency data were produced by a random walk on a          INVITE model given a small number of lists. It does so by
network, what is the most probable network? Given M                extending INVITE in two ways: (1) by using the time
fluency lists, each denoted as ùëã ! = (ùëã!! ‚Ä¶ ùëã!"!
                                                  ), we seek a     between responses (IRTs), and (2) assuming that the
network G that maximizes the likelihood of the data:               network is undirected and unweighted (the probability of
            YM       Y Nm      1                                   transiting to any connected node is equal).
                                     m       m
                                 P(Xk+1   |X1:k )          (1)
               m=1       k=1
                                                                   Inter-item Response Times As shown in Jun et al. (2015),
                                                                   INVITE works particularly well when the number of lists is
where Nm denotes the length of the mth censored list and ùëã!!       large. When the number of lists is small, there may not be
denotes the kth item from the mth list. Hereafter, we remove       enough information in the order of the items to accurately
                                                               1908

estimate the network. One way we resolve this is by                    probability (Phub=.8) that we toggle an edge that connects
incorporating IRTs into the emission probability. Rather               two hub nodes, or otherwise toggle an edge at random. We
than maximizing Equation 1, we maximize the following                  also favor toggling one edge at a time, as the probability of
equation:                                                              producing a network that has zero probability (cannot
YM      Y Nm   1 X1
                            m              m ‚úì      m
                                                                       produce the data) increases rapidly as the number of
                        P(Xk+1 in r steps|X1:k ) P(Sk+1 |r, )(1 ‚úì)
   m=1     k=1      r=1                                                simultaneous edge changes is increased. At each update, we
   That is, we weight the probability of being absorbed by             toggle 1+D edges simultaneously where D is sampled from
Xk+1 in r steps by the probability of observing an IRT of Sk+1         a Geometric distribution with Pgeom=.2. These free
given an r-step walk. We calculate the probability of                  parameters affect only the time to convergence, and ensure
observing an IRT given r steps using a gamma distribution              that the search procedure will converge in the limit. We run
parameterized by Œ≤. We add an additional free parameter Œ∏              this procedure repeatedly until we have tried 1500 updates
to adjust the influence of IRTs on the model, i.e., when Œ∏ is          without finding a network with a higher likelihood. We
1 the model ignores IRT information. Although this                     found this stopping criterion to be robust for the toy
equation contains an infinite summation, we have found that            networks estimated in this article.
limiting this to r = 20 works as an efficient approximation in
practice, as most chains are absorbed by the next state in                                     Simulations
fewer than 20 steps. Rather than computing the probability             Varying the Number of Lists
of being absorbed by Xk+1 in the limit, we compute:                    We used simulated data to estimate the accuracy of four
                                     Xk                                different models as a function of the number of fluency lists
                                                  r 1
     P(Xk+1 in r steps|X1:k ) =                Q          Ri1
                                         i=1          ki               used to fit the network. We compared RW, U-INVITE, and
We assume a uniform prior for G, and that ‚Ñô(ùëã!! |ùêÜ) is                 U-INVITE with IRTs. We report results using two possible
uniformly distributed for all M lists.                                 values of Œ∏ in the IRT method: 0.5 (the IRT5 model) and 0.9
                                                                       (the IRT9 model).
Unweighted Networks and the Search Procedure In                           We generated 10 toy small-world networks, consisting of
addition to timing information, we include additional                  15 nodes each, using the Watts-Strogatz procedure (Watts &
constraints to estimate networks efficiently: We assume that           Strogatz, 1998). Previous literature has suggested that
the random walk is unweighted and undirected. Although                 human semantic networks are small-world like (e.g., Borge-
these assumptions may seem psychologically unrealistic,                Holthoefer & Arenas, 2010), being highly clustered yet
Abbott et al. (2015) found that both weighted and                      having a low shortest path length between any two nodes.
unweighted       semantic     networks      captured       human       We chose parameters for the Watts-Strogatz procedure to
performance in semantic fluency tasks well. Whether human              generate networks that were roughly comparable in node
semantic networks are unweighted or weighted is an                     degree and clustering coefficient to what has been reported
unsettled question and orthogonal to the purpose of our                previously for human semantic networks (Steyvers &
paper (a method for estimating weighted networks with IRT              Tenenbaum, 2005). Our toy networks had an average node
information could be created by deriving a MLE estimator               degree of 4 and a mean clustering coefficient of 0.29.
without constraints on the transition matrix, as in Jun et al.,           We varied the number of fluency lists used to estimate the
2015). Its strength enables us to estimate networks                    network from 2 to 35. Lists were generated by starting at a
efficiently from censored lists. The original INVITE allows            random node in the network and taking a random walk until
weighted edges, adding additional degrees of freedom that              all of the nodes were traversed, then extracting only the first
need to be inferred. Further, the transition matrix inferred by        visit of each node from the list. Each list was truncated to
INVITE is fully-connected; to convert it into a network that           roughly 70% of its length, or 11 items, with the restriction
is not fully-connected would require an additional                     that each node in the network is traversed at least once in
thresholding process (where estimated edge weights lower               the set of lists. This truncation process mimics human-
than an additional threshold parameter are removed from the            generated data reported later (i.e., each list contains
final network and then appropriately normalized). For these            approximately 70% of the total items listed by a
reasons, it is difficult to compare networks constructed by            participant). Simulated IRTs were generated from a gamma
INVITE and U-INVITE, and we do not provide a direct                    distribution, using the number of steps between two items in
comparison of the algorithms in this paper.                            a walk and Œ≤=1.1 as parameters.
   To find the network that maximizes the likelihood of the               We calculated the cost of each reconstructed network
data, we use a stochastic search procedure with smart                  using Hamming distance, or the number of edges that would
initialization. Using an initial network constructed with the          need to be added or removed to convert it to the original
RW procedure, we toggle one or more edges and compute                  network. The results, shown in Figure 2, demonstrate that
the new network‚Äôs probability, accepting the change when               U-INVITE does converge to the original network, though
the new network is more probable given the data. We favor              incorporating IRTs can lead to convergence with fewer lists.
toggling edges that connect two items present in multiple              While the IRT5 model performs reasonably well, we found
lists, as these ‚Äúhub nodes‚Äù have a larger effect on the                that it was outperformed by the IRT9 model, which assigns
network‚Äôs posterior probability. Specifically, we set a fixed          a higher weight to the item order than to the IRTs.
                                                                   1909

                                                                  most false alarms. In future work, we will explore why this
                                                                  is the case and how to weight IRT and order information
                                                                  optimally. Next, we compare the different methods on real
                                                                  behavioral results from a semantic fluency task where
                                                                  participants generate multiple fluency lists.
                                                                  Table 1: Results of estimating networks from three lists. 300
                                                                  networks were generated and each method was used to
                                                                  estimate these toy networks. Values denote average scores
                                                                  (standard deviation in parentheses).
                                                                   Measure       RW         U-INVITE     IRT5       IRT9
                                                                   Cost          19.2 (3.3) 18.9 (3.6)   19.1 (3.7) 18.2 (3.5)
                                                                   Hits          17.7 (1.8) 16.3 (2.0)   18.3 (1.9) 16.9 (2.0)
                                                                   Misses        12.3 (1.8) 14 (2.0)     11.7 (1.9) 13.0 (2.0)
                                                                   False         6.9 (1.9) 5.0 (2.2)     7.5 (2.4) 5.0 (2.1)
                                                                   Alarms
Figure 2: As the number of fluency lists increases, our
                                                                  Experiment: A repeated semantic fluency task
methods tend toward zero error. Not shown: the RW method
increases linearly to about 50 by 35 lists.
                                                                  Methods
Model Comparison Given Three Lists                                Participants We recruited twenty participants from
We conducted an additional simulation using only three            Amazon Mechanical Turk (11 male, mean age 31.75) who
fluency lists to examine whether IRTs improve network             were located in the United States.
estimation when only a small number of lists are used.
Using the same procedure as above, we generated 300 toy
                                                                  Procedure Participants were given a category label (e.g.,
networks with 15 nodes each, and reconstructed each
                                                                  animals) and asked to generate as many items from that
network using each of the four methods. A one-way
                                                                  category as possible in three minutes. Each participant
repeated measures ANOVA was conducted to examine the
                                                                  completed nine lists in total, three for each of three
effect of the different methods on the cost of estimating the
                                                                  categories (animals, fruits, and vegetables). The order of the
original network (Table 1). This analysis revealed a
                                                                  lists was pseudo-randomized so that each triad of lists
significant main effect of method, F(3, 897) = 26.13, p <
                                                                  contained one of each category, and participants never
0.001, Œ∑2 = .08. Post-hoc analyses revealed that this main
                                                                  completed the same category twice in succession.
effect was due to the IRT9 model outperforming the other
                                                                     Each response was hidden from view after it was entered
three models (all p‚Äôs < 0.001). No significant differences
                                                                  to reduce cueing effects from previously entered items.
were found between the average cost of the RW, U-
                                                                  Participants were instructed to list each item no more than
INVITE, and IRT5 models.
                                                                  once within a list, but that they could repeat themselves on
   We classified the edges in the reconstructed networks to
                                                                  subsequent lists.
indicate whether an edge was present in both the original
and reconstructed network (Hit), in the original but not the
reconstructed network (Miss), or in the reconstructed but not     Results
the original network (False Alarm). A one-way repeated            We present the results solely from the animal category,
measures ANOVA was conducted for Hits/Misses, F(3,                which generated the most responses. Twenty participants
897) = 262.06, p < 0.001, Œ∑2 = .47, as well as False Alarms,      generated 280 unique animals in total (average 54.5 per
F(3, 897) = 415.79, p < 0.001, Œ∑2 = .51. We found that            participant and 33.7 per list). Participants were largely
compared to U-INVITE, the IRT9 model contains                     successful at avoiding repetitions, repeating fewer than one
significantly more hits (and fewer misses). However, we           animal per list on average. All repetitions were removed
found no difference in the number of false alarms. This           from the data set prior to analysis.
indicates that incorporating IRTs improves upon U-INVITE             To validate our method, we examined the similarity
by accurately detecting more genuine edges, while keeping         between connected nodes using the BEAGLE lexical
the number of false alarms constant. In contrast, the RW          semantic database (Jones & Mewhort, 2007). The database
method generates substantially more false alarms compared         estimates the semantic similarity between two words from
to U-INVITE and IRT9. Finally, the IRT5 model resulted in         their statistical co-occurrence in a large corpus of text. For
the highest amount of hits and fewest misses, but also the        example, dog-cat has a high BEAGLE similarity whereas
                                                                  dog-toad has a low BEAGLE similarity.
                                                              1910

 Figure 3: Network reconstruction with U-INVITE and IRT5 models of the semantic network of a single participant. Edge
 style denotes model success at estimating edges: Solid line: edges estimated by both methods; Dashed line: edges estimated
 only by the U-INVITE model; Sinusoidal line: edges estimated only by the IRT5 model.
   We computed the BEAGLE value for all edges in each               networks, INVITE was typically a poor estimator of the true
network, except those that could not be computed because            network when the number of lists was small.
one of the nodes was not in the BEAGLE database                        Compared to U-INVITE, the IRT9 model added 23 edges
(accounting for 6.4% of edges). For each participant, we            (1.4%) and removed 22 edges (1.4%). We calculated the
also calculated the BEAGLE value that would be expected             average BDS (per participant) of edges present in IRT9 but
between a random pair of nodes in the network (i.e., the            not in U-INVITE, and found that these edges had a BDS
average BEAGLE value across all possible edges in the               significantly greater than expected by chance, indicating
network). We then subtract this score from the BEAGLE               that the added edges connect nodes that are semantically
value of each edge in the network to generate a BEAGLE              similar, MBDS = .068, t(12) = 2.21, p = .047. However, we
difference score (BDS), where positive scores indicate the          also found that edges present in U-INVITE but not in IRT9
two connected animals are more similar than would be                were more similar than expected by chance, MBDS = .063,
expected by chance.                                                 t(10) = 3.23, p = .009. There was no statistical difference
  All five methods generated sensible networks1: the                between the average BDS of edges added compared to
average BDS of all edges for each participant and each              edges removed (p = .89).
method (80 networks) was higher than would be expected                 The IRT5 model made substantial changes to the network
by chance. U-INVITE generated networks that were similar            compared to U-INVITE (see Figure 3 for an example).
to the RW method. Across all twenty participants, U-                Across all participants, the IRT5 method added 486 edges
INVITE added zero edges compared to the RW method, and              (30.1%) that were not present in the U-INVITE network and
removed only 39 edges (roughly 2.4% of all edges). This is          removed 150 edges (9.3%) of the edges that were present in
probably because U-INVITE needs more data to make                   the U-INVITE network. The edges added by IRT5 have an
accurate estimates. Jun et. al (2015) found that for toy            average BDS significantly greater than expected by chance,
                                                                    MBDS = .015, t(19) = 2.91, p = .017. However, as with IRT9,
                                                                    we also found the reverse to be true: Edges that were
  1
    Networks for each participant and each method are available
                                                                    removed from the U-INVITE model have a higher BDS
online at http://research.clps.brown.edu/austerweil/UINVITE16/      score than was expected by chance, MBDS = .025, t(18) =
                                                                1911

4.34, p < .001. Comparison between the edges removed and         De Deyne, S., Kenett, Y. N., Anaki, D., Faust, M., &
edges added showed no statistical difference (p = .22).             Navarro, D. J. (in press). Large-scale network
                                                                    representations of semantics in the mental lexicon. In M.
                       Conclusions                                  N. Jones (Ed.), Big data in cognitive science: From
Advancements in network science and probabilistic                   methods to insights: Psychology Press.
modeling enable scientists to investigate how the structure      Doyle, P. G., & Snell, J. L. (1984). Random walks and
of semantic memory contributes to language development,              electric networks.
creativity and intelligence, and memory retrieval (De            Faust, M., & Kenett, Y. N. (2014). Rigidity, chaos and
Deyne, Kenett, Anaki, Faust, & Navarro, in press).                   integration: Hemispheric interaction and individual
However, current research has been limited to group                  differences in metaphor comprehension. Frontiers in
analyses, which cannot account for individual differences.           Human Neuroscience, 8(511), 1-10.
Our method estimates an individual‚Äôs semantic memory             Heathcote, A., Popiel, S. J., & Mewhort, D. J. (1991).
structure based on multiple semantic fluency responses.            Analysis of response time distributions: an example using
   Our approach extends that of Jun et al. (2015) by               the Stroop task. Psychological Bulletin, 109(2), 340-347.
constraining the estimated networks to be unweighted and         Henley, N. M. (1969). A psychological study of the
undirected, and incorporating response time information.              semantics of animal terms. Journal of Verbal Learning
We found that our method accurately recreated small-world             and Verbal Behavior, 8(2), 176-184.
networks, which have consistently been found to resemble         Hills, T. T., Jones, M. N., & Todd, P. M. (2012). Optimal
human networks (Borge-Holthoefer & Arenas, 2010).                     foraging in semantic memory. Psychological Review,
Further modifications to our model may improve its                    119(2), 431-440. doi:10.1037/a0027373
accuracy. For instance, we may use a more realistic              Hills, T. T., Todd, P. M., Lazer, D., Redish, A. D., &
response time function other than a gamma distribution,                Couzin, I. D. (2015). Exploration versus exploitation in
such as the ex-Gaussian distribution (Heathcote, Popiel, &             space, mind, and society. Trends in Cognitive Sciences,
Mewhort, 1991). We also plan to examine more realistic                19(1), 46-54.
process models (e.g., an imperfect censoring function would      Jones, M. N., & Mewhort, D. J. K. (2007). Representing
allow us to model perseverations in semantic retrieval).              word meaning and order information in a composite
Finally, we plan to examine how to weight IRT information             holographic lexicon. Psychological Review, 114(1), 1-
optimally and perform additional validations of our method.         37. doi:10.1037/0033-295X.114.1.1
   Developing methods to estimate an individual‚Äôs network        Jones, M. N., Willits, J., & Dennis, S. (2015). Models of
representation from fluency data has great potential across         semantic memory. In J. Busemeyer & J. Townsend
cognitive science. They will allow us to examine individual         (Eds.), Oxford Handbook of Mathematical and
differences in semantic networks and relate them to                 Computational Psychology (pp. 232-254).
neurocognitive variables that affect memory search and           Jun, K.-S., Zhu, X., Rogers, T. T., Yang, Z., & Yuan, M.
executive functions in typical and clinical populations             (2015). Human memory search as initial-visit emitting
(Faust & Kenett, 2014). For instance, Alzheimer‚Äôs and               random walk. Advances in Neural Information
semantic dementia patients show marked disruption in                Processing Systems (NIPS).
performance on a semantic fluency task (Rohrer, Salmon,          Luce, R. D. (1986). Response times (No. 8). Oxford
Wixted, & Paulsen, 1999). We hope that our method can be           University Press.
used to improve our understanding of impaired and                Morais, A. S., Olsson, H., & Schooler, L. J. (2013).
unimpaired cognitive search.                                        Mapping the structure of semantic memory. Cognitive
                                                                    Science, 37(1), 125-145. doi:10.1111/cogs.12013
                                                                 Rohrer, D., Salmon, D. P., Wixted, J. T., & Paulsen, J. S.
                        References
                                                                    (1999). The disparate effects of Alzheimer's disease and
Abbott, J. T., Austerweil, J. L., & Griffiths, T. L. (2012).        Huntington's disease on semantic memory.
    Human memory search as a random walk in a semantic              Neuropsychology, 13(3), 381-388.
    network. Advances in Neural Information Processing           Steyvers, M., & Tenenbaum, J. B. (2005). The large scale
    Systems, 25, 3050-3058.                                         structure of semantic networks: Statistical analysis and a
Abbott, J. T., Austerweil, J. L., & Griffiths, T. L. (2015).        model of semantic growth. Cognitive Science, 29(1), 41-
    Random walks on semantic networks can resemble                  78.
    optimal foraging. Psychological Review, 122(3), 558-         Troyer, A. K., Moscovitch, M., & Winocur, G. (1997).
    569. doi:10.1037/a0038693                                       Clustering and switching as two components of verbal
Baronchelli, A., Ferrer-i-Cancho, R., Pastor-Satorras, R.,          fluency: Evidence from younger and older healthy adults.
    Chater, N., & Christiansen, M. H. (2013). Networks in           Neuropsychology, 11(1), 138-146.
    Cognitive Science. Trends in Cognitive Sciences, 17(7),      Watts, D. J., & Strogatz, S. H. (1998). Collective dynamics
    348-360. doi:10.1016/j.tics.2013.04.010                         of ‚Äòsmall-world‚Äô networks. Nature, 393(4), 440-442.
Borge-Holthoefer, J., & Arenas, A. (2010). Semantic
    networks: Structure and dynamics. Entropy, 12(5), 1264-
    1302.
                                                             1912

