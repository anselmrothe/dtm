Spatial Interference and Individual Differences in Looking at Nothing for Verbal
Memory
Alper Kumcu (axk393@bham.ac.uk)
School of Psychology, University of Birmingham
Edgbaston, Birmingham, B15 2TT UK

Robin L. Thompson (r.thompson@bham.ac.uk)
School of Psychology, University of Birmingham
Edgbaston, Birmingham, B15 2TT UK

Abstract
People tend to look at uninformative, blank locations in
space when retrieving information. This gaze behaviour,
known as looking at nothing, is assumed to be driven by the
use of spatial indices associated with external information.
We investigated whether people form spatial indices and
look at nothing when retrieving words from memory.
Participants were simultaneously presented four words.
During retrieval participants looked at the relevant, blank
location, where the probe word had appeared previously,
longer than the other blank locations. Additionally, word
presentation was sometimes followed by a visual cue either
co-located or not with the probe word. Valid cues functioned
as visual reinforcement while invalid cues caused
interference. Finally, participants with better visuospatial
memory looked less at the relevant, blank location,
suggesting a dynamic relationship between so-called
“external” and “internal” memory. Overall findings suggest
an automatic, instantaneous spatial indexing mechanism for
words and a dynamic looking at nothing behaviour.
Keywords: looking at nothing; spatial indexing; mental
representation; visuospatial memory; verbal memory; spatial
interference; individual differences

Introduction
The human mind can anchor spatially-located information
to external spatial locations. This mechanism has been
expressed within a visual processing model, where the
location of an object is separated from the visual features
of it (Marr, 1982). This view, expanded into an exhaustive
spatial indexing model (Pylyshyn, 2001), assumes that the
visual system is able to individuate spatial relations before
discerning a visual pattern and immediately index the
locations of such patterns.
Additionally, within the model, spatial indices remain
attached to a particular object independent of its
movements and visual properties. Spatiotemporal
continuity occurs even when the visual information
disappears, as often manifested in mental imagery studies
(i.e., Brandt & Stark, 1997). Accordingly, spatial indices
tied to external visual and verbal information trigger eye
movements when a mental representation is reactivated.
Thus, when retrieving information from memory, people
tend to exploit location-based indices and look at the
seemingly uninformative, empty locations where the
information originally occurred even if location is
irrelevant to the task. This behaviour is known as looking
at nothing (Ferreira, Apel, & Henderson, 2008).

In their pioneering study, Richardson & Spivey (2000)
documented the use of spatial information and looking at
nothing in verbal memory. Four faces randomly appeared
on different quadrants of a two by two grid along with four
corresponding spoken facts (e.g., “Shakespeare’s first
plays were historical dramas; his last was the Tempest”).
On the next screen, a statement (e.g., “Shakespeare’s first
play was the Tempest”) probed participants’ memory for
verbal information. During recall, there were significantly
more looks at the blank quadrant where the face associated
with the probed semantic information had been when
compared to other quadrants. Thus, people did not just look
at any nothing when answering the questions. Rather, they
looked at an invisible spatial index, which was previously
allocated to the information (Spivey & Geng, 2000).
Looking at nothing may be best thought of as an interface
between internal and external worlds. Ferreira et al. (2008)
proposed an integrated memory architecture, where
external cues and internal representations work hand in
hand to retrieve information as efficiently as possible (see
also Richardson, Altmann, Spivey, & Hoover, 2009). More
precisely, the integrated memory account combines
visual/auditory and spatial information in the external
world with visual, linguistic, spatial and conceptual
counterparts in the mental world. When part of an
integrated representation (linguistic information) is
reactivated, the other parts (spatial information) are
retrieved as well.
In the current study, we address the looking at nothing
triangle, which is composed of (A) actual looking
behaviour, (B) spatial indices and (C) mental
representations. Unlike any other looking at nothing
studies, we used single, visual words as retrieval material
instead of visual objects (i.e., Johansson & Johansson,
2014; Martarelli & Mast, 2013; Spivey & Geng, 2000;
Vankov, 2009; Wantz, Martarelli, & Mast, 2015) or
auditorily presented statements which are explicitly
associated with visual objects (i.e., Hoover & Richardson,
2008; Richardson & Kirkham, 2004; Richardson & Spivey,
2000; Scholz, Mehlhorn, & Krems, 2011, 2014). Our main
motivation was to reveal automatic and instantaneous
spatial indexing and clear-cut looking at nothing behaviour
guided specifically by verbal memory in a visuospatial
context. Additionally, we focus on two separate but
interrelated questions with regard to different vertices of
this triangle within the scope of dynamicity of looking at
nothing.

2387

Spatial Interference and Spatial Indexing
First, we probe (1) how (in)congruency of interfering
spatial cues affects spatial indexing and looking at nothing.
A plethora of studies show that the human mind is
susceptible to spatial manipulation in tasks even when the
location is irrelevant to successful performance. People
react faster and perform better when there is spatial
compatibility between cue and probe (the Simon effect;
Simon & Rudell, 1967). Although there is evidence for a
Simon-like effect in spatial indexing (Vankov, 2009),
relatively little is known about the role of spatial
interference and congruency in looking at nothing.
Understanding spatial interference and congruency is
important for defining a spatial encoding mechanism.
Looking at nothing has been observed even when the
locations associated with the to-be-retrieved information
moved and thus updated the spatial indices. Both adults and
6-month-olds were able to track moving events and looked
at the updated locations, indicating a flexible and dynamic
spatial indexing structure (Richardson & Kirkham, 2004).
In light of such evidence, we might argue that if looking at
nothing is sensitive to systematic cue manipulation (i.e.,
Wühr & Ansorge, 2007), that is, to (in)congruencies with
the original indices, then the link between a spatial
indexing mechanism and looking at nothing might be
stronger than previously thought. More precisely, such a
directional link might suggest that not only the existence
but also the magnitude of looking at nothing is determined
by the strength and stability of spatial encoding.
Interfering cues are also important in understanding the
interplay between (B) spatial indices and (C) mental
representations. If looking at nothing depends on internal
operations working with external spatial cues, then spatial
codes which are updated with interference should lead to
less looking at nothing. This is predicted based on the
assumption that, in such as a case, space becomes
unreliable: i.e., there is competition between the mental
representations corresponding to the spatial indices for
words and for cues, respectively. In contrast, a valid spatial
code should strengthen the association between mental
representations corresponding to the word and to its
location, which, in turn, should be reflected in looking
behaviour. While stability of spatial indexing across time
has been shown (Martarelli & Mast, 2013; Wantz et al.,
2015), spatial stability and the role of interference in
looking at nothing still remain largely unknown.

Integrated Memory and Individual Differences
Additionally, we investigate the relationship between (A)
looking at nothing and (C) mental representations by
asking (2) whether there are individual differences in
looking at nothing behaviour based on “internal”
visuospatial memory. We hypothesize that the cognitive
system uses both internal and external cues to access
memory traces. Therefore, external cues may be used to
relieve internal operations, and people with relatively
worse visuospatial memory should rely more on looking at
nothing behaviour (and vice versa). Determining the
existence or absence of a correlation between individual
visuospatial memory differences and memory-driven eye
movements is essential to understanding the intrinsic

nature of looking at nothing and its relation with mental
representations. If a correlation is found, it will provide
further evidence for the integrated memory account
(Ferreira, et al., 2008). There is already growing evidence
that looking at nothing changes according to internal
demands. For example, people tend to exhibit less looking
at nothing as they are asked to study and recall the same
sentences over and over again, suggesting less reliance on
external cues as the task becomes easier through repetition
(Scholz et al., 2011). However, not much is known about
how differences in internal memory map onto differences
in looking at nothing behaviour within the scope of
integrated memory operations.
Our experimental paradigm diverges from the previous
looking at nothing studies in the following ways: (1) Single
words were used instead of visual objects as information to
be retrieved. Looking at nothing is fundamentally a
visuospatial phenomenon. However, what makes the words
recognizable visually is both controllable and not usually
related to vision (Harm & Seidenberg, 2004). Thus, we
aimed to disentangle the retrieval items from the visual
environment to be able to observe more refined behaviour.
We also aimed to systematically manipulate and control the
stimuli and rule out any item-related effect on the memory
load and thus, looking at nothing. Accordingly, words were
controlled for a number of memory-related variables. (2)
Participants were exposed to retrospective memory
interference which was irrelevant to the main task. We
expected to push out old information (i.e., encoded words)
from the episodic buffer (Baddeley, 2000) and encourage
participants to depend on spatial indices for the retrieval of
words. (3) Words to be retrieved were presented
simultaneously and were not explicitly associated with any
kind of visual object. Rather, participants processed the
words together and were expected to form immediate
indices based on the word location. This is how verbal
information is processed in real-world cognitive tasks such
as reading (see Fischer, 1999), thus making the task more
naturalistic. We aimed to unearth more ecologically valid,
systematic and robust looking at nothing behaviour.

Method
Participants
The experiment was carried out with forty-eight students at
the University of Birmingham (six males; Mage = 19.92, SD
= 1.96, range: 18 – 27, four left-handed). All participants
were monolingual native speakers of British English as
determined with the Language History Questionnaire
(version 2.0; Li, Zhang, Tsai, & Puls, 2013). Participants
reported normal or corrected-to-normal vision, no speech
or hearing difficulties and no history of any neurological
disorder. They received either £6 (n = 12) or course credit
(n = 36) for participation. All participants were fully
informed about the details of the experimental procedure
and gave written consent. Post-experiment debriefing
revealed that all participants were naïve to the purpose of
the experiment.

2388

Materials
There were 192 trials involving 864 unique nouns in total.
Trials were evenly divided into two groups (n = 96) as
experimental (positive probe) trials and fillers. Probe words
in the experimental trials were among the four study words
in the encoding phase, whereas a different, not seen, word
was probed in fillers. Words in the experimental trials (n =
384) were drawn from the extensions of Paivio, Yuille and
Madigan norms for 925 nouns (Clark & Paivio, 2004). The
word pool was filtered to exclude words shorter than 3
letters and longer than 6 letters. Imageability, frequency
(logarithmic values of occurrences per million in Kučera &
Francis, 1967; and the CELEX database, Baayen,
Piepenbrock, & Gulikers, 1995), age of acquisition,
concreteness, availability (Keenan & Benjafield, 1994),
length in letters and number of syllables were identified as
major predictors of verbal memory (Rubin & Friendly,
1986) and used to control the experimental stimuli.
The subset was then grouped into quadruples and trial
sets were identified. Words within quadruples were
matched on age of acquisition, availability, concreteness,
imageability, length in letters, log frequency and number of
syllables (all SDs < 2.00 and all SEs < 1.00). Words were
further controlled so that no word started with the same
letter, rhymed or related semantically with any other in the
quadruple. Monosyllabic, disyllabic and trisyllabic words
were evenly distributed [e.g., (3, 3, 3, 3), (1, 2, 1, 2) or (3,
2, 3, 2) etc.]. The word in each trial set with the median
imageability value was selected as the probe among four
words leaving the others as distractors (see Rubin &
Friendly). Welch’s t-tests revealed no significant
difference between the probe and distractor words in any of
the variables (all ps > .05). Thus, any word among the four
words in each trial set was as likely to be remembered as
any other word. Words in filler trials were drawn from the
Toronto Word Pool (Friendly, Franklin, Hoffman, &
Rubin, 1982). They were also controlled to develop a
consistent stimuli set. Words were grouped into quintuples
and matched on log frequency in CELEX database (all SDs
< 0.60 and all SEs < 0.30). Welch’s t-tests revealed that
there was no significant difference between the probe and
the study words in frequency, length in letters or number of
syllables (all ps > .05).
We formed 192 unique mathematical equations (e.g.,
(5X2) – (1+8) = 1) to present as memory interference
between encoding and retrieval phases (see Conway &
Engle, 1996 for a similar design). Half of the equations
were correct. Incorrect equations were further divided into
two equal groups: The results were either plus or minus one
of the correct result.

Apparatus
Stimuli were presented on a TFT LCD 22-inch widescreen
monitor operating at 60 Hz with a resolution of 1680 x 1050
pixels (501.7 mm x 337.4 mm). The monitor was placed
640 mm in front of the participant. A chin and forehead rest
was used to reduce head movements. Participants’ eye
movements were monitored using SR EyeLink® 1000
(sampling rate: 1000 Hz, spatial resolution < 0.5°, http://srresearch.com/eyelink1000.html). Viewing was binocular
but only the left eye was monitored. Auditory material was

produced by a native female speaker of British English in a
sound attenuated room and recorded using Audacity
(version 2.1.10, http://web.audacityteam.org). Participants
responded (yes/no they had seen the word) by pressing one
of two keys on a standard keyboard. Eye movement data
were analysed using the SR EyeLink® Data Viewer
(version
2.4.0.198,
http://www.srresearch.com/accessories_EL1000_dv.html). No drift or
blink correction procedure was applied. Data were
analysed and visualised with R (version 3.2.3) (R Core
Team, 2015).

Procedure
A pre-experiment questionnaire involving Language
History Questionnaire and Edinburgh Handedness
Inventory (Oldfield, 1971) was administered.
Eye tracking started with a standard nine-point
calibration and validation, which confirmed high data
quality (average calibration error < 1° and maximum
calibration error < 1.50°). The experiment was composed
of five consecutive phases. Fixation: A fixation cross
appeared at the centre of the screen for 500 ms. Encoding:
Participants were presented four words on a 2 x 2 grid for
1600 ms. Words (Times New Roman, font size = 40) were
centrally placed in rectangular boxes (285 x 85 in pixels,
7.6° x 2.4° of visual angle). Cueing: A flashing black dot
appeared in cue trials for 1000 ms either in the same (valid
cue) or in the diagonal quadrant (invalid cue) as the original
location of the probe word in the encoding phase. There
was also a third condition where no cue was presented
between encoding and interference. The cue manipulation
was a between-subjects variable. An equal number of
random participants (n = 16) saw the probe word with valid
cue, invalid cue or without any cue. Interference:
Participants were presented a mathematical equation and
asked to identify whether the equation was correct or not
within 10,000 ms. Retrieval: The probe word was
auditorily presented as participants looked at the blank grid
with empty boxes. Participants were asked to make an
unspeeded yes/no judgement to determine whether they
had seen the probe word among the four words shown in
the encoding phase within 10,000 ms (or they timed-out).
The order of trials and equations were fully randomised.
The location of all words in all conditions was
counterbalanced with Latin Square design to control gaze
biases so that each word appeared an equal number of times
in each location of the grid. The experiment was divided
into four equal blocks and there was a short pause between
blocks. A typical session lasted approximately 60 minutes.
Overall accuracy in interference equations was 81.19% and
86.07% in the verbal recognition test, suggesting that
participants were attending to the task.
Following the experiment, a computerized version of the
Corsi block-tapping task (Milner, 1969) operated on PEBL
(Psychology Experiment Building Language, version 0.13,
test battery version 0.7, http://pebl.org) (Mueller & Piper,
2014) was used to measure visuospatial short-term
memory.

2389

Results

Individual Differences in Looking at Nothing

Dwell time percentage (i.e., percentage of total time - in
milliseconds - spent on a specific interest area) was used as
the main gaze measure and dependent variable because it is
immune to differences in task duration. Accordingly, four
rectangular interest areas corresponding to the quadrants
were identified. All interest areas were of the same size
(502 x 368 in pixels, 13.4° x 10.6° of visual angle). They
framed the rectangular boxes and were not contiguous. A
circular interest area with a diameter of 40 pixels (1.1° of
visual angle) was also defined at the centre of the grid.
Dwell time percentages accrued on the interest areas during
the retrieval phase (from the presentation of the probe word
until the participant’s response) were calculated. Fixations
were a minimum duration of 40 ms. Fixations outside the
interest areas (6.54%) were omitted.

Looking at Nothing with Spatial Interference

We investigated whether looking at nothing behaviour
changes according to the visuospatial memory differences
of participants. Overall, there was a significant, positive
correlation between dwell time percentage spent on the
central interest area and visuospatial memory measured
with Corsi block-tapping test 𝑟& (46) = .34, p = .02 such
that participants with better visuospatial memory tended to
look more at the centre of the screen and did not look at
“nothing” (i.e., relevant, blank quadrant) by definition. An
additional variable, looking at nothing strength, was
formulated by simply subtracting dwell time percentage
spent on the central interest area from dwell time
percentage spent on the relevant quadrant. As expected,
there was also a significant, negative correlation between
looking at nothing strength and visuospatial memory
𝑟& (46) = - .29, p = .04 (see Figure 1).

We began by investigating whether there was a difference
between spontaneous looking times across quadrants and
cue conditions during the retrieval phase. Dwell time
percentages allocated to three irrelevant quadrants were
averaged into one irrelevant quadrant and analysed against
the relevant quadrant across the three different cue
conditions. A mixed analysis of variance showed a main
effect of quadrant F1(1, 141) = 14.40, p < .001; 𝜂"# = .09;
F2(1, 573) = 15.85, p < .001, 𝜂"# = .03 and an interaction
effect of cue condition F1(2, 141) = 3.60, p = .03, 𝜂"# = .05;
F2(2, 573) = 2.89, p = .06, 𝜂"# = .01. Paired t-tests revealed
that participants looked significantly longer at the relevant
quadrant than the average of three irrelevant quadrants
when retrieving the probe word in all conditions together
and in the valid cue condition (see Table 1).
Table 1: Differences between dwell time percentages of
relevant and irrelevant quadrants under different cue
conditions (df = 47).
Condition
Valid
Invalid
No Cue

Relevant
0.22
0.19
0.19

Irrelevant
0.17
0.19
0.17

t
3.66
0.64
1.93

p
.00
.53
.06

d
0.6
0.1
0.3

Participants did not look at the relevant quadrant
significantly longer in the invalid cue condition. Therefore,
dwell time percentages in the invalid cue condition were
further analysed to understand the impact of the invalid
cue. A repeated measures analysis of variance showed that
there was not a significant difference between dwell time
percentages across cue quadrant (i.e., where the cue was
presented in the cueing phase) (M = 0.20, SD = 0.08),
relevant quadrant (M = 0.19, SD = 0.08) and irrelevant
quadrant (M = 0.18, SD = 0.06) F1(2, 94) = 1.33, p = .27;
F2(2, 382) = 1.95, p = .15.
Dwell time percentage spent on the relevant, blank
quadrant decreased significantly across blocks F(3, 141) =
4.33, p = .006, 𝜂"# = .08.

Figure 1: Scatterplots showing the correlations between
looking at nothing and visuospatial memory.
To analyse the effect of the interfering cue on the
correlation between looking at nothing and visuospatial
memory, participants were divided into two equal groups:
(1) good (memory score, M = 79.08 SD =19.54) and (2)
poor (memory score, M = 43.04 SD = 9.43) visuospatial
memory. Welch’s t-tests showed that participants with
better visuospatial memory looked significantly less at the
relevant, blank quadrant when retrieving the probe word
during the invalid cue condition compared to participants
with poor visuospatial memory (Good M = 0.17, SD = 0.07,
Poor M = 0.22, SD = 0.07) t(45.95) = 2.49, p = .02, d = 0.7
but not in valid or no cue condition (ps > .05). The effect
of invalid cue was confirmed with Spearman correlations.
As found in all conditions together, there was a significant,
positive correlation between dwell time percentage spent
on the central interest area and visuospatial memory 𝑟& (46)
= .33, p = .02 and also a significant, negative correlation
between looking at nothing strength and visuospatial
memory 𝑟& (46) = - .35, p = .01 in invalid cue condition.

Discussion
In the present study, we investigated the spatial indexing
and looking at nothing processes with (in)congruent spatial

2390

cues for simultaneously presented single words in a
recognition memory test, and whether visuospatial memory
differences between participants correlate with looking at
nothing behaviour. Participants instantly formed spatial
indices corresponding to simultaneously presented words
even though the locational information was unnecessary
for the successful completion of the task. They also looked
at relevant, blank locations significantly longer than the
other, irrelevant blank locations when they were asked to
retrieve the probe word.
We replicated a looking at nothing effect with marginal
significance in a “pure” looking at nothing condition where
no cue was presented. Given that the presented words were
not explicitly associated with visual cues in our experiment,
results might be interpreted as further evidence for the
automaticity and availability of spatial indices (Vankov,
2009), which, guide eye movements to empty locations.
Along with that, the novelty of the present research lies in
the use of words instead of visual objects. The fact that
participants used the visuospatial channel to access verbal
memory traces suggests that looking at nothing is a
distinctive, memory-oriented behaviour and might be even
more robust than previously documented. One might argue
that the looking at nothing effect in this study can be
accounted for by an attentional mechanism initiated by the
interfering cues. However, participants also looked at the
relevant, blank quadrant without any cue in the pure
looking at nothing condition with a marginally significant
difference and a small effect size. Further, they did not look
at the previous location of the cue longer than the other
quadrants in the invalid cue condition. Therefore, we
conclude that spatial indices formed for single words can
reliably orient eye movements to blank locations in a
recognition memory task.
Results from the cue manipulation confirmed our
hypothesis in general and resulted in a Simon-like effect
(Wühr & Ansorge, 2007). As expected, participants formed
spatial indices for cues. When the spatial index
corresponding to the probe word and the index
corresponding to the cue matched (as in the valid cue
condition), the looking at nothing effect was amplified.
However, when these indices were in competition (as in the
invalid cue condition), the initial index was updated and
eye movements to the relevant, blank location were
disrupted. Taken together, cue manipulation results
demonstrate that the link between spatial indexing and
looking at nothing is indeed dynamic and systematic.
Similarly, we observed a decrease in looking at nothing
towards the end of the experiment, which was in favour of
the previous findings (Scholz et al., 2011) with the
exception that participants in our study studied different
items throughout the experiment. One explanation could be
that as the participants gradually became accustomed to the
task, mental load decreased and so did the necessity to draw
information from space.
The relation between mental load and reliance on space
was also reflected in individual differences results. To our
knowledge, this is the first evidence showing individual
differences when looking at nothing. Participants with
better visuospatial memory, thus richer internal sources,
relied less on the spatial indices and consequently looking
at nothing. The tendency of looking at the centre was

revealed among these participants probably because they
were faster in general and did not have the necessity to refer
to any blank quadrants including the relevant one.
Although the correlations were either weak or moderate,
this alone might be regarded as clear evidence for the
integrated memory model, where external (space) and
internal (mental representations) elements of memory work
together (see Jackendoff, 1996). More importantly,
differences were mostly pronounced in the invalid cue
condition. Thus, in the event of spatial interference and
confusion, participants with better visuospatial memory
seemed to disengage from the space by ignoring any deictic
code either attached to words or cues, and turned to internal
sources. This is particularly important considering that,
looking at the centre was not a general trend among all
participants in invalid cue condition. The correlation might
also suggest that looking at nothing is not a by-product but
a functional (Johansson & Johansson, 2014; Scholz et al.,
2014) and even a strategic behaviour which systematically
changes not only with the processing demands of the task
but also from individual to individual. In a nutshell, our
results suggest that there is a balanced trade-off between
internal and external sources driven by task conditions in
order to make the most of environmental opportunities and
cognitive capacity.
Looking at nothing is a unique case in that it demonstrates
how the cognitive system can maximize efficiency by
spreading the cognitive problem across three domains with
the act of looking, the environment with the spatial indices
and mental representations in the brain. Further, looking at
nothing in this study can be regarded as an example of very
efficient multimodal coordination given that participants
studied verbal information and made use of the visuospatial
canvas when auditorily probed. In this regard, the study is
expected to have broader implications towards a new and
unorthodox understanding of cognition.

References
Baayen, H., Piepenbrock, R., & Gulikers, L. (1995). The
CELEX lexical database. Philadelphia, PA.: Linguistic
Data Consortium, University of Pennsylvania.
Baddeley, A. D. (2000). The episodic buffer: a new
component of working memory? Trends in Cognitive
Sciences, 4(11), 417–423. doi:10.1016/S13646613(00)01538-2
Brandt, S. A., & Stark, L. W. (1997). Spontaneous Eye
Movements During Visual Imagery Reflect the Content
of the Visual Scene. Journal of Cognitive Neuroscience,
9(1), 27–38. doi:10.1162/jocn.1997.9.1.27
Clark, J. M., & Paivio, A. (2004). Extensions of the
Paivio, Yuille, and Madigan (1968) norms. Behavior
Research Methods, Instruments, & Computers : A
Journal of the Psychonomic Society, Inc, 36(3), 371–
383. doi:10.3758/BF03195584
Conway, A. R., & Engle, R. W. (1996). Individual
differences in working memory capacity: more evidence
for a general capacity theory. Memory, 4(6), 577–590.
doi:10.1080/741940997
Ferreira, F., Apel, J., & Henderson, J. M. (2008). Taking a
new look at looking at nothing. Trends in Cognitive
Sciences, 12(11), 405–10.

2391

doi:10.1016/j.tics.2008.07.007
Fischer, M. H. (1999). Memory for word locations in
reading. Memory, 7(1), 79–116. doi:10.1080/741943718
Friendly, M., Franklin, P. E., Hoffman, D., & Rubin, D.
C. (1982). The Toronto Word Pool: Norms for imagery,
concreteness, orthographic variables, and grammatical
usage for 1,080 words. Behavior Research Methods &
Instrumentation, 14(4), 375–399.
doi:10.3758/BF03203275
Harm, M. W., & Seidenberg, M. S. (2004). Computing the
Meanings of Words in Reading: Cooperative Division of
Labor Between Visual and Phonological Processes.
Psychological Review, 111(3), 662–720.
doi:10.1037/0033-295X.111.3.662
Hoover, M. A., & Richardson, D. C. (2008). When facts
go down the rabbit hole: contrasting features and
objecthood as indexes to memory. Cognition, 108(2),
533–542. doi:10.1016/j.cognition.2008.02.011
Jackendoff, R. (1996). The architecture of the linguisticspatial interface. In P. Bloom, M. F. Garrett, L. Nadel,
& M. A. Peterson (Eds.), Language and space (pp. 1–
30). Cambridge, MA: The MIT Press.
Johansson, R., Holsanova, J., & Holmqvist, K. (2006).
Pictures and spoken descriptions elicit similar eye
movements during mental imagery, both in light and in
complete darkness. Cognitive Science, 30(6), 1053–
1079. doi:10.1207/s15516709cog0000_86
Johansson, R., & Johansson, M. (2014). Look here, eye
movements play a functional role in memory retrieval.
Psychological Science. doi:10.1177/0956797613498260
Keenan, T. R., & Benjafield, J. G. (1994). An additional
measure of availability derived from the Oxford English
Dictionary. Psychonomic Bulletin & Review, 1(2), 255–
257. doi:10.3758/BF03200777
Kučera, H., & Francis, W. N. (1967). Computational
Analysis of Present Day American English. Providence:
Brown University Press.
Li, P., Zhang, F., Tsai, E., & Puls, B. (2013). Language
history questionnaire (LHQ 2.0): A new dynamic webbased research tool. Bilingualism: Language and
Cognition, 17(03), 673–680.
doi:10.1017/S1366728913000606
Marr, D. (1982). Vision. San Francisco: W.H. Freeman.
Martarelli, C. S., & Mast, F. W. (2013). Eye movements
during long-term pictorial recall. Psychological
Research, 77(3), 303–309. doi:10.1007/s00426-0120439-7
Milner, B. (1969). Interhemispheric differences in the
localization of psychological processes in man. British
Medical Bulletin, 27, 272 – 277.
Mueller, S. T., & Piper, B. J. (2014). The Psychology
Experiment Building Language (PEBL) and PEBL Test
Battery. Journal of Neuroscience Methods, 222, 250–9.
doi:10.1016/j.jneumeth.2013.10.024
Oldfield, R. C. (1971). The assessment and analysis of
handedness: the Edinburgh inventory.
Neuropsychologia, 9, 97–113. doi:10.1016/00283932(71)90067-4
Pylyshyn, Z. (2001). Visual indexes, preconceptual
objects, and situated vision. Cognition, 80(1-2), 127–
158. doi:10.1016/S0010-0277(00)00156-6
R Core Team (2015). R: A language and environment for

statistical computing. Vienna, Austria: R Foundation for
Statistical Computing.
Richardson, D. C., Altmann, G. T. M., Spivey, M. J., &
Hoover, M. A. (2009). Much ado about eye movements
to nothing: a response to Ferreira et al.: taking a new
look at looking at nothing. Trends in Cognitive Sciences,
13(6), 235–6. doi:10.1016/j.tics.2009.02.006
Richardson, D. C., & Kirkham, N. Z. (2004). Multimodal
events and moving locations: eye movements of adults
and 6-month-olds reveal dynamic spatial indexing.
Journal of Experimental Psychology: General, 133(1),
46–62. doi:10.1037/0096-3445.133.1.46
Richardson, D. C., & Spivey, M. J. (2000).
Representation, space and Hollywood Squares: looking
at things that aren’t there anymore. Cognition, 76(3),
269–295. doi:10.1016/S0010-0277(00)00084-6
Rubin, D. C., & Friendly, M. (1986). Predicting which
words get recalled: measures of free recall, availability,
goodness, emotionality, and pronunciability for 925
nouns. Memory & Cognition, 14(I), 79–94.
doi:10.3758/BF03209231
Scholz, A., Mehlhorn, K., & Krems, J. F. (2011). Looking
at nothing diminishes with practice. In L. Carlson, C.
Hoelscher, & T. F. Shipley (Eds.), Proceedings of the
33rd Annual Conference of the Cognitive Science
Society (pp. 1070–1075). Austin, TX: Cognitive Science
Society.
Scholz, A., Mehlhorn, K., & Krems, J. F. (2014). Listen
up, eye movements play a role in verbal memory
retrieval. Psychological Research, 12(20), 1–10.
doi:10.1007/s00426-014-0639-4
Simon, J. R., & Rudell, A. P. (1967). Auditory S-R
compatibility: the effect of an irrelevant cue on
information processing. The Journal of Applied
Psychology, 51(3), 300–304. doi:10.1037/h0020586
Spivey, M. J., & Geng, J. J. (2000). Oculomotor
mechanisms activated by imagery and memory: eye
movements to absent objects. Psychological Research,
65(4), 235–241. doi:10.1007/s004260100059
Vankov, I. (2009). Mind the Gap: The Cost of Looking at
Nothing, or the Performance Implications of Memoryinduced Attention Shifts. In N. Taatgen & H. van Rijn
(Eds.), Proceedings of the 31th Annual Conference of
the Cognitive Science Society (pp. 1318–1323). Austin,
TX: Cognitive Science Society.
Wantz, A. L., Martarelli, C. S., & Mast, F. W. (2015).
When looking back to nothing goes back to nothing.
Cognitive Processing, 17(1), 105–114.
doi:10.1007/s10339-015-0741-6
Wühr, P., & Ansorge, U. (2007). A Simon effect in
memory retrieval: evidence for the responsediscrimination account. Psychonomic Bulletin &
Review, 14(5), 984–988. doi:10.3758/BF03194132

2392

