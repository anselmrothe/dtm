      Abstraction in time: Finding hierarchical linguistic structure in a model of
                                                 relational processing
                                     Leonidas A.A. Doumas (alex.doumas@ed.ac.uk)
                                       Andrea E. Martin (andrea.martin@ed.ac.uk)
                                                      Department of Psychology
                                    School of Philosophy, Psychology and Language Sciences
                                                       University of Edinburgh
                                     7 George Square, Edinburgh, EH8 9JZ, United Kingdom
                              Abstract                                     Ding et al. (2016) recently showed evidence of
                                                                      cortical tracking of abstract, hierarchical linguistic
    Abstract mental representation is fundamental for human           structures in oscillatory patterns in data from an
cognition. Forming such representations in time, especially           electrocorticography           (ECoG)          and         a
from dynamic and noisy perceptual input, is a challenge for
                                                                      magnetoencephalography (MEG) experiment. This
any processing modality, but perhaps none so acutely as for
language processing. We show that LISA (Hummel &
                                                                      tracking crucially could not be attributed to processing
Holyaok, 1997) and DORA (Doumas, Hummel, & Sandhofer,                 of acoustic information, transitional probability, or
2008), models built to process and to learn structured (i.e.,         word predictability (Ding et al., 2016). Strikingly, LISA
symbolic) representations of conceptual properties and                (Hummel & Holyoak, 1997, 2003), a symbolic-
relations from unstructured inputs, show oscillatory activation       connectionist model of analogy making, and DORA
during processing that is highly similar to the cortical activity     (Doumas, Hummel, & Sandhofer, 2008), a symbolic
elicited by the linguistic stimuli from Ding et al. (2016). We        connectionist model of relational reasoning, predict
argue, as Ding et al. (2016), that this activation reflects           such a representational pattern. We tested the
formation of hierarchical linguistic representation, and              hypothesis that the representational patterns produced
furthermore, that the kind of computational mechanisms in
LISA/DORA (e.g., temporal binding by systematic
                                                                      by LISA and DORA during their processing will give
asynchrony of firing) may underlie formation of abstract              rise to the hierarchical structures matching the linguistic
linguistic representations in the human brain. It may be this         structures observed by Ding et al. (2016) without any
repurposing that allowed for the generation or emergence of           formal or structural changes to the model. Such an
hierarchical linguistic structure, and therefore, human               approach would be particularly compelling because it
language, from extant cognitive and neural systems. We                shines a light both on how the brain might parse
conclude that models of thinking and reasoning and models of          language (i.e., the class of possible parsing mechanisms
language processing must be integrated—not only for                   underlying cortical tracking of linguistic representations
increased plausiblity, but in order to advance both fields
                                                                      as seen in Ding et al., 2016), and about how linguistic
towards a larger integrative model of human cognition.
                                                                      structures might have come to be the way there are. In
    Keywords: computational models, sentence processing,              order to test these predictions, we simulated oscillatory
analogy, relational reasoning, concepts, binding, temporal            unit data in LISA/DORA using the same sentence
asynchrony, oscillations, computational neuroscience                  stimuli as Ding et al. (2016). We tested whether
                                                                      LISA/DORA parsed the sentences correctly, and we
                         Introduction                                 observed the pattern of unit firing LISA/DORA
                                                                      exhibited while processing the sentences.
    Abstract hierarchical representations are the
hallmark of human language (Chomsky, 1957).
Forming such representations is certainly necessary
                                                                                     The LISA/DORA models
during language processing (see Martin, 2016 for a                         LISA (Hummel & Holyoak, 1997, 2003) is a model
possible process model). But what are the                             of analogy and relational reasoning. DORA (Doumas et
computational origins of such an ability? One                         al., 2008) is an extension of LISA that learns structured
possibility is that the brain repurposed a mechanism or               (i.e., symbolic) representations of relations from
process already at its disposal when abstraction become               unstructured (holistic flat feature vector) inputs. That is,
an efficient solution to a problem posed by the                       DORA provides an account of how the structured
environment, such as communicating information                        relational representations LISA uses to perform
across time and space, or predicating novel arguments                 relational reasoning are learned from examples. Both
that you have never encountered before.                               LISA and DORA are symbolic-connectionist models,
                                                                      or models based on traditional connectionist computing
                                                                  2279

principles that effectively implement symbolic                    LISA/DORA is attending to at a specific moment). The
representations as they solve the binding problem and             driver contains one (or at most three) proposition(s).
can, therefore, represent compositional structures (see           Activation flows from the driver units to their semantic
Doumas & Hummel, 2005, 2012).                                     units. Units in the driver and recipient are connected to
     DORA accounts for over 25 phenomena from the                 the same pool of semantic units. Thus, units in the
literature on relational learning, as well as its                 recipient become active in response to the pattern of
development (e.g., Doumas & Hummel, 2010; Doumas                  activation imposed on the semantic units by the active
et al., 2008; Lim et al., 2014; Morrison et al., 2012;            driver proposition. The flow of activation from driver to
Sandhofer & Doumas, 2008). In addition, as DORA                   recipient through shared semantic units is important for
learns relational representations, it comes to take LISA          many of LISA and DORA’s processes including
as a special case, and can simulate the additional 30-            comparison, analogical mapping, relation learning,
plus phenomena in relational thinking simulated by                schema induction, and memory retrieval. We will not
LISA. The description of LISA/DORA that follows is a              discuss these processes further as they are not important
brief overview due to space constraints. For full details         for the purposes of the current paper, but full details
of the models and their operations see Doumas et al.              may be found in Hummel & Holyoak, 1997, 2003) and
(2008) and Hummel and Holyoak (1997, 2003).                       Doumas et al. (2008).
LISAese Representations                  In     LISA     (and     Representing binding information              What       is
DORA after it has gone through learning) relational               most important about LISA/DORA for the purposes of
structures are represented by a hierarchy of distributed          the present paper is the manner in which the models
and localist codes (see Figure 1). At the bottom,                 solve the binding problem. As noted above, LISA and
“semantic” units represent the features of objects and            DORA are symbolic-connectionist models. That is, they
roles in a distributed fashion. At the next level, these          are based on traditional connectionist computing
distributed representations are connected to localist             principles (i.e., layers of interconnected nodes passing
units (POs) representing individual predicates (or roles)         activation via weighted connections that are modified
and objects. Localist role-binding units (RBs) link               via Hebbian learning), but unlike traditional
object and predicate units into role-filler binding pairs.        connectionist systems, they can process symbolic
At the top of the hierarchy, localist P units link RBs            structure.
into whole relational propositions.                                   Processing symbolic structure requires that
                                                                  representational elements in a system can be composed
                                                                  into meaningful structures in a manner that does not
                             chase (goblin,                       violate  the independence of those elements (see e.g.,
                                gnome)                                P units
                                                                  Markman, 1999; Russell & Norvig, 2003). For
                                                                  example, representing a relational proposition like
                chaser+goblin               chased+gnome              RB units
                                                                  chase    (goblin, gnome) requires representing that
                                                                  chasing, a goblin, and a gnome are all present, and that
                                                                  goblin is bound the chaser role and gnome to the
                                                                  chased role. Importantly, the binding of chaser to
             chr.        goblin          chd.         gnome           PO must
                                                                  goblin   units not change the fundamental meaning of
                                                                  either what it means to be a goblin or what it means to
                                                                  be a chaser—i.e., the binding system must not violate
                                                                  role-filler
                                                                      semanticindependence.
                                                                                  units
                                                                      In LISA and DORA roles and fillers are represented
         Figure 1. Representation of a LISA/DORA                  independently in the PO and semantic units. In order to
representation of the proposition chase (goblin, gnome).          behave symbolically, however, when a proposition in
  We use different shapes to represent units in different         the driver becomes active, role-filler bindings must be
     layers (ovals for P units, rectangles for RB units,          represented dynamically on these units (i.e., POs and
     triangles and large circles for PO units, and small          semantic units; see Hummel & Holyoak, 1997). Both
circles for semantic units) for the purposes of clarity. In       LISA and DORA use time to carry this dynamic
    the model these units are simply nodes in different           binding information.
                    layers of the network.                            Binding information is represented in LISA with
                                                                  bound role-filler pairs firing in synchrony. To illustrate,
     Propositions are divided into two mutually                   when a proposition like chase (goblin, gnome) becomes
exclusive sets: a driver and one or more recipients. In           active in the driver (Figure 2a), the units representing
LISA/DORA, the sequence of firing events is                       chaser and goblin become active and fire together
controlled by the driver. We take the driver to be the            (representing the binding between chaser and goblin;
focus of attention in LISA/DORA (i.e., what                       Figure 2a[i]). Subsequently, the units representing
                                                              2280

chased and gnome become active and fire together                                                              sequence.1 During asynchronous binding, when a
(representing the binding between chased and gnome;                                                           proposition like chase (goblin, gnome) becomes active
Figure 2a[ii]). Bound role-filler pairs fire together, and                                                    in the driver (Figure 2b), the units representing chaser
out of synchrony with other bound role-filler pairs.                                                          fire (along with units conjunctively coding for
These distinct firing bursts allow LISA to code bindings                                                      chaser+goblin and for the chase (goblin, gnome)
between roles and their fillers, and process these                                                            proposition; Figure 2b[i]), followed directly by the units
structures symbolically, forming the basis of LISA’s                                                          representing goblin (along with units conjunctively
capacity to solve analogical mappings, and perform                                                            coding for chaser+goblin and for the chase (goblin,
relational inference (see Hummel & Holyoak, 2003)                                                             gnome) proposition; Figure 2b[ii]), representing the
                                                       (a)                                                    binding of chaser to goblin. Then, the units
                                                                                                              representing chased fire (along with units conjunctively
                             (i)                                               (ii)                           coding for chased+gnome and for the chase (goblin,
                                                                                                              gnome) proposition; Figure2b[iii]), followed directly by
                       chase (goblin,                                      chase (goblin,
                           gnome)                                             gnome)
          chaser+goblin                chased+gnome           chaser+goblin               chased+gnome        the units representing gnome (along with units
                                                                                                              conjunctively coding for chased+gnome and for the
                                                                                                              chase (goblin, gnome) proposition; Figure 2b[iv]),
       chr.         goblin          chd.         gnome     chr.        goblin          chd.         gnome
                                                                                                              representing the binding of chased to gnome. In short,
                                                                                                              bound role-filler pairs fire in direct sequence, and out of
                                                                                                              synchrony with any other bound role-filler pairs. These
                                                       (b)                                                    patterns of sequential oscillation dynamically code role-
                             (i)                                               (ii)                           filler bindings in DORA, and underlie DORA’s
                        chase (goblin,
                           gnome)
                                                                           chase (goblin,
                                                                              gnome)
                                                                                                              capacity to use the representations that it learns to
           chaser+goblin               chased+gnome           chaser+goblin               chased+gnome
                                                                                                              support relational reasoning (e.g., analogical mapping,
                                                                                                              schema induction, and relational induction; see Doumas
        chr.        goblin          chd.         gnome     chr.        goblin          chd.         gnome
                                                                                                              et al., 2008) and to learn structured relational
                                                                                                              representations         from       unstructured      object
                                                                                                              representations.
                                                                                                                   Crucially, sequential firing of related constituent
                            (iii)                                              (iv)
                        chase (goblin,                                     chase (goblin,
                                                                                                              elements is a necessary property of binding via
                           gnome)                                             gnome)
                                                                                                              synchrony and systematic asynchrony. When
           chaser+goblin               chased+gnome           chaser+goblin               chased+gnome
                                                                                                              LISA/DORA perform any structured processing, a
        chr.        goblin          chd.         gnome     chr.        goblin          chd.         gnome
                                                                                                              pattern will invariably emerge wherein bound elements
                                                                                                              within a larger compositional proposition will fire in
                                                                                                              direct sequence and at a different time-scale than units
                                                                                                              coding for conjunctions of independently bound
     Figure 2. Dynamic binding in LISA and DORA. (a)                                                          elements and full propositional compounds. In the
 Binding in LISA. (i) To bind the role chaser to goblin,                                                      following section we show that the pattern produced by
   units coding for chaser and goblin (as well as those                                                       LISA/DORA as it processes compositional structures
  coding conjunctively for chaser+goblin) fire. (ii) To                                                       matches very closely the temporal pattern of spike
   bind chased to gnome, units coding for chased and                                                          activity observed in Ding et al.’s (2016) when people
    gnome (as well as those coding conjunctively for                                                          process compositional propositions.
  chased+gnome) fire. (b) Binding in DORA. (i-ii) To
 bind the chaser role to goblin, units coding for chaser                                                                                Simulation
         (as well as those coding conjunctively for                                                                Ding et al. (2016) presented auditory strings of
  chaser+goblin) fire, followed by the units coding for                                                       synthesized speech in Mandarin Chinese in an MEG
     goblin (as well as those coding conjunctively for                                                        experiment, and strings of synthesized speech in
    chaser+goblin). (iii-iv) To bind the chased role to                                                       American English in an ECoG experiment. They
gnome, units coding for chased (as well as those coding                                                       manipulated the structural relationship between the
 conjunctively for chased+gnome) fire, followed by the                                                        units in the auditory string, i.e., the syllables. In one
     units coding for gnome (as well as those coding                                                          condition, there was no meaningful relationship
                  conjunctively for chased+gnome).
                                                                                                              1
                                                                                                                 Asynchrony-based binding allows roles and fillers to be
    In DORA, binding information can be carried either                                                        coded by the same pool of semantic units, which allows
by synchrony (as in LISA) or by systematic asynchrony                                                         DORA to learn representations of relations from
of firing, with bound role-filler pairs firing in direct                                                      representations of objects (Doumas et al., 2008).
                                                                                                          2281

between the strings of syllables, in the second                 explicitly by the propositional structure dry(fur), which
condition, phrases were formed from adjacent syllables,         can then serve as the argument of the agent role of the
and in the third condition, sentences emerged from the          rubs relation (see Figure 3b; details of higher-order
string of syllables. Using this design, they observed           structure representation in LISA and DORA can be
peaks in the MEG-based oscillatory response on the              found in Hummel & Holyoak, 1997 and Doumas et al.,
timescale of syllabic rate (4Hz), phrasal rate (2Hz), and       2008). We have previously hypothesised that
sentential rate (1Hz). Importantly, for trials with             LISA/DORA can alternate between these types of
Mandarin sentences only speakers of Mandarin                    representation depending on the properties of the
(compared to English speakers in a control group)               current task (e.g., Doumas et al., 2008; Rabagliati et al.,
showed tracking of phrasal and sentential                       submitted). Specifically, when modifier information
representations in the form of peaks at 2Hz and 1Hz,            must be considered explicitly, the later type of
respectively, although both English and Mandarin                representation (as in Figure 3b) might be employed.
speakers showed tracking of speech/acoustic-syllabic            Alternately, when the modifier information can be
stimuli regardless of language comprehension. The               considered implicitly, the former type of representation
ECoG data from English speakers showed a similar                (as in Figure 3a) can be employed. For the purposes of
pattern to the Mandarin MEG data, but without direct            the current simulations both types of representations
one-to-one acoustic-syllabic-to-phrase correspondence.          would work, however we used the hierarchical
Importantly, Ding et al. also observed cortical activity        representations (i.e., Figure 3b) to code the sentences
coding for sentence structure when English speakers             following our assumption that participants coded the
tracked sentences of varying syllabic durations. For            modifier-noun structure explicitly.
example, when English speakers tracked sentences with               (a)
a noun phrase followed by a verb phrase wherein the                                            rubs(dry-fur,
initial noun phrase was three or four syllables (e.g., “the                                       skin)
gold lamp”, or “mahogany desk”), cortical activity                              rubber+dry-fur                rubbed+skin
tracked the entire phrasal structure, with a burst firing
for the duration of the phrasal unit. Ding et al.
                                                                                          dry-fur          rbd.           skin
controlled for effects of predictability in a string by                      rbr.
showing that tracking of phrasal and sentence forms is
not confounded by transitional probability.
    Ding et al.’s results suggest definite structural form
emerging during sentence processing. Specifically,
beyond processing information at the level of syllables               (b)
(or the basic features of a sentence tracked even by non-                                     rubs(dry(fur),
speakers of a language), speakers of a language process                                           skin)
information that appears to track phrase structure and                         rubber+dry(fur)                rubbed+skin
sentence structure. Moreover, when processing simple 2
argument verb structures, the structural pattern that
                                                                                                                               skin
emerges is two significant cortical response peaks                      rbr.               dry+fur                    rbd.
(seemingly capturing phrasal information) firing within
(at twice the rate) of a single cortical response peak
(seemingly capturing sentence information).                                           dry           fur
    We simulated the Ding et al. (2016) studies using
the same English sentences used in their experiments 5
and 6 (with native English speakers). All of these
sentences took the form modifier-noun-verb-noun,
forming sentences like, “new plans give hope”, and
“dry fur rubs skin”. LISA/DORA can represent                     Figure 3. Representations of the sentence “dry fur rubs
sentences of this type in two ways. Most simply, such             skin” in LISA/DORA. (a) A representation where the
sentences could be represented with the modified noun             dry-skin modified noun is represented as a single unit
represented as a single object containing both the               connected to the semantics of both dry and skin. (b) A
semantics of the object and the modifier (see Figure              higher-order representation of the sentence where the
3a). Alternately, LISA/DORA can represent                         modified noun is represented as a predicate structure,
hierarchical propositions by representing propositional          dry(skin) taken as an argument of the agent role of the
structures as arguments of other propositional                                                  rubs relation.
structures. For example, to represent “dry fur rubs skin”
the modified noun phrase “dry fur” can be represented
                                                            2282

    It is important to note that the DORA model can              binding information; see above). We tracked firing rate
learn all of the representations used in the current             of all the nodes in the driver as LISA/DORA processed
simulation from experience. As demonstrated                      the sentences. Because of the controlled length and
previously (e.g., Doumas & Hummel, 2010; Doumas et               structure of the sentences, DORA, like the participants
al., 2008; Hamer & Doumas, 2013; Lim et al., 2014;               in the Ding et al. experiments, took the same amount of
Sandhofer & Doumas, 2008), DORA can learn explicit               time to process each sentence. The results of the
structured (i.e., symbolic) representations of verb              simulation and the comparison to the patterns observed
structures like give, rubs, or chases, and of single-place       by Ding et al. are presented in Figure 4. Interestingly,
modifiers like dry, new, or golden from experience with          the pattern of firing of the nodes in the various layers of
objects in the world involved in those relations or with         LISA/DORA very closely mirror the patterns observed
those feature. For the present study we hand-coded               by Ding et al. Specifically, just like the human
these representations, as the process of learning was not        participants, DORA showed an activation burst in it’s P
the focus of the current simulations.                            units that lasted throughout the processing of the
    To simulate Ding et al.’s experimental procedure we          sentence (i.e., firing at the 1Hz range), activation bursts
allowed LISA/DORA to process Ding et al.’s English               at twice the rate of the whole sentence burst (i.e., the
sentences one at a time. Representations of the sentence         RB unit firing in the 2Hz range), and activation bursts
structures entered the driver (i.e., were attended to).          at 4 times the rate of the whole sentence burst (i.e., the
LISA/DORA processed the sentences as it normally                 PO units firing in the 4 Hz range).
would (i.e., the units fired to represent and encode
Figure 4. The solid line represents cortical power of participants listening to 4 word sentences played for 1 second in
Ding et al. (2016). High cortical firing is evident at the 1Hz (the duration of the sentence), 2Hz, and 4 Hz range. The
 dashed line depicts firing in LISA/DORA while processing the same sentences used in Ding et al. There is evidence
of units firing for the duration of the sentence, at intervals of half the length of the sentence, and at intervals lasting 1
                                           quarter of the length of the sentence.
                                                            2283

                                                                 generalization of shape information. Cognitive Science,
                       Conclusion                                34, 698-712.
  We have shown that abstract, hierarchical linguistic               Doumas, L.A.A., Hummel, J.E., & Sandhofer, C.M.
representation can be acquired, represented, and                 (2008). A theory of the discovery and predication of
processed by LISA/DORA, models that were built for               relational concepts. Psychological Review,115, 1-43.
                                                                     Hamer, A. J. & Doumas, L. A. A. (2013).
completely different purposes (analogy making in the
case of LISA and relation learning in the case of                Discovering quantification and number in a role-filler
DORA). Specifically, we have shown that the                      model. Proceedings of the Thirty-Fifth Annual
oscillatory activation patterns in LISA/DORA that arise          Conference of the Cognitive Science Society.
as a natural consequence of the models performing                    Holyoak, K. J. (2012). Analogy and relational
dynamic binding appear to very closely fit data from             reasoning. In K. J. Holyoak & R. G. Morrison (Eds.),
human cortical tracking of hierarchical linguistic units         The Oxford handbook of thinking and reasoning (pp.
(Ding et al., 2016).                                             234-259). New York: Oxford University Press.
  It is interesting that models built for completely                 Hummel, J. E., & Holyoak, K. J. (1997). Distributed
different purposes so successfully perform another task          representations of structure: A theory of analogical
without modification. It is notable that extant models of        access and mapping. Psychological Review, 104, 427-
sentence processing would likely not generalise so               466.
seamlessly to tasks such as analogical reasoning. Both               Hummel, J. E., & Holyoak, K. J. (2003). A
probabilistic grammar (e.g., Levy, 2008) and                     symbolic-connectionist theory of relational inference
connectionist approaches (see Joanisse & McClelland,             and generalization. Psychological Review, 110, 220-
2015 for a review) must either be given a set of explicit        264.
grammatical phrase structure rules, or must learn the                Joanisse, M. F., & McClelland, J. L. (2015).
statistical specifics of a particular syntactic structure or     Connectionist perspectives on language learning,
parsing problem, rendering them unable to generalize to          representation and processing. Wiley Interdisciplinary
problems that routinely violate statistical and featural         Reviews: Cognitive Science, 6(3), 235-247.
regularity like analogical reasoning (see, e.g., Holyoak,            Levy, R. (2008). Expectation-based syntactic
2012).                                                           comprehension. Cognition, 106(3), 1126-1177.
  We take our results to provide computational support               Lim, A., Doumas, L. A. A., & Sinnett, S. (2014).
                                                                 Supramodal Representations in Melodic Perception.
the general claim—see, e.g., Penn, Holyoak, and
Povinelli (2008)—that the ability to form and represent          Proceedings of the Thirty-Sixth Annual Conference of
relational roles may underlie a number of our uniquely           the Cognitive Science Society.
human cognitive capacities such as language. It is,                  Markman, A. E. (1999). Knowledge representation.
perhaps, telling that the very same mechanisms that are          Taylor & Francis: New York, NY.
necessary for processing relational structure and                    Martin, A. E. (2016). Language Processing as Cue
performing relational cognition seem to so closely               Integration: Grounding the Psychology of Language in
simulate language processing.                                    Perception and Neurophysiology. In press at Frontiers
  Given our results, we suggest that models of                   in Psychology: Language Sciences.
relational reasoning and language processing might                   Penn, D. C., Holyoak, K. J., & Povinelli, D. J.
fruitfully be integrated. Such an integrative approach           (2008). Darwin's mistake: Explaining the discontinuity
offers the possibility of producing powerful,                    between human and nonhuman minds. Brain and
neurophysiologically and cognitively plausible models            Behavioral Sciences, 31, 109-178.
that can perform well on multiple problems. We aim to                Russell, S. & Norvig, P. (2003). Artificial
further articulate the model by testing DORA on natural          Intelligence: A modern approach. Pearson.
speech input, varied syntactic structures, in rich                   Sandhofer, C. M. & Doumas, L. A. A. (2008).
discourse contexts, on multilingual input, and with              Order and presentation effects in learning categories.
different assumptions about existing knowledge                   Journal of Cognition and Development, 9, 194-221.
representations.
                         References
    Ding, N., Melloni, L., Zhang, H., Tian, X., &
Poeppel, D. (2016). Cortical tracking of hierarchical
linguistic structures in connected speech. Nature
neuroscience, 19(1), 158-164.
    Doumas, L. A. A. & Hummel, J. E. (2010). A
computational account of the development of the
                                                             2284

