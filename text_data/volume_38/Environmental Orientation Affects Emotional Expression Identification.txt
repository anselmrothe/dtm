            Environmental Orientation Affects Emotional Expression Identification
                                      Stephen J. Flusberg (stephen.flusberg@purchase.edu)
                                             Derek Shapiro (dshapiro723@gmail.com)
                                         Kevin B. Collister (kevin.b.collister@gmail.com)
                                           SUNY Purchase College, Department of Psychology
                                           735 Anderson Hill Road, Purchase, NY 10577, USA
                                            Paul H. Thibodeau (pthibode@oberlin.edu)
                                                Oberlin College, Department of Psychology
                                              101 N. Professor St., Oberlin, OH 44074, USA
                               Abstract                                   Casasanto & Dijkstra, 2010; Lynott & Coventry, 2013;
   Spatial metaphors for affective valence are common in                  Meier & Robinson, 2004).
   English, where up in space=happy/positive and down in                     In one study, participants were faster and more likely to
   space=sad/negative. Past research suggests that these                  retrieve positive memories while making concurrent motor
   metaphors have some measure of psychological reality:                  movements upwards, and faster and more likely to retrieve
   people are faster to respond to valenced words and faces
                                                                          negative memories while making concurrent motor
   when they are presented in metaphor-congruent regions of
   space. Here we explore whether the orientation of a stimulus           movements downwards (Casasanto & Dijkstra, 2010). In
   – rather than its position – is sufficient to elicit such spatial-     another experiment, Meier and Robinson (2004) found that
   valence congruency effects, and, if so, which spatial reference        participants were faster to identify positive words like hero
   frame(s) people use to represent this orientation. In                  when they appeared at the top of the screen than when they
   Experiment 1, participants viewed images of happy and sad              appeared at the bottom of the screen, while the reverse was
   profile faces in different orientations and had to identify the        true for negative words like liar. A follow-up study revealed
   emotion depicted in each face. In Experiment 2, participants
   completed this task while lying down on their sides, thereby           that simply attending to higher or lower regions of space
   disassociating environmental and egocentric reference frames.          facilitated the subsequent processing of valenced words
   Experiment 1 revealed a metaphor-congruent interaction                 presented centrally in a metaphor-congruent fashion. More
   between emotion and orientation, while Experiment 2                    recently, Lynott and Coventry (2013) extended these
   revealed that this spatial-valence congruency effect was only          findings by using non-linguistic stimuli: in their study,
   reliable in the environmental frame of reference.                      participants were faster to respond to happy faces that
   Keywords: spatial metaphor; valence, emotional expression              appeared at the top of the screen compared to sad faces that
   identification; spatial reference frames                               appeared at the top of the screen and happy faces that
                                                                          appeared at the bottom of the screen. Taken together, these
                           Introduction                                   findings provide compelling evidence for the cognitive
We often talk about abstract domains like time, emotion,                  reality of the spatial-valence metaphorical mapping.
consciousness, health, and social status using spatial                       The present work builds on these findings by testing
metaphors (Lakoff & Johnson, 1980). For example, we                       whether people are also sensitive to the orientation of
organize the concept of emotional valence around a vertical               valenced stimuli. That is, one way to test for spatial-valence
spatial dimension, where a higher spatial position connotes               congruency effects is to manipulate the position of stimuli
happiness and positivity while a lower spatial position                   in a display (or the direction of movement towards a
connotes sadness and negativity. Thus we say things like                  particular position) – the method used by other researchers
“She sank into a deep depression and is feeling quite low,                tackling this phenomenon. Another way of testing for
very down in the dumps; we need to give her a lift, raise her             spatial-valence congruency effects is to manipulate the
spirits, and boost her self-esteem until she’s flying high.”              orientation of a stimulus. In addition to presenting a face at
This particular mapping between space and valence may                     the top of a computer screen (position), “up” can be cued by
have its origins in everyday embodied experiences: sad                    presenting an upward gazing face (orientation).
feelings are associated with a drooping posture and                       Furthermore, spatial relations like upright and orientation
drowsiness, while happy feelings are associated with a more               must be defined with respect to a particular frame of
alert and erect bearing (though it’s rare to see people                   reference; objects that are upright with respect to a computer
literally jumping with joy).                                              screen (environmental frame of reference) would appear
   Interestingly, research has found that this association                upside-down to a person standing on their head (egocentric
between space and valence goes beyond language: people                    frame of reference). In other words, spatial relationships are
seem to automatically activate metaphor-congruent spatial                 multifaceted; a fuller consideration of this nuance can help
representations in the course of processing valenced stimuli              us understand how people use space to represent valence.
(and vice versa. e.g., Brookshire, Ivry, & Casasanto, 2010;                  Across two experiments, we investigated whether the
                                                                          orientation of a stimulus – rather than its position in space –
                                                                      2315

would be sufficient to elicit such spatial-valence congruency    using the same ovular template to highlight the face and
effects, and, if so, which spatial reference frame people use    keep each picture the same size.
to represent this orientation. In Experiment 1, participants        On every trial, a black fixation cross appeared at the
viewed images of happy and sad profile faces in different        center of the screen, which had a light gray background.
orientations and had to identify the emotion depicted in each    After 500 milliseconds, one of the face images appeared at
face. We expected a metaphor-congruency effect: that             the center of the display in one of five possible orientations
people would be faster (and more accurate) to respond to         (0º = upright; -90º, -45º = looking downwards; 45º, 90º =
upward gazing happy faces and downward gazing sad faces,         looking upwards; see Figure 1). All 40 face images
and slower (and less accurate) to respond to upward gazing       appeared in each of the 5 orientations, for a total of 200
sad faces and downward gazing happy faces. This finding          trials. Half of the faces were presented facing to the left, and
would provide additional evidence that representations of        half were presented facing to the right (counterbalanced);
valence are grounded in conceptions of space, and it would       the order of trials was fully randomized.
demonstrate that spatial-valence congruency effects are not         Participants were instructed to respond as quickly and as
limited to spatial located, but extend also to spatial           accurately as possible as soon as the face image appeared
orientation.                                                     during a trial, pressing one button on the keyboard if the
  In Experiment 2, participants completed this task while        face was “happy” and another button if the face was “sad.”
lying on their right sides, thereby disassociating               Participants used the “f” and “j” keys to respond
environmental and egocentric reference frames. In a              (counterbalanced across participants).
majority of everyday experiences, environmental and                 Participants were also randomly assigned to one of two
egocentric reference frames are highly correlated – most of      stimulus duration conditions. In the Unmasked condition
the time we see faces that are upright in the world              (N=40), the face image remained on the screen until
(environmental reference frame) while we sit or stand in an      participants pressed a response key. In the Masked condition
upright position (egocentric reference frame). This study        (N=41), the face image remained on the screen for 100
design allowed us to investigate whether the representation      milliseconds and was then replaced by a scrambled version
of valence is more strongly tied to the reference frame of the   of one of the images, created in Photoshop. This
world (environmental) or the individual (egocentric).            manipulation was included to test whether the effects of
  Given the importance of egocentric reference frames in         metaphorical spatial congruence on emotional expression
face perception (e.g., Rossion, 2008; Troje, 2003), one          identification emerge early in visual processing (i.e., within
possibility is that the spatial-valence mapping will be          the first 100 milliseconds).
defined with respect to the orientation of the participant. On      Before the main experimental task, participants completed
the other hand, our experience with faces in the world,          8 practice trials consisting of upright, front view, cartoon
which are normally upright (even if we are tilted or on our      faces (two sad faces and two happy faces, each presented
side), may tie the spatial-valence mapping to an                 twice) to acclimate them to the task.
environmental frame of reference. Indeed, some metaphors
in English seem to reference the environmental frame
                                                                    Unmasked
specifically, as when we say, “things are looking up.”
Identifying the reference frame(s) in which the spatial-
valence mapping is defined can help us understand how
                                                                                            +
                                                                    Condition
these representations are learned and when they influence                        500 msec
our behavior (Davidenko & Flusberg, 2012).
                      Experiment 1                                                                    Happy or sad?
Methods
Participants We recruited 81 participants (59 female) from
the Introduction to Psychology Participant Pool at SUNY
Purchase College. The average age was 19 (SD=1.2), and               Masked             +
participants received course credit for their participation.                     500 msec
Materials & Procedure The experiment was created using              Condition                   100 msec
PsychoPy software (Pierce, 2007) and was administered on
a 21.5” iMac desktop computer. Face stimuli were drawn                                                      Happy or sad?
from the Karolinska Directed Emotional Faces Database
(KDEF; Lundqvist, Flykt, & Öhman, 1998). We selected 40
                                                                 Figure 1. Schematic diagram of trial structure for both
profile faces from the database for use in the study: 10 male
                                                                 stimulus duration conditions in Experiment 1.
faces and 10 female faces each expressing both happiness
and sadness. The images were cropped in Adobe Photoshop
                                                             2316

Results                                                                                 conducted another 2 (emotion) X 5 (orientation) repeated-
Response times faster than 200 milliseconds and slower                                  measures ANOVA with condition as a between-subjects
than five standard deviations above the overall mean RT                                 factor. Consistent with the analysis of RTs, we found that
were removed from analysis (<1% of all trials). Accuracy                                people made more errors on trials that presented downward
was very good overall (M=93.7%, SD=4.3).                                                gazing happy faces than trials that presented downward
   Our initial analysis included only trials where participants                         gazing sad faces, and vice versa for upward gazing faces,
correctly identified the emotional facial expression. Using                             F(4, 316)=4.84, p<0.001, η2=.056. Planned contrasts
reaction time as our dependent variable, we ran a 2                                     revealed that participants made more errors in recognizing
(emotion: happy vs. sad) X 5 (orientation: -90º, -45, 0º, 45º,                          happy faces oriented at -90º, t[80]= 5.23, p<.001, -45º,
90º) repeated measures ANOVA with stimulus duration                                     t[80]=3.28, p=.002, 0º, t[80]=4.35, p<.001, and 45º,
condition included as a between-subjects factor. Of                                     t[80]=2.94, p=.004; there were no differences in error rates
particular relevance to our theoretical question was a                                  by emotional expression 90º, t[80]=0.05, p=.958.
predicted metaphor-congruent interaction between the                                       The model also revealed differences between the Masked
emotion and orientation of the face, which was statistically                            and Unmasked conditions. Not surprisingly, participants in
significant, F(4, 316)=5.74, p<0.001, η2=.0681 (see Figure                              the Unmasked condition (mean accuracy=96.4%, SD=2.39)
2). Planned contrasts revealed that participants were faster                            made fewer errors than those in the Masked condition (mean
to recognize happy faces oriented at 45º, t[80]= 2.28,                                  accuracy=91%, SD=4.13), F(1, 79)=47.76, p<0.001,
p=.025, and 90º, t[80]=3.07, p=.003. There were no                                      η2=.379. Since the performance of participants in the
differences in recognition time by emotional expression at                              Unmasked condition was close to ceiling, the interaction
other orientations (-90º, -45º, 0º), ts < 1, ps > .3.                                   between emotion and orientation was only present for
   In addition to the predicted interaction, the model                                  participants in the Masked condition (i.e., the 2-way
revealed a main effect of orientation, F(4, 316)=36.88,                                 interaction between emotion and orientation was qualified
p<0.001, η2 = .317, consistent with prior work on the effects                           by a 3-way interaction between emotion, orientation, and
of orientation on face perception (e.g., Davidenko &                                    condition, F(4, 316)=3.89, p<0.005, η2=.0452).
Flusberg, 2012): participants were fastest to respond to                                   In addition, this model revealed that people made more
upright faces (0º) and were progressively slower to respond                             errors for happy face trials (M=92.4% accuracy, SD=5.64)
as the faces were rotated away from upright. No other main                              than for sad face trials (M=95.2% accuracy, SD=4.59)3, F(1,
effects or interactions were statistically significant, ps > .1.                        79)=20.1, p<0.001, η2=.201, and more errors as the faces
                                                                                        were rotated away from upright, F(4, 316)=13.6, p<0.001,
                                                                                        η2=.136. As shown in Figure 3, the effect of orientation was
                                 0.84          Happy Faces                              only apparent for those in the Masked condition, F(4,
                                 0.82
                                               Sad Faces                                316)=10.66, p<0.001, η2=.104. See Figure 3.
       Reaction Time (seconds)
                                 0.80
                                                                                                                                 Masked Condition                 Unmasked Condition
                                 0.78                                                                               4.0
                                                                                                                                                                                 Happy Faces
                                                                                                                    3.5
                                 0.76                                                                                                                                            Sad Faces
                                                                                            Mean Number of Errors
                                                                                                                    3.0
                                 0.74
                                                                                                                    2.5
                                 0.72                                                                               2.0
                                 0.70                                                                               1.5
                                                                                                                    1.0
                                        -90º       -45º        -0º       45º   90º
                                                                                                                    0.5
                                                                                                                    0.0
                                                                                                                          -90º    -45º   -0º   45º     90º -90º     -45º   -0º   45º     90º
                                                           Orientation
Figure 2. Mean reaction times for happy and sad faces for                                                                                            Orientation
each stimulus orientation in Experiment 1, collapsed across                             Figure 3. Mean number of errors for happy and sad faces
stimulus duration condition. Error bars represent 95% CIs                               for each stimulus orientation in each condition in
                                                                                        Experiment 1. Error bars represent 95% CIs
 An analysis of error trials revealed a similar pattern.
Using error frequency as the dependent variable, we                                                                 2
                                                                                             Results of planned contrasts do not change when focusing
                                                                                        exclusively on data from the Masked condition: ts > 2.5, ps < .016
                                                                                        for orientations < 90º; t = .62, p = .539 at 90º.
  1                                                                                        3
     Though Mauchly’s test indicated that the assumption of                                  This may reflect a slight response bias in our sample to
sphericity was violated in this and several of the following                            perceive sadness in others (or negativity more generally), or it may
analyses, the F and p-values remain nearly identical under both                         signal that our stimuli were not equally discriminable based on
Greenhouse-Geisser and Huynh-Feldt corrections in all cases.                            emotion.
                                                                                     2317

Discussion                                                        (as compared to environmentally inverted), though effects in
In Experiment 1, we asked whether the orientation of a face       the environmental reference frame were reliably smaller. In
(i.e. where the face is looking, as opposed to its position in    Experiment 2, participants completed the same task as in
space) would be sufficient to elicit spatial-valence              Experiment 1 while lying down on one side.
congruency effects on performance in an emotional
expression identification task. The answer was a clear yes:                                Experiment 2
participants were faster and more accurate to identify            Methods
emotional expressions when the faces were oriented towards        Participants We recruited 85 participants (59 female) from
metaphor-congruent regions of space. This was true whether        the Introduction to Psychology Participant Pool at SUNY
the stimuli were masked after 100 milliseconds or remained        Purchase. The average age was 19.2 (SD=2.63) and
visible until response, suggesting that metaphorical spatial      participants received course credit for their participation.
representations of valence are activated quickly and
automatically when people view emotional stimuli (and vice        Materials & Procedure The experiment was similar in
versa; cf., Brookshire, Ivry, & Casasanto, 2010).                 design to Experiment 1, with a few key differences:
   Interestingly, these effects seemed to be driven largely by       Instead of sitting on a stool at a computer workstation,
a decrease in performance for sad faces facing upwards:           participants began the experiment by sitting upright on a
while RTs and error rates (in the Masked condition) for           futon positioned at the back of the lab room. The computer
happy faces increased symmetrically as the images were            running the experimental software was positioned on a low
rotated upwards and downwards away from upright, RTs              table in front of the futon. Participants first completed the
and error rates for sad faces dramatically increased on           same 8 practice trials featuring front-view cartoon faces that
upward rotations (i.e., metaphor-incongruent orientations).       participants completed in Experiment 1. The only difference
This is somewhat surprising, as the only other published          was that they used only their left hand to make the speeded
work on spatial-valence congruency effects that used happy        response, using the “1” and “2” keys on the keyboard
and sad face stimuli found a response time advantage for          (counterbalanced across participants). After the practice
happy faces positioned in metaphor-congruent regions of           trials, participants were instructed to lay down on their right
space (i.e., the top of the display), rather than a metaphor-     side with their head resting horizontally on a flat pillow
incongruent decrease in performance for sad faces (Lynott         facing the computer screen.
& Coventry, 2013). These researchers interpreted these               For Experiment 2 we used eight out of the ten male and
findings as evidence for a “polarity” account of spatial-         eight out of the ten female profile faces that we had used in
valence congruency effects, which is an issue we return to in     Experiment 1, each one again appearing with both a happy
the general discussion (cf., Dolscheid & Casasanto, 2015).        and sad expression4. On any given trial, one of the 32
   The results of Experiment 1 cannot address one key             individual profile images (8 males, 8 females, 2 expressions
question: which way is up? Spatial relations like up, down,       each) appeared in one of 8 possible orientations (see Table 1
and orientation must be defined with respect to a particular      and Figure 4). Participants saw each of the 32 faces in each
frame of reference. When participants are seated at a             of the 8 possible orientations, for a total of 256 trials, the
computer in a typical lab study like Experiment 1, several        order of which was randomized across participants.
spatial reference frames are conflated: faces that are
oriented upwards with respect to the computer screen, the         Table 1. Stimulus orientations in Experiment 2
room itself, and the directional pull of gravity
(environmental frames) are also orientated upwards with                                 Egocentric             Environmental
respect to the participant (egocentric reference frames). This                         Orientation               Orientation
makes it impossible to determine which reference frame(s)                 1               upright                    90º
participants are using to represent the orientation of the                2           upside-down                    90º
faces (and thus which reference frame is driving the                      3               upright                   -90º
observed spatial-valence congruency effects).                             4           upside-down                   -90º
   Fortunately, there is a simple method for disassociating               5                 90º                   upright
environmental and egocentric reference frames: tilt your                  6                 90º                 upside-down
head 90º to one side. Now faces that appeared to be gazing                7                -90º                   upright
upwards in the environment will appear to be upright or                   8                -90º                 upside-down
upside-down in your egocentric frame of reference
(depending on which way you tilt your head). Interestingly,
prior research has shown that people process faces                   4
                                                                       This was to keep the experiment short enough to complete in a
independently in both the environmental and egocentric            reasonable time frame, since each face appeared 8 times in
reference frames: Davidenko & Flusberg (2012) found that          Experiment 2 compared to 5 times in Experiment 1. The 4 faces
people were better at classifying and remembering images          we eliminated for Experiment 2 were chosen based on pilot subject
of faces that were egocentrically upright (as compared to         ratings (1-10 scale) of how happy and sad the expressions looked.
egocentrically inverted) as well as environmentally upright       We selected the two male and two female faces that scored lowest
                                                                  on these ratings.
                                                              2318

                                                                       upwards and downwards in this environment, t[80]=.36,
   Note that when participants lay on their right side to view         p=.719 (see Figure 4).
these images, faces that were oriented upwards or                         Egocentric Frame We repeated this analysis for trials
downwards in one frame of reference (i.e., rotated 90º or -            where the faces were oriented upwards or downwards in the
90º in that frame) were always either perfectly upright or             egocentric frame of reference. There were no main effects
perfectly upside-down in the other frame of reference5. This           of emotion or orientation, nor was there an interaction
decoupling of the environmental and egocentric reference               between the two (all F’s < 0.2, all p’s > 0.7; see Figure 4).
frames allowed us to investigate independent spatial-valence                In both the environmental, F(1, 80)=27.93, p<.001,
congruency effects in both frames of reference.                        η2=.259, and egocentric, F(1, 80)=6.53, p=.013, η2=.075,
                                                                       frames of reference, analyses of error rates revealed a main
Results & Discussion                                                   effect of emotional expression: in both frames of reference
The data from four participants were removed from analysis             people were more accurate recognizing happy faces.
because the computer crashed mid-session (N=1), the
participant was under 18 and could not give legal consent to                                          0.94
                                                                                                               Environmental FoR
                                                                                                                                        0.94
                                                                                                                                                                  Egocentric FoR
participate (N=26), or the participant’s error rate was
                                                                            Reaction Time (seconds)
                                                                                                                    Happy Faces                                            0.84          Happy Faces
extremely high, representing a clear outlier (32% errors;                                             0.92          Sad Faces           0.92                               0.82
                                                                                                                                                                                         Sad Faces
                                                                                                                                                 Reaction Time (seconds)
N=1). Accuracy for the remaining 81 participants was quite                                            0.90                              0.90
                                                                                                                                                                           0.80
good (M=96%, SD=3.14). Response times less than 200                                                   0.88                              0.88
                                                                                                                                                                           0.78
milliseconds and greater than five standard deviations above                                                                                                               0.76
the overall mean RT across all participants and trials were                                           0.86                              0.86                               0.74
removed from analysis (<1% of all trials).                                                            0.84                              0.84
                                                                                                                                                                           0.72
                                                                                                                                               -90º                                                 90º
  Past research suggests that there are independent effects                                                  -90º                 90º                                      0.70
of spatial orientation on face perception in the                                                                                                                                  -90º       -45º         -0º      45º   90º
environmental and egocentric reference frames (Davidenko
& Flusberg, 2012). Therefore, we analyzed the trial data                                                                                                                                             Orientation
separately for each frame, including only those trials where
participants correctly identified the emotional facial
expression.
  Environmental Frame We first conducted a 2 (emotion:
happy vs. sad) X 2 (orientation: -90º in the environment vs.           Figure 4. Mean RTs for happy and sad faces for each
90º in the environment) repeated measures ANOVA with                   stimulus orientation and each frame of reference
mean RT as the dependent variable. There was no main                   (environmental on the left) in Experiment 2. Error bars
effect of emotion, as participants had similar reaction times          represent 95% CIs.
to happy and sad faces, F(1, 80)=0.75, p=0.39. There was a
marginal effect of orientation, as participants were slightly                                                           General Discussion
slower to respond to faces looking upwards in the                      Spatial metaphors for affective valence are common in
environment (90º) compared to faces looking downwards in               English, where up in space connotes happy or positive
the environment (-90º), F(1, 80)=3.29, p=0.074. Crucially,             feelings (“things are looking up!”) and down in space
there was a significant metaphor-congruent interaction                 connotes sad or negative feelings (“I’m down in the
between emotion and orientation, F(1,80)=4.48, p=0.038,                dumps”). Past research suggests that this association is not
η2=.053: participants were marginally slower to respond to             merely a matter of language; rather, it offers a window into
sad faces gazing upwards compared to happy faces gazing                how people (metaphorically) represent the concept of
upwards, t[80]=1.82, p=.073, and to sad faces facing                   emotional valence. For example, people are faster to
downwards, t[80]=2.94, p=.004, in the environment; there               respond to positive and negative words and faces when they
was no difference in recognition time for downward facing              are presented in metaphor-congruent regions of space
faces by emotional expression, t[80]=.14, p=.887;                      (Lynott & Coventry, 2013; Meier & Robinson, 2004). In the
participants responded similarly fast to happy faces facing            present study, we explored whether the orientation of a
                                                                       stimulus – rather than its position in space – is sufficient to
  5                                                                    elicit such spatial-valence congruency effects, and, if so,
     As it turns out, when people tilt their head to one side, their
eyes rotate several degrees in the opposite direction, a phenomenon
                                                                       which spatial reference frame people use to represent this
known as Ocular Counter-Roll (OCR). At 90º rotation, this effect       orientation.
is very small (roughly 4º), and it does not appear to explain the         In Experiment 1, participants viewed images of happy and
effects of environmental orientation on face processing (see           sad profile faces in different orientations and had to identify
Davidenko & Flusberg, 2012). Because we observe an interaction         the emotion depicted in each face. Results revealed a
between emotion and orientation in our data, OCR cannot account        significant    spatial-valence     congruency     effect    on
for our findings, since it should equally affect all faces.            performance: participants were faster and more accurate to
   6
     A valuable legal and ethical lesson for undergraduate research    respond when faces were oriented towards metaphor-
assistants!
                                                                   2319

congruent regions of space. In Experiment 2, participants             That being said, there is one way to interpret the present
completed the same task while lying down on their side,            findings that would actually support the polarity account: if
thereby disassociating environmental and egocentric                people are generally much worse at perceiving upward than
reference frames. Results indicated that this spatial-valence      downward gazing faces, then in fact it would be the case
congruency effect was only reliable in the environmental           that we are seeing a processing advantage for happy faces
frame of reference, suggesting that (metaphorical)                 looking upwards. However, based on other research on
representations of the spatial dimension of emotional              orientation effects in face processing and other
valence are constructed with respect to the environment.           (unpublished) findings from our lab, we do not think this is
   Of course, multiple environmental reference frames were         the most parsimonious explanation of the current findings.
conflated in the present study design (e.g., faces that were       Still, more work may be required to fully rule out this
environmentally upright were upright with respect to the           possibility, and to fully explain why different performance
computer display, the lab room, and the directional pull of        asymmetries emerge in studies of spatial-valence
gravity), so future work is required to tease apart which          congruency.
one(s) people are using to structure affective valence.
Nonetheless, the present findings are notable in part because                              References
other research has found that effects of spatial orientation on    Brookshire, G., Ivry, R., & Casasanto, D. (2010).
face perception and memory are typically larger in the                Modulation of motor-meaning congruity effects for
egocentric frame (e.g., Davidenko & Flusberg, 2012; Troje,            valenced words. In S. Ohlsson & R. Catrambone (Eds.),
2003).                                                                Proceedings of the 32nd Annual Conference of the
   Also of note, in both experiments the spatial-valence              Cognitive Science Society (pp. 1940-1945). Austin, TX:
congruency effects appeared to be driven by a decrease in
                                                                      Cognitive Science Society.
performance for sad faces looking upwards in the
                                                                   Casasanto, D., Dijkstra, K. (2010). Motor action and
environment. As mentioned in the discussion of Experiment
                                                                      emotional memory. Cognition, 115, 179 – 185.
1, this result is somewhat surprising, as other researchers
                                                                   Davidenko, N. & Flusberg, S. J. (2012). Environmental
have observed similar congruency effects driven by a                  inversion effects in face perception. Cognition, 123(3),
relative increase in performance for happy faces and                  442-447.
positively valenced words that appear in higher regions of         Dolscheid, S., & Casasanto, D. (2015). Spatial congruity
space (Lakens, 2012; Lynott & Coventry, 2013). One                    effects reveal metaphorical thinking, not polarity
possibility is that differences in stimuli may account for
                                                                      correspondence. Frontiers in Psychology, 6(1836), 1-11.
these disparate findings: It may be that people simply
                                                                      doi: 10.3389/fpsyg.2015.01836
respond to profile faces differently than they do to front
                                                                   Lakens, D. (2012). Polarity correspondence in metaphor
view faces and common English words, perhaps due to the
                                                                      congruency effects: Structural overlap predicts
fact that judging emotions based on profile views is not a
                                                                      categorization times for bipolar concepts presented in
common activity.
                                                                      vertical space. Journal of Experimental Psychology:
   No matter the explanation, these data may pose a
                                                                      Learning, Memory, and Cognition, 38, 726–736
challenge to some theories that have been put forth to             Lakoff, G., & Johnson, M. (1980). Metaphors We Live By.
explain spatial-valence congruency effects. In particular, the
                                                                      Chicago and London: University of Chicago Press.
“polarity-based” perspective suggests that stimulus
                                                                   Lundqvist, D., Flykt, A., & Öhman, A. (1998). The
dimensions (including space and valence) are always
                                                                      Karolinska Directed Emotional Faces - KDEF, CD ROM
anchored at a default endpoint (+pole) that is typically more
                                                                      from Department of Clinical Neuroscience, Psychology
frequent and unmarked linguistically (Lakens, 2012; Lynott
                                                                      section, Karolinska Institutet, ISBN 91-630-7164-9.
& Coventry, 2013). In the case of valence, for example,
                                                                   Lynott, D., & Coventry, K. (2013). On the ups and downs of
“happy” is the default +pole (you can negate the unmarked
                                                                      emotion: testing between conceptual-metaphor and
term happy – unhappy – but not the term sad; unsad is not
                                                                      polarity accounts of emotional valence–spatial location
an English word). The polarity account attributes spatial-
                                                                      interactions. Psychonomic Bulletin & Review, 21; 218-
valence congruency effects to a generic processing
                                                                      226.
advantage for +polar items, and since up is another example
                                                                   Meier, B.P., Robinson, M.D. (2004). Why the sunny side is
of a +polar endpoint, this means that people should be
                                                                      up, associations between affect and vertical position.
fastest to respond to happy stimuli in higher regions of
                                                                      Psychological Science, 15, 243 – 247.
space (but see Dolscheid & Casasanto, 2015, for evidence
                                                                   Peirce, J.W. (2007) PsychoPy - Psychophysics software in
against a universal polarity correspondence account of
                                                                      Python. Journal of Neuroscience Methods, 162(1-2):8-13.
metaphor-congruency effects). In the present study,
                                                                   Rossion, B. (2008). Picture-plane inversion leads to
however, we do not observe this sort of processing
                                                                      qualitative changes of face perception. Acta Psychologia,
advantage, but rather a processing cost for sad faces
                                                                      128(2), 274–289.
oriented towards the metaphor-incongruent upper-regions of
                                                                   Troje, N. F. (2003). Reference frames for orientation
the environment.
                                                                      anisotropies in face recognition and biological-motion
                                                                      perception. Perception, 32(2), 201–210.
                                                               2320

