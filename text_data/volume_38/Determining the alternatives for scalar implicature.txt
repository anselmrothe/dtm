                             Determining the alternatives for scalar implicature
                              Benjamin Peloquin                                           Michael C. Frank
                            bpeloqui@stanford.edu                                      mcfrank@stanford.edu
                            Department of Psychology                                   Department of Psychology
                                Stanford University                                        Stanford University
                               Abstract                                   scalar implicature. For example, Degen & Tanenhaus (2015)
                                                                          demonstrated that the scalar item some was judged less appro-
   Successful communication regularly requires listeners to make
   pragmatic inferences — enrichments beyond the literal mean-            priate when exact numbers were seen as viable alternatives.
   ing of a speaker’s utterance. For example, when interpreting           And in a different paradigm, van Tiel (2014) found converg-
   a sentence such as “Alice ate some of the cookies,” listeners          ing evidence that some was judged to be atypical for small
   routinely infer that Alice did not eat all of them. A Gricean
   account of this phenomenon assumes the presence of alterna-            quantities. These data provide indirect evidence that people
   tives (like “all of the cookies”) with varying degrees of infor-       may actually consider a broader set of alternatives when com-
   mativity, but it remains an open question precisely what these         puting scalar implicatures. Since some is logically true of sets
   alternatives are. To address this question, we collect empirical
   measurements of speaker and listener judgments about vary-             with one or two members, these authors argued that the pres-
   ing sets of alternatives across a range of scales and use these as     ence of salient alternatives (the words one and two, for exam-
   inputs to a computational model of pragmatic inference. This           ple) reduced the felicity of some via a pragmatic inference.
   approach allows us to test hypotheses about how well differ-
   ent sets of alternatives predict pragmatic judgments by peo-              By formalizing pragmatic reasoning, computational mod-
   ple. Our findings suggest that comprehenders likely consider           els can help provide more direct evidence about the role that
   a broader set of alternatives beyond those logically entailed by       alternatives play. The “rational speech act” model (RSA)
   the initial message.
                                                                          is one recent framework for understanding inferences about
   Keywords: pragmatics; scalar implicature; bayesian modeling            meaning in context (Frank & Goodman, 2012; Goodman &
                                                                          Stuhlmuller, 2013). RSA models frame language understand-
                           Introduction                                   ing as a special case of social cognition, in which listeners and
How much of what we mean comes from the words that go                     speakers reason recursively about one another’s goals. In the
unsaid? As listeners, our ability to make precise inferences              case of scalar implicature, a listener makes a probabilistic in-
about a speaker’s intended meaning in context is indispens-               ference about what the speaker’s most likely communicative
able to successful communication. For example, listeners                  goal was, given that she picked the quantifier some rather than
commonly enrich the meaning of the word some to some                      the stronger quantifier all. In turn, the speaker reasons about
but not all in sentences like “Alice ate some of the cook-                what message would best convey her intended meaning to the
ies” (Grice, 1975; Levinson, 2000). These inferences, called              listener, given that he is reasoning in this way. This recursion
scalar implicatures, have been an important test case for un-             is grounded in a “literal” listener who reasons only according
derstanding pragmatic inferences more generally. A Gricean                to the basic truth-functional semantics of the language.
account of this phenomenon assumes listeners reason about                    Franke (2014) used an RSA-style model to assess what
a speaker’s intended meaning by incorporating knowledge                   alternatives a speaker would need to consider in order to
about A) alternative scalar items a speaker could have used               produce the typicality/felicity ratings reported by Degen &
(such as all) and B) the relative informativity of using such             Tanenhaus (2015) and van Tiel (2014) for the scale some/all.
alternatives (Grice, 1975). According to this account, a lis-             In order to do this, Franke (2014)’s model assigned weights
tener will infer that the speaker intended to convey that Alice           to a set of alternative numerical expressions. Surprisingly,
did not eat all the cookies because it would have been under-             along with weighting one highly (a conclusion that was sup-
informative to use the descriptor some when the alternative               ported by the empirical work), the best-fitting model assigned
all could have been used just as easily.                                  substantial weight to none as an alternative to some. This
   But what are the alternatives that should be considered in             finding was especially surprising considering the emphasis of
the implicature computation more generally? Under classic                 standard theories on scalar items that stand in entailment re-
accounts, listeners consider only those words whose mean-                 lationships with one another (e.g. one entails some even if it
ings entail the actual message (Horn, 1972), and these alter-             is not classically considered to be part of the scale).
natives enter into conventionalized or semi-conventionalized                 We pick up where these previous studies left off, consid-
scales (Levinson, 2000). For example, because all entails                 ering the set of alternatives for implicature using the RSA
some, and hence is a “stronger” meaning, all should be con-               model. To gain empirical traction on this issue, we broaden
sidered as an alternative to some in implicatures. Similar                the set of scales we consider. Our inspiration for this move
scales exist for non-quantifier scales, e.g. loved entails liked          comes from work by van Tiel, Van Miltenburg, Zevakhina,
(hence “I liked the movie” implicates that I didn’t love it).             & Geurts (2014), who examined a phenomenon that they
   Recent empirical evidence has called into question whether             dubbed “scalar diversity,” namely the substantial difference
entailment scales are all that is necessary for understanding             in the strength of scalar implicature across a variety of scalar
                                                                      319

pairs (e.g., liked / loved, palatable / delicious). Making use of
this diversity allows us to investigate the ways that different
alternative sets give rise to implicatures of different strengths
across scales.
   In our current work, we use a computational framework to
investigate the set of alternatives that best allow the model to
predict human pragmatic judgments across a series of differ-
ent scales. We begin by presenting the computational frame-
work (RSA) we use throughout the paper. We next describe
a series of experiments designed to measure both the lit-
eral semantics of a set of scalar items (used as input to the
model) and comprehenders’ pragmatic judgments for these
same items (used for model comparison). These experiments
allow us to compare the effects of different alternative sets on
our ability to model listeners’ pragmatic judgments. To pre-
view our results: we find that standard entailment alternatives
do not allow us to fit participants’ judgments, but that expand-      Figure 1: Alternative sets used in Experiments 2 and 3 (gen-
ing the range of alternatives empirically (by asking partici-         erated in Experiment 1). Green coloring denotes classic en-
pants to generate alternative messages) allows us to predict          tailment items pulled from van Tiel et al. (2014), used in the
listeners’ pragmatic judgments with high accuracy.                    two alternatives condition. Blue coloring denotes top-two al-
                                                                      ternatives added to entailment scales in the four alternatives
           Modeling Implicature Using RSA                             condition. Red coloring denotes “neutral” items added in the
We begin by giving a brief presentation of the basic RSA              five alternatives condition.
model. This model simulates the judgments of a pragmatic
listener who wants to infer a speaker’s intended meaning m               This model of the pragmatic speaker (denoted S1 ) is con-
from her utterance u. For simplicity, we present a version            sistent with a speaker who chooses words to maximize the
of this model in which there is only one full recursion: The          utility of an utterance in context (Frank & Goodman, 2012),
pragmatic listener reasons about a pragmatic speaker, who in          where utility is operationalized as the informativity of a par-
turn reasons about a “literal listener.” We assume throughout         ticular utterance (surprisal) minus a cost:
that this computation takes place in a signaling game (Lewis,
1969) with a fixed set of possible meanings m ∈ M and a fixed                        pS1 (u | m) ∝ e−α[−log(pL0 (m|u))−C(u)]         (3)
possible set of utterances u ∈ U, with both known to both par-
ticipants. Our goal in this study is to determine which utter-        where C(u) is the cost of a particular utterance, −log(pL0 )
ances fall in U.                                                      represents the surprisal of the message for the literal listener
                                                                      (the information content of the utterance), and α is a param-
   In the standard RSA model, the pragmatic listener (denoted
                                                                      eter in a standard choice rule. If α = 0, speakers choose ran-
L1 ), makes a Bayesian inference:
                                                                      domly; as α → ∞, they greedily choose the highest probabil-
                                                                      ity alternative. In our simulations below, we treat α as a free
                    pL1 (m | u) ∝ pS1 (u | m)p(m)             (1)
                                                                      parameter and fit it to the data.
In other words, the probability of a particular meaning                  To instantiate our signaling game with a tractable message
given an utterance is proportional to the speaker’s probabil-         set M, in our studies we adopt the world of restaurant reviews
ity of using that particular utterance to express that meaning,       as our communication game. We assume that speakers and
weighted by a prior over meanings. This prior represents the          listeners are trying to communicate the number of stars in an
listener’s a priori expectations about plausible meanings, in-        online restaurant review (where m ∈ {1...5}). We then use ex-
dependent of the utterance. Because our experiments take              periments to measure three components of the model. First, to
place in a context in which listeners should have very little         generate a set of plausible alternative messages in U, we ask
expectation about which meanings speakers want to convey,             participants to generate alternatives for particular scalar items
for simplicity we assume a uniform prior where p(m) ∝ 1.              (Experiment 1). Next, to measure literal semantics pL0 (m | u)
   The pragmatic speaker in turn considers the probability            we ask participants to judge whether a message is compatible
that a literal listener would interpret her utterance correctly:      with a particular meaning (Experiment 2). Lastly, to obtain
                                                                      human L1 pragmatic judgments, we ask participants to inter-
                       pS1 (u | m) ∝ pL0 (m | u)              (2)     pret a speaker’s utterances (Experiment 3).
where L0 refers to a listener who only considers the truth-                   Experiment 1: Alternative Elicitation
functional semantics of the utterance (that is, which meanings        To examine the effect different alternative sets have on impli-
the utterance can refer to).                                          cature, we needed a way of expanding alternative sets beyond
                                                                  320

              50                                                                goal of Experiment 2 is to test whether the set of alternatives
              40                                                                queried during literal semantic elicitation impacts literal se-
     counts
                                                                                mantic judgments. If it does we should see differences in
              30
                                                                                these judgments for shared items between conditions.
              20
              10                                                                Methods
               0                                                                Participants Conditions were run sequentially. In each
                              hated
                           disliked
                                                                                condition we recruited 30 participants from AMT. In the two
                        despised
                           loathed
                            adored
                          enjoyed
                         detested
                        tolerated
                        regretted
                          savored
                        abhorred
                        accepted
                         admired
                   appreciated
                                                                                alternatives condition, 16 participants were excluded for ei-
                      cherished
                          coveted
                        criticized
                       devoured
                   disapproved didnt
                                dug
                             feared
                              forgot
                      indifferent
                           praised
                             prized
                                                                                ther failing to pass two training trials or because they were
                        regarded
                              regret
                          rejected
                          relished
                          repelled
                       treasured
                     worshiped
                                alternatives                                    not native English speakers, leaving a total sample of 14 par-
                                                                                ticipants.2 In the four alternatives condition, 7 participants
Figure 2: Combined counts for participant-generated alterna-                    were excluded for either failing to pass two training trials or
tives for liked and loved in Experiment 1.                                      not being native English speakers, leaving a total sample of 23
                                                                                participants. In the five alternatives condition, 3 participants
entailment pairs. We addressed this issue by adopting a mod-                    were excluded for either failing to pass two training trials or
ified cloze task to elicit alternatives empirically. This design                not being native English speakers, leaving a total sample of
was inspired by Experiment 3 of van Tiel et al. (2014).                         27 participants.
                                                                                Design and procedure Figure 3, left, shows the experimen-
Methods
                                                                                tal setup. Participants were presented with a target scalar item
Participants We recruited 30 workers on Amazon Mechan-                          and a star rating (1–5 stars) and asked to judge the compat-
ical Turk (AMT). All participants were native English speak-                    ibility of the scalar item and star rating. Compatibility was
ers and naive to the purpose of the experiment.                                 assessed through a binary “yes/no” response to a question of
Design and procedure On each trial participants were pre-                       the form, “Do you think that the person thought the food was
sented with a target scalar item from five scales, selected from                    ?” where a target scalar was presented in the blank. Each
the entailment items used in van Tiel et al. (2014). These                      participant saw all scalar item and star rating combinations
were embedded in a sentence such as, “In a recent restaurant                    for their particular condition, in a random order.
review someone said they thought the food was             ,” with                  The two alternatives condition only included entailment
a target scalar presented in the blank. Participants were then                  pairs taken from van Tiel et al. (2014) for a total of 50 trials
asked to generate three plausible alternatives by responding to                 for each participant. The four alternatives condition included
the question, “If they’d felt differently about the food, what                  entailment pairs plus the top two alternatives generated for
other words could they have used instead of           ?” Partici-               each scalar family by participants in Experiment 1 (100 trials
pants saw each scalar item in random order. In total, each                      per participant). The five alternatives condition included the
participant saw ten target scalar items (each entailment pair                   four previous items plus one more neutral item chosen from
from the five scales selected from van Tiel et al., 2014).                      alternatives generated in Experiment 1 (125 trials per partici-
                                                                                pant).
Results and Discussion
Figure 2 shows an example alternative set for the scalar items                  Results and Discussion
liked and loved (combined). Figure 1 shows the complete list                    Figure 4 plots estimated literal listener semantics for the three
of alternative sets derived from Experiment 1.                                  conditions. Each row shows a unique scalar family with
                                                                                items ordered horizontally by valence. Several trends are vis-
          Experiment 2: Literal Listener Task                                   ible. First, in each scale, the alternatives spanned the star
Experiment 2 was conducted to approximate literal listener                      scale — there were scalar items that were highly compati-
semantics—pL0 (m | u) in Equation (3)—for the same five                         ble with both the lowest and highest numbers of stars. Sec-
pairs of scalar items used in Experiment 1. We included three                   ond, participant compatibility judgments match intuitive lit-
conditions: two alternatives (“entailment”), four alternatives,                 eral semantics. That is, both weaker (e.g. some or good) and
and five alternatives. The two alternatives condition makes                     stronger (e.g. all or excellent) entailment items were seen
a test of the hypothesis that the two members of the classic                    as compatible with five-star ratings. This means participants’
Horn (entailment) scale (Horn, 1972) are the only alternatives                  compatibility judgments reflect literal semantic intuitions, not
necessary to predict the strength of listeners’ pragmatic infer-
                                                                                logically after the two alternative condition; all literal listener exper-
ence. The four and five alternative conditions then add suc-                    iments are grouped together for simplicity in reporting.
cessively more alternatives to test whether including a larger                      2 The majority of respondent data excluded from the two alter-
number of alternatives will increase model fit.1 A secondary                    natives condition was caused by failure to pass training trials. We
                                                                                believe the task may have been too difficult for most respondents
   1 Note that alternatives in the four and five alternative conditions         who may have been confused by the question wording. Training
were chosen on the basis of Experiment 1, which was run chrono-                 trials in later conditions included clearer language.
                                                                          321

Figure 3: (Left) A trial from Experiment 2 (literal listener) with the target scalar ’liked’. (Right) A trial from Experiment 3
(pragmatic listener) with the target scalar ’liked’.
enriched pragmatic judgments. We see clear variability be-            ers, leaving a total sample of 41 participants. In the four alter-
tween scalar families (literal semantic judgments for memo-           natives condition, data from 7 participants was excluded after
rable are considerably different from palatable), but also sub-       participants either failed to pass two training trials or were
stantial consistency for individual scalar items across condi-        not native English speakers, leaving 43 participants.
tions (good in the two alternatives condition is similar to good
                                                                      Design and Procedure Participants were presented with a
in the four and five alternative conditions).
                                                                      one-sentence prompt such as “Someone said they thought the
   To examine this last issue of consistency across conditions        food was        .” with a target scalar item in the blank. Partic-
(our secondary hypothesis) we fit a mixed effects model, re-          ipants were then asked to generate a star rating representing
gressing compatibility judgment on scale, number of stars             the rating they thought the reviewer likely gave. Each partic-
and experimental condition, with subject- and word-level ran-         ipant was presented with all scalar items in a random order.
dom effects, which was the maximal structure that converged.          Participants in the two alternatives condition gave a total of
Results indicate no significant differences between two and           10 pragmatic judgments. Participants in the four alternatives
five alternative conditions (β = −0.05, z = −0.53, p = 0.59)          condition gave a total of 20 pragmatic judgments. The exper-
or between four and five alternative conditions (β = −0.04,           imental setup is shown in Figure 3, right.
z = −0.52, p = 0.6). The addition of condition as a predic-
tor did not significantly improve model fit when compared             Results and Discussion
to a model without the condition variable using ANOVA
(χ2 (2) = 0.43, p = 0.81). These findings suggest that literal        Figure 5 plots pragmatic listener judgment distributions for
semantic intuitions are not affected by the set of alternatives       “weak” / “strong” scalar pairs (e.g. good / excellent). Several
queried in our paradigm. This finding is important because            trends are visible. First, in each scale participants generated
literal semantic data generated in these three conditions are         implicatures. They were substantially less likely to assign
used as input to our model to simulate the effects of different       high star ratings to weaker scalar terms, despite the literal se-
alternative sets on implicature generation.                           mantic compatibility of those terms with those states shown
                                                                      in Experiment 2. Second, the difference between strong and
      Experiment 3: Pragmatic Listener Task                           weak scalar items varied considerably across scales, consis-
                                                                      tent with previous work (van Tiel et al., 2014).
Experiment 3 was conducted to measure pragmatic judg-
                                                                         To rule out the potential effects of having a larger set of
ments. As in Experiment 2, we include several conditions to
                                                                      alternatives during the pragmatic judgment elicitation, we fit
test inferences in the presence of different alternative sets. In
                                                                      a mixed effects model. We regressed pragmatic judgments
the two alternatives condition, participants made judgments
                                                                      on scale and experimental condition with subject- and word-
for items included in the entailment scales. In the four alter-
                                                                      level random effects, which was the maximal structure that
natives condition, participants made judgments for the entail-
                                                                      converged. There were no significant differences between
ment items and also the top two alternatives elicited for each
                                                                      the two alternative and four alternative conditions (β = 0.05,
scale in Experiment 1. Including two conditions with differ-
                                                                      t(150) = 1.04, p = 0.3). The addition of the condition pre-
ing alternatives allowed us to rule out the potential effects of
                                                                      dictor did not significantly improve model fit when compared
having a larger set of alternatives during the pragmatic judg-
                                                                      to a model without that variable (χ2 (1) = 1.13, p = 0.29).
ment elicitation and also provided two sets of human judg-
ments to compare with model predictions.
                                                                                           Model Simulations
Methods                                                               Using literal listener data from Experiment 2, we conducted a
Participants We recruited 100 participants from AMT, 50               set of simulations with the RSA model. Each simulation kept
for each condition. Data for 9 participants was excluded from         the model constant, fitting the choice parameter α as a free
the two alternatives condition after participants either failed       parameter, but used a set of alternatives to specify the scale
to pass two training trials or were non-native English speak-         over which predictions were computed. We considered four
                                                                  322

                                                                horrible                      bad                          okay                             good                         excellent
                                                1.00
      proportion compatible ('yes' responses)
                                                0.75
                                                0.50
                                                0.25
                                                0.00
                                                                 hated                       disliked                    indifferent                        liked                         loved
                                                1.00
                                                0.75
                                                0.50
                                                0.25
                                                0.00
                                                               forgettable                    bland                      ordinary                         memorable                   unforgettable
                                                1.00
                                                0.75
                                                0.50
                                                0.25
                                                0.00
                                                               disgusting                     gross                      mediocre                         palatable                      delicious
                                                1.00
                                                0.75
                                                0.50
                                                0.25
                                                0.00
                                                                 none                         little                       some                             most                            all
                                                1.00
                                                0.75
                                                0.50
                                                0.25
                                                0.00
                                                       1   2       3         4   5   1   2      3       4   5   1    2       3         4   5    1     2      3        4   5   1      2      3        4   5
                                                                                                                    star rating
                                                                                              Condition         five alts         four alts         two alts
Figure 4: Literal listener judgments from Experiment 2. Proportion of participants indicating compatibility (answering “yes”)
is shown on the vertical axis, with the horizontal axis showing number of stars on which the utterance was judged. Rows are
grouped by scale and items within rows are ordered by valence. Colors indicate the specific condition with conditions including
different numbers of items.
different alternative sets, with empirical measurements corre-                                                                   model         Empirical 2-alts                   Empirical 4-alts
sponding to those shown in Figure 1: 1) the two alternatives                                                                     5-alts        r = 0.88 (alpha = 4.4)             r = 0.91 (alpha = 4.5)
in the classic entailment scales, 2) those two alternatives with                                                                 4-alts        r = 0.85 (alpha = 4.4)             r = 0.89 (alpha = 4.7)
the addition of a generic negative alternative, 3) the expanded                                                                  3-alts        r = 0.68 (alpha = 6.8)             r = 0.71 (alpha = 6.7)
set of four alternatives, and 4) the expanded set of five alter-                                                                 2-alts        r = 0.54 (alpha = 8.9)             r = 0.56 (alpha = 9.4)
natives. Literal semantics for the generic negative alternative
served as a baseline “none” semantics in which the scalar item                                                             Table 1: Model performance with fitted alpha levels. Model
was only compatible with 1 star.                                                                                           fit assessed through correlation with human judgments in the
   Model fit with human judgments was significantly im-                                                                    two conditions of Experiment 3.
proved by the inclusion of alternatives beyond the entailment
items (Table 1). The two alternatives model contained only                                                                 1972). For other, contextually-determined inferences, the is-
entailment items, which, under classic accounts, should be                                                                 sue of alternatives has been considered relatively intractable
sufficient to generate implicature, but fit to data was quite                                                              in terms of formal inquiry (Sperber & Wilson, 1995).
poor with these items. The addition of a generic negative
                                                                                                                              In our current work, we used the rational speech act frame-
element produced some gains, but much higher performance
                                                                                                                           work to investigate the set of alternatives that best allowed the
was found when we included four and five alternatives, with
                                                                                                                           model to predict pragmatic judgments across a series of dif-
the alternatives derived empirically for the specific scale we
                                                                                                                           ferent scales. We found that the best predictions came when
used. Figure 6 plots model fit for the five alternatives model.
                                                                                                                           a range of scale-dependent negative and neutral alternatives
                                                                                                                           were added to the implicature computation, suggesting the
                                                           General Discussion                                              importance of considering non-entailment alternatives. This
Pragmatic inference requires reasoning about alternatives.                                                                 work builds on previous investigations, reinforcing the claim
The fundamental pragmatic computation is counterfactual:                                                                   that negative alternatives are critical for understanding im-
“if she had meant X, she would have said Y, but she didn’t.”                                                               plicature (Franke, 2014), and replicates and extends findings
Yet the nature of these alternatives has been controversial. For                                                           that different lexical scales produce strikingly different pat-
a few well-studied scales, a small set of logically-determined                                                             terns of inference (van Tiel et al., 2014).
alternatives has been claimed to be all that is necessary (Horn,                                                              While improvements in model fit were substantial as we
                                                                                                                    323

       percentage selecting
                                          good_excellent             liked_loved         memorable_unforgettable                    palatable_delicious             some_all
                              0.75
                              0.50
                              0.25
                              0.00
                                     1    2     3     4    5 1   2       3         4   5 1    2              3           4    5 1    2      3      4      5 1   2      3       4   5
                                                                                              star rating
                                                           Condition         four alts   two alts                     Scalar type     stronger         weaker
Figure 5: Pragmatic listener judgments from Experiment 3. Vertical axis shows proportion of participants generating a star
rating. Horizontal axis shows number of stars on which the utterance was judged. Line type denotes condition and colors
indicate the particular scalar items. Each panel shows one entailment scalar pair.
moved from two to four alternatives, we saw only a minor                                                              1.00
increase in fit from the move to five alternatives. One pos-
                                                                                                    human judgments
sible explanation is that alternatives are differentially salient                                                     0.75
in context, and in moving to larger sets we should consider
                                                                                                                                                                                   stars
                                                                                                                                                                                       5
weighting the alternatives differentially (as Franke, 2014 did).                                                      0.50                                                             4
Preliminary simulations using weightings derived from Ex-                                                                                                                              3
                                                                                                                                                                                       2
periment 1 provide some support for this idea but would re-                                                           0.25                                                             1
quire further empirical work for confirmation.
   The precise set of alternatives present during implicature                                                         0.00
is likely to be domain dependent. Our empirical paradigm                                                                     0.00     0.25             0.50     0.75
elicited literal semantics, pragmatic judgments, and plausible                                                                           model predictions
alternatives all within the restricted domain of restaurant re-
views. Our measurements might have differed substantially                                          Figure 6: Judgments for entailment items from the four alter-
if we had instead grounded our ratings in a different context.                                     natives condition of Experiment 3 are plotted against model
Future investigations should probe the context-specificity of                                      predictions using the five alternatives data from Experiment
the weight and availability of particular alternative sets.                                        2. Colors show the star rating for individual judgments.
   More broadly, considering the context- and domain-
specificity of alternative sets may provide a way to unite what
Grice (1975) called “generalized” (cross-context) and “par-                                          implicature: Modeling language understanding as social
ticularized” (context-dependent) implicatures. Rather than                                           cognition. Topics in Cognitive Science, 5(1), 173–184.
being grounded in a firm distinction, we may find that these                                       Grice, H. P. (1975). Logic and conversation. In P. Cole & J.
categories are simply a reflection of the effects of context on                                      Morgan (Eds.), Syntax and semantics (Vol. 3). New York:
a constantly-shifting set of pragmatic alternatives.                                                 Academic Press.
                                                                                                   Horn, L. R. (1972). On the semantic properties of logical
                                         Acknowledgements                                            operators. (PhD thesis). University of California, Los An-
Thanks to NSF BCS #1456077 for support, and thanks to                                                geles.
Michael Franke, Judith Degen, and Noah Goodman for valu-                                           Levinson, S. C. (2000). Presumptive meanings: The theory
able discussion.                                                                                     of generalized conversational implicature. MIT Press.
                                                                                                   Lewis, D. (1969). Convention: A philosophical study. John
                                              References                                             Wiley & Sons.
Degen, J., & Tanenhaus, M. K. (2015). Processing scalar im-                                        Sperber, D., & Wilson, D. (1995). Relevance: Communica-
  plicature: A constraint-based approach. Cognitive Science,                                         tion and cognition (2nd ed.). Oxford, UK: Blackwell.
  39(4), 667–710.                                                                                  van Tiel, B. J. M. (2014). Quantity matters: Implicatures,
Frank, M., & Goodman, N. D. (2012). Predicting pragmatic                                             typicality, and truth.
  reasoning in language games. Science, 336(6084), 998.                                            van Tiel, B. J. M., Van Miltenburg, E., Zevakhina, N., &
Franke, M. (2014). Typical use of quantifiers: A probabilistic                                       Geurts, B. (2014). Scalar diversity. Journal of Semantics,
  speaker model. In Proceedings of the 36th annual confer-                                           ffu017.
  ence of the cognitive science society (pp. 487–492).
Goodman, N. D., & Stuhlmuller, A. (2013). Knowledge and
                                                                                             324

