        From low to high cognition: A multi-level model of behavioral control in the
                                                              primate brain
 Jerald D. Kralik1,2 (jerald.kralik@gmail.com), Dongqing Shi1 (dongqshi@gmail.com), Omar A. El-Shroa1
                           (o.a.elshroa@gmail.com), Laura E. Ray3 (laura.e.ray@dartmouth.edu)
                 1
                   Department of Psychological and Brain Sciences, Dartmouth College, Hanover, NH 03755 USA
                      2
                        Department of Bio and Brain Engineering, Program of Brain and Cognitive Engineering,
                       College of Engineering, Korea Advanced Institute of Science and Technology (KAIST),
                                                         Daejeon, 34141, South Korea
                             3
                               Thayer School of Engineering, Dartmouth College, Hanover, NH 03755 USA
                                Abstract                                 problem-solving system — and nonapparent — i.e., those
   The basic cognitive architecture of the human brain remains
                                                                         that break the system.
   unknown. However, there is evidence for the existence of                 In primates, there is neuroanatomical evidence for a
   distinct behavioral control systems shared by humans and              distinct region of prefrontal cortex (PFC), called granular
   nonhumans; and there is further evidence pointing to distinct         PFC (which includes lateral PFC and frontal pole), and
   higher-level problem solving systems shared by humans and             some theorists have suggested that this region may enable
   other primates. To clarify the nature of these proposed               primates to perform unconventional behaviors, such as
   systems and examine how they may interact in the brain, we            looking away from a salient visual stimulus when required
   present a four-level model of the primate brain and compare
   its performance to three other brain models in the face of a          to do so (Passingham & Wise, 2012; Striedter, 2005).
   challenging foraging problem (i.e., with transparent, and thus,       Related to this view, we hypothesize that granular PFC
   invisible barriers). In all manipulations (e.g., size of problem      mediates the cognitive ability to solve nonapparent
   space, number of obstacles), our model never performed the            problems. Moreover, we believe that a detailed analysis of
   best outright; however, it was always among the best,                 this ability in primates will shed light on the mechanisms
   appearing to be a jack-of-all-trades. Thus, the virtues of our        that underpin creative problem solving in people.
   primate brain lie not only in the heights of thinking it can
                                                                            Here, we present a computational framework and model
   reach, but also in its range and versatility.
                                                                         to begin this analysis of clarifying apparent versus
   Keywords: cognitive control; cognitive architecture;                  nonapparent problem solving, as well as to examine how
   reinforcement learning; creativity; agency; concept formation         these processes interrelate with the other main behavioral
                                                                         control systems of the primate brain. First, we focus on the
                            Introduction                                 classic detour problem in the comparative literature, in
There is considerable evidence for the existence of two                  which subjects must circumvent a barrier (either via
neural systems controlling mammalian behavior: (1) a goal-               reaching or navigating) to obtain a reward item (Wynne &
directed decision-making system based in the ventromedial                Udell, 2013). Most comparative research on the detour
prefrontal cortex (vmPFC), and (2) a habit system based in               problem has focused on cases with opaque barriers as
the striatum (Daw, Niv, & Dayan, 2005; Rangel, Camerer,                  obstacles, and have generally shown that many species can
& Montague, 2008). It has been argued that the goal-                     solve the problem — thus, they have the basic capacity to
directed system is model-based, meaning essentially that an              take paths away from a goal item to reach it, at least when
individual knows what will happen upon taking an action;                 the obstacle is clearly defined.
while the habit system is not, meaning that an individual                   However, as illustrated in Figure 1a, many nonhuman
simply knows what action to take in a given state of the                 animals and human infants find the problem challenging
world (Daw et al., 2005). A model-based system potentially               when the barrier is transparent, as they repeatedly attempt to
provides an infrastructure for mental simulation, planning,              reach directly for the reward item, even in the face of strong,
and reasoning, which in turn lead to faster learning and                 negative feedback (Diamond, 1990; Santos, Ericson, &
greater generalization across environmental conditions.                  Hauser, 1999; Wallis et al., 2001). This insensitivity to
Such potent abilities reduce errors when facing novel                    feedback is typically explained as an inability to inhibit a
situations. However, research in engineering and computer                lower-level behavioral control system (such as a Pavlovian
science shows that models are notoriously brittle and                    system). However, other experimental conditions suggest
therefore often break under real-world conditions. One                   not, at least for nonhuman primates (Santos et al., 1999).
approach to dealing with this brittleness is to have a fallback          For example, when first given experience with an opaque
process that does not rely on the model, and this appears to             barrier, subjects tend to solve the transparent barrier
be one of the main advantages of the model-free habit                    problem. The ease with which they refrained from reaching
system. Another approach would be to have an additional                  directly for the food item once they had an alternative
system that can fix the models when they break, enabling                 response available suggests that the major difficulty did not
individuals to solve these harder problems. We classify                  stem from a lack of self-control.
these two types of problems as apparent — i.e., the problem                 We propose that the difficulty results from confusion with
features are properly modeled by the standard model-based                the transparent barrier: the subjects do not readily see that
                                                                    2723

there is a barrier. Although their response is blocked, there       represents the striatal-based habit system, which uses
is no apparent reason for it, and so they continue to attempt       model-free reinforcement learning. The third level
the most efficient solution of reaching directly for the goal       represents the first model-based problem solving system,
item. We suggest that this is an example in which a                 i.e., that which solves apparent problems. This system
problem-solving system sees a clear solution and is                 would solve the detour problem with well-defined, opaque
therefore overriding feedback to the contrary. However, it is       barriers, but would produce direct reaching with the ill-
using a broken model. Put differently, it is an example of a        defined transparent barrier. The fourth level, then, performs
cognitive illusion that provides insight into how cognitive         nonapparent problem solving, and evidence suggests it is
systems are constructed (Kahneman, 2011).                           mediated by granular PFC. Evidence that granular PFC
                                                                    mediates nonapparent problem solving further suggests that
                                                                    mammalian vmPFC likely underlies the solving of apparent
                                                                    problems.
                                                                       Because these systems of the primate mind/brain evolved
                                                                    under specific selection pressures, we also attempted to
                                                                    model these pressures to best understand the utility of each
                                                                    system and their interactions. More specifically, we used a
                                                                    foraging problem, and tested parameters to mimic basic
                                                                    selection pressures, such as size of the foraging
     Figure 1: Illustration of a nonapparent problem. (a) The       environment, number of obstacles, and changing conditions,
      marmoset monkey attempts to reach directly for the            e.g., changes in the goal state position. In addition, because
  marshmallow but is blocked by the transparent barrier. (b)        the primate brain evolved along a specific phylogenetic
        The monkey learns to reach around the barrier.1             trajectory, rather than studying each system in isolation, we
                                                                    examine them from this phylogenetic perspective, in which
   We further suggest that the transparent barrier problem          each system appears to be added to a previous combination.
requires a nonapparent solution. To solve it, the problem-          Thus, very roughly, we compared the four-level primate
solving system must include an obstacle in the problem              brain model to an ancestral vertebrate brain, consisting of
formulation, thus fixing the model that did not include it.         the first two levels, and an ancestral mammalian brain,
However, if an individual cannot see that an obstacle exists,       consisting of the first three levels. We also compared the
it must be inferred from the effect of being blocked. Thus,         model to an alternative primate brain consisting of Levels 1,
taken together, we use the detour problem with a transparent        2, and 4 (i.e., without the simpler apparent problem-solving
barrier as an example of a nonapparent problem, and more            system).
specifically, as a case in which an individual confronts an            In this paper, we focus on the main difference between
unknown event or consequence, must infer a hidden cause,            the levels and therefore only use transparent barriers (i.e., no
and create a (nonperceptual) concept to model it (Goswami,          opaque ones). Thus, when no obstacles are in the direct
2008; Holyoak & Morrison, 2012).                                    path, the apparent system can solve the problem; otherwise,
   In addition, there is evidence that the ability to solve this    the nonapparent system must be utilized.
nonapparent problem is subserved by a separate problem-                In sum, the aims of the current project were (1) to begin
solving system. Chiefly, it has been shown that rhesus              specifying more clearly how nonapparent problems can be
monkeys who normally solve the transparent barrier                  solved when the simpler model-based problem solving
problem lose this ability with lateral PFC lesions (Diamond,        system fails; (2) to examine the potential advantages and
1990). Thus, such findings implicate lateral PFC in                 disadvantages of a four-level system; and (3) to determine
mediating nonapparent problem solving, and suggest that it          the foraging conditions that would provide a selective
is separable from what we are calling apparent problem              advantage for this brain architecture.
solving.
   From these results and others, we model the primate brain                                  Methods
with four basic levels of behavioral control. The first is
based on the first main system in the vertebrate brain that         In what follows, we describe the modeling environment, and
controls     complete        goal-oriented    behaviors:     the    then layout the details of our model; we next present the
hypothalamus (Swanson, 2000). That is, it is the first              four competing models, and then describe how the models
behavioral control system involving complete behavioral             were assessed.
sequences that attain goals, such as goal-directed approach
and ingestion behaviors when food is perceived. However,
                                                                    Modeling environment
here we assume it is normally inhibited until the goal state is     To focus on the main features of our model, we sought to
reached, and then is used to complete the process of actually       keep the testing environment as simple and straightforward
obtaining and ingesting the food item. The second level             as possible. Therefore, we tested the model with a foraging
                                                                    problem using a 2D grid world, in which the agent must
   1                                                                learn a path from its current location to the goal location that
    With permission from Wallis, Dias, Robbins, & Roberts (2001)
© 2001 Federation of European Neuroscience Societies.
                                                                    avoids all obstacles (Figure 2).
                                                                2724

                                              Initial	  state           nonapparent problem solving respectively, derive their
                                                                         behavioral control by modulating the actor in Level 2 (by
                                                                         modifying the action values and then passing control back
                                                                         to the Level 2 actor when a solution is found). If Level 3
                                                                         fails to find a solution, it passes control to Level 4; and if
                                                                         Level 4 fails, Level 2 selects an action randomly. Future
                                                                         work will examine a more sophisticated controller based on,
           Goal	  state
                                                                         e.g., cost/benefit analysis (Daw et al., 2005; Kowaguchi et
                                                                         al., accepted).
      Figure 2: Example grid world, with the ‘Initial state’
     denoted as “S” (Start) and the ‘Goal state’ in green.               Level 3 represents explicit problem solving when problem
  Obstacles are denoted in black, however, they are actually             components are apparent, passing control to Level 4 when
transparent (and thus hidden to the problem solver visually).            they are ill-defined and a solution cannot be found. Both
                                                                         Levels 3 and 4 look for solutions based on a cognitive
Model description                                                        model—i.e., a cognitive map—of the problem environment
Our model consists of the four levels and a cognitive control            that is built in the background as the problem solver moves
mechanism that passes control between them.                              through it and experiences the state transitions: i.e., the
                                                                         subsequent state reached when an action is taken in a given
Level 1 enables actual goal attainment once in view. For                 state (with all transition probabilities = 1), e.g., T(si, aj) à
foraging, it completes the act of food consumption. This                 sʹ′, where si = (1, 1), aj = move right; and sʹ′ = (2, 1), and
level is assumed in the four-level model, and is not                     thus, placing sʹ′ to the right of si in the map/model (Sutton &
explicitly modeled or tested here. With respect to the brain,            Barto, 1998; Daw et al., 2005). This model thus has an
Level 1 represents hypothalamus, which is considered the                 understanding of the relationships among the states in the
first behavioral control system involving complete                       grid world that Level 2 cannot see. Currently, we have one
behavioral sequences that attain goals (Swanson, 2000).                  cognitive model that is built; however, Levels 3 and 4
Level 2 represents the striatal-based habit system. It uses a            contribute different elements to it and utilize what they have
Markov Decision Process (MDP) and Reinforcement-                         access to.
Learning (RL) framework (Sutton & Barto, 1998). Thus,                        More specifically, for both Levels 3 and 4, all problems
there is a set of states, i.e., the (x, y) positions in the grid         are considered multi-agent problems, with three classes of
world; a set of possible actions, i.e., all eight reachable              agents: self, others, and goals (Holyoak & Morrison, 2012;
positions from a given grid world position; and a reward                 Shi et al., 2010; Wooldridge, 2009). All are considered
function that assigns values (called action or Q values) to              agents because they could theoretically invoke a state
the actions based on environmental feedback, with the Q                  change by virtue of their actions and functional relationships
values representing expected future reward. The agent then               with other agents. (This would occur for the goal item if, for
learns to choose the best action (i.e., policy) in a given state         example, it were moving prey; however, in the current case,
that leads to the highest future reward. Thus, rather than               the goal item is stationary.) Thus, the cognitive model used
having a model of the world, i.e., an understanding of how               by Levels 3 and 4 consists of four main components: (1) an
the states relate to each other in the larger grid world, Level          x, y coordinate frame that defines each location in the grid
2 sees the states independently, simply using a Q-Table to               world; (2) the identification and location of every agent in
determine action values in each state (Daw et al., 2005).                the problem; (3) the set of available actions each agent
Level 2 is composed of learning and acting components.                   could take; and (4) an understanding of functional
The learner updates the action values using the following                interactions among the agents (Goswami, 2008): i.e.,
Q-learning algorithm (a form of RL learning):                            fi(agentj, target agentk), where fi could be acquiring the goal
  Qt+1(st, at) = Qt(st, at) + α [rt+1 + γmaxa(st+1, a) - Qt(st, at)]     item by the problem solver or blocking of the problem
where α is the learning rate α ∈ [0, 1]; rt+1 is the actual              solver by an obstacle (also considered an agent by virtue of
reward received at episode t+1; and γ is the discount factor             this blocking effect). For the current study, there is only one
                                                                         type of obstacle with only one available action: blocking.
γ ∈ (0, 1) (Sutton & Barto, 1998). The actor selects an
                                                                             For any novel problem in the grid world, the problem
action according to the Boltzmann distribution of Q values:
                                                                         solver cannot see the entire problem immediately — the
                                                                         world is too large — and so a cognitive model must be
                             , where τ is the temperature that           developed via initial experience with each state. Model
controls the degree of action exploration.                               building entails developing the cognitive map of (x, y)
Cognitive control, i.e., control between levels, in the                  coordinates for each state as well as whether an agent
current model is generally hierarchical and modulatory                   resides in each state. Again, because Level 3 can only see
(Kahneman, 2011; Miller & Cohen, 2001). Control begins                   apparent obstacles, not invisible ones, it cannot see any of
at Level 2; however, when Level 2 fails (here, when the                  the transparent obstacles, and thus assumes there aren’t any.
maximum Q value for an action is not unique), control                        For problem solving, Level 3 uses the cognitive model to
passes to Level 3. Levels 3 & 4, representing apparent and               find a path to the goal. Since Level 3’s view of the grid-
                                                                     2725

world problem appears clear of obstacles, it always finds a            Brain models
direct path to the goal. The potential advantage of this is that       We compared our model to three others, thus testing four
when there are clear paths to the goal, a brain that contains          different multi-level models:
this system would provide fast and efficient solutions. Since
                                                                            (1) Model 1: consisting of levels 1 & 2
Level 3 always sees a clear path, it will continue producing
                                                                            (2) Model 2: levels 1, 2, & 3
this solution (via hill climbing), leaving the problem solver
                                                                            (3) Model 3: levels 1, 2, & 4
in a potential phase of perseveration (i.e., continuing to
                                                                            (4) Our model, Model 4: levels 1, 2, 3, & 4
attempt the same direct path solution). This impasse, then, is
what causes cognitive control to pass to Level 4.                         All four models assume the existence of Level 1. Model 1
                                                                       simply uses model-free reinforcement learning, and roughly
Level 4 assumes control when Level 3’s model breaks.                   speaking, perhaps represents an ancestral vertebrate. Model
Level 4 therefore represents the system that attempts to find          2 combines model-free RL with the ability to solve more
these nonapparent solutions. For the current project, this             straightforward, apparent problems, perhaps representing
occurs every time a hidden cause, i.e., an ‘invisible’                 the ancestral mammalian brain. Model 3 represents a brain
obstacle, blocks the direct path to the goal. In this case, the        that contains both lower level model-free RL and the higher
obstacle is literally nonapparent to Level 3.                          level nonapparent problem-solving system that one might
   Level 4’s main contributions occur with both the building           argue should replace the simpler apparent problem-solving
of the overall cognitive model of the grid-world problem               system altogether. Model 4 is our multi-level model of the
and utilizing it to solve the nonapparent problems. First, as          primate brain.
the problem solver is moving in the problem space (the grid
world) via the actor module, when it is blocked, Level 4               Model assessment
uses this information conceptually, inferring that there is an
agent doing the blocking (Goswami, 2008; Holyoak &                     We examined the effects of (1) grid world size, (2) number
Morrison, 2012; Tenenbaum et al., 2011; Wynne & Udell,                 of obstacles, (3) changing initial states, (4) changing goal
2013). That is, it infers fi(obstacle, self), where fi is blocking.    states, and (5) changing obstacles. The models were
From this inference, Level 4 places a blocking agent at the            assessed via two measures (average from ~50 iterations): (1)
grid location in the cognitive model. Unfortunately, Level 3           Cumulative number of steps to reach the goal after 200
cannot see this nonvisual conceptual obstacle; it is beyond            learning episodes (i.e., 200 times in which the goal item was
Level 3’s comprehension.                                               reached); and (2) Cumulative computational cost needed per
   Second, when cognitive control is passed to Level 4, it             action, measured as the amount of processing time per
uses the complete cognitive model (including the                       action. The two measures were combined to obtain an
transparent barriers) to find a path to the goal. To achieve           overall performance score.
this, Level 4 currently uses the planning algorithm A*
(called ‘A star’) to find an efficient path around the                                    Simulation results
obstacles to the goal (Russell & Norvig, 2010). Once a path               Because Level 1 was not explicitly modeled or examined
is found, Level 4 then modifies the Level 2 action values so           here, results are from Levels 2-4. We maintain the color-
that the actor module will use the path. The main advantage            coding of the model names to help keep them straight.
of Level 4 over Level 2 (simple model-free RL) is that it can
perform inductive inference, and use the internal cognitive            Grid world size
map for mental simulation and planning, leading to rapid,              To examine the effects of grid world size, no obstacles were
one-trial learning via problem solving (as well as greater             included. As seen in Figure 4a, performance was best for
generalization to novel problems in future model                       Model 1 with the smaller world and worse with the largest
development) (Passingham & Wise, 2012).                                grid size. As the world size increased, Model 2 and Model 4
   Figure 3 summarizes the key characteristics of each level.          performed the best. Figure 4b shows the learning rates, and
                                                                       Figure 4c the cumulative computational costs for all four
       Levels                                                          brain models for the largest grid world size (40x40). Model
       1. See goal à obtain it                                        1 was slower to learn a path to the goal (and progressively
          (e.g., Approach food à ingest)                              more so as the world size increased); in contrast, the other
       2. (a) Actor (action selection via Boltzmann distribution)
                                                                       models all continued to learn very quickly. For all grid
          (b) Learner (Q-learning algorithm)                           world sizes, the computational cost was greatest for Model 3
                                                                       and lowest for Model 1.
       3. (a) Builds internal cognitive model
          (b) Hill-climbing search
          (c) Change Level 2 Q-values for Actor                        Number of transparent obstacles
       4. (a) Adds transparent obstacles to the internal model         All remaining analyses used the large grid size. As the
          (b) A* search                                                number of obstacles increased, Model 1 and Model 2 were
          (c) Change Level 2 Q-values for Actor                        slower to learn a path to the goal, while Model 3 and Model
                                                                       4 continued to learn quickly. As shown in Figure 5, Model 4
             Figure 3: Description of model levels.                    performed relatively well across all numbers of obstacles,
                                                                   2726

Model 2 performed relatively well until the largest number,
Model 3 was relatively better with the largest number of                                                     Model 4
obstacles, while Model 1 performed the poorest at every                                                      Model 2
number of obstacles.
         a.                                                                                                  Model 3
                                                     Model 2
                                                                                                             Model 1
                                                     Model 4
                                                                                                       1/50         Changing initial state         1/10
                                                     Model 3
                                                                                          Figure 6: Model performance as a function of the rate of
                                                                                       change of the initial state: once every 50 episodes or once
                                                                                                              every 10 episodes.
                                                     Model 1
                 10x10              20x20                     40x40                    a.                           Model	  1
                                                                                                                               b.
  b.                               Grid	  size
                                                 c.                                                                 Model	  2
                                                                                                                    Model	  3
                                                                                                                    Model	  4
                                                                   Model 3
                Model 1
                                                           Model 2      Model 4
     All other models                                                 Model 1
                                                                                               Figure 7: (a) Learning rates and (b) Cumulative
    Figure 4: (a) Performance of the four brain models as a                                computational costs for the highest rate of goal state
   function of grid world size, (b) Learning rates, and (c)                          location change (once every 10 episodes). Bands around the
  Cumulative computational costs for all four brain models                                                     curves are SEMs.
  for the largest grid world size (40x40). Bands around the
     curves represent standard error of the mean (SEM).                             As seen in Figure 8, Model 2 and Model 4 outperformed the
                                                                                    others.
                                                           Model 4
                          Model 3
                                                                                                                                           Model 4
                                                                                                            Model 3
                                                        Model 2                                                                            Model 2
                          Model 1
                                                                                                            Model 1
                       40                      60                   80                                                                             1/10
                       0          Number of    0 obstacles          0                                 1/50           Changing goal state
   Figure 5: Model performance as a function of the number                          Figure 8: Performance as a function of changing goal state.
             of transparent obstacles in the grid world.
                                                                                    Changing (transparent) obstacles As shown in Figure 9,
Changing world                                                                      when the number of obstacles (600) and frequency of
                                                                                    change (1/10) were high, Model 3 and Model 4 found a path
To examine the effects of a changing initial state and                              to the goal most quickly (Fig. 9a), however, the
changing goal state, no obstacles were used.                                        computational demands were relatively steep (Fig. 9b).
Changing initial state The initial state of the problem
                                                                                                                    Model	  1
solver was changed once every 50 episodes or once every                                    a.                       Model	  2
                                                                                                                    Model	  3
                                                                                                                                b.
10 episodes. The models were generally robust with the                                                              Model	  4
changing initial states, although computational costs
increased, especially for Model 3. As shown in Figure 6,
overall performance was best for Model 2 and Model 4.
Changing goal state As seen in Figure 7a, rises in path
length occurred when the goal state changed, especially for
Model 1. With a changing goal state (and no obstacles), the                                   Figure 9: (a) Learning rates and (b) Cumulative
computational costs for Model 3 were relatively high (Fig.                            computational costs for changing obstacles (600 total, once
7b).                                                                                    every 10 episodes). Bands around the curves are SEMs.
                                                                                2727

                         Discussion                                    The ability to solve problems creatively across a wide
                                                                    range of domains embedded in complex, physical
Model-based problem solving potentially provides great
                                                                    environments remains out of reach for current artificial
advantages, such as lowering the number of errors during
                                                                    systems; but we are extending their reach (Hélie & Sun,
learning and generalizing to novel problems (Daw et al.,
                                                                    2010). A detailed analysis of how it evolved in the human
2005; Holyoak & Morrison, 2012). However, models of the
                                                                    lineage should help to further demystify the creative
real world are notoriously brittle, and thus require other
                                                                    process. Such an analysis can also help to clarify how
approaches to problem solving when they break. It has been
                                                                    primates in general, and humans in particular, have come to
hypothesized that primates have evolved granular prefrontal
                                                                    fill the low-to-high cognitive niche. Creative thinking
cortex to cope with these more challenging, nonapparent
                                                                    represents the pinnacle of high-level cognition and underlies
problems. Here, the aims of our study were threefold: (1) to
                                                                    many of our greatest achievements. This success not only
begin clarifying the mechanisms of nonapparent problem
                                                                    derives from the heights of thinking we can attain, but also
solving, (2) to examine the potential advantages and
                                                                    the diversity of challenges we can master.
disadvantages of having four types of behavioral control
systems, and (3) to determine the foraging conditions that                                       Acknowledgments
would provide a selective advantage for this brain                  ONR Grant N00014-08-1-0693 supported the project.
architecture. We used the classic detour problem in the                                                References
comparative literature, and in particular, focused on the use       Botvinick, M. M., Niv, Y., & Barto, A. C. (2009). Hierarchically organized behavior
of transparent barriers, which prove challenging for                   and its neural foundations: A reinforcement learning perspective. Cognition, 113,
                                                                       262-280.
nonhuman animals. We suggest that an apparent problem-              Daw, N. D., Niv, Y., & Dayan, P. (2005). Uncertainty-based competition between
solving system, likely mediated by vmPFC, can solve detour             prefrontal and dorsolateral striatal systems for behavioral control. Nature
problems with well-defined obstacles; while a nonapparent              Neuroscience, 8(12), 1704–1711.
                                                                    Diamond, A. (1990). Developmental time course in human infants and infant
system, mediated by granular PFC, can solve the problem                monkeys, and the neural bases of, inhibitory control in reaching. Ann New York Ac
with ‘invisible’, transparent barriers. It does so by inferring        Sci, 608, 637-676.
                                                                    Goswami, U. (2008). Cognitive Development. London, UK: Routledge.
the existence of a barrier from its effects on the problem          Hélie, S. & Sun, R. (2010). Incubation, Insight, and Creative Problem Solving: A
solver. Thus, this system may underlie the powerful ability            Unified Theory and a Connectionist Model. Psychological Review, 117, 994-1024.
                                                                    Holyoak, K. J. and Morrison, R. G. (2012). The Oxford Handbook of Thinking and
of humans to infer hidden causes from given events and                 Reasoning. Oxford: Oxford University Press.
consequences (Holyoak & Morrison, 2012; Tenenbaum et                Kahneman, D. (2011). Thinking, fast and slow. New York: Farrar, Straus, and Giroux.
al., 2011). Other behavioral research we have conducted             Kowaguchi, M., Patel, N. P., Bunnell, M. E., & Kralik, J. D. (Accepted). Competitive
                                                                       control of cognition in rhesus monkeys. Cognition.
with monkeys suggests further possible mechanisms for the           Kralik, J.D. (2005). Inhibitory control and response selection in problem solving:
nonapparent system that help solve insight problems by both            How cotton-top tamarins (Saguinus oedipus) overcome a bias for selecting the
                                                                       larger quantity of food. Journal of Comparative Psychology, 119(1), 78-89.
nonhuman primates and people (Murray, Kralik, Wise,                 Kralik, J.D. (2011). Rhesus Macaques (Macaca mulatta) spontaneously generalize to
2005; Kowaguchi et al., accepted; Kralik, 2005, 2011). We              novel quantities in a reverse-reward contingency task. Journal of Comparative
                                                                       Psychology, 255-262.
plan to incorporate these findings in the future.                   Miller, E. K., & Cohen, J. D. (2001). An integrative theory of prefrontal cortex
   With respect to our second and third aims, the advantages           function. Annual Review of Neuroscience, 24, 167-202.
of greater cognitive abilities must outweigh the                    Murray, E. A., Kralik, J. D., & Wise, S. P. (2005). Learning to inhibit prepotent
                                                                       responses: successful performance by rhesus macaques, Macaca mulatta, on the
disadvantages, and the advantages of a multi-level brain               reversed-contingency task. Animal Behavior, 69, 991-998.
architecture appears to lie in its versatility. In all              Passingham, R. E., & Wise, S. P. (2012). The neurobiology of the prefrontal cortex:
                                                                       Anatomy, evolution, and the origin of insight. Oxford, UK: Oxford University
manipulations conducted here, our model (Levels 1-4) never             Press.
performed the best outright; however, it was always among           Rangel, A., Camerer, C., & Montague, P. R. (2008). A framework for studying the
                                                                       neurobiology of value-based decision making. Nature Reviews Neuroscience, 9(7),
the best, appearing to be a jack-of-all-trades. Thus, rather           545–556.
than fitting a high-level cognitive niche best, our brain           Russell, S., & Norvig, P. (2010). Artificial Intelligence: A Modern Approach. Upper
model appears to best fit a niche with problems of varying             Saddle River, NJ: Prentice Hall
                                                                    Santos, L. R., Ericson, B. N., & Hauser, M. D. (1999). Constraints on problem solving
levels of complexity: a low-to-high cognitive niche. Thus, it          and inhibition: Object retrieval in cotton-top tamarins. J. Comparative Psychology,
may be useful to have multiple behavioral control systems              113, 186-193.
                                                                    Shi, D., Sauter, M. Z., Sun, X., Ray, L. E., & Kralik, J. D. (2010). An extension of
at different levels of sophistication, which allow                     Bayesian game approximation to partially observable stochastic games with
computational savings when facing simpler problems, and                competition and cooperation. Proceedings of the International Conference on
                                                                       Artificial Intelligence (ICAI).
more elaborate capabilities when faced with more                    Sutton, R. S. & Barto, A. G. (1998). Reinforcement Learning: An Introduction.
challenging ones (Kahneman, 2011; Rangel et al., 2008).                Cambridge, MA, USA: MIT Press.
   More theoretical development, however, is required to            Striedter, G. F. (2005). Principles of Brain Evolution. Sunderland: Sinaur Assoc.
                                                                    Swanson, L. W. (2000). Cerebral hemisphere regulation of motivated behavior. Brain
better understand the characteristics of such multi-level              Research, 886(1-2), 113–164.
systems. For example, we plan further developments that             Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman, N. D. (2011). How to grow
                                                                       a mind: Statistics, Structure, and Abstraction. Science, 331, 1279-1285.
include using a dynamic environment, different classes of           Wallis, J. D., Dias, R., Robbins, T. W., & Roberts, A. C. (2001). Dissociable
agents that can both hinder or aid the problem solver in goal          contributions of the orbitofrontal and lateral prefrontal cortex of the marmoset to
                                                                       performance on a detour reaching task. European Journal of Neuroscience, 13(9),
attainment, more sophisticated inductive reasoning and                 1797–1808.
cognitive-control mechanisms, and further levels of                 Wooldridge, M. (2009). An Introduction to MultiAgent Systems. Chichester, UK: John
abstraction (Botvinick, Niv, & Barto, 2009; Daw et al.,                Wiley & Sons.
                                                                    Wynne, C., & Udell, M. A. R. (2013). Animal Cognition. London, UK: Palgrave
2005; Shi et al., 2010; Tenenbaum et al., 2011).                       Macmillan.
                                                                2728

