       Essays about service-learning events can be mined for program assessment
                 Anne T. Gilman (gilman@juniata.edu) & Deborah W. Roney (roneyd@juniata.edu)
                        Juniata College Department of Psychology & Language in Motion, 1700 Moore Street
                                                          Huntingdon, PA 16652 USA
                                                    Victoria Rehr (vrehr@cscc.edu)
                  Columbus State Community College Writing Center, 102 Columbus Hall, 550 East Spring Street
                                                          Columbus, OH 43215 USA
                                                    Helen H. Hu (huh162@psu.edu)
             PSU Department of Educational Psychology, Counseling, & Special Education, 125E CEDAR Building
                                                       University Park, PA 16802 USA
                                     Mark P. Peterson (mark.phillip.peterson@gmail.com)
                             Viterbo Universty Department of Biology and Mathematics, 900 Viterbo Drive
                                                          La Crosse, WI 54601 USA
                               Abstract                                  guistics research, could some computational techniques help
                                                                         document attitude changes and avoid the need for additional
   Psychological applications of human language technology
   combined with multidisciplinary approaches to similarity cal-         assessment activities? Student privacy protection and vari-
   culations and data visualization offer avenues to broaden the         ation among assignment types stand in the way of produc-
   use of students’ own words in program assessment. We                  ing a useable large-scale corpus of this type of writing. In
   compared multiple analysis approaches on both simple to-
   ken counts (word roots and character trigrams) and top-down           this study, we used students’ reflections on service-learning
   language indicators from 85 student essays about service-             events to explore the potential for computational linguistics
   learning events. Bioinformatic distance calculations on word          to supplement other evalutations of student learning.
   root counts provided useable assessment information on at-
   titude change, showing patterns of word use that match the            How computers detect patterns in texts
   holistic goals of the assignment. Although these patterns were
   not found in a subsequent batch of 81 essays, the tools we are        Enormous growth (Lyman & Varian, 2003) in available,
   providing may facilitate other efforts to detect attitude change      machine-readable text data continues to foster the develop-
   in student writing about service-learning events.
                                                                         ment of tools for detecting patterns in a much greater volume
   Keywords: events; semantic similarity; LIWC; text mining
                                                                         of writing than a single instructor could feasibly read (Bender
                                                                         & Good, 2010), These tools count written words, phrases,
Discovering attitude changes in writing about events
                                                                         and/or pieces of words in a given text and apply different
Writing about emotion-laden topics, including events such as             calcuations using those counts to compare that text to oth-
starting college, is associated with gains in school success             ers. For example, “happy birthday to you” is more similar by
and even physical health (Pennebaker & Chung, 2011). In-                 word count to “you are too happy” than to “many happy re-
structors routinely assess students’ content learning and skill          turns”. A knowledge-added approach might have the phrases
development by examining students’ assigned writing about                “happy birthday” and “happy returns” listed in the same cat-
events (Reynolds, Livingston, Willson, & Willson, 2010), al-             egory and thus identify those as more similar to each other
though questions remain about interpretating these assess-               than to “too happy”. With longer and more numerous texts,
ment practices (Baker, O’Neil, & Linn, 1993). Institutions               the calculations used to measure text similarity–usually ex-
of higher learning are facing increasing pressure to provide             pressed as a distance—become more complex. The calcula-
documentation of changes in knowledge, skill, and attitude in            tions that group documents by topic draw on different text
their students (Ewell, 2009). Measuring changes in cultural              characteristics than those that can detect an author’s emo-
attitudes is an assessment area with even less consensus than            tional outlook (Pennebaker, Mehl, & Niederhoffer, 2003),
measuring writing skill development. Some measures rely                  mental health status (Resnik, Garron, & Resnik, 2013), or
on a few self-reported rating-scale items (Pascarella, Wol-              personal identity (Koppel & Schler, 2003). In this study, we
niak, Seifert, Cruce, & Blaich, 2005). Other measures that               compared several similarity calculations, drawing from bioin-
avoid self-report and claim to indicate implicit attitudes can           formatics as well as computational linguistics, to discover
be gamed (Marini, Rubichi, & Sartori, 2012) and should be                common patterns in essays about service-learning events.
interpreted with caution (Gawronski, LeBel, & Peters, 2007).
Student writing constitutes a greater volume than most pro-              Contrasting computational techniques
fessors can assess for learning goals beyond the grading cri-            A key challenge in finding similar patterns in a group of natu-
teria for each assignment. Although this volume remains tiny             ral language texts is the sparseness of the distribution of indi-
in comparison to the language data used in computational lin-            vidual words. Among one hundred essays about a service trip
                                                                     1062

abroad, these terms might each occur three times: undoubt-                                     Method
edly, counterrevolutionary, twin. How should similarity cal-
culations treat these terms compared to extremely common
                                                                    Language in Motion (LIM)
ones such as and or the?                                            As a service-learning program, Language in Motion (LIM)
   Some approaches divide words into short sequences of let-        brings college students with extensive knowledge of foreign
ters such as the three-letter trigrams used as part of our cal-     cultures into rural K-12 classes. For more than a decade, the
culation; others rely on a dictionary to remove endings and         LIM program has formally documented the professional de-
count word roots, so that revolutionary and revolutionaries         velopment gains of participating K-12 teachers and their stu-
count as the same term. Individual words, letter sequences,         dents. Now, program leaders face growing pressure to label
and word roots are called tokens when used this way. Other          and document the effects on the college students involved: in-
approaches add even more knowledge by grouping terms by             ternational students, multilingual students, and those return-
their part of speech (e.g. noun, verb) and even their emo-          ing from study abroad programs. Assessments of LIM’s im-
tional connotations (e.g. glad, happy). Since character tri-        pact for participating K-12 sites do not address program goals
grams have been employed to allow for errors from faulty            such as attitude and perspective changes among presenters.
optical character recognition in scanned documents (Faber,
Hochberg, Kelly, Thomas, & White, 1994), they may aid               A bottom-up approach to assessment
the processing of documents authored by native and non-             The source texts for this project are essays written by stu-
native speakers. On the other hand, completely bottom-up            dents to discuss what they learned from one or more edu-
approaches often fall short of the mark in natural language         cational outreach events. Each text author (all of whom are
processing (Chang & Su, 2004), so we also used top-down             college students) made several language and culture presen-
semantic and rough part-of-speech information via the Lin-          tations to K-12 students, typically featuring a language other
guistic Inquiry and Word Count (LIWC) tool (Francis & Pen-          than English and stories of the presenter’s experiences in an-
nebaker, 1993; Pennebaker et al., 2003), as a comparison fa-        other country.
cilitated by bioinformatic distance measures.                          Some program goals, such as practice using the featured
                                                                    language, are comparatively easy to measure independently
Applying bioinformatic analysis to student writing                  of these essays; measuring the attainment of goals such as
                                                                    gains in cultural awareness is more difficult. The program ad-
Biology, like computational linguistics, is seeing enormous         ministrator (DR), a coauthor and our designated expert, looks
growth in new tools to find patterns in the rapidly-increasing      for evidence in the essays of progress towards goals such as
volumes of data, for example (Buonaccorsi et al., 2014;             students learning about themselves and gaining a fresh per-
Sboner, Mu, Greenbaum, Auerbach, & Gerstein, 2011). The             spective on their culture of origin. Since expert evaluation of
focus of bioinformatics in particular on deep analysis of of-       written texts does not map transparently onto assessment cri-
ten small numbers of unique samples, makes it a promising           teria that outside reviewers can use, several text-mining tech-
source of tools and analogies for processing natural language       niques were compared to see which most closely approached
texts. Many bioinformatic tools converge on the analysis of         the expert’s holistic essay ratings.
count data, such as the number of copies of a gene or the num-
                                                                       Each presenter submits a narrative evaluation of their expe-
ber of a bacterial species in a sample. While computational
                                                                    rience presenting to younger students, and these essays, av-
linguistics methods are commonly applied to biomedical re-
                                                                    eraging 821 words per student, offer the opportunity for au-
search (Ananiadou & McNaught, 2006), applying bioinfor-
                                                                    tomated knowledge extraction. For this study, 85 presenter
matic techniques to language data is still in its infancy. Ap-
                                                                    essays from 2008–2012 were analyzed using computational
plying these tools to natural language data stands to increase
                                                                    approaches to increase the depth of evaluation analysis and
the reach of natural language processing innovations for text-
                                                                    reporting, including identifying effects not yet articulated in
rich social and behavioral sciences.
                                                                    the stated mission of LIM and offering avenues to document
                                                                    qualitative observations.
Summary
                                                                    Data processing
In this paper we present ongoing work to evaluate the
utility of low-knowledge and expert-informed computa-               Each essay was converted to an anonymous plain-text docu-
tional linguistics tools with and without the application           ment. To remove potentially identifiable (i.e. unique) place
of bioinformatic models for educational program assess-             names from the corpus and standardize the target culutural
ment. In addition to new findings, we have developed a              information, foreign country names and languages were re-
small R package to ease the entry of researchers to au-             placed with ZZTopia and ZZTopian.
tomated textual analysis. The wordcountWrapper pack-                   The LIM director rated 22 randomly chosen essays for evi-
age is available at https://bitbucket.org/petersmp/                 dence of learning from their program participation. Our anal-
wordcountwrapper including source code and a description            yses compared those essays rated as showing ‘Excellent’ suc-
of the included tools.                                              cess (8) in large program goals with all others (14). Unrated
                                                                1063

essays, omitted from clustering analyses, provide useful con-          Horn similarities were then converted to dissimilarity mea-
text for our application of the results found here and will al-     sures and supplied to the non-metric multidimensional scal-
low for follow-up analysis of the value added by our cluster-       ing function in the R package vegan (Oksanen et al., 2013).
ing approaches.                                                     Briefly, this calculated the two-dimensional representation of
                                                                    the data that most accurately recreates the pair-wise distances
Token counts                                                        to allow plotting of the spatial relationship between samples.
Character trigrams and word roots were extracted from each
student essay using R (R Core Team, 2013). The func-                Differential token usage
tions to read, count, and provide context for these analyses        To determine which tokens were used differentially by
are available from the authors as an R package (https://            ‘Excellent’ and other essays, we used the R pack-
bitbucket.org/petersmp/wordcountwrapper). Punctua-                  ages DESeq (Anders & Huber, 2010) accessed via
tion and non-standard characters were discarded, and all num-       rnaseqWrapper (Peterson et al., 2015). DESeq uses a nega-
bers were all replaced with a single 7. Root words were             tive binomial test on count data to determine whether or not
identified using the package SnowballC (Bouchet-Valat,              two groups (i.e. ‘Excellent’ and other essays) have differen-
2013). Character trigrams were identified and counted, with-        tial representation of a given token (i.e. word root, trigram,
out spaces between words, using the package tau (Buchta,            or LIWC category).
Hornik, Feinerer, & Meyer, 2014). Analysis of whole words              Designed for gene expression data, DESeq accurately
was similar to word roots, and trigram analysis including           models dispersion across samples by comparing similarly
spaces was similar to those without (data not shown).               used words to increase the accuracy of the test statistic.
                                                                    However, because it is designed for large scale sequencing
Standard dimensional reduction
                                                                    projects, the test statistic, particularly its false discovery rate
Since word root and trigram data is sparsely distributed, di-       corrected q-value, are likely to be overly conservative for this
mensional reduction is needed to make comparisons between           analysis. Therefore, we report uncorrected p-values but note
texts feasible. To do this, we initially used principal compo-      that these results should be interpreted with caution.
nent analysis (PCA), linear discriminant analysis (LDA), and
k-means clustering to analyze frequency data for trigrams,                                       Results
word roots, and LIWC categories. Token frequencies within
                                                                    Standard dimensional reduction
each essay were used rather than raw counts to avoid con-
founds with differences in essay length, as ‘Excellent’ essays      Conventional dimensional reduction methods failed to pro-
were approximately twice as long as others (1,269 vs 674            vide any insight into the differences between ‘excellent’ and
mean words, t(11.425) = 6.78, p<0.0001). Each method was            other essays for word roots and trigrams, but identified some
then compared to expert ratings to determine their value for        patterns in LIWC categories. Jackknifed LDA prediction of
future program evaluation.                                          sample ratings was non-significantly worse than chance for
   We compared PCA scores (for any component explain-               word roots and trigrams, and better than chance for LIWC
ing at least five percent of the variance) between ratings, us-     categories (Fisher’s exact test, p = 0.19, 0.66, and 0.19).
ing a t-test, to determine if any of the dimensions separated          PCA yielded 5 components in word roots, 7 components
our groups. To test the value of the LDA discrimination,            in trigrams, and 6 components in LIWC categories that each
we performed a jackknife analysis, serially omitting a sin-         explained at least five percent of variance (for a total of 57%,
gle rated sample, and then determining if the LDA test ac-          55%, and 83% of variance, respectively). None of these dif-
curately placed it after training on the remaining data. K-         fered between ‘Excellent’ and other ratings (t-test, all p >
means clusters were compared to expert ratings using Co-            0.05). For k-means with two clusters, Cohen’s kappa was
hen’s kappa statistic (Cohen, 1960) implemented in the R            0.35, 0.05, and 0.21 for word roots, trigrams, and LIWC (p =
package fmsb (Nakazawa, 2014) to determine if rated groups          0.06, 0.72, and 0.35), respectively.
could be reproduced.
                                                                    Distance measures
Distance measures from biology                                      Horn distance and non-metric dimensional scaling visualiza-
Many methods have been developed in ecology to assess               tion revealed a centralized cluster of essays rated as ‘excel-
the relative abundance of flora and fauna between divergent         lent,’ with a dispersion of other essays (Figure 1).
sites (Leinster & Cobbold, 2012). One of these measures,
the Horn similarity index (Horn, 1966), is now being used in        Differential token usage
bioinformatics due to its ability to accurately and efficiently     Between ‘Excellent’ and other essays, 25 trigrams, 5 root
handle large numbers of items and samples while account-            words, and 4 LIWC categories significantly differed in us-
ing for variation in total sampling depth (i.e. length of each      age (Figure 2). Essays rated as excellent used both and look
essay). We calculated Horn similarities for all pairs of sam-       more frequently than the others, which in turn had higher oc-
ples using the R package rnaseqWrapper (Peterson, Malloy,           currences of didn’t, American, and words beginning in cours.
Buonaccorsi, & Marden, 2015).                                       LIWC analysis showed that the top-rated essays used more
                                                                1064

                                                                                                                   0.3
                      0.3
                                                                                ●                                                                         ●                                                               ●
                             ●   Excellent                                                                                       ●                                                                                                                     ●
                                                                                                                                                                 ●
                             ●   Other                  ●
                                                                                                                   0.2                            ●                                     ●
                      0.2                                                                                                                                                                                5
                                                                            ●                  ●                                                                                                                    ●
                                               ●                                                                   0.1                                                                                                                                 ●
                                                                                                                                                  ●                   ●                                                            ●
                      0.1                                                                                                            ●                      ●                                                                                                      ●
                             ●                                ●             ●                                                                                                                                       ●
                                                                                          ●
                                                                                                                                                                                                                               ●           ●
                                                                                                                                          ●                                                  ●                                         ●
               mds2                                                                                         mds2                                                                                  mds2
                                                                                                                   0.0
                                                                                                        ●                  ●                                                                             0    ●       ●    ●
                      0.0                          ●                                                                                                  ●
                                                                  ●         ●                                                                                   ●
                                                                                      ●
                                                                                                                                                                                                                                           ●       ●       ●
                                                                                                                   −0.1                       ●                                     ●                                ●         ●
                      −0.1          ●                       ●                                                                    ●
                                                                            ●                       ●                                                                                                                ●
                                                                                                                                                      ●
                                                                                                                                                                ●         ●
                                                                                          ●                        −0.2                                                                                  −5
                      −0.2                     ●                                                                                                                                                                                               ●
                                                                  ●
                                                                                                                                                          ●                                                                                                            ●
                                                                                ●                                  −0.3                   ●                                                                                ●
                      −0.3
                             −0.3       −0.2           −0.1           0.0           0.1       0.2                         −0.3   −0.2         −0.1    0.0       0.1           0.2           0.3               −6     −4   −2       0           2           4   6           8
                                                                  mds1                                                                                mds1                                                                         mds1
                                           (a) Trigrams                                                                                  (b) Word Roots                                                            (c) LIWC Categories
                                                              Figure 1: Non-metric scaling of pair-wise Horn similarity indices.
negation, in spite of using didn’t less, and more perception-                                                                                                 cluster of “Excellent” essays because they are focused on a
related terms. Less-successful essays had more longer words                                                                                                   single culture (and those cultures may cluster) rather than the
and social terms.                                                                                                                                             broader program goals and/or they may focus on a smaller
                                                                                                                                                              portion of the goals of the program (and cluster by the por-
                                        Discussion                                                                                                            tion of the program they cover). This type of analysis would,
We developed a toolkit that enables knowledge extraction                                                                                                      in part, require breaking the anonymity of the analysis and
from collections of free text where traditional clustering ap-                                                                                                use subject matter expertise to explore those possibilities.
proaches fail. This toolkit delineated student accomplish-                                                                                                       Specific visualization features for large data sets influence
ment of stated but hard-to-measure goals in a language out-                                                                                                   what knowledge viewers gain and remember (Ware, Gilman,
reach program and promises insights for a range of other ed-                                                                                                  & Bobrow, 2008). The bioinformatic visualization tools ap-
ucational objectives. Of particular note, the addition of two                                                                                                 plied here allowed for more meaningful knowledge extraction
bioinformatic tools, Horn similarities and DESeq, substan-                                                                                                    from a very limited text corpus.
tially improved these analyses. These tools revealed clus-
tering that were unlikely to be identified by traditional ap-
                                                                                                                                                              Differential word usage
proaches and identified several of the tokens that character-                                                                                                 In addition to this general pattern, we identified specific
ized high-quality essays.                                                                                                                                     words and trigrams that are used differently by writers of ‘Ex-
                                                                                                                                                              cellent’ versus other essays. In particular, ‘Excellent’ essays
Clustering                                                                                                                                                    never used the contraction didn’t, while other ratings used it
Traditional approaches to dimensional reduction and cluster-                                                                                                  on average 1.5 times per essay, suggesting that other ratings
ing failed to accurately identify groups, but the addition of                                                                                                 used less-polished language.
Horn similarites suggests why this may be the case. PCA,                                                                                                         In addition, ‘Excellents’ used the word root American less
LDA, and k-means clustering attempt to separate groups                                                                                                        than other ratings (1.13 vs 3.94 times per essay; similar rates
along a single axis at a time. The distance measures in the                                                                                                   for its component trigrams). This trend continued for focus
non-metric scaling, however, demonstrated that ‘Excellent’                                                                                                    on the student’s country: ‘Excellent’ essays used the word
essays are instead clustering in the middle.                                                                                                                  root ZZTopia (an anonymizer for assigned country) less than
   Collecting more essays might reveal separable, dispersed                                                                                                   other ratings (5.61 vs. 8.94 times per essay), though this dif-
clusters. Cluster dispersion can indicate mention or absence                                                                                                  ference was not statistically significant (p= 0.31). Together,
of specific LIM goals, e.g. changing perspective on one’s own                                                                                                 these differences strongly imply that students that are most
culture, or simply reflect an extraneous detail such as a spe-                                                                                                completely meeting the stated goals of LIM are those that are
cific food name. That is, addition of more sample essays may                                                                                                  focusing less on a specific country and more on the cross-
allow the identification of a single central cluster (the ‘Ex-                                                                                                cultural goals of the program.
cellent’s here) along with multiple edge clusters, each shar-
ing some common set distinguishing it from the high quality                                                                                                   Boundary conditions for LIWC
central group. The central distribution of ‘Excellent’ essays,                                                                                                LIWC analysis did not improve the clustering of essays,
however, impedes discovery of these dispersed clusters.                                                                                                       though a few categories differed between ‘Excellent’ and
   Furthermore, this centrality may suggest that ‘Excellent’                                                                                                  other essays. LIWC can be confounded by departing from the
essays share a core vocabulary. This could mean that: a) Ex-                                                                                                  original expressive writing prompt (Hu, Koestler, Stroup, &
cellents are not including extraneous information, particularly                                                                                               Gilman, 2013). The present findings confirm that the LIWC
about their assigned country, and/or b) Excellents are touch-                                                                                                 tool is distinct from low-knowledge word- and character-
ing on more of the core concepts from the program. That                                                                                                       based approaches, at the same time demonstrating additional
is, the clusters of other essays may diverge from the central                                                                                                 boundary conditions for LIWC.
                                                                                                                                                     1065

          Color Key                         Color Key                         Color Key
          −2  0   2                      −3  −1     1 2 3                  −2 −1  0    1   2
         Row Z−Score                       Row Z−Score                      Row Z−Score
                                                  szz
                                                  nim
                                                  iaw                               cours
                                                                                                                  Sixltr
                                                  opu
                                                  wto
                                                  wea
                                                  dnt
                                                  ntf                               didnt
                                                  nfi
                                                  fid                                                             social
                                                  okn
                                                  owi
                                                  loo                               both
                                                  mas
                                                  bot
                                                  urs                                                             percept
                                                  erm
                                                  ack                               look
                                                  ook
                                                  mer
                                                  ric
                                                  ema
                                                                                                                  negate
                                                  ica                               american
                                                  can
                                                  our
                           (a) Trigrams                    (b) Word Roots                     (c) LIWC Categories
Figure 2: Heatmap of token usage by rating. For each essay (column), usage of each token (row) significantly differentially
used (by DESeq), with usage z-scale transformed by row (darker is higher usage). ‘Excellent’ essays are to the left in each
panel, denoted by the black bars above the heatmap.
No single assessment meets all needs                                spective accompanying service-learning activities, and aware
The educator who provided expert ratings on LIM essays              that self-report and implicit measures (including this one)
aimed to spend no more than several minutes per essay to ar-        can be gamed, we mined student-authored texts to supple-
rive at a broad rating of the writer’s success in learning from     ment (not replace) the administrator’s assessment data with-
LIM involvement. This rating was specifically not intended          out adding another instrument. Like Paquette, de Carvalho,
to follow from the grade the paper might receive considered         and Baker (2014), we see this project based on interactions
only as a piece of writing. Mining assignment text for stu-         with one expert as a starting point. The R package provides
dents’ attitude changes should provide different results than       tools to aid novices to NLP analysis the ability to rapidly cre-
expert ratings (Lee, Pincombe, & Welsh, 2005). The tools            ate substantial count data from a number of formats. The
presented here were applied to a comparison set of 113 essays       output count tables are intended to be ready to use in any of
from British students of anthropology and sociology (Nesi,          several analysis and visualization tools, including the ones
Gardner, Thompson, & Wickens, 2007), fields where per-              shown here. In addition, the package has a function to pro-
spective on one’s own and others’ culture matters. No sim-          vide context information (i.e., surrounding words) of any to-
ilar clustering patterns were found according to paper grade        ken of interest to aid exploratory analyses. Combined, these
or education stage, suggesting that our results are not based       tools may aid in increasing quantitative reporting to agencies
on writing quality but on learning from a described event.          on the effectiveness of difficult-to-assess program objectives
   Automated essay grading can invite attempts to game such         across higher education.
systems (Perelman, 2008). The present study seeks new ways
to describe holistic educational outcomes discovered in par-
                                                                                             Acknowledgments
ticipants’ words—a very different aim than that of grading.         Portions of this work were supported a summer grant to ATG
   We put 81 LIM essays (23 of which were rated) from 2013-         by the James J. Lakso Endowment for Faculty Excellence and
2016 through wordcountWrapper. Although the patterns de-            funding to MPP from Penn State University Huck Institues of
scribed here were not directly replicated, it is important to       the Life Sciences and Howard Hughes Medical Institute.
note that many of the essays were written by students that
went through the program after the initial analyses described                                     References
here were completed. It is possible that changes made in re-        Ananiadou, S., & McNaught, J. (2006). Text mining for biol-
sponse to insights developed with these tools are impacting           ogy and biomedicine. Boston, MA, USA: Artech House.
the depth and quality of student experiences. In particular,        Anders, S., & Huber, W. (2010). Differential expression anal-
looking at the context of key tokens such as ZZTopia revealed         ysis for sequence count data. Genome Biology, 11, R106.
that the more recent papers were describing difficult topics          Retrieved from http://genomebiology.com/2010/11/
about the featured country rather than merely listing topics.         10/R106/ doi: 10.1186/gb-2010-11-10-r106
The context tools in this package make such comparisons fea-        Baker, E. L., O’Neil, H. F., & Linn, R. L. (1993). Policy
sible even for hundreds of essays.                                    and validity prospects for performance-based assessment.
                                                                      American Psychologist, 48(12), 1210.
Conclusions                                                         Bender, E., & Good, J. (2010). A grand challenge for linguis-
Here, we have demonstrated the utility of applying bioinfor-          tics: Scaling up and integrating models. In Social, behav-
matic analysis and visualization to text mining for program           ioral, & economic sciences 2020. National Science Foun-
assessment. Lacking a consensus measure for changes in per-           dation (USA). (White Paper)
                                                                1066

Bouchet-Valat, M. (2013). Snowballc: Snowball stemmers                 of self-involvement in shifting IAT effects. Experimen-
  based on the c libstemmer utf-8 library [Computer software           tal Psychology, 59(6), 348–354. doi: 10.1027/1618-3169/
  manual]. Retrieved from http://CRAN.R-project.org/                   a000163
  package=SnowballC (R package version 0.5)                          Nakazawa, M. (2014). fmsb: Functions for medical statis-
Buchta, C., Hornik, K., Feinerer, I., & Meyer, D. (2014).              tics book with some demographic data [Computer software
  tau: Text analysis utilities [Computer software man-                 manual]. Retrieved from http://CRAN.R-project.org/
  ual]. Retrieved from http://CRAN.R-project.org/                      package=fmsb (R package version 0.4.3)
  package=tau (R package version 0.0-16)                             Nesi, H., Gardner, S., Thompson, P., & Wickens, P. (2007).
Buonaccorsi, V., Peterson, M., Lamendella, R., Newman, J.,             The British Academic Written English (BAWE) corpus, de-
  Trun, N., Tobin, T., . . . Roberts, W. (2014). Vision and            veloped at the Universities of Warwick.
  change through the genome consortium for active teach-             Oksanen, J., Blanchet, F. G., Kindt, R., Legendre, P.,
  ing using next-generation sequencing (gcat-seek). CBE-               Minchin, P. R., O’Hara, R. B., . . . Wagner, H. (2013).
  Life Sciences Education, 13(1), 1–2.                                 vegan: Community ecology package [Computer software
Chang, J.-S., & Su, K.-Y. (2004). Pitfalls in applying unsu-           manual]. Retrieved from http://CRAN.R-project.org/
  pervised learning to NLP. In IJCNLP-04. Hainan Island,               package=vegan (R package version 2.0-10)
  China.                                                             Paquette, L., de Carvalho, A. M., & Baker, R. S. (2014). To-
Cohen, J. (1960). A coefficient of agreement for nominal               wards understanding expert coding of student disengage-
  scales. Educational and Psychological Measurement, 37.               ment in online learning. In Proceedings of the 36th Annual
Ewell, P. T. (2009). Assessment, accountability, and im-               Cognitive Science Conference (pp. 1126–1131).
  provement: Revisiting the tensions. National Institute for         Pascarella, E. T., Wolniak, G. C., Seifert, T. A., Cruce, T. M.,
  Learning Outcomes Assessment (USA). (Occasional Pa-                  & Blaich, C. F. (2005). Liberal arts colleges and liberal
  per No. 1)                                                           arts education: New evidence on impacts. ASHE Higher
Faber, V., Hochberg, J. G., Kelly, P. M., Thomas, T. R., &             Education Report, 31, 1–168.
  White, J. M. (1994). Concept extraction: A data-mining             Pennebaker, J. W., & Chung, C. K. (2011). Expressive writ-
  technique. Los Alamos Science, 22, 123–149.                          ing: Connections to physical and mental health. Oxford
Francis, M. E., & Pennebaker, J. W. (1993). LIWC: Linguistic           handbook of health psychology, 417–437.
  inquiry and word count (Tech. Rep.). University of Texas           Pennebaker, J. W., Mehl, M., & Niederhoffer, K. (2003).
  at Austin.                                                           Psychological aspects of natural language use: Our words,
                                                                       our selves. Annual Review of Psychology, 54, 547–577.
Gawronski, B., LeBel, E. P., & Peters, K. R. (2007). What
                                                                     Perelman, L. (2008). Information illiteracy and mass market
  do implicit measures tell us?: Scrutinizing the validity of
                                                                       writing assessments. College Composition and Communi-
  three common assumptions. Perspectives on Psychologi-
                                                                       cation, 60, 128–141.
  cal Science, 2(2), 181-193. doi: 10.1111/j.1745-6916.2007
                                                                     Peterson, M., Malloy, J., Buonaccorsi, V., & Marden, J.
  .00036.x
                                                                       (2015). Teaching rnaseq at undergraduate institutions: A
Horn, H. S. (1966). Measurement of ‘overlap’ in comparative
                                                                       tutorial and r package from the genome consortium for ac-
  ecological studies. American Naturalist, 100, 419–424.
                                                                       tive teaching. CourceSource.
Hu, H., Koestler, A., Stroup, S., & Gilman, A. (2013). Com-
                                                                     R Core Team. (2013). R: A language and environment for
  paring text characteristics of expressive and values writing.
                                                                       statistical computing [Computer software manual]. Vienna,
  In Annual meeting of the Eastern Psychological Associa-
                                                                       Austria. Retrieved from http://www.R-project.org/
  tion. New York, USA.
                                                                     Resnik, P., Garron, A., & Resnik, R. (2013). Using topic
Koppel, M., & Schler, J. (2003). Exploiting stylistic idiosyn-         modeling to improve prediction of neuroticism and depres-
  crasies for authorship attribution. In Proceedings of ijcai0́3       sion in college students. In Proceedings of the 2013 confer-
  workshop on computational approaches to style analysis               ence on empirical methods in natural language processing
  and synthesis (Vol. 69, p. 72).                                      (p. 1348-1353). Stroudsburg, PA, USA: Association for
Lee, M. D., Pincombe, B., & Welsh, M. (2005). A compari-               Computational Linguistics.
  son of machine measures of text document similarity with           Reynolds, C. R., Livingston, R. B., Willson, V. L., & Will-
  human judgments. In 27th annual meeting of the cognitive             son, V. (2010). Measurement and assessment in education.
  science society (cogsci2005) (pp. 1254–1259).                        Pearson Education International.
Leinster, T., & Cobbold, C. A. (2012). Measuring diversity:          Sboner, A., Mu, X. J., Greenbaum, D., Auerbach, R. K., &
  the importance of species similarity. Ecology, 93(3), 477–           Gerstein, M. B. (2011). The real cost of sequencing: higher
  489.                                                                 than you think! Genome biology, 12(8), 125.
Lyman, P., & Varian, H. R. (2003). How much informa-                 Ware, C., Gilman, A. T., & Bobrow, R. J. (2008). Vi-
  tion? 2003. University of California, Berkeley, California,          sual thinking with an interactive diagram. In G. Stapleton,
  USA. Retrieved from http://www.sims.berkeley.edu/                    J. Howse, & J. Lee (Eds.), Diagrams (Vol. 5223, p. 118-
  how-much-info-2003                                                   126). Springer.
Marini, M., Rubichi, S., & Sartori, G. (2012). The role
                                                                 1067

