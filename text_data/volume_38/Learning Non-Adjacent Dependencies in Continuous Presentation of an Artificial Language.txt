                                   Learning Non-Adjacent Dependencies in
                             Continuous Presentation of an Artificial Language
   Felix Hao Wang (wang970@usc.edu)a, Jason Zevin (zevin@usc.edu)a,b,c, Toby Mintz (tmintz@usc.edu)a,b,c
         a
           Department of Psychology, University of Southern California, 3620 McClintock Ave, Los Angeles, CA, 90089
                     b
                       Department of Linguistics, University of Southern California, Los Angeles, CA, 90089
                      c
                        Program in Neuroscience, University of Southern California, Los Angeles, CA, 90089
                            Abstract                                 While most studies on adjacent dependency learning
                                                                   report success, the same cannot be said for learning of non-
  Many grammatical dependencies in natural language
  involve elements that are not adjacent, such as between          adjacent dependencies. The studies to date have found
  the subject and verb in the child always runs. To date,          evidence of non-adjacent dependency learning only in
  most experiments showing evidence of learning non-               limited situations, with some studies reporting success in
  adjacent dependencies have used artificial languages in          learning and others reporting failure. Interestingly, a
  which the to-be-learned dependencies are presented in            characteristic of experiments that showed successful
  isolation by presenting the minimal sequences that               learning is that the minimal sequences that contained a
  contain      the    dependent      elements.    However,
  dependencies in natural language are not typically               dependency were presented as discrete chunks. In other
  isolated in this way. In this study we exposed learners          words, the chunks were surrounded by silences, and the
  to non-adjacent dependencies in long sequences of                edges of such a chunk consisted of the (non-adjacent)
  words. We accelerated the speed of presentation and              dependent elements. For example, studies that have probed
  learners showed evidence for learning of non-adjacent            non-adjacent dependency learning between words in
  dependencies. The previous pause-based positional                artificial languages typically have used trigrams in which
  mechanisms for learning of non-adjacent dependency               the dependent words were at the trigram edges, and subjects
  are challenged.
                                                                   were presented the trigrams one at a time, with silence
  Keywords:         implicit     learning;     non-adjacent        intervening between presentations (Gómez, 2002; Gómez &
  dependencies                                                     Maye, 2005; Gómez, Bootzin & Nadel 2006; Romberg &
                                                                   Saffran, 2013). With the one trigram at a time design, the
                         Introduction                              words immediately before and after the silences are salient
Sentences in natural languages contain grammatical                 for learning the dependencies given that they make up the
dependencies, such as those that arise from agreement              dependency. Similarly, in experiments investigating non-
marking between the sentence subject and the verb.                 adjacent dependencies between syllables in syllable
Sometimes these dependencies hold between adjacent words           sequences, learning occurred only when brief pauses were
(or morphemes), and sometimes the dependencies are non-            introduced before (and after) each syllable trigram (Peña et
adjacent. For example, the dependency between the                  al.,2002). When syllables were concatenated continuously,
singular subject child and the agreeing inflected verb runs in     participants showed no learning (see also Newport & Aslin,
the child runs is an adjacent dependency, whereas in, the          2004). In the studies just discussed, the fact that subjects’
child always runs it is non-adjacent. These dependencies           success in learning non-adjacent dependencies was
are expressed by hierarchical syntactic structures in formal       correlated with whether the trigrams containing the
syntactic grammars. However, there has been considerable           dependency were pre-segmented suggests that the chunked
interest in investigating learning mechanisms that could           presentation might have played an important role in
detect these dependencies in linear sequences within spoken        learning. One reason in which pre-segmenting the material
utterances.      Such mechanisms could be useful for               in this way could be helpful is that it places one or both
discovering syntactic structure in children acquiring a            dependent elements in an edge position. Indeed, Endress,
language, and could also aid proficient language users in          Nespor & Mehler (2009) argued that edges are privileged in
building syntactic parses. For example, there have been a          the kind of position-related computations they afford, and
number of studies using artificial and natural languages that      placement at edges could be an important constraint for
have investigated how language learners acquire non-               learning non-adjacent dependencies.
adjacent dependencies (e.g., Gómez, 2002; Newport &                   However, non-adjacent dependencies in natural language
Aslin, 2004; Peña, Bonatti, Nespor & Mehler, 2002;                 are not restricted to edge positions, and are often embedded
Romberg & Saffran, 2013; Pacton & Perruchet 2008), and             in longer sequences. Thus, learning the dependency
how early in the acquisition process such dependencies are         relations of a natural language may require learning non-
detected (Gómez, 2002; Gómez & Maye, 2005; Santelmann              adjacent dependencies of items that may not always occur at
& Jusczyk, 1998).                                                  boundaries marked by silences. Given the apparent
                                                                   difficulty in detecting non-adjacent dependencies of
                                                                   continuous sequences of syllables (Newport & Aslin, 2004;
                                                               1661

Peña et al., 2002; Gebhart, Newport, & Aslin 2009), the              Participants. Thirty-eight USC undergraduates              were
experiments presented here were designed to assess how               recruited. Half of them participated in                    each
detection and learning of word-level non-adjacent                    counterbalancing condition.
dependencies fairs when the critical sequences are
embedded in longer sequences, such that the dependent                Stimuli. We recorded speech from a native English speaker
items are not at edges.                                              and digitized the recording at a rate of 44.1 kHz. We
   In this study, we present non-adjacent dependencies with          recorded 9 novel words to form the non-adjacent
words concatenated together without pauses. Similar                  dependency: 3 at position 1 (rud, swech, voy), 3 at position
previous attempts without pauses with syllables (Newport &           2 (dap, wesh, tood) and 3 at position 3 (tiv, ghire, jub).
Aslin, 2004; Peña et al, 2002) have all reported failure to             After all the words were recorded in list intonation, we
learn. Instead of CV syllables in previous studies, our study        spliced the words from the recording. Each word by itself
used recorded monosyllabic words with a presentation rate            from the recording lasts between 300ms to 737ms, and we
close to the normal speech rate (3Hz). This temporal                 used the lengthen function in Praat (Boersma, 2001) to
characteristic is significantly different from previous              shorten all the words into approximately 250ms. An
experiments with words, when individual words were                   additional 83ms of silence was added to the end of each
presented every 0.75 seconds (Gomez, 2002; Romberg &                 word to increase its intelligibility. Thus, words occurred at a
Saffran, 2013). We believe that this faster rate may facilitate      rate of 3Hz.
learning in a number of ways, for a number of reasons. For
one, previous theories suggested that speech processing              Design and Procedure. The experiment consisted of three
generally occurs at the theta rate (for a review, see Kiebel,        blocks, each with a training phase and a number of testing
Daunizeau & Friston, 2008). For another, faster presentation         trials. Each learning trial consisted of listening to materials
may expand short memory capacity (Frensch & Miner,                   passively. Each learning trial contained 144 non-adjacent
1994). Moreover, it has been suggested that presenting               dependency triplets. Given the word presentation rate of
auditory material rapidly may aid auditory statistical               3Hz, each sentence lasted 1 second, and each learning trial
learning (Emberson, Conway & Christiansen 2011). Thus,               lasted 2.4 minutes. There were no extra pauses between any
presenting auditory materials rapidly arguably presents the          novel words of artificial language. The testing section
best chance for people to learn non-adjacent dependencies            consisted of a set of 18 question trials. Each question trial
in speech.                                                           involved participants giving a familiarity rating after hearing
   We recently described the effect of presenting English            a three word sequence. Half of the 18 questions play a
sentences for entraining grammatical boundaries to aid               triplet from the language with the correct dependency, and
learning non-adjacent dependencies (Wang, Zevin & Mintz,             the other half from the counterbalancing condition, with
under review). We found that non-adjacent dependency is              order of presentation randomized each time.
learnable with English bracketing the boundaries of the                 Each novel sentence was a concatenation of 3 novel
dependency. However, whether non-adjacent dependency is              words, 1 each from choices of 3 for each position, as
learnable without English is unknown, especially under the           specified in the Stimuli section. We denote the words
current learning conditions, where no pauses are inserted to         making up the dependencies with A and B, and the words
indicate where the dependency boundaries are. The                    filling up other positions with X (and Y). The pattern we
variability at the intermediate position of the dependency           tested in Experiment 1 can thus be represented as AXB. All
has also been theorized to influence the learnability of non-        the possible combinations occurred for AiXBi where the first
adjacent dependency, where dependency with low                       position word predicted the third position word. As such,
variability is generally hard to learn (Gomez, 2002). In the         there were 3 AB pairs and 3 X words, which made 9
current paper, we employed low variability (n=3) in the              possible different artificial sentences. A counterbalancing
intermediate position. To summarize, we used no pauses to            condition was created such that the ungrammatical strings
indicate dependency boundaries, and low variability in               that occurred in the test are grammatical in the training
intermediate position of the dependency, both of which has           sequence in the counterbalancing condition, similar to
been theorized to exacerbate the learning problem.                   Gomez (2002). That is to say, where AiXBi is grammatical
   However, we found that the fast presentation rate is              in one condition and AiXBj is ungrammatical, the reverse is
enough to yield learning in all three experiments, and that          true for the other condition, and both conditions use the
makes this the first demonstration of learning of non-               same test items.
adjacent dependencies at the syllable/word level. Given all
of the failures to learn in the literature, we present the first     Training phase. At the start of the experiment subjects
success demonstration of learning word level non-adjacent            heard the following instructions:
dependencies (Experiment 1). We consequently replicated              “In this study, you will be presented with rapid succession
the finding with similarly designs (Experiment 2 & 3).               of made-up words. Press Space to start listening.”
                                                                        Participants listened to the sound stream passively while
                       Experiment 1                                  the screen was blank during the training phase.
Methods
                                                                 1662

 Testing phase. Immediately after a training phase, we                        Figure 1. Rating data from all three experiments. The
 showed the instructions for the testing section on the screen.               mean and the 95% confidence interval were plotted for
 The instruction made it clear that participants would hear                   each item type (grammatical/ungrammatical). The bar
 word sequences and make judgments about them. There                          graph indicated that the grammatical items were
 were a total of 18 test trials during each testing section, half             judged to be more likely to be in the language than the
 of which were from the correct dependency, and the other                     ungrammatical items. All three experiments showed
 half from the counterbalancing condition (i.e.,                              significant learning.
 ungrammatical). The sequence of presenting the test trials
 was randomized for each participant.                                   Discussion
    Participants initiated each test trial. Per trial, participants     Experiment 1 demonstrated that the non-adjacent
 clicked on a button to play an artificial language sentence,           dependency with one intermediate item can be learned
 and a question followed asking the participant to indicate             efficiently as long as the words are presented in quick
 whether some sequences are from the previous section that              succession. However, natural languages rarely have non-
 they have heard. A scale with radio buttons showed up after            adjacent dependencies stack one after other. In Experiment
 playing the sentence and participants were asked to answer             2, we explore learning when there is a word between the
 the question “Do you think that you heard this sequence in             dependencies, with the pattern of YAXB. Success in
 the previous section?” There were five possible items to               Experiment 2 should also be considered as a conceptual
 choose from, “Definitely”, “Maybe”, “Not Sure”, “Maybe                 replication of Experiment 1.
 Not”, “Definitely Not”. Participants could click on any of
 the radio buttons to make their choice, and this trial ended
 and the next trial began.
                                                                                                Experiment 2
                                                                        Experiment 2 tests non-adjacent dependency learning with
 Results                                                                the pattern is YAXB, where A & B words formed the
                                                                        dependency. Whereas Experiment 1 presented triplets with
 For each question in the testing section, participants rated           the dependency continuously, Experiment 2 has the triplet
 their familiarity for a given test sequence. We coded the              portion (AXB) separated from the next dependency by a
 scale of “Definitely”, “Maybe”, “Not Sure”, “Maybe Not”                word (Y). The choice of Y words is random with respect to
 and “Definitely Not” into numeric values of 1 through 5                other parts of the artificial language.
 (Definitely = 1). This allowed us to compared ratings for
 grammatical items vs. the ungrammatical items.
                                                                        Methods
   Next, we examined the means and standard error of the
 ratings. We show the rating information of grammatical and             Participants. Thirty-eight USC undergraduates participated
 ungrammatical items by block in Figure 1. To compare                   in Experiment 2. These participants have not participated in
 ratings statistically, we ran mixed effect linear regressions          other experiments reported here. Half of the participants
 with the data. In the regression, ratings were compared with           were in each counterbalancing condition.
 test item (correct vs. incorrect) as the fixed effect, and
 subject as the random effect. We found that participants               Stimuli. We used the stimuli in Experiment 1. We used 12
 were able to learn the non-adjacent dependency in general              novel words to form the non-adjacent dependency: 3 at
 (β= -0.160, p<0.001).                                                  position 1 (blit, pel, tink), 3 at position 2 (rud, swech, voy),
                                                                        3 at position 3 (dap, wesh, tood) and 3 at position 4 (tiv,
                                                                        ghire, jub). There are four positions in Experiment 2
Mean             Experiment Results                                     because the pattern is YAXB where A & B formed the
Rating                                                                  dependency.
   2.7                                                                     Again, all the words were approximately 250ms long with
                                                                        an additional 83ms of silence was added to the end of each
   2.5                                                                  word. When words are concatenated in a continuous stream,
                                                                        they would occur at a rate of 3Hz.
   2.3
   2.1                                              Ungrammatical       Design and procedure. The experiment consisted of three
                                                                        blocks, each with a training period followed by a sub-block
                                                    Grammatical
   1.9                                                                  of 18 question trials. Each learning period consisted of
                                                                        listening to materials passively. Each learning trial
   1.7                                                                  contained 144 non-adjacent dependency triplets. Given that
                                                                        words were at 3Hz and each sentence contained 4 words,
   1.5                                                                  each sentence took a second and a third. Each learning trial
            Exp1         Exp2       Exp3                                lasted 3.2 minutes. During the testing, each testing section
                                                                        contains 18 questions, half from the language and half from
                                                                    1663

the counterbalancing condition, with order of presentation             Participants. Thirty-eight USC undergraduates participated
randomized each time.                                                  in Experiment 2. These participants have not participated in
                                                                       other experiments reported here. Half of the participants
Training phase. At the start of the experiment subjects                were in each counterbalancing condition.
heard the following instructions:
“In this study, you will be presented with rapid succession            Stimuli. In Experiment 3, we explore learning when there
of made-up words. Press Space to start listening.”                     are two intermediate items between the dependencies, with
  Participants listened to the sound stream passively while            the pattern of AXYB. We used the stimuli in Experiment 1.
the screen was blank during the training phase.                        We used 12 novel words to form the non-adjacent
                                                                       dependency: 3 at position 1 (rud, swech, voy), 3 at position
Testing phase. Immediately after a training phase, we                  2 (blit, pel, tink), 3 at position 3 (dap, wesh, tood) and 3 at
showed the instructions for the testing section on the screen.         position 4 (tiv, ghire, jub).
The instruction made it clear that participants would hear                Again, all the words were approximately 250ms long with
word sequences and make judgment about the sequences.                  an additional 83ms of silence was added to the end of each
There were a total of 18 test trials during each testing               word. When words are concatenated in a continuous stream,
section, half of which were from the correct dependency,               they would occur at a rate of 3Hz.
and the other half from the counterbalancing condition. The               The experiment consisted of three blocks, each with a
sequence of presenting the test trials was randomized for              training period followed by a sub-block of 18 question
each participant.                                                      trials. Each learning phase consisted of listening to materials
   Participants initiated each test trial. Per trial, participants     passively. Each learning trial contained 216 non-adjacent
clicked on a button to play an artificial language sentence,           dependency triplets. Given that words were at 3Hz and each
and a question followed asking the participant to indicate             sentence contained 3 words, each sentence took a second.
whether some sequences were from the previous section that             Each trial lasted 3.6 minutes. There were no extra pauses
they have heard. A scale with radio buttons showed up after            between any novel words of artificial language. During the
playing the sentence and participants were asked to answer             testing, each testing section contains 18 questions, half from
the question “Do you think that you heard this sequence in             the language and half from the counterbalancing condition,
the previous section?” There were five possible items to               with order of presentation randomized each time.
choose from, “Definitely”, “Maybe”, “Not Sure”, “Maybe
Not”, “Definitely Not”. Participants could click on any of             Training phase. At the start of the experiment subjects
the radio buttons to make their choice, and this trial ended           heard the following instructions:
and the next trial began.                                              “In this study, you will be presented with rapid succession
                                                                       of made-up words. Press Space to start listening.”
Results                                                                   Participants listened to the sound stream passively while
                                                                       the screen was blank during the training phase.
We examined the means and standard error of the ratings
(Figure 1). To compare ratings statistically, we ran mixed
                                                                       Testing phase. Immediately after a training phase, we
effect linear regressions with the data. In the regression,
                                                                       showed the instructions for the testing section on the screen.
ratings were compared with test item (correct vs. incorrect)
                                                                       The instruction made it clear that participants would hear
as the fixed effect, and subject as the random effect. We
                                                                       sound sequences and make judgment about the sequences.
found that participants were able to learn the non-adjacent
                                                                       There were a total of 18 test trials during each testing
dependency in general (β= -0.101, p=0.021).
                                                                       section, half of which were from the correct dependency,
   Experiment 1 & 2 demonstrate that the non-adjacent
                                                                       and the other half from the counterbalancing condition. The
dependency with one intermediate item can be learned
                                                                       sequence of presenting the test trials was randomized for
efficiently as long as the words are presented in quick
                                                                       each participant.
succession.
                                                                          Participants initiated each test trial. Per trial, participants
                                                                       clicked on a button to play an artificial language sentence,
                        Experiment 3                                   and a question followed asking the participant to indicate
Natural languages are not restricted to have only one word             whether some sequences are from the previous section that
in between the dependency (e.g., the child very rarely runs).          they have heard. A scale with radio buttons showed up after
In cases where there is more than one item in between the              playing the sentence and participants were asked to answer
items that form the dependency, it has been suggested that             the question “Do you think that you heard this sequence in
learning becomes more difficult (Santelmann & Jusczyk,                 the previous section?” There were five possible items to
1998). In Experiment 3, we explore learning when there are             choose from, “Definitely”, “Maybe”, “Not Sure”, “Maybe
two intermediate items between the dependencies, with the              Not”, “Definitely Not”. Participants could click on any of
pattern of AXYB.                                                       the radio buttons to make their choice, and this trial ended
                                                                       and the next trial began.
Methods
                                                                   1664

Results                                                            require the presence of pauses as a prosodic cue, contrary to
We examined the means and standard error of the ratings            previous theories (see Peña et al. 2002, for a discussion).
(Figure 1). To compare ratings statistically, we ran mixed         Peña et al. 2002 argued that successful learning requires a
effect linear regressions with the data. In the regression,        prosodic analysis whereby boundaries and positional
ratings were compared with test item (correct vs. incorrect)       information is obtained before non-adjacent dependencies
as the fixed effect, and subject as the random effect. We          are learnable. Across all the previous studies that report
found that participants were able to learn the non-adjacent        success on non-adjacent dependency learning with spoken
dependency in general (β= -0.261, p<0.001).                        artificial language (Peña et al. 2002; Newport & Aslin,
   In sum, we found that robust learning is present even           2004), this has been the case. The current work suggests that
when there are 2 items between the words forming the non-          pauses are not a necessary condition for learning non-
adjacent dependency.                                               adjacent dependencies. In the absence of explicit pauses, we
                                                                   speculate that the learning mechanism may still have access
                                                                   to virtual boundaries that arise via a distributional analysis
                          Discussion                               that detects simpler repeated patterns. There may be some
As we mentioned, learning non-adjacent dependencies in             kind of distributional or syntactic analyses that can make
the lab has been demonstrated in very restricted situations.       uses of these positional boundaries which in turn may
There are a variety of reasons for this. For the most part,        reduce the computational load for calculating dependency
past literature suggested (Newport & Aslin, 2004; Peña et          relations between non-adjacent items, and induce the
al., 2002) that pauses are critical to the learning of non-        detection of higher order dependencies, such as non-
adjacent dependencies. Our design does not contain pauses,         adjacent dependency in the current paper. Future work
which makes our study the first we know that showed                should examine these possibilities. In sum, the position
success of learning non-adjacent dependencies without              based accounts (Endress et al., 2009) may still apply to the
resorting to pauses. There have been studies of non-adjacent       current findings, except that positional information may not
dependencies with auditory artificial language where the           come from prosodic processes, but it may be obtained from
non-adjacent dependency is embedded in which dependent             distributional analysis as well.
items sometimes occur at edges enables the detection of               One methodological note is regarding the measure we
non-adjacent patterns (Mintz et al., 2014; Reeder, Newport         took, which is a rating scale of confidence. This is different
& Aslin, 2013; Wang & Mintz, under review). In the cases           from how artificial language is assessed in the past
where successful learning of non-adjacent dependencies has         literature, which involves a variant of this question, “Have
been reported, at least one edge (beginning or ending) is          you heard this sentence in the language before?”, “Is this
marked with pauses (Mintz et al., 2014; Reeder, Newport &          sentence in the language?”, etc, requiring a yes/no answer
Aslin, 2013). When both edges are not marked with pauses,          from participants. There are a number of problems with this
learning failed (Wang & Mintz, under review). It is possible       approach, most of which involves the interpretation of the
that having exposure to elements at edge positions                 phrase “in the language”. What does it mean to a naïve
facilitated, detecting non-adjacent dependencies at least          participant that a novel sentence is in a novel language?
initially. However, natural languages contain non-adjacent         Does it mean that the sentence literally heard? Or does it
dependencies at non-edge positions, thus making it difficult       mean that it follows some kind of a rule? Regardless, given
to evaluate learning theories that requires the presence of        any interpretation of “in the language”, participants also
pauses.                                                            need to decide on the criterion when a phrase is “close
   Why would the presentation rate make a difference?              enough” to be in the language. Many artificial language
There are a number of possibilities. The auditory system for       studies from our labs suggest that participants may simply
speech perception may be tuned towards a particular                answer yes to all questions, because it is not clear to them
frequency (Kiebel, Daunizeau & Friston 2008), so efficient         what the experimenter is asking (for similar results, see
speech processing may play a role. This line of explanation        Gómez, 2002). In light of these findings, we used a rating
is along the lines of modality-specific statistical learning       scale instead of collecting yes/no responses. Rating that
theories (Emberson, Conway, & Christiansen 2011). They             making subjects make explicit judgments, we asked
argued for the central role of modality-specific processing        participants to report their confidence level that a phrase has
by contrasting the opposite influence of changing                  been heard. This measure, degrees of certainty, does not
presentation rate in visual and auditory statistical learning.     require any commitment to any type of meta-linguistic
These theories hold promising directions for understanding         knowledge of knowing what it means to be “in a language”,
the modality-specific statistical learning mechanisms, but         but rather, assesses familiarity with a phrase. Making use of
they are also vague regarding why specific kind of statistical     this measure has yielded much success with multiple
learning (in this case, non-adjacent dependency learning)          artificial language/statistical learning studies from our lab
would benefit from fast presentation. We leave these               already.
questions for future research.                                        Getting back to our study, we wish to emphasize the role
   Success in learning non-adjacent dependencies without           of the timing. There are other word level non-adjacent
pauses point to the possibility the non-adjacent dependency        dependency studies (Gómez, 2002; Romberg & Saffran,
learning mechanisms with spoken language do not critically
                                                               1665

2013), but the timing profile is different. In those                 Gómez, R. L., & Maye, J. (2005). The developmental
experiments, utterances were concatenated words, such that             trajectory of nonadjacent dependency learning. Infancy, 7,
there was around 0.8 s between word onsets. This is a                  183-206.
relatively slow rate of speech, which can be considered              Gómez, R. L., Bootzin, R. R., & Nadel, L. (2006). Naps
unnatural as far as speech perception is concerned in terms            promote abstraction in language-learning infants.
of its timing characteristics. It is conceivable that this mode        Psychological Science, 17(8), 670-674.
of presentation makes detecting patterns of non-adjacent             Kiebel, S. J., Daunizeau, J., & Friston, K. J. (2008). A
elements more difficult because they are not temporally                hierarchy of time-scales and the brain. PLoS
close.                                                                 computational biology, 4(11).
  Lastly, existing theories (Gomez, 2002, among others)              Mintz, T. H., Wang, F. H., & Li, J. (2014). Word
suggest that the dependency is hard to detect without highly           categorization from distributional information: Frames
variable middle elements. This is different from our design            confer more than the sum of their (Bigram) parts.
in important ways. In our design, the variability of the               Cognitive psychology, 75, 1-27.
middle elements (n=3) is very low according to Gomez                 Pacton, S., & Perruchet, P. (2008). An attention-based
2002, making the dependency hard to learn. We show that                associative account of adjacent and nonadjacent
this hard problem of learning of non-adjacent dependency               dependency learning. Journal of Experimental
can be solved when the non-adjacent dependency is                      Psychology: Learning, Memory, and Cognition, 34(1), 80.
presented at a typical speech rate. It remains possible that         Peña, M., Bonatti, L. L., Nespor, M., & Mehler, J. (2002).
the variability issue is important when the presentation rate          Signal-driven computations in speech processing.
of speech is slow, but at least with fast presentation rate, low       Science, 298(5593), 604-607.
variability does not seem to lead to failure to learn. Future        Newport, E. L., & Aslin, R. N. (2004). Learning at a
work is needed to examine whether increase variability will            distance I. Statistical learning of non-adjacent
make learning more robust.                                             dependencies. Cognitive psychology, 48(2), 127-162.
  In sum, we have shown that temporally controlled word-             Reeder, P. A., Newport, E. L., & Aslin, R. N. (2013). From
level non-adjacent dependency is learnable without pauses.             shared contexts to syntactic categories: The role of
We propose that learning about distributional analysis may             distributional information in learning linguistic form-
be best obtained the learning material is presented at the             classes. Cognitive psychology, 66(1), 30-54.
optimal rate is critical, and the importance of the speech rate      Romberg, A. R., & Saffran, J. R. (2013). All together now:
may outweigh constraints previously proposed, such as                  Concurrent learning of multiple structures in an artificial
presence of pauses and variability in the middle element.              language. Cognitive Science, 37(7), 1290-1320.
                                                                     Santelmann, L. M., & Jusczyk, P. W. (1998). Sensitivity to
                           References                                  discontinuous dependencies in language learners:
Boersma, Paul (2001). Praat, a system for doing phonetics              Evidence for limitations in processing space. Cognition,
  by computer. Glot International (2001): 341-345.                     69(2), 105-134.
Chemla, E., Mintz, T. H., Bernal, S., & Christophe, A.               Shi, R., & Melançon, A. (2010). Syntactic Categorization in
  (2009). Categorizing words using ‘frequent frames’: what             French‐Learning Infants. Infancy, 15(5), 517-533.
  cross‐linguistic analyses reveal about distributional              Turk-Browne, N. B., Jungé, J. A., & Scholl, B. J. (2005).
  acquisition strategies. Developmental Science, 12(3), 396-           The automaticity of visual statistical learning. Journal of
  406.                                                                 Experimental Psychology: General, 134, 552-564.
Emberson, L. L., Conway, C. M., & Christiansen, M. H.                Van den Bos, E., & Christiansen, M.H. (2009). Sensitivity
  (2011). Timing is everything: Changes in presentation                to non-adjacent dependencies embedded in sequences of
  rate have opposite effects on auditory and visual implicit           symbols. Proceedings of the 31st Annual Meeting of the
  statistical learning. The Quarterly Journal of                       Cognitive Science Society.
  Experimental Psychology, 64(5), 1021-1040.                         Vuong, L.C., Meyer, A.S. & Christiansen, M.H. (in press).
Endress, A.D., Nespor, M. & Mehler, J. (2009). Perceptual              Concurrent statistical learning of adjacent and non-
  and memory constraints on language acquisition. Trends               adjacent dependencies. Language Learning.
  in Cognitive Sciences, 13(8), 348-353.                             Wang, H., Höhle, B., Ketrez, N. F., Küntay, A. C., & Mintz,
Frensch, P. A., & Miner, C. S. (1994). Effects of                      T. H. (2011). Cross-linguistic Distributional Analyses
  presentation rate and individual differences in short-term           with Frequent Frames: The Cases of German and Turkish.
  memory capacity on an indirect measure of serial                     In N. Danis, K. Mesh, & H. Sung (Eds.), Proceedings of
  learning. Memory & Cognition, 22(1), 95-110.                         the 35th annual Boston University Conference on
Gebhart, A. L., Aslin, R. N., & Newport, E. L. (2009).                 Language Development (pp. 628-640). Somerville, MA:
  Changing Structures in Midstream: Learning Along the                 Cascadilla Press.
  Statistical Garden Path. Cognitive Science, 33(6), 1087–           Wang, F. H., & Mintz, T. H. (under review). Learning Non-
  1116. http://doi.org/10.1111/j.1551-6709.2009.01041.x                Adjacent Dependencies Embedded in Sentences of an
Gómez, R. L. (2002). Variability and detection of invariant            Artificial Language: When Learning Breaks Down.
  structure. Psychological Science, 13(5), 431-436.
                                                                 1666

