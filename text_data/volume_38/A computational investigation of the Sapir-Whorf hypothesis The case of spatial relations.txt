                    A computational investigation of the Sapir-Whorf hypothesis:
                                                The case of spatial relations
                 Christine Tseng1 (ctseng@caltech.edu), Alexandra Carstensen2 (abc@berkeley.edu),
                   Terry Regier3 (terry.regier@berkeley.edu), Yang Xu3 (yang_xu_ch@berkeley.edu)
                 1 Computation and Neural Systems, California Institute of Technology, Pasadena, CA 91125 USA
                           2 Department of Psychology, University of California, Berkeley, CA 94720 USA
           3 Department of Linguistics, Cognitive Science Program, University of California, Berkeley, CA 94720 USA
                              Abstract                                   tematic way, because of general principles. We pursue these
                                                                         questions here.
   Investigations of the Sapir-Whorf hypothesis often ask whether
   there is a difference in the non-linguistic behavior of speak-
   ers of two languages, generally without modeling the underly-            Our empirical focus is the semantic domain of topolog-
   ing process. Such an approach leaves underexplored the rela-          ical spatial relations. Earlier investigations have revealed
   tive contributions of language and universal aspects of cogni-        wide yet constrained cross-language variation in spatial se-
   tion, and how those contributions differ across languages. We
   explore the naming and non-linguistic pile-sorting of spatial         mantic categories (Levinson & Meira, 2003), and have also
   scenes across speakers of five languages via a computational          revealed that non-linguistic cognition about such spatial re-
   model grounded in an influential proposal: that language will         lations reflects both universal forces and some influence of
   affect cognition when non-linguistic information is uncertain.
   We report two findings. First, native language plays a small          native language (Khetarpal, Majid, Malt, Sloman, & Regier,
   but significant role in predicting spatial similarity judgments       2010; Carstensen et al., under revision). However, while doc-
   across languages, consistent with earlier findings. Second, the       umenting the interesting interplay of universal and linguis-
   size of the native-language role varies systematically, such that
   finer-grained semantic systems appear to shape similarity judg-       tic forces in apparently non-linguistic spatial cognition, such
   ments more than coarser-grained systems do. These findings            earlier studies did not explore that interplay using a compu-
   capture the tradeoff between language-specific and universal          tational model, and did not illuminate under which circum-
   forces in cognition, and how that tradeoff varies across lan-
   guages.                                                               stances language shapes cognition.
   Keywords: Linguistic relativity; Sapir-Whorf hypothesis; se-             In addressing these open questions, our theoretical starting
   mantic universals; name strategy; categorization; spatial rela-
   tions; computational models.                                          point is an influential proposal from the literature. In a clas-
                                                                         sic study of language and color cognition, Kay and Kempton
                          Introduction                                   (1984) proposed what they called the name strategy: that
                                                                         language will affect cognition when non-linguistic aspects of
Languages partition human experience into semantic cate-                 cognition are ambiguous, uncertain, or otherwise ineffective.
gories in different ways. For example, the Mandarin Chi-                 Their empirical findings were consistent with this idea. We
nese spatial term shang4 denotes a set of spatial relations that         instantiate the name strategy in a computational model, apply
is roughly equivalent to those described by English on and               the model to data from the spatial domain, and explore the
above combined. Do such differences affect how speakers of               above open questions in terms of the theoretical framework
different languages apprehend and think about the world?                 this model provides.
   The Sapir-Whorf hypothesis (Sapir, 1929; Whorf, 1956)
is commonly framed in terms of this question. When the                      In what follows, we first describe the data we consider,
question is posed this way, in simple yes-or-no terms, it in-            which are drawn from five languages: Dutch, English,
vites an equally simple answer: that language either does                Chichewa, Mandarin, and Maihiki. We then present our com-
or does not influence cognition. However, empirical stud-                putational model, and show how it instantiates the name strat-
ies have provided conflicting answers to this question across            egy. We then analyze the data through the lens of the model.
a variety of semantic domains (Roberson, Davies, & David-                To preview our results, we find: (1) that across all five lan-
off, 2000; Gilbert, Regier, Kay, & Ivry, 2006; Brown, Lind-              guages, native language plays a small but significant role in
sey, & Guckes, 2011; Malt, Sloman, Gennari, Shi, & Wang,                 predicting spatial similarity judgments, consistent with ear-
1999; Munnich, Landau, & Dosher, 2001; Kranjec, Lupyan,                  lier findings, and (2) that the size of the native-language
& Chatterjee, 2014; Majid, Bowerman, Kita, Haun, & Levin-                role varies systematically across languages, such that finer-
son, 2004). This inconsistent pattern of results suggests that           grained semantic systems appear to shape similarity judg-
a slightly more complex formulation of the hypothesis may                ments more than coarser-grained systems do. We argue that
be warranted. Concretely, rather than asking whether lan-                these findings contribute to the debate over the Sapir-Whorf
guage does or does not shape cognition, it may be useful to              hypothesis by grounding the tradeoff between universal and
ask under which circumstances it does, to what extent, and               language-specific forces in a computational model based on
whether that extent itself varies across languages in a sys-             an independently proposed principle: the name strategy.
                                                                     2231

                              Data                                   took part in a nonlinguistic pile-sorting task and subsequently
To investigate the relation of spatial language and cogni-           completed a naming task; English speakers’ pile-sorting data
tion, we compare linguistic and nonlinguistic categoriza-            is from Khetarpal et al. (2010) but their naming data is from
tion of spatial scenes across five languages: Dutch, English,        Carstensen et al. (under revision) for which naming instruc-
Chichewa, Mandarin, and Maihiki. Maihiki is an under-                tions are more closely aligned with those of the other studies.
documented language of Peruvian Amazonia, presently being
                                                                     Pile-sorting task
investigated by Lev Michael and colleagues at Berkeley. The
spatial scenes were those of the Topological Relations Picture       Participants sorted the 71 scenes in the TRPS into piles based
Series (TRPS) (Bowerman & Pederson, 1992). This stimulus             on the similarity of the spatial relations depicted in the scenes.
set contains 71 spatial relational scenes, each of which depicts     Each scene showed an orange figure object positioned relative
a spatial relationship between a figure object and a ground ob-      to a black ground object and participants were instructed to
ject. Figure 1 shows a small subset of the TRPS scenes, and          group the scenes into piles based on the similarity of these
the semantic categories in which these scenes fall for some of       spatial relations, such that the relation was similar for all
the languages we consider. It can be seen that there is consid-      cards in a given pile. Participants were informed that they
erable variation in spatial categories across these languages.       could make as few or as many piles as they chose, rearrange
                                                                     their piles as they felt necessary, and could take as much time
                                                                     as they wanted.
                                                                     Naming task
                                                                     After completing the sorting task, the same participants were
                                                                     asked to name the spatial relation depicted on each card. For
                                                                     languages other than Maihiki, labels picking out the figure
                                                                     and ground objects were supplied in the participant’s native
                                                                     language and the participant filled in a blank to complete a
                                                                     sentence specifying the figure object’s location relative to the
                                                                     ground object. For example, for the scene depicting a cup
                                                                     on a table, English-speaking participants were presented with
                                                                     the partial sentence “The cup is (blank) the table”, and were
                                                                     asked to fill in the blank. Maihiki speakers were asked to
Figure 1: Cross-linguistic naming variation in the spatial do-       produce full sentences, supplying names for the figure and
main. Each scene depicts a spatial relation between a figure         ground objects and describing the spatial relation between
object (in orange) and a ground object (in black). The scenes        them; verbal clarification of the scenes was given in Span-
are grouped differently by different languages.                      ish when necessary. In keeping with earlier work, the labels
                                                                     produced in the naming task were sanitized to collapse over
   The data on which we rely were collected previously by            responses that differed in components without spatial mean-
Khetarpal et al. (2009, 2010, 2013), Carstensen (2011), and          ing (e.g. variations in verb tense).
Carstensen et al. (under revision). Below we briefly describe
the data collection procedure used in those prior studies.           Treatment of the data
                                                                     We aggregated these data into separate language-specific and
Participants                                                         universal components, for use in our computational analyses
A total of 47 native English speakers (24 from Khetarpal             below. For each language l, we constructed a 71 × 71 co-
et al., 2010; 23 from Carstensen et al., under revision),            naming matrix Ll , such that entry Lil j of that matrix contained
24 native Dutch speakers (Khetarpal et al., 2009), 38 na-            the proportion of speakers of language l who supplied the
tive Chichewa speakers (Carstensen, 2011), 7 native Maihiki          same spatial term for scenes i and j. For instance, if 12 out
speakers (Khetarpal et al., 2013), and 17 native speakers of         of 16 speakers of language l supplied the same spatial term
Mandarin Chinese (Carstensen et al., under revision) pile-           in l for scenes i and j, then Lil j = 12/16 = 0.75. Thus the Ll
sorted and then named spatial scenes. All English, Dutch,            matrix summarizes which scenes tended to receive the same
and Chichewa speakers were tested in their native languages          name vs. different names in language l. We analogously con-
and home countries (the United States, the Netherlands, and          structed, for each language l, a 71 × 71 co-sorting matrix Sl ,
Malawi, respectively). Mandarin Chinese speakers were re-            such that entry Sil j of that matrix contains the proportion of
cruited on the UC Berkeley campus and tested in their na-            speakers of language l who sorted scenes i and j into the same
tive language. Speakers of Maihiki were tested in their home         pile. Finally, we approximated a universal similarity space,
country of Peru, but as this is an endangered language with          U, by taking the average over the Sl matrices across lan-
very few speakers, they were tested in Spanish, in which all         guages l. Earlier studies (Khetarpal et al., 2010; Carstensen
Maihiki participants were also fluent. All participants first        et al., under revision) found that spatial sorting patterns were
                                                                 2232

broadly similar across languages,1 although they did reflect                                                       3
the sorter’s native language to some extent. Thus, U is an at-                                               ?             ?
tempt to retain what is common and discard what is different
                                                                                                             1               2
about pile-sorting behavior across languages.
               Computational formulation
                                                                                                                           N1
The core principle behind our analyses is the name strategy of                                    3                                     3
Kay and Kempton (1984). Figure 2 illustrates this principle
in the context of a simple pile-sorting scenario. Suppose there                                                                                      N2
are three stimuli (in our case three spatial scenes) here labeled                         1               2                      1              2
1, 2, and 3, and suppose that the task is to sort stimulus 3 into
one of two existing piles, which presently contain stimuli 1                          Universal similarity space               Linguistic categories
and 2 respectively. Assume further that the three stimuli are
equally distant from each other in a universal similarity space,
                                                                              Choice
so that it is entirely ambiguous on that basis which pile stimu-              probability
lus 3 should be sorted into. Finally, assume that the speaker’s
native language partitions these stimuli into two categories
                                                                                            1           2                          1          2
N1 and N2, where stimuli 1 and 3 are co-named under N1,                                   Universal model                       Linguistic model
and stimulus 2 is named under N2. The name strategy holds
that in such cases, where universal non-linguistic structure                              Figure 2: Illustration of the name strategy.
yields ambiguity or is otherwise ineffective, linguistic cate-
gory structure may provide additional information to resolve
the issue. In this case, stimuli 3 and 1 are co-named, which                predict which pile that scene was sorted into, using a leave-
should encourage stimulus 3 to be sorted into pile 1, tipping               one-out procedure. That is, for each scene i, we held out
the balance in that direction. The bars in the bottom panel of              pile membership for i and sought to predict pile membership
Figure 2 contrast the choice probabilities over the two piles               for i, based on pile membership for all other scenes j 6= i.2
for a hypothetical model that relies only on a universal sim-               We cast this prediction in probabilistic terms, and predicted
ilarity space, with those for a model that relies only on the               that this individual would place spatial scene i in that pile c
category structure of the language.                                         (for non-linguistic category) that yielded the highest posterior
    To capture the idea of the name strategy, we formulate                  probability p(c|i):
models that can be used to predict an individual’s pile-sorting
                                                                                                    p(c|i) ∝ p(i|c)p(c) ∝ f (i|c)                       (1)
behavior. These predictions are based on universal similar-
ity structure U, and on language-specific naming information                Here, we assume the individual has no preference for any
Ll , both as specified above, where l is the native language                pile to begin with, and we therefore place a uniform prior on
of the individual in question. We instantiate the name strat-               c. In determining the likelihood f (i|c), we considered three
egy through a residual predictive analysis: we first note how               possible strategies on which individuals might rely in sorting
much of an individual’s sorting behavior can be predicted by                scenes into piles, shown in Equation 2 below. These are: (a)
U, and then determine how much of that individual’s as-yet-                 a fixed clustering strategy: sort by average similarity between
unexplained (residual) sorting behavior can be predicted by                 a query scene i and all existing scenes j in a given pile c;
Ll , beyond what U can predict. This two-step procedure re-                 (b) a fixed nearest-neighbor or chaining strategy: sort based
quires that we specify a universal model based on U that we                 on maximum similarity between a query scene i and any of
employ in the first step, and a language-specific model based               the existing scenes j in a given pile c; and (c) a hybrid strat-
on Ll for the residual analysis, i.e. the items left unexplained            egy that varies on a trial-by-trial basis: choose between the
by U. This procedure provides a way to quantify the relative                clustering and chaining strategies according to which yields
contributions of universal and language-specific forces, and                higher likelihood. We formalize these strategies by specify-
to assess the degree to which those relative contributions may              ing the likelihood function as follows:
vary across languages.                                                                     1
    For each individual, we know the number of piles that in-                               |c| ∑ j∈c sim(i, j),
                                                                                                                                           clustering
dividual produced, and which scenes were sorted into each                      f (i|c) = max j∈c sim(i, j),                                 chaining
                                                                                           
pile. We sought to recapitulate the sorting process of that                                
                                                                                              max( f (i|c)clustering , f (i|c)chaining ), hybrid
individual. Concretely, for each query scene, we sought to                                                                                              (2)
    1 We verified the universal tendencies in pile sorting by correlat-          2 Ideally, we would like to predict scene-pile assignments in the
ing the S matrices (upper triangular parts due to symmetry) between         sequence in which they occurred during the experiment. However,
each pair of languages. We confirmed that pile sorting is largely sim-      only the end-state of the pile-sort was recorded, not the sequence that
ilar across speakers of different languages reflected in mean Pear-         led to it, so we used the leave-one-out procedure which is unaffected
son’s r = 0.98 (SD = 0.01) among the pairwise correlations.                 by the sorting sequence.
                                                                        2233

                                                                                                         Dutch            English         Chichewa         Mandarin         Maihiki
For each scene assignment, we chose the strategy that yielded                                       1                1               1                1                1
                                                                                                           U
the highest predictive accuracy. To distinguish between the                                        0.9     L        0.9             0.9              0.9              0.9
                                                                                                           chance
universal and language-specific models, we took sim(i, j) =                                        0.8              0.8             0.8              0.8              0.8
Ui j for the universal model, and sim(i, j) = Lil j for the linguis-                               0.7              0.7             0.7              0.7              0.7
                                                                             Predictive Accuracy
tic model, where l is the individual’s native language and U                                       0.6              0.6             0.6              0.6              0.6
and Ll are as defined above.                                                                       0.5              0.5             0.5              0.5              0.5
   To model a given individual’s behavior, we first conducted                                      0.4              0.4             0.4              0.4              0.4
a predictive analysis using the universal model, and noted
                                                                                                   0.3              0.3             0.3              0.3              0.3
which of that individual’s scene assignments were predicted
                                                                                                   0.2              0.2             0.2              0.2              0.2
correctly and which incorrectly. We then conducted a resid-
                                                                                                   0.1              0.1             0.1              0.1              0.1
ual predictive analysis using the language-specific model, on
                                                                                                    0                0               0                0                0
those scenes that were incorrectly predicted by the universal
model, and again noted which scenes were predicted correctly
                                                                             Figure 3: Summary of results of residual predictive analyses.
and which incorrectly.
                    Analyses and results
                                                                             for whom the language-specific model exhibits above-chance
We conducted such analyses for each speaker of each lan-
                                                                             residual predictive accuracy. We found that this proportion
guage. We then examined the results of those analyses with a
                                                                             is high across speakers of all the languages we considered
view to answering the open questions posed at the beginning
                                                                             (Chichewa: 30/38; Dutch: 21/24; English: 20/23; Maihiki:
of this paper. We did so in three sets of followup analyses,
                                                                             6/7; Mandarin: 15/17; Bonferroni-corrected p < 0.05 for
which we present below.
                                                                             each language except for Maihiki (uncorrected p = 0.05) un-
Relative contributions of universal and                                      der binomial tests assuming 0.5 probability of success per
language-specific forces                                                     speaker). Taken together, these findings provide evidence in
                                                                             support of the Sapir-Whorf hypothesis in this domain, and
One open question is the magnitude of the relative contri-
                                                                             contextualize it relative to what can be accounted for by uni-
bution of universal and language-specific forces to allegedly
                                                                             versal forces alone. It should be emphasized that this is a
non-linguistic tasks such as pile-sorting, when assessed using
                                                                             rather conservative test for an effect of language, in that any
the method outlined above.
                                                                             scene-pile assignment that would be correctly predicted by
   Figure 3 summarizes the results of the residual predic-
                                                                             both the universal model and the language-specific model will
tive analyses just described. For each language, the black
                                                                             be credited here to the universal model, as it was run first, in
bar shows the accuracy of the universal model in predicting
                                                                             keeping with our instantiation of the name strategy. Thus,
scene-pile assignments, averaged across speakers of that lan-
                                                                             it may be safest to think of these residual predictive accura-
guage. The white bar stacked on top of it shows the accuracy
                                                                             cies as providing a lower bound on the size of the language-
of the language-specific model in predicting residual scene-
                                                                             specific contribution.
pile assignments, i.e. those that the universal model failed
to predict, again averaged across speakers of that language.3                Native language compared with other languages
To establish a baseline in this language-specific residual pre-
dictive task, we considered chance predictions from a model                  Support for the Sapir-Whorf hypothesis would be strength-
that chooses scene-pile assignments randomly from among                      ened if we had evidence that an individual’s native language
the available piles. In this case, the chance-level accuracy for             outperformed other languages in residual predictive accuracy.
each individual is 1k where k is the number of piles that indi-              For example, is residual Maihiki pile-sorting better predicted
vidual generated during pile sorting, and the dashed horizon-                by Maihki naming than it is by Chichewa naming, or Man-
tal line for each language shows the chance level of residual                darin, or some other language? This pattern would be ex-
predictive accuracy for that language, averaged across speak-                pected if the sorter’s native language is in fact being called
ers of the language.                                                         upon during the putatively non-linguistic sorting process. We
   Overall, the universal model accounts for a substantial                   turn next to consider this question.
proportion of the pile-sort data for each language, suggest-                    To test this, we re-ran the residual predictive analyses de-
ing strong universal tendencies in people’s similarity judg-                 scribed above, but for each individual, instead of using that
ments about spatial relations. At the same time, for each lan-               individual’s native-language naming information (in the form
guage, the language-specific model predicts residual scene-                  of Ll for native language l), we used naming information from
pile assignments at rates above chance. To assess whether                    each other language (i.e. Lk for each language k 6= l). For ex-
this effect of language is significant at the level of indi-                 ample, to predict residual pile-sorting data for Dutch speak-
vidual speakers, we examined the proportion of individuals                   ers, we used four different linguistic models based on naming
    3 Similar results were also obtained when, for each speaker, we          from each of the four alternative languages other than Dutch,
left pile-sort data from that speaker’s native language out of the uni-      while keeping all other procedures unchanged. For this and
versal similarity matrix U on which we base predictions.                     remaining analyses, we focused on individuals that exhibited
                                                                          2234

  a)                                                                                             b)
                                                                                                                                    40
                                                         Native language (%)                                                                                                Dutch
                                                         Other language (%)                                                                                                 Maihiki
                                                                                                    Residual gain from naming (%)
                                                                                                                                                                            English
                        Chichewa                                                                                                    35                                      Mandarin
                                                                                                                                                                            Chichewa
    Linguistic naming
                                                                                                                                                                            r=−0.9 (p<0.01)
                        Mandarin
                                                                                                                                    30
                        English
                                                                                                                                    25
                        Maihiki
                        Dutch                                                                                                       20
                                      Du      Ma        En         Ma      Ch
                                        tch     ihi        glish     nd       ich
                                                   ki                  ari        ew
                                                                          n          a
                                                                                                                                    15
                                                                                                                                         0       0.1         0.2            0.3        0.4
                                  Pile sorting (non−linguistic)                                                                              Expected confusion in naming
Figure 4: Summary of results of cross-language comparisons. (a) Within-language and cross-language predictive accuracies on
residual scene-pair assignments. Diagonal elements (black squares) reflect predictive accuracies from native languages. Off-
diagonal elements (gray squares) reflect predictive accuracies from other languages. Square size is proportional to percentage
gain in predictive accuracy in the residual analysis. (b) Relationship between naming confusion (semantic coarse-grainedness;
horizontal axis) and percentage gain in residual prediction from each language (vertical axis).
above-chance accuracies in residual prediction.                                             Carstensen et al., under revision). A natural possibility is
   Figure 4(a) presents the results of this cross-language pre-                             that fine-grained semantic systems may have a greater ef-
dictive analysis. The plot summarizes how well different lin-                               fect on non-linguistic spatial similarity judgments (reflected
guistic naming matrices L (by row) predict residual scene-                                  in higher residual predictive accuracy) than coarse-grained
pile assignments in pile-sorting by speakers of different lan-                              systems do. The rationale is that a fine-grained semantic sys-
guages (by column). Square size is proportional to per-                                     tem offers more opportunities to resolve ambiguous cases.
centage gain in predictive accuracy in the residual analysis.                               This proposal follows from the name strategy, where Kay
Diagonal elements (in black) represent performance given                                    and Kempton (1984) found that the degree of linguistic ef-
native-language information, and the four off-diagonal ele-                                 fect on how speakers resolve ambiguity in color judgements
ments (in gray) within each column represent performance                                    (e.g. distinguishing colors near the blue-green boundary) de-
given non-native-language information, on the same pile-sort                                pends on the fine-grainedness of color naming systems. Sim-
data. In almost all cases, native-language models outper-                                   ilarly, in the case of pile-sorting of spatial scenes, we expect
formed the non-native-language models in predicting resid-                                  scene pairs that cannot be resolved linguistically by a coarse-
ual pile-sorting data by speakers of that native language (19                               grained system because they fall in the same category in that
out of 20 pairwise comparisons; the exception is that English                               system, can be resolved linguistically by a fine-grained sys-
naming predicts sorting data from Mandarin speakers slightly                                tem because they fall in different categories in that system.
better than Mandarin naming itself). This finding supports the                                 To test this prediction, we examined the relationship be-
suggestion that native language was recruited in pile-sorting.                              tween native-language residual predictive accuracy (from the
We note also that the percentage gain in the residual pre-                                  previous analyses) and the semantic grain of each language.
diction differs across languages. In Figure 4(a), the diago-                                We assessed semantic grain for each language l by measur-
nal elements are sorted by accuracy, and it can be seen that                                ing the expected amount of naming confusion, or co-naming,
Dutch predicts its speakers’ residual pile-sort data the best,                              in l’s co-naming matrix Ll , averaging together the co-naming
and Chichewa predicts its speakers’ residual pile-sort data the                             proportions across all unique pairs of scenes i, j:
worst. In our final analysis, we asked whether this variation
                                                                                                                                             nc(l) = average(i, j) Li,l j                     (3)
in cross-language predictive accuracy is systematically linked
to the nature of the semantic systems involved.                                             Here, nc(l) measures the extent to which different stimuli
                                                                                            tend to receive the same name and thus be linguistically in-
Semantic grain and linguistic relativity                                                    distinguishable in language l. Coarse semantic grain corre-
Our final analysis builds on earlier explorations of seman-                                 sponds to a high value for nc(l) (because different scenes i, j
tic grain in sorting and naming (Khetarpal et al., 2010;                                    will often receive the same names in a coarse-grained system,
                                                                                         2235

and thus have high co-naming values Li,l j ), and fine semantic            sals and variation in cognition: The cases of space and ar-
grain corresponds to a low value for nc(l).                                tifacts.
   Figure 4(b) shows that there is a strong negative correla-            Gilbert, A., Regier, T., Kay, P., & Ivry, R. (2006). Whorf hy-
tion (Pearson’s r = −0.9; p < 0.01 from a permutation test                 pothesis is supported in the right visual field but not the
with 10,000 samples) between expected naming confusion                     left. Proceedings of the National Academy of Sciences,
(coarse-grainedness) for a language, and residual gain in pre-             103, 489-494.
dictive accuracy (size of the Sapir-Whorf effect) for that lan-          Kay, P., & Kempton, W. (1984). What is the Sapir-Whorf
guage.4 Dutch and Maihiki–the two most fine-grained sys-                   hypothesis? American Anthropologist, 86, 65-79.
tems in our data–yield the highest predictive accuracies in              Khetarpal, N., Majid, A., Malt, B., Sloman, S., & Regier,
the residual analysis. In contrast, Chichewa–which has a                   T. (2010). Similarity judgments reflect both language and
comparatively coarse-grained spatial semantic system–yields                cross-language tendencies: Evidence from two semantic
the lowest residual predictive accuracy. We have considered                domains. Proceedings of the 32nd Annual Meeting of the
only five languages here, and future work can usefully ex-                 Cognitive Science Society.
amine the robustness of this finding with a larger set of lan-           Khetarpal, N., Majid, A., & Regier, T. (2009). Spatial terms
guages. Nevertheless, these findings provide initial support               reflect near-optimal spatial categories. Proceedings of the
for the prediction that semantically finer-grained languages               31st Annual Meeting of the Cognitive Science Society.
will tend to have a greater effect on non-linguistic judgments           Khetarpal, N., Neveu, G., Majid, A., Michael, L., & Regier,
than coarser-grained languages will.                                       T. (2013). Spatial terms across languages support near-
                                                                           optimal communication: Evidence from Peruvian Amazo-
                            Conclusion                                     nia, and computational analyses. Proceedings of the 35th
We have presented two main findings: (1) Language appears                  Annual Meeting of the Cognitive Science Society.
to play a small but significant role in shaping spatial similarity       Kranjec, A., Lupyan, G., & Chatterjee, A. (2014). Categor-
judgments, in line with earlier studies, and (2) the extent of             ical biases in perceiving spatial relations. PLoS ONE, 9,
this linguistic effect varies as a function of the semantic grain          e98604.
of one’s native language. We have arrived at these findings by           Levinson, S. C., & Meira, S. (2003). Natural concepts in
pursuing a proposal from the literature, Kay and Kempton’s                 the spatial topological domain–adpositional meanings in
(1984) name strategy, and by instantiating that proposal in a              crosslinguistic perspective: An exercise in semantic typol-
computational analysis. Similar ideas appear elsewhere in the              ogy. Language, 79, 485-516.
literature (e.g. Vong et al., 2015), and we hope that our work           Majid, A., Bowerman, M., Kita, S., Haun, D., & Levinson, S.
will encourage further formal analyses of the link between                 (2004). Can language restructure cognition? The case for
cross-language semantic structures and cognition.                          space. Trends in Cognitive Sciences, 8(3), 108-114.
                                                                         Malt, B. C., Sloman, S. A., Gennari, S., Shi, M., & Wang,
                      Acknowledgments                                      Y. (1999). Knowing versus naming: Similarity and the
                                                                           linguistic categorization of artifacts. Journal of Memory
We thank Lev Michael and Grace Neveu for access to the                     and Language, 40(2), 230–262.
Maihiki data, and Asifa Majid for access to the Dutch data.              Munnich, E., Landau, B., & Dosher, B. (2001). Spatial lan-
This project was funded by NSF award SBE-1041707, the                      guage and spatial representation: A cross-linguistic com-
Spatial Intelligence and Learning Center (SILC), and NSF                   parison. Cognition, 81, 171-207.
Graduate Research Fellowship grant DGE-1106400 (to AC).                  Roberson, D., Davies, I., & Davidoff, J. (2000). Color cat-
                                                                           egories are not universal: Replications and new evidence
                            References
                                                                           from a stone-age culture. Journal of Experimental Psy-
Bowerman, M., & Pederson, E. (1992). Topological relations                 chology: General, 129(3), 369-398.
   picture series. In Space stimuli kit 1.2 (p. 51). Nijmegen:           Sapir, E. (1929). The status of linguistics as a science. Lan-
   Max Planck Institute for Psycholinguistics.                             guage, 207–214.
Brown, A., Lindsey, D., & Guckes, K. (2011). Color names,                Vong, W. K., Navarro, D. J., & Perfors, A. (2015). The
   color categories, and color-cued visual search: Sometimes,              helpfulness of category labels in semi-supervised learning
   color perception is not categorical. Journal of Vision, 11.             depends on category structure. Psychonomic Bulletin &
Carstensen, A. (2011). Universals and variation in spatial                 Review, 1–9.
   language and cognition: Evidence from Chichewa. Under-                Whorf, B. (1956). The relation of habitual thought and be-
   graduate thesis, University of California, Berkeley.                    havior to language. In J. Carroll (Ed.), Language, thought,
Carstensen, A., Khetarpal, N., Majid, A., Malt, B., Sloman,                and reality (p. 134-159). Cambridge, Massachusetts: The
   S., & Regier, T. (under revision). Cross-language univer-               MIT Press.
    4 We replicated this finding using a discrete measure for seman-
tic grain based on height following Khetarpal et al., (2010), where
we found a strong negative correlation between mean coarseness in
naming for a language and residual gain (Pearson’s r = − 0.92).
                                                                     2236

