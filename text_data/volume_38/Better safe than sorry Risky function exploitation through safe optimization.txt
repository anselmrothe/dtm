                                            Better safe than sorry:
                  Risky function exploitation through safe optimization
  Eric Schulz1 , Quentin J.M. Huys2 , Dominik R. Bach3 , Maarten Speekenbrink1 & Andreas Krause4
               1
                 Department of Experimental Psychology, University College London, London, WC1H0AP
           2
             Translational Neuromodeling Unit, ETH and University of Zürich, Wilfriedstrasse 6, 8032 Zürich
                         3
                           Psychiatric Hospital, University of Zürich, Lenggstrasse 31, 8032 Zürich
                    4
                      Institute for Machine Learning, ETH Zürich, Universitaetstrasse 6, 8092 Zürich
                           Abstract                              tasks is known as the exploration-exploitation dilemma:
                                                                 should I take an action which I know will lead to a high
   Exploration-exploitation of functions, that is learning
   and optimizing a mapping between inputs and expected          reward, or try an unknown action to experience its out-
   outputs, is ubiquitous to many real world situations.         come and thereby learn more about the function map-
   These situations sometimes require us to avoid certain        ping features to rewards, increasing my chances of gain-
   outcomes at all cost, for example because they are
   poisonous, harmful, or otherwise dangerous. We test           ing higher rewards in the future? In order to avoid cer-
   participants’ behavior in scenarios in which they have        tain bad outcomes (e.g., poisonous dishes), one should
   to find the optimum of a function while at the same           only explore uncertain options which are likely to be
   time avoid outputs below a certain threshold. In
   two experiments, we find that Safe-Optimization, a            ‘safe’. Such restricted exploration-exploitation problems
   Gaussian Process-based exploration-exploitation algo-         are ubiquitous in daily life, from choosing which restau-
   rithm, describes participants’ behavior well and that         rant to visit, which car to buy, all the way to whom to
   participants seem to care first about whether a point is
   safe and then try to pick the optimal point from all such     befriend. In our previous research on human behavior in
   safe points. This means that their trade-off between          contextual multi-armed bandits (Schulz et al., 2015a,b),
   exploration and exploitation indicates intelligent,           we found that participants’ behavior is well-described by
   approximate, and homeostasis-driven behavior.
                                                                 Gaussian Process regression, a non-parametric regres-
   Keywords: Safe Optimization, Function Learning, Ap-           sion tool that adapts its complexity to the data at hand
   proximate Learning, Gaussian Process, Homeostasis             by the means of Bayesian posterior computation.
                                                                    The aim of the present study is to assess how peo-
                                                                 ple behave when they have to maximize their rewards
                       Introduction
                                                                 whilst avoiding outcomes below a given threshold. The
Imagine you are hosting a dinner party. In the after-            task is couched as a function learning task, where par-
noon, you open up your fridge and kitchen cupboards to           ticipants choose an input and observe and accrue the
find a plethora of ingredients at your disposal. Aiming to       output of the function. In two experiments with a uni-
amaze your friends with an unique culinary experience,           and bivariate function, we find that participants effi-
you decide to prepare something extraordinary not found          ciently adapt their exploration-exploitation behavior to
in recipe books. Considering your options, you generate          risk-inducing situations. Overall, they are well-described
expectations of how the tastes of different ingredients          by a Gaussian Process-based safe optimization algorithm
combine and interact to produce a – hopefully memo-              that tries to safely expand a set of ‘explorers’ while si-
rable – culinary experience. You have time to try out            multaneously maximizing outputs within a set of possi-
some options and experience their overall taste, learning        ble ‘maximizers; (Sui et al., 2015). Such behavior might
about the effects of unusual combinations and methods            be based on the principle of homeostasis maintenance
of preparation. At the same time, however, you need              (Korn & Bach, 2015), where organisms need to forage for
to avoid certain combinations at all costs, for example          food while avoiding the probability of starvation. Addi-
those that are inedible, poisonous, or otherwise bad.            tionally, we find evidence that participants first assess
   This scenario is an example of a multi-armed bandit           whether points are safe and then attempt to maximize
task (Srinivas et al., 2009), where there are a number of        within this safe subset. This simplification of the task
actions or ‘arms’ of the bandit (e.g., the possible dishes)      in terms of subgoals resonates well with recent results
which lead to initially unknown and stochastic outcomes          on approximate planning strategies in complex dynamic
or rewards (e.g., the taste of the dish), which are related      tasks (Huys et al., 2015).
to a set of features (e.g., the ingredients, the method of
preparation, etc.). Through experience, one can learn                 Modeling learning and optimization
the function which maps the features to the rewards and
                                                                 If the task is to learn and maximize an unknown func-
maximize the overall rewards gained over repeated plays
                                                                 tion, then two ingredients are needed: (a) a model to
of the bandit. A key issue in optimal behavior in such
                                                                 represent an unknown function, for which we will use
    1
      Corresponding author: eric.schulz@cs.ucl.ac.uk             Gaussian process regression, and (b) a method to safely
                                                             1140

choose the next inputs, for which we will use a safe op-                      Optimizing a function
timization algorithm.                                                         Given a learned representation of a function at time t,
                                                                              this knowledge needs to be used to choose a next input
Learning a function
                                                                              at time t + 1. This is done through an acquisition func-
We assume people represent and learn a function through                       tion that takes the expected output for each input and
Gaussian process regression, a universal function learn-                      the associated uncertainty to balance exploration and
ing algorithm which has been supported in previous re-                        exploitation (Brochu et al., 2010).
search (Griffiths et al., 2009; Schulz et al., 2015b).                        An algorithm that is well-poised to cope with the addi-
A Gaussian Process (GP) is a stochastic process of which                      tional requirement to avoid outcomes below a threshold
the marginal distribution of any finite collection of obser-                  first separates possible inputs into those that are likely
vations is multivariate Gaussian (Rasmussen, 2006). It                        to provide outputs above the threshold (the safe set)
is a non-parametric Bayesian approach towards regres-                         and those that are not, and then separates this safe
sion problems and can be seen as a rational model of                          set further into a set of maximizers (inputs that are
function learning as it adapts its complexity to the data                     likely to provide the maximum output) and expanders
encountered. Let f (x) be a function mapping an input                         (inputs that are likely to expand the safe set). Following
x = (x1 , . . . , xd )> to an output y. A GP defines a distri-                Berkenkamp et al. (2015), we define upper and a lower
bution p(f ) over such functions. A GP is parametrized                        bounds of a confidence interval as sum of the current
by a mean function m(x) and a covariance (or kernel)                          expectation mt−1 and its attached uncertainty σt−1 .
function, k(x, x0 ):
                                                                                             ut (x) = mt−1 (x) + βt σt−1 (x)             (8)
          m(x) = E [f (x)]                                            (1)                    lt (x) = mt−1 (x) − βt σt−1 (x).            (9)
      k(x, x0 ) = E [(f (x) − m(x))(f (x0 ) − m(x0 ))]                (2)
                                                                              the parameter βt determines the width of the confidence
At time t, we have collected observations y1:t =                              bound, and we set it to βt = 3 to assure high safety a
[y1 , y2 , . . . , yt ]> at inputs x1:t = (x1 , . . . , xt ). For each        priori (i.e. 99.9%). Using these bounds, we can define
outcome yt , we assume                                                        the safe set as all the input points in the set X of available
                                                                              inputs that are likely to lead to output values above the
                   yt = f (xt ) + t    t ∼ N (0, σ 2 )              (3)     safe threshold, Jmin
Given a GP prior on the functions                                                              St = {x ∈ X |lt (x) ≥ Jmin }             (10)
                       f (x) ∼ GP (m(x), k(x, x0 )) ,                 (4)     The set of potential maximizers contains all safe inputs
                                                                              that are likely to obtain the maximum output value;
the posterior over f is also a GP with                                        these are the safe inputs for which the upper confidence
                                                                              bound ut is above the best lower bound:
    mt (x) = k1:t (x)> (K 1:t + σ 2 I t )y 1:t                        (5)
            0               0          >                    −1                          Mt = {x ∈ St |ut (x) ≥ maxx0 ∈X lt (x0 )}       (11)
 kt (x, x ) = k(x, x ) − k1:t (x) (K 1:t + σ I t )    2
                                                               k1:t (x0 )
                                                                      (6)     To find a set of expanders, we define
where k1:t (x) = [k(x1 , x), . . . , k(xt , x)]> , K 1:t is the                   gt (x) = |{x0 ∈ X \ St |lt,(x,ut (x)) (x0 ) ≥ Jmin }| (12)
positive definite kernel matrix [k(xi , xj )]i,j=1,...,t , and I t
is a t by t identity matrix. This posterior distribution                      where lt,(x,ut (x)) (x0 ) is the lower bound of x0 based on
can be used to derive predictions for each possible input                     past data and a predicted outcome for x which provides
x on the next time point, which again follow a Gaussian                       a new upper bound ut (x). The function is used to de-
distribution. A key aspect of a GP is the covariance or                       termine how many inputs are added to the safe set after
kernel function k. The choice of a kernel function cor-                       choosing input x and observing the output it provides.
responds to assumptions about the kind of functions a                         This function is positive only if the new data point has
learner expects. Here, we will use a squared exponential                      a non-negligible chance to expand the safe set. The set
kernel:                                                                       of possible expanders is then defined as
                                           (x − x0 )2
                                                        
                              0   2                                                              Gt = {x ∈ St |gt (x) ≥ 0}              (13)
                  ksqe (x, x ) = θ1 exp −                             (7)
                                              2θ22
                                                                              Normally, the safe optimization routine picks as the next
This kernel induces a universal function learning engine                      point a safe point that is within the intersection of ex-
and has been found to describe human function learning                        panding and maximizing points, but currently shows the
well (Griffiths et al., 2009).                                                highest uncertainty measured by the difference between
                                                                          1141

the upper and the lower bound. However, for this first         Procedure
investigation of human behavior within safe exploration        Participants were told that they had to maximize an
scenarios we will focus on how participants choices of in-     unknown function while at the same time trying to avoid
put points are influenced by simple membership of the          sampling below the red line as this would end the current
3 sets and if their behavior can be described by more          block. After reading the instructions and performing an
heuristic, stepwise decision behavior.                         example task, they had to correctly answer 4 questions
                                                               to check their understanding, then performed the task,
    Experiment 1: Univariate functions                         and at the end saw their total score.
The first experiment required participants to maximize         Results
unknown univariate functions f : x → y. On each trial          As shown in Figure 2, participants obtained outputs
t = 1, . . . , 10 in a block, they could choose an input       higher than expected by chance on the large majority of
value x ∈ {0, 0.5, 1, . . . , 10} to observe (and accrue) an   trials and indeed the average score per participant was
output y = f (x) +  with noise term  ∼ N (0, 1). The         significantly higher than chance, t(60) = 13.311, p <
underlying functions were sampled from a GP with a             0.01. In addition, the average number of trials per block
squared exponential kernel (l=1, θ=1). The objective
was to maximize the sum of the obtained outputs over                                               Scores
all trials in a block. A threshold Jmin was introduced
                                                                                0.25
and a block was ended abruptly if an output below this
threshold was obtained. On average, that threshold was
fixed to separate 50% of the points into safe and unsafe                        0.20
points. Before the first trial, an initial safe point above
the threshold was provided. A screenshot is shown in                            0.15
                                                                    Frequency
Figure .
                                                                                0.10
                                                                                0.05
                                                                                0.00
                                                                                       0   2   4         6   8   10
                                                                                                     y
                                                                  Figure 2: Scores per trial. Black line: chance level.
                                                               statistically exceeded what would be expected if partic-
                                                               ipants chose completely at random, t(548) = 5.1201,
                                                               p < 0.01 and participants’ scores were positively cor-
                                                               related with trials (r = 0.25, p < 0.01). Taken together,
                                                               these results indicate that participants learned the task
                                                               and tended to chose safe inputs.
                                                               We used mixed-effects logistic regression analysis to asses
                                                               which factors influenced participants’ choices. The de-
                                                               pendent variable was whether each input was chosen or
                                                               not on each trial for each participant. As predictors, we
                                                               used indicator variables for membership of an input of
        Figure 1: Screenshot of first experiment.              the safe, maximization, and expander set. Results indi-
                                                               cated that the most plausible model was a model that
                                                               contains all variables as fixed effects and a participant-
Participants                                                   specific random intercept, indicating that participants
                                                               were influenced by set membership in an overall simi-
61 participants (36 female) with an average age of 32.95       lar fashion. The coefficients of the fixed effects are pre-
(SD = 8.02) were recruited via Amazon Mechanical Turk          sented in Table 1 below. Comparing the magnitude of
and received $1 for their participation and a bonus of up      the slopes of the predictors, we can conclude that par-
to $1, in proportion to their overall score.                   ticipants cared about all of the sets, but mostly about
                                                           1142

                                                                of chosen points to the initially provided input point,
Table 1: Fixed effects estimate. Significant estimates are
                                                                xstart − xt is calculated as shown in Figure 4.
flagged.
            Variable           b             SE(b)
                                                                                       Distance to initial point
            Intercept          −4.26∗        0.04
            Safe set           1.57∗         0.06                       0.8
            Maximizer set      1.72∗         0.05
            Expander set       0.12          0.05
                                                                        0.6
whether or not a point was safe and/or a maximizer.
Next, we used a random intercept decision tree analysis                 0.4
(Sela & Simonoff, 2011) to assess whether participants
might utilize a simple but effective heuristic strategy that
can be implemented as a decision tree, as suggested by                  0.2
Huys et al. (2012). For this, we replaced the indicators of
set membership with probability assessments, substitut-
ing membership of the maximizer set with the probabil-                  0.0
ity of improvement, the safe set with the probability of                      −10     −5          0           5    10
being above the threshold, and the expander set with the                                       Distance
probability of safely expanding the set (assessed through
one step ahead forward simulation). The probability of          Figure 4: Distance of chosen input points to initially
improvement is defined as the probability that an input         provided point. Black line indicates expected density
x produces a higher output than the input x+ that is            for sampling at random.
currently thought to provide the maximum, and can be
calculated as
                                                                This means that people’s behavior in this uni-variate
             P It (x) = P f (x) ≥ f (x+ )
                                          
                                                        (14)    function optimization experiment was based on the at-
                                         +
                            mt (x) − f (x )
                                                               tempt of locally maximizing points that they strongly
                      =Φ                                (15)    perceived as safe.
                                  σt (x)
where Φ is the cumulative Normal distribution func-                  Experiment 2: Bivariate functions
tion. Figure 3 depicts the decision tree which best fitted
participants’ choices. This analysis shows that partici-        In the second experiment, participants were asked to
pants seem to partition the problem into two sub-goals:         maximize an unknown bivariate function f : x → y
first they conservatively assess whether or not a point is      with x = (x1 , x2 )> , defined over the grid x1 , x2 ∈
safe, then they maximize within that safe set. That ex-         [0, 0.05, 0.1, . . . , 1], with y = f (x) +  with  ∼ N (0, 1).
panders are not considered within this decision process         As in Experiment 1, the function f was sampled on
could be due to the brevity of the task (10 trials) or to       each block from a GP with a squared exponential kernel
risk aversion (i.e., the fear of sampling below the thresh-     (l = 2,θ = 1). The output values y varied between 0 and
old). The non-inclusion of possibly expanding points also       100 and one initial point above 50 was provided. We
                                                                varied the level of risk within-participants: there were
                                                                10 blocks in total out of which 5 were “normal”, that is
                                                   sample       unconstrained maximization tasks without a threshold
                                           0.05
                                      )>
                               p   (mn                          and 5 were “safe” blocks in which obtaining an output
                                p (m                            below 50 caused the current block to end abruptly. The
                   0.99              n) <
             )>                             0.05                blocks were presented in randomly permuted order. A
         p(sn
                                                                screenshot is shown in Figure 5.
root                                               ignore
       p(sn                                                     Participants
           )<
                0 . 99
                          ignore                                62 participants (37 male), with an average age of 31.77
                                                                years (SD = 8.97) were recruited via Amazon Mechan-
Figure 3: Multi-level decision tree minimizing log-loss.        ical Turk and received $1 for their participation and a
                                                                performance-dependent bonus of up to $1. The average
means that participant only tried to maximize very lo-          completion time of the whole experiment was 11 min-
cally, something that can also be seen when the distance        utes.
                                                             1143

                                                                                                     puts on the grid (t(length = 5) = −0.32 with p = 0.72).
                                                                                                     A similar mixed-effects logistic regression analysis as
                                                                                                     used for Experiment 1 (Table 2) showed that participants
                                                                                                     seemed to care most about scoring above the threshold
                                                                                                     in both conditions. As expected, this effect was more
                                                                                                     pronounced in the safe conditions than in the normal
                                                                                                     conditions. Still, the presence of this effect in the nor-
                                                                                                     mal condition is interesting as it did not matter whether
                                                                                                     or not participants scored below the threshold. If scor-
                                                                                                     ing below 50 did not matter, participants should have
                                                                                                     not cared as much about sampling above this point in
                                                                                                     the normal condition as they actually did. One explana-
                                                                                                     tion for this might be a transfer effect by which partic-
                                                                                                     ipants assume that sampling below 50 is generally bad.
                                                                                                     The maximizer set only had a small influence on par-
                                                                                                     ticipants’ choices that was slightly bigger for the safe
                                                                                                     condition. Participants showed no tendency to expand
                                                                                                     the safe set in either of the conditions. This indicates
         Figure 5: Screenshot of second experiment.                                                  that most chosen inputs were close to the initial safe in-
                                                                                                     put and previously chosen inputs. This relatively high
                                                                                                     risk aversion is understandable, as the bivariate task is
Procedure                                                                                            more difficult than the univariate one of Experiment 1.
The procedure was essentially the same as for Experi-                                                Lastly, a random intercept decision tree analysis (Fig-
ment 1, apart from additional detailed instructions re-
garding the difference between normal unconstrained                                                  Table 2: Fixed effects estimates. Significant estimates
(without a threshold) and safe (with a threshold) trials.                                            are flagged.
Results                                                                                                    Condition      Variable         b        SE(b)
As shown in Figure 6, participants scored better than                                                                     Intercept        −5.17∗   0.04
expected by chance in both the safe and the normal                                                                        Safe Set         1.35∗    0.04
                                                                                                           Normal
conditions (t(normal = 50) = 24.9 with p < 0.01;                                                                          Maximizer        0.13∗    0.04
t(safe = 59) = 9.3 with p < 0.01). The reason why                                                                         Expander         0.04     0.05
chance level performance is higher in the safe condition                                                                  Intercept        -5.92∗   0.09
is that scores below 50 were not allowed and therefore the                                                                Safe Set         2.11∗    0.07
                                                                                                           Safe
output was truncated to be above 50. This time, partic-                                                                   Maximizer        0.23∗    0.09
                                                                                                                          Expander         0.03     0.08
               Normal                                                               Safe
                                                                                                     ure 7) showed that in the best fitting model, only the
  0.04                                                                                               probability of being above the threshold mattered. This
                                     0.00 0.01 0.02 0.03 0.04 0.05 0.06
                                                                                                     indicates that participants only seemed to care about
  0.03
                                                                                                     whether or not an input was safe, simplifying the task
                                                                                                     to a great extent with a strong focus on the probability
                                                                                                     of losing. Such simplification makes sense in light of the
  0.02                                                                                               relative complexity of the bivariate task.
                                                                                                                                    0.8
                                                                                                                                           sample
  0.01
                                                                                                                               )>
                                                                                                                           p(sn
  0.00
                                                                                                                   root
         20   40      60    80                                            50   60     70     80                           p(sn
                                                                                                                              )<
                   Scores                                                           Scores                                          0 .8
                                                                                                                                           ignore
                     Figure 6: Scores per trial.                                                           Figure 7: Decision tree minimizing log-loss.
ipants within the safe condition did not complete more                                                 This means that participants again only sampled lo-
trials in a block than expected by randomly choosing in-                                             cally, staying close to the initial point (Figure 8).
                                                                                                  1144

Figure 8: Distance of participants’ sample points to initial point for safe condition, normal condition, and the
theoretically expected distance for random sampling. Participants stay a little closer to the initial point in the safe
condition than in the normal condition. Randomly sampling would theoretically cause much higher distances.
If participants sampled locations are treated as a Pois-        the description of participants’ intuitive function learn-
son process and centred around the initial point, then          ing process and for the actual functions sampled within
the posterior density of sampled points shows that par-         the task, another direction is to assume different ker-
ticipants stayed very close to the initial point in the safe    nel parametrizations of these functions as those lead to
condition, sampled a little further away from the initial       diverse theoretical predictions about how fast partici-
point in the normal condition, but never sampled as dis-        pants are able to learn (Schulz et al., 2015c). Future
persively as a completely random sampler.                       work could also extend our approach to active versions
                                                                of more traditional models such as heuristics and weight-
            Discussion and Conclusion                           based strategies (Parpart et al., 2015).
Learning unknown functions and exploiting this knowl-           Unlike previous work on human behavior in the bandit
edge to maximise rewards are essential cognitive skills.        setting, which has focused on pure optimization primar-
Such tasks can be formalized as bandit tasks and here           ily, our work explored a relatively novel facet–optimizing
we focused on a restricted version thereof where out-           risky functions. We expect that this new approach will
comes below a given threshold need to be avoided. We            provide further insights into how people resourcefully op-
found that participants’ behavior was described well by         timize outcomes in the real world.
a Gaussian Process safe optimization routine that estab-
lishes safe sets and then tries to maximize outputs within
                                                                                             References
                                                                Bach, D. R. (2015). Anxiety-like behavioural inhibition is normative under
                                                                   environmental threat-reward correlations. PLOS Computational Biology,
these sets. Participants mostly ignored input points that          11 , e1004646.
could expand the safe set, shunning risks and maximiz-          Berkenkamp, F., Schoellig, A. P., & Krause, A. (2015). Safe controller
                                                                   optimization for quadrotors with Gaussian Processes. arXiv preprint
ing outputs locally, thereby preferring to rather be “safe         arXiv:1509.01066 .
                                                                Brochu, E., Cora, V. M., & De Freitas, N. (2010). A tutorial on Bayesian
than sorry”.                                                       optimization of expensive cost functions, with application to active
                                                                   user modeling and hierarchical reinforcement learning. arXiv preprint
Participants’ behavior was consistent with a sequential            arXiv:1012.2599 .
                                                                Griffiths, T. L., Lucas, C., Williams, J., & Kalish, M. L. (2009). Modeling
heuristic in which they first determined whether inputs            human function learning with Gaussian Processes. In Advances in Neural
                                                                   Information Processing Systems, (pp. 553–560).
were safe and then maximized within this safe set. While        Huys, Q., Eshel, N., ONions, E., Sheridan, L., Dayan, P., & Roiser, J. P.
                                                                   (2012). Bonsai trees in your head: How the Pavlovian system sculpts goal-
this strategy involves only local searches, it can result in       directed choices by pruning decision trees. PLoS Computational Biology,
                                                                   8 , e1002410.
truly auspicious behavior, especially when the choices          Huys, Q. J., Lally, N., Faulkner, P., Eshel, N., Seifritz, E., Gershman, S. J.,
                                                                   Dayan, P., & Roiser, J. P. (2015). Interplay of approximate planning
are limited. Participants’ focus on avoiding unsafe in-            strategies. Proceedings of the National Academy of Sciences, 112 , 3098–
                                                                   3103.
puts is consistent with a biological homeostasis main-          Korn, C. W., & Bach, D. R. (2015). Maintaining homeostasis by decision-
                                                                   making. PLOS Computational Biology, 11(5):e1004301 .
tenance principle that prioritizes not loosing everything       Parpart, P., Schulz, E., Speekenbrink, M., & Love, B. C. (2015). Active
over gaining as much as possible. The continued influ-             learning as a means to distinguish among prominent decision strategies.
                                                                   In Proceedings of the Thirty-Seventh Annual Conference of the Cognitive
ence of the save threshold on participants’ choices in the         Science Society, (pp. 1829–1834).
                                                                Rasmussen, C. E. (2006). Gaussian Processes for machine learning.
normal condition, where it had no effect on their poten-        Schulz, E., Konstantinidis, E., & Speekenbrink, M. (2015a). Exploration-
                                                                   exploitation in a contextual multi-armed Bandit Task. Proceedings of the
tial earnings, might be due to participants generalizing           13th International Conference on Cognitive Modeling. Groningen, NL.
                                                                Schulz, E., Konstantinidis, E., & Speekenbrink, M. (2015b). Learning and
their evaluation of outputs below the threshold as “bad”           decisions in contextual multi-armed bandit tasks. Proceedings of the 37th
                                                                   annual conference of the cognitive science society, (pp. 2122–2127).
from the safe conditions.                                       Schulz, E., Tenenbaum, J. B., Reshef, D. N., Speekenbrink, M., & Gersh-
                                                                   man, S. J. (2015c). Assessing the perceived predictability of functions.
In future work, we want to focus on what factors drive             Proceedings of the 37th annual conference of the cognitive science society,
                                                                   (pp. 2116–2121).
participants to switch from explorative to safe behavior        Sela, R., & Simonoff, J. (2011). Reemtree: Regression trees with random
                                                                   effects. R package version 0.90 , 3 , 741–749.
and in which situations switching constitutes as a nor-         Srinivas, N., Krause, A., Kakade, S. M., & Seeger, M. (2009). Gaussian
mative strategy, for example because it is minimizing              Process optimization in the bandit setting: No regret and experimental
                                                                   design. arXiv preprint arXiv:0912.3995 .
costs (Bach, 2015). As we have only focused on functions        Sui, Y., Gotovos, A., Burdick, J. W., & Krause, A. (2015). Safe exploration
                                                                   for optimization with Gaussian Processes. In International Conference on
sampled from a squared exponential kernel here, both for           Machine Learning (ICML).
                                                            1145

