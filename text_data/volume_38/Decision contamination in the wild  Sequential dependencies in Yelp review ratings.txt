                                            Decision contamination in the wild:
                                  Sequential dependencies in Yelp review ratings
                                                     David W. Vinson, Rick Dale
                                                    Cognitive and Information Sciences
                                                     University of California, Merced
                                                      [dvinson][rdale]@ucmerced.edu
                                                            Michael N. Jones
                                    Departments of Psychology, Cognitive Science, and Informatics
                                                     Indiana University, Bloomington
                                                           jonesmn@indiana.edu
                               Abstract                                 system, including motor control (Dixon, McAnsh, & Read,
   Current judgments are systematically biased by prior
                                                                        2012), spatial memory (Freyd & Fink, 1984), face
   judgments. Such biases occur in ways that seem to reflect the        perception (Hsu & Yang, 2013; Liberman, Fischer &
   cognitive system’s ability to adapt to the statistical               Whitney, 2014), selective attention (Kristjansson, 2006),
   regularities within the environment.          These cognitive        decision making (Jesteadt, Luce, & Green, 1977), and
   sequential dependencies have been shown to occur under               language processing (Bock & Griffin, 2000).
   carefully controlled laboratory settings as well as more recent         SDs have primarily been studied in the laboratory or at
   studies designed to determine if such effects occur in real          least with well-controlled experimental stimuli. They are
   world scenarios. In this study we use these well-known
   findings to guide our analysis of over 2.2 million business          more difficult to study in real-world scenarios because of
   review ratings. We explore how both within-reviewer and              the very large number of trials that would be required to
   within-business (between reviewer) ratings are influenced by         identify their effects. In stimulus identification, for example,
   previous ratings. Our findings, albeit exploratory, suggest          the immediately preceding (n-1) and non-adjacently
   that current ratings are influenced in systematic ways by prior      preceding (n-2…7) items exert opposing forces on
   ratings. This work is couched within a broader program that          identification of the stimulus presented on trial n (Lockhead,
   aims to determine the validity of laboratory findings using
                                                                        2004). To observe this pattern in a reasonable amount of
   large naturally occurring behavioral data.
                                                                        time in the lab, carefully designed stimulus sequences are
   Keywords: Sequential dependency; Online reviews; Large               needed.
   natural data; Decision making                                           In this paper, we explore SDs in a real-world situation by
                                                                        mining a large natural database of online review ratings
                          Introduction                                  from Yelp, Inc. This is one of many freely available
Humans are surprisingly bad at rating the absolute                      structured databases that can be explored. Here we use the
magnitude of their internal cognitive states. Regardless of             dataset to determine if current review ratings are
the task, judgments of the absolute magnitude of a stimulus,            contaminated by previous reported experiences. In what
experience, or feeling, are inherently contaminated by                  follows we first review SD trends observed in standard
relative information from the sequence of judgments prior               laboratory tasks.
to the current one. Although we tend to believe that our
judgment reflects the absolute value of the current                     SDs in the Laboratory
experience, a good deal of the judgment is in fact                      Assimilation occurs whenever the judgment of stimulus n
determined by the relative difference between the current               moves closer on the measurement scale to the judgment of
experience and experiences from previous trials (Laming,                stimulus n-k than it otherwise would have been. Contrast is
1984; Stewart, Brown, & Chater, 2005). This pattern is                  the opposite effect, when the judgment of stimulus n moves
complicated by the fact that decisions are also influenced by           further away on the measurement scale from the judgment
other factors, such as stimulus, response, and feedback (see            of stimulus n-k. In this sense, assimilation can be thought of
Donkin, Rae, Heathcote, & Brown, 2015, for a review).                   as a pulling force from the preceding stimulus, while
   These cognitive sequential dependencies (SDs) occur                  contrast can be thought of as a pushing force (Zotov, Jones,
whenever behavior on a trial is influenced by behavior on               & Mewhort, 2011).
preceding trials. Far from rare, SDs are ubiquitous in                     Much of the early work on SDs was psychophysical in
cognition, contaminating absolute judgments from low-level              nature and involved rating unidimensional stimuli such as
perception all the way up to high-level moral judgments.                the loudness of a tone or length of a line (Garner, 1953;
We see the effect of previous trials on RT, accuracy, the               Holland & Lockhead, 1968). Identifying the absolute
type of errors produced, and interpretation of ambiguous                magnitude of these stimuli (e.g., line length) has been well
stimuli. SDs seem to affect all levels of the cognitive                 studied: Errors when identifying stimulus n assimilate
                                                                   1433

towards the stimulus on trial n-11. Participants are more             to both the service quality Yelp aims to provide, as well as a
likely to estimate the absolute value of some stimuli more            more accurate assessment of the business in question.
similar to their most proximal previous estimate. Oddly,                 In Yelp, reviewers rate their experience with a business
categorization of the same stimuli shows the opposite effect          on a scale of 1 to 5 stars. Because both the rating and rating
from the most recent response—when placing stimuli into               scale are most similar to categorization tasks studied in the
categories, classification of stimulus n shows contrast from          laboratory (i.e., what is the best label to classify the
stimulus n-1 (Stewart, Brown, & Chater, 2002; Ward &                  exemplar, experience with the business, on a scale of 1-5
Lockhead, 1971).                                                      stars), our predictions are loosely drawn from SDs in
   The contrast effect (push) of trial n-1 on the category            categorization. Businesses typically specialize in specific
rating of trial n is not limited to low-level perception, but is      services (such as a restaurants that serve American cuisine)
seen across levels of cognition. As a striking high-level             while reviewers typically do not provide more than one
demonstration, consider Parducci’s (1968) example of                  review per business—similar to many individuals rating the
classifying the event of “poisoning a neighbor’s barking dog          same moral statement, opposed to one individual rating
that was bothering you” on a moral judgment scale from 1-             different statements. In particular, we expect that within
10 scale (where 10 is “extremely evil”). This terrible                reviewers we will see a contrast effect from ratings across
statement was rated as more evil by subjects if it was                businesses: The rating of a business will be artificially
preceded by a mild judgment (“stealing a towel from a                 inflated if previous ratings from this reviewer were lower
hotel”) than if it was preceded by a nastier judgment (“using         than if they were higher. Secondly, and more tentatively, we
guns on striking workers”)—a contrast effect when                     expect that businesses may act like categories themselves—
classifying moral judgments. Similar patterns of SDs have             a rating of a business is likely to assimilate towards
been seen in a variety of laboratory tasks designed to tap            preceding ratings. In addition, while little known work
real-world scenarios, including brake initiation latencies in         investigates the effects of SDs on increasing temporal
driving behavior (Doshi, Tran, Wilder, Mozer, & Trivedi,              distances, we anticipate that the effects of stimulus distance
2012), jury evidence interpretation (Furnham, 1986), and              will be similar to temporal distance (cf. Ward, 1973). In this
clinical assessments (Mumma & Wilson, 2006). In addition,             sense, our predictions of Yelp review ratings are a simple
SDs seem to be immune to practice—they are seen even in               extension of both the perceptual work of Zotov et al. (2011),
overlearned and expert behaviors.                                     and the moral judgments of Parducci (1968).
   At first glance, SDs appear to be an irrational bias in               Natural datasets are wrought with noise. Yet, where they
decision making (or perhaps in event memory), and have                lack structure they make for in sheer size. We do not
been traditionally viewed as the natural by-product of low-           anticipate that SDs will play such a substantial role as to
level brain dynamics such as residual neural activation.              alter the usefulness of user or business ratings on its face.
However, more recent theoretical perspectives suggest that            Instead we expect to fine echoes of cognitive influence
SDs may be a rational property of any cognitive system.               detectible in large datasets of naturally occurring behavior.
These accounts characterize SDs in terms of an individual’s           We consider this work a guided exploration, in an effort to
adaptation to the statistical regularities of a nonstationary         bridge laboratory findings with relevant and functional
environment with related stimulus bundles (Qian & Aslin,              natural behavior.
2014; Wilder et al., 2010; Yu & Cohen, 2009).
   Our interest is to mine Yelp, guided by knowledge from             Method
laboratory studies, to look for these naturally occurring             We used the most recent release of the Yelp Inc., dataset,
contaminations that may affect how a business is currently            part of Yelp’s Dataset Challenge2. The dataset consists of
rated and can expect to be rated in the future. Future                just over 2.2 million reviews spanning 12 years from 2004-
business demand is largely influenced by online reviews               2016, with ratings between one (negative) and five
(Cantallops, Silva, 2014; Mudambi & Schuff, 2010)                     (positive) stars, from approximately 552,000 reviewers on
affecting a business’s revenue between 5-9% with this                 roughly 77,000 businesses. Reviews were provided from
number increasing by 50% for businesses with more than 50             nine cities across four different countries (United States,
reviews (Luca, 2011). Computational models that explain               Canada, Scotland and Germany). Interestingly, star ratings
how SDs emerge from the decision making process are now               follow a J-shaped distribution (fig. 1, top) with mostly four
being developed, at least for low-level perceptual tasks (e.g.,       and five star ratings a dip in two star ratings and roughly
Mozer, et. al, 2010). These models have great promise in              and equal number of one and three star ratings. In addition,
that they may be reversed and then applied to rating data to          the number of reviews increased steadily over Yelp’s
“decontaminate” the SD pollution in the rating, essentially           lifetime (Fig. 1, center).
producing a more accurate estimation of the individual’s
absolute experience of a business by removing the pollution
from the relative information. This has an obvious benefit
   1                                                                     2
     Interestingly, the same absolute judgment that assimilates to         Further information on how to access the dataset for free as
the most proximal past judgment contrasts from stimuli n-2…5.         part of Yelp’s dataset challenge can be found here at
   2
     Further information on how to access the dataset for free as     http://www.yelp.com/dataset_challenge
part of Yelp’s dataset challenge can be found here at
                                                                  1434

                                                                                    Review Distance is a lag measure of the number of reviews
                                                                                    (k) between the current review and previous review, while
                   6e+05                                                            Date Difference is a time measure of the number of days
                                                                                    between reviews. Reviews that are farther displaced both in
                   0e+00
                                                                                    time and in the number of reviews may show dependence on
                            1          2             3             4         5      previous review ratings.
                                               Star Rating
Review Frequency
                                                                                    Results
                                                                                    We first determined whether one’s current review was
                   200000
                                                                                    related to one’s previous review rating at k-distances. Fig. 2
                                                                                    presents the mean and standard error bars for deviation of
                   0                                                                the current review rating from the mean (y-axis) by the
                                2006    2008     2010       2012   2014   2016      previous star ratings (x-axis) at seven different Review
                                              Date by Year                          Distances (k) within reviewers. The figure reveals a contrast
                                                                                    effect that dissipates the farther away the previous review is
                                                                                    from the current review. At n-1 (the immediately preceding
                   6e+05                                                            review) for example, a 1-star rating resulted in an artificial
                                                                                    increase in the subsequent rating from the overall mean
                   0e+00
                                                                                    rating. The opposite would be the case if the n-1 rating was
                            0          1000          2000          3000             5 stars—the subsequent rating would be a lower star rating
                                           Date Difference                          on average than it otherwise should have been. In this sense,
                                                                                    the data are very much consistent with Parducci’s (1968)
     Figure 1: Frequency of reviews by star rating (top),                           “dog poisoning” example in that the current rating is
 frequency of reviews by year (center), frequency of reviews                        systematically biased in the opposite direction from the
       at different temporal distances in days (bottom).                            previous rating.
  We tested whether previous reviews influence the current
review both within reviewers and within businesses. For this
reason, we predict reviews from the same reviewer will be                                                    0.3                         k
pushed away from previous reviews showing a contrast                                                                                         1
                                                                                        R x − M (R T −x )
effect (cf. Zotov et al., 2011). Alternatively, there may be an
                                                                                                             0.2                             2
assimilation effect for reviews within businesses. When
successive stimuli are presented from the same category, the                                                                                 3
representation of that category is pulled toward the                                                         0.1                             4
exemplar of the previous trial. Similarly, successive
reviews on the same businesses, a type of category, may be
                                                                                                                                             5
pulled toward ratings from previous reviews. To be sure,                                                     0.0                             6
this prediction is more exploratory as the nature of most                                                                                    7
laboratory studies on SDs have not focused on the influence                                                 −0.1
of previous judgments from other individuals on the
assessment of the same category. We anticipate that these                                                          1    2   3    4   5
effects will dissipate the farther away the previous review is                                                     n − k Review Rating
from the current review.
                                                                                        Figure 2: Within-reviewer contrast between previous and
Measures We first determined how far the current review                                       current review ratings at k Review Distances
rating was from its mean:
                                                                                       To assess the visual impression quantitatively, we use a
                                              Rx – M(RT-x )                         linear model to predict current review ratings by n-k ratings
                                                                                    for each of seven different values of k. That is, we treated
Where Rx is the current rating and M(RT-x) is the average                           each value of k as distinct. The results, presented in Table 1,
rating by reviewer or business with the current value x                             reveal that as the value of k increases, or the current review
removed to account for possible inflation within our                                is farther displaced from the previous review, the contrast
statistical models. This allows us to determine whether the                         effect dissipates. However, due to size of our dataset, all
current review is systematically biased away from the                               results show a significant negative relationship, accounting
average response relative to the value of the preceding n-k                         for ~2% of variance at the closest Review Distance (k = 1).
review(s). To assess how distance is related to this deviation
measure, we use Review Distance (k), and Date Difference.
                                                                                 1435

                         Table 1: Regression model by Reviewer                         Table 2: Regression model by Business
            k         99.9% (CIb)    F (df)                 R2adj                 k   99.9% (CIb)     F (df)                R2adj
            1         (-.11, -.10)   2.8x104 (1, 1.7x106)   .016                  1   (.02, .02)      1179 (1, 2.1x106)     <.001
            2         (-.07, -.06)   8482 (1, 1.4x106)      .01                   2   (.01, .01)      203 (1, 2.1x106)      <.001
            3         (-.05, -.05)   3681 (1, 1.4x106)      .003                  3   (.01, .01)      175 (1, 2.0x106)      <.001
            4         (-.04, -.03)   1997 (1, 1.1x106)      .002                  4   (.004, .007)    121 (1, 1.9x106)      <.001
            5         (-.04, -.03)   1333 (1, 1.0x106)      .001                  5   (.003, .007)    75 (1, 1.9x106)       <.001
            6         (-.03, -.02)   756     (1, 9.4x105)   .001                  6   (.002, .006)    56 (1, 1.8x106)       <.001
            7         (-.03, -.02)   562     (1, 8.7x105)   .001                  7   (.002, .006)    54 (1, 1.8x106)       <.001
  Turning now toward within-business reviews, Fig. 3                          Next, we briefly explore whether there is a similar effect
presents the mean and standard error bars for the deviation                for reviewers and businesses by date. Yelp provides the date
of the current review rating from the mean (y-axis) by the                 (in hours) for each review. However, reviewers occasionally
previous star rating (x-axis) at different Review Distances                provide multiple reviews within the same time frame (e.g.,
(k). This figure suggests an assimilation effect that                      hours, days). To clearly differentiate between previous and
dissipates the farther away the previous review is from the                current reviews, we first took the average review rating per
current review.                                                            day, by reviewer and business, and rounded this to the
                                                                           nearest star rating (1-5). The distribution of the number of
                                                                           days occurring between successive reviews is shown in Fig.
                                                                           1 (bottom). Temporal distances between successive reviews
                                                            k              for both within-reviewer and –business were log-normally
                      0.00                                          1      distributed and thus log transformed for all subsequent
 R x − M (R T −x )
                                                                           analyses (i.e., there were significantly more reviews that
                                                                    2      occurred closer to one another in time, than across time).
                                                                    3      We call this Date Difference—the number of days between
                     −0.02                                                 reviews—and use it in subsequent analyses below.
                                                                    4
                                                                              Using a simple linear regression model, we first centered
                                                                    5      and squared Date Difference. There was a significant
                     −0.04                                          6      interaction between Date Difference and lagged star rating (t
                                                                    7      = -63), such that as the time between a reviewer’s previous
                                                                           star rating increased, an observed contrast effect became
                                                                           more extreme, F(3,1.0x106) = 1.65x104, R2adj = .047.
                               1    2   3   4    5                            Turning to within-business effects of temporal distance on
                               n − k Review Rating                         current review ratings, a linear regression analysis revealed
                                                                           a significant interaction between Date Difference and lag
 Figure 3: Within-business assimilation between previous                   star rating (t = -53), F(3,1.9x106) = 1061, R2adj = .002. This
     and current review ratings at k Review Distances                      within business effect, albeit weak, is also a between
                                                                           reviewer effect—a study yet to be tested in a controlled
  The results of seven linear regression analyses on the                   laboratory environment. That is, businesses are often not
within-business data are presented in Table 2. The linear                  reviewed sequentially by the same reviewer, if ever.
regression model shows a significant negative relationship                 However, the effects of this interaction are less clear,
between previous and current star ratings. As the value of k               showing a slight assimilation effect, that reverses to contrast
increases the model accounts for less of the variance in                   only at the longest temporal intervals, requiring a more
current star ratings. All results show a significant negative              sophisticated series of analysis, discussed below, prior to
relationship, though accounting for less than .1% of                       further interpretation.
variance at the closest Review Distance (k = 1). Hence, this
within-business assimilation effect is considerably weaker                                           Discussion
than the within-reviewer contrast.
                                                                           This study was a guided exploration into the influence that
                                                                           previous business ratings might have on current ratings. We
                                                                           tested the presence of sequential dependencies in business
                                                                           reviews both within reviewer and business, finding that
                                                                           there are significant, albeit subtle, sequential patterns.
                                                                             Prior research guides interpretation of these findings. Past
                                                                           work shows that individuals are likely to provide contrasting
                                                                           evaluations when asked to rate different stimuli on a similar
                                                                        1436

rating scale (Parducci, 1968). In addition, with longer             with a fixed number of ratings per reviewer. However the
temporal intervals the effects of previous responses on             type of distribution we assume when generating such data
current ones tends to dissipate (Doshi et al., 2014). Our           may artificially inflate our findings if it does not reflect a
predictions are loosely drawn from prior work on SDs in             natural distribution we see here.
categorization tasks (Zotov, et al., 2011) as well as moral            Note that the Yelp distribution is not normal, exhibiting a
judgments (Parducci, 1968), such that within-reviewer               J-shape or bimodal distribution at 1-star and 4/5-stars with a
ratings may contrast with previous ratings while within-            mean of 3.75. Recent studies suggest that a J-shape bimodal
business ratings may show effects of assimilation, exploring        distribution, unique to review data, may be the result of an
the effects of longer stimulus intervals (n = 2, 3, etc.) on        underreporting bias (Hu, Zhang, & Pavlou, 2009), such that
current evaluations is a relatively new approach. In this           reviewers are more likely not to provide reviews when the
respect, the current study stands as an initial exploration into    average business rating is similar to their own experience.
the effects of SDs in the wild.                                     Determining an appropriate baseline measure will be
   We found that a reviewer’s current rating deviates from          dependent, in this case, on how we interpret the cause of the
their mean rating in contrast with previous ratigns. If a           J-shape distribution. For instance, this may be dependent on
reviewer’s previous rating was positive, their current rating       the type of reviewer that is considered. Critics are more
is more likely to be less positive than average. This effect        likely to have a unimodal distribution whereas non-critic
dissipates the farther the previous review is from the current      reviewers tend to produce a J-shape distribution (Dellarocas
review, an effect that replicates previous findings that show       & Narayan, 2006). One speculative hypothesis is that when
contrast when making sequential moral judgments on the              one has a choice to write a review (e.g., non-critics), they
same scale (Parducci, 1968). In addition, this effect was           are susceptible to influences of SDs of other’s reviews,
observed across time, such that successive ratings that were        resulting in a bimodal shape compared to those who may
displaced across different temporal distances were more             have less of a choice to write a review (e.g., critics).
likely to contrast with previous ratings. Findings from this           Computational models that explain how sequential
analysis suggest that the observed contrast effect may be           dependencies emerge from the decision making process can
stable across time. This warrants further exploration               help decontaminate current evaluations so as to obtain a
   We found that ratings given to the same business were            more accurate measure of one’s experience (e.g., Mozer, et.
more likely to assimilate to the previous rating, an effect         al, 2010). Such models, though currently only developed for
that flattened at greater review distances. The weakness of         low-level perceptual tasks, might be fruitfully applied to
this effect is most likely due to the nature of the dataset,        areas such as online rating systems shown to impact a
such that many reviewers provide reviews to a single                business’s future success (Luca, 2011). Our current work is
business, so that any effect is naturally between reviewers.        a first step toward uncovering contamination effects that
Just as a participant’s report of an experience is not              may be a rational property of the cognitive system (Qian &
independent of their prior experience, in social                    Aslin, 2014; Wilder et al., 2010; Yu & Cohen, 2009) within
circumstances there may be a sequential dependence across           naturally occurring behavior. Developing tools that can
persons. We speculate (very tentatively) that such an effect,       adjust for such effects might help to provide ratings that
if true, would have interesting implications for how we             reflect the consumer’s true experience.
ought to conceptualize our own judgments as entirely
independent of others’ judgments.                                                           Conclusion
   In addition, we found a very slight assimilation effect          Data sets such as the Yelp, Inc. dataset are incredibly noisy.
within businesses between previous and current review               Reviewers sometimes don’t review for various reasons and
ratings over time. However, this effect reversed at longer          businesses change their names and their products adapting
temporal distances. While initially this effect appears to be       in real time to the demands of consumer behavior. In SD
consistent Review Distance findings, the reversal is                experiments the stimulus is often held constant, but this may
puzzling. Such an effect suggests, perhaps, that evaluations        not be the case in the real world. Restaurants go out of
of our seemingly independent experiences are represented            business, while other change drastically over time.
relative to others’ previous ratings. As such, further              Moreover, Yelp reviews occur over a much larger time
exploration as well as experimentation is necessary to more         course than sequential dependency experiments, and Yelp
fully understand how sequential dependencies influence              reviewers do not see their previous review ratings at the
natural behavior.                                                   time when they make a new rating. If there are trends in
   One possible aim for future studies is to control for the        business quality or reviewer performance over time, or
business’s current rating—normalizing the reviewer’s rating         adjustments to Yelp’s user interface (Yelp, too, must adapt
using the average rating for the business around the time at        to its customers), the ability to discover echoes of cognitive
which the reviewer’s rating is made. This would provide a           effects in the wild may be affected.
more absolute difference measure, adjusted to the business’s           The current work targets a broader goal of validating
average which could be used to determine if observed SD             well-known findings from carefully controlled laboratory
effects can be explained by the business’s current rating. In       studies in large, unconstrained, natural and noisy behavioral
addition, one could generate an artificial baseline dataset         data. Our aim was to determine if we can use well-known
                                                                1437

cognitive findings from controlled laboratory experiments,        Hu, N., Zhang, J., & Pavlou, P. A. (2009). Overcoming the
to sift through that noise in an effort to understand one’s         J-shaped       distribution     of     product      reviews.
true experience and how that experience is affected by              Communications of the ACM, 52(10), 144-147.
cognitive biases. To this end, our exploratory analysis           Laming, D. (1984). The relativity of ‘absolute’
found that current judgments, such as business review               judgements. British Journal of Mathematical and
ratings, are in some way dependent on previous judgments.           Statistical Psychology, 37(2), 152-183.
Reviewer’s current ratings tend to be displaced from their        Liberman, A., Fischer, J., & Whitney, D. (2014). Serial
average rating in a direction that contrasts with their             dependence in the perception of faces. Current Biology,
previous ratings. While a business’s current review rating          24(21), 2569-2574.
tends to assimilate with its previous rating. Our findings, at    Lockhead, G. R. (2004). Absolute judgments are relative: A
times unpredicted and surprising, provide new avenues for           reinterpretation of some psychophysical ideas. Review of
future research while validating the efficacy of previous           General Psychology, 8(4), 265.
well-established laboratory findings in the wild.                 Luca, M. (2011). Reviews, reputation, and revenue: The
                                                                    case of Yelp.com. Harvard Business School
                    Acknowledgments                               Kristjánsson, Á. (2006). Simultaneous priming along
This work was in part funded by an IBM PhD fellowship               multiple feature dimensions in a visual search task. Vision
awarded to David W. Vinson for the 2015-16 academic                 research, 46(16), 2554-2570.
year.                                                             Mozer, M. C., Pashler, H., Wilder, M., Lindsey, R. V.,
                                                                    Jones, M. C., & Jones, M. N. (2010). Decontaminating
                         References                                 human judgments by removing sequential dependencies.
                                                                    In J. Laffterty, C. K. I. Williams, J. Shawe-Taylor, R. S.
Bock, K., & Griffin, Z. M. (2000). The persistence of               Zemel, & A. Culota (Eds.), In Advances in Neural
   structural priming: Transient activation or implicit             Information Processing Systems 23 (pp. 1705-1713). La
   learning?. Journal     of    Experimental      Psychology:       Jolla, CA: NIPS Foundation.
   General, 129(2), 177.                                          Mudambi, S. M., & Schuff, D. (2010). What makes a
Cantallops, S., & Salvi, F. (2014). New consumer behavior:          helpful online review? A study of customer reviews on
   A review of research on eWOM and hotels. International           Amazon. com. MIS quarterly, 34(1), 185-200.
   Journal of Hospitality Management, 36, 41-51.                  Parducci, A. (1968). The relativism of absolute
Dellarocas, C., & Narayan, R. (2006). A statistical measure         judgments. Scientific American.
   of a population’s propensity to engage in post-purchase        Qian, T., & Aslin, R. N. (2014). Learning bundles of stimuli
   online word-of-mouth. Statistical Science, 21(2), 277-           renders stimulus order as a                  cue, not a
   285.                                                             confound. Proceedings of the National Academy of
Dixon, P, McAnsh, S., & Read, L. (2012). Repetition effects         Sciences, 111(40), 14400-14405.
   in grasping. Canadian Journal of Experimental                  Stewart, N., Brown, G. D., & Chater, N. (2005). Absolute
   Psychology, 66.                                                  identification by relative judgment. Psychological
Donkin, C., Heathcote, B. R. A., & Brown, S. D. (2015).             review, 112(4), 881.
   Why is accurately labelling simple magnitudes so hard? A       Ward, L. M. (1973). Repeated magnitude estimations with a
   past, present and future look at simple perceptual               variable standard: Sequential effects and other
   judgment. The Oxford Handbook of Computational and               properties. Perception & Psychophysics, 13(2), 193-200.
   Mathematical Psychology.                                       Ward, L. M., & Lockhead, G. R. (1971). Response system
Doshi, A., Tran, C., Wilder, M. H., Mozer, M. C., &                 processes     in     absolute    judgment. Perception     &
   Trivedi, M. M. (2012). Sequential dependencies in                Psychophysics, 9(1), 73-78.
   driving. Cognitive science, 36(5), 948-963.                    Wilder, M., Jones, M., & Mozer, M. C. (2010). Sequential
Furnham, A. (1986). The robustness of the recency effect:           effects reflect parallel learning of multiple environmental
   Studies using legal evidence. Journal of General                 regularities. In Y. Bengio, D. Schuurmans, J. Lafferty,
   Psychology, 113, 351-357.                                        C.K.I. Williams, & A. Culotta (Eds.), Advances in Neural
Freyd, J. J., & Finke, R. A. (1984). Representational               Information Processing Systems 22 (pp. 2053-2061). La
   momentum. Journal of Experimental Psychology:                    Jolla, CA: NIPS Foundation.
   Learning, Memory, and Cognition, 10(1), 126-132.               Yu, A. J., & Cohen, J. D. (2009). Sequential effects:
Garner, W. R. (1953). An informational analysis of absolute         superstition or rational behavior?. In Advances in neural
   judgments of loudness. Journal of Experimental                   information processing systems (pp. 1873-1880).
   Psychology, 46(5), 373.                                        Zotov, V., Jones, M. N., & Mewhort, D. (2011). Contrast
Holland, M. K., & Lockhead, G. R. (1968). Sequential                and assimilation in categorization and exemplar
   effects in absolute judgments of loudness. Perception &          production. Attention, Perception, & Psychophysics 73,
   Psychophysics, 3(6), 409-414.                                    621-639.
Hsu, S. M., & Yang, L. X. (2013). Sequential effects in
   facial expression categorization. Emotion, 13(3), 573.
                                                              1438

