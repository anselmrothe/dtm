           How Different Frames of Reference Interact: A Neural Network Model
                                                 Weizhi Nan (nanwz@psych.ac.cn)ͣ,
                                                  Yanlong Sun (ysun@tamhsc.edu)ᵇ,
                                                    Xun Liu (liux@psych.ac.cn)ᵃ,
                                               Hongbin Wang (hwang@tamhsc.edu)ᵇ
                                ᵃ Key Laboratory of Behavioral Science, Institute of Psychology,
                     Chinese Academy of Sciences, 16 Lincui Road, Chaoyang District, Beijing 100101, China
                         ᵇ Center for Biomedical Informatics, Texas A&M University Health Science Center,
                                          2121 West Holcombe Blvd, Houston, TX 77030, USA
                              Abstract                                 reference point. For a comprehensive review, see (Mou,
                                                                       Fan, McNamara, & Owen, 2008; Mou & McNamara, 2002;
   It has been argued that people use multiple frames of
   reference (FORs) for representing and updating spatial              Sun & Wang, 2010, 2014; Tamborello et al., 2012;
   relationships between objects in a complex environment.             Yamamoto & Philbeck, 2013).
   When there are conflicts among representations of multiple             Particularly of our interests is how multiple FOR
   FORs, they compete to determine behavior. “Frame of                 representations develop and interact with each other.
   Reference-based Map of Salience” theory (FORMS) suggests            Mathematically, all FORs are equivalent. Depending on
   that FORs with high salience may be processed in priority.          specific situations, however, some FORs are more useful or
   Here, we report a computational neural network model for a
   two-cannon task, which naturally involves multiple FORs
                                                                       convenient. In comparison, EFOR is probably more
   with different levels of salience: intrinsic frame of reference     automatic and almost effortless, AFOR is quite stable but
   (IFOR) and egocentric frame of reference (EFOR). The goal           computationally demanding, and IFOR is a balance between
   is to investigate the computational neural mechanisms               flexibility and stability. “Frame of Reference-based Map of
   underlying human spatial performance. Our simulation results        Salience” theory (FORMS) states the human brain
   fit earlier behavioral results well. The model suggests             represents spatial information simultaneously using multiple
   although multiple FORs may be initially represented                 FORs, each being a spatial map of salience (i.e. only salient
   independently, they interfere with each other by the inhibitory
   competition of neurons in the later process (in hidden layer)       objects or locations are represented on each map), and that
   for conflict resolution. Moreover, salience may modulate the        human performance is determined by the interaction of all
   competition by prioritizing FORs with high salience levels.         relevant FOR-based representations (Sun & Wang, 2010,
   These results represent a connectionist support for the             2014; Tamborello et al., 2012; Wang et al., 2001; Wang,
   FORMS theory.                                                       Sun, Johnson, & Yuan, 2005; Yamamoto & Philbeck,
   Keywords: frame of reference; inhibitory competition;               2013).
   salience; neural network model                                         To understand the interaction among multiple FORs and
                                                                       the effect of salience, Tamborello et al. (2012) designed a
                           Introduction                                two-cannon task (a modified and simplified version is
People adopt multiple frames of reference (FORs) to                    shown in Figure 1), in which two cannons (a red and a blue)
represent the spatial relationship of objects in a complex             were surrounded by 8 pellets in red or blue color. The
environment (Klatzky, 1998; Mou & McNamara, 2002;                      salience of the cannons was determined by the pellet color
Piaget & Inhelder, 1956; Sun & Wang, 2014; Tamborello,                 ratio such that the cannon with more same-color pellets was
Sun, & Wang, 2012; Wang, Johnson, & Zhang, 2001; Zacks                 more salient. In the task, when one of the pellets was
& Michelon, 2005). Based on the relationship with the                  randomly chosen as the target pellet (flashing), the cannon
observer, FORs can be classified into three types, egocentric          in the same color became the target cannon. Participants
FOR (EFOR), intrinsic FOR (IFOR) and allocentric FOR                   were asked to rotate the target cannon to the location of the
(AFOR) (Klatzky, 1998; Mou & McNamara, 2002;                           flashing target pellet in the shortest way by pressing either
Tamborello et al., 2012; Wang & Spelke, 2002). An EFOR-                the left-arrow or the right-arrow button on the keyboard. An
based representation is anchored to the observer, which                analysis (Figure 3A and 3B) showed that reaction time (RT)
needs to be updated following the movement of the                      became longer when there was a conflict among different
observer’s eye, head, body coordinates (Wang et al., 2001).            FOR-based representations. RT in cannon angle 180°
In an IFOR-based representation, an object or an object                condition was longer than RT in cannon angle 0° condition
group in the viewing environment but exogenous to the                  (Cannon Angle Effect). In the cannon angle 180° condition,
observer is used as the reference point. For example, a table          RT for trials where the target pellet appeared in the minority
is used as an IFOR anchor in the description “the cup is on            color group was longer than RT for those in the majority
the table”. IFORs remain stable with the observer’s                    color group (Salience Effect). RT in target cannon point-
movement but have to be updated when the reference object              down condition was longer than RT in target cannon point-
moves. In an AFOR-based representation, the entire                     up condition (Target Cannon Orientation Effect). And the
environment, such as a room or a city, is taken as the                 target cannon orientation effect was larger in cannon angle
                                                                       180° condition than that in cannon angle 0° condition,
                                                                   1457

Figure 1. A schematic illustration of the two-
cannon task. Middle: trial procedure. At the
beginning of each trial, a fixation cross was
presented at the center of the screen for 500 ms,
and subjects were asked to fixate on it, then
two cannons (one red and one blue) and eight
pellets (in either red or blue) were presented
together on the computer screen. After a one-
second pause, a randomly selected pellet would
flash as the target pellet. The participants’ task
was to use the arrow keys to rotate the cannon
in the same color of the target pellet toward the
target pellet as quickly as possible. Auditory
feedback was played for either the correct (a
shot sound) or incorrect (an alarm sound)
response; top left: cannon congruent (0°) and
cannon incongruent (180°); top right: pellet
color ratio (blue : red = 6:2, 4:4, and 2:6);
bottom left: likely target pellet (target occurs in
the majority color pellets) and less likely target
pellet (target occurs in the minority color
pellets); bottom right: target cannon orientation
up (12 o’clock is 0°, clockwise rotation, set
315°, 0°, and 45° as the target cannon up
condition) and down (set 135°, 180°, and 225°
as the target cannon down condition).
    Table 1. The training data for the model. Each row represents a group of trials that covers different FORs with different
 orientations and salience, different target pellet color. The first three columns (“FOR number”, “Cannon Angle” and “Pellet
   Ratio B:R”) represent different conditions; Column “Weights” represents relative frequency; Column “Types” represents
   how many trial types are contained in each group; the last ten columns represent specific input information, with salience
  level ranging from 0.2 to 0.8, and cannon orientation or target location as up-right (UR), up (U), down-left (DL), or down-
                                    right (DR); the last column is the response (right or left key).
which means there was an interaction between cannon angle             2014). In the current study, we evaluate the hypothesis by
effect and target cannon orientation effect. These results            developing a neural network model of the two-cannon task.
indicate that people encounter difficulties when they have to         The model is implemented in Leabra (local, error-driven and
process different conflicting FOR representations and that            associative, biologically realistic algorithm), a biologically
they seem to prioritize processing of each FOR by salience.           based computational modeling framework (O'Reilly, 1998;
   How the conflicts occur raises an issue. In particular, how        O'Reilly, Munakata, Frank, & Hazy, 2012). Among all the
are the conflicts among FORs represented and what is the              features, Leabra incorporates complex network dynamics
mechanism of conflict resolution? Previously, we have                 using bidirectional excitatory connections and fast pooled
hinted that spatiotemporal association and predictive                 inhibition, which makes it an ideal candidate for exploring
learning play a major role in such tasks (Sun & Wang,                 the interference among conflicting cognitive process.
                                                                 1458

                                                                   Training and Testing
                                                                   The training data set consists of 13 groups of trials (Table
                                                                   1). The first 12 groups are used to train the three FORs-
                                                                   coexisting conditions and the last group is for the single
                                                                   EROR condition. The first 12 groups are generated based on
                                                                   three independent variables: cannon angle (0°, 180°), the
                                                                   pellet color ratio (blue: red = 2:6, 4:4, and 6:2), and target
                                                                   pellet color (Blue, Red). The orientations of each cannon
                                                                   (shown in “Blue Cannon Orientation” column and “Red
                                                                   Cannon Orientation” column, same orientations for cannon
                                                                   angle 0° condition, opposite orientations for cannon angle
                                                                   180° condition) control the cannon angle (shown in
                                                                   “Cannon Angle” column). The pellet color ratio (shown in
                                                                   “Pellet Ratio B: R” column) will change the salience of each
                                                                   cannon (shown in “Blue Cannon Salience” column and
     Figure 2. The model of the two-cannon task. Three 3x3         “Red Cannon Salience” column. e.g. if blue: red= 2:6, we
   FOR orientation layers (excluding the center neuron, the        set 0.2 for blue salience and 0.8 for red salience). The target
 other eight neurons corresponding to eight orientations: U-       pellet color (shown in “Blue Target Pellet” column and
   up, UR-up-right, R-right, DR-down-right, D-down, DL-            “Red Target Pellet” column) controls the target pellet color
 down-left, L-left, UL-up-left) with three 1x1 salience layer;     of each trial and the blue/red target pellet also indicates the
   one 3x3 target pellet location layer (excluding the center      correct response should be made by the blue/red cannon. In
 neuron, the other neurons corresponding to eight locations)       each of the 12 groups, there are 36 trial types separated by
with two 1x1 target pellet color layer (representing the color     the cannon orientation and target pellet location (shown in
of the target pellet); one 10x10 hidden layer; one 2x1 output      “Types” column. 8 cannon orientations and different target
                       layer (Left, Right).                        pellet location excluding locations same with or opposite to
                                                                   cannon and EFOR orientations). In order to increase the
              The Neural Network Model                             robustness of salience effect, we set the salience groups 3
                                                                   times more than the other groups (shown in “Weights”
Model Architecture and Connectivity                                column).
The model (Figure 2) consists of three levels of layers               EFOR is always automatic activated as the point-up
(input, hidden and output). At the input level, there are nine     orientation because in behavioral studies participants
input layers. Each layer encodes one piece of stimulus             (“observers”) were always facing with the computer screen.
information independently. Three 3x3 layers are used to            When the target cannon points above the horizontal, the
encode the orientations of two IFORs and one EFOR (Blue            target cannon’s IFOR matches the participant’s EFOR;
Cannon Orientation, Red Cannon Orientation and EFOR                when it points below the horizontal, IFOR does not match
Orientation in Figure 2). Three 1x1 layers aside the three         EFOR, causing a conflict between IFOR and EFOR (Target
FOR input layers are used to encode their salience (Blue           Cannon Orientation Effect). Thus, we set the last group for
Cannon Salience, Red Cannon Salience, EFOR Salience).              the EFOR, and specially train the single EFOR with an only
One 3x3 layer filled in gray color is used to encode the           point-up orientation group. In EFOR group, there are 6 trial
locations of target pellet (Target Pellet Location). Two 1x1       types (1 EFOR orientation and 6 target pellet location
layers aside the target location input layer are used to           excluding locations same with or opposite to EFOR
encode the color of target pellet (Blue Target Pellet, Red         orientation). In order to increase the robustness of the effect,
Target Pellet). At the hidden level, one 10x10 layer is used       we set the weight of the EFOR group as 50. The total trial
to represent and process all the vision input information. At      number of training data is (1*10+3*2) *36+50*6=876. And
the output level, one 2x1 layer is used to encode the              the testing data contains only three FORs coexisting groups,
response.                                                          and each group only repeats by one time, so the total trial
   The connections among the layers are all bi-directional.        number of testing data is 12*36=432.
The hidden layer has a self-recurrent excitatory connection           We set the maximum cycles of each trial as 200. If the
to itself. The weight of forward connection is stronger than       cycle reaches 200, the current training trial would stop and
the weight of the feedback and self-recurrent excitatory           switch to next trial. The stop criterion of the whole training
connection with a ratio of 2:1. The k-winner-take-all              is the average sum square error (SSE) reaching 0 by four
parameter is used in the hidden layer (the percentage, k=          times continuously. In the testing phase, when the activation
25%) and the output layer (the number of neurons, k= 1),           of output layer reaches a set threshold (0.85) a response is
which controls the activation level of the two layers without      said to have been made. The number of cycles is taken as
using explicit inhibitory neurons. All other parameters used       the measure of model RT.
in the model take the default values of Leabra (O'Reilly et
al., 2012).
                                                               1459

   Thirty “simulated subjects”, each with randomly                   target pellet colors (red target pellet: 26.20 ± 0.79, blue
initialized weights were trained and tested to get thirty            target pellet: 26.18 ± 0.91) showed no difference in the blue:
independent simulation results.                                      red = 4:4 condition, p > .05. No other significant effects
                                                                     were obtained, ps > .05.
                    Simulation Results
Analysis
The dependent variable is the number of computational
cycles of each trial. The independent variables are cannon
angle (0°, 180°), target cannon orientation (Up, Down),
pellets color ratio (Blue: Red = 2:6, 4:4, 6:2), target pellet
color (Red, Blue). One 2 (cannon angle) × 3 (pellet color
ratio) × 2 (target pellet color) repeated-measures ANOVA
was performed on the cycles to search for the main effects
of cannon angle effect and the salience effect (Figure 3C.
and Table 2). A 2 (cannon angle × 2 (target cannon
orientation) repeated-measures ANOVA was performed on
the cycles to search for the main effects of target cannon
orientation effect, cannon angle effect, and their interaction
(Figure 3D and Table 3). A correlation analysis was
performed on the simulation results and the behavioral
results (Figure 4). According to the FORMS theory and the
earlier behavioral experimental results, we expected our
model could learn from the training data, and the simulation
results would have a positive correlation with earlier
behavioral experimental results. The effects of interest are
summarized below.                                                        Figure 3 A. RTs for target pellet color, pellet color ratio
                                                                       and cannon angle in behavioral results; B. RTs for target
Cannon Angle Effect and Salience Effect                               cannon orientation and cannon angle in behavioral results;
In Figure 3C and Table 2, there was a significant main                   C. Cycles for target pellet color, pellet color ratio and
effect of cannon angle effect, F (1, 29) = 719.96, p < .001,            cannon angle in simulation results; D. Cycles for target
ηp2 = .96, indicating that the cycles in the cannon angle 0°          cannon orientation and cannon angle in simulation results.
condition (23.51 ± 0.07) were fewer than the cycles in the
cannon angle 180° condition (26.28 ± 0.11). There was a                  Table 2: Cycles of target pellet color, pellet color ratio,
significant interaction of pellet color ratio and target pellet                             and cannon angle
color, F (2, 58) = 9.10, p < .001, ηp2 = .24. Post hoc
analysis suggested that the pattern as below: the cycles of          Cannon     Target                Pellet color ratio
the red target pellet (24.81 ± 0.12) were marginally fewer            angle      pellet                   blue: red
than that of the blue target pellet (25.09 ± 0.13) in the blue:                  color        2:6            4:4             6:2
red = 2:6 condition, p = .09. In contrast, cycles of the red           180°       blue    26.82±1.15 26.18±0.91 25.90±0.88
target pellet (25.01 ± 0.13) had a trend to be larger than that                   red     25.96±0.99 26.20±0.79 26.63±1.06
of the blue target pellet (24.77 ± 0.11) in the blue: red = 6:2         0°        blue    23.36±0.52 23.45±0.52 23.64±0.53
condition, p > .05. The cycles of the two target pellet colors                    red     23.66±0.50 23.57±0.60 23.40±0.51
(red target pellet: 24.89 ± 0.11, blue target pellet: 24.82 ±
0.11) showed no difference in the blue: red = 4:4 condition,            Table 3: Cycles of target cannon orientation and cannon
p > .05. This interaction pattern only appeared significantly                                     angle
in the cannon angle 180° condition and not in the cannon
angle 0° condition, as revealed by the significant three-way             Target cannon orientation           Cannon angle
interaction among cannon angle, target pellet color, and                                                    0°        180°
pellet color ratio, F (2,58) = 47.84, p < .001, ηp2 = .62. Post                     Down               23.63±0.52 26.87±1.03
hoc analysis in cannon angle 180° condition suggested that                           Up                22.89±0.48 25.16±0.65
the pattern as below: the cycles of the red target pellet
(25.96 ± 0.99) were fewer than that of the blue target pellet        Target Cannon Orientation Effect and Cannon
(26.82 ± 1.15) in the blue: red = 2:6 condition, p < .01. In
                                                                     Angle Effect
contrast, cycles of the red target pellet (26.63 ± 1.06) were
larger than that of the blue target pellet (25.90 ± 0.88) in the     The cycles results (Figure 3D and Table 3) showed
blue: red = 6:2 condition, p < .01. The cycles of the two            significant main effects for target cannon orientation effect
                                                                 1460

and cannon angle effect [F (1, 29) = 75.82, p < .001, ηp2 =         different FOR-based representations by inhibitory
.72; F (1, 29) = 717.79, p < .001, ηp2 = .96]. The interaction      competition among groups of neurons and predictive
of the two factors was also significant, F (1, 29) = 25.03, p       learning.
< .001, ηp2 = .46. Post hoc analysis suggested that target             According to the FORMS theory, multiple representations
cannon orientation effect in the cannon angle 180° condition        with respect to different FORs may co-exist in a segmented
(1.71 ± 0.20) was larger than the effect in the cannon angle        but competitive fashion. The salience of any particular
0° condition (0.74 ± 0.13).                                         representation is driven by not only the perception of a static
                                                                    scene (e.g., the ratio between blue and red pellets) but also
Correlation                                                         the prediction of the changing environment (e.g., a red
A correlation analysis between the simulation results and           cannon would be more likely to be the target cannon
behavioral results was conducted. For cannon angle effect           because there are more red pellets). This means that in a
and salience effect, we combined all the 12 conditions              complex environment with multiple spatial relationships,
(target color × cannon angle × pellet color ratio) together to      representations anchored to different FORs have to be
analyze the relation among these conditions. It is evident          constantly maintained and updated. The simulation results
results (Figure 4A) that there was a significantly positive         from the neural network model suggest that the process of
correlation, r = 0.53, p < .01, df = 358. For the cannon angle      maintenance and updating can take place distributive within
effect and target cannon orientation effect, we combined the        the same group of neurons (hidden layer), and therefore
4 conditions (target cannon orientation × cannon angle)             afford the possibility of interference among different FOR-
together to analyze the relation among these conditions.            based representations at the neural level.
Results (Figure 4B) showed that there was also a                       The model showed the cannon angle effect, target cannon
significantly positive correlation, r =.56, p < .01, df = 118.      orientation effect and the interaction between them. The
                                                                    cannon angle effect was demonstrated by the fewer cycles in
                                                                    the cannon angle 0° condition (the orientation of the
                                                                    potential IFOR was the same as the orientation of the target
                                                                    IFOR) than in the cannon angle 180° condition (the
                                                                    orientation of the potential IFOR was opposite to the
                                                                    orientation of target IFOR). And the target cannon
                                                                    orientation effect was revealed by the fact that the cycles of
                                                                    the target cannon point-up condition (the orientation of
                                                                    target IFOR was the same as the orientation of EFOR) were
                                                                    fewer than that of the target cannon point-down condition
                                                                    (the orientation of target IFOR was opposite to the
                                                                    orientation of EFOR). These two effects suggest that in the
                                                                    hidden layer, there may be the same group of neurons
                                                                    responsible for computing the output based on the different
                                                                    FORs (blue cannon anchored to blue IFOR, red cannon
                                                                    anchored to red IFOR and observer anchored to EFOR).
                                                                    Therefore, when the orientation of the target IFOR was
                                                                    same as the orientation of the potential IFOR or EFOR, the
                                                                    response became faster. On the contrary, when their
                                                                    orientations were different, inhibitory competition occurred,
                                                                    and neurons took more time to focus on the target IFOR,
                                                                    leading to slower responses. In addition, the interaction
                                                                    between the two effects was revealed by the larger target
                                                                    cannon orientation effect in cannon angle 180° condition
                                                                    than that in cannon angle 0° condition. According to the
  Figure 4 A. Correlation in target color, cannon angle and         adding factor theory, when two processes occur in the same
pellet color ratio; B. Correlation in target cannon orientation     phase, they will compete with each other for the cognitive
                       and cannon angle.                            resource, resulting in longer RT (Liu, Banich, Jacobson, &
                                                                    Tanabe, 2004; Liu, Park, Gu, & Fan, 2010; Sternberg,
                         Discussion                                 1969). In this study, it is likely that some shared neurons for
The results from the neural network model of the two-               FOR information processing in the hidden layer give rise to
cannon task are consistent with our earlier interpretations of      these effects. The salience effect was demonstrated by fewer
the behavioral results based on the FORMS theory. The               cycles in the likely target pellet condition than that in the
model shows stable performance and replicates all major             less likely target pellet condition. We hypothesize that
effects with a close match to the behavioral results.               neurons in the hidden layer learned to predict the cannon
Importantly, these results provide a neural basis to our            with the same color of majority pellets as the target cannon.
theory where we can characterize the competition between
                                                                1461

If the prediction was right, the response would be fast. If the              of stimulus-response compatibility effects. Atten
prediction was incorrect, it would take more time to update                  Percept Psychophys, 72(6), 1710-1720.
the target cannon, so the response would be slow. The               Mou, W., Fan, Y., McNamara, T. P., & Owen, C. B. (2008).
salience level associated with each FOR might enhance the                    Intrinsic frames of reference and egocentric
competition and lead to a prioritization of the corresponding                viewpoints in scene recognition. Cognition, 106(2),
FOR. However, it was the real-time prediction and                            750-769.
inhibitory competition that contributed to the extra                Mou, W., & McNamara, T. P. (2002). Intrinsic frames of
computational time for resolving potential conflicts (Sun &                  reference in spatial memory. J Exp Psychol Learn
Wang, 2014).                                                                 Mem Cogn, 28(1), 162-170.
   The above analysis suggests that the interaction among           O'Reilly, R. C. (1998). Six principles for biologically based
neuron groups in the hidden layer may be responsible for                     computational models of cortical cognition. Trends
the modeling results. The next step is to perform further                    in Cognitive Sciences, 2(11), 455-462.
data analysis, such as PCA and cluster analysis to evaluate         O'Reilly, R. C., Munakata, Y., Frank, M., & Hazy, T.
these predictions. Another step is to add the cue data to the                (2012). Computational cognitive neuroscience:
testing data set to make the model process the input                         PediaPress.
information in temporal sequences. Then the predictive              Piaget, J., & Inhelder, B. (1956). The child’s concept of
learning and the target decision making could be more                        space. New York: Humanities Pr.
clearly separated in the model.                                     Sternberg, S. (1969). The discovery of processing stages:
                                                                             Extensions      of    Donders'       method.      Acta
                         Conclusion                                          Psychologica, 30, 276-315.
Our neural network model replicates the behavioral results          Sun, Y., & Wang, H. (2010). Perception of space by
well, supporting the claim that representations with multiple                multiple intrinsic frames of reference. Plos One,
FORs co-exist and compete to determine performance.                          5(5), e10442.
Importantly, it suggests a plausible neural mechanism               Sun, Y., & Wang, H. (2014). Insight into others’ minds:
underlying the FORMS theory. Depending on whether there                      spatio-temporal representations by intrinsic frame
are conflicts among different FOR representations and                        of reference. Frontiers in Human Neuroscience,
whether the actual outcome is consistent with the                            8(58), 1-11.
expectation, competition takes place at different levels and        Tamborello, F. P., 2nd, Sun, Y., & Wang, H. (2012). Spatial
results in the engagement and disengagement of different                     reasoning with multiple intrinsic frames of
FOR-based representations. According to the salience                         reference. Experimental Psychology, 59(1), 3-10.
effect, the internal spatial representation of the environment      Wang, H., Johnson, T. R., & Zhang, J. (2001). The mind’s
is always dynamically constructed and updated toward the                     views of space. Paper presented at the Proceedings
anticipated outcomes, rather than just representing static                   of the Third International Conference of Cognitive
associations of the current spatial configuration. These                     Science.
results support our interpretation of spatiotemporal                Wang, H., Sun, Y., Johnson, T. R., & Yuan, Y. (2005).
association and predictive learning.                                         Prioritized spatial updating in the intrinsic frame of
                                                                             reference. Spatial Cognition and Computation,
                                                                             5(1), 89-113.
                    Acknowledgments                                 Wang, R., & Spelke, E. (2002). Human spatial
This work was partially supported by a Natural Science                       representation: insights from animals. Trends in
Foundation of China grant (31328013), an Air Force Office                    Cognitive Sciences, 6(9), 376.
of Scientific Research (AFOSR) grant (FA9550-12-1-0457),            Yamamoto, N., & Philbeck, J. W. (2013). Intrinsic frames
and an Office of Naval Research (ONR) grant (N00014-16-                      of reference in haptic spatial learning. Cognition,
1-2111).                                                                     129(2), 447-456.
                                                                    Zacks, J. M., & Michelon, P. (2005). Transformations of
                         References                                          visuospatial images. Behav Cogn Neurosci Rev,
Klatzky, R. L. (1998). Allocentric and egocentric spatial                    4(2), 96-118.
          representations: Definitions, distinctions, and
          interconnections. Paper presented at the Spatial
          cognition.
Liu, X., Banich, M. T., Jacobson, B. L., & Tanabe, J. L.
          (2004). Common and distinct neural substrates of
          attentional control in an integrated Simon and
          spatial Stroop task as assessed by event-related
          fMRI. Neuroimage, 22(3), 1097-1106.
Liu, X., Park, Y., Gu, X., & Fan, J. (2010). Dimensional
          overlap accounts for independence and integration
                                                                1462

