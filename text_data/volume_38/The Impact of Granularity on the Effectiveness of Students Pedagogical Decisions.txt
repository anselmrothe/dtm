 The Impact of Granularity on the Effectiveness of Students’ Pedagogical Decision
                              Guojing Zhou, Collin F. Lynch, Thomas W. Price, Tiffany Barnes, Min Chi
                                                      Department of Computer Science
                                                       North Carolina State University
                                           {gzhou3,cflynch,twprice, tmbarnes,mchi}@ncsu.edu
                               Abstract                                     On the other hand, much previous research showed that it
                                                                         is desirable for student to experience a sense of control over
   In this study we explored the impact of student versus tutor
   pedagogical decision-making on learning. More specifically,           their own learning (Harackiewicz, Sansone, Blair, Epstein, &
   we examined what would happen if we let students decide               Manderlink, 1987). People are likely to persist at doing con-
   how to handle the next task: to view it as a worked exam-             structive things, like learning, exercising, quitting smoking,
   ple or to solve it as a problem solving. We examined this im-
   pact at two levels of task granularity: problem vs. step. This        or fighting cavities, when they are given the choice and when
   2 × 2 study was conducted on an existing Intelligent Tutoring         they can make decisions. Letting students make decisions
   System (ITS) called Pyrenees. 279 students were randomly              during the tutorial process should make them feel that they
   assigned to four conditions and the domain content and re-
   quired steps were strictly controlled to be equivalent across         are actively directing their own learning process and not just
   four conditions: all students used the same system, followed          passively following it. Therefore, in this paper we provided
   the same general procedure, studied the same training materi-         the students with two different yet both reasonable choices
   als, and worked through the same training problems. The only
   substantive differences among the four conditions were deci-          and let them decide how they want to solve the problem next.
   sion agency {Student vs. Tutor} and granularity {Problem vs.          So the question is: can students make effective pedagogical
   Step}. That is: who decided to present an example or to solve         decisions that would promote their learning?
   a problem; and was the decision made problem-by-problem or
   step-by-step? Our results showed that there was a significant            Moreover, we investigated the impact of students’ deci-
   interaction effect between decision agency and granularity on         sions across two levels of granularity: problem versus step.
   student learning and a significant main effect of granularity on      Tutoring in domains such as math and science can be viewed
   time on training. That is, step level decisions can be more ef-
   fective than problem level decisions but the students were more       as a two-loop procedure (Vanlehn, 2006). In the outer loop,
   likely to make effective pedagogical decisions at problem level       the tutor makes task or problem-level decisions such as de-
   than step level. In general, on both problem and step levels, the     ciding what problem to solve next, while the inner loop con-
   students were significantly more likely to decide to do problem
   solving rather than study it as a worked example.                     trols step level decisions such as whether or not to give a hint.
   Keywords: pedagogical policy, student-centered learning,              In educational literature, ‘steps’ often refer to the application
   problem solving, faded worked example, granularity                    of a major domain principle such as Newton’s Third Law of
                                                                         Thermodynamics. Solving a complete problem generally in-
                           Introduction                                  volves applying many individual principles in a logical order.
Human one-on-one tutoring is one of the most effective way                  In theory, problem-level decisions are at a larger grain size
to improve student learning (Bloom, 1984). Intelligent Tu-               and thus once students make one ‘big’ decision, they can
toring Systems (ITSs) are computer systems that mimic as-                focus on comprehending an example or solving a problem.
pects of human tutors and have also shown to be successful as            However, such ”big” decision might not be very sensitive to
well (Koedinger, Anderson, Hadley, & Mark, 1997; Vanlehn,                students’ specific moment-by-moment needs. For example, a
2006). Most ITSs are tutor-centered. The tutor is respon-                student faces difficulty with a single principle then a complete
sible for selecting the next action to take at any given time.           worked example may rob them of the chance to exercise other
Each of these decisions affects student’s successive actions             skills. When making step-level decisions, by contrast, stu-
and performance. In the learning literature, the skills used to          dents may be better able to tailor their decisions to their im-
make such decisions are generally referred to as pedagogical             mediate needs and current knowledge level. However, mak-
skills. More formally, Chi et al. defined pedagogical skills             ing many fine grain decisions can be more frustrating than
are those “involve skillful execution of tactics, such as giving         beneficial over time.
explanations and feedback, or selecting the appropriate prob-               In order to investigate the effectiveness of students’ ped-
lems or questions to ask the students” (M. T. H. Chi, Siler, &           agogical decision-making at both levels of granularity, it is
Jeong, 2004). Most ITSs generally employ fixed pedagogi-                 necessary to separate the pedagogical decisions from the in-
cal policies that do not adapt to users’ needs, or they rely on          structional content, strictly controlling the content so that it is
hand-coded rules that seek to implement existing cognitive or            equivalent for all participants. To strictly control the content
instructional theories that may not have been well-evaluated.            to be equivalent, 1) we used an ITS which provides equal sup-
For example, in most ITSs students are asked to solve a se-              port for all learners; and 2) we focused on tutorial decisions
ries of training problems while research showed that studying            that cover the same domain content at both problem and step
worked examples can be more effective than solving prob-                 levels, in this case Worked Examples (WE) versus Problem-
lems and the former generally takes much less time (Sweller              Solving (PS). In WE, student were given a detailed example
& Cooper, 1985; McLaren & Isotani, 2011).                                showing the expert solution for the problem or were shown
                                                                     2801

the best step to take given their current solution state. In PS,     Students Pedagogical Decision on ITS
by contrast,the students were tasked with solving the same
                                                                     Prior research on problem-level decision-making has primar-
problem using the ITS or completing an individual problem-
                                                                     ily focused on the impact of letting the students dictate con-
solving step. While engaging students in decision-making
                                                                     tent, e.g which problem to solve but not let students to decide
within an ITS is not novel, prior researchers have generally
                                                                     how, e.g. WE vs. PS. The results for student step-level ped-
focused on letting students dictate content by letting them de-
                                                                     agogical decision-making are inclusive. Aleven & Koedinger
cide what problem they wish to solve but not how they wished
                                                                     studied students’ help-seeking behaviors in the Cognitive Tu-
to solve it (Koedinger et al., 1997). So as far as we know, no
                                                                     tor (Aleven & Koedinger, 2000) where tutor permits students
prior research has investigated pedagogical decision-making
                                                                     to request help when they do not know what step to take next.
independently of content selection.
                                                                     Help is provided via a sequence of hints that progress from
   In short, our primary research question is: will the gran-        general top-level hints that prompt the student to consider a
ularity of the pedagogical decisions have an impact on the           principle or variable, to bottom-out hints that tell them exactly
effectiveness of students’ pedagogical decision-making? To           what action to take. They found that students do not always
investigate this question we will compare students’ pedagog-         have the necessary metacognitive skills to know when they
ical decisions against tutor’s decisions.                            need help. They tend to wait too long before requesting infor-
                                                                     mation, and then focus only on applying the bottom-out ac-
Background                                                           tion rather than processing the top-level conceptual guidance.
                                                                     Roll et al. by contrast examined the relationship between stu-
WE/PS, vs. FWE
                                                                     dents’ help-seeking patterns and their learning (Roll, Baker,
A number of researchers have examined the impacts of                 Aleven, & Koedinger, 2014). They found that asking for
problem-level PS, problem-level WE, vs. Faded Worked                 help on challenging steps was generally productive while help
Example (FWEs) (Renkl, Atkinson, Maier, & Staley, 2002;              abusing behaviors were correlated with poor learning.
Schwonke et al., 2009; Najar, Mitrovic, & McLaren, 2014;                Therefore prior research on students’ help-seeking sug-
Salden, Aleven, Schwonke, & Renkl, 2010). FWEs interleave            gests that the students can benefit substantially from effec-
problem-solving steps with worked example steps within a             tive pedagogical decision-making. Yet they often lack the
single problem. Renkl et al. compared WE-PS pairs with               metacognitive skills that are required to do so. On the other
FWE using a fixed fading policy (Renkl et al., 2002). In that        hand, help in ITSs is generally provided on demand, and
study the number of example steps and problem-solving ac-            better-performing students are less likely to ask for it. Thus
tions were strictly equal between the conditions. They found         some students may simply never need to do so. In this
that FWEs with the fixed fading policy significantly outper-         study we controlled for this possible conflict by focusing on
formed the WE-PS pairs. They found no significant time-              WE/PS decisions, and by examining both problem and step-
on-task differences between the two groups. Schwonke et              level decision-making. This allows us to evaluate all stu-
al. compared FWE with a fixed fading policy to tutored PS            dents’ decision-making, not just the lower-performers and
(Schwonke et al., 2009). Over the course of two studies,             help-abusers. It also allows us to investigate the impact of
they found no significant differences between the two condi-         granularity on student learning outcomes.
tions in terms of their learning outcomes. However the FWE
group spent significantly less time on task than the tutored PS      Our Approach
group. Najar and colleagues compared FWE with an adap-               Previous studies on problem-level decision-making, PS vs.
tive fading policy to WE-PS pairs. They found that the FWE           WE, mainly employed some fixed pedagogical polices (either
condition significantly outperformed the WE-PS condition in          WE-PS or PS-WE) and prior studies on step-level decision-
their learning outcomes and spent significantly less time on         making, FWE, either used fixed fading polices or relied on
task (Najar et al., 2014). Finally, Salden et al. compared           hand-coded adaptive polices. With adaptive policies, the sys-
three conditions: FWE with a fixed fading policy, FWE with           tem decides whether the next step is WE or PS based on a
an adaptive fading policy, and PS-only (Salden et al., 2010).        realtime assessment of the student’s concept mastery. For ex-
They found that the adaptive FWE group outperformed the              ample, students may be asked to solve steps involving the
fixed FWE who, in turn, outperformed PS-only. They found             same concepts repeatedly until they demonstrate mastery and
no significant time-on-task differences among three groups.          then such steps would be faded away by presented as WEs
   Thus prior researchers have shown that FWE with effective         only. However there is no clear consensus on how or when
pedagogical polices can outperform fixed WE-PS pairs. It has         students should be given a WE, nor how the faded policy
also been shown that the former may require significantly less       should change on each level.
time on task than the latter. However all of these studies re-          Therefore in this study we will investigate the impact of
lied on hand-coded tutor pedagogical polices whereas in this         students’ pedagogical decisions on learning by comparing
study, we investigated whether students can make effective           students’ decisions to tutors’ random decisions at either
pedagogical decisions on whether to do PS or study a WE at           problem or step level in order to avoid the impact of possi-
either problem level or step level.                                  bly misguided pedagogical policies. This study is 2 {Student,
                                                                 2802

 Tutor} × 2 {Problem, Step} design with four conditions:             domain-general problem-solving strategies, which draw stu-
                                                                     dents’ attention to the conditions under which each domain
1. StudProb : problem-level student decisions.                       principle is applicable. The differences were apparent on
2. StudStep : step-level student decisions.                          all types of test problems: simple/complex problems and
                                                                     isomorphic/non-isomorphic problems, and the effects were
3. TutProb : problem-level random tutor decisions.                   large, with Cohen’s d=1.17 for overall post-test scores.
                                                                        Figure 1 shows the interface of Pyrenees, which is divided
4. TutStep : step-level random tutor decisions.                      into multiple windows. Through the dialogue window, Pyre-
                                                                     nees provides messages to the students such as explaining
    All students in this study were given the same problems in
                                                                     a worked example step, or prompting them to complete the
 the same order. We compared the four groups using pre- and
                                                                     next step. Students can enter their inputs, such as writing an
 post-tests as well as their time on task.
                                                                     equation or selecting the answer to a multiple-choice ques-
                            Methods                                  tion, through the response text box below. Any variables or
                                                                     equations that are defined through this process are displayed
 Participants                                                        on left side of the screen for reference. Any time an an-
 This study was conducted in the undergraduate Discrete              swer is submitted, Pyrenees provides immediate feedback on
 Mathematics course at the Department of Computer Science            whether or not it is correct.
 at North Carolina State University in the Fall of 2015. 279            In addition to providing immediate feedback, Pyrenees can
 students were enrolled in the course and this study was their       also provide on-demand hints prompting the student with
 final homework assignment. The students had two weeks to            what they should do next. As with other systems, help in
 complete it and they were graded based upon their effort in         Pyrenees is provided via a sequence of increasingly specific
 completing the assignment, not their post-test scores.              hints. The last hint in the sequence, the bottom-out hint,
                                                                     tells the student exactly what to do. For the purposes of
 Conditions
                                                                     this study we incorporated four distinct pedagogical decision
 The students were assigned to the four conditions via bal-          modes into Pyrenees to match the four conditions.
 anced random assignment based upon their course section
 and performance on the class mid-term exam. Since the               Procedure
 two tutor-random decision groups were already compared              In this experiment, students were required to complete 4
 in our prior study (Zhou, Price, Lynch, Barnes, & Chi,              phases: 1) pre-training, 2) pre-test, 3) training on Pyrenees,
 2015) and the primary goal of this work is to examine the           and 4) post-test.
 nature and effectiveness of students’ pedagogical decision-
                                                                        During the pre-training phase, all students studied the do-
 making, we assigned twice more students to the two student-
                                                                     main principles through a probability textbook. They read a
 decision groups, StudProb & StudStep , than the two tutor-
                                                                     general description of each principle, reviewed some exam-
 random groups, TutProb & TutStep . The final group sizes are
                                                                     ples of its application, and solved some single- and multiple-
 as follows: N = 92 for StudProb , N = 93 for StudStep , N = 47
                                                                     principle practice problems. After solving each problem, the
 for TutProb , and N = 47 for TutStep .
                                                                     student’s answer was marked in green if it was correct and red
    Due to the holiday break, preparations for final exams,
                                                                     if incorrect. They were also shown an expert solution at the
 and length of the experiment, 212 students completed the ex-
 periment. 11 students were excluded from our subsequent
 analysis because they performed perfectly on the probability
 pretest. The remaining 201 students were distributed as fol-
 lows: N = 70 for StudProb ; N = 59 for StudStep ; N = 38 for
 TutProb ; N = 34 for TutStep . We performed a χ2 test of the re-
 lationship between students’ condition and their rate of com-
 pletion and found no significant difference among the groups:
 χ2 (3) = 1.159, p = 0.763.
 Probability Tutor
 Pyrenees is a web-based ITS for probability. It covers 10 ma-
 jor principles of probability, such as the Complement The-
 orem and Bayes’ Rule. In prior studies Pyrenees was com-
 pared against Andes, another well-evaluated ITS (Vanlehn
 et al., 2005). Results showed that Pyrenees significantly
 outperformed Andes in both physics (VanLehn et al., 2004)
 and probability (M. Chi & VanLehn, 2007). This improve-             Figure 1: The interface of the Pyrenees probability tutor used
 ment was observed in part because Pyrenees teaches students         in this study.
                                                                 2803

same time. If the students failed to solve a single-principle         scores than the two Student decision groups: StudProb and
problem then they were asked to solve an isomorphic one;              StudStep but the difference is not significant. Next we will
this process was repeated until they either failed three times        compare students’ learning performance in the post-test and
or succeeded once. The students had only one chance to solve          training time across the four conditions. We discuss each
each multiple-principle problem and were not asked to solve           comparison in turn.
an isomorphic problem if their answer was incorrect.
   The students then took a pre-test which contained 10 prob-         Learning Performance
lems. The textbook was not available. They were not given             A repeated measures analysis using test type (pre-test and
feedback on their answers, nor were they allowed to go back           isomorphic post-test) as factors and test score as the depen-
to earlier questions. This was also true of the post-test.            dent measure showed a main effect for test type F(3, 197) =
   During phase 3, students in all four conditions received the       163.160, p < 0.0001. On the isomorphic questions, all
same 12 problems in the same order on Pyrenees. Each pri-             four groups of students scored significantly higher on the
mary domain principle was applied at least twice. The min-            post-test than on the pre-test, F(1, 69) = 68.04, p < 0.0001
imum number of steps needed to solve each training prob-              for StudProb ; F(1, 58) = 65.35, p < 0.0001 for StudStep ;
lem ranged from 20 to 50. The steps included variable def-            F(1, 37) = 8.349, p = 0.004 for TutProb ; and F(1, 33) =
initions, principle applications and equation solving. The            32.04, p < 0.0001 for TutStep . Therefore all four conditions
number of domain principles required to solve each problem            made significant gains from pre- to post-test by training on
ranged from 3 to 11. For the FWE problems, the StudStep               Pyrenees. This suggests that the basic practice and problems,
students were asked to make decision only on two types of             domain exposure, and interactivity of Pyrenees might help
steps: principle selection and principle application. To ap-          students to learn even when the problem- and step-level deci-
ply each principle, students need to first do principle selec-        sions are made randomly.
tion: to choose the principle that they will use and then do             Table 1 shows a comparison of the pre-test, isomorphic
principle application: to write the appropriate equation to ap-       post-test (10 isomorphic questions), and overall post-test
ply it. We evaluated the students’ decisions on both types of         scores among the four conditions, showing the mean (and
steps in our analysis below. The only procedural differences          SD) for each score. We calculated a two-way ANCOVA anal-
among the four conditions were the decision agency: Student           ysis on decision agency (Student vs. Tutor) × granularity
vs. Tutor and the granularity of the decision: Problem vs.            (Problem vs. Step) using pretest scores as a covariate. We
Step. Apart from this, the system was identical.                      found a significant interaction effect on the isomorphic post-
   Finally, all of the students took a post-test with 16 prob-        test scores: F(1, 196) = 5.664, p = 0.018. However, there
lems. Ten of the problems were isomorphic to the pre-                 was no significant main effect on either decision agency or the
test problems given in phase 2. The remainder were non-               granularity alone. Pairwise t-tests showed a significant differ-
isomorphic complicated multiple-principle problems.                   ence between StudProb and TutProb groups: t(106) = 2.514,
Grading Criteria                                                      p = 0.013, d = 0.477, that is, the StudProb scored significantly
                                                                      higher than the TutProb on isomorphic post-test scores. Ad-
The test problems required students to derive an answer by
                                                                      ditionally, there is a trend that TutStep group out-performed
writing and solving one or more equations. We used three
                                                                      TutProb group: t(70) = −1.853, p = 0.068, d = 0.444. There-
scoring rubrics: binary, partial credit, and one-point-per-
                                                                      fore, this result showed that students were able to make effec-
principle. Under the binary rubric, a solution was worth 1
                                                                      tive problem-level decisions in that StudProb group learned
point if it was completely correct or 0 if not. Under the partial
                                                                      significantly more than random decision TutProb group but
credit rubric, each problem score was defined by the propor-
                                                                      not step level decisions in that StudStep is not significantly
tion of correct principle applications evident in the solution.
                                                                      better than those trained with the random decisions TutStep .
A student who correctly applied 4 of 5 possible principles
                                                                         Similarly, a two-way ANCOVA on the factors of granu-
would get a score of 0.8. The One-point-per-principle rubric
                                                                      larity and decision using pretest scores as a covariate also
in turn gave a point for each correct principle application. All
                                                                      showed significant interaction effect on the overall post-test
of the tests were graded in a double-blind manner by a single
                                                                      score: F(1, 196) = 4.375, p = 0.038. Again there was no
experienced grader. The results presented below were based
                                                                      significant main effect on either the granularity or decision
upon the partial-credit rubric but the same results hold for the
other two. For comparison purposes, all test scores were nor-
malized to the range of [0,1].
                                                                                       Table 1: Learning Performance
                            Results
A one-way ANOVA test on students’ pre-test score show                     Cond             pre          Iso Post      Overall Post
that there is no significant difference among the four groups.            StudProb (70)    .684(.186)   .890(.119)    0.788(.137)
F(3, 197) = 1.969, p = 0.12. The second column in Table 1                 StudStep (59)    .671(.212)   .861(.129)    0.778(.152)
showed students’ pretest scores and as we can see, the two                TutProb (38)     .737(.189)   .818(.177)    0.726(.198)
Tutor decision groups, TutProb and TutStep , had higher pretest           TutStep (34)     .754(.167)   .882(.101)    0.811(.133)
                                                                  2804

                                                                     StudProb and the TutProb groups. Columns 2 and 3 show
               Table 2: Time on task (in minutes)
                                                                     the average number of worked examples and problem-solving
               Cond       # Stud    Total Time                       problems that each condition experienced. We required each
               StudProb   70        130.39(28.26)                    student to solve two problems in order to familiarize them
               StudStep   59        148.54(42.31)                    with Pyrenees. Therefore each student made 10 problem-
               TutProb    38        121.53(47.15)                    level decisions. For the StudProb group, the students chose
               TutStep    34        136.44(30.27)                    less than two WEs on average; while the TutProb group, the
                                                                     students received an almost equal number of WEs and PSs
                                                                     (5.45 vs. 4.55) since the tutor makes random decisions. That
agency alone. Post-hoc pairwise t-tests showed the TutStep           is, the StudProb group only received 15.8% of worked exam-
group had significantly higher scores than the TutProb group:        ples; while the TutProb group received 54.5% worked exam-
t(70) = −2.107, p = 0.039, d = 0.503 and a trend that the            ples . This difference was statistically significant: t(106) =
StudProb group out-performed the TutProb group: t(106) =             −13.203, p < 0.0001, d = 2.614
1.933, p = 0.056, d = 0.368. Therefore, it seems that tutor’s
step-level decision is more effective than tutor’s problem-
                                                                               Table 3: Number of problem-level decisions
level decision. But no significant difference was found be-
tween the two student decision making groups.                                  Cond         WE           PS            Total
   To summarize, our results showed that: 1) the granular-                     StudProb     1.58(1.40)   8.44(1.40)    10
ity can make a significant difference on student learning in                   TutProb      5.45(1.57)   4.55(1.57)    10
that tutor’s step-level decisions can be more effective than tu-
tor’s problem-level decisions; and 2) students can make better
problem-level decision than random, but not better step level
decisions. Therefore, one potential explanation for the lack                     Table 4: Number of step-level decisions
of the difference between the two student decision groups is
                                                                           ST              Cond        WE        PS       Total
that: while the step level decisions can indeed be more effec-
tive than problem-level decisions, the students cannot make                Principle       StudStep    9(10)     58(11)   67
effective step level decisions to fully take advantage of the              Selection       TutStep     34(4)     33(4)    67
learning power that step level decisions can provide. Further              Principle       StudStep    11(11)    56(11)   67
research is needed to investigate this hypothesis.                         Application     TutStep     34(5)     33(5)    67
Training Time                                                           Step Level Decisions: Table 4 shows the number of differ-
Table 2 shows the average amount of total training time              ent types of step level decisions made by the StudStep and
(in minutes) students spent on Pyrenees for each condi-              TutStep groups on the principle selection and principle ap-
tion. A two-way ANOVA analysis on granularity and deci-              plication steps. For both groups the number of WE and PS
sion agency revealed there is no significant interaction effect.     decisions sum to 67. The StudStep group selected an aver-
However, there is a significant main effect of granularity:          age of only 9 WE steps and decided to do PS on the re-
F(1, 197) = 10.283, p = 0.0015 and a marginal main effect of         maining 58 steps; while in the TutStep group, since the tu-
decision agency: F(1, 197) = 3.609, p = 0.059. Subsequent            tor makes random decisions, the students received an almost
pairwise t-tests showed that the StudStep condition spent sig-       equal number of WE and PS steps (34 vs. 33). That is, the
nificantly more time than the StudProb and TutProb condi-            StudStep group received 14.81% WE steps while the TutStep
tions: t(127) = −2.902, p = 0.004, d = 0.504 (StudProb );            group received 50.92% WE steps. This difference was also
t(95) = −2.937, p = 0.004, d = 0.603 (TutProb ).                     statistically-significant: t(91) = 13.67, p < 0.0001. We found
   Overall, we found that decision granularity can make a dif-       the similar patterns on the principle application steps as well.
ference on the time on task: 1) students spent more time with           To summarize, the two tutor decision groups received
step-level decisions than problem-level decisions in that the        about equal number of WE vs. PS at either problem or step
two step-level groups spent significantly more time than the         levels while the two student decision groups, either problem
two problem-level groups; 2) the two student decision groups         level or step level, are significantly more likely to decide to
seemingly spent more time on task than the two random tutor          do Problem Solving than Worked Examples.
groups, but the difference was only marginally-significant.
                                                                                                Discussion
Student Decisions                                                    In this study, we investigated the impact of students’ peda-
Our preliminary analysis on students’ decision-making pref-          gogical decision-making on learning. We focused on the de-
erence suggested that students are far more likely to choose         cisions whether to give students a WE or to engage them in
problem solving than worked examples.                                PS at two levels of granularity: problem versus step. We were
   Problem Level Decisions: Table 3 shows the number                 able to strictly control the domain content and thus to isolate
of different types of problem level decisions made by the            the impact of pedagogy from content. And we compared the
                                                                 2805

students’ pedagogical decision making performance to a ran-            conference of the cognitive science society, nashville, ten-
dom baseline with a goal of factoring out the impact of hand-          nessee (pp. 167–172).
coded strategies on student learning.                                Chi, M. T. H., Siler, S., & Jeong, H. (2004). Can tutors mon-
   Interestingly, our results showed that students can make ef-        itor students’ understanding accurately? Cognition and
fective problem-level decisions that enabled them to signifi-          Instruction, 22(3), 363-387.
cantly outperform students with random decisions. However,           Harackiewicz, J. M., Sansone, C., Blair, L. W., Epstein, J. A.,
the students were no better than a random tutor when mak-              & Manderlink, G. (1987). Attributional processes in be-
ing step-level decisions. When comparing across the four               havior change and maintenance: smoking cessation and
conditions we found that the Tutor random step-level deci-             continued abstinence. Journal of Consulting and Clinical
sion group outperformed the Tutor random problem-level de-             Psychology, 55(3), 372.
cision group (TutStep > TutProb ) but no significant difference      Koedinger, K. R., Anderson, J. R., Hadley, W. H., & Mark,
was found between the two student decision groups.                     M. A. (1997). Intelligent tutoring goes to school in the
   Our results suggests that different granularity of pedagogi-        big city. International Journal of Artificial Intelligence in
cal policies can significantly impact students’ performance in         Education, 8(1), 30-43.
that the step-level decisions can potentially be more beneficial     McLaren, B. M., & Isotani, S. (2011). When is it best to
than the step level ones; however, the students are more capa-         learn with all worked examples? In Artificial intelligence
ble of making effective problem-level pedagogical decisions            in education (pp. 222–229).
than making step-level ones. This may be due to the fact that        Najar, A. S., Mitrovic, A., & McLaren, B. M. (2014). Adap-
students may lack the necessary metacognitive skills to make           tive support versus alternating worked examples and tu-
such fine-grain decisions or because they get overwhelmed by           tored problems: Which leads to better learning? In User
the number of decisions to make.                                       modeling, adaptation, and personalization (pp. 171–182).
                                                                     Renkl, A., Atkinson, R. K., Maier, U. H., & Staley, R. (2002).
   Surprisingly, students selected more problem solving than
                                                                       From example study to problem solving: Smooth transi-
worked example on both problem and step levels. The feeling
                                                                       tions help learning. The Journal of Experimental Educa-
of engagement may partly explain their decisions. Prior work
                                                                       tion, 70(4), 293–315.
has shown that students are more likely to be engaged in the
                                                                     Roll, I., Baker, R. S. d., Aleven, V., & Koedinger, K. R.
learning process when they experience a sense of control over
                                                                       (2014). On the benefits of seeking (and avoiding) help
it(Harackiewicz et al., 1987). Therefore, the students might
                                                                       in online problem-solving environments. Journal of the
decide to do problem solving simply because they feel more
                                                                       Learning Sciences, 23(4), 537–560.
involved in problem solving than in worked example. How-
                                                                     Salden, R. J., Aleven, V., Schwonke, R., & Renkl, A. (2010).
ever, much further research is needed to fully understand why.
                                                                       The expertise reversal effect and worked examples in tu-
   Currently we are applying Reinforcement Learning (RL)               tored problem solving. Instructional Science, 38(3), 289–
to induce effective pedagogical policies directly from our             307.
data. We will investigate whether the RL-induced policies            Schwonke, R., Renkl, A., Krieg, C., Wittwer, J., Aleven, V.,
can be more effective than student decision making at both             & Salden, R. (2009). The worked-example effect: Not an
levels of granularity. We will also investigate whether it             artefact of lousy control conditions. Computers in Human
is possible to combine RL-induced policies with student                Behavior, 25(2), 258–266.
decision making and thus give students both beneficial               Sweller, J., & Cooper, G. A. (1985). The use of worked
guidance and an all-important sense of agency.                         examples as a substitute for problem solving in learning
                                                                       algebra. Cognition and Instruction, 2(1), 59–89.
Acknowledgements                                                     Vanlehn, K. (2006). The behavior of tutoring systems. In-
This research was supported by the NSF Grant #1432156:                 ternational journal of artificial intelligence in education,
”Educational Data Mining for Individualized Instruction in             16(3), 227–265.
STEM Learning Environments”.                                         VanLehn, K., Bhembe, D., Chi, M., Lynch, C., Schulze, K.,
                                                                       Shelby, R., . . . Wintersgill, M. (2004). Implicit versus
                          References                                   explicit learning of strategies in a non-procedural cognitive
                                                                       skill. In Intelligent tutoring systems (pp. 521–530).
Aleven, V., & Koedinger, K. R. (2000). Limitations of stu-           Vanlehn, K., Lynch, C., Schulze, K., Shapiro, J. A., Shelby,
   dent control: Do students know when they need help? In              R., Taylor, L., . . . Wintersgill, M. (2005). The andes
   Intelligent tutoring systems (pp. 292–303).                         physics tutoring system: Lessons learned. JAIED, 15(3),
Bloom, B. S. (1984). The 2 sigma problem: The search                   147–204.
   for methods of group instruction as effective as one-to-one       Zhou, G., Price, T. W., Lynch, C., Barnes, T., & Chi, M.
   tutoring. Educational Researcher, 13, 4-16.                         (2015). The impact of granularity on worked examples and
Chi, M., & VanLehn, K. (2007). The impact of explicit strat-           problem solving. In Proceedings of the 37th annual con-
   egy instruction on problem-solving behaviors across intel-          ference of the cognitive science society (pp. 2817–2822).
   ligent tutoring systems. In Proceedings of the 29th annual
                                                                 2806

