  A connectionist model for automatic generation of child-adult interaction patterns
                      Moinuddin M. Haque (m.m.haque@uvt.nl), Paul Vogt (P.A.Vogt@uvt.nl),
                     Afra Alishahi (A.Alishahi@uvt.nl), Emiel Krahmer (E.J. Krahmer@uvt.nl)
                                          Tilburg Center for Cognition and Communication,
                                                          Tilburg University
                                            PO Box 90153, 5000 LE Tilburg, the Netherlands
                                                                     situational learning model. Another example of a data-
                            Abstract                                 driven model where multiple modalities are incorporated is
      This study introduces a neural network that models the         the work Matusevych, Alishahi and Vogt (2013). In this
      social interactions from a video corpus. The corpus            model features, such as occurrence frequencies of
      consists of recordings of naturalistic observations of         utterances, utterance types, action types, action arguments
      social interactions among children and their                   along with participants and objects in the visual context,
      environment. The videos are annotated multimodally             were used to simulate interactions in the context of playing
      including features like gestures. We explore how this
                                                                     with toys.
      video corpus can be utilized for modelling by training
      our model on a portion of the annotated data extracted            The language game model of Steels (2003) is an example
      from the corpus, and then by using the model to predict        of an agent-based model in which agents interact with each
      novel interaction sequences. We evaluate our model by          other, exchange utterances and can learn from each other.
      comparing its automatically generated sequences to an          Typically, such models have been used to study language
      unseen portion of the corpus data. The initial results         evolution. Various language game models have been used to
      show strong similarities between the generated                 investigate vocabulary development, also incorporating
      interactions and those observed in the corpus.
                                                                     cross-situational learning (Smith, 2005; Steels & Loetzsch,
Keywords: Neural Networks; Child Language Acquisition;               2008; Vogt & Haasdijk, 2010). However, these models tend
      Sequence Generation; Modelling Social Interactions.            to implement interactions between agents using toy
                                                                     languages and do not reflect naturalistic interaction patterns.
                         Introduction                                Considering the restrictions of data-driven and agent-based
   Children adapt to their environment and communication             approaches to word learning, the next natural extension is to
partners trough interaction. These interactions along with           integrate the two approaches, but the problem is finding
the linguistic information are richly augmented with social          large and rich datasets for training such models.
cues (such as eye gaze and gestures), and are suggested to              Large-scale corpora of child-adult conversations, such as
facilitate child language developement (Tomasello & Todd,            CHILDES (MacWhinney, 2000), are available and provide
1983; Iverson, Capirci, Longobardi & Caselli, 1999;                  us with naturalistic linguistic exchanges between children
Hollich, Hirch-Pasek & Golinkoff, 2000). Therefore,                  and adults. However, most of the corresponding audio and
cognitive models of child language learning should take              video files are not annotated with extra-linguistic (e.g.,
these cues into account and integrate such interaction-based         semantic information about the surrounding scene) or
features with linguistic input in the process of learning            interaction-based cues (such as gaze and gesture) that are
language.                                                            machine readable.
   One of the well-studied mechanisms for learning the                  The CASA MILA corpus, which consists of longitudinal
meaning of words is cross situational learning (Quine 1960),         video recordings of 40 children interacting in naturalistic
which draws on word-referent co-occurrences that children            environments, is a corpus that has incorporated annotations
observe from their environment. Many computational                   for non-verbal social cues (Vogt & Mastin, 2013a). The
models have implemented (variations of) this mechanism               video frames are richly annotated based on the observed
using associative networks to predict a word form based on           interactions between children and their caregivers, and thus
semantic features (e.g., Li & Farkas, 2002; Regier, 2005) or         provides a valuable resource for modeling child-adult
to discover statistical regularities in observations of              interaction. However, it only covers 1.5 hours of recording
linguistic labels and visual features or concepts (e.g.,             for each child, which is hardly enough for training a
Siskind, 1996; Frank, Goodman & Tenenbaum, 2007;                     computational model of child language development. What
Fazly, Alishahi & Stevenson, 2010). Typically, such models           we need is an automatic input-generation engine that can
treat learning as a unidirectional process where the learner         replicate the interaction patterns and their statistical
focuses only on the linguistic cues and discards the social          properties observed in a corpus such as CASA MILA,
interactions. We refer to these models as data-driven models         without the quantitative limitations of such a corpus.
of word learning. To date, only a few models of word                    The current paper presents a study to generate novel
learning have incorporated interaction features. The data-           interactions based on observations from the corpus. One
driven models by Yu and Ballard (2007), and Frank,                   approach to create more data can be simply by copying the
Tenenbaum and Fernald (2013) have incorporated                       already annotated data multiple times. The limitation of this
information about eye gaze and pointing in a cross                   approach is that there will be no new interactions present in
                                                                 486

the data, and the rigidity of the interactions remains. Yet,                        child.2 In this study, we let the machine learn to predict the
the flexibility of having new interaction patterns in the data                      joint engagement level, and when the children and
is one of our aims. We therefore present a method for                               communication partners produce utterances and/or gestures,
discretizing the continuous video and annotation data, and                          but not what words or gestures are actually used.
using these data to train a neural network that generates new
interactions. We evaluate this method by analysing the                              Feature selection
newly generated sequences against the original annotated                              Figure 1, illustrates how the original annotations are
sequences, as well as three different baseline models.                              transformed to provide the learning algorithm a simplified
                                                                                    representation of the input. Figure 1(a) shows a small
                            Methods                                                 fragment of an actual timeline showing the engagement
                                                                                    level (top row), child-directed speech (second row), child-
Data                                                                                directed gesture (third row), child speech (fourth row) and
The CASA MILA corpus contains video recordings of 40                                child gesture (bottom row). The highlighted regions show
different children at home, interacting with one or more                            where speech or gesture was observed.
communication partners. These recordings are from three
different cultures: rural and urban Mozambique, and the
Netherlands. Each recording contains naturalistic
observations of interactions between infants and their
communication partners at their home. The corpus is
longitudinal in nature, with recordings taken at children's
ages of 13-, 18- and 25-months old.1 For this study we will
only use the data from the 13-months old children from the
Netherlands. This was done, because these mainly contained                                                           (a)
one-to-one interactions, thus simplifying our problem.
   The corpus was annotated for a variety of tiers, five of
which we use for the present study: child engagement,
child-directed speech, child-directed gesture, child-speech
and child-gesture. In the recordings we only focus on those
parts in which the child interacted with someone. The
annotated features are hierarchically organized. On the top
layer is the child's joint engagement level (Mastin & Vogt,
2016), as described in Table 1.                                                                                      (b)
                                                                                    Figure 1. (a) Simplified annotated timeline with
Table 1. Joint engagement levels.                                                   highlights. (b) Spliced timeline (not to scale).3
Name                    Description                 Example
Persons engagement      Infants interact with       The infant responds with           To process our data, the original time sequence is broken
                        another person by           a smile to the mother’s
                        responding to the other     voices; infant reaches          down into slices of 200 milliseconds duration, with the
                        person or by trying to      toward the mother.              purpose of capturing the information in the annotations
                        start an exchange.
Passive joint attention Infants play with an        The infant plays with a         (Figure 1(b)). The duration of 200 milliseconds was
                        object that is also the     toy car. The mother says:       determined after trial and error to capture significant
                        focus of another person’s   “What a nice car!”, but
                        attention but they do not   receives no response at all
                                                                                    information without having too many unchanged sufficient.
                        acknowledge the other       from the infant.                These time slices allow us to represent the state of an
                        person’s attention.                                         interaction at time t as an 8-bit vector x(t), where presence
Shared joint attention  Infants share the attention The mother offers the
                        to an object or event with  infant a toy to play with,      of activity is represented as 1 and absence as 0. To construct
                        the interlocutor, but they  the infant looks from the       these vectors, engagement levels are represented with four
                        do not share a mutual       mother to the toy, but
                        goal in the interaction.    does not respond                bits, of which exactly one bit has the value of 1 at any given
                                                    otherwise.                      time (see Table 2, rows 1-4). Since we are only interested in
Coordinated joint       Infants share the attention The mother offers the           predicting when someone speaks or gestures, the remaining
attention               to an object or event with  infant a toy to play with,
                        the interlocutor, and they  the infant looks to the         four bits encode whether or not child-directed speech, child-
                        clearly share a mutual      mother and the infant           directed gesture, child speech or child gesture was present at
                        goal in the interaction.    takes the toy and starts
                                                    playing.                        time t. This binary vector representation is then used to
                                                                                    serve as input for our neural network.
   At the lower layers, speech and gestures (e.g., pointing,
showing or reaching) are annotated for both caregiver and
                                                                                       2
                                                                                         Consult Vogt et al. (2015) for the transcriptions of speech, and
    1
      For more details on the recording procedures, consult Mastin                  Vogt and Mastin (2013b) for the annotation of gestures.
                                                                                       3
and Vogt (2016) or Vogt, Mastin, and Schots (2015).                                      Created with ELAN (Sloetjes & Wittenburg, 2008).
                                                                                487

Table 2. The bit vector representation.
Position Represents                            Possible values
1            Persons engagement                0/1
2            Passive joint attention           0/1
3            Shared joint attention            0/1
4            Coordinated joint attention       0/1
5            Child-directed speech             0/1
6            Child-directed gesture            0/1
7            Child speech                      0/1                   Figure 3: The Parallel Architecture of the NARX network in
8            Child gesture                     0/1                   closed loop.
Model                                                                  During training, the network receives two input vectors, x
  We developed a neural network model to generate novel              (input time series) and y (output time series) each
interaction sequences based on the naturalistic patterns             represented as a vector with 8 bits. The input time series
observed in the annotated corpus, and evaluated this on how          corresponds to the bit sequence we are training at time t.
well the model can recreate an unseen sequence. Treating             The output series corresponds to the observed output at t+1.
the bit sequence as a time series with each vector as a given        To introduce a temporal memory the network delay is set to
state, the model is trained to predict the next possible stage       6, meaning that each new vector is predicted based on the 6
given a previous set of states.                                      previous input vectors. This parameter was derived
   We used a non-linear autoregressive neural network with           empirically. The hidden layer has 20 neurons. For the
external input (NARX) (Haykin, 1999; Lin, Horne, Tiňo &              transfer function in the hidden layer a hyperbolic tangent
Giles, 1996; Gao & Er., 2005), which is a class of neural            sigmoid transfer function was used. At the output layer a
networks that is well suited for training nonlinear systems          log-sigmoid transfer function is used to get the final result in
and time series. The NARX is a recurrent dynamic network             the format of a matrix where each row corresponds to the
with feedforward connections enclosing several layers of the         target annotations.
network. The network is used to predict the next value of              The network is trained with a function that updates the
the input signal. The NARX architecture was chosen over              weights and bias values according to Levenberg-Marquardt
others for its success with predicting time series.                  optimization (Levenberg, 1944). It minimizes a combination
   Since the true output is available during the training of the     of squared errors and weights, and then determines the
network, one can create a 'series-parallel architecture', in         correct combination so as to produce a network that
which the true output is used instead of feeding back the            generalizes well. The process is called Bayesian
estimated output, as a series-parallel architecture (Figure 2).      regularization. The error calculation is done using mean
During training the network is set in the series-parallel            squared normalized error.
architecture. Once the network has finished training the
network is changed into the closed loop, standard NARX
'parallel architecture' to make it usable for predicting the         Experimental setup
next state in the evaluation phase (Figure 3). During this             From the corpus we constructed 2 different data sets. We
prediction stage the output is fed back to the input of the          will discuss each separately as study 1 and study 2. For both
feed forward neural network. The output of the NARX                  studies, data from 12 children in the 13-month age group of
network is an estimate of the output of the nonlinear                the Netherlands dataset was used.
dynamical system that is being modelled. Making this
distinction has two advantages: First, in the series-parallel
architecture the input to the feedforward network is more
accurate. Second, this series-parallel architecture has a
purely feedforward network, and static backpropagation can
be used for training.
                                                                     Figure 4: Division of data for study 1.
                                                                     Study 1. Each of the children’s data is broken into 3 distinct
                                                                     parts: a training section, a development section, and a test
                                                                     section, with a size of 70%, 15%, and 15% for each section
                                                                     respectively. The individual parts of the sections are joined
Figure 2: The Series-parallel Architecture of the NARX               together to form aggregated sets. The training set is used for
network in open loop.                                                training of the neural network. The development set is used
                                                                 488

to fine tune the parameters of the network. The test set is           Measures. To measure the performance of the neural
used to evaluate the performance of the network. Figure 4             network, we evaluated the sequences generated at a micro
shows the division of data for study 1.                               and a macro level. At the micro level, the generated
                                                                      sequence was aligned with the test set to check for matches.
Study 2. The development set and training set are formed              A match is said to occur when slices match each other
by selecting data from 11 of the 12 children. This data is            exactly. We measured Accuracy as the percentage of the test
broken into two sections per child. The development                   set that had a perfect match.
sections contained 15% of the data and, aggregated, these               For the macro level analysis we compared the generated
formed the development set. The training sections contained           distributions with the transition distribution observed in the
85% of the data and formed the training set. Data from the            test set. To do so we calculated the number of times a
12th child is taken as the test set. Figure 5 shows the division      transition took place to create a probability distribution
of data for study 2.                                                  corresponding to each sequence. These probability
                                                                      distributions were then compared with the test set’s
                                                                      transition probability distribution using the Hellinger
                                                                      distance, which was used to quantify the similarity between
                                                                      two probability distributions (Hellinger, 1909). The
                                                                      Hellinger distance forms a bounded metric on the space of
                                                                      probability distributions over a given probability space.
                                                                      Mathematically this is calculated by taking the square root
                                                                      of the distance between two vectors. The closer the
Figure 5: Division of data for study 2                                Hellinger distance is to 0, the more similar two distributions
                                                                      are. The maximum distance of 1 is obtained when there is
Evaluation                                                            no overlap between the two distributions.
Baselines. To evaluate the accuracy of the neural network
generated sequences (NNG), we implemented three baseline                                          Results
models for predicting sequences. In each of these baselines
the size of the generated sequence equals the length of the           Study 1
test set. The three baseline models are defined as:                   Accuracy. Figure 6 provides the accuracy of the different
   Complete random generation (CRG). This creates a                  sequence generation models. As we can see, replicating the
      sequence by putting together random slices taken from           exact time series is difficult. The accuracy of the CRG (4%)
      a set of all distinct slices observed in the training set.      is expectedly very low.
   Attribute-based generation (ABG). This sequence is                  The low accuracy for ABG (11%) shows that the
      created by calculating the probability distributions for        assumption that the attributes are independent of each other
      each of the attributes annotated in the individual slices       is too simplistic and that there are meaningful dependencies
      (e.g., child gesture, mother gesture or engagement              between them, which are useful for sequence generation.
      level). In this model it is assumed that the attributes are       The accuracy gain through NNG (21%) over the TBG
      independent of each other and the predictions are               (19%) is small. The TBG is very faithful to the training data
      based on their distribution probability only.                   and therefore makes few mistakes, but it cannot generalize
   Transition based generation (TBG). This is formed by              beyond what it is has seen in the training data. To get a
      calculating the transition probability for each of the          better understanding of the difference in the sequences
      unique slices, as observed in the training set. Once            generated by these two models we look at the Hellinger
      these probabilities are known a new discrete sequence           distance.
      is generated using the transition probabilities.
These three generations present us with a comparative                 Time series distribution. Figure 7 shows the Hellinger
baseline to test the effectiveness of the neural network              distances calculated for each of the generated sequences.
generated sequences.                                                  The macro level analysis displays a much better trend than
                                                                      accuracy measures. When looking at the macro-level
Transitions. To capture the patterns in interactions we will          analysis, the NNG has a Hellinger value of 0.30, which is
evaluate the transitions in interaction states. Transitions           considerable improvement over the baseline models. The
occur when at least one bit changes between two time steps            Hellinger values for the baseline models are close to 1,
t and t+1. For example, when a bit sequence “00010001”                meaning the compared distributions are dissimilar. In short
(representing child and mother having coordinated joint               the sequences generated by the NNG have more overall
attention where the child is gesturing) is followed by                similarity with the test sets than those generated by the other
“00011001” (representing child and mother having                      baseline methods.
coordinated joint attention where the child is gesturing and
mother is speaking).
                                                                  489

                                                                      The interaction sequences produced by the different
                                                                   generation techniques shows that the neural network
                                                                   generated patterns have higher accuracy and more similar
                                                                   transition distribution than the baseline methods. Although
                                                                   the TBG and NNG data have similar levels of accuracy,
                                                                   when it comes to the transitional distribution, we observe a
                                                                   large difference, showing that NNG generates interactions
                                                                   more similarity with the training data.
  Figure 6. Accuracy measures for different generations.           While the NNG yields the highest accuracy, it is still far
                                                                   from perfect. The reason for this is that the interactions the
                                                                   network is trained on represents a non-linear complex
                                                                   dynamical system, whose exact time series is extremely
                                                                   hard to replicate. Although neural networks have shown to
                                                                   be universal approximators, they have difficulty modelling
                                                                   time series. While NARX networks perform better than
                                                                   others when it comes to time series modelling, they still
                                                                   have problems learning long term dependencies due to
Figure 7: Hellinger Distance for different generations.            vanishing gradients (Diaconescu, 2008). The behavior of the
                                                                   network is highly dependent on the size of the input
  To continue our analysis, we provide a visualization of the      sequence that represents the temporal memory of the model.
transitions and their probabilities as observed. Figure 8          However, the NARX model lacks a decent procedure for
shows the probability distributions for the NNG sequence           optimizing this size.
and the test set. We can see that the probabilities of the            The Hellinger distance gives us a better performance, as it
highly frequent transitions are closely replicated by the          looks at the distributions of the series and not exact
network, but it fails to replicate the low frequency               locations. For the NNG, the transitions observed in the
transitions.                                                       generated sequence are more similar to the test set than the
                                                                   baseline sequences, but the distance obtained with the
                                                                   present method is still insufficiently close to zero. Highly
                                                                   frequent transitions in the interactions are fairly well
                                                                   replicated, but many transitions observed in the test set are
                                                                   not. Moreover, the network generates sequences that have
                                                                   not been observed. The reason for these discrepancies are
                                                                   likely due to the possibility that the test set contains
                                                                   transitions that have not occurred in the training data and
                                                                   vice versa. Further analysis is required to verify whether this
Figure 8: Transition probabilities in the test set (blue bars)
                                                                   is, indeed, the case.
and the NNG (yellow bars). The x-axis represents the
                                                                      For study 2, the Hellinger distance approaches 1, which
different transitions, and the y-axis shows the probability.
                                                                   means that the distributions of transitions are not well
                                                                   generalized for replicating interactions of an unseen child.
Study 2                                                            One reason for this is that there are substantial individual
   In the second study, we investigated how the model              differences between the interactions the children engage in
would behave when faced with data from a child it has not          (Vogt et al., 2015). So, although they interact using the
been trained on. Accuracy of the generated sequence for the        same gestures in conjunction with speech, the frequencies
NNG was approximately 5%, showing a much lower                     with which gestures are used vary considerably, as do the
performance compared to study 1.                                   sequences of interactions (Vogt & Mastin, 2013b). Since the
   Doing the macro level analysis we found the Hellinger           network has a memory that helps generating sequences
distance to be close to 1, which means that the generated          based on previous observations, testing the network on an
sequences distribution is very different from the one              unseen test set is likely the cause for the marked difference
observed in the test set. Although there are some matches          in the transition probabilities.
for the slices produced, yielding accuracy greater than zero,         In order to reduce the complexity of the learning task, we
the distribution of transitions differs.                           chose to represent the speech and gesture in the annotated
                                                                   corpus as bitstrings indicating the presence or absence of
                         Discussion                                speech or gesture. However, doing this reduced the amount
In this paper we took a novel approach to generating new           of information contained in the training data. While
multimodal interaction sequences based on corpus data,             maintaining all words and different gestures is likely too
using neural networks.                                             complex with the amount of data, using more informative
                                                                   categories of speech or gesture might improved the results.
                                                               490

  To conclude, our initial attempt to replicate patterns of          Lin, T., Horne, B. G., Tiňo, P., & Giles, C. L. (1996).
interactions between young children and their caregivers               Learning long-term dependencies in NARX recurrent
observed in a video corpus yields mixed results. Our method            neural networks. IEEE Transactions on Neural
can replicate interactions of aggregated children reasonably           Networks, 7(6), 1329-1338.
well, but it cannot generalize to a previously unseen child,         MacWhinney, B. (2000). The CHILDES project: Tools for
nor does it fail to replicate exact sequences in the time series       analyzing talk: Volume I: Transcription format and
well. In later stages we intend to introduce more features             programs, volume II: The database. Computational
into the training along with exploring other modelling                 Linguistics, 26(4), 657-657.
paradigms, such as incorporating the corpus data more                Mastin, J. D., & Vogt, P. (2016). Infant engagement and
directly in an agent-based model that can then be trained to           early vocabulary development: a naturalistic observation
interact following the patterns observed in the data.                  study of Mozambican infants from 1;1 to 2;1. Journal of
                                                                       Child Language, FirstView, 1-30.
                    Acknowledgements                                 Matusevych, Y., Alishahi, A., & Vogt, P. (2013). Automatic
This study was funded by the Netherlands Organization for              generation of naturalistic child–adult interaction data.
Scientific Research (NWO) with a grant in the Natural                  In Proceedings of the 35th Annual Meeting of the
Artificial Intelligence program.                                       Cognitive Science Society (pp. 2996-3001).
                                                                     Quine, W. V. O. (1960). Word and object: Cambridge
                          References                                   University Press.
Diaconescu, E. (2008). The use of NARX neural networks               Regier, T. (2005). The emergence of words: Attentional
  to predict chaotic time series. Wseas Transactions on                learning in form and meaning. Cognitive Science, 29(6),
  Computer Research, 3(3), 182-191.                                    819-865.
Fazly, A., Alishahi, A., & Stevenson, S. (2010). A                   Siskind, J. M. (1996). A computational study of cross-
  Probabilistic Computational Model of Cross-Situational               situational techniques for learning word-to-meaning
  Word Learning. Cognitive Science, 34(6), 1017-1063.                  mappings. Cognition, 61(1), 39-91.
Frank, M. C., Tenenbaum, J. B., & Fernald, A. (2013).                Sloetjes, H., & Wittenburg, P. (2008, May). Annotation by
  Social and discourse contributions to the determination of           Category: ELAN and ISO DCR. In LREC.
  reference in cross-situational word learning. Language             Smith, A. D. (2005). Mutual exclusivity: Communicative
  Learning and Development, 9(1), 1-24.                                success despite conceptual divergence. Language
Frank, M., Goodman, N. D., & Tenenbaum, J. B. (2007,                   Origins: perspectives on evolution, 372-388.
  December). A Bayesian Framework for Cross-Situational              Steels, L. (2003). Evolving grounded communication for
  Word-Learning. In NIPS (pp. 457-464).                                robots. Trends in Cognitive Sciences, 7(7), 308-312.
Gao, Y., & Er, M. J. (2005). NARMAX time series model                Steels, L., & Loetzsch, M. (2008). Perspective alignment in
  prediction: feedforward and recurrent fuzzy neural                   spatial language. Spatial Language and Dialogue, 70-89.
  network approaches. Fuzzy sets and systems, 150(2), 331-
                                                                     Tomasello, M., & Todd, J. (1983). Joint attention and
  350.
                                                                       lexical acquisition style. First Language, 4(12), 197-211.
Haykin, S. (1999). Neural Networks, Second Edition.
                                                                     Vogt, P. & Haasdijk, E. (2010) Modelling social learning of
  Pearson Education.
                                                                       language and skills. Artificial Life, 16(4): 289-310
Hellinger, E. (1909). Neue Begründung der Theorie
                                                                     Vogt, P., & Mastin, J. D. (2013a). Anchoring social symbol
  quadratischer         Formen        von      unendlichvielen
                                                                       grounding in children’s interactions. KI-Künstliche
  Veränderlichen. Journal für die reine und angewandte
                                                                       Intelligenz, 27(2), 145-151.
  Mathematik, 136, 210-271.
                                                                     Vogt, P., & Mastin, J. D. (2013b). Rural and urban
Hollich, G. J., Hirsh-Pasek, K., Golinkoff, R. M., Brand, R.
                                                                       differences in language socialization and early vocabulary
  J., Brown, E., Chung, H. L., ... & Bloom, L. (2000).
                                                                       development in Mozambique. In Proceedings of the 35th
  Breaking the language barrier: An emergentist coalition
                                                                       annual meeting of the Cognitive Science Society(pp.
  model for the origins of word learning. Child Language,
                                                                       3787-3792). Austin, TX: The Cognitive Science Society.
  43(2): 235-264.
                                                                     Vogt, P., Mastin, J. D., & Schots, D. M. (2015).
Iverson, J. M., Capirci, O., Longobardi, E., & Caselli, M. C.
                                                                       Communicative intentions of child-directed speech in
  (1999). Gesturing in mother-child interactions. Cognitive
                                                                       three different learning environments: Observations from
  Development, 14(1), 57-75.
                                                                       the Netherlands, and rural and urban Mozambique. First
Levenberg, K. (1944). A method for the solution of certain             Language, 35, 341-358.
  non–linear problems in least squares. 164-168.
                                                                     Yu, C., & Ballard, D. H. (2007). A unified model of early
Li, P., Farkas, I., & MacWhinney, B. (2004). Early lexical             word learning: Integrating statistical and social
  development in a self-organizing neural network. IEEE                cues. Neurocomputing, 70(13), 2149-2165.
  Transactions on Neural networks, 17(8), 1345-1362.
                                                                 491

