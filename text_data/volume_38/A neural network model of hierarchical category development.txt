                   A neural network model of hierarchical category development
                                              Chris Gorman (cgorman@cs.otago.ac.nz)
                                                   Alistair Knott (alik@cs.otago.ac.nz)
                                            Department of Computer Science, 133 Union St East
                                                          Dunedin, 9016 New Zealand
                                 Abstract                                    This category system is hierarchically organized. Basic
                                                                          level categories like “chair” or “dog” afford the agent a
   Object recognition and categorization is a fundamental aspect          cognitively efficient representation of the object (Mervis &
   of cognition in humans and animals. Models have been imple-
   mented around the idea that categories are sets of frequently          Rosch, 1981). Above the basic level we have superordinate
   co-occurring features. Out of these models a question has been         categories. Superordinate categories, like “furniture” or “an-
   raised, namely what is the mechanism by which we learn a hi-           imal,” are difficult for agents to visualize and they contain
   erarchically organized set of categories, including types and
   subtypes? In this paper we introduce such a model, the Domi-           several intra-category differences. For example, a car and a
   nant Property Assembly Network (DPAN). DPAN uses an un-                boat can both be considered in the “vehicles” superordinate
   supervised neural network to model an agent which develops             category, but they have far fewer shared properties. In addi-
   a hierarchy of object categories based on highly correlated ob-
   ject features. Initially, the network generates representations of     tion, the important correlations may be determined as much
   high-level object types by identifying commonly co-occurring           by culture as by the objects themselves (Liu, Golinkoff, &
   sets of features. Over time, the network will start to use an          Sak, 2001). Below the basic level we have subordinate cat-
   inhibition of return (IOR) operation to examine the features
   of a categorized object that make it unusual as an instance of         egories. This level contains categories which may not con-
   its identified category. The result is a network which, early          tain many functionally actionable differences when compared
   in training, represents classes of objects using coarse-grained        against their basic level category, such as “computer chair”
   categories and recognizes objects as members of these general
   classes, but eventually is able to recognize subtle differences        or “pug,” but rather simply provide more detailed informa-
   between subtypes of objects within the broad classes, and rep-         tion. Developmentally, subordinate categories are learned
   resent objects using these more fine-grained categories.               after basic-level categories (Rosch, Mervis, Gray, Johnson,
   Keywords: categorization; computational modeling; proto-               & Boyes-Braem, 1976). Finally, beneath the subordinate
   type theory                                                            level we have the level of token individuals which is able to
                                                                          differentiate particular, unique instances of categories from
                             Introduction                                 one-another, such as differentiating “a dog” from “my dog,
Humans and animals begin developing classifications of ob-                Charles Barkley.” This level includes spatiotemporal infor-
jects starting from very soon after birth (Quinn, Slater,                 mation in conjunction with other sensory input and is beyond
Brown, & Hayes, 2001) and throughout the rest of our lives.               the scope of this work. This paper focuses on the subordinate
We are able recognize tens of thousands of different ob-                  level of categorization and, to a lesser degree, the basic level.
jects (Biederman, 1987; Brady, Konkle, & Alvarez, 2011),                     When a person has minimal experience with a type of ob-
which is an extremely important evolutionary tool. It allows              ject1 , they tend to focus on the major features shared between
us to rapidly determine whether a token object is, for exam-              members of that type before investigating the differences. For
ple, edible, dangerous, friendly, and so on (DiCarlo, Zoc-                example, a child may categorize any animal with four legs as
colan, & Rust, 2012). It is embedded in so many aspects                   “dog” (Rakison & Yermolayeva, 2010). A young child can
of our lives that we often don’t give it a second thought. It             recognize categories, such as “dog” and “cat,” from a series
provides us a way to compress as much information as pos-                 of commonly occurring features. Within these categories, the
sible with as little cognitive effort as possible (Rosch, 1999).          child is able to pick up on more frequently occurring, albeit
Humans and animals learn to represent token objects as in-                more subtle, combinations of features, such as those shared
stances of object categories. The structure of categories has             by pugs. They also notice other sets of subtle, frequently oc-
been explored extensively in cognitive science (see e.g. Rak-             curring features within the same category, like those shared
ison & Yermolayeva, 2010). Categories reflect several types               by spaniels. Due to the subtle nature of these regularities, they
of structures. A central idea is that categories represent cor-           weren’t noticed until after the basic-level category was solid-
relations between the features of objects. We recognize that,             ified. If we assume that the mechanism which learns basic-
for example, a token object is a “dog” because it has features            level categories does so by identifying the strongest correla-
shared with other things we call dogs. But another key idea is            tions among object features, then by definition we must seek
that categories emerge to represent types of objects that have            a different explanation for the emergence of subordinate-level
distinctive properties. Exactly how these two apparently con-             categories.
flicting criteria coexist is the subject of much debate (Tyler                1 For the remainder of the paper we refer to a category or type as
& Moss, 2001). In the current paper we will propose a novel               an internal representation of commonly co-occurring features and a
architecture that reconciles them.                                        token object as a particular instance of a category.
                                                                      342

   Most modern work on computational object categorization           The difference between referential nominals and predicating
has focused on the basic and individual levels (Riesenhuber &        nominals is still a matter of debate for linguists; our model
Poggio, 2000; Winn, Criminisi, & Minka, 2005; Galleguillos,          of IOR in category learning will make a suggestion about
Rabinovich, & Belongie, 2008). However, in recent years, a           this difference. Once training is completed, the network will
significant amount of work has been done in an attempt to            have developed representations of object classes as well as
recognize subordinate categories as well (Zhang, Gao, Xia,           subtypes of those classes. In our example, it would contain
Dai, & Li, 2015; Farrell, Oza, Morariu, Darrell, & Davis,            category representations of “dog” alongside “pug,” “beagle,”
2011; Yang, Bo, Wang, & Shapiro, 2012; Chai, Lempitsky,              “spaniel,” and “corgi.”
& Zisserman, 2013). Most of these models recognise sub-                 The other key novelty in DPAN is the use of per-unit
ordinate categories by analysing the sub-parts of objects and        learning rates. DPAN uses localist units to represent highly
discovering regularities in the identity and configuration of        correlated features. The method by which the network learns
these sub-parts. However, the models do not pay so much              these correlations is explained in detail in a later section.
attention to the question of when an agent begins to learn           Once a localist unit emerges which strongly and sufficiently
subordinate-level categories within a given basic-level cate-        represents a token object’s category, the unit stops learning to
gory - that is, to the developmental trajectory of subcategory       prevent further input from altering its encoded category. To
learning. We propose that there are particular circumstances         achieve this end, the network employs per-unit learning rates.
which lead to an agent starting to learn subcategories, and that     These learning rates are associated with a particular localist
the process of learning subcategories is implemented through         unit, monotonically decreasing, and are based on a measure
overtly scheduled cognitive operations that have correlates in       of the rate of change of the connections for their respective
surface language.                                                    unit.
   Our model of subcategory learning is implemented within              The use of a per-unit local learning rate is well established
a network called the dominant property assembly network              in the field of neural networks (Thimm, Moerland, & Fiesler,
(DPAN). DPAN is presented with the visual features of a se-          1996; Bengio, Simard, & Frasconi, 1994; Becker & Le Cun,
ries of token objects and begins learning internal represen-         1988; Schiffmann & Geffers, 1993). The notion of a learning
tations of those objects’ basic-level categories by identifying      rate which changes based on its objective performance is also
the strongest correlations amongst these features. This might        well established (Senior, Heigold, Ranzato, & Yang, 2013;
lead to the emergence of categories “dog” and “cat”, for ex-         Renals, Morgan, Cohen, & Franco, 1992). Since the learning
ample. However, in order to learn more subtle correlations           rate is a monotonically decreasing function, it doesn’t cause
identifying subordinate-level categories, we propose that the        a feedback loop. For example, if the learning rate updated
strongest correlations should be actively inhibited. We ac-          as a function of the gradient of change, then it would simply
complish this through a cognitive operation that is a type of        raise itself up or lower itself down because the learning rate
inhibition of return (IOR).                                          directly affects the weights’ gradient of change. By allowing
                                                                     the weights to update using a constant value, we are able to
   When presented with a token object, DPAN first classifies         more accurately measure the amount of learning each unit is
the object to activate an internal representation of its cate-       accomplishing. Then, when the weight change gradient for
gory. This internal representation is associated with a cer-         that unit is low, we can confidently say that it is because the
tain collection of features which identify dogs, for example.        unit has completed its learning process and no longer needs
Having activated this representation, DPAN then inhibits the         to be updated.
associated features, allowing it to focus on what makes this
                                                                        The remainder of this paper is organized as follows. First
particular token object different or unusual. This idea of “in-
                                                                     we describe DPAN in detail, followed by an introduction to
hibiting the winner” is found in several neural circuits and
                                                                     our experiments and walk through of their results. In the final
is often referred to as “inhibition of return.” It was origi-
                                                                     section we present our conclusions.
nally shown in spatial attention (Posner, Rafal, Choate, &
Vaughan, 2007), where agents were shown to “inhibit ori-
                                                                                                Architecture
enting towards visual locations which have been previously
attended”. DPAN, however, operates on the domain of prop-            DPAN is effectively organized into three separate layers (Fig-
erties rather than spatial locations. The IOR operation can be       ure 1). The first layer is the rich property complex (RPC)
understood as an operation that identifies a property of the         which contains the raw object properties provided by the sen-
currently attended object. The process of identifying proper-        sorimotor system. The next layer is the dominant property
ties is one that is readily reported in language, in predicative     assembly (DPA). The DPA essentially provides a workspace
sentences. For instance, in the sentence “The dog is brown”,         for computations to be done on the RPC without permanent
the dog is predicated as having the property brown. It is in-        modification. When the network is presented with a token ob-
teresting that object categories can feature both referentially      ject, it first copies the information directly from the RPC into
and as predicates: for instance, in the sentence “The dog is         the DPA. Above the DPA layer lies the conditional principal
a pug”, “The dog” is a referential expression, but “a pug” is        component analysis (CPCA) units, introduced by O’Reilly
simply a property that is predicated of the dog (Partee, 1987).      and Munakata (2000), which constitute the localist property
                                                                 343

                                                                          may involve several iterations, i.e. an update of the network’s
                                                                          weights. An epoch is a collection of training episodes such
                                                                          that each training item has been presented to the network
                                                                          once. The maximum number of epochs for each execution
                                                                          is represented by λ and the current epoch is represented by
                                                                          t. Training typically consists of multiple epochs where the
                                                                          list of training items has been shuffled each time. It’s also
                                                                          worth mentioning that there should be at least enough CPCA
                                                                          units to represent the number of basic level and subordinate
                                                                          categories in the training data, but fewer than the number of
                                                                          features in the input vectors. The network is initialized with
                                                                          psuedorandom weights between 0.4 and 0.6. This allows each
                                                                          CPCA unit to have a decent chance of learning each of the ob-
        Figure 1: An overview of the DPAN architecture.                   jects without any major bias initially. At this point, we also
                                                                          initialize the learning rate for each unit. At the start of each
                                                                          training iteration, the RPC is copied into the DPA and the net-
assembly (LPA) layer. The weights connect each feature in                 work calculates the activity of the CPCA units using Equa-
the DPA layer with each unit in the LPA layer. CPCA pro-                  tion 2. The network then chooses the unit with the highest
vides the core learning mechanism for the network and is                  output max~y, selects it as the winner, sets its output to 1 and
explained in detail in the next section. The CPCA units in                the output of all other units to 0. Once the winner is selected,
the LPA layer represent the basic level and subordinate cate-             the weights for that unit w    ~ j are updated using equation 1. The
gories.                                                                   total change in weight is now measured to determine whether
                                                                          or not to begin IOR and to disable further learning on this
CPCA                                                                      unit. If the gradient of change is steeper than the threshold τ,
As we stated previously, the core learning of DPAN is ac-                 the iteration is complete and the process begins again.
complished via CPCA. CPCA is an unsupervised artificial
neural network based on Hebbian learning which generates                                                  ~y = WT~x                             (2)
an internal model of strongly correlated features. The algo-                 To calculate the gradient of change of the weight vector
rithm is explained in detail in (O’Reilly & Munakata, 2000),              ~ j at time t, DPAN allocates space for a temporary weight
                                                                          w
but we present a brief overview here as our method differs                vector, w ~ j (t − 1), updates the weights as normal, and then
slightly from the original implementation. CPCA takes bi-                 subtracts the current weight from the previous one, taking the
nary input and generates binary outputs using a competitive               absolute values (equation 3). d~ is now summed up to produce
winner-take-all approach. It uses one layer of neurons fully              the scalar value of the total change the weight vector w          ~ j un-
connected to the input vector. The neurons produce output                                                                                        ~j
                                                                          derwent (equation 4). This sum is appended to a vector Ω
by calculating the weighted sum of of their inputs, selecting
                                                                          such that the contents of the vector are the total change in
the one with the highest output, setting that value to 1 and the
                                                                          weight for each iteration. Ω        ~ j 0 is calculated such that it con-
rest to 0. The weights are updated using Equation 1 where
y j is the activity of the unit, xi is the input feature, wi j is the     tains the gradient of Ω   ~ j . Finally, the last two elements of Ω   ~ j0
weight between them, and α j is a learning rate, between 0                are subtracted from one another and if their difference is less
and 1, of the unit. O’Reilly et al. provide a derivation proving          than τ, we consider the gradient of change to be minimal.
that wi j = P(y j = 1|xi = 1). In a practical sense, the weight
between a CPCA unit and an input vector increases when the                                       d~ = |~ w j (t) − w  ~ j (t − 1)|              (3)
unit is active and the input is 1, or decreases when the neu-
ron is active and the input is 0. In DPAN, the weights are                                                    |w
                                                                                                               ~ j|
connected to the dominant property assembly rather than to                                                    ∑ wik                             (4)
the rich property complex. This allows us to manipulate the                                                   k=1
CPCA’s input vector, during inhibition of return for example,                If the network determines that there was minimal change,
while maintaining a reference to the original input data.                 IOR begins. The DPA is now updated such that ~x = W~y, es-
                                                                          sentially copying the object prototype from the LPA into the
                       ∆wi j = α j y j (xi − wi j )               (1)     DPA. The RPC is now subtracted from the DPA in the in-
                                                                          hibition step, ~x := ~z −~x, and stored back into the DPA. At
The Training Algorithm                                                    this stage, the DPA to now contains the difference between
We start by defining a few terms. A training item is a com-               the prototype object and the actual token object. For exam-
bination of feature values originally presented to the RPC. A             ple, if the token object was “pug” and the winning unit was
training episode encompasses all of the processing that is                “dog,” the DPA would now contain the properties that pugs
done on a single training item. If IOR is invoked, the episode            have which differentiate them from other dogs.
                                                                      344

   Since the IOR operation can run indefinitely, we must de-
fine stopping conditions. If, after the inhibition operation,
the DPA doesn’t contain anything “interesting,” IOR ceases
                                                                                                 (a) A token pug
and no learning is done. That is, if there is minimal differ-
ence between the token object and the winning unit’s prop-
erty assembly, there is nothing for the network to learn, so it
stops. For example, if the winning unit near-perfectly repre-
sented the token object there would be very little difference                                   (b) A token tabby
between the RPC and the prototype object. If there is some-
thing interesting left in the DPA, the network learns in the          Figure 2: Two vectors representing token individuals. Red
same way as before: the activity of each unit is calculated, a        indicates a value of 1 and blue a value of 0.
winner is selected, and that unit’s weights are updated. The
only differences this time are that the LPA layer performs
a self-inhibition operation which prevents previous winners           by which two of those bits are active, so there are eight bits for
from this iteration to win again and that before the weights          the dog breeds (pug, beagle, spaniel, and corgi) and eight bits
are updated, the contents of the DPA are replaced with the            for the cat breeds (tabby, maine coon, siamese, and persian).
contents of the RPC; the network chooses a winner based               Finally, there is a set of five idiosyncratic property bits which
on the unique properties, but then trains on the entire prop-         are each uniformly randomly set to 0 or 1 for each token in-
erty complex. After the weights are updated, the gradient of          dividual. These bits represent weak, uncorrelated properties,
change for the new winning unit is calculated. If the change          a unique color or a marking of some kind for example.
was large, the inhibition loop finishes and the training itera-       Training Runs
tion for this input is complete. Otherwise, the loop repeats,
allowing more interesting features to bubble up.                      DPAN was trained on a set of 5000 input vectors. Each of the
                                                                      eight breeds were equally distributed in the training set. The
   The initial result of training (Stage 1) is that the coarse-
                                                                      network was trained using the following input parameters:
grained object categories are learned. At this stage, when
an object is presented to the network, the winning LPA unit           • |y| := 25
represents a supertype. Now the network starts to systemati-
cally inhibit the units representing coarse-grained types after       • α j := 0.02∀ j ∈ y
they are activated, allowing other units in the network to de-
                                                                      • τ := 0.000001
velop representations of finer-grained subtypes. When these
are first learned (Stage 2), the network activates first a unit       • λ := 500
representing a supertype, and then (after IOR) a unit repre-
senting a subtype. After even more training, the subtype units        These parameters were selected based on empirical evidence
learn better representations of the training objects than the su-     showing they provide the best results for this particular
pertype units, and the network activates a subtype represen-          dataset. The network produces output at arbitrary epoch and
tation as its first response (Stage 3). In linguistic terms, the      input intervals. The output of the network is a heat-map of
response at Stage 1 could be rendered “that is a dog”, at Stage       the weight matrix, again where red indicates a value of 1 and
2, “That dog is a pug”, and at Stage 3, “That is a pug”.              blue a value of 0. The column vectors of the weight matrix
                                                                      represent the CPCA units and the row vectors represent the
                    Experimental Setup                                input features.
Input Data                                                                                          Results
DPAN was trained on a set of binary input vectors, each rep-          We present the results of the execution by examining three
resenting a token object containing 36 features. Each element         key stages of training. Early in training, DPAN learns local-
of the vector encodes a distinct, abstract property of the token      ist representations of the basic-level categories for dog and
object. When a bit is set to 1 it indicates the presence of a         cat, as shown in Figure 3a where units 23 and 16 repre-
property and when it is set to 0 it indicates the absence of that     sent dog and cat respectively. The basic-level units repre-
property. Each input vector represents one of four cat or four        sent the highly correlated properties found in the dog and cat
dog breeds. Figure 2 describes the layout of the input bits and       breeds while also maintaining the weak correlations of each
provide examples of token individuals. All four breeds of dog         subordinate-level category. For example, the network’s lo-
shared the same set of “generic dog” properties and all four          calist dog unit encapsulates the common features associated
breeds of cat shared the same set of “generic cat” properties.        with each dog it has been exposed to, but also maintains weak
There is an overlap of three bits between these two sets rep-         connections to the subtle correlations for each dog breed it
resenting properties shared between all dogs and cats. The            has seen. At this stage of training, DPAN’s each dog or cat
next 16 bits represent breed-specific properties, e.g. a wrin-        it sees will activate its corresponding basic-level localist unit
kled face and short snout for a pug. Each breed is identified         and reinforce these connections.
                                                                  345

                (a)                                (b)                              (c)                               (d)
Figure 3: DPAN results: (a) aDPAN weight matrix during the first stage of training when basc-level categories are formed. (b)
bDPAN weight matrix during the second stage of training. Subordinate-level units are beginning to emerge as a result of the
IOR operation. (c) cDPAN weight matrix after the final stage of training. Each subordinate-level and basic-level category is
well represented by at least one unit in the LPA layer. (d) dModified DPAN without IOR operation after 100 epochs.
   The next stage of training occurs after learning in the ’dog’      “cat.” Stage 2 corresponds to predicative sentences, featur-
and ’cat’ units stabilizes. At this point, whenever a cat or dog      ing subordinate-level categories as predicates: “The dog is a
is presented, DPAN executes an IOR operation and chooses              pug.” We also posit that the use of the word “is” represents
another unit to represent the ’unusual’ features of the cat or        the inhibition operation that allows DPAN to learn these fine
dog that has just been classified. The results of this stage of       grained categories. That is, when describing the token ob-
training are illustrated in Figure 3b. At this point, there are       ject, a person first activates their internal representation of
CPCA units that represent subtypes of dogs and subtypes of            the object’s basic level category (“The dog...”), then inhibits
cats. For example, unit 23 still represents the ’dog’ category        that (“..is a...”) to focus on the subtle correlations of the
while unit 17 represents the ’corgi’ subcategory.                     subordinate-level category (“...pug.”). Stage 3 corresponds
   Finally, after each subordinate-level unit has been exposed        to referential uses of subordinate categories. The agent no
to enough token objects, DPAN reaches its last stage of train-        longer actively inhibits the basic-level category and instead
ing. During this stage, when the network is exposed to a token        initially activates its internal representation of the token ob-
object it will simply activate the corresponding subordinate-         ject’s subordinate-level category (“The pug.”).
level localist unit. Note as well that the basic-level units re-
main intact. If a new subordinate-level category is presented                      Conclusions and Future Work
to the network at this point, i.e. one which has no localist rep-
resentation, the basic-level unit will still activate.                Members of basic-level categories contain many highly-
   In order to illustrate the importance of the IOR operation,        correlated features. After enough experience we can in-
an experiment was carried out wherein IOR was disabled dur-           hibit these more obvious connections, allowing us to hone
ing execution. The results of this experiment are presented in        in on more subtle correlations and to create finer-grained
Figure 3d. As anticipated, after 100 epochs the network is            subordinate-level categories. The dominant property assem-
still only able to learn the basic-level categories. Without the      bly network is able to learn basic-level and subordinate-level
inhibition of return operation, the network is unable to learn        categories in the same manner. DPAN learns the strong cor-
the subtle differences that define the subordinate-level cate-        relations that exist in the data to create a representations
gories.                                                               of basic-level categories. Once these have been encoded,
                                                                      DPAN then uses its inhibition of return operation to learn the
A Possible Account of the Difference Between                          dataset’s weaker correlations, generating new representations
Referential and Predicative Nominals                                  of subordinate-level categories. After enough experience,
While describing the execution of DPAN, we separated it               the subordinate-level categories win out over their basic-level
into three distinct stages. As discussed previously, these            counterparts, mimicking human categorization.
three stages of training model a human acquiring expertise               The next step for DPAN is to integrate it into a compu-
in a given category. In the first stage, the network corre-           tational vision system, allowing it to train on real-world im-
sponds to referential uses of basic-level categories: “dog” and       age data. DPAN would also benefit from an additional su-
                                                                  346

pervised network to assign names to its category representa-         Quinn, P. C., Slater, A. M., Brown, E., & Hayes, R. A. (2001,
tions. DPAN could potentially be used in a large-scale image           June). Developmental change in form categorization in
recognition system to create categories and subcategories of           early infancy. British Journal of Developmental Psychol-
any number of objects.                                                 ogy, 19(2), 207–218. doi: 10.1348/026151001166038
                                                                     Rakison, D. H., & Yermolayeva, Y. (2010, November). Infant
                          References                                   categorization. Wiley Interdisciplinary Reviews: Cognitive
                                                                       Science, 1(6), 894–905. doi: 10.1002/wcs.81
Becker, S., & Le Cun, Y. (1988). Improving the convergence           Renals, S., Morgan, N., Cohen, M., & Franco, H. (1992).
   of back-propagation learning with second order methods.             Connectionist probability estimation in the DECIPHER
   In Proceedings of the 1988 connectionist models summer              speech recognition system. In Icassp-92 (Vol. 1, pp. 601–
   school (pp. 29–37).                                                 604 vol.1). IEEE. doi: 10.1109/ICASSP.1992.225837
Bengio, Y., Simard, P., & Frasconi, P. (1994, January). Learn-       Riesenhuber, M., & Poggio, T. (2000, November). Models
   ing long-term dependencies with gradient descent is diffi-          of object recognition. Nature neuroscience, 3 Suppl, 1199–
   cult. IEEE Transactions on Neural Networks, 5(2), 157–66.           204. doi: 10.1038/81479
   doi: 10.1109/72.279181                                            Rosch, E. (1999). Principles of categorization. Concepts:
Biederman, I. (1987). Recognition-by-components: a the-                Core Readings, 189–206.
   ory of human image understanding. Psychological Review,           Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., &
   94(2), 115.                                                         Boyes-Braem, P. (1976, July). Basic objects in natural
Brady, T., Konkle, T., & Alvarez, G. (2011). A review of               categories. Cognitive Psychology, 8(3), 382–439. doi:
   visual memory capacity: Beyond individual items and to-             10.1016/0010-0285(76)90013-X
   ward structured representations. Journal of Vision, 11(5),        Schiffmann, W. H., & Geffers, H. W. (1993, January).
   1–34.                                                               Adaptive control of dynamic systems by back propaga-
Chai, Y., Lempitsky, V., & Zisserman, A. (2013, Decem-                 tion networks. Neural Networks, 6(4), 517–524. doi:
   ber). Symbiotic Segmentation and Part Localization for              10.1016/S0893-6080(05)80055-3
   Fine-Grained Categorization. In Iccv 2013 (pp. 321–328).          Senior, A., Heigold, G., Ranzato, M., & Yang, K. (2013). An
   IEEE. doi: 10.1109/ICCV.2013.47                                     empirical study of learning rates in deep neural networks
DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012, February).          for speech recognition. In Icassp 2013 (pp. 6724–6728).
   How does the brain solve visual object recognition? Neu-          Thimm, G., Moerland, P., & Fiesler, E. (1996, February).
   ron, 73(3), 415–34. doi: 10.1016/j.neuron.2012.01.010               The Interchangeability of Learning Rate and Gain in Back-
                                                                       propagation Neural Networks. Neural Computation, 8(2),
Farrell, R., Oza, O., Morariu, V. I., Darrell, T., & Davis,
                                                                       451–460. doi: 10.1162/neco.1996.8.2.451
   L. S. (2011, November). Birdlets: Subordinate catego-
                                                                     Tyler, L., & Moss, H. (2001, June). Towards a dis-
   rization using volumetric primitives and pose-normalized
                                                                       tributed account of conceptual knowledge. Trends in Cog-
   appearance. In Iccv 2011 (pp. 161–168). IEEE. doi:
                                                                       nitive Sciences, 5(6), 244–252. doi: 10.1016/S1364-
   10.1109/ICCV.2011.6126238
                                                                       6613(00)01651-X
Galleguillos, C., Rabinovich, A., & Belongie, S. (2008,
                                                                     Winn, J., Criminisi, A., & Minka, T. (2005). Object catego-
   June). Object categorization using co-occurrence, loca-
                                                                       rization by learned universal visual dictionary. In Iccv’05
   tion and appearance. In Cvpr 2008 (pp. 1–8). IEEE. doi:
                                                                       volume 1 (Vol. 2, pp. 1800–1807 Vol. 2). IEEE. doi:
   10.1109/CVPR.2008.4587799
                                                                       10.1109/ICCV.2005.171
Liu, J., Golinkoff, R. M., & Sak, K. (2001, January). One            Yang, S., Bo, L., Wang, J., & Shapiro, L. G. (2012).
   cow does not an animal make: Young children can extend              Unsupervised Template Learning for Fine-Grained Object
   novel words at the superordinate level. Child Development,          Recognition. In F. Pereira, C. J. C. Burges, L. Bottou,
   72(6), 1674–94.                                                     & K. Q. Weinberger (Eds.), Advances in neural informa-
Mervis, C. B., & Rosch, E. (1981, January). Categorization             tion processing systems 25 (pp. 3122–3130). Curran Asso-
   of Natural Objects. Annual Review of Psychology, 32(1),             ciates, Inc.
   89–115. doi: 10.1146/annurev.ps.32.020181.000513                  Zhang, L., Gao, Y., Xia, Y., Dai, Q., & Li, X. (2015,
O’Reilly, R. C., & Munakata, Y. (2000). Computational Ex-              January). A fine-grained image categorization system by
   plorations in Cognitive Neuroscience: Understanding the             cellet-encoded spatial pyramid modeling. IEEE Trans-
   Mind by Simulating the Brain. MIT Press.                            actions on Industrial Electronics, 62(1), 564–571. doi:
Partee, B. (1987). Noun phrase interpretation and type-                10.1109/TIE.2014.2327558
   shifting principles. Studies in discourse representation the-
   ory and the theory of generalized quantifiers, 8, 115–143.
Posner, M. I., Rafal, R. D., Choate, L. S., & Vaughan, J.
   (2007, August). Inhibition of return: Neural basis and
   function. Cognitive Neuropsychology, 2(3), 211–228. doi:
   10.1080/02643298508252866
                                                                 347

