       Examining Referential Uncertainty in Naturalistic Contexts from the Child’s
                       View: Evidence from an Eye-Tracking Study with Infants
                                                       Yayun Zhang and Chen Yu
                                              yayzhang@indiana.edu, chenyu@indiana.edu
       Department of Psychology & Brain Science, Indiana University, 1101 E. 10th Street, Bloomington, IN 47405 USA
                              Abstract
                                                                          Snedeker, Trueswell, and Gleitman (2011) argue that learners
  Young infants are prolific word learners even though they are
  facing the challenge of referential uncertainty (Quine, 1960).          encounter words in complex environments where infinite
  Many laboratory studies have shown that human infants are               referents might be treated as the label’s correct referent,
  skilled at inferring the correct referent of an object from             therefore co-occurrences in the real world are too noisy to be
  ambiguous contexts (Swingley, 2009). However, little is                 effectively learned by human learners. In their study using the
  known regarding how children visually attend to and select the          “Human Simulation Paradigm” (HSP). They showed adults
  target object among many other objects in view when parents             video clips of parent interacting with an infant. The original
  name it during free play interactions. In the current study, we         sound of the video was muted and a beep was inserted at the
  explored the looking pattern of 12-month-old infants using              onset of the label when parent named an object. Adult
  naturalistic first person images with varying degrees of
                                                                          learners were asked to watch these videos and guess the
  referential ambiguity. Our data suggest that infants’ attention
  is selective and they tend to only select a small subset of objects     intended referent by the parent at the moment of the beep.
  to attend to at each learning instance despite the complexity of        They found that participants were not able to aggregate
  the data existed in the real world. This work allows us to better       information and learn the correct word-referent mapping
  understand how perceptual properties of objects in infants’             across trials. The researchers concluded that because there are
  view influence their visual attention, which is also related to         potentially too many candidate referents which could be
  how they select candidate objects to build word-object                  mapped on to a label, it is impossible for learners to
  mappings.                                                               continuously store and update the word-object co-
                                                                          occurrences across word learning moments and make
  Keywords: statistical learning; word-referent mapping;                  appropriate decisions based on aggregated statistics.
  learning mechanisms
                                                                             However, other investigators reached different conclusions
                                                                          by using variants of the HSP method. Yurovsky, Smith and
                          Introduction                                    Yu (2013) used training videos from both the observers’ view
Infants encounter words in complex environment and one                    (captured by a tripod-mounted camera) and the child’s view
challenge in early word learning is that of referential                   (captured by a head-mounted camera) to study how uncertain
uncertainty: how infants manage to find the right word-                   participants were when asked to make explicit hypothesis
referent pairs in the noise (Quine, 1960). Many studies have              regarding the intended referent by the parent. They found that
shown that human infants are able to infer the correct referent           about 50% of the naming episodes by mothers to toddlers
of an object from ambiguous contexts (Swingley,                           were not ambiguous to the adults, who could accurately guess
2009; Waxman & Booth, 2001). Using the cross-situational                  the target referent. They then investigated whether
word-learning task, Smith and Yu (2008) have found that                   participants were able to learn artificial language labels by
infants can learn word-referent pairs by computing                        integrating statistics across the most ambiguous naming
distributional statistics across the co-occurrences of words              events, which were instances that most adults could not guess
and referents at multiple naming moments, suggesting that                 the correct target referent. Significant learning was found
infants attend to and systematically store the co-occurrence              only from the child’s perspective but not from the observer’s
information during training. Additional evidence                          perspective, suggesting that the kind of input children
demonstrates that infants keep track of not only the strongest            experience may facilitate statistical aggregation. In a related
available associations but also low-frequency information,                follow-up study done by Zhang, Yurovsky and Yu (2015),
which further supports the notion that infants are sensitive to           participants were presented with a mixture of ambiguous and
the co-occurrence statistics between words and referents and              unambiguous first person videos and were asked to make
they keep track of a system of associations (Vouloumanous                 guesses about the correct referent on a trial-to-trial basis.
& Werker, 2009).                                                          Their results suggest that word-learning is a continuous
   While laboratory tests have led to significant advancement             process that learners make progress gradually by integrating
in our understanding of the underlying word-learning                      previous knowledge. Being able to remember and carry over
mechanism, cognitive scientists have also started to                      partial knowledge, despite the uncertainty of the information
investigate word learning using more naturalistic data. One               at a moment, could facilitate learning and partial knowledge
interesting ongoing discussion in the literature is centered on           can be especially helpful when the learning situations are
the question of how noisy our daily environment is. Medina,               ambiguous.
                                                                      2027

   Several recent studies have investigated word learning             tracking data has been done successfully in other studies (e.g.
from learners’ own perspective by placing lightweight head-           Aslin, 2009). Different from the original paradigm that used
cameras and eye-trackers on children while they interact with         dynamic videos, we used still images in the current study.
their parents. For example, researchers have found that               Our goal of Experiment 1 was to measure 12-month-old’s
referential uncertainty in 1½ year olds infants’ own visual           looking behaviors during free viewing of natural word-
field is significantly reduced at the sensory level. The clutter      learning scenes. Specifically, we wanted to compare and
and distraction in child’s visual field are effectively reduced       examine how different visual properties of target objects at
when objects are close to their eyes and head as close objects        naming moments influence the way infants allocate their
are visually large and can block the view of potential                attention. No spoken label was provided in this condition.
distracters (Yu & Smith, 2012). In addition, when parents
played with and talked about novel objects with their                 Participants. Twenty-five 12-month-old infants (10
toddlers, the visual properties (e.g. object’s image size or          female, ages ranged from 11.7 to 13.2 months, Mage = 12.28,
centeredness relative to other objects) of the target object          SDage = .43) participated the study. Parental consent was
during naming predicted children’s later novel object-name            obtained for all participants in compliance with the IRB of
learning (Pereira, Smith & Yu, 2014). These perceptual cues           Indiana University. All children received a gift for their
available in children’s view may play an important role in            participation.
children’s internal statistical computations. These findings          Materials. Forty-four images were selected from a set of
are quite informative considering the previous assumption             naming moment vignettes collected by Yurovsky et al. (2013)
that cluttered everyday environment can cause a high degree           for their original study. This set of vignettes included play
of referential uncertainty. There is a need to take the learners’     sessions from eight parent-child dyads. All vignettes were
view into account and to study the visual input directly              captured from children’s first person view using head-
perceived by the learners, because ultimately the statistical         mounted cameras during toy play with their parents and each
information that makes contact with children’s learning               vignette was 5 seconds long with the target name’s onset
system matters the most. Even though low referential                  occurred at the third second. As shown in Figure 1, we
ambiguity facilitates word learning and parents do create             selected one frame from each 5-second naming window and
relatively clean and unambiguous naming moments (Frank,               systematically varied both the size (big vs. small) and
Tenebaum & Fernald, 2013), naturalistic learning situations           location (centered vs. off-centered) of the target toy to create
vary in their quality with some being more ambiguous than             4 experimental conditions (Figure 1). The four frames of the
others, and some may facilitate learning and some may not.            same object were selected from different naming moments.
   In addition, reserachers have also started to investigate
whether visual attention plays a role in infants’ word learning
process (e.g. Smith & Yu, 2013). Although past research on
visual attention indicates that statistical word-learning is
constrained by infants’ developing attention system (Yu &
Smith, 2011), little is known regarding how children visually
attend to and select the target object among many other
objects in view when parents name it during everyday
interactions. Given that infants’ attention is selective as they
voluntarily direct their attention to certain aspects of the
environment moment by moment, will they select a subset of
information to attend to at each naming instance and
aggregate their knowledge over time? Is it the case that when
the adults utter a new word during interaction, children pay
attention to a lot of objects, happenings, and properties that
can possibly be a match, therefore word learning by
aggregating information is so hard and impossible? In the
current study, we explored the looking pattern of 12-month-           Figure 1: Sample images from target object “ball” for four
old infants using naturalistic images with varying degrees of         experimental conditions.
referential ambiguity in order to examine whether perceptual
properties of objects in children’s own view during naming            As shown in table 1: 1) there were many objects in view
moments would influence how young infants select candidate            (ranging from 10 to 15) to which infants could direct their
objects to build word-object mappings.                                attention, which suggests that overall there was a high degree
                                                                      of ambiguity and uncertainty in all 4 experimental conditions;
                                                                      2) there were also distinct differences in visual complexity
                        Experiment 1                                  and uncertainty among the four conditions. The target objects
The paradigm of presenting dynamic natural first-person               seem to be more visually dominant and salient in the
scenes obtained from an infant’s first person perspective to          big/centered condition and therefore more likely to attract
another age-matched infant while gathering on-line eye-               infants’ attention while the targets in small/off-centered
                                                                  2028

Table 1: Visual property details averaged across all 11 images         uncertainty; and 2) to measure how much time infants attend
in each condition.                                                     to the target objects.
                                                                       Quantifying Degree of Uncertainty. To investigate whether
                                                                       the number of objects attended by infants differed when
                                                                       target size or location changes, we first measured the total
                                                                       number of objects attended and found that even given that
                                                                       there were more than 10 objects in view, and also given
                                                                       plenty of viewing time (7 seconds per image) to attend to
condition were embedded in a set of objects in view, therefore
                                                                       many objects, infants only selectively attended 3-6 objects
less noticeable. These learning scenes with varying degrees
                                                                       per trial (Mbig/centered=3.74; Mbig/off-centered=5.24; Msmall/centered=
of uncertainty allow us to examine how infants direct their
                                                                       5.11; Msmall/off-centered=5.94). As shown in Figure 2A, we did
attention in those different contexts.
                                                                       not find a significant main effect for size or location (size:
                                                                       β=1.13, p=.05; location: β=.75, p=.21).
Apparatus. The learners’ eye gaze was measured by a Tobii
1750 eye tracker. The principle of this corneal reflection
tracking technique is that an infrared light source is directed
at the eye and the reflection of the light on the corneal relative
to the center of the pupil is measured and used to estimate
where the gaze is fixated. The eye-tracking system recorded
gaze data at 50 Hz (accuracy = 0.5°, and spatial resolution =
0.25°) as a learner watched an integrated 17 inch monitor
with a resolution of 1280 × 1024 pixels. E-prime software
was used to present the stimuli and to automate the recording
of eye location with the eye tracker software.
Procedure. Infants were seated on their caregivers’ laps
approximately 60cm from the monitor in a quiet room.
Parents were instructed to keep their child seated, facing
forward and refrain from talking to them or direct their
attention. We also told parents to either look down or close
their eyes throughout the entire procedure so as to not to
influence their infant’s behavior.
   The point of gaze was calibrated with a toy animation that
appeared randomly at five locations (four corners and center)          Figure 2: A. Mean number of objects attended; B. Mean
across the screen, one at a time. After successful calibration,        proportion of time infants look at the most attended object;
the first trial began with the centered presentation of an             C. Mean entropy (averaged across trials in each condition).
animation to orient infants’ attention to the screen. As soon
as infants looked at the center, pre-selected first person view           Knowing that the subset of objects infants attended to was
images would be presented full-screen. In total, 44 images             quite small, we further examined how infants allocated their
(11 toys, each has 4 conditions) were displayed for 7 seconds          attention among the subset of objects they chose. Do infants
each. The temporal order of images was pseudorandomized                attend to those objects equally frequently or do they only
so that images of the same object and images of the same               primarily attend to one or two objects? To answer this
condition do not appear consecutively. The first attention             question, we measured infants’ proportion of time looking at
grabbing slide was interspersed every 4 trials to maintain             the most attended object and found that across all four
child’s attention. While infants were attending to the images,         conditions, as shown in Figure 2B, infants spent more than
they also heard soft music played in the background. The               50% of time looking at one selected object (Mbig/centered=.71;
entire testing session was about 6 minutes long.                       Mbig/off-centered=.57; Msmall/centered= .58; Msmall/off-centered=.53). By
                                                                       fitting lmer models, we found that if the target size was big,
Results and Discussion. Because perfect tracking in a                  infants spent more time looking at their most attended object
continuous mode is not possible due to technical limitation of         (β =          -.13, p<.01). However, location does not have an
the eye-tracker, involuntary head movement or loss of                  impact (β = -.07, p=.13). This finding suggests that even
attention, we only included trials with more than 50% of gaze          infants focused on only a few objects per trial, they
data points. Included trials have an average of 80% of gaze            predominantly only look at one object at least half of the time.
data points. For data analysis, we fit linear mixed effect                Next, to further capture the uncertainty that infants faced
model to the data by using size or location as the fixed factor,       within a trial, we calculated entropy based on their looking
and subject and item as random factors. In Experiment 1, we            times. In information theory, Entropy can be used to describe
focused on analyzing gaze data to 1) quantify the degree of            the uncertainty given a distribution. In the present case, given
                                                                   2029

                                                             1
n objects in view, we calculated 𝐼𝐼 = ∑𝑛𝑛𝑖𝑖=1 𝑃𝑃𝑖𝑖 𝑙𝑙𝑙𝑙𝑙𝑙        where 𝑝𝑝𝑖𝑖     be the target, if so, whether the visual properties of the target
                                                            𝑃𝑃𝑖𝑖
                                                                                toy influence their accuracy. Our results indicate that only
is the proportion of time looking at object i. This Entropy                     location (β=-.32, p<.001) but not size (β=-.19, p=0.05) was a
measure captures the dynamics of attention as it takes into                     significant predictor (Mbig/centered=.66; Mbig/off-centered=.29;
account not only the number of objects attended but also the                    Msmall/centered=.56; Msmall/off-centered=.22, Figure 3B). This
looking duration on each object. For example, if one looked                     analysis provides evidence that when the target object is off-
at two objects equally, entropy equals to 1. If one looked at                   centered, infants are less likely to attend to it and treat it as a
two objects, but one look is much longer (75% of the time)                      potential target even it is still big in view, which suggests that
than the other (25% of the time), then entropy value would                      infants may have a center bias when free viewing natural
get lower and equals to 0.81 as it was a less uncertain                         scenes.
situation compare with looking at two objects equally. If one
looked at three object equally, then entropy gets higher and
equals to 1.56 (Figure 2C). Thus, both more looks and a more
even distribution of looks will cause the increase of entropy
with high uncertainty while fewer and uneven looks will
cause the decrease of entropy with low uncertainty. As shown
in Figure 2C, entropy measures in all four conditions were
relatively low, suggesting low uncertainty based on infants’
looking behavior (Mbig/centered=1.50; Mbig/off-centered=2.00;
Msmall/centered= 2.33; Msmall/off-centered=2.75). We then assessed
whether size or location of target objects influenced how
uncertain learners were based on entropy value. We found                        Figure 3: A. Mean proportion of time looking at the target
that infants tended to be more uncertain (higher entropy)                       object; B. Mean proportion of time that the most attended
when target size was small (β=.42, p<.05), but location was                     object is target (averaged across trials in each condition).
not a significant factor (β=.26, p =.15).
   These results are quite informative as they support the idea                    By analyzing free-viewing gaze data without naming in
that the visual dynamics of children’ visual field might not be                 Experiment 1, we found that visual properties, such as size
as noisy as people previously believed if we consider                           and location of objects in infants’ own view can influence the
statistical learning from an embodied view (Yu & Smith,                         way learners visually attend to those objects and the number
2012). The present results also show that children’s selective                  of objects they are able to attend to is quite limited due to
attention may simplify the learning problem even more                           selective attention.
because they only look at a subset of objects in their visual
field and spend most time attending to only one of the                                                  Experiment 2
selected objects.
                                                                                Because we are interested in examining referential
Target Look. Because all frames are taken from natural                          uncertainty during naming moments, in the second study, we
naming moments, there is a correct named target for each                        investigated whether hearing a label during free-viewing
scene even though participants were not aware of which                          would have an impact on how infants allocate their attention
object was being named. We next explored whether learners                       and whether their looking pattern changes after the label (e.g.
attended to the correct target or not without labels and we                     look at more or fewer objects, stay longer or shorter on
used two different ways to quantify this measure: 1)                            previously attended objects).
proportion of time infants look at the correct target in a given
trial; 2) if we treat the object that was attended the most by                  Participants. Twenty-three infants (11 females) between
infants as the one selected by them as the target, then how                     11.4 and 12.6 months of age (Mage = 12.2, SDage = .31) were
likely the object they select is the correct target.                            recruited from the same population as in Experiment 1, none
   By examining whether size or location of target objects                      of these children participated in the previous experiment.
influences how long infants look at the target object
(Mbig/centered=.34; Mbig/off-centered=.15; Msmall/centered=.24; Msmall/off-     Materials. The same 44 images used in Experiment 1 were
centered=.11, Figure 3A), we observed that infants looked at the                used in Experiment 2. A female native English speaker
target object significantly longer when it is big in view (β=                   recorded the 44 labeling sentences that were infant directed.
-.90, p<.001) and when it is centered in view (β=-1.01,                         Toys’ English labels were used. As shown in Figure 4, all
p<.01). These results suggest that if the target’s size is big or               labeling utterances were about 1 second long, with the onset
if it is centered relative to other objects in the visual field,                of the utterance occurred at exactly the fourth second of each
infants are more likely to pay attention to that object and treat               7-second trial, so there were 3 seconds of silence both before
it as a potential referent if naming occurs.                                    and after the labeling sentences. To keep infants attentive, the
   Because infants were not aware that there was a potential                    same object was labeled using different sentence structures in
target object in each scene, we were interested to see whether                  different conditions, such as “Look at the __!” “There is a
their most attended object during free viewing was likely to                    __!” See the__!” “It’s a__!” and same sentence structure does
                                                                            2030

not occur consecutively. Same background music with lower            can be quite narrow that only a few objects are first attended
volume was used.                                                     and then stored in the memory, infant might still try to
                                                                     maintain more flexible visual attention and sample relatively
Procedure. The procedure was the same as Experiment 1.               broad co-occurrence data when the additional cues provided
                                                                     (e.g. label) could not help them narrow down the information
Results and Discussion. Mean percentage of gaze points               selected further at the moment.
contained across all usable trials is 83%. As shown in Figure
4, we are mainly interested in two types of comparisons: 1)
compare looking behaviors happened in the last 3 seconds of
the silence condition and the last 3 seconds of the label
condition. This comparison controlled for the amount of
visual experience infants received, the only difference
between the two conditions was whether or not a label was
presented; 2) calculate looking pattern changes between the
first and the last 3 seconds of viewing for each condition, then
compare the changes between silence and label conditions. In
Experiment 2, we emphasized on analyzing gaze data to
examine whether label would influence: 1) the number of
objects infants select to attend; 2) the proportion of time
infants attend to the correct target. For all subsequent
analyses, we fit lmer models to the data and used label as the       Figure 5: A. Mean number of object attended; B. Mean
fixed factor and subject and item as random factors.                 number of new objects attended after label in 4 conditions.
                                                                        Because the labeling utterances are referring to the correct
                                                                     target in view, we further examined which object infants
                                                                     chose to pay attention to the longest and whether that object
                                                                     was the correct target. As shown in Figure 6, label does not
                                                                     influence the proportion of time infants look at the most
                                                                     attended object (β=.02, p=.21) nor the proportion of time that
                                                                     their most attended object is target (β=-.03, p=.32),
                                                                     suggesting that infants did not change their looking patterns
                                                                     dramatically after hearing the label.
Figure 4: Types of comparisons implemented in Exp 2.
   To compare looking behaviors observed in the last 3
seconds of the silence condition and the last 3 seconds of the
labeled condition, we did not find a significant main effect of
label on the number of objects attended (β=-.13, p=.46,
Figure 5A), suggesting that label doses not influence how
many objects infants choose to pay attention to. By
comparing the number of objects attended before and after
the label (first vs. last 3 seconds of the label condition), we      Figure 6: A. Mean proportion of time looking at the target
found that the average number of new objects (the ones they          object; B. Mean proportion of time that the most attended
did not attend to before the label) they chose to attend after       object is target in 4 experimental conditions.
the label was 1.33. The average number of new objects
attended in the silence condition (first vs last 3 seconds of the       The results in Experiment 2 are consistent with previous
silence) is 1.32, which is not significantly different from the      studies on parents’ object labels in free play (e.g. Tomasello
label condition (β=.03, p=.77, Figure 5B). Our data suggest          & Todd, 1983). They found that parents who use more
that infants do not change their looking patterns by selecting       follow-in labeling, which is the case the child is already
fewer or more objects to attend to because of the label. This        attending to the object before labeling, have children with
is probably because if infants do not already know the               larger vocabulary, suggesting that just following and labeling
referent’s name, even with a label, there is still no clear          what they have already attended to (instead of redirecting
indicator of which object might be the correct target.               child’s attention) would be quite effective because children
Although the information selected within a learning moment           would not switch their attention after hearing a label.
                                                                 2031

                    General Discussion                               retained in the sensory, attentional, and memory processes as
                                                                     it is through the interactions of all these cognitive
Our results show that perceptual properties of objects in
                                                                     components in the learning system that young learners
infants’ own view during naming moments dramatically
                                                                     acquire the knowledge of solving word-learning problems
influence how they select candidate objects to be considered
                                                                     and build their vocabularies.
to build word-object mappings. Experiment 1 results
demonstrate that data available to statistical learners are not                           Acknowledgments
the data in the real world, but only a small subset of that data     This research was supported by NIH R01 HD074601. Special
that is made into the learners’ perceptual system at each            thanks to Lillian Hogan for data collection.
learning moment. Such information is filtered through not
only the dynamics of first person views, but also the learner’s                                 References
own developing attention system because it is not possible for       Aslin, R. N. (2009). How infants view natural scenes gathered
infants to attend to everything in their own view. Thus, to             from a head-mounted camera. Optometry and vision science:
address the question of whether natural learning moments are            official publication of the American Academy of
too complex for statistical learners to keep track of lots of           Optometry, 86, 561.
information over time, we provide evidence to show that              Frank, M. C., Tenenbaum, J. B., & Fernald, A. (2013). Social
what the learners attend to at naming moments is not a large            and discourse contributions to the determination of reference
number of objects, but rather they attend to a small sample of          in cross-situational word learning. Language Learning and
available information in the world. This filtering process              Development, 9, 1-24.
significantly simplifies the amount of information available         Medina, T. N., Snedeker, J., Trueswell, J. C., & Gleitman, L. R.
for learners to carry over from one moment to the next, and             (2011). How words can and cannot be learned by
to further process and integrate statistical evidence in their          observation. Proceedings of the National Academy of
cognitive systems.                                                      Sciences of the United States of America, 108, 9014-9019.
   The quantitative results derived from gaze data can               Pereira, A. F., Smith, L. B., & Yu, C. (2014). A bottom-up view
                                                                        of toddler word learning. Psychonomic bulletin & review, 21,
advance our understanding of the referential uncertainty
                                                                        178-185.
problem encountered in real-life situations. At the same time,
                                                                     Quine, W. V. (1960). Word and Object. MIT Press. Cambridge,
they are also in line with the previous results found using the         MA.
cross-situational learning paradigm (Smith & Yu, 2008). The          Smith, L., & Yu, C. (2008). Infants rapidly learn word-referent
way infants learn word labels from real life learning moments           mappings via cross-situational statistics. Cognition, 106,
might be similar to the way they learn words in cross-                  1558-1568.
situational learning (CSL) tasks as in both cases they allocate      Smith, L. B., & Yu, C. (2013). Visual attention is not enough:
their attention to only a few objects in view at a moment.              Individual differences in statistical word-referent learning in
Given that infants are able to learn the correct object-label           infants. Language Learning and Development, 9, 25-49.
mappings by aggregating information across trials in CSL             Swingley, D. (2009). Contributions of infant word learning to
tasks, it would be interesting to see whether they are also able        language development. Philosophical Transactions of the
to learn correct object names by collecting and accumulating            Royal Society B: Biological Sciences, 364, 3617-3632.
information selected from first person scenes that resemble          Tomasello, M., & Todd, J. (1983). Joint attention and lexical
real-world learning situations. In addition, many adult studies         acquisition style. First language, 197-211.
using various paradigms (e.g. Yu & Smith, 2007; Zhang,               Yu, C., & Smith, L. B. (2007). Rapid word learning under
Yurovsky & Yu, 2015) have shown that word-referent                      uncertainty via cross-situational statistics. Psychological
learning is a continuous statistical learning process and               Science, 18, 414-420.
individual’s ability to remember and carry over knowledge            Yu, C., & Smith, L. B. (2011). What you learn is what you see:
from past learning instances facilitates subsequent learning.           using eye movements to study infant cross‐situational word
                                                                        learning. Developmental Science, 14, 165-180.
One possible future direction along this line would be to
                                                                     Yu, C., & Smith, L. B. (2012). Embodied attention and word
design a word-learning experiment using first person view
                                                                        learning by toddlers. Cognition, 125, 244-262.
naming instances. By measuring learners’ eye movement                Yurovsky, D., Smith, L. B., & Yu, C. (2013). Statistical word
during training and comparing that with their learning                  learning at scale: The baby's view is better. Developmental
outcome may allow us to understand real-time learning                   Science, 16, 959-966.
mechanisms, such as how statistical learners aggregate               Vouloumanos, A., & Werker, J. F. (2009). Infants’ learning of
information moment by moment and whether the information                novel words in a stochastic environment. Developmental
learners select to attend to during training would link to what         psychology, 45, 1611.
they learn at the end.                                               Waxman, S. R., & Booth, A. E. (2001). Seeing pink elephants:
   Despite the fact the environment young learners encounter            Fourteen-month-olds' interpretations of novel nouns and
is very complex and noisy, they are able to use selective               adjectives. Cognitive psychology, 43, 217-242.
attention to filter and clean up the inputs before processing        Zhang, Y, Yurovsky, D., & Yu, C. (2015). Statistical Word
them in their cognitive system. It is important to examine the          Learning is a Continuous Process: Evidence from the Human
underlying learning mechanisms by measuring and analyzing               Simulation Paradigm. Proceedings of the 37th Annual
statistical information that is selected by, further stored and         Meeting of the Cognitive Science Society.
                                                                 2032

