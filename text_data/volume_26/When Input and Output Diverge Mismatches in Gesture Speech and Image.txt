UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
When Input and Output Diverge: Mismatches in Gesture, Speech, and Image
Permalink
https://escholarship.org/uc/item/9g00h8h5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Melinger, Alissa
Kita, Sotaro
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       When Input and Output Diverge: Mismatches in Gesture, Speech, and Image
                                               Alissa Melinger (melinger@coli.uni-sb.de)
                                               Department of Computational Psycholinguistics,
                                             Saarland University, Saarbrücken, 66041, Germany
                                                Sotaro Kita (sotaro.kita@bristol.ac.uk)
                                        Department of Experimental Psychology, 8 Woodland Road
                                          University of Bristol, Bristol BS8 1TN, United Kingdom
                               Abstract                                   representation, but they can also be influenced by ‘thinking
                                                                          for speaking’ operations on this representation.
   The goal of the current paper is to investigate the behavior of           Discriminating between these theoretical alternatives is
   gesture when the information conveyed by speech and the                difficult because there is usually a close isomorphism
   information conveyed by the image being described conflict             between the semantic content of speech and the imagistic
   as a result of perspective taking. To construct a corpus of
   speech-image mismatches, we designed a picture description
                                                                          content of the representation speech is describing.
   elicitation procedure using path-like networks of colored                 Bearing on this discussion are recent studies
   circles. The results of our analysis demonstrate that gestures         demonstrating that gestures can convey complementary
   can be mismatched to both speech, as has been previously               information to what is expressed in speech. For example,
   observed, and to the image, which has not been previously              when describing their solutions to the Tower of Hanoi
   reported. The results provide insights into the nature of the          problem, speakers’ gestures sometimes corresponded to
   representations that give rise to gestures.                            possible strategies that were not mentioned in the concurrent
                                                                          speech rather than to the strategy that was mentioned in
                   The Origin of Gesture                                  speech. (Garber & Goldin-Meadow, 2002). The non-
This paper investigates the underlying cognitive processes                isomorphism between the content of speech and gesture has
involved in relating spatial information from a visual input              been referred to as speech-gesture mismatches. High rates
to two separate output modalities, namely speech and                      of speech-gesture mismatches have also been reported for
gesture. Three theoretical possibilities have been proposed               children who are in the transitional stage of acquiring the
for how these three modalities of representation, visual-                 ability to correctly respond to the Piagetian conservation
spatial, verbal and gestural, are related: The Lexical                    task (Church & Goldin-Meadow, 1986).
Semantic Hypothesis (Butterworth & Hadar, 1989;                              Speech-gesture mismatches appear to contradict the
Schegloff, 1984), the Free Imagery Hypothesis (Krauss,                    claims of the Lexical Semantic Hypothesis in that they
Chen, & Chawla, 1996; Krauss, Chen, & Gottesman, 2000;                    express information not included in speech. However, the
but see de Ruiter, 1998, 2000 for another version of this                 information expressed by gesture in the speech-gesture
hypothesis), and the Interface Hypothesis (Kita & Özyürek,                mismatches does not actually conflict with either the
2003).                                                                    linguistic or the imagistic representation; instead they
    The Lexical Semantic Hypothesis (Butterworth & Hadar,                 provide complementary information. Thus, they do not
1989; Schegloff, 1984) proposes that gestures are generated               provide a strong test of the competing theories. In this paper
from the semantics of the lexical items chosen to express the             we employed perspective taking to create situations in
desired message. It predicts that gestures should always                  which what was said conflicted with what was seen.
correspond to the meaning expressed by specific lexical                   Examining the behavior of gesture in these cases should
items. In contrast, the Free Imagery Hypothesis (Krauss et                discriminate between the competing hypotheses regarding
al., 1996, 2000) claims that gestures are generated on the                gesture generation. The Lexical Semantics Hypothesis
basis of pre-linguistic non-propositional representations; the            predicts that gestures will always align with the speech. The
strong reading of this proposal implies that the information              Free Imagery Hypothesis predicts that the gestures will
conveyed by gesture should be unaffected by the specific                  always align with the image. The Interface Hypothesis
lexical items selected during formulation and by the                      predicts that gesture alignment will be influenced by
‘thinking for speaking’ (Slobin, 1987, 1996) processes that               ‘thinking for speaking’ processes and therefore the
convert the imagistic representation into propositional                   alignment of gesture could be to either or both
content (however, see below for alternative readings of this              representations, depending on the specific situation.
proposal). The Interface Hypothesis (Kita & Özyürek, 2003)
claims that gestures originate from a mediating                                              Perspective Taking
representation connecting spatio-motoric representations in               Perspective taking is a critical step required to express
memory and linguistic representations. According to this                  spatial relations in speech (cf. Miller & Johnson-Laird,
view, gestures are generated from the imagistic
                                                                      950

1976). Spatial representations, which are inherently relative,                            Mismatch Corpus
must be grounded to some referent in a scene. The choice of
                                                                     To compile a corpus of speech-image-gesture mismatches,
the grounding referent impacts the linguistic terms that can
                                                                     we presented speakers with networks of colored circles
be selected to express the relationship. Thus, perspective
                                                                     arrayed along a path. The images were very similar to
taking necessarily precedes linguistic formulation. It forms
                                                                     networks used previously by Levelt (1996) to investigate
part of the ‘thinking for speaking’ conceptualizing process
                                                                     perspective taking in speech production. As with other
(cf. Levelt, Roelofs & Meyer, 1999) that abstracts away
                                                                     spatial relations, adopting different linguistic perspectives to
from the visual imagery and maps the relations onto
                                                                     describe an image, such as in Figure 2, results in the use of
propositional representations. Choice of perspective can be
                                                                     different linguistic terms to express the same spatial
influenced by, among other things, language/culture specific
                                                                     relations, as seen in examples (3a) and (3b).
resources (Levinson, 2003), the specific task at hand
(Tversky, 1991) and/or pragmatic concerns (Levelt, 1996).
                                                                     Deictic Sample descriptions:
   Consider the image in Figure 1. In describing the
                                                                     (3a)       You begin with a yellow circle. Above that you see
relationship between the ball and the car, the speaker can
                                                                     a blue circle. To the right you see a red circle and above the
select himself as the grounding referent, describing the
                                                                     red circle you see another red circle. Right of the second red
relationship from his own personal orientation, as in (1).
                                                                     circle is the yellow circle and right of that is a blue circle.
This perspective will be referred to as the d e i c t i c
perspective. Alternatively, he can select one of the objects
                                                                     Intrinsic Sample descriptions:
in the scene as the grounding referent, such as the car, and
                                                                     (3b)       You begin with a yellow circle. You go straight
describe the relation with respect to the car’s inherent
                                                                     ahead to a blue circle. Then you go to the right to a red
orientation, producing the intrinsic description in (2).
                                                                     circle and then left to another red circle. From the second
                                                                     red circle, go to the right again to a yellow circle and then
                                                                     straight ahead to a blue circle.
                            Figure 1
     (1) The ball is to the left of the car.
     (2) The ball is in front of the car.                                                         Figure 2
                                                                     Notice that the term straight ahead in description (3b) is
When speakers choose to describe the relationship between            used to refer to two different directions of transition. First, it
the ball and car as in (2), a special situation arises; namely,      is used for the vertical transition from the first (yellow)
the characteristics of the visual input, pre-abstraction, do not     circle to the second (blue) circle. Later, it is used again to
match the linguistic terms used to describe them. On the two         refer to the lateral transition from the second from the last
dimensional representation of the image, nothing is in front         (yellow) circle to the last (blue) circle. In contrast, the terms
of the car; the notion of front used in (2) is only relevant         used in description (3a) hold a constant relationship to a
with respect to the orientation of the car — only within the         particular axis on the paper. For the deictic description,
perspectivized mental representation of the image. This              there is perfect isomorphism between the input image and
contrast between the pre-abstraction visual input and the            the output description. In contrast, for the intrinsic
perspectivized mental representation provides the gesture            descriptions, there is non-isomorphism, which allows for a
researcher with the opportunity to contrast the content of the       further investigation of how gesture is related to the two
image with the content of speech in a unique way.                    representations.
Specifically, the content of the input imagistic                        If gesture is generated on a faithful memory
representation and the output linguistic representation can          representation of the image, as proposed by the strong
be pitted against each other. How gesture behaves when the           version of the Free Imagery Hypothesis, then, in cases of
input and output representations conflict will reveal the            speech-image mismatch, gesture should align to the image
underlying representation from which gesture was                     and conflict with speech. If gesture is generated from the
generated, thus discriminating between the three                     lexical semantics of the words used to encode the message,
hypotheses.
                                                                 951

as suggested by the Lexical Semantics Hypothesis, then                three binary features: Speech matches image, gesture
gesture should always match the speech and conflict with              matches speech, and gesture matches image. These codes,
the image. If gesture is generated from an interface                  together with codes for which directional term was
representation that results from ‘thinking for speaking’              produced and unperspectivized direction of transition, form
processes, as suggested by the Interface Hypothesis, then             the bases of the mismatch analysis.
gestures may match preferentially either the image or the                Speech-image mismatches were identified as any
speech, depending on the needs of the speaker at any given            transition in the network for which the verbal description
moment. In this case, characteristics of the image, the               provided in the intrinsic perspective did not match the actual
lexical item, or the situation could affect to which                  direction of the transition in the network. For example, any
representation the gesture is aligned.                                transition labeled right that did not progress rightward on
                                                                      the page was a mismatch. Likewise, any use of straight
Constructing the Corpus                                               ahead that did not correspond to an upward transition was
                                                                      coded as a mismatch. (Note that as the image was placed on
Speakers. Sixteen native speakers of Dutch from the Max               the table in front of the speaker, the upward transition in the
Planck Institute for Psycholinguistics’ subject pool were             image was in the forward direction for the speaker, for
paid for their participation.                                         which straight ahead is felicitous.)
                                                                         Every picture provided multiple mismatch opportunities.
Pictures. Sixteen path-like images depicting networks of              For example, 11 networks included an upwards transition,
colored circles were constructed. Each image consisted of             similar to the transition from circle 3 to 4 in Figure 2, which
an explicit start point as well as red, yellow, and blue circles      intrinsic speakers described as right or left. Eight networks
arrayed along a path. Half of the pictures had branching              included lateral transitions, similar to the final movement in
paths while the other half did not. All speakers saw all              Figure 2, linguistically described as straight ahead. Four
pictures in the same presentation order. In sum, 256 picture          networks included downward transitions, linguistically
descriptions were collected.                                          described as right and three networks including lateral
                                                                      transitions that followed downward transitions. These
Procedure. Speakers were seated across from their                     transitions leftwards or rightwards were described with the
interlocutor separated by a visual block. Their task was to           opposite directional term, namely, rightward turns were
describe the pictures to the interlocutor, who was, in fact, a        described as left and vise versa.
confederate.
   Speakers were given approximately 15 seconds to study
the image, which was placed on the table by the                       Corpus Analysis
experimenter. After this memorization period, the picture
was removed and the speaker began to describe the image.                 In this section we first give some descriptive details of the
Speakers were free to describe the routes in any way that             corpus before we turn to the crucial questions under
was natural to them; they were not given any linguistic               investigation.
examples to bias their description strategy. The listener was            Characteristics of speech and gesture varied greatly
instructed not to ask any specific questions that might bias          between speakers. Six speakers produced almost no gestures
the content of the descriptions. She was free, however, to            at all. Of the ten gesturers, three produced predominantly
ask the speaker to repeat portions or even the entire                 deictic descriptions and seven produced predominantly
description of an image. All sessions were video recorded.            intrinsic descriptions. While the deictic speakers are
                                                                      generally orthogonal to the issue of speech-image mismatch,
Coding system. A native Dutch speaker familiar with                   two produced some mixed perspective descriptions,
gesture transcription systems but blind to the hypotheses             producing mismatch opportunities. Only speakers who
under investigation used the videotapes to create a                   adopted the intrinsic frame of reference AND who gestured
transcription of the speech as well as a record of all                are of relevance to our investigation.
gestures. Several types of linguistic information were                In total, the corpus of directional terms consisted of 1440
identified, including directional information (e.g., right, left,     directional tokens, 389 of which were produced with a co-
straight ahead), destination information (e.g., a red circle, a       expressive gesture. Table 1 presents lexical, gesture, and
blue circle), landmark information (e.g., you arrive at an            mismatch frequencies for each of the directional terms
intersection), and shape information (e.g., you will travel in        found in our corpus.1
a big circle). In this paper, we will focus exclusively on
directional information and accompanying directional
gestures.
   Gestures were either produced with the head or hands.
                                                                      1
Both were coded for several features, most crucially for the            We will present English translations for the Dutch directional
direction of the stroke but also for handedness. Once speech          terms found in our corpus. With respect to the description of our
and gesture were fully transcribed, they were coded for               images, there are no critical differences in how directions and
                                                                      spatial relations are lexicalized.
                                                                  952

    Table 1. For each directional term, the total number of          Friedman’s c2 (2) = 7.3, N=8, p < .05. Second, for the cases
  tokens, the percentage of tokens produced with a gesture,          in which gesture aligned with image, the proportion of
        and the number of speech-image mismatches.                   speech-image mismatches for each of the three lexemes was
                                                                     calculated for each speaker in the analogous way to the
    Lexemes          Total       % With        Speech- Image         previous analysis. There is no evidence that proportions
                    Tokens       Gesture         Mismatches          differed between the lexemes, Friedman’s c2 (2) = 0.9, N=8,
      Right           494          27%               100             p > .1.
      Left            317          26%               79                 Table 2 shows that gesture alignment patterned differently
 Straight ahead       321          15%               62              for different lexemes. Table 3 further breaks down the
       Up             120          8%                 --             information for different directions of transition within the
     Down              19          10%                --             network.
      Back            106          37%                --
     Further           63          13%                --                Table 3. Number of speech-image mismatches in
                                                                     descriptions of either upwards, downwards or lateral
The three directional terms that are relevant for mismatches         transition in which gesture aligned to either the image or to
are right, left, and straight ahead. In 241 instances, these         speech.
words did not match the direction in the image. 58 of these
speech-image mismatches were produced with a gesture that              Transition        Lexeme           Gesture =       Gesture =
could either align with the linguistic term or the direction in        Direction                            Image           Speech
the image. The terms up and down were only used by deictic                 Up          Right or left           5              12
speakers and therefore always matched the input image. The               Down          Right or left           5              11
terms back and further can only be interpreted in the context          Laterally       Right or left           7               2
of prior movements, and therefore the question of whether              Laterally     Straight ahead           13               3
they match the picture is not applicable
   The term back received the highest proportion of co-                 The alignment pattern for vertical (up and down)
expressive gestures. The terms left and right were each              transitions was significantly different compared to lateral
produced with co-expressive gestures over 25% of the time,           transitions, c2 (1) = 12.15, p < .001. Speakers preferred to
further and straight were produced with intermediate                 align with the image when the transition was lateral but
gesture rates and up and down had the lowest gesture rates.          preferred to align with speech when the transition was
   We now turn to the central question of the paper. The             vertical. One possible interpretation of this pattern is that
crucial data from the corpus are gestures produced when              speakers generally prefer to gesture laterally.
speech and image are mismatched. The critical question is               In speech-image mismatch cases, gestures sometimes
whether these gestures reflect the direction represented in          aligned with the image and sometimes with the speech.
the image, in speech, or both. The number of gestures that           This split was quite even for gestures produced for the
matched the image or the speech for each directional term is         lexemes left and right but not for straight ahead. In the
presented in Table 2.                                                latter case, speakers preferred to align their gestures with the
                                                                     image. The different alignment patterns to different lexical
 Table 2. Number of speech-image mismatches for which the            items may also be interpreted in terms of a general
 gesture matches either the speech or the image, for the three       preference to gesture laterally rather than vertically.
                   relevant directional terms.                          What the data from the corpus clearly indicate, however,
                                                                     is that there is no strong tendency to align gestures to the
       Lexeme          Gesture = Image       Gesture = Speech        image at the expense of speech or vise versa. When the
        Right                  8                    15               information conveyed in speech conflicts with the
        Left                   9                    10               information presented in the visual input, gesture can align
   Straight ahead             13                     3               with either. The decision as to whether a gesture aligns with
                                                                     the con-current speech is mediated by a spatial factor
   The distribution of cases where the gesture matches the           (lateral vs. vertical transitions). This result was not predicted
image compared to when it matches speech is different for            by the Free Imagery Hypothesis or the Lexical Semantic
the three directional terms, right, left, and straight ahead, c2     Hypothesis, as we will discuss in more details in the next
(2) = 7.13, p < .05. Two by-speakers comparisons were also           section. The result is, however, compatible with the
carried out to assess this relationship. First, for the cases in     Interface Hypothesis.
which gesture aligned with speech, the proportion of
speech-image mismatches for each of the three lexemes was                                      Discussion
calculated for each speaker by dividing the number of
                                                                     By using images consisting of path-like networks of circles,
speech-image mismatches for the lexeme divided by the
                                                                     we succeeded in constructing a corpus of picture
total speech-image mismatches for all three lexemes. The
                                                                     descriptions in which the content of speech and the content
proportions differed significantly between the lexemes,
                                                                     of the to-be-described image often conflicted. Our aim was
                                                                 953

to see whether gestures produced in these instances would           of being prepared for speech. According to this hypothesis,
be co-expressive with the lexical affiliate, as predicted by        there is a general tendency for an interface representation to
the Lexical Semantics Hypothesis (Butterworth & Hadar,              converge with the linguistic representation in the utterance
1989; Schegloff, 1984), with the characteristics of the             being planned. The degree of convergence is determined by
image, as predicted by the strong reading of the Free               various contextual factors (Kita, 2000). In the case of this
Imagery Hypothesis (Krauss et al., 1996, 2000), or whether          study, when the spatial representation of the transition is
the alignment to one representation or another would be             confusable, that is, when the transition is lateral (i.e.,
influenced by ‘thinking for speaking’ processes, as proposed        leftwards or rightwards), the convergence to the linguistic
by the Interface Hypothesis (Kita & Özyürek, 2003).                 representation is weak, and thus gesture tends to match the
   What our corpus analysis reveals is that gesture                 spatial representation of the transition, rather than the
alignment behavior in speech-image mismatches was not               linguistic representation. When the spatial representation of
driven solely by either the characteristics of the input image      the transition is not confusable, that is, when the transition is
or the characteristics of speech. Rather, the gestural content      vertical (i.e., u p w a r d s or downwards), the interface
seemed to be co-determined by the lexeme choice and the             representation converges strongly to the linguistic
type of spatial representation. Specifically, when the              representation. Note further that the idea that gestures help
lexemes left and right were used to express the spatial             distinguish confusable spatial representations is compatible
representations upwards and downward, gesture tended to             with theories of self-oriented functions, in particular, the
align with speech rather than with the spatial representation.      theory that gestures help organize spatio-motoric
When the lexeme straight ahead was used to express the              information for speaking (Kita, 2000; Alibali, Kita, Yong,
spatial concepts leftwards and rightwards, gestures tended          2000; Kita, 2003).
to align with the spatial representation of the image. When            The data also rule out the possibility that gestures can be
the lexemes left and right were used to express the spatial         randomly generated from either the input imagistic
representations rightwards and leftwards, respectively,             representation or the output lexical representations,
gesture again tended to align with the spatial representation.      alternating randomly between these two sources. This
   The fact that the gestural content was determined by the         possibility, previously discussed in Kita and Özyürek (2003)
interplay between both lexical and spatial representations          predicts that speech-gesture mismatches should randomly
makes it difficult to maintain either the Lexical Semantics         align to the input or to speech, without a discernable pattern.
Hypothesis, which holds that gestures are generated from            This is not the observed pattern, as seen in Table 3.
the semantic representations of lexical items that have been           One could object to our definition of speech-image
selected for speaking, or the strong version of the Free            mismatch. Consider for example the possibility that
Imagery Hypothesis, which holds that gestures are                   speakers mentally rotate the image in memory in order to
generated from pre-linguistically generated imagery.                calculate the correct directional term for the intrinsic
      However, we need to recognize that there are different        perspective. In this case, apparent speech-image mismatches
versions of the Free Imagery Hypothesis, which make                 would in fact be matches. However, if this were true we
different assumptions. In de Ruiter's (2000) version of the         would not have expected gesture alignment to ever conflict
Free Imagery Hypothesis, gestures are generated in the              with speech, since speech would always match the
Conceptualizer in Levelt's (1989) sense, which generates the        perspectivized internal memory representation of the image
(pre-linguistic) proposition to be linguistically formulated in     for the speaker at that moment. This is not consistent with
the next utterance. According to de Ruiter, both gestural and       the observe data pattern, as seen in Table 1.
linguistic perspectives are determined in the Conceptualizer.          The gesture-speech mismatches reported in this study are
Similarly to the strong version of the Free Imagery                 of a different type from what have been attested in previous
Hypothesis, "the shape of the gesture [iconic gesture] will         research. Gesture-speech mismatch has been observed in
be largely determined by the content of the imagery" (de            children's explanations for Piagetian conservation tasks
Ruiter, 2000: 293). As such, the results from the present           (Church & Goldin-Meadow, 1986) and children's
study are problematic not only to the strong version of the         explanations for equivalence of an equation (Perry, Church,
Free Imagery Hypothesis, but also to de Ruiter's version.           & Goldin-Meadow, 1988), and adult and children's
However, because in de Ruiter's model the shape of a                description of the solution to the Tower of Hanoi puzzle
gesture is determined in the Conceptualizer, which in               (Garber & Goldin-Meadow, 2002). In these studies, gesture
principle has access to (pre-linguistic) propositions to be         and speech refer to two distinct referents that are both
linguistically formulated, it might be possible to modify the       relevant to the current goal of discourse, or two alternative
model to account for the present results.                           strategies or solutions that might apply to the problem at
   The gestural content is determined by the interplay              hand. For example, in the explanation for a Piagetian
between lexical choice and directions of the transition in the      conservation task, speech may indicate the height of a glass,
image. This result could be accounted for by the Interface          this one is tall, and gesture may indicate the width of the
Hypothesis (Kita & Özyürek, 2003), which proposes that              same glass. By contrast, mismatches that result from
gestures are generated from an interface representation,            perspective taking can be called same-referent mismatches.
namely, a spatio-motoric representation that is in the process      Speech and gesture have the same referent, namely a motion
                                                                954

vector, but they map the vector to a gestural body movement         Goldin-Meadow, S., Nusbaum, H., Kelly, S. D., & Wagner,
under different perspectives. Using these same-referent               S. (2001). Explaining match: Gesturing lightens the load.
mismatches allows the predictions of the competing theories           Psychological Science, 12 (6), 516-522.
to be properly tested.                                              Kita, S. (2000). How representational gestures help
    To conclude, we have introduced a new source of                    speaking. In D. McNeill (Ed.), Language and gesture
evidence into the field of gesture research, namely speech-            (pp. 162-185). Cambridge: Cambridge University Press.
image mismatches with concomitant gestures. These                   Kita, S. (2003). Interplay of gaze, hand, torso orientation
speech-image mismatches allow the content of the linguistic           and language in pointing. In S. Kita (Ed.), Pointing:
and the imagistic representations to be separated and                 where language, culture, and cognition meet (pp.307-
contrasted. An analysis of the behavior of these gestures             328). Mahwah, NJ: Lawrence Erlbaum
                                                                    Kita, S. & Özyürek, A. (2003). What does cross-linguistic
revealed that gestures cannot be generated from a purely
                                                                      variation in semantic coordination of speech and gesture
linguistic or purely imagistic representation. Rather, gestural
                                                                      reveal?: Evidence for an interface representation of spatial
content was determined by the interplay between the lexical           thinking and speaking. Journal of Memory and Language,
items used in the description and the type of directional             48, 16-32.
information in spatial representation of the transitions.           Krauss, R., Chen, Y., & Chawla, P. (1996). Nonverbal
Many issues in gesture research have had difficulty in                behavior and nonverbal communication: What do
finding clear evidence for or against specific proposals              conversational hand gestures tell us? Advances in
exactly because it is generally difficult to disentangle the          Experimental Social Psychology, 28, 389-450.
independent contributions of linguistic and imagistic               Krauss, R., Chen, Y., & Gottesman, R. (2000). Lexical
representations. The present paper uses perspective taking to         gestures and lexical access: a process model. In D.
avoid this problem. The present study is also significant in          McNeill (Ed.), Language and gesture: Window into
that the methodology affords reliable elicitation of same-            thought and action. Cambridge, UK: Cambridge
referent mismatches from normal adult speakers.                       University Press.
                                                                    Levelt, W. (1996). Perspective taking and ellipsis in spatial
                    Acknowledgments                                   descriptions. In P. Bloom, M. A. Peterson, M. F. Garrett,
                                                                      & L. Nadel (Eds.), Language and space (pp. 77-107).
We acknowledge useful comments from the members of the                Cambridge: MIT Press.
Gesture Project at the Max Plank Institute for                      Levelt, W.J.M., Roelofs, A., & Meyer, A.S. (1999). A
Psycholinguistics. We greatly appreciated comments on an              theory of lexical access in speech production. Behavioral
earlier version of this paper from Joana Cholin, Asifa Majid          and Brain Sciences, 22(1), 1-38.
and Andrea Weber. We also benefited greatly from                    Levinson, S. C. (2003). Space in language and cognition:
insightful comments by anonymous reviewers. Special                   Exploration in cognitive diversity. Cambridge: Cambridge
thanks also go to Anne-Marie van Hoof and Esther Vrinzen              University Press.
for acting convincingly as our confederate and for                  Melinger, A. & Kita, S. (Submitted). Conceptual load
transcribing the descriptions.                                        triggers gesture production.
                                                                    Miller, G. A., & Johnson-Laird, P. N. (1976). Language and
                         References                                   Perception. Cambridge, MA: Harvard University Press.
                                                                    Perry, M., Church, R.B., & Goldin-Meadow, S. (1988).
Alibali, M. W., Kita, S, & Young, A. J. (2000). Gesture and
                                                                      Transitional knowledge in the acquisition of concepts.
   the process of speech production: we think, therefore we
                                                                      Cognitive Development, 3, 359-400.
   gesture. Language and Cognitive Processes, 15, 593-613.
                                                                    Schegloff, E. A. (1984). On some gestures’ relation to
Butterworth, B. & Hadar, U. (1989). Gesture, speech and
                                                                      speech. In J. M. Atkinson & J. Heritage (Eds.), Structures
   computational stages: A reply to McNeill. Psychological
                                                                      of social action: Studies in conversational analysis.
   Review, 96, 167-174.
                                                                      Cambridge: Cambridge University Press.
Cassell, J., McNeill, D., & McCullough, K. (1999). Speech-
                                                                    Slobin, D. I. (1987). Thinking for speaking. In J. Aske, N.
   gesture mismatches: Evidence for one underlying
                                                                      Beery, L. Michaelis, & H. Filip (Eds.), Proceedings of the
   representation of linguistic and nonlinguistic information.
                                                                      13th annual meeting of the Berkeley Linguistic Society
   Pragmatics & Cognition, 7, 1-33.
                                                                      (pp. 435-445).
Church, R. B., & Goldin-Meadow, S. (1986). The mismatch
                                                                    Slobin, D. I. (1996). From “thought and language” to
   between gesture and speech as an index of transitional
                                                                      “thinking for speaking”. In J. J. Gumperz & S. C.
   knowledge. Cognition 23, 43-71.
                                                                      Levinson (Eds.), Rethinking linguistic relativity (pp. 70-
de Ruiter, J.-P. (1998). Gesture and Speech Production.
                                                                      96). Cambridge: Cambridge University Press.
   Ph.D. Dissertation, Max Planck Institute for
                                                                    Tversky, B. (1991) Spatial mental models. In G. H. Bower
   Psycholinguistics, The Netherlands.
                                                                      (Ed.), The psychology of learning and motivation:
de Ruiter, J. P. (2000). The production of gesture and
                                                                      Advances in research and theory, Vol. 27 (pp.109-146).
   speech. In D. McNeill (Ed.), Language and gesture (pp.
                                                                      New York: Academic Press.
   284-311). Cambridge: Cambridge University Press.
Garber, P., & Goldin-Meadow, S. (2002). Gesture offers
   insight into problem solving in adults and children.
   Cognitive Science, 26, 817-831.
                                                                955

