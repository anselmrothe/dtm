UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Model of Children's Semantic Memory
Permalink
https://escholarship.org/uc/item/2dg5b94j
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Denhiere, Guy
Lemaire, Benoit
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                         A Computational Model of Children's Semantic Memory
                                              Guy Denhière (denhiere@up.univ-mrs.fr)
                                                  L.P.C & C.N.R.S. Université de Provence
                                                        Case 66, 3 place Victor Hugo
                                                       13331 Marseille Cedex, France
                                      Benoît Lemaire (Benoit.Lemaire@upmf-grenoble.fr)
                                                  L.S.E., University of Grenoble 2, BP 47
                                                      38040 Grenoble Cedex 9, France
                               Abstract                                 & Dumais (1997) designed a model of vocabulary
                                                                        acquisition based on LSA; Lemaire & Dessus (2001),
   A computational model of children's semantic memory is               Rehder et al. (1998) and Wolfe et al. (1998) used it for
   built from the Latent Semantic Analysis (LSA) of a                   modeling knowledge assessment; Quesada et al. (2001)
   multisource child corpus. Three tests of the model are               modeled complex problem solving by means of LSA basic
   described, simulating a vocabulary test, an association test         representations; Wolfe & Goldman (2003) worked on a
   and a recall task. For each one, results from experiments with       model of reasoning about historical accounts based on LSA.
   children are presented and compared to the model data.               However, to our knowledge, no computational basic
   Adequacy is correct, which means that this simulation of             representations were made that mimic full children's
   children's semantic memory can be used to simulate a variety         semantic memory.
   of children's cognitive processes.                                      This paper aims at presenting such a model. First, we
                                                                        present LSA. We then describe our corpus, which is
                          Introduction                                  supposed to mimic the kind of texts children are exposed to.
Models of human language processing are usually based on                Finally, we present three experiments which aim at
a layer of basic semantic representations on top of which               validating the model.
cognitive processes are described. For instance, the
construction-integration model (Kintsch, 1998) describes                                Latent Semantic Analysis
processes that operate on a network of propositions. These
basic representations can just be descriptions of what the              Basic semantic representations
human memory looks like, in order for the upper models to               There are many ways of constructing basic semantic
be explicitly stated, but they can also be operationalized so           representations that can be processed by a computer. The
that the model can be tested on a computer. In the first case,          first one is to build them by hand. Powerful formalisms like
these representations are usually designed by hand, but this            description logic (Borgida, 1996) or semantic networks
method prevents large-scale simulations.                                (Sowa, 1991) have been designed to accurately represent
   This was the case with Kintsch's construction-integration            concepts, properties and relations. However, in spite of
model until 1998. Before that, researchers had to code                  huge efforts (Lenat, 1995), no full set of symbolic represen-
propositions by hand and guess relevant values to code the              tations has been made that can be considered a reasonable
strength of links between nodes. Then Kintsch (1998) used               model of human semantic memory. Hand-coding semantic
the Latent Semantic Analysis (LSA) model (Deerwester et                 information is tedious and, as we mention later, symbolic
al., 1990; Landauer et al., 1998) which provides a way to               representations might not be the best formalism for that.
automatically build these basic representations. This was a                Another strategy is to rely on corpora to get the semantic
major step since the construction-integration processes                 information. Artificial intelligence researchers have
could then be tested on a large variety of inputs, while being          designed sophisticated syntactic processing tools for
less dependent on idiosyncratic codings. Such a mechanism               automatically describing the knowledge using the kind of
for automatically constructing basic semantic represen-                 symbolic formalisms mentioned earlier. They usually refer
tations should be carefully designed and tested in order to             to them as ontologies or knowledge bases (Vossen, 2003).
simulate as good as possible human semantic memory.                     However, in spite of great strides, this approach still cannot
   LSA is nowadays considered as a good candidate for                   be the means to form the basic semantic representations that
modeling an adult semantic memory based on a large                      cognitive researchers need. First, it cannot be fully
corpora of representative texts: Bellissens et al. (2002),              automatized, except for specific domains, thus preventing
Kintsch (2000) and Lemaire & Bianco (2003) used it for                  complete descriptions of the language. Second and quite
modeling metaphor comprehension; Pariollaud et al. (2002)               paradoxically, since the descriptions are quite elaborated, it
used it for modeling the comprehension of idiomatic                     is very hard to design reasoning processes on top of them.
expressions; Howard & Kahana (2002) relied on it to model               For instance, a simple process like estimating the degree of
free recall and episodic memory retrieval; Laham (1997) did             semantic association is very hard to operationalize on
the same for modeling categorization processes; Landauer                complex structures like semantic networks.
                                                                  297

 Instead of relying on symbolic representations, a third               For your fitness, you can practice bike. It is very nice and
approach consists in (1) analyzing the co-occurrence of                good to your body.
words in large corpora in order to draw semantic similarities
                                                                       Bicycling and bike appear in similar paragraphs. If this is
and (2) relying on very simple structures, namely high-
                                                                       repeated over a large corpus, it would be reasonable to
dimensional vectors, to represent meanings. In this
                                                                       consider them similar, even if they never co-occur within
approach, the unit is the word. The meaning of a word is not
                                                                       the same paragraph. Now we need to define paragraph
defined per se, but rather determined by its relationships
                                                                       similarity. We could say that two paragraphs would be
with all others. For instance, instead of defining the
                                                                       similar if they share words, but that would be restrictive: as
meaning of bicycle in an absolute manner (by its properties,
                                                                       illustrated in the previous example, two paragraphs should
function, role, etc.), it is defined by its degree of association
                                                                       be considered similar although they do not have words in
to other words (i.e., very close to bike, close to pedals, ride,
                                                                       common (functional words are usually not taken into
wheel, but far from duck, eat, etc.). This semantic
                                                                       account). Therefore, the rule is:
information can be established from raw texts, provided that
enough input is available. This is exactly what human                    R2: paragraphs are similar if they contain similar words.
people do: it seems that most of the words we know, we
                                                                       Rules 1* and 2 constitute a circularity, but this can be
learn by reading (Landauer & Dumais, 1997). The reason is
                                                                       solved by a specific mathematical procedure called singular
that most words appear almost only in written form and that
                                                                       value decomposition, which is applied to the occurrence
direct instruction seems to play a limited role. Therefore, we
                                                                       matrix. This is exactly what LSA does. To state it in other
would learn the meaning of words mainly from raw texts,
                                                                       words, LSA is not only based on direct co-occurrence, but
by mentally constructing their meaning through repeated
                                                                       rather on higher-order co-occurrence. Kontostahis &
exposure to appropriate contexts.
                                                                       Pottenger (2002) have shown that these higher-order co-
Relying on direct co-occurrence                                        occurrences do appear in large corpora.
                                                                          LSA consists in reducing the huge dimensionality of
One way to mimic this powerful mechanism would be to                   direct word co-occurrences to its best N dimensions. All
rely on direct co-occurrences within a given context unit. A           words are then represented as N-dimensional vectors.
usual unit is the paragraph which is both computationally              Empirical tests have shown that performance is maximal for
easy to identify and of reasonable size. We would say that:            N around 300 for the whole general English language
R1: words are similar if they occur in the same paragraphs.            (Landauer et al., 1998; Bellegarda, 2000) but this value can
                                                                       be smaller for specific domains (Dumais, 2003). We will
Therefore, we would count the number of occurrences of                 not describe the mathematical procedure which is presented
each word in each paragraph. Suppose we use a 5,000-                   in details elsewhere (Deerwester, 1990; Landauer et
paragraph corpus. Each word would be represented by                    al., 1998). The fact that word meanings are represented as
5,000 values, that is by a 5,000 dimension vector. For                 vectors leads to two consequences. First, it is straight-
instance:                                                              forward to compute the semantic similarity between words,
avalanche: (0,1,0,0,0,0,1,0,2,0,0,0,0,0,0,1,1,0,1,0,1,0,0,0,0,0,0…)    which is usually the cosine between the corresponding
snow:       (0,2,0,0,0,0,0,0,1,1,0,0,0,0,0,0,2,1,1,0,1,0,0,0,0,0,0…)   vectors, although others similarity measures can be used.
                                                                       Examples of semantic similarities between words from a
This means that the word avalanche appears once in the 2nd             12.6 million word corpus are (Landauer, 2002):
paragraph, once in 7th, twice in the 9th, etc. One could see
that, given the previous rule, both words are quite similar:              cosine(doctor, physician) = .61
they co-occur quite often. A simple cosine between the two                cosine(red, orange) = .64
vectors can measure the degree of similarity. However, this            Second, sentences or texts can be assigned a vector, by a
rule does not work well (Perfetti, 1998; Landauer, 2002):              simple weighted linear combination of their word vectors.
two words should be considered similar even if they do not             This is a powerful feature of a semantic representation to be
co-occur. French & Labiouse (2002) think that this rule                able to go easily from words to texts. An example of
might still work for synonyms because writers tend not to              semantic similarity between sentences is:
repeat words, but use synonyms instead. However, defining
semantic similarity only from direct co-occurrence is                      cosine(the cat was lost in the forest, my little feline
probably a serious restriction.                                           disappeared in the trees) = .66
Relying on higher-order co-occurrence                                         Modeling children's semantic memory
Therefore, another rule would be:
                                                                       Semantic space
 R1*: words are similar if they occur in similar paragraphs.           As we mentioned before, our goal was to rely on LSA to
This is a much better rule. Consider the following two                 define a reasonable approximation of children's semantic
paragraphs:                                                            memory. This is a necessary step for simulating a variety of
                                                                       children cognitive processes.
Bicycling is a very pleasant sport. It helps keeping a good               LSA itself obviously cannot form such a model: it needs
health.                                                                to be applied to a corpus. We gathered French texts that
                                                                       approximately correspond to what a child is exposed to:
                                                                   298

stories and tales for children (~1,6 million words), children's       - what is used to feed the body (correct);
productions (~800,000 words), reading textbooks (~400,000             - what can be eaten (close);
words) and children's encyclopedia (~400,000 words). This             - matter which is being spoiled (far);
corpus is composed of 57,878 paragraphs for a total of 3.2            - letter exchange (unrelated).
million word occurrences. All punctuation signs were ruled
                                                                    Participants were asked to select what they thought was the
out, capital letters were transformed to lower cases, dashes
                                                                    correct definition. This task was performed by four groups
were ruled out except when forming a composed word (like
                                                                    of children: 2nd grade, 3rd grade, 4th grade and 5th grade.
tire-bouchon). This corpus was analyzed by means of LSA
                                                                    These data were compared with the cosines between the
and the occurrence matrix reduced to 400 dimensions,
                                                                    given word and each of the four definitions. For instance,
which appears to be an optimal value as we will see later.
                                                                    the four cosines on the previous examples were: .38
The resulting semantic space contains 40,588 different
                                                                    (correct), .24 (close), .16 (far) and .04 (unrelated). 116
words. This step took 15 minutes on a 2.4 Ghz computer
                                                                    questions were used because the semantic space did not
with 2 Gb RAM.
                                                                    contain four rare words.
Tests                                                                 The first measure we used was the percentage of correct
                                                                    answers. Figure 1 displays the results. The percentage of
In order to test whether this semantic space can be an              correct answers is .53 for the model, which is exactly the
acceptable approximation of the semantic memory of                  same value as the 2nd grade children. Except for unrelated
children, we tested three features: its extent, its organization    answers, the model data globally follow the same pattern as
and its use. For each one, we relied on a specific task and         the children's data.
compared the data from the simulation of the task to data
obtained from children on the exact same task.
   The extent feature has to do with the size of lexical                                     75
                                                                                             70
knowledge. Does our semantic space knows the kind of                                         65
                                                                                             60
words that a child knows? We used a vocabulary task for                                      55
that: given a word, the goal is to find the correct definition                               50
from four of them. By comparing the model data with                                          45
                                                                     Percentage of answers
                                                                                             40
children's data at various ages, our goal is to approximately                                35
identify the kind of children we are mimicking.                                              30
                                                                                             25
   The organization feature concerns the way words are                                       20
associated to others in memory. Do we correctly mimic the                                    15
                                                                                             10
semantic neighborhood of words? The task we used for                                          5
testing that feature is an association task :given a word, the                                0
goal is to provide the most associated one. We will compare                                    Correct                Close                          Far              Unrelated
children's association norms to association measures in the                                                                   Definition types
semantic space.
   The use feature has to do with the way semantic memory
is used. Is our semantic space adequate enough so that it can                                 Figure 1: Percentage of answers for different types of
account for a process that uses it? We used a recall task for                                                     definitions
studying the text comprehension process which obviously             In order to compare our semantic spaces with adult semantic
largely relies on semantic representations.                         spaces, we defined a measure which integrates the four
   These three experiments cover different tasks and                values. We used a d measure, which is a normalized
different grain sizes of language entities, from words to           difference between the cosines for correct and close
texts: the first one consists of word comparisons, the second       definitions together and the cosines for far and unrelated
one compares a word and a sentence and the third one                definitions together. The higher this measure, the better the
compares texts. We expect a good match between human                result. Given a word W, four definitions (correct, close, far
data and model data. In addition, we hypothesize that results       and unrelated) and a global standard deviation S, the
will be higher with our children corpus than with adult             formula is the following:
corpora.
                                                                                             cos W , correct      cos W , close               cos W , far  cos W , unrelated 
Experiment 1                                                                                                   2                                                  2
                                                                    d=
The first experiment, which aims at validating the model,                                                                                     S
involves a vocabulary task. The design of the material as           We also compared these results with several adult corpora,
well as the experiments with children were realized by              in order to test whether our semantic space was specific to
Denhière et al. (in preparation). Material consists of 120          children. We used five corpora: a literature corpus,
questions, each one composed of a word and four                     composed of novels from the XIXth and XXth centuries and
definitions: the correct one, a close definition, a far             four corpora from the French daily newspaper Le Monde, of
definition and an unrelated definition. For instance, given         the years 1993, 1995, 1997 and 1999. Table 1 shows the
the word nourriture (food), translations of the four                results.
definitions are:
                                                              299

     Table 1: Comparison between children's semantic space     able to distinguish between the strong and weak associates,
                     and adult semantic spaces                 but can also discriminate the first-ranked from the second-
                                                               ranked and the latter from the third-ranked.
  Semantic space          Size (in    Percentage of     d         Measure of correlation with human data is also significant
                      million words) correct answers           (r(1184 =.39, p<.001). Actually, two factors might have
Children                    3.2            .53         .69     lowered this result. First, although we tried to mimic what a
Literature                 14.1            .38         .52     child has been exposed to, we could not control all word
Le Monde 1993              19.3            .44         .23     frequencies within the corpus. Therefore, some words might
Le Monde 1995              20.6            .37         .21     have occurred with a low frequency in the corpus, leading
Le Monde 1997              24.7            .40         .28     to an inaccurate semantic representation. When the previous
Le Monde 1999              24.2            .34         .25     comparison was performed on the 20% most frequent
                                                               words, the correlation was much higher (r(234 =.57,
In accordance with the previous experiment, the children's     p<.001).
semantic space has the better results, although its size is       The second factor is the participant agreement: when
much smaller. Student tests have shown that the children       most children provide the same answer to an inducing word,
semantic space is significantly different from others          there is a high agreement, which means that both words are
(p < .05) except for the percentage of correct answers when    very strongly associated. However, there are cases when
compared to the Le Monde 1993 corpus (p < .1).                 there is almost no agreement: for instance the three first
                                                               answers to the word bruit (noise) are crier (to shout) (9%),
Experiment 2                                                   entendre (to hear) (7%) and silence (silence) (6%). It is not
This second experiment is based on verbal association          surprising that the model corresponds better to the children
norms published by de La Haye (2003). Two-hundred              data in case of a high agreement, since this denotes a strong
inducing words (144 nouns, 28 verbs and 28 adjectives)         association that should be reflected in the corpus. In order to
were proposed to 9 to 11-year-old children. For each word,     select answers whose agreement was higher, we measured
participants had to provide the first word that came to their  their entropy. The formula is the following:
mind. This resulted in a list of words, ranked by frequency.                                                        1
                                                                entropy item         freq answer  . log                
For instance, given the word cartable (satchel), results are                      answer                      freq  answer 
the following for 9-year-old children:                         A low entropy corresponds to a high agreement and vice
   - école (school): 51%                                       versa. When we selected the 20% items with the lowest
   - sac (bag): 12%                                            entropy, the correlation also raises (r(234)=.48, p<.001).
   - affaires (stuff): 6%                                         All these results show that the association degree between
   ...                                                         words defined by the cosine measure within the semantic
   - classe (class): 1%                                        space seems to correspond quite well to children's
   - sacoche (satchel): 1%                                     judgement of association.
   - vieux (old): 1%                                              We also compared these results with the previous adult
                                                               semantic spaces. Results are presented in Table 3.
This means that 51% of the children answered the word
école (school) when given the word cartable (satchel). The         Table 3: Correlations between participant child data and
two words are therefore strongly associated for 9-year-old                    different kinds of semantic spaces
children. These association values were compared with the
LSA cosine between word vectors: we selected the three              Semantic space         Size (in million   Correlation with
best-ranked words as well as the three worst-ranked (like in                                  words)            child data
the previous example). We then measured the cosines               Children                        3.2                .39
between the inducing word and the best ranked, the 2nd best-      Literature                     14.1                .34
ranked, the 3rd best ranked, and the mean cosine between the      Le Monde 1993                  19.3                .31
inducing word and the three worst-ranked. Results are             Le Monde 1995                  20.6                .26
presented in Table 2.                                             Le Monde 1997                  24.7                .26
                                                                  Le Monde 1999                  24.2                .24
  Table 2: Mean cosine between inducing word and various
           associated words for 9-years-old children           In spite of much larger sizes, all adult semantic spaces
                                                               correlate worse than the children's semantic space with the
   Words                      Mean cosine with inducing word   data of the participants in the study. Statistical tests show
   Best-ranked words                         .26               that all differences between the child model and the other
   2nd best-ranked words                     .23               semantic spaces are significant (p<.03).
   3rd best ranked-words                     .19
   3 worst-ranked words                      .11               Experiment 3
                                                               The third experiment is based on recall or summary tasks.
Student tests show that all differences are significant
                                                               Children were asked to read a text and write out as much as
(p < .03). This means that our semantic space is not only
                                                               they could recall, immediately after reading or after a fixed
                                                           300

delay. We used 7 texts. We tested the ability of the semantic  (Burgess, 1998) is another model of human memory. It is
representations to estimate the amount of knowledge            quite similar to LSA except that it does not rely on a
recalled. This amount is classically estimated by means of a   dimension reduction step. It is currently based on a corpus
propositional analysis: first, the text as well as the         of 300 million words, which is closer to the human inputs
participant production are coded as propositions. Then, the    than PMI-IR, although this could be considered quite
number of text propositions that occur in the production is    overestimated.
calculated. This measure is a good estimate of the
knowledge recalled. Using our semantic memory model,           Further investigations
this is accounted for by the cosine between the vector         Our semantic space provides a means for researchers
representing the text and the vector representing the          studying children's cognitive processes to design and
participant production.                                        simulate computational models on top of these basic
  Table 4 displays all correlations between these two          representations. In particular, computational models of text
measures. They range from .45 to .92, which means that the     comprehension could be tested using the basic semantic
LSA cosine applied to our children's semantic space is a       similarities that the space provides. It would also be possible
good estimate of the knowledge recalled.                       to investigate the development of semantic memory by
                                                               looking at the evolution of various semantic similarities
  Table 4: Correlations between LSA cosines and number         according to the size of the corpus in detail. In particular,
of propositions recalled for different texts.                  Landauer & Dumais (1997) claim that we learn the meaning
                                                               of a word through the exposition to texts that do not contain
    Story             Task           Number of Correlations    it. Our semantic space gives the opportunity to test this
                                    participants               assertion by checking the kind of paragraphs that cause an
  Poule         Immediate recall           52          .45     increase of similarity through incremental exposure to the
  Dragon        Delayed recall             44          .55     corpus.
  Dragon        Summary                    56          .71
  Araignée      Immediate recall           41          .65     Improvements
  Clown         Immediate recall           56          .67     Our semantic space could be improved in many ways. Its
  Clown         Summary                    24          .92     composition (50% stories, 25% production, 12.5% reading
  Ourson        Immediate recall           44          .62     textbooks, 12.5% encyclopedia) is very rough and work has
  Taureau       Delayed recall             23          .69     to be done to better know the amount and nature of texts
  Géant         Summary                   105          .58     that children are exposed to. Several studies led us to think
                                                               that lemmatization could significantly improve the results,
In an experiment with adults, Foltz et al. (1996) have shown   especially for the French language that has so many forms
that LSA measures can be used to predict comprehension.        for some verbs. We did perform the previous experiments
Besides validating our model of semantic memory, this          on a lemmatized version of the corpus (using the Brill
experiment shows that an appropriate semantic space can be     tagger on the French files developed by ATILF, and the
used to assess text comprehension in a much faster way than    Flemm lemmatizer written by Fiametta Namer). Results
propositional analysis, which is a very tedious task.          were worse than with the non-lemmatized version. In order
                                                               to know more about this surprising result, we distinguished
                        Conclusion                             between verbs and nouns. We found that the overall
                                                               decrease is mainly due to a decrease for the nouns. One
A model of the development of children's semantic
                                                               reason could be that the singular and plural forms of a noun
memory
                                                               are not arguments of the same predicates. For instance, the
Our model is not only a computational model of children's      word vague (wave) is generally used in its plural form in the
semantic memory, but of its development. Other                 context of the sea, but more frequently in the singular form
computational models of human memory have been                 in its metaphorical meaning (a wave of success). Therefore,
developed but some of them are based on inputs that do not     if both forms are grouped into the same one, this affects the
correspond to what humans are exposed to. They are good        co-occurrence relations and modifies the semantic
models of the memory itself, but not of the way it is          representations.
mentally constructed. In order to be cognitively plausible,       Another way of improvement would have to deal with
models of the construction of semantic memory need to be       syntax. LSA does not take any syntactic information into
approximately based on the kind of input to humans.            account: all paragraphs are just bags of words. A slight
  LSA is such model. Its performance is similar to those of    improvement would consist in considering a more precise
human people. It needs an input of a few million words,        unit of context than a whole paragraph. A sliding context
which is comparable to what humans are exposed to              window (like in the HAL model for instance) would take
(Landauer & Dumais, 1997). On the contrary, PMI-IR             into account the local context of each word. This might
(Turney, 2001) is a good model of semantic similarities,       improve the semantic representations, while being
even better than LSA in modeling human judgement of            cognitively more plausible. We are working in that
synonymy, but it is based on an input of thousands of          direction.
millions of words, since it relies on all the texts published
on the web. This is of course cognitively unplausible. HAL
                                                           301

For the moment, our model is an estimation. We cannot           Laham, D. (1997). Latent Semantic Analysis approaches to
precisely identify to which age it corresponds. Our goal is to    categorization. In M. G. Shafto & P. Langley (Eds.),
stratify it so that we would have a model for each age.           Proceedings of the 19th annual meeting of the Cognitive
Developmental models would then be able to be simulated.          Science Society (p. 979). Mawhwah, NJ: Erlbaum.
                                                                Landauer, T. K. & Dumais, S. T. (1997). A solution to
                   Acknowledgements                               Plato's problem : the Latent Semantic Analysis theory of
This work was done while the second author was in                 acquisition, induction and representation of knowledge.
sabbatical at the university of Aix-Marseille. We would like      Psychological Review, 104, 211-240.
to thank D. Chesnet, E. Lambert and M.-A. Schelstraete, for     Landauer, T. K., Foltz, P. W. & Laham, D. (1998). An
providing us with parts of the corpus, F. de la Haye for the      introduction to Latent Semantic Analysis. Discourse
association data as well as M. Bourguet and H. Thomas for         Processes , 25, 259-284.
the design of the vocabulary test. We also thank P. Dessus      Landauer (2002). On the computational basis of learning
and E. de Vries for their comments on a previous version.         and cognition: Arguments from LSA. In N. Ross (Ed.),
                                                                  The psychology of Learning and Motivation, 41, 43-84.
                         References                             Lemaire, B & Dessus, P. (2001). A system to assess the
Bellegarda, J. (2000) Exploiting Latent Semantic                  semantic content of student essay. Journal of Educational
   Information in statistical language modeling. Proceedings      Computing Research, 24-3, 305-320.
   of IEEE, 88 (8), 1279-1296.                                  Lemaire, B. & Bianco, M. (2003). Contextual effects on
Bellissens, C., Thiesbonenkamp, J. & Denhière, G. (2002).         metaphor comprehension: experiment and simulation.
   Property attribution in metaphor comprehension:                Proc. of the 5th International Conference on Cognitive
   simulations of topic and vehicle contribution within the       Modeling (ICCM'2003), Bamberg, Germany.
   LSA-CI framework. Twelfth Annual Meeting of the              Lenat, D.B. (1995). CYC: A large-scale investment in
   Society for Text and Discourse, June 2002.                     knowledge infrastructure. Comm. of the ACM, 11, 32-38.
Borgida, A. (1996). On the relative expressive power of         Pariollaud, F., Denhière, D. & Verstiggel, J.C. (2002)
   description logics and predicate calculus, Artificial          Comprehension of idiomatic expressions: effect of
   Intelligence, 82, 353-367.                                     meaning salience. Proc. of the 9th Int. Conference on
Burgess, C. (1998). From simple associations to the               Information Processing and Management of Uncertainty
   building blocks of language: modeling meaning in               in Knowledge-Based Systems (IPMU), Annecy, July 1-5.
   memory with the HAL model. Behavior Research                 Perfetti, C. A. (1998). The limits of co-occurrence: tools
   Methods, Instruments, & Computers, 30, 188-198.                and theories in language research. Discourse Processes,
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T.        25, 363-377.
   K. & Harshman, R. (1990). Indexing by Latent Semantic        Quesada, J., Kintsch, W., & Gomez E. (2002) A theory of
   Indexing. Journal of the American Society for                  complex problem solving using Latent Semantic
   Information Science , 41-6, 391-407.                           Analysis. In W. D. Gray & C. D. Schunn (Eds.)
de la Haye, F. (2003). Normes d'associations verbales chez        Proceedings of the 24th Annual Conference of the
   des enfants de 9, 10 et 11 ans et des adultes. L'Année         Cognitive Science Society. Lawrence Erlbaum Associates,
   Psychologique, 103, 109-130.                                   Mahwah, NJ.
Dumais, S. D. (2003). Data-driven approaches to                 Rehder, B., Schreiner, M. E., Wolfe, M. B. W., Laham, D.,
   information access. Cognitive Science 27 (3), 491-524.         Landauer, T. K. & Kintsch, W. (1998). Using Latent
Foltz, P. W. (1996). Latent Semantic Analysis for text-           Semantic Analysis to assess knowledge: some technical
   based research. Behavior Research Methods, Instruments         considerations. Discourse Processes, 25, 337-354.
   and Computers, 28-2, 197-202.                                Sowa, J.F. (1991). Principles of Semantic Networks:
French, R.M. & Labiouse, C (2002). Four problems with             Exploration in the Representation of Knowledge, Morgan
   extracting human semantics from large text corpora.            Kaufmann.
   Proceedings of the 24th Annual Conference of the             Turney, P. (2001). Mining the Web for synonyms: PMI-IR
   Cognitive Science Society, NJ:LEA.                             versus LSA on TOEFL. In De Raedt, L. and Flach, P.,
Howard, M.W. & Kahanna, M.J. (2002). When does                    (Eds). Proceedings of the 12th European Conference on
   semantic similarity help episodic retrieval? Journal of        Machine Learning (ECML-2001) , 491-502, Freiburg.
   Memory and Language 46, 85-98.                               Vossen, P. (2003). Ontologies. In R. Mitkov (Ed.) The
Kintsch, W. (1988). The role of knowledge in discourse            Oxford Handboof of Computational Linguistics. Oxford,
   comprehension: a construction-integration model.               464-482.
   Psychological Review, 95, 163-182.                           Wolfe, M. B. W., Schreiner, M. E., Rehder, B., Laham, D.,
Kintsch, W. (2000). Metaphor comprehension: a                     Foltz, P. W., Kintsch & W., Landauer, T. K. (1998).
   computational theory. Psychonomic Bulletin & Review, 7-        Learning from text: matching readers and texts by Latent
   2, 257-266.                                                    Semantic Analysis. Discourse Processes, 25, 309-336.
Kontostathis, A. & Pottenger, W.M. (2002). Detecting            Wolfe, M.B.W. & Goldman, S.R. (2003) Use of Latent
   patterns in the LSI term-term matrix. Workshop on the          Semantic Analysis for predicting psychological
   Foundation of Data Mining and Discovery, IEEE                  phenomena: two issues and proposed solutions. Behavior
   International Conference on Data Mining.                       Research Methods Instruments & Computer, 35(1), 22-
                                                                  31.
                                                            302

