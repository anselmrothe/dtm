UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Natural Input Memory Model
Permalink
https://escholarship.org/uc/item/2cd6x26h
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Lacroix, Joyca P.W.
Murre, Jaap M.J.
Postma, Eric O.
et al.
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                           The Natural Input Memory Model
                                            Joyca P.W. Lacroix (j.lacroix@cs.unimaas.nl)
  Department of Computer Science, IKAT, Universiteit Maastricht, St. Jacobsstraat 6, 6211 LB Maastricht, The Netherlands
                                                 Jaap M.J. Murre (jaap@murre.com)
        Department of Psychology, Universiteit van Amsterdam, Roeterstraat 15, 1018 WB Amsterdam, The Netherlands
                                              Eric O. Postma (postma@cs.unimaas.nl)
                                           H. Jaap van den Herik (herik@cs.unimaas.nl)
  Department of Computer Science, IKAT, Universiteit Maastricht, St. Jacobsstraat 6, 6211 LB Maastricht, The Netherlands
                              Abstract                                   recognition-memory studies. Finally our main conclusion
                                                                         will be given.
   A new recognition memory model is proposed which differs
   from the existing memory models in that it operates on natural                             The N IM Model
   input. Therefore it is called the natural input memory (N IM)
   model. A biologically-informed perceptual pre-processing              The N IM model encompasses the following two stages.
   method takes local samples from a natural image and translates       1. A perceptual pre-processing stage that translates a natural
   these into a feature-vector representation. The feature-vector           image into a number of feature vectors.
   representations reside in a similarity space in which perceptual
   similarity corresponds to proximity. By using the similarity         2. A memory stage comprising two processes:
   structure of natural input, the model by-passes assumptions
   about distributional statistics of real-world input. Our sim-          (a) a storage process that simply stores feature vectors;
   ulations on the list-strength effect, the list-length effect, and      (b) a recognition process that compares feature vectors of
   the false memory effect support the validity of the proposed
   model. In particular, we conducted a face recognition simula-              the image to be recognized with previously stored fea-
   tion with the N IM model and found that it is able to replicate            ture vectors.
   well-established recognition memory effects that relate to the
   similarity of the input.
                  Memory Representation
Many computational memory models represent an item by a
vector of abstract features (e.g., the S AM model, Raaijmakers
& Shiffrin, 1981; the R EM model, Shiffrin & Steyvers, 1997,
the model of differentiation, McClelland & Chappell, 1998).
The feature values are usually drawn from a mathematical
distribution (e.g., a geometric distribution). Since the com-                  Figure 1: The natural input memory (N IM) model.
putational models artificially generate vector representations,
they do not address the contribution of the similarity struc-
ture intrinsic to natural data. However, we believe that the             Figure 1 presents a schematic diagram of the N IM model.
similarity structure contains important information. There-              The face image is an example of a natural image. The two
fore, we propose a memory model that operates on natural                 boxes correspond to the perceptual pre-processing stage and
data and represents the similarity structure of these data.              the memory stage.
   The similarity structure of natural data can be represented           The Perceptual Pre-Processing Stage
in any type of space that fulfills the compactness criterion             In this section, we first provide some background on the
(Arkadev & Braverman, 1966). This criterion is fulfilled                 sources of biological inspiration and on the computational
when similar objects in the real world are close in their rep-           considerations. Then, we discuss some relevant implemen-
resentations. Several researchers developed so called ‘simi-             tation details.
larity spaces’, in which representations of similar items are in
close proximity of each other (e.g., Nosofsky, 1986; Steyvers,           Biological Inspiration and Computational Considerations
Shiffrin, & Nelson, in press). An analysis of human similarity           The human visual system is our main source of biological
judgments or of free association data often forms the basis of           inspiration. The eye sequentially fixates on those parts of a
a similarity space. However, we propose to derive the similar-           visual scene that are most informative for recognition (e.g.,
ity space from the natural data by employing a biologically-             Yarbus, 1967). Early visual processing in the brain leads to
informed transformation.                                                 the activation of millions of optic nerve cells (Palmer, 1999).
   In the next section, a new recognition memory model that              The nerve-cell activations may be conceived as a high di-
operates on natural images is introduced and described. We               mensional vector. The high dimensionality enables the rep-
call this model the natural input memory (N IM) model. We                resentation of a large amount of information without suffer-
will conduct a face recognition simulation with the N IM                 ing from interference (Rao & Ballard, 1995), but it also ham-
model and will evaluate its ability to replicate findings from           pers the memory performance, as the number of examples
                                                                     773

that is necessary for a reliable generalization performance         selected at a fixation point and the 16 × 49 pixel values are
grows exponentially with the number of dimensions. This             placed in a vector. In addition, the pixel values of a 7 × 7
phenomenon is known as the ‘curse of dimensionality’ (Bell-         low-resolution subimage centered at the fixation point are ap-
man, 1961; Edelman & Intrator, 1997). In coping with the            pended to the vector. Fixation points are randomly drawn
curse of dimensionality, subsequent stages in the visual sys-       from the contours of the face. The result is a feature vector
tem are assumed to reduce the dimensionality of the high-           for each fixation. As mentioned before, a principal compo-
dimensional input (e.g., Hubel, 1988; Tenenbaum, Silva, &           nent analysis was used to reduce the dimensionality of the
Langford, 2000). The assumption is supported by findings            feature vectors by taking the projection onto the first p basis
of Edelman and Intrator (1997), who showed that the human           vectors.
visual system is able to retrieve the intrinsic low-dimensional
structure of the high-dimensional visual input.                     The Memory Stage
   In the N IM model, dimension reduction of high-                  The Storage Process In the N IM model, the storage pro-
dimensional natural input is achieved in two sequential steps:      cess straightforwardly stores an item (i.e., a pre-processed
(1) a biologically-informed feature-vector extraction (Free-        natural image). A pre-processed natural image is represented
man & Adelson, 1991) followed by (2) a principal compo-             by a number of low-dimensional feature vectors in the simi-
nent analysis (Pearson, 1901). The feature-vector extraction        larity space, each corresponding to an eye fixation. The stor-
method employed by the N IM model operates directly on a            age strength, S, is defined as the number of feature vectors
high-dimensional natural image. The image has a high di-            stored for an image.
mensionality because it is treated as a vector, the elements of
which are the constituent pixel values. Motivated by eye fixa-      The Recognition Process In the N IM model, the recog-
tions in human vision, the feature-vector extraction method         nition process determines the familiarity of an image to
takes samples from randomly-selected locations along the            be recognized by comparing feature vectors of the image
contours in the image. To emphasize the parallel with hu-           to be recognized with previously stored feature vectors.
man vision, we refer to the samples as ‘fixations’. For each        Models with a recognition process based on comparing
fixation, the NIM model extracts features (i.e, a feature vec-      items to previously stored exemplars can provide an accurate
tor) from the image area centered at the fixation location.         quantitative account of recognition performance (Medin &
Since the feature vector contains a limited number of fea-          Schaffer, 1978; Nosofsky, 1986; Nosofsky, Clark, & Shin,
tures, it is of a much lower dimensionality than the image.         1989). In the N IM model, the recognition process uses a
The feature-vector extraction method is based on the visual         nearest neighbor classifier method, which takes each feature
processing generally believed to occur in the visual area V1.       vector of the image to be recognized and then determines
The responses of neurons in V1 are modeled by a multi-              the number of previously stored feature vectors, f , that fall
scale wavelet decomposition (described later). Several stud-        within a hypersphere with radius r, centered around the
ies showed that the biologically-informed multi-scale wavelet       feature vector of the image. The familiarity, F, of the image
decomposition results in a representation space that accu-          is defined as ∑ fi /T , with fi the value of f for the ith feature
rately represents similarities as perceived by humans (e.g.,        vector of the image, and T the total number of feature vectors
Kalocsai, Zhao, & Biederman, 1998; Lyons & Akamatsu,                of the image.
1998; Bartlett, Littleworth, Braathen, Sejnowski, & Movel-
lan, 2003). After extraction of feature vectors, principal com-        We expect that the similarity-space representations em-
ponent analysis represents the feature vectors by their projec-     ployed by the N IM model will deepen our understanding of
tion onto a number of orthogonal basis vectors which are or-        human recognition memory. Moreover, they may effectively
dered according to the amount of variance they explain. The         support a number of memory effects often obtained in recog-
dimensionality of the feature vectors is reduced by taking the      nition memory studies. The latter studies are described in the
projection onto the first p basis vectors. The low-dimensional      next section.
feature vectors reside in a similarity space where visual sim-
ilarity translates to proximity of feature vectors. Translating             Human Recognition Memory Studies
a two-dimensional image using a multi-scale wavelet decom-          Three recognition memory effects often found in recognition
position followed by a principal component analysis, is an          memory studies are: the list-strength effect, the list-length
often applied method in the domain of visual object recogni-        effect, and the false memory effect. In general, recognition
tion to model the first three stages of processing of informa-      memory studies provide subjects with a study list of items
tion in the human visual system (i.e., retina/LGN, V1/V2,           and test their recognition memory for (some of) the studied
V4/LOC; Palmeri & Gauthier, 2004). In contrast, existing            items (i.e., targets) and a number of non-studied items (i.e.,
memory models lack such a pre-processing method and often           lures). We will emphasize the relation between the similarity
make simplifying assumptions about object representations.          structure of the targets and the lures used in the experiments
                                                                    on the one hand and the memory effects on the other hand.
Implementation The input image is translated into a multi-
scale representation at four spatial scales. At every scale,        The List-Strength Effect
the image is processed by four oriented filters in the orien-       A list-strength effect is defined as: a decrease in memory per-
tations 0◦ , 45◦ , 90◦ , and 105◦ using the steerable-pyramid       formance for a given set of study list items when other items
transform (Freeman & Adelson, 1991). This processing re-            of the study list are ”strengthened” (i.e., the amount of time or
sults in sixteen (four scales times four orientations) filtered     the number of times the items are studied is increased) (Rat-
images. From each of the sixteen images a 7 × 7 window is           cliff, Clark, & Shiffrin, 1990). While some researchers failed
                                                                774

to find a list-strength effect for recognition memory (e.g., Rat-      similarity between targets and lures on the list-strength ef-
cliff et al., 1990), recent findings showed that a list-strength       fect, (2) the effect of the similarity between targets and lures
effect can be obtained when there is a high degree of similar-         on the list-length effect, and (3) the false memory effect. The
ity between targets and lures. Norman (2002) tested whether            N IM model was repeatedly provided with a study list of face
strengthening some words of the study list affected a sub-             images and tested for recognition of the studied images (i.e.,
ject’s recognition performance for other (non-strengthened)            targets) and a number of non-studied images (i.e., lures). The
studied words. In the experiments, a significant list-strength         images were gray-scale images of human faces taken from the
effect was obtained only when targets and lures were sim-              F ERET database (Phillips, Wechsler, Huang, & Rauss, 1998)
ilar. For dissimilar targets and lures, no list-strength effect        of facial images. Male and female Caucasian faces without
was found. Moreover, recognition scores were significantly             beards or glasses were selected. An example of such an image
higher for dissimilar targets and lures than for similar targets       is shown on the left hand side of Figure 1. In this simulation,
and lures.                                                             recognition memory was tested in two different conditions:
                                                                       (1) the dissimilar condition that employed lures dissimilar
The List-Length Effect                                                 from the targets, and (2) the similar condition, that employed
A list-length effect is defined as: a decrease in memory per-          lures similar to one of the targets. In the N IM model, simi-
formance for the items of the study list when additional items         lar images are separated by a small distance in the similarity
are added to the study list (Ratcliff et al., 1990). List-length       space. List-strength effects and list-length effects were as-
studies yielded contradictory results. While some researchers          sessed in both conditions and compared to determine whether
failed to find a list-length effect (e.g., Dennis & Humphreys,         the similarity between targets and lures had affected the de-
2001), others did obtain it (e.g., Cary & Reder, 2003). Re-            gree to which the list effects occurred. Moreover, a compari-
cent experimental results indicate that the similarity between         son of the recognition results in the dissimilar condition and
targets and lures can affect the degree to which a list-length         the similar condition revealed whether a false memory effect
effect occurs (MacAndrew, Klatzky, Fiez, McClelland, &                 had occurred. Below we describe the calculation of recogni-
Becker, 2002). In a study examining the effect of phono-               tion scores, the paradigms, the conditions, the procedure, and
logical similarity on recognition memory, MacAndrew et al.             the results.
(2002) tested subjects’ recognition memory for letters on a
study list of four or six letters. The results showed that a           Calculation of Recognition Scores
larger list-length effect occurred for similar targets and lures       The familiarity values, F, were used in a signal detection
than for dissimilar targets and lures. Also, overall recogni-          analysis to determine the recognition scores. The appropri-
tion scores were higher for dissimilar targets and lures than          ate measure for the recognition score (da ) was based on the
for similar targets and lures.                                         normalized difference between the average F values of the
                                                                       targets (F(IT )) and the average F values of the lures (F(IL )):
The False Memory Effect
A number of experimental studies showed a false memory                                              F(IT ) − F(IL )
                                                                                             da = r
effect, which holds that the recognition of a lure (i.e., a                                           σ2[F(I )] +σ2[F(I )]
false memory or a false alarm) is more likely to happen                                                     T          L
                                                                                                                2
when the lure is similar to (one of the) studied items (e.g.,
Postman, 1951; Dewhurst & Farrand, 2004). For instance,                (Simpson & Fitter, 1973). Each da value was calculated on
the results by Dewhurst and Farrand (2004) show that                   the basis of the familiarity values for targets (F(IT )) and the
the number of false memories increases together with the               familiarity values for lures (F(IL )) of ten recognition tests.
number of targets on the study list that are similar to the lures.
                                                                       Paradigms
   In a similarity space, representations of similar targets and       The List-Strength Effect We used the mixed-pure
lures show more overlap than representations of dissimilar             paradigm first proposed by Ratcliff et al. (1990). It is used
targets and lures. Similar targets and lures are thus more dif-        in many list-strength studies. The mixed-pure paradigm em-
ficult to discriminate than dissimilar targets and lures. There-       ploys three types of study lists: pure weak lists (N weak im-
fore, we expect that list-strength effects and list-length effects     ages), pure strong lists (N strong images), and mixed lists
will be more pronounced and there will be more false alarms            (N/2 strong and N/2 weak images). A list-strength effect is
when targets and lures are similar than when targets and lures         said to occur (1) when the recognition score for weak images
are dissimilar.                                                        on a pure list is higher than the recognition score for weak
   We hypothesize that the similarity structure of the per-            images on a mixed list or, (2) when the recognition score for
ceived targets and lures can give rise to the recognition-             strong images on a mixed list is higher than the recognition
memory effects discussed above. To test this hypothesis, we            score for strong images on a pure list. The pure/mixed ratio
conducted a face recognition simulation with the N IM model,           for weak images (i.e., the recognition score for weak images
which employs similarity-space representations of perceived            on a pure list divided by the recognition score for weak im-
natural images.                                                        ages on a mixed list) thus is an indication for the degree to
                                                                       which a list-strength effect occurs for weak images. Like-
                           Simulation                                  wise, the mixed/pure ratio for strong images is an indication
In our simulation, we investigated the ability of the N IM             for the degree to which a list-strength effect occurs for strong
model to produce the following effects: (1) the effect of the          images.
                                                                   775

The List-Length Effect A list-length effect is said to oc-
cur when the recognition score for images on a shorter list
is higher than the recognition score for images on a longer
list. To assess the occurrence of a list-length effect we com-
pared recognition scores for images on study lists of different
lengths.
The False Memory Effect A higher false alarm rate (to-                (a)                              (b)
gether with no difference in the hit rate) for the similar condi-
tion than for the dissimilar condition is said to indicate the        Figure 2: (a) Norman’s (2002) results, and (b) Recognition
occurrence of a false memory effect. However, using the               scores (da ) for weak images on pure lists (black bars) and on
general performance measure da (as described in the pre-              mixed lists (white bars) of length N = 12 for the dissimilar
vious subsection) to determine recognition scores, the N IM           condition and for the similar condition.
model produces no false memories (and thus no false memory
effect), simply because no recognition decisions are made.
Most computational memory models, however, make recog-                recognition. Lures in the dissimilar condition were selected
nition decisions based on the comparison of an obtained fa-           with dissimilarity constant d1 = 0.26 and lures in the simi-
miliarity value to a given criterion (e.g., Busey, 2001). When        lar condition were selected with similarity constant d2 = 0.8.
the familiarity value exceeds the criterion, the item is rec-         Recognition tests and the selection of targets and lures were
ognized, if not, the item is not recognized. To assess the            performed using the radius parameter r = 5.0.
false memory effect, we also applied a decision criterion to
the familiarity values, F, obtained for the dissimilar condi-
                                                                      Results
tion and for the similar condition. As a criterion we used:
C = S × (0.02 + N/500), with S the storage strength of the            Table 1 presents the results for the dissimilar and similar con-
images, and N the number of images on the study list.                 ditions, respectively. The rows show the recognition results
                                                                      for lists of lengths N = 4, 8, and 12. The columns labeled
Conditions                                                            w show the recognition scores for the weak images and the
We distinguished two conditions: the dissimilar and the sim-          columns labeled s show the recognition scores for the strong
ilar condition. For the dissimilar condition, recognition per-        images. The columns labeled pw/mw show the pure/mixed
formance for targets versus dissimilar lures was tested. Tar-         ratio for weak images and the columns labeled ms/ps show
gets and lures were selected from a subset of dissimilar im-          the mixed/pure ratio for strong images (both of which are
ages. The images in the subset of dissimilar images were              indications of the degree to which a list-strength effect oc-
selected in such a way that the clusters of their feature vec-        curred). Figure 2(a) presents a bar graph of the results re-
tors in the similarity space showed relatively little overlap.
Hence, dissimilarity for a subset of images, D, is defined as:
∑ fB,Ai /TA ≤ d1 , ∀A, B ∈ D, with fB,Ai the number of feature        Table 1: The average recognition scores produced by the N IM
vectors of image B that fall within a hypersphere with radius r       model for the dissimilar and the similar condition.
centered around the ith feature vector of image A, TA the total
number of feature vectors of image A, and d1 a dissimilarity                                 Dissimilar condition
constant. For the similar condition, recognition performance                      Pure lists     Mixed Lists            ratios
for targets versus similar lures was tested. Pairs of similar              N      w       s       w        s     pw/mw ms/ps
targets and lures were selected in such a way that the clusters             4    1.81 2.39 1.78 2.41               1.01        1.01
of their feature-vector representations in the similarity space             8    1.65 2.18 1.54 2.28               1.07        1.05
showed relatively much overlap. Hence, similarity for two
                                                                           12    1.59 2.11 1.48 2.15               1.07        1.02
images, A and B, is defined as: ∑ fB,Ai /TA ≥ d2 , with fB,Ai the
number of feature vectors of image B that fall within a hyper-                                Similar condition
sphere with radius r centered around the ith feature vector of                    Pure lists     Mixed Lists            ratios
image A, TA the total number of feature vectors of image A,                N      w       s       w        s     pw/mw ms/ps
and d2 a similarity constant, with d2 > d1 .                                4    1.38 1.83 1.14 1.97               1.21        1.08
                                                                            8    1.12 1.52 0.87 1.78               1.29        1.17
Procedure                                                                  12    0.98 1.35 0.73 1.61               1.36        1.20
We provided the N IM model with (1) pure weak study lists,
(2) pure strong study lists, and (3) mixed study lists of lengths
N = 4, 8, and 12, in both the dissimilar and the similar con-         ported by Norman (2002) (described previously). Figure 2(b)
dition. Weak images were stored with storage strength S = 5           presents a bar graph of the recognition scores produced by the
(i.e., five feature vectors were stored, corresponding to five        N IM model in conditions analogous to the conditions in Nor-
fixations) and strong images were stored with storage strength        man’s experiment. Since results were similar for lists of dif-
S = 10. For each feature vector, the first p = 50 dimensions          ferent lengths N, only the results for lists of length N = 12 are
were stored. After the last image of a study list had been pre-       shown. A comparison of the graphs in Figures 2(a) and 2(b)
sented to the model, the N images of the study list (i.e., tar-       reveals a close correspondence between Norman’s results and
gets) along with N new images (i.e., lures) were presented for        the results produced by the N IM model.
                                                                  776

Similarity and the List-Strength Effect List-strength ef-             model, Shiffrin & Steyvers, 1997), with predefined similar-
fects for the dissimilar condition were significantly smaller         ity spaces (e.g., the SimSample model, Busey, 2001), or with
than list-strength effects for the similar condition as indicated     synthesized natural images (Kahana & Sekuler, 2002). The
by the higher pw/mw and ms/mw values for the similar con-             predictions these models make for recognition memory per-
dition compared to those for the dissimilar condition. This           formance can be similar to the predictions the N IM model
was supported in a two-way analysis of variance (A NOVA) by           makes, provided that a representation space is employed that
the interaction between list type (pure or mixed) and condi-          accurately reflects the similarity structure of the input. How-
tion. Calculated F values for lists of lengths N = 4, 8, and 12       ever, these models fall short in constructing a representation
ranged from F(1, 159) = 4.97 to F(1, 159) = 9.62, p < 0.05            in an a priori manner. In contrast, the N IM model remedies
for weak images and F(1, 159) = 4.52 to F(1, 159) = 12.02,            this. Therefore, we expect that the N IM model provides us
p < 0.05, for strong images.                                          with a useful tool for making predictions about the effects of
                                                                      varying similarity of natural input on memory.
Similarity and the List-Length Effect The list-length ef-
fects for the dissimilar condition were significantly smaller         Single versus dual-process models Several memory mod-
than those for the similar condition. This was indicated in a         els assume two processes for recognition to explain recog-
two-way A NOVA by the interaction between list length and             nition results. These dual-processing models assume that
condition for pure weak lists, F(2,239) = 4.61, p < 0.05, and         recognition involves (1) a familiarity process, i.e., a context
for pure strong lists, F(2,239) = 3.68, p < 0.05.                     insensitive automatic process, and (2) a recollection process,
The False Memory Effect Table 2 presents the hit rates and            i.e., a context sensitive strategic process (see Yonelinas, 2002,
false alarm rates for pure strong lists of lengths N = 4, 8, and      for a review of dual-processing models). Norman (2002) ex-
12 for both the dissimilar and the similar condition. Since           plains his experimental findings on the similarity effect by
the results were similar for pure weak lists and pure strong          a dual-processing approach. He argues that the degree to
lists, we only present the results for pure strong lists. The         which a list-strength effect occurs depends on the extent to
                                                                      which recollection drives recognition. While there might be
                                                                      good biological evidence that more than one process is in-
Table 2: The average hit rates and false alarm rates produced         volved in recognition, our results show that a single straight-
by the N IM model for the dissimilar and the similar condition.       forward process for recognition suffices to produce Norman’s
                                                                      and other findings on recognition memory.
             Dissimilar condition        Similar condition
                                                                      Mirror Effects
       N     Hit rate   F/A rate         Hit rate F/A rate
                                                                      In addition to the list-strength effect and the list-length ef-
       4      0.84         0.01            0.86       0.14            fect, memory models are often tested for two related effects
       8      0.76         0.02            0.78       0.17            consistently obtained in experimental studies: the strength-
       12     0.69         0.02            0.70       0.15            mirror effect and the length-mirror effect (e.g., Murnane
                                                                      & Shiffrin, 1991). Simulation results, reported elsewhere
                                                                      (Lacroix, Murre, Postma, & Herik, submitted), showed that
results show that a false memory occurred: false alarm rates          the N IM model exhibits these effects.
were higher for lists in the similar condition than for lists in
the dissimilar condition (while hit rates were not significantly                                Conclusion
different). In an A NOVA, calculated F values for the false           We have seen that the N IM model is able to build a similar-
alarm rates ranged from 163.38 to 384.74, p < 0.05, while F           ity space from perceived natural data. Moreover, it success-
values for the hit rates ranged from 2.08 to 2.24, p > 0.05.          fully replicated recognition findings on list-strength effects,
                                                                      list-length effects, false memory effects, and mirror effects.
                          Discussion                                  Though it is at present not clear to what extent these results
Based on recent experimental findings (Norman, 2002), we              emerge from the use of natural images, it does increase the
assumed that the degree to which a list-strength effect and a         validity of the model by by-passing assumptions about dis-
list-length effect occur varies with the degree of similarity be-     tributional statistics of real-world perceptual features. Future
tween targets and lures. The N IM model produces this effect,         studies aim at extending the N IM model to simulate a wider
as well as a false memory effect. Below we discuss the single-        variety of findings on recognition memory.
process N IM model in relation to other memory models and
the ability of the N IM model to simulate mirror effects.                                  Acknowledgments
                                                                      The research project is supported in the framework of the
Comparison to Other Models                                            NWO Cognition Program with financial aid from the Nether-
                                                                      lands Organization for Scientific Research (NWO). It is part
The N IM model differs from existing memory models in that            of the larger project: ’Events in memory and environment:
it operates on natural input and employs a single process for         modeling and experimentation in humans and robots’ (project
recognition.                                                          number: 051.02.2002).
A Perceptual Process Operating on Natural Input The
N IM model encompasses a transformation that yields the sim-                                     References
ilarity structure of natural images. So far, existing memory          Arkadev, A. G., & Braverman, E. M. (1966). Computers and
models have been tested with artificial data (e.g., the R EM             pattern recognition. Washington, DC: Thompson.
                                                                  777

Bartlett, M. S., Littleworth, G., Braathen, B., Sejnowski, T. J.,     Norman, K. A. (2002). Differential effects of list strength
  & Movellan, J. R. (2003). A prototype for automatic                   on recollection and familiarity. Journal of Experimental
  recognition of spontaneous facial actions. In S. Becker &             Psychology: Learning, Memory and Cognition, 28, 1083-
  K. Obermayer (Eds.), Advances in neural information pro-              1094.
  cessing systems (Vol. 15). Cambridge, MA: The MIT Press.            Nosofsky, R. M. (1986). Attention, similarity, and the
Bellman, R. (1961). Adaptive control processes: a guided                identification-categorization relationship. Journal of Ex-
  tour. Princeton, NJ: Princeton University Press.                      perimental Psychology: General, 115, 39-57.
Busey, T. (2001). Formal models of familiarity and memora-            Nosofsky, R. M., Clark, S. E., & Shin, H. J. (1989). Rules
  bility in face recognition. In M. Wenger & J. Townsend                and exemplars in categorization, identification, and recog-
  (Eds.), Computational, geometric, and process perspec-                nition. Journal of Experimental Psychology: Learning,
  tives on facial cognition: Contexts and challenges. Hills-            Memory and Cognition, 15, 282-304.
  dale, NJ: Erlbaum Associates.                                       Palmer, S. E. (1999). Vision science: Photons to phenomenol-
Cary, M., & Reder, L. M. (2003). A dual-process account of              ogy. Cambridge, MA: The MIT Press.
  the list-length and strength-based mirror effects in recogni-       Palmeri, T. J., & Gauthier, I. (2004). Visual object under-
  tion. Journal of Memory and Language, 49, 231-248.                    standing. Nature Reviews Neuroscience, 5, 291-303.
Dennis, S., & Humphreys, M. S. (2001). A context noise                Pearson, K. (1901). On lines and planes of closest fit to
  model of episodic word recognition. Psychological Review,             systems of points is space. The London, Edinburgh and
  108, 452-478.                                                         Dublin Philosophical Magazine and Journal of Science, 2,
Dewhurst, S. A., & Farrand, P. (2004). Investigating the phe-           559-572.
  nomenological characteristics of false recognition for cate-        Phillips, P. J., Wechsler, H., Huang, J., & Rauss, P. (1998).
  gorised words. European Journal of Cognitive Psychology,              The F ERET database and evaluation procedure for face
  16, 403-416.                                                          recognition algorithms. Image and Vision Computing Jour-
Edelman, S., & Intrator, N. (1997). Learning as extrac-                 nal, 16, 295-306.
  tion of low-dimensional representations. In R. Goldstone,           Postman, L. (1951). The generalization gradient in recog-
  D. Medin, & P. Schyns (Eds.), Mechanisms of perceptual                nition memory. Journal of Experimental Psychology, 42,
  learning (Vol. 36, pp. 353-380). San Diego, CA: Academic              231-235.
  press.                                                              Raaijmakers, J. G. W., & Shiffrin, R. M. (1981). Search of
Freeman, W. T., & Adelson, E. H. (1991). The design and                 associative memory. Psychological Review, 88, 93-134.
  use of steerable filters. IEEE Trans. Pattern Analysis and          Rao, R. P. N., & Ballard, D. H. (1995). An active vision
  Machine Intelligence, 13, 891-906.                                    architecture based on iconic representations. Artificial In-
Hubel, D. H. (1988). Eye, brain, and vision. New York, NY:              telligence, 461-505.
  WH Freeman.                                                         Ratcliff, R., Clark, S. E., & Shiffrin, R. M. (1990). The
Kahana, M. J., & Sekuler, R. (2002). Recognizing spatial                list-strength effect: I. data and discussion. Journal of Ex-
  patterns: A noisy exemplar approach. Vision Research, 42,             perimental Psychology: Learning, Memory and Cognition,
  2177-2192.                                                            16, 163-178.
Kalocsai, P., Zhao, W., & Biederman, I. (1998). Face similar-
                                                                      Shiffrin, R. M., & Steyvers, M. (1997). A model for recog-
  ity space as perceived by humans and artificial systems. In
                                                                        nition memory: Rem: Retrieving effectively from memory.
  Proceedings, third international conference on automatic
                                                                        Psychonomic Bulletin & Review, 4, 145-166.
  face and gesture recognition (pp. 177-180). Nara Japan.
                                                                      Simpson, A. J., & Fitter, M. J. (1973). What is the best index
Lacroix, J. P. W., Murre, J. M. J., Postma, E. O., & Herik,
                                                                        of detectability? Psychological Bulletin, 80, 481-488.
  H. J. van den. (submitted). Modeling recognition memory
  using the similarity structure of natural input. Psychologi-        Steyvers, M., Shiffrin, R. M., & Nelson, D. L. (in press).
  cal Review.                                                           Word association spaces for predicting semantic similarity
Lyons, M., & Akamatsu, S. (1998). Coding facial expressions             effects in episodic memory. In A. Healy (Ed.), Cognitive
  with gabor wavelets. In Proceedings, third international              psychology and its applications: Festschrift in honor of lyle
  conference on automatic face and gesture recognition (pp.             bourne, walter kintsch, and thomas landauer. Washington,
  200-205). Nara Japan.                                                 DC: American Psychological Association.
MacAndrew, D. K., Klatzky, R. L., Fiez, J. A., McClelland,            Tenenbaum, J. B., Silva, V. de, & Langford, J. C. (2000). A
  J. L., & Becker, J. T. (2002). The phonological-similarity            global geometric framework for nonlinear dimensionality
  effect differentiates between two working memories. Psy-              reduction. Science, 290, 2319-2323.
  chological Science, 13, 465-468.                                    Yarbus, A. L. (1967). Eye movements and vision. New York:
McClelland, J. L., & Chappell, M. (1998). Familiarity breeds            Plenum Press.
  differentiation: A subjective-likelihood approach to the ef-        Yonelinas, A. P. (2002). The nature of recollection and famil-
  fects of experience in recognition memory. Psychological              iarity: A review of 30 years of research. Journal of Memory
  Review, 105, 724-760.                                                 and Language, 46, 441-517.
Medin, D. L., & Schaffer, M. M. (1978). Context theory of
  classification learning. Psychological Review, 85, 207-238.
Murnane, K., & Shiffrin, R. M. (1991). Interference and
  the representation of events in memory. Journal of Experi-
  mental Psychology: Learning, Memory and Cognition, 17,
  855-874.
                                                                  778

