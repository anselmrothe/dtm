UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Efficient Method for the Minimum Description Length Evaluation of Deterministic
Cognitive Models
Permalink
https://escholarship.org/uc/item/2mj1q73t
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Author
Lee, Michael D.
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

           An Eﬃcient Method for the Minimum Description Length
                      Evaluation of Deterministic Cognitive Models
                               Michael D. Lee (michael.lee@adelaide.edu.au)
                                   Department of Psychology, University of Adelaide
                                           South Australia, 5005, AUSTRALIA
                         Abstract                              Tenenbaum & Griﬃths 2001), and decision­making
                                                               (e.g., Myung & Pitt 1997).
   The ability to evaluate competing models against
   noisy data is central to progress in cognitive science.
   In general, this requires advanced model selection          Probabilistic Models
   criteria, such as the Minimum Description Length
   (MDL) criterion, that balance goodness­of­ﬁt with
   model complexity. One limiting property of many             For the most part, however, these recent development
   of these criteria, however, is that they cannot read­
   ily be applied to deterministic models. A solution to       have been restricted to considering probabilistic cogni­
   this problem, developed by Grünwald (1999), involves       tive models. This class of models has the property
   a process called ‘entropiﬁcation’ that associates de­       that any parameterization (or, more generally, any
   terministic models with probability distributions, and      probability distribution over the parameter space) cor­
   allows MDL criteria to be calculated. However, a po­
   tential practical diﬃculty with this approach is that it    responds to a probability distribution over the data.
   requires a multidimensional summation over the data         That is, the model corresponds to a parametric family
   space that can be prohibitively computationally ex­         of probability distributions over the data. This means
   pensive in realistic situations. This paper derives a       that considering a probabilistic model at a particular
   simpler version of the MDL criterion for deterministic      set of parameter values makes some data quantiﬁably
   models in the important special case of 0­1 loss func­
   tions that is computationally feasible. Two concrete        more likely than others. In turn, for probabilistic mod­
   applications of the simpler MDL criterion are pre­          els the likelihood of any observed data having arisen
   sented, demonstrating its ability to consider model ﬁt      under the model at any parameterization of interest
   and complexity in selecting between competing mod­          can be evaluated.
   els of cognitive processes. The ﬁrst application in­
   volves three diﬀerent heuristics for a problem solving         Many cognitive models are probabilistic in this way.
   task, while the second involves three diﬀerent models       For example, models of memory retention (e.g., Ru­
   of forced­choice decision making.
                                                               bin & Wenzel 1996) usually consist of parameterized
                                                               functions that specify the probability an item will be
                      Introduction                             recalled correctly after a period of time. As another ex­
To a large extent, progress in cognitive science relies        ample, the ALCOVE model of category learning (Kr­
on the development of better models of cognitive phe­          uschke 1992) also produces a probability, that depends
nomena. Models provide a formalized representation             upon the values of a number of parameters, for each
of theoretical explanations, and make predictions that         possible category response on any trial. For these mod­
can be tested empirically. For this reason, the ability        els, their probabilistic nature allows likelihood to be
to evaluate competing cognitive models against noisy           measured against any pattern of observed data.
data in a complete and meaningful way has been a cen­             Many advanced model selection criteria, such as
tral concern recently in mathematical psychology (e.g.,        Bayes Factors (e.g., Kass & Raftery 1995), Minimum
Myung & Pitt 1997; Myung, Balasubramanian & Pitt               Description Length (MDL: e.g., Grünwald 2000), Sto­
2000; Myung, Forster, & Browne 2000; Pitt, Myung,              chastic or Geometric Complexity (Myung, Balasubra­
& Zhang 2002).                                                 manian & Pitt 2000; Rissanen 1996), and Normalized
   In particular, there has been a strong (and overdue)        Maximum Likelihood (Rissanen 2001), rely on this
focus on balancing the goodness­of­ﬁt of models with           property. This is because they integrate the proba­
their complexity. These ideas have been applied to             bilities of the data across the parameter space of the
core topics in cognitive science such as models of psy­        models, or the maximum likelihoods across all possible
chophysical discrimination (e.g., Myung et al. 2000),          data sets, and so require non­zero probabilities over a
stimulus representation (e.g., Lee 2001; Navarro &             subset of the parameter space that has measure greater
Lee 2003; in press), inference and generalization (e.g.,       than zero to be meaningful.
                                                         807

Deterministic Models                                      data space that could be prohibitively computation­
As Myung, Pitt and Kim (in press) note, however,          ally expensive in some realistic situations. This pa­
there are many important cognitive models that belong     per derives and demonstrates a reformulation of the
to the alternative class of deterministic models. These   MDL criterion for deterministic models in the impor­
models specify diﬀerently how to assess the relation­     tant special case of 0­1 loss functions that is much less
ship between data on the one hand, and model predic­      computationally expensive.
tions at diﬀerent parameterizations on the other. For
example, a sum­squared loss or error function might                           The MDL Criterion
be proposed, so that increasingly large diﬀerences be­    In this section, Grünwald’s (1999) formulation of the
tween model predictions and observed data are penal­      MDL criterion based on entropiﬁcation is described,
ized more heavily in evaluating the model. Alterna­       and a computationally simpler form is then presented.
tively, a 0­1 loss function might be proposed, so that    In one sense, the reformulation is just a straightforward
models are evaluated as being correct only if they pre­   algebraic manipulation, and has probably been noted
dict data exactly, and are wrong otherwise. What de­      (but not published, as far as we are aware) by others.
terministic models do not specify, however, is an error   In another sense, making the reformulation explicit,
theory that describes the likelihood of data that dif­    and demonstrating its advantages, is a useful contri­
fer from model predictions. This means that, when a       bution. There are many cognitive models that are de­
deterministic model makes incorrect predictions, it is    terministic and naturally assessed under 0­1 loss1 , for
not possible to assign the probabilities needed by many   which the MDL method described here ought to ﬁnd
modern model selection criteria.                          wide application.
   A good example of a deterministic cognitive model is
the ‘Take the Best’ model of decision making (Gigeren­    Original Formulation
zer & Goldstein 1996). This model takes the form of       Suppose a deterministic model M is being evaluated
a simple algorithm, searching a ﬁxed stimulus envi­       using a dataset D that has n observations, D =
ronment in a deterministic way, so that it will always    [d1 , . . . , dn ]. Each of the observed data are discrete,
make the same decisions. One way of interpreting the      and can assume only k diﬀerent values. The model
model in relation to empirical data is that it has prob­  uses P parameters θ = (θ1 , . . . , θP ) to make predic­
ability one when it makes the same decision as that       tions Y = [y1 , . . . , yn ]. To evaluate any prediction
observed, but probability zero when it makes a diﬀer­     made by the�        model, a 0­1 loss function is deﬁned as
                                                                               n
ent decision. Adopting this approach, however, any        f (D, Y ) =          i=1 γi , where γi = 0 if di = yi and
evaluation of the model against human data involv­        γi = 1 otherwise. By considering all possible para­
ing multiple decisions is very likely to ﬁnd an overall   meterizations, the model makes a total of N diﬀer­
probability of zero, because at least one of the model’s  ent predictions. In other words, there are N diﬀer­
decisions will disagree with the data.                    ent predictions, Y1 , . . . , YN , the model is able to make
   Other deterministic models that face similar prob­     about the data by choosing diﬀerent parameter values.
lems include the memory models surveyed by Pietsch        In general, the relationship between parameterizations
and Vickers (1997), axiomatic theories of judgment        and predictions will be many­to­one. This means that
and choice (e.g., Luce 2000), and various lexicographic   every unique model prediction is naturally associated
decision models (e.g., Payne, Bettman & Johnson           with one or more parameterizations of the model.
1990). For these sorts of models, the natural assess­        Under these assumptions, Grünwald (1999) shows
ment is in terms of the proportion of correct decisions   that using entropiﬁcation the model making prediction
it makes, or some such error function, but this mea­      Y can be associated with a probability distribution,
sure is not the same as the probabilities from likelihood parameterized by the scalar w, as follows:
functions used in probabilistic model selection. In par­
ticular, it is not clear how the error function measuring
goodness­of­ﬁt should be combined with measures of                                                e−wf (D,Y )
model complexity to undertake model selection.            p (D | M, Y, w) = �k                   �k                             .
                                                                                                          −wf (D,[x1 ,...,xn ])
                                                                                     x1 =1 . . .   xn =1 e
   Recently, however, Grünwald (1999; see also Myung,
Pitt, & Kim in press), has developed a model selection    Determining the MDL criterion for the model requires
methodology that overcomes these diﬃculties. He pro­      ﬁnding the model predictions Y ∗ and scalar w∗ that
vides a principled technique for associating determin­    jointly maximize p (D | M, θ, w) to give the value p∗ .
istic models with probability distributions, through a
                                                              1
process called ‘entropiﬁcation’, that allows MDL cri­           All of the deterministic decision making, memory and
teria for competing models to be calculated. There is     judgment models already mentioned eﬀectively have 0­1
                                                          loss when they are restricted to two choices. There are
a potential practical diﬃculty, however, in using this    other models, such as the optimal stopping models consid­
approach to evaluate cognitive models. The MDL cri­       ered later, that are also naturally associated with 0­1 loss
terion involves multidimensional summations over the      despite having a larger number of choices.
                                                      808

Once this is achieved the MDL criterion for the model
is given simply by MDL = − ln p∗ + ln N .                                             n � �
   Besides automatically balancing the competing de­                        1 −wm � n                 x
                                                                ∂p/∂w =       e               (k − 1) (x − m) e−wx.
mands of model ﬁt and complexity, this MDL criterion                       Z2              x
                                                                                     x=0
has at least two attractive properties for model selec­
tion in cognitive science. First, diﬀerences in MDL             This derivative is clearly always positive if m = 0 and
values, through their natural probabilistic interpreta­         always negative if m = n. This means, if a model
tion, can be assessed as odds, in much the same way             predicts all of the data correctly, wi∗ → ∞, and if a
as Bayes Factors. This allows the assessment the ‘sig­          model fails to predict any of the data correctly wi∗ →
niﬁcance’ of diﬀerent MDL values for diﬀerent models            −∞. Otherwise, if 0 < m < n, the substitution u =
to be done meaningfully as a question of the standards          e−w allows wi∗ to be found from the positive real roots
of scientiﬁc evidence required for the problem at hand,         of the degree n polynomial
using a scale that is calibrated by betting. Secondly, as
Grünwald (1999, pp. 24­28) discusses, the information                        �n � �
                                                                                   n           x
theoretic or coding approach used by MDL means that                                    (k − 1) (x − m) ux .
results are available for cases where the data generat­                       x=0
                                                                                   x
ing process that is being modeled has statistical prop­
erties that are not perfectly represented by the models         by standard numerical methods (e.g., Forsythe, Mal­
being considered. We would argue this is inevitably             colm, & Moler 1976).
the case for cognitive models, and so the ability of the           Grünwald (1999, pp. 98­99) notes, with particular
MDL approach to address this problem is an important            reference to the 0­1 loss function, that the case w < 0
one.                                                            corresponds to ‘inverting’ models. For example, if a
   Despite these attractions, however, there is an ob­          model only makes two choices, and so considers bi­
vious diﬃculty in maximizing p (D | M, θ, w). The               nary data (i.e., k = 2), the inverted model changes
problem is that the denominator given by Z =                    all of the model predictions to the alternative possi­
�k             �k      −wf (D,[x1 ,...,xn ])                    bility. We would argue it will generally be the case in
   x1 =0 . . .  xn =0 e                      involves consider­
ing every possible data set that could be observed,             cognitive modeling that it is not appropriate to con­
which involves a total of k n terms. In cognitive sci­          sider inversion, because this manipulation will require
ence, where it is possible for a deterministic model to         the model to be interpreted in a substantively diﬀerent
be evaluated using many data points, each of which              and unintended way. If this is the case, it is necessary
can assume many values, the repeated calculation of             to restrict consideration to w ≥ 0 in ﬁnding the MDL
Z may be too computationally demanding to be prac­              value.
tical.                                                             With this restriction in place, the Y ∗ and w∗ learned
                                                                from data for qualitative model selection convey use­
A Simpler MDL Computation                                       ful information in their own right. In particular, as
A simpler form for Z can be derived by noting that              Grünwald (1999, pp. 94­95) explains carefully, the
f (D, Y ) can only take the values 0, . . . , n, in accor­      value of w∗ measures the ‘randomness’ of the data with
dance with how many of the model predictions agree              respect to the model Y ∗ , so that smaller values of w∗
with the data. Since Z considers all possible data sets,        indicate that the the model provides relatively less in­
the number of� times    n−x matches (i.e., x mismatches)        formation about the data.
                   �        x
will occur is nx (k − 1) . For a prediction Y that has
                                                                 Demonstrations of the MDL Criterion
n − m matches with the data (i.e., there are m mis­
matches and f (D, Y ) = m), this leads to the simpliﬁ­          In the remainder of this paper, we present two con­
cation                                                          crete examples of the MDL criterion evaluating cogni­
                                                                tive models, in situations where there is a clear need
                                          e−wm                  to assess whether the better goodness­of­ﬁt of some
       p (D | M, Y, w) = �n           �n�         x −wx ,       models warrants their additional complexity. The ﬁrst
                               x=0 x (k − 1) e
                                                                involves diﬀerent heuristics for a problem solving task,
which has a denominator that sums n + 1 rather than             while the second involves diﬀerent models of forced­
k n terms.                                                      choice decision making.
   The computational eﬃciency oﬀered by this refor­
mulation means it will generally be possible to ﬁnd             Optimal Stopping Problem
the wi∗ that maximizes p (D | M, Yi , wi ), giving p∗i , for    As a ﬁrst demonstration of the MDL criterion for de­
all N model predictions. The p∗ required for MDL                terministic models, consider three diﬀerent account
calculation is then just the maximum of p∗1 , . . . , pN  ∗
                                                            .   of human decision­making on an optimal stopping
   Finding each wi∗ can also be done eﬃciently by ob­           task sometimes known as the full­information secretary
serving that                                                    problem (see Ferguson 1989 for a historical overview).
                                                           809

        100                                                                cutoﬀ proportion respectively. For all three models,
                                                             Threshold
                                                                           if no value meets the decision criterion, the last value
                                                                           presented becomes the forced choice.
         80                                                                   Figure 1 summarizes the three models on a secre­
                              Cutoff                  Biased
                                                      Optimal              tary problem of length 10. The sequence of values
                                                                           presented is shown by the ﬁlled circles. The horizontal
         60
                                                                           line shows the constant level used by the threshold
Value                                                                      model. The threshold levels for the optimal model
         40                                                                with no bias follow the solid curve. The vertical
                                                                           line shows the proportion used by the cutoﬀ model.
                                                                           Under these parameterizations, the biased optimal,
         20                                                                threshold, and cutoﬀ models choose, respectively, the
                                                                           eighth, ninth, and ﬁfth values presented.
          0
              1   2   3   4        5   6      7   8      9      10         Application of MDL Lee, O’Connor and Welsh
                               Presentation                                (this volume) administered n = 20 problems of length
                                                                           k = 10 to a number of subjects. For this set of prob­
Figure 1: An optimal stopping problem of length 10,                        lems, the threshold, biased optimal, and cutoﬀ models
with the sequence of values shown by circles, demon­                       are able to predict, respectively, 60, 78, and 9 data
                                                                           sets by varying their parameters. As a concrete ex­
strating the operation of the biased optimal (curved
                                                                           ample of how the MDL criterion can balance these
line), threshold (horizontal line) and cutoﬀ (vertical                     diﬀerent model complexities against the ﬁt they are
line) models.                                                              able to achieve, consider the decisions made by one
                                                                           subject from the experiment. For this subject, the
                                                                           best­ﬁtting parameterizations of the threshold, biased
                                                                           optimal, and cutoﬀ models correctly predict, respec­
Background In these problems, a person presented
                                                                           tively 14, 17, and 10 of the 20 decisions. This is an in­
with a sequence of numerical values, and told to select
                                                                           teresting case to consider, because increases in model
the maximum. They must decide whether to accept
                                                                           complexity lead to increases in model ﬁt.
or reject each possibility in turn and, if a possibility is
                                                                              The MDL criteria values for each model, in relation
rejected, they cannot select it at some later point. The
                                                                           to this subject’s data, are 29.5, 19.4 and 38.0 respec­
number of choices in the complete sequence is ﬁxed and
                                                                           tively, showing that, despite its increased complexity,
known, and the distribution from which the values are
                                                                           the biased optimal model provides a better account
drawn (usually a uniform distribution on the interval
                                                                           than the threshold and cutoﬀ models. This superi­
[0, 1]) is also known. Performance is assessed using a
                                                                           ority can be quantiﬁed in terms of naturally inter­
0­1 loss function, so that if choosing the maximum is
                                                                           pretable odds, because diﬀerences between MDL val­
regarded as correct, but any other choice is regarded
                                                                           ues lie on the log­odds scale. For example, the bi­
as incorrect.
                                                                           ased optimal model provides an account that is about
   From the mathematical (e.g., Gilbert & Mosteller                        e29.5−19.4 ≈ 24, 000 times more likely than that pro­
1966) and psychological (e.g., Seale & Rappoport                           vided by the threshold model.
1997) literature, there are at least three plausible ac­
counts of how people might make decisions on these                         Sequential Sampling Processes
problems. The ﬁrst ‘threshold’ model assumes peo­
                                                                           As a second example, we consider the sequential sam­
ple simply chooses the ﬁrst value that exceeds a ﬁxed
                                                                           pling model of decision making developed by Lee and
threshold. The second ‘biased optimal’ model assumes
                                                                           Cummins (in press).
people choose the ﬁrst value that exceeds a threshold
level, where the threshold level changes for each posi­                    Background Lee and Cummins (in press) proposed
tion in the sequence. The threshold levels correspond                      that an evidence accumulation approach can unify the
to the mathematically optimal values (see Gilbert &                        ‘Take the Best’ (TTB: Gigerenzer & Goldstein 1996)
Mosteller 1966, Tables 7 and 8), for the given prob­                       model with the ‘rational’ (RAT) alternative to which
lem length, all potentially biased by shifting by the                      it is usually contrasted. The cognitive process being
same constant. The third ‘cutoﬀ ’ model assumes peo­                       modeled involves choosing between two stimuli on the
ple view a ﬁxed proportion of the sequence, remember                       basis of the cues or features that each does or does
the maximum value up until this cutoﬀ point, and then                      not have. In essence, TTB searches the cues until it
choose the ﬁrst value that exceeds the maximum in the                      ﬁnds one that only one stimulus has, and then simply
remainder of the sequence. Each of these models has                        chooses that stimulus. The RAT model, in contrast,
one parameter, giving the threshold, the bias, or the                      forms weighted sums across the cues for both stimuli,
                                                                     810

            5                                                         Application of MDL For the 200 decisions col­
            4
                                                                      lected from 40 subjects by Lee and Cummins (in press),
                                                                      the TTB model made 36% correctly, while the RAT
            3
                                    A                                 model made 64% correctly. The sequential sampling
                                                                      model, at the best­ﬁtting value of its evidence thresh­
            2
                                                                      old parameter, made 84.5% of the decisions correctly.
            1                                                         Of course, the sequential sampling model, through
Evidence
                                                                      its use of the parameter, is more complicated than
            0
                                                                      both the TTB and RAT decision models, which are
           −1                                                         parameter­free. This raises the issue of whether the
                                                                      extra complexity is warranted by the improved ac­
           −2
                                                                      curacy. Using the model selection method developed
           −3
                                    B                                 here, Lee and Cummins (in press) found MDL values
                                                                      of 87.6, 138.6 and 130.7 for the sequential sampling,
           −4
                                                                      TTB and RAT models respectively. The much smaller
           −5                                                         MDL value for the uniﬁed model indicates that it pro­
                Cue 1   Cue 2   Cue 3   Cue 4   Cue 5   Cue 6
                                                                      vides a better account of the data, even allowing for
                                                                      its additional complexity.
Figure 2: A sequential sampling process using evidence
accumulation to decide between choices A and B. Suc­                                      Conclusion
cessive evidence values are shown as cues are examined
from highest validity to lowest. A decision is made                   These demonstration of the MDL criterion provides
once the evidence exceeds a threshold value.                          clear practical examples of how it can be used to eval­
                                                                      uate competing deterministic models of human cogni­
                                                                      tive processes. It also highlights the contribution of
                                                                      this paper, which is a simpler form of the MDL cri­
and chooses the one with the maximum sum.                             terion for the special case of 0­1 loss functions. For
   Figure 2 shows a sequential sampling process accru­                the optimal stopping problem example, the original
ing information in making this sort of decision. Each                 MDL formulation involves summing 1020 terms in the
of the cues is examined and the evidence provided by                  denominator to ﬁnd p (D | M, Y, w) for each combina­
that cue is used to update the state of the random                    tion of m and Y that needs to be evaluated in opti­
walk in favor of choosing stimulus A or stimulus B. If                mization. The simpler form given here requires sum­
stimulus A has the cue and stimulus B does not, the                   ming only n + 1 = 21 terms each time. For the se­
random walk moves towards choosing A. If stimulus B                   quential sampling problem, the original formulation
has the cue and stimulus A does not, the random walk                  involves 2200 ≈ 1060 , while the simpliﬁcation involves
moves towards choosing B. If both stimuli either have                 201 terms. As these comparisons make clear, the dras­
or do not have the cue, the state of the random walk                  tic reduction in computation oﬀered by the simpliﬁ­
is unchanged.                                                         cation developed here makes the MDL evaluation of
                                                                      deterministic cognitive models under 0­1 loss feasible
   The important observation about Figure 2 is that
                                                                      for most (if not) all empirical data collected in cogni­
the TTB and RAT models correspond simply to
                                                                      tive science.
diﬀerent required levels of evidence being accrued
before a decision is made. If a very small evidence
threshold were set, the sequential sampling process                                  Acknowledgments
would choose stimulus A, in agreement with the                        I thank Jay Myung, Peter Grünwald and three anony­
TTB choice. Alternatively, if a very large evidence                   mous reviewers for particularly helpful comments.
threshold were set, the sequential sampling process
would eventually choose stimulus B (because the ﬁnal                                      References
evidence is in its favor), in agreement with the RAT
model. In general, if a threshold is small enough                     Ferguson, T. S. (1989). Who solved the secretary prob­
that the ﬁrst discriminating cue is guaranteed to                       lem? Statistical Science 4 (3), 282–296.
have evidence that exceeds the threshold, sequential                  Forsythe, G. E., Malcolm, M. A., & Moler, C. B.
sampling corresponds to the TTB decision model. If
                                                                        (1976). Computer Methods for Mathematical Com­
a threshold is large enough that it is guaranteed never                 putations. New York: Prentice­Hall.
to be reached, the ﬁnal evidence is used to make a
forced decision, and sequential sampling corresponds                  Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning
to the RAT decision model.                                              the fast and frugal Way: Models of bounded ratio­
                                                                        nality. Psychological Review, 103 (4), 650–669.
                                                                811

Gilbert, J. P., & Mosteller, F. (1966). Recognizing the Navarro, D. J., & Lee, M. D. (in press). Common and
  maximum of a sequence. American Statistical Asso­       distinctive features in stimulus similarity: A mod­
  ciation Journal 61, 35–73.                              iﬁed version of the contrast model. Psychonomic
                                                          Bulletin & Review.
Grünwald, P. D. (1999). Viewing all models as ‘proba­
  bilistic’. In Proceedings of the Twelfth Annual Con­  Payne, J. W., Bettman, J. R., & Johnson, E. J. (1990).
  ference on Computational Learning Theory (COLT’         The Adaptive Decision Maker. New York: Cam­
  99), Santa Cruz. ACM Press.                             bridge University Press.
Grünwald, P. D. (2000). Model selection based on min­  Pitt, M. A., Myung, I. J., & Zhang, S. (2002). Toward
  imum description length. Journal of Mathematical        a method of selecting among computational models
  Psychology 44 (1), 133–152.                             of cognition. Psychological Review 109 (3), 472–491.
Kass, R. E., & Raftery, A. E. (1995). Bayes fac­        Rissanen, J. (1996). Fisher information and stochas­
  tors. Journal of the American Statistical Associa­      tic complexity. IEEE Transactions on Information
  tion 90 (430), 773–795.                                 Theory 42 (1), 40–47.
Kruschke, J. K. (1992). ALCOVE: An exemplar­based       Rissanen, J. (2001). Strong optimality of the normal­
  connectionist model of category learning. Psycholog­    ized ML models as universal codes and information
  ical Review, 99 (1), 22–44.                             in data. IEEE Transactions on Information The­
                                                          ory 47 (5), 1712–1717.
Lee, M. D. (2001). Determining the dimensionality of    Rubin, D. C., & Wenzel, A. E. (1996). One hundred
  multidimensional scaling representations for cogni­     years of forgetting: A quantitative description of re­
  tive modeling. Journal of Mathematical Psychology,      tention. Psychological Review, 103 (4), 734–760.
  45 (1), 149–166.
                                                        Seale, D. A., & Rapoport, A. (1997). Sequen­
Lee, M. D., & Cummins, T. D. R. (in press). Evidence      tial decision making with relative ranks: An ex­
  accumulation in decision making: Unifying the ‘take     perimental investigation of the “Secretary Prob­
  the best’ and ‘rational’ models. Psychonomic Bul­       lem”. Organizational Behavior and Human Deci­
  letin & Review.                                         sion Processes 69 (3), 221–236.
Lee, M. D., O’Connor, T. A., & Welsh, M. B.             Tenenbaum, J. B., & Griﬃths, T. L. (2001). General­
  (this volume). Human decision­making on the full­       ization, Similarity, and Bayesian Inference. Behav­
  information secretary problem. Proceedings of the       ioral and Brain Sciences, 24 (4), 629–640.
  26th Annual Conference of the Cognitive Science So­
  ciety.                                                Pietsch, A., & Vickers, D. (1997). Memory capacity
                                                          and intelligence: Novel techniques for evaluating ri­
Luce, R. D. (2000). Utility of Gains and Losses: Mea­     val models of a fundamental information process­
  surement Theoretical and Experimental Approaches.       ing mechanism. Journal of General Psychology, 124,
  Mahwah, NJ: Erlbaum.                                    229–339.
Myung, I. J., Balasubramanian, V., & Pitt, M. A.
  (2000). Counting probability distributions: Diﬀer­
  ential geometry and model selection. Proceedings of
  the National Academy of Sciences 97, 11170–11175.
Myung, I. J., Forster, M., & Browne, M. W. (2000). A
  special issue on model selection. Journal of Mathe­
  matical Psychology 44, 1–2.
Myung, I. J., & Pitt, M. A. (1997). Applying Occam’s
  razor in modeling cognition: A Bayesian approach.
  Psychonomic Bulletin & Review 4 (1), 79–95.
Myung, I. J., Pitt, M. A., & Kim, W. J. (in press).
  Model evaluation, testing and selection. In K. Lam­
  bert & R. Goldstone (Eds.), Handbook of Cognition.
  Thousand Oaks, CA: Sage.
Navarro, D. J., & Lee, M. D. (2003). Combining di­
  mensions and features in similarity­based represen­
  tations. In S. Becker, S. Thrun., & K. Obermayer
  (Eds.), Advances in Neural Information Processing
  Systems 15, pp. 59–66. Cambridge, MA: MIT Press.
                                                   812

