UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The effect of stimulus familiarity on modality dominance

Permalink
https://escholarship.org/uc/item/7cj6j8w6

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)

Authors
Robinson, Christopher W.
Sloutsky, Vladimir M.

Publication Date
2004-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The effect of stimulus familiarity on modality dominance
Christopher W. Robinson (robinson.777@osu.edu)
Center for Cognitive Science
The Ohio State University
207D Ohio Stadium East, 1961 Tuttle Park Place
Columbus, OH 43210, USA

Vladimir M. Sloutsky (sloutsky.1@osu.edu)
Center for Cognitive Science
The Ohio State University
208C Ohio Stadium East, 1961 Tuttle Park Place
Columbus, OH 43210, USA
learning equipped with a broad, universal expectation
that directs them to link novel words to
commonalities among objects.” (Waxman, 2003, p.
213).
For example, in Balaban and Waxman’s (1997)
study, 9-month-olds who heard labels or contentfiltered speech (which retained the original prosodic
pattern) were more likely to categorize entities at the
basic-level than children who only heard sounds.
Therefore, it appears that hearing the same linguistic
input associated with different exemplars helps
infants group these exemplars together. Labels can
also help infants detect differences between objects
(Xu, 2002). Here, 9-month-olds are more likely to
differentiate two objects when the two objects are
associated with different labels. Thus, hearing the
same label associated with different exemplars helps
infants group these objects together, and hearing
different labels helps infants differentiate the objects.
Various mechanisms have been proposed in an
attempt to explain the importance of linguistic input
on conceptual development. Language-specific
explanations suggest that children understand that
entities belong to categories, and labels highlight
categories (Gelman & Markman, 1987). Labels may
also be weighed heavier than other features such as
appearance because children may be attentive to the
prosody of human speech (Balaban & Waxman,
1997). From a general-auditory explanation, labels
may initially be weighed heavier than other features
because labels are presented to the auditory modality.
Moreover, auditory information receives privileged
processing early in development (Robinson &
Sloutsky, in press; Sloutsky & Napolitano, 2003).
In support of a general-auditory explanation,
Sloutsky and Napolitano (2003) demonstrated that
modality
preference
changes
throughout
development: Four-year-olds are more likely to
attend to auditory input, whereas adults are more

Abstract
When unfamiliar non-speech sounds and visual input cooccur, they often compete for attention, with auditory input
overshadowing visual information for infants and young
children (Robinson & Sloutsky, in press; Sloutsky &
Napolitano, 2003). The current study investigated whether
labels and familiar sounds also compete for attention with
corresponding visual information in infancy. The results
indicate that, unlike unfamiliar, non-speech sounds, labels
do not compete for attention with corresponding visual
information at 16-months of age: 16-month-olds ably
encoded both auditory and visual information. At the same
time 8-month-olds only encoded the labels. When infants
were familiarized to the same non-speech sounds that
overshadowed visual input in Robinson and Sloutsky’s
study, 16-month-olds encoded both auditory and visual
information, whereas, 8-month-olds continued to encode
only the sounds. These findings, in conjunction with the
findings of Robinson and Sloutsky (in press) and Sloutsky
and Napolitano (2003), point to an important
developmental progression in processing of auditory and
visual information.

Introduction
Language plays an important role in conceptual
development. When two entities share a common label,
children are more likely to perceive these entities as being
more similar to each other (Sloutsky & Lo, 1999), more
likely to group these entities together (Sloutsky, Lo, &
Fisher, 2001), and more likely to make inferences from
one entity to the other (Gelman & Markman, 1986;
Sloutsky, et al., 2001).
The effect of linguistic input on categorization appears
very early in development. Even 9-months-olds were
purported to benefit from linguistic input when forming
object categories (Balaban & Waxman, 1997). In
particular, it has been argued that “…from the onset of
acquisition, object naming and object categorization are
linked. Infants across the world begin the task of word

1167

likely to attend to visual input. This finding suggests that
the greater attention to auditory information may explain,
in part, the effects of labels.
More recently, Robinson and Sloutsky (in press)
extended these findings with infants as young as 8-months
of age. Here, infants were familiarized to an auditoryvisual compound stimulus (AUDoldVISold). After
familiarization, infants were presented with four different
test trials (AUDoldVISold and AUDnewVISnew), which
served as within subjects controls and (AUDnewVISold and
AUDoldVISnew), which were used to determine if infants
were primarily attending to auditory, visual, or both
auditory and visual components during familiarization. If
infants attend to a specific component during
familiarization, looking should increase when that
component changes at test. In sum, infants increased
looking when either the auditory component or both
components changed (AUDnewVISold and AUDnewVISnew);
however, infants at 8-, 12-, and 16-months of age did not
increase looking when only the visual component
changed (AUDoldVISnew). This finding suggests that
infants were primarily attending to the auditory input
during familiarization. At the same time, infants amply
encoded the visual component when it was presented in
isolation, which suggests that the auditory component
overshadowed the visual component.
These results point to auditory dominance early in
development and they have several important
implications. Most importantly, auditory dominance
effects can provide a coherent account for many of the
previous findings. Recall that it has been argued that
common labels help infants detect commonalities between
objects, and different labels help children differentiate
objects. Although infants in Robinson and Sloutsky (in
press) study were presented with non-speech sounds, the
pattern of results are identical to what would be expected
if infants were presented with linguistic labels (i.e., the
same visual stimulus that was presented during
familiarization was perceived as new when paired with a
new sound and a new visual stimulus was perceived as
old when paired with the old sound). In short, it seems
possible that under both speech and non-speech auditory
input conditions, infants rely primarily on the auditory
information.
The aim of Experiment 1 was to test this hypothesis by
investigating whether linguistic labels, similar to the nonspeech sounds (Robinson & Sloutsky, in press),
overshadow visual input. In particular, if linguistic input
is weighed heavier than visual input because it represents
auditory information then non-speech sounds and labels
should reveal similar patterns of results.

Experiment 1
Method
Participants Nineteen 8-month-olds (5 boys and 14
girls, M = 249 days, Range = 231 - 280 days) and
nineteen 16-month-olds (6 boys and 13 girls, M =
489 days, Range = 470 - 501 days) participated in
this experiment. Parents’ names were collected from
local birth announcements, and contact information
was obtained through local directories. All children
were full-term (i.e., > 2500g birth weight) with no
auditory or visual deficits, as reported by parents. A
majority of infants were Caucasian. Seven infants
were not included due to fussiness, and 10 infants
were excluded because they did not reach the training
criterion indicated below.
Apparatus Infants were seated on parents’ laps
approximately 100 cm away from a 152 cm x 127 cm
projection screen, which was located approximately 5
cm above the infant’s eye level. A Sony DCRTRV40 camcorder was used to capture infants’
fixations and was projected to one of two Dell flat
panel monitors in the observation room. An NEC
GT2150 LCD projector was mounted on the ceiling
approximately 30 cm behind the infant (130 cm away
from the projection screen). Two Boston Acoustics
380 speakers were 76 cm apart from each other and
mounted in the wall. The speakers and camcorder
were concealed by black felt and located directly
below the projection screen. Two small lights were
located behind the infant to ensure that the room was
dimly lit throughout the entire procedure. In an
adjacent room, a Dell Dimension 8200 computer with
Presentation software was used to present stimuli to
the infants, as well as to record the onset and offset of
infant’s visual fixations. Fixations were recorded
online by pressing a button on an Excalibur 10-button
gamepad when infants were looking at the stimulus
and releasing the button when infants looked away
from the stimulus. A second Sony DCR-PC120
camcorder was used to record the video stream of the
infant from the monitor indicated above, as well as to
record the image of the stimulus presentation on a
second Dell flat panel monitor. This split screen
recording was used to establish interrater reliability.
Stimuli Each infant was familiarized to an auditoryvisual compound stimulus (AUdoldVISold) and tested
on four auditory/visual combinations (AUDnewVISold,
AUDoldVISnew, AUDnewVISnew, and AUDoldVISold).
The auditory components consisted of two infantdirected nonsense labels (vika and kuna), which were
presented at 65-68 dB. The visual components

1168

consisted of two three-shape patterns (circle, pentagon,
triangle, and cross, octagon, square), and were projected
to 25 cm x 7 cm in size. Previous research has
demonstrated that infants can discriminate these visual
stimuli when presented in isolation; however, they are
overshadowed by unfamiliar non-speech sounds
(Robinson & Sloutsky, in press; Experiment 2).

changing the auditory component had a larger effect
than changing the visual component, DIFFAUDnewVISold
= 3435 ms > DIFFAUDoldVISnew = -552 ms, paired t (18)
= 5.87, p < .001. This difference, however, attenuated
at 16-months of age (DIFFAUDnewVISold = 3403 ms =
DIFFAUDoldVISnew = 2318 ms), paired t (18) = 1.40, p >
.1.

Procedure The procedure consisted of 10 familiarization
trials, 2 test trials, 3 retraining trials, and 2 more test
trials. Each familiarization trial consisted of a compound
stimulus that appeared for 1000 ms and disappeared for
500 ms. Each stimulus appeared five times during each
trial (7500 ms trial duration). After familiarization, infants
were present with 4 different test trials (AUDnewVISold,
AUDoldVISnew, AUDnewVISnew, and AUDoldVISold). Test
trials were 12 s in duration and were randomized so that
each test stimulus had an equally likely chance of
appearing as the first test trial, last test trial, etc. The
retraining trials were the same as familiarization trials and
were used to remind infants of the familiarization
stimulus. Retraining trials always appeared between the
first two and last two test trials. Fixations were recorded
online by an experimenter for all training, test, and
retraining trials. A random sample of 25% of the infants
were coded offline by experimenters who were blind to
the auditory and visual components presented to infants.
No differences were found between subjects coded onand offline.

Figure 1. Effects of changing
visual stimuli in Experiment 1

Results and Discussion

It is important to note that, although the nonsense
labels overshadowed visual input at 8 months of age,
these same visual stimuli were ably encoded by 8months-olds when presented in isolation (Robinson
& Sloutsky, in press). In contrast, 16-month-olds
encoded both the auditory and visual components.
This pattern of results is strikingly different from
those reported by Robinson & Sloutsky. In particular,
when the same visual stimuli were paired with
unfamiliar non-speech sounds (laser and static
sounds), 8- , 12-, and 16-month-olds only encoded
the auditory component. Thus, the results from the
current experiment, in conjunction with Robinson &
Sloutsky, demonstrate that both speech and nonspeech sounds overshadow visual input at 8-months
of age. In contrast, by 16-months of age children
encode both auditory and visual components;
however, only when the auditory input consists of
speech sounds. While revealing interesting
developmental differences in effects of label on
processing of visual information, the current study
did not elucidate the nature of these effects.

labels

and

New Auditory/Old Visual
Old Auditory/New Visual
New Auditory/New Visual

750 0

Difference in looking time
compared to baseline (ms)

6 50 0
550 0
4 50 0

*

*

*

3 50 0

*
*

2 50 0
150 0
50 0
-50 0
-150 0

8-months

16-months
Age

Note: *Difference score > 0, p < .01. Error bars represent
standard errors.

Training Criterion. Only infants who demonstrated a
novelty preference at test were included in additional
analyses (i.e., looking to AUDnewVISnew > AUDoldVISold).
As reported above, 10 infants did not reach this criterion.
Test Trials. Analysis of test trials focused on whether
infants were primarily attending to auditory and/or visual
input during familiarization. A difference score was
calculated by taking the accumulated looking to each test
stimulus and subtracting it from baseline (e.g., the effect
of changing the auditory component = AUDnewVISold –
AUDoldVISold). Thus, positive numbers indicate that
looking increased as a function of changing a specific
stimulus component, which suggests that infants encoded
that modality during training. As can be seen in Figure 1,
at 8- and 16-months of age, looking increased when the
auditory component changed and when both auditory and
visual components changed, one-sample ts > 0, ts > 5, ps
< .001. In contrast, only the 16-month-olds increased
looking when the visual stimulus changed, one-sample t >
0, t (18) = 2.88, p < .01.
A 2 (Age: 8-months, 16-months) x 3 (Test Trial:
AUDnewVISold, AUDoldVISnew, AUDnewVISnew) revealed
an effect of Test Trial and also confirmed the Age x Test
Trial interaction, Fs > 5, ps < .01. At 8-months of age,

1169

experience with the three-shape patterns. After
infants heard each sound 10 times, infants were given
a 4 minute distracter task in which they looked at
realistic pictures of animals. After the distracter task,
infants were then presented with the main
experiment.

Experiment 2
The goal of Experiment 2 was to determine whether the
effect of label stems from language-specific properties or
from general-attentional effects. From a language-specific
perspective, the different pattern of results at 16-months
of age between Experiment 1 with those reported in
Robinson & Sloutsky (in press) could stem from
privileged processing of linguistic input. In particular, it is
possible that linguistic information does not compete for
attention with corresponding visual information, which
allowed 16-month-olds to process both auditory and
visual information. However, it is also possible that
human speech represents a familiar class, and even
familiar non-speech sounds do not compete for attention
with corresponding visual input. Although very few
empirical studies, if any, have compared processing of
familiar sounds with linguistic input early in
development, there is preliminary neurophysiological
evidence with adults suggesting that familiar non-speech
sounds are processed in the brain similarly to words
(Cycowicz & Friedman, 1998). Thus, the goal of
Experiment 2 is to determine if stimulus familiarity can
account for differences between Experiment 1 and
Robinson & Sloutsky (in press).

Results and Discussion
As in Experiment 1, a difference score was calculated
by taking the accumulated looking to each test
stimulus and subtracting it from baseline. As can be
seen in Figure 2, the pattern of results are very
similar to Experiment 1. That is, both age groups
increased looking when either the auditory
component changed or when both auditory and visual
components changed, one-sample ts > 0, ts > 3, ps <
.01, and only the 16-month-olds increased looking
when the visual stimulus changed, one-sample t > 0, t
(9) = 3.86, p < .01.
A 2 (Age: 8-months, 16-months) x 3 (Test Trial:
AUDnewVISold,
AUDoldVISnew,
AUDnewVISnew)
revealed an effect of Test Trial, F (2, 56) = 7.72, p <
.001. Here, children looked longer when both
components changed (DIFFAUDnewVISnew = 4401 ms)
than when only the auditory component changed
(DIFFAUDnewVISold = 2940 ms) or when only the visual
component changed (DIFFAUDoldVISnew = 1819 ms),
paired ts > 2.5, p < .01. The above analyses also
revealed an effect of Age, F (1, 28) = 5.93, p < .05,
with 16-month-olds (M = 4631 ms) accumulating
more looking across test trials than 8-month-olds (M
= 2264 ms).

Method
Participants Twenty 8-month-olds (10 boys and 10 girls,
M = 252 days, Range = 245 - 269 days) and ten 16month-olds (4 boys and 6 girls, M = 490 days, Range =
474 - 504 days) participated in this experiment.
Recruitment procedures and demographics were identical
to Experiment 1. Two infants were not included due to
fussiness, and 13 infants were excluded because they did
not demonstrate a novelty preference (i.e., AUDnewVISnew
> AUDoldVISold).

Figure 2. Effects of changing familiar sounds and
visual stimuli in Experiment 2
New Auditory/Old Visual
Old Auditory/New Visual

Stimuli and Procedure With two exceptions, the
procedure was identical to Experiment 1. First, the
nonsense labels were replaced with non-speech sounds
(laser sound and static sound). Note that these same
sounds overshadowed the three-shape patterns in
Robinson & Sloutsky (in press). Second, and most
importantly, children were familiarized to the non-speech
sounds prior to the actual experiment. In the current
experiment children sat on parent’s laps and heard each
non-speech sound 10 different times. As with the actual
experiment, the auditory stimulus was presented at 65-68
dB, and each auditory stimulus lasted for 1000 ms.
Auditory stimuli were presented in pairs and
pseudorandomized so that infants heard the same stimulus
at least twice in a row and no more than 4 times in row. In
addition, the non-speech sounds were not associated with
the three-shape patterns or any visual stimulus. This
ensured that children in Experiments 1 and 2, and children
in Robinson & Sloutsky (in press) all had equal

7500

New Auditory/New Visual

Difference in looking time
compared to baseline (ms)

6500

*

5500

*

4500
3500

*

*

*

2500
1500
500
-500
-1500

8-months

16-months

Age
Note: *Difference score > 0, p < .01. Error bars represent
standard errors.

1170

At a more general level, it is well known that
linguistic input plays a large role in conceptual
development. However, it is uncertain how and when
labels become special. Even as young as 9-months of
age, hearing the same label associated with different
exemplars helps infants group these objects together,
and hearing different labels helps infants differentiate
objects (Balaban & Waxman, 1997; Xu, 2002).
Interestingly, 8-month-olds in the current study
demonstrated the same pattern of results when
presented with unfamiliar non-speech sounds
(Robinson & Sloutsky, in press), labels, and familiar
sounds. This suggests that young children may
initially rely on various types of auditory information
(sounds and labels), and this initial preference for
auditory input may help bootstrap labels into a
special status.

General Discussion
The results from the two experiments in conjunction with
Robinson & Sloutsky (in press) demonstrate that
unfamiliar non-speech sounds, familiar non-speech
sounds, and nonsense labels all overshadow visual input
at 8-months of age. That is, 8-month-olds do not
discriminate visual stimuli when these images are paired
with auditory input; however, they ably discriminate the
same images when presented in isolation (Robinson &
Sloutsky, in press). In contrast, 16-month-olds encode
both the auditory and visual components; however, only
when the visual stimuli are paired with labels or familiar
sounds.
Interestingly, the non-speech sounds that
children heard in Experiment 2 were the same non-speech
sounds that overshadowed the three-shape patterns in
Robinson and Sloutsky’s study. These findings
demonstrate that, at 16-months of age, just hearing an
auditory stimulus a few times affects the way children
attend to auditory and visual input. These findings also
demonstrate that familiar sounds and labels have similar
effects on processing of auditory and visual information at
8- and 16-months of age.
Overall, the current study expands previous research
concerning the development of attention, the role of
familiarity in the auditory modality, and possible
mechanisms underlying the effect of labels on conceptual
development.
One potential explanation of the developmental
differences found in the current study concerns the notion
that attentional biases and attentional resources change
considerably throughout development.
There is a
growing body of research demonstrating that younger
children are more likely than adults to demonstrate a
preference for auditory input and more likely to encode
only one modality (Robinson & Sloutsky, in press;
Sloutsky & Napolitano, 2003). Currently, there are
several possible mechanisms that may explain this
developmental pattern. First, it is possible that young
children lack attentional resources that are needed for
simultaneously processing auditory and visual input.
However, it is also possible that young children either
habituate to and/or process auditory information faster
than visual information. Future research will need to
address this issue.
The current study also introduces the notion that
familiar sounds and labels may play a similar role early in
development. Although there is neurophysiological work
demonstrating that familiar sounds are processed in the
brain similarly to words (Cycowicz & Friedman, 1998),
the current study provides behavioral evidence for this
notion in infancy. One interesting question concerns the
idea that labels may represent a familiar class of auditory
stimuli. This would explain why labels and familiar
sounds have similar effects in the adult brain, as well as in
the current study.

Acknowledgments
This research has been supported by a grant from the
National Science Foundation (BCS # 0078945) to
Vladimir M. Sloutsky.

References
Balaban, M.T., & Waxman, S.R. (1997). Do words
facilitate object categorization in 9-month-old
infants?
Journal
of
Experimental Child
Psychology, 64, 3-26.
Cycowicz, Y.M., Friedman, D. (1998). Effect of
sound familiarity on the event-related potentials
elicited by novel environmental sounds, Brain and
Cognition, 36, 30-51.
Gelman, S. A., & Markman, E. (1986). Categories
and induction in young children. Cognition, 23,
183-209.
Napolitano, A. V., & Sloutsky, V. M. (2003).
Flexible attention and modality preference in
young children. In R. Alterman & D. Kirsh (Eds.),
Proceedings of the XXV Annual Conference of the
Cognitive Science Society. Mahwah, NJ: Erlbaum.
Robinson. C.W. & Sloutsky, V.M. (in press).
Auditory dominance and its change in the course of
development. Child Development.
Sloutsky, V. M., & Lo, Y. (1999). How much does a
shared name make things similar? Part 1:
Linguistic labels and the development of similarity
judgment. Developmental Psychology, 6, 14781492.
Sloutsky, V. M., Lo, Y., & Fisher, A. V. (2001). How
much does a shared name make things similar?
Linguistic labels, similarity, and the development
of inductive inference. Child Development, 72,
1695-1709.

1171

Sloutsky, V. M., & Napolitano, A. (2003). Is a
picture worth a thousand words? Preference for
auditory modality in young children. Child
Development, 74, 822-833.
Waxman, S. R. (2003).
Links between object
categorization and naming: Origins and emergence in
human infants. In D. H. Rakison & L. M. Oakes (Eds.),
Early category and concept development: Making sense
of the blooming, buzzing confusion (pp. 213-241).
London, UK: Oxford University Press.
Xu, F. (2002). The role of language in aquiring object
kind concepts in infancy. Cognition, 85, 223-250.

1172

