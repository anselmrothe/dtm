UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Event Related Potentials (ERP) and Behavioral Responses: Comparison of Tonal stimuli to
speech stimuli in phonological and semantic tasks

Permalink
https://escholarship.org/uc/item/9sc1j6h3

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)

Authors
Geal-Dor, Miriam
Babkoff, Harvey

Publication Date
2004-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Event Related Potentials (ERP) and Behavioral Responses: Comparison of Tonal
stimuli to speech stimuli in phonological and semantic tasks.
Miriam Geal-Dor (gealdor@gesher.co.il)
Faculty of Life Science, Bar Ilan University
Ramat Gan, Israel.

Harvey Babkoff (babkofh@mail.biu.ac.il)
Department of Psychology, Bar Ilan University
Ramat Gan, Israel.

amplitude. These differences reflect the involvement of
different processes in tonal and speech stimuli.
Using tonal stimuli Polich (1997)) reported an asymmetry
in P300 amplitude with right hemisphere dominance
specifically at the frontal and central electrode sites. They
interpreted the data as reflecting the allocation of attention.
Other researchers (Bruder et al 1999, Breier et al 1999) did
not observe any laterality effect. Using speech stimuli a left
hemisphere advantage was observed for phonemes, syllables
(Kayser et al 2001, Alho et al 1998) and word stimuli
(Breier et al 1999).

Abstract
Event Related Potentials (ERPs) were recorded from 20
young subjects to auditory target stimuli while they were
performing three different tasks, using an odd-ball paradigm;
1. Tones: Subjects were instructed to respond to a 2kHz tone,
and ignore a 1kHz tone. 2. Phonological: Subjects were
instructed to respond only to words that had a specific ending
(“f”). 3. Semantic: Subjects were instructed to respond to
words that belonged to a specific category (name of
alphabetic letters). EEG was recorded from 19 electrode sites.
Peak amplitude of the early component (N100) did not differ
significantly across the three tasks, while peak latency
differed significantly across stimuli. In contrast, the later
endogenous component (P300) was stimulus- and taskdependent. P300 latency differed significantly across stimuli
and tasks; 327 ms to target tones; 668 ms to the phonological
targets; and 706 ms to target words in the semantic task. P300
amplitude was significantly larger to tones than to linguistic
stimuli. P300 peak amplitude recorded from electrode sites
over the left hemisphere to the tonal target stimuli did not
differ significantly from that recorded over the right
hemisphere. In contrast, P300 amplitude recorded to both the
phonological and semantic targets was significantly larger
over the left hemisphere than over the right hemisphere. The
present results can aid in our understanding of how humans
process linguistic stimuli. These findings emphasize the
importance of using similar experimental protocols for a
broad comparison of the ERP response to a variety of stimuli
and tasks.

Studies have examined ERP morphology and topography
using linguistic stimuli (Novick et al 1985, Henkin et al
2002). There seems to be an agreement among researchers
that while phonological processing is characterized by a left
hemisphere advantage, semantic processing is less localized,
since it involves the activation of distributed networks in the
brain (Lovrich et al 1988, Thierry et al 1998, Angrilli et al
2000).
In the present study, we used the oddball paradigm to
generate a clear P300 component. We suggest that this
paradigm, and specifically the P300 component, is
appropriate to compare the ERP to a variety of target stimuli
that lie along a continuum of auditory processing, from
basic sensory discrimination of auditory features (tones) to
cognitive language processing (e.g. phonology and
semantics).

Introduction

Methods

The process of auditory speech perception requires the
use of sensory information in conjunction with linguistic
knowledge. Event related potential recordings which have
been increasingly used in the research of human cognitive
processes, can provide information on the patterns of
cortical activity that underlie different modes of processing
various kinds of auditory and linguistic information.
The use of P300 for auditory presented tonal stimuli is
well known. Studies have compared the ERP responses to
tonal stimuli to vowels (Tiitinen et al 1999), syllables
(Kayser et al 2001) or words (Lovrich et al 1988) and
reported prolongation of latency as well as decrease in

Subjects:
Twenty University students ranging in age from 20-26,
mean age 22.5 (10 male and 10 female) participated in the
study as part of their course requirement. Written informed
consent was obtained, and the Bar Ilan University Ethic
committee approved all experiments.
All subjects reported they were right handed, native
Hebrew speakers, healthy and had no history of neurological
or psychiatric disease. All passed a hearing screening test
446

performed in a quiet room using the Madsen OB 822
audiometer.

The recording system:
The electroencephalogram (EEG) was recorded from 19
sites on the scalp according to the International 10-20
system referenced to back of neck. A ground electrode was
placed on the right mastoid. An additional electrode placed
below the right eye recorded electrooculogram (EOG) to
monitor eye movement. The impedance measured for each
electrode was lower than 7k ohm. The EEG program used to
collect the data was Ceegraph IV Digital EEG system
Biologic Corp. Raw data was continuously recorded with a
band pass filter at 0.1-100Hz, sampling rate was 256Hz.
Signals were amplified and digitized on line with a 4ms
step.

Stimuli:
Three different auditory tasks were tested using the
oddball paradigm. One task consisted of tonal stimuli, and
the other two tasks consisted of speech stimuli:
Tones: Subjects were instructed to respond to a 2kHz
pure tone target and ignore the standard 1kHz tone. The tone
duration was 50ms with rise/fall time of 10ms, and an
interstimulus interval (onset to onset) of 2 sec.
Speech stimuli: High frequency Hebrew monosyllabic
short words were chosen as stimuli. The duration of word
stimuli ranged between 450-500ms. The same initial
phonemes were used for both targets and nontargets so that
discrimination between the targets and nontargets was only
possible if the subject attended to the last phoneme. For
example: If the target was “kaf” (alphabetic letter), the
nontargets were “kal” (easy) or “kar” (cold). In a series of
pilot experiments, we attempted to record ERPs using
11different target stimuli. The waveform in the expected
P300 window was extremely spread with no clear peak.
Consequently, in the present experiment we used three
different targets and twelve nontarget stimuli to generate a
clear P300 (See figure 1).

All data underwent analysis using BPM Orgil medical
equipment. Recordings were first segmented into epochs
that were time locked to the stimuli and extended from
200ms pre-stimulus to 1800ms post-stimulus. Behavioral
reaction time and accuracy were measured. The data were
referenced to a common 100 ms pre-stimulus base line.
Trials containing eye blinks or movements, excessive
muscle activity artifacts were corrected or rejected. If more
than 15 of the 35-40 sweeps of a given target were rejected
for any reason, then all of the data in that condition for that
subject was rejected. Thus, each ERP was based on a
minimum of 20-25 sweeps.

Two linguistic tasks were included in the experiment:
Phonological: Subjects were instructed to respond only to
words that had a specific ending ("f").
Semantic: Subjects were instructed to respond to words
from a specific category (name of Alphabetic letter).

Recordings to the target were averaged separately from
recordings to the standard stimuli. The responses to
standards preceding the targets were averaged and used as
the comparison. ERPs were originally analyzed for correct
response only. Because there were no differences between
the averaged ERPs for correctly detected targets and those
for all targets, further analysis was based on the later.

The exact same target and nontarget words were used in
the two speech tasks so that we could compare the
behavioral and ERP responses to the same target stimuli in
the two different linguistic tasks.

In a collateral behavioral experiment eight young naive
subjects were instructed to write down exactly what they
heard. Target words were cut and segmented in 25 ms
intervals from 200ms to 500ms. All the segments were
rearranged and randomly presented. The earliest cut off
point where at least six subjects recognized the word
correctly was defined as the point of identification for that
word (e.g. "taf" was identified at 300ms). The results
indicated that although the length of the words in the present
experiment ranged from 450-500ms, all the words were
correctly identified within the range of 275-350ms after
word onset. ERP recording analysis were time-locked both
to stimulus onset, and also to the point of identification
based on the behavioral judgments. Using averaging to
behavioral point of identification rather than to the onset of
stimuli showed no significant difference in P300 peak
latency and amplitude.

The oddball paradigm was programmed on a PC with the
Audio task editor, Orgil medical equipment. In all
experimental tasks conducted, a total of 180-195 stimuli
were presented, thus the probability that a stimulus would
be a target was 0.2. Stimuli were presented binaurally at 60
dBSL.

Procedure:
During the experiment subjects were instructed to fixate
on a point located 1.5meters distant on the wall facing them,
while keeping eye movement, blinks and general body
movement to a minimum.
Subjects were instructed to press a button when detecting
the target stimuli. A practice run was used to ensure that all
individuals understood the task. Presentation order of the
different conditions was counterbalanced across subjects.
The entire session (of all 11 tasks not all reported here)
lasted not longer than 3.5 hours.

The measurements:
Behavioral measures of reaction time and performance
accuracy were recorded as well as electrophysiologic
447

targets in the semantic task was significantly longer than to
the targets in the phonological task (p<0.044) (Figure 1).

measures. ERP’s were quantified in terms of peak latencies
and peak amplitudes of the maximum negative or positive
values within specific time windows. The time window for
the different components was determined by visual
inspection of the grand averages over all subjects. N100 was
identified as the most negative point between 50 and 180ms
post-stimulus. P300 peak amplitude was identified as the
maximum positive point between 250 and 450ms for tones
and 550 to 900ms for the speech stimuli.

There were no significant correlations between any of the
behavioral and electrophysiological measurements.
Table 2: N100 and P300 latency results averaged from all
20 subjects
tone
phonology semantic
N100
Mean 91.48
129.48
124.4
29.14
25.51
22.53
latency (ms) SD
P300 latency Mean 327.5
668.71
705.58
SD
18.76
78.4
74.34
(ms)

Statistical analysis
Latency and amplitude values as well as behavioral
measures were subjected to repeated measures analysis of
variance (ANOVA) with 3 levels of task as well as 6 levels
of electrode site as within subject factors. The level of
significance was set to p<0.05.
Correlation tests were preformed between tasks, between
behavioral and electrophysiological components.

Results:
Behavioral results:
The accuracy and reaction time data were analyzed (each
separately) by a one-way analysis of variance (ANOVA)
with task as a repeated variable. Accuracy measured as
percent of target detection was not significantly affected by
task. Task had a significant effect on reaction times to target
stimuli (F[2,36]=109.426, p<0.001). Post hoc analysis
revealed that the response to the target tones was always
shorter than to the target speech stimuli (p<0.001), with no
significant differences in RT within the speech stimuli
(Table 1).
Table 1: Behavioral results of
averaged from all 20 subjects.
tone
Accuracy
Mean 93.74
SD
8.04
(%)
Reaction
Mean 459.95
SD
87.46
time (ms)

Figure 1: Grand average from all 20 subjects for the 3
tasks recorded at the Pz electrode. As can be seen, N100
latency was shorter for the tonal targets (dashed line) than
the phonological (thick) and semantic (thin) targets. The
P300 was shortest in latency and had larger amplitude to
tonal targets as compared to speech targets.
Amplitude and Topography: A general repeated
measure ANOVA with 5 levels for electrode site (frontal,
central, parietal, occipital and temporal) revealed P300
amplitude was largest in parietal electrodes (Main effect of
electrode site F[4,76]=9.023, p<.001). Further statistical
analyses were performed on selected sets of scalp sites. On
the basis of the observed distributions, the statistical
analysis of ERP was limited to the central and parietal
electrode sites (C4, Cz, C3, P3, Pz, P4).
Peak amplitude of N100 and P300 were analyzed
separately by a two-way repeated measures analysis of
variance (ANOVA) with 6 levels of electrode site and 3
levels of task as within subject factors.

accuracy and reaction time
phonology
93.94

semantic
90.1

9.87

11.82

829.67

869.3

92.27

98.72

Electrophysiological results:
Latency: Latency values (N100 and P300) were analyzed
separately by a repeated measure analysis of variance
(ANOVA) with 3 levels of task as a within subject factor.
Both N100 and P300 latencies showed a significant main
effect of task (N100 F[2,38]=12.35, p<0.001; P300
F[2,38]=217.561, p<0.001) (Table 2). Post Hoc analysis
showed that N100 latency to the target in the tonal task was
significantly shorter than to targets in both speech tasks
(p<0.001). However, there were no significant differences in
N100 latency to targets in the phonological task versus
targets in the semantic task. Post hoc analysis revealed that
P300 peak latency was significantly shortest to tonal stimuli
(p<0.001), and within the speech stimuli, P300 latency to

N100: N100 amplitude showed a main effect of electrode
site (F[5,92]=144.194, p<0.001) and did not show any
significant effect of task. Post hoc analysis indicated that
N100 peak amplitude was largest over the central electrode
sites (p<0.001).
The degree of hemispheric asymmetry was computed by
subtracting N100 peak amplitude recorded over the right
hemisphere from that recorded over the left hemisphere (see
Bellis et al 2000 for use of a similar index). As seen in
448

At the central electrode sites the distribution of P300 was
symmetrical.

Figure 2 there was no significant difference in N100
amplitude recorded from the electrode sites over the left
hemisphere (c3, p3) as compared to the electrode sites over
the right hemisphere (c4, p4), for targets in either tonal,
phonology or semantic tasks.

Discussion
Behavioral
The average accuracy scores for the 3 tasks ranged
between 90-94% (Table 1). The high level of accuracy may
have caused a ceiling effect and resulted in the inability to
differentiate among the three tasks (Henkin et al 2002). In
contrast, RT was sensitive to the different tasks. RT to
targets in the tonal task was significantly shorter than to the
targets in the two speech tasks. Although we did not find
significant differences in RT to the targets in the
phonological task versus targets in the semantic task, earlier
studies did report such a difference (Novick et al 1985,
Henkin et al 2002). The present study differs from the two
earlier studies in that the construction of the targets in both
the phonological and semantic tasks was such that subjects
could not differentiate targets from nontargets unless they
attended to the last phoneme. This may have presented a
more difficult task than either of the earlier studies whose
stimulus construction allowed for discrimination of targets
from nontargets at an earlier stage of stimulus processing.

4

tones
phonology
semantic
0

-3

0

3

left hemisphere

right hemisphere

Figure 2: Degree of hemispheric symmetry in N100
amplitude. Results indicate responses were essentially
symmetrical across all tasks.
P300: P300 peak amplitude was significantly affected by
two of the variables, task and electrode site (F[2,38]=21.08,
p<0.001; F[5,95]=61.256, p<0.001 respectively) as well as a
two-way
interaction of task X electrode site
(F[10,195]=3.021, p<0.001). Post hoc analyses showed that
the largest P300 amplitude was recorded over the parietal
sites (p<0.001), and when comparing the tasks the largest
P300 amplitude was recorded to targets in the tonal task
(p<0.001).

N100
The largest N100 peak amplitude was recorded over the
central electrode sites. There were no significant differences
between N100 recorded to targets and to nontargets in any
of the tasks. Furthermore, there was a significant correlation
between N100 to target and non-target in each of the tasks.
These findings support the hypothesis that N100 represents
obligatory primary sensory processing dependant upon the
arrival of any stimuli at the auditory cortex, but does not by
itself indicate any sort of discrimination or any of the task
requirements (Martin et al 1999).

P300 amplitude to targets in the tonal task were
distributed symmetrically over the electrode sites. There
was no significant difference in P300 amplitude recorded to
tonal targets from the electrode site over the left hemisphere
as compared to the comparable electrode site over the right
hemisphere. In contrast, for both the phonological and
semantic speech tasks, P300 amplitudes recorded from the
parietal electrode site (p3) over the left hemisphere was
significantly larger than P300 amplitude recorded from the
parietal electrode site (p4) over the right hemisphere
(phonology t[18]=2.551 p<0.02; semantics t[18]=4.392
p<0.001). ( Figure 3).

The N100 latency to the tonal stimuli was always shorter
than to the speech stimuli, but there were no significant
differences in N100 latency between the two speech stimuli.
Similar results were previously reported (Wunderlich and
Cone-Wesson 2001). Since N100 is an exogenous wave, it
is sensitive to changes in the basic physical characteristics
of the stimuli.

4

tone
phonology

P300

semantic

As noted above, the P300 paradigm was chosen as the
experimental
technique
so
that
the
same
electrophysiological components might be compared across
a variety of stimuli and tasks.

0

3

0
left hemisphere

-3
right hemisphere

Figure 3: Degree of asymmetry for P300 amplitude.
While for the tonal stimuli responses were essentially
symmetrical, a significant degree of asymmetry can be seen
for both speech stimuli, most pronounced in the semantic
task, favoring the left hemisphere.

In the present study P300 latency showed significant
differences between the responses to tones and to the speech
stimuli (327ms versus 668-706ms). The increase in latency
for speech stimuli compared to tonal stimuli was reported
previously (Tiitinen et al 1999, Kayser et al 1998). We
449

shorter than to targets in the semantic tasks. Similar results
have been reported (Novick et al 1985, Cobianchi and
Giaquinto 1997)

tested the hypothesis that the difference in P300 peak
latency to tonal targets as compared to speech targets was
due to the specific construction of the speech stimuli which
required attention to the last phoneme before discrimination
was possible. Subjects could only discriminate the target
from the nontargets after hearing the last phoneme of the
word while they could theoretically begin the process of
discriminating the tone target from the tone nontargets
beginning with stimulus onset. Furthermore, the duration of
the tonal stimuli was 50ms, while the duration of the speech
stimuli ranged between 450-500ms. This would mean that
the difference in P300 peak latency to targets in the tonal
task versus targets in the speech tasks should be directly
related to the duration of the speech stimuli necessary to
discriminate the words (Woodward et al 1990). In an
adjunct experiment, we found that the average word
identification point ranged between 275-350ms after word
onset. Note the additional amount of time required for
identification of speech stimuli (approximately 325ms)
coincides with the time difference between P300 latency of
tones (327ms) and P300 latency of speech stimuli (668706ms).
Alternatively, it is possible that processing speech stimuli
takes longer than processing tones. Therefore, the difference
in P300 peak latency to tone targets versus speech targets
also included the differences in processing time to the two
types of stimuli (Bentin et al 1999).

Topographical distribution
Tones: In our study both N100 and P300 peak amplitude
in the tonal task were distributed symmetrically over the
two hemispheres. These results are similar to previous
reports using pure tones (Breier et al 1999) as well as
complex tones (Bruder et al 1999, Kayser et al 2001).
Speech tasks: In the present study, While N100 peak
amplitude distribution was symmetrical over the two
hemispheres, P300 peak amplitude to the targets in the two
speech tasks, was significantly larger when recorded from
the parietal electrode over the left hemisphere (p3) as
compared to the right hemisphere (p4). Similar results were
reported in other studies using phonemes, syllables (Kayser
et al 2001, Alho et al 1998) and words (Breier et al 1999). It
is important to note that the change from hemispheric
symmetry in tonal stimuli to hemispheric asymmetry in
speech stimuli was found only for the P300 component and
not for the N100 component (compare Fig 2 and 3). This
dissociation of the two ERP components further emphasizes
their different electrophysiological representations and may
point to a dynamic change of hemispheric interaction in the
processing of speech stimuli over time.
Phonology vs. semantics: A number of imaging and
ERP studies have concluded that while phonological
processing is more confined to regions of the left
hemisphere, the semantic processing is less localized, since
it involves the activation of distributed networks in the
brain. (Ferlazzo et al 1993, Cobianchi and Giaquinto 1997,
Thierry et al 1998, Angrilli et al 2000, Connolly et al 2001).
For example, imaging studies demonstrated that
phonological processes are related to Broca’s area and the
left inferior frontal gyrus (Demonet et al 1992, Becker at al
1999). However, during lexical-semantic tasks there is a
wider cortical distribution of activation, not confined only to
the left temporal and inferior frontal areas (Zatorre et al
1992, Kareken et al 2000, Zahn et al 2000). In the present
study we found hemispheric asymmetry favoring the left
hemisphere to targets in both the phonological and semantic
tasks and did not find a significant difference in the
hemispheric asymmetry of P300 peak amplitude favoring
either the targets in the phonological or semantic tasks.
These results are in line with several imaging studies
(Poldrack et al 1999, Johnson et al 2001) that point to a
greater activation of left hemisphere neural systems for both
semantic and phonological tasks.

The present findings can be related to the ongoing debate
concerning the identity of the late ERP potential recorded to
speech stimuli within the 500-750 ms time window, the
“identity” thesis. Coulson et al (1998) argued that ERPs
recorded in complex cognitive tasks are basically identical
to (or are just modifications of) waves found in simpler
conditions. Particularly, the P600 component of the scalp
recorded event-related brain potential related to syntactic
violation processing is just a delayed P300 similar to that
recorded in simple oddball tasks (both are sensitive to
probability manipulations and are similar in their respective
scalp distribution). Kotchoubey and Lang (2001) used a
paradigm in which subjects discriminated infrequent targets
from frequent standards based on a semantic feature (e.g.
animals versus other common nouns), this paradigm elicited
a positive parietal wave in the 600 ms window frame. They
argued that the P600 is an oddball delayed P300 component
elicited in a semantic oddball experiment to more complex
stimuli.
The alternative view states that there exist specific ERP
waves manifesting brain mechanisms of language
processing (Osterhout et al 1994, Frisch et al 2003). The late
positive wave P600 recorded in response to syntactically
anomalous words manifests specific brain mechanisms of
syntactic processing.

Acknowledgments
This work is part of the Ph.D. dissertation of the first author,
was supported by the Schupf scholarship. The study was
conducted in the Gonda Goldschmied Medical Diagnostic
Research Center. The authors also thank Shlomo Gilat for

Comparison between speech tasks: P300 latency to
target stimuli in the phonology word tasks was significantly
450

semantic and phonological processing with age: patterns
of fMRI activation. Aging, Neuropsychology and
cognition 8(4), 307-20.
Kareken D.A., Lowe M., Chen S.H., Lurito J., Mathews V.
(2000). Word rhyming as a probe of hemispheric
language dominance with functional magnetic resonance
imaging. Neuropsychiatry Neuropsychol Behav Neurol.
13(4), 264-70
Kayser J., Bruder G.E., Tenke C.E., Stuart B.K., Amador
X.F., Gorman J.M. (2001). Event-related brain potentials
(ERPs) in schizophrenia for tonal and phonetic oddball
tasks. Biol Psychiatry. 49(10), 832-47.
Kotchoubey B., Lang S. (2001). Event-related potentials in
an auditory semantic oddball task in humans. Neurosci
Lett. 14, 93-6.
Lovrich D., Novick B., Vaughan Jr. (1988). Topographic
analysis of auditory event-related potentials associated
with acoustic and semantic processing. EEG Clin
Neurophysiol 71, 40-54.
Martin B.A., Kurtzberg D., Stapells D.R.(1999). The effects
of decreased audibility produced by high pass noise
masking on N1 and the mismatch negativity to speech
sounds /ba/ and /da/. J Speech Lang Hear Res 42, 271-86.
Novick B., Lovrich D., Vaughan HG. (1985). Event-related
potentials associated with the discrimination of acoustic
and semantic aspects of speech. Neuropsychologia 23(1),
87-101.
Osterhout L., Holcomb P.J., Swinney D.A.(1994). Brain
potentials elicited by garden-path sentences: evidence of
the application of verb information during parsing. J Exp
Psychol Learn Mem Cogn. 4, 786-803.
Poldrack R.A., Wagner A.D., Prull M.W., Desmond J.E.,
Glover G.H., Gabrieli J.D. (1999). Functional
specialization for semantic and phonological
processing in the left inferior prefrontal cortex.
Neuroimage 10(1), 15-35.
Polich J.(1997). EEG and ERP assessment of normal aging.
Electroencephalog. Clin. Neurophysiol. 104, 244-256.
Thierry G., Doyon B., Demonet J.F. (1998). ERP mapping
in phonological and lexical semantic monitoring tasks: A
study complementing previous PET results. Neuroimage
8(4), 391-408
Tiitinen H., Sivonen P., Alku P., Virtanen J., Naatanen R.
(1999). Electromagnetic recordings reveal latency
differences in speech and tone processing in humans.
Brain Res. Cogn. Brain Res. 8(3), 355-63.
Woodward S.H., Owens J., Thompson L.W. (1990). Word
to word variation in ERP components latencies: spoken
words. Brain Lang 38, 488-503
Wunderlich J.L., & Cone-Wesson B.K. (2001). Effects of
stimulus frequency and complexity on the mismatch
negativity and other components of the cortical auditory
evoked potential. Acous. Soc Am. 109, 1526-36.
Zahn R., Huber W., Drews E., Erbrich S., Krings T.,
Willmes K., & Schwarz M. (2000). Hemispheric
lateralization at different levels of human auditory word
processing: a functional magnetic resonance imaging
study. Neurosci lett. 287, 195-198.

the technical assistance and Yury Kamenir for the statistical
analysis.

References
Alho K., Connolly J.F., Cheour M., Lehtokoski A.,
Huotilainen M., Virtanen J., Aulanko R., Ilmoniemi R.J.
(1998). Hemispheric lateralization in preattentive
processing of speech sounds. Neurosc. Lett. 258, 9-12.
Angrilli A., Dobel C., Rocksroch B., Stegagno L., Elbert T.
(2000). EEG brain mapping of phonological and semantic
tasks in Italian and German languages. Clin Neurophysiol.
111, 706-716.
Becker J.T., MacAndrew D.K., & Fiez J.A. (1999). A
comment on the functional localization of the
phonological storage subsystem of working memory.
Brain and Cognition 41, 27-38.
Bellis T.J., Nicol T., Kraus N. (2000). Aging affects
hemispheric asymmetry in the neural representation of
speech sounds. J. Neurosc. 15(5), 791-797.
Bentin S., Mouchetant-Rostaing Y., Giard M.H., Echallier
J.F., Pernier J. (1999). ERP manifestations of processing
printed words at different psycholinguistic levels: time
course and scalp distribution. J Cogn Neurosci. 11(3),
235-60.
Breier J.L., Simos P.G., Zouridakis G., Papanicolaou A.C.
(1999). Lateralization of cerebral activation in auditory
verbal and non verbal memory tasks using
magnetoencephalography. Brain Topogr. 12, 89-97.
Bruder G., Kayser J., Tenke C., Amador X., Friedman M.,
Sharif Z., Gorman J. (1999). Left temporal lobe
dysfunction in schizophrenia: event related potential and
behavioral evidence from phonetic and tonal dichotic
listening tasks. Arch. Gen. Psychiatry 56, 267-276.
Cobianchi A. and Giaquinto S. (1997): Event related
potentials in Italian spoken words. EEG Clin.
Neurophysiol. 104, 213-221.
Connolly J.F., Service E., D'Arcy R.C., Kujala A., Alho K.
(2001). Phonological aspects of word recognition as
revealed by high-resolution spatio-temporal brain
mapping. Neuroreport. 12(2), 237-43.
Coulson S., King J.W., Kutas M. (1998). ERPs and domain
specificity: beating a straw horse. Lang Cogn Proces
13(6), 653-72
Demonet J.F., Chollet F., Ramsay S., Cardebat D.,
Nespoulous J.L., Wise R., Rascol A., Frackowiak R.
(1992). The anatomy of phonological and semantic
processing in normal subjects. Brain 115, 1753-68.
Ferlazzo F., Conte S., Gentilomo A. (1993). Event-related
potentials and recognition memory within the 'levels of
processing' framework. Neuroreport 4(6), 667-70.
Frisch S., Kotz S.A., von Cramon D.Y., Friederici A.D.
(2003). Why the P600 is not just a P300: the role of the
basal ganglia. Clin Neurophysiol 114(2), 336-40.
Henkin Y., Kishon-Rabin L., Gadoth N., Pratt H. (2002).
Auditory event-related potentials during phonetic and
semantic processing in children. Audiol Neurootol. 7(4),
228-39.
Johnson S.C., Saykin A.J., Flashman L.A., McAllister T.W.,
O'Jile J.R., Sparling M.B., Guerin S.J., Moritz C.H., &
Mamourian A.C. (2001). Similarities and differences in
451

