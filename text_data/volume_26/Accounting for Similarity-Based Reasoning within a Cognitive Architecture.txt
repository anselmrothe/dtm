UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Accounting for Similarity-Based Reasoning within a Cognitive Architecture
Permalink
https://escholarship.org/uc/item/3689h9kn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Sun, Ron
Zhang, Xi
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Accounting for Similarity-Based Reasoning within a Cognitive
                                                     Architecture
                    Ron Sun (rsun@rpi.edu)                          Xi Zhang (xzf73@mizzou.edu)
                    Cognitive Sciences Department                              Department of CS
                   Rensselaer Polytechnic Institute                          University of Missouri
                         Troy, NY 12180, USA                              Columbia, MO 65211, USA
                          Abstract                              out of the very same model (albeit with a combination
                                                                of localist and distributed representations).
   This work explores the importance of similarity-based           The theory was backed up by psychological evidence
   processes in human everyday reasoning, beyond purely
   rule-based processes prevalent in AI and cognitive sci-      in the form of verbal protocols as in Collins (1978) and
   ence. A unified framework encompassing both rule-            Collins and Michalski (1989). In Sun (1995), these pro-
   based and similarity-based reasoning may provide ex-         tocols were analyzed based on two mechanisms: rules
   planations for a variety of human reasoning data.            and similarity (Tversky 1977, Hahn and Chater 1998).
   The paper implements this analysis in a cognitive ar-        The analysis showed that vast majority of the proto-
   chitecture Clarion, which has previously succeeded           col data might be easily captured by the intermixing
   in capturing a variety of human learning data in sim-
   ulations. The exploration of similarity-based reason-        of these two mechanisms. This theory was crystallized
   ing in this architecture leads to a more complete and        into a two-component model whereby rule-based reason-
   more comprehensive framework of human reasoning and          ing was carried out in one component with localist rep-
   learning. The simulation within this architecture accu-      resentation, and similarity-based reasoning in another
   rately captures human reasoning data, including numer-       with distributed representation (Sun 1995). Relevant to
   ical measures and verbal protocols. This work demon-
   strates the significant role played by similarity-based      this approach, Sloman (1993) published a set of experi-
   reasoning. Furthermore, it demonstrates how such a           ments, which provided support to the hypothesis of Sun
   reasoning process falls out of the existing structure in     (1991) (see also Sun 1995). He found that similarity
   the cognitive architecture Clarion.                          played a significant role in determining outcomes of in-
                                                                ductive reasoning and similarity might be characterized
                      Introduction                              by feature overlapping (as in Sun 1991). Five years later,
                                                                Sloman (1998) described further experiments that again
What is human everyday reasoning like? Is it suitably           supported the hypothesis that there were two parallel
captured by formal models developed by logicians and AI         mechanisms at work in human everyday reasoning (Sun
researchers? Or is it different? What are its similarities      1991).
and differences to these models? After all, computation-           In the remainder of this paper, we first describe the
ally speaking, what are the essential patterns in such          three pertinent experiments of Sloman (1998), which
reasoning?                                                      were consistent with the theory advanced in Sun (1991)
   In this paper, we will attempt to describe some data of      and Sun (1995). We then describe the generic cognitive
human everyday (i.e., mundane or “commonsense”) rea-            architecture, Clarion, used in capturing human every-
soning in computational terms. We will instantiate our          day reasoning. Next, the particular setup of the archi-
analysis in the form of a computational model imple-            tecture for capturing this set of human experiments is
mented in a generic cognitive architecture — Clarion            described. We then describe the results from simulat-
(Sun 2002).                                                     ing the experiments of Sloman (1998) using Clarion.
   A little background is in order here. Sun (1991) pro-        Finally, some general discussion completes the paper.
posed a theory of human everyday reasoning based on a
combination of rule-based reasoning and similarity-based
reasoning, implemented with a mixture of localist and
                                                                        The Categorical Inference Task
distributed connectionist models. This theory was fur-          Let us examine some human reasoning data that illus-
ther developed and elaborated in Sun (1995). The basic          trates combinations of similarity-based and rule-based
tenet of this theory is that, to a significant extent, human    reasoning (SBR and RBR, respectively). We will look
everyday reasoning may be described by a combination            into the data from experiments 1, 2, 4, and 5 of Sloman
of rule-based and similarity-based reasoning. Human ev-         (1998), which are most relevant to this issue.
eryday reasoning may be reduced to these two types of              Among them, according to our interpretation, al-
processes. The intermixing of rule-based and similarity-        though experiment 1 used forced choice while experiment
based reasoning can lead to complex patterns of infer-          2 used rating of argument strength, both involved SBR
ences as commonly observed in human everyday reason-            to a very significant extent. Experiment 4 involved ex-
ing. And these two types of processes may be captured           plicit use of categorical relations, and thus mainly RBR.
within a unified connectionist model; that is, they fall        Experiment 5 involved more of SBR, as well as RBR.
                                                            1297

                                                                                                     Top Level
   Specifically, in experiment 1, subjects were given pairs
of arguments, either in the form of premise specificity:                  action−centered                       non−action−centered
                                                                          explicit representation               explicit representation
   a. All flowers are susceptible to thrips. =⇒ All roses
   are susceptible to thrips.                                             action−centered implicit               non−action−centered
                                                                                                modules
   b. All plants are susceptible to thrips. =⇒ All roses                                                         implicit representation
   are susceptible to thrips.
or in the form of inclusion similarity:
   a. All plants contain bryophytes. =⇒ All flowers                                                Bottom Level
   contain bryophytes.
   b. All plants contain bryophytes. =⇒ All mosses                      Figure 1: The CLARION architecture.
   contain bryophytes.
Subjects were to pick the stronger of the two arguments        gave 0.99 throughout). In other words, the similarity-
from each pair. 73 subjects were tested and each was           based phenomena almost disappeared. Instead, an ex-
given 18 pairs of arguments (among other things not            plicit RBR mode based on category inclusion relations
related to this task).                                         was used.
   The results showed that the more similar argument              Experiment 5 was similar to experiment 2, in that rat-
from each pair of arguments was chosen 82% of times (for       ings were obtained. However, before any ratings were
inclusion similarity) and 91% of times (for premise speci-     done, subjects were asked to make category inclusion
ficity). t tests showed that these percentages were signif-    decisions. Thus, in this case, subjects were reminded of
icantly above chance, either by subjects (t(72) = 18.64        rule-based reasoning explicitly involving category inclu-
and t(72) = 33.09 for premise specificity and inclusion        sion relations. Therefore, they were more likely to use
similarity, respectively; p < 0.0001) or by argument pairs     RBR, although probably not as much as in experiment 4,
(t(8) = 6.97 and t(8) = 15.61 respectively; p < 0.0001).       due to the separation of category inclusion judgment and
We note that, if only RBR had been used, then sim-             argument likelihood rating in the experiment procedure
ilarity should not have made a difference, because the         (unlike that of experiment 4).
conclusion category was contained in the premise cate-            The results showed that no one of the 18 subjects gave
gory and thus both arguments in each pair should have          a likelihood judgment of 1 for every argument, indicating
been equally, perfectly strong. Therefore, the data sug-       SBR was probably at work. Compared with experiment
gest that SBR was involved to a significant extent.            2, having subjects make category inclusion judgments
   In experiment 2, subjects were instead asked to rate        increased the likelihood ratings. The mean judgment for
the likelihood (“conditional probability”) of each argu-       experiment 5 was 0.92 as opposed to 0.87 for experiment
ment. Ratings could range from 0 to 1. 18 subjects were        2. 1 This increase might reflect the increased involve-
tested.                                                        ment of RBR. Nevertheless, ANOVA showed a signifi-
   The mean rating was 0.89 for inclusion similarity and       cant effect of similarity (low vs. high), across subjects
0.86 for premise specificity. Both were significantly be-      (F (1, 17) = 9.33, p < 0.01), and across argument pairs
low 1, both by subjects (t(17) = 2.75 and t(17) = 3.23         (F (1, 16) = 11.42, p < 0.01).
respectively; p < 0.01), and by arguments (t(17) = 8.87           Below, we will utilize this task of categorical inference
and t(17) = 6.14 respectively; p < 0.0001). Again we           for the further testing of cognitive architecture Clarion.
note that it would have been the case that the out-            The simulation shows indications of the significance of
come was 1 if only RBR had been used (because the              similarity-based reasoning (as opposed to probabilistic
conclusion category was contained in the premise cat-          or Bayesian reasoning; cf. Anderson and Lebiere 1998).
egory). Thus, SBR was significantly present here too.
Indeed, ANOVA showed that across subjects, there was                                 The Clarion Model
a significant main effect of similarity (low vs. high;
F (1, 17) = 18.90, p < 0.001). So was the case across          Clarion is an integrative model with a dual represen-
argument pairs (F (1, 16) = 12.64, p < 0.001).                 tational structure (Sun et al 2001, Sun 2002). It consists
   In experiment 4, subjects were asked to rate the like-      of two levels: the top level captures explicit processes
lihood of each argument. Ratings could range from 0 to         and the bottom level captures implicit processes. See
1. However, in this case, each category inclusion relation     Figure 1.
was specifically presented as part of each argument. For          First, the inaccessible nature of implicit knowledge is
example,                                                       suitably captured by subsymbolic distributed represen-
                                                               tations provided by a backpropagation network. This
   All plants contain bryophytes. All mosses are               is because representational units in a distributed rep-
   plants. =⇒ All mosses contain bryophytes.                   resentation are capable of accomplishing tasks but are
The results showed that the mean judgment was 0.99. 23             1
                                                                     However, the difference was not statistically significant
out of 27 subjects gave all 1’s. 32 out of 36 arguments re-    by subjects, although significant by arguments (t(35) =
ceived judgments of all 1’s (excluding one individual who      3.81, p < 0.0001).
                                                           1298

subsymbolic and generally not individually meaningful            where j indicates the jth rule at the top level, Sja is the
(see Smolensky 1988, Sun 1995). This characteristic of           support for associative rule j, Sic is the strength of the
distributed representation accords well with the (direct)        ith chunk in the condition of the rule, i ranges over all
inaccessibility of implicit knowledge.                           the chunks in the condition of rule j, Wia is the weight
   In contrast, explicit knowledge may be captured in            of the ith chunk in the condition of rule j (which, by
computational modeling by a symbolic or localist rep-            default, is Wia = 1/n, where n is the number of chunks
resentation (Clark and Karmiloff-Smith 1993), in which           in the condition of the rule).
each unit is more easily interpretable and has a clearer            The conclusion chunk has a strength level that is de-
conceptual meaning. This characteristic captures the             termined by the maximum of all the support from all the
property of explicit knowledge being (directly) more ac-         relevant rules:
cessible and more manipulable (Smolensky 1988, Sun
1995).                                                                   Scck =                      max                  Sja  (2)
                                                                                 j:all associative rules leading to ck
   This radical difference in the representations of the two
types of knowledge leads to a two-level model whereby            where Scck is the strength of chunk ck (resulting from
each level using one kind of representation captures one         associative rules), and j ranges over all the associative
corresponding type of process, either implicit or explicit.      rules pointing to ck .
The model may select to use one level or the other, based           In addition, similarity-based reasoning falls out of
on current circumstances (e.g., experimental conditions;         knowledge encoding with chunks (i.e., with sets of
see Sun 2002 for details). When both levels are used,            dimension-value pairs). A known (given or inferred)
the outcome from the two levels may be combined in               chunk is automatically compared with another chunk.
some ways, which may be partially domain specific (Sun           If their similarity is high enough, then the other chunk
2002).                                                           is inferred. The strength of a chunk ci as the result of
   At each level of the model, there may be multiple             similarity-based reasoning is:
modules, both action-centered modules and non-action-
centered modules (Schacter 1990, Moscovitch and Umilta                               Scci = max(Scj ∼ci × Sccj )
                                                                                                j
1991). The reason for having both action-centered
and non-action-centered modules (at each level) is be-           where Scj ∼ci measures the similarity from cj to ci (Tver-
cause, as it should be obvious, action-centered knowl-           sky 1977), Scj ∼ci × Sccj measures the support to ci from
edge (roughly, procedural knowledge) is not necessarily          the similarity, and j ranges over all the chunks.
inaccessible (directly), and non-action-centered knowl-             The default similarity measure (Sun 1995, Tversky
edge (roughly, declarative knowledge) is not necessar-           1977) is:
ily accessible (directly). Although it was argued by                                                  Nc1 ∩c2
some that all procedural knowledge is inaccessible di-                                     Sc1 ∼c2 =
                                                                                                      f (Nc2 )
rectly and all declarative knowledge is directly accessi-
ble, such a clean mapping of the two dichotomies is un-          where Sc1 ∼c2 denotes the similarity from c1 to c2 . Nc1 ∩c2
tenable in our view. We will refer to these two sets of          is the weighted sum of the identically valued dimensions
modules as the action-centered subsystem (the ACS) and           in c1 and c2 (among all the specified dimensions of c2
the non-action-centered subsystem (the NACS), respec-            — the dimensions
                                                                              P           that have specified values). That is,
tively. There are also other components, such as working         Nc1 ∩c2 = i∈c2 ∩c1 Wic2 × Ai , where Ai is the strength
memory, episodic memory, etc., which are not important           of the value of dimension i in chunk c1 , which is nor-
to this work.                                                    mally 1 (representing full strengths). The weights (Wic2 )
   In this work, we will focus on the NACS, due to the           in the weighted sum are specified with respect to c2
declarative nature of the task. This subsystem, as stated        (the target of similarity, not the source of it). Nor-
earlier, consists of (1) a top level (known as the GKS, or       mally, these weights are the same and equal to 1. Nc2 is
the general knowledge store), which is made up of a set          the weighted sum of the specified dimensions (the di-
of chunks and a set of explicit associative rules linking        mensions  Pthat have        specified values) of c2 . That is,
                                                                                       c2
chunks, and (2) a bottom level (known as the AMNs, or            N c2 =       i∈c2 Wi × Ai , where normally Ai = 1 and
the associative memory networks), which is made up of            Wic2 = 1. f is a super-linear, but close to linear, func-
implicit associative memories (Sun 2002).                        tion (such as f (x) = x1.0001 as in our simulation of this
   At the top level of the NACS, the essential ele-              task). 2 For further details, see Sun (1995).
ments are chunks, each of which is specified by a set               Similarity is automatically computed whenever rea-
of dimension-value pairs (i.e., attribute-value pairs) that      soning involves multiple chunks that are similar to one
describes an entity (or an object), along with a chunk la-       another. Therefore, there is no dedicated representation
bel. Each chunk is represented by a chunk node, which is         of similarity between any two chunks.
linked to the nodes at the bottom level (the AMNs) rep-             Similarity-based and rule-based reasoning can be
resenting the individual dimension-value pairs involved.         inter-mixed. When both SBR and RBR are employed,
   The support for the conclusion of an associative rule,        we have:
which is a chunk, is calculated as follows (Sun 1994):                   Scci = max(c14 ×                 max            Sja ,
                            X                                                                  j:all rules leading to ci
                      Sja =     Sic ∗ Wia                 (1)        2
                             i
                                                                       Similarity is thus limited to [0, 1).
                                                             1299

       c15 ×            max             (Scj ∼ci × Sccj ))     by the human data. For simulating experiment 5, they
             j:all chunks similar to ci                        were set at c14 = 0.88, c15 = 1.0, because the experi-
where c14 and c15 are two constants that balance the           ment involved an intermediate level of reliance on RBR
two measures (rule versus similarity), and Scj ∼ci is the      as suggested by the human data. In all, these values
similarity measure.                                            were set in accordance with our interpretations of what
   As a result of mixing SBR and RBR, complex patterns         happened under these different experimental conditions
of reasoning can emerge. As explicated in Sun (1995),          respectively.
the conclusion from one step of reasoning can be used as          At the bottom level of the NACS (the AMNs), al-
the starting point of the next step. The iterative process     though the associative memories were present, they were
of combined rule-based and similarity-based reasoning          not very relevant for the performance of this task, be-
allows all possible conclusions to be reached (including       cause there was no sufficient prior training of the network
“inheritance” reasoning; Sun 1995). These different se-        with any data directly relevant to this task. 3
quences together capture essential patterns of human ev-          Training of the model, before the simulation of the
eryday reasoning (see Sun 1995 for details).                   experimental test, consisted of presenting categorical
   Note that all of the operations of the non-action-          features (dimension-value pairs) along with the cate-
centered subsystem are under the control of the action-        gory labels, to both levels of the NACS. The features
centered subsystem, which makes action decisions each          (dimension-value pairs) captured similarities between
step of the way. To do so, the top level of the ACS con-       entities. That is, if A was more similar to C than B
sists of a set of explicit action rules, either externally     was, then A would have more features in common with
given or extracted from the bottom level (from implicit        C than B would. And so on. Note that repeated pre-
knowledge), while the bottom level consists of implicit        sentations were not required. The one-pass presentation
decision networks (trained with reinforcement learning         enabled the formation of chunks and associative rules in
algorithms, negligible in this task). For details regard-      the GKS, but not much implicit knowledge in the AMNs.
ing the ACS and its parameters, see Sun et al (2001) and       With a proper process of chunk encoding and associative
Sun (2002). We will not get into these details here, as        rule encoding as in Clarion, one-pass presentation was
they are not directly relevant to this work.                   sufficient for the GKS.
   It is worth noting that Clarion has been successful            During test, when a category name was given, the cat-
in simulating a variety of cognitive tasks. These tasks in-    egory name was matched with a corresponding chunk
clude serial reaction time tasks, artificial grammar learn-    label. The matching chunk was activated to the full
ing tasks, process control tasks, alphabetical arithmetic      extent (i.e., 1). Then, through associative rules as well
tasks, and the Tower of Hanoi task (Sun 2002, Sun and          as through similarity-based processes, conclusion chunks
Zhang 2004). In addition, we have done extensive work          were also activated (to varying extents). Conclusion
on a complex minefield navigation task (Sun et al 2001,        chunks were retrieved along with their strengths, com-
Sun and Peterson 1998). We are now in a good position          bining SBR and RBR according to the balancing param-
to extend the effort to the capturing of a wide range of       eters.
human reasoning and memory processes, through simu-               For simulating ratings of conclusions (as in experi-
lating reasoning and memory task data. This paper is           ments 2, 4, and 5), the strengths of chunks derived from
but one aspect of this effort.                                 a proper combination of the results of SBR and RBR (as
                                                               determined by the balancing parameters) were directly
                    Simulation Setup                           used. However, for simulating forced choices (as in ex-
                                                               periment 1), a stochastic decision process based on the
At the top level of the NACS (i.e., the GKS), all relevant     Boltzmann distribution was used to select between two
category inclusion relations, such as “flowers are plants”     possible outcomes.
or “mosses are plants”, were encoded as associative rules.
Chunk nodes in the GKS were used to represent the                                Simulation Results
concepts involved, such as “flowers” and “plants”. The
dimensional values of these chunks were represented as         We simulated the data from experiments 1, 2, 4, and 5 of
separate nodes in the AMNs, and thus the chunk nodes           Sloman (1998) as described earlier. For each experiment,
were linked to the AMNs.                                       a set of simulation runs (i.e., simulated “subjects”) equal
   For simulating various experimental settings, the fol-      to the number of the human subjects involved were used.
lowing manipulations were used: For simulating settings        The results and the statistical analysis of the results were
where SBR was dominant, RBR was de-emphasized. For             as follows.
simulating settings where RBR was dominant, RBR was               As described before, in experiment 1, subjects were to
emphasized. The relative emphasis of the two methods           pick the stronger of the two arguments from each pair.
was accomplished through the balancing parameters. We          The simulation of experiment 1 showed, the same as the
set c14 = 0.5 and c15 = 1.0 for experiments 1 and 2, be-       human data, that the more similar argument from each
cause of the heavy reliance on SBR as opposed to RBR              3
as suggested by the analysis of the human data (see the             For the associative memory network, the number of input
                                                               units was 1800 (for representing all chunks specifiable with 60
earlier discussion of the human data). For simulating ex-      dimensions of 30 possible values each), the number of hidden
periment 4, they were set at c14 = 1.0, c15 = 1.0, because     units was 500, and the number of output units was 1800. The
this setting prompted more reliance on RBR as indicated        learning rate was 0.2 and the momentum was 0.1.
                                                           1300

pair of arguments was chosen more often: 82% of times                            Concluding Remarks
(for inclusion similarity) and 83% of times (for premise
                                                                 Overall, the simulation accurately captured the human
specificity). t tests showed that these percentages were
                                                                 reasoning data from Sloman (1998). The simulation was
significantly above chance, either by subjects (p < 0.001)
                                                                 conducted based on our framework of mixed rule-based
or by argument pairs (p < 0.001), the same as in the
                                                                 reasoning and similarity-based reasoning, which, along
human data. In our simulation setup, there was a sig-
                                                                 with other simulations published elsewhere (e.g., Sun
nificant involvement of SBR (with c14 = 0.5, c15 = 1.0).
                                                                 1995, 2002, Sun et al 2001, Sun and Zhang 2004), showed
If only RBR had been used, then similarity could not
                                                                 the cognitive plausibility of the Clarion architecture to
have made a difference, and thus both arguments in a
                                                                 some extent.
pair should have been equally strong. This simulation
                                                                    This simulation demonstrates the importance of
demonstrated that the conjecture of the involvement of
                                                                 similarity-based reasoning in human everyday reasoning.
SBR in producing the human data in this experiment
                                                                 This similarity-based process is quite distinct from prob-
was a reasonable interpretation (see the earlier exposi-
                                                                 abilistic reasoning as implemented in other existing cog-
tion of the human experiments), given the close match
                                                                 nitive architectures, such as ACT-R (see Anderson 1993
with the human data.
                                                                 or Anderson and Lebiere 1998). Let us compare the two
   In experiment 2, subjects were instead asked to rate          different approaches. ACT-R as described in Anderson
the likelihood of each argument. In this simulation, the         and Lebiere (1998) tries to capture all inferences in a
mean rating was 0.86 for inclusion similarity and 0.87 for       probabilistic framework. In so doing, it lumps together
premise specificity. Both were significantly below 1, dif-       all forms of weak inferential connections in a unified way.
ferent from what would have been predicted if only RBR           Although this approach leads to uniformity, it has short-
had been used, both by subjects (p < 0.001) and by ar-           comings as well. All similarity relations between any pair
guments (p < 0.001), the same as in the human data.              of any two objects must be explicitly represented with
ANOVA also showed that across subjects and across ar-            all the associated parameters, which specify probabilis-
gument pairs, there was a significant main effect of simi-       tic computation used to capture similarity-based reason-
larity (low vs. high; p < 0.001). With the same setup as         ing (along with other inexact inferences). The problem
the previous simulation, this simulation again demon-            is the complexity of representing all similarity pairings.
strated the same pattern of significant involvement of           This complexity is very high in ACT-R but in contrast
SBR in the human performance.                                    is avoided in Clarion.
                                                                    The limitations of probabilistic reasoning (Pearl 1988)
   In experiment 4, subjects were asked to rate the like-        in general include its neglect of many heuristics, simpli-
lihood of each argument, right after being presented             fications, and rules of thumb (Tversky and Kahneman
relevant category inclusion relations. The simulation            1983, Sun 1995, Yang and Johnson-Laird 2001) useful in
produced the mean judgment 0.99, exactly the same as             reducing the computational complexity of formal math-
the human data. Compared with experiment 2, explicit             ematical models. As a result, it suffers from higher com-
RBR based on category inclusion was much more promi-             putational complexity (Sun 1995).
nent in this case, as specified in our simulation setup             We should also look into the framework of Collins
(c14 = 1.0, c15 = 1.0), which captured the human data            and Michalski (1989), which apparently incorporated
accurately.                                                      “similarity-based” reasoning through explicitly repre-
                                                                 senting similarity in a complex logical formalism. Sim-
   In experiment 5, ratings were obtained after subjects         ilarity was explicitly represented as a logical operator:
were asked to make category inclusion decisions. In this         That is, for almost any pair of any two objects, there
case, subjects were reminded of RBR involving category           would be a logical relation explicitly represented, denot-
inclusion relations and therefore they were more likely to       ing their similarity. Inferences could be performed on
use RBR (compared with experiment 2), although not               the basis of similarity operators, using a search process.
exclusively (unlike experiment 4). In the simulation, the        The complexity of this representational framework was
mean judgment for experiment 5 was 0.91 for both in-             extremely high.
clusion similarity and premise specificity, as opposed to           In general, logic-based models suffer from a number of
0.86 and 0.87 for the two cases in experiment 2. ANOVA           well known shortcomings, including their restrictiveness
also showed a significant main effect of similarity (low vs.     concerning pre-conditions, consistency, and correctness,
high), across subjects (p < 0.001), and across argument          and their inability in dealing with inexactness (see, e.g.,
pairs (p < 0.001). This simulation replicated the human          Israel 1987, Sun 1995). Their restrictiveness renders such
data well, which showed that our interpretation as em-           models costly, difficult to specify, and difficult to use.
bodied in the simulation setup (c14 = 0.88, c15 = 1.0),             In a different vein, psychological work on reasoning is
that is, less involvement of RBR compared with exper-            relevant also. Such work mostly centers around either
iment 4 but more compared with experiment 2, was a               mental logic (Rips 1994, Braine and O’Brien 1998) or
reasonable one.                                                  mental models (Yang and Johnson-Laird 2001). Neither
                                                                 approach deals with similarity-based reasoning as cap-
   In all, simulation of this task successfully validated the    tured in Clarion. Their focuses are elsewhere.
interpretation and the analysis of human performance in             In sum, this line of work, combining similarity-based
this task and, to some extent, our framework in general.         reasoning and rule-based reasoning (Sun 1995, Sloman
                                                             1301

1998, Hahn and Chater 1998), offers a new approach           S. Sloman, (1993). Feature based induction. Cognitive
for capturing some essential patterns of human every-        Psychology, 25, 231-280.
day reasoning (albeit not all patterns of human reason-      S. Sloman, (1998). Categorical inference is not a tree:
ing). It complements logic-based “commonsense” rea-          The myth of inheritance hierarchies. Cognitive Psychol-
soning models prevalent in AI, which is very much cen-       ogy, 35, 1-33
tered on logic and thus limited by logic. This work also
points to new avenues of cognitive modeling, beyond the      P. Smolensky, (1988). On the proper treatment of con-
current psychology of reasoning (which largely focuses       nectionism. Behavioral and Brain Sciences, 11 (1), 1-74.
on various logics and mental models) and beyond exist-       R. Sun, (1991). Connectionist models of rule-based
ing cognitive architectures (Anderson and Lebiere 1998).     reasoning. Proceedings of the 13th Cognitive Science
In addition, this approach may well be extended to case-     Conference, pp.437-442. Lawrence Erlbaum Associates,
based and/or analogical reasoning (e.g., Sun 1995a).         Hillsdale, NJ.
                                                             R. Sun, (1995). Robust reasoning: Integrating rule-
                  Acknowledgment                             based and similarity-based reasoning. Artificial Intel-
This work has been supported in part by Army Research        ligence. 75, 2. 241-296.
Institute contract DASW01-00-K-0012 to Ron Sun and           R. Sun, (1995a). A microfeature based approach to-
Bob Mathews.                                                 ward metaphor interpretation. Proceedings of the In-
                                                             ternational Joint Conference on Artificial Intelligence
                      References                             (IJCAI-95). Montreal, Canada. pp.424-430, Morgan
J. R. Anderson, (1993). Rules of the Mind. Lawrence          Kaufmann, San Francisco, CA.
Erlbaum Associates. Hillsdale, NJ.                           R. Sun, (2002). Duality of the Mind. Lawrence Erlbaum
J. Anderson and C. Lebiere, (1998). The Atomic Compo-        Associates, Mahwah, NJ.
nents of Thought, Lawrence Erlbaum Associates, Mah-          R. Sun, E. Merrill, and T. Peterson, (2001). From im-
wah, NJ.                                                     plicit skills to explicit knowledge: A bottom-up model of
M. Braine and D. O’Brien (eds.), (1998). Mental Logic.       skill learning. Cognitive Science. Vol.25, No.2, 203-244.
Lawrence Erlbaum Associates, Mahwah, NJ.                     R. Sun and T. Peterson, (1998). Autonomous learning
A. Clark and A. Karmiloff-Smith, (1993). The cognizer’s      of sequential tasks: experiments and analyses. IEEE
innards: a psychological and philosophical perspective       Transactions on Neural Networks, Vol.9, No.6, pp.1217-
on the development of thought. Mind and Language. 8          1234.
(4), 487-519.                                                R. Sun and X. Zhang, (2004). Top-down versus bottom-
A. Collins, (1978). Fragments of a theory of human plau-     up learning in cognitive skill acquisition. Cognitive Sys-
sible reasoning. In: D.Waltz (ed.), Theoretical Issues in    tems Research, Vol.5, No.1, pp.63-89.
Natural Language Processing II, 194-201. Ablex, Nor-         Y. Yang and P. Johnson-Laird, (2001). Mental models
word, NJ.                                                    and logical reasoning problems in the GRE. Journal of
                                                             Experimental Psychology: Applied, 7 (4), 308-316.
A. Collins and R. Michalski, (1989). The logic of plau-
sible reasoning. Cognitive Science, 13(1), 1-49.             A. Tversky, (1977). Features of similarity. Psychological
                                                             Review, 84(4), 327-352.
E. Davis, (1990). Representations of Commonsense
Knowledge. Morgan Kaufman, San Mateo, CA.                    A. Tversky and D. Kahneman, (1983). Extensional ver-
                                                             sus intuitive reasoning: The conjunction fallacy in prob-
U. Hahn and N. Chater, (1998). Similarity and rules:
                                                             ability judgment. Psychological Review, 439-450.
distinct? exhaustive? empirically distinguishable? Cog-
nition, 65, 197-230.
D. Israel, (1987). What’s wrong with non-monotonic
logic? In: Ginsberg (ed.), Readings in Non-monotonic
Reasoning, pp.53-55, Morgan Kaufman, San Mateo, CA.
M. Moscovitch and C. Umilta, (1991). Conscious and
unconscious aspects of memory. In: Perspectives on Cog-
nitive Neuroscience. Oxford University Press, New York.
J. Pearl, (1988). Probabilistic Reasoning in Intelligent
Systems. Morgan Kaufman, San Mateo, CA.
L. Rips, (1994). The Psychology of Proof. MIT Press,
Cambridge, MA.
D. Schacter, (1990). Toward a cognitive neuropsychol-
ogy of awareness: implicit knowledge and anosagnosia.
Journal of Clinical and Experimental Neuropsychology.
12 (1), 155-178.
                                                         1302

