UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Variability is the spice of learning, and a crucial ingredient for detecting and generalizing in
nonadjacent dependencies
Permalink
https://escholarship.org/uc/item/4558716n
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Onnis, Luca
Monaghan, Padraic
Christiansen, Morten H.
et al.
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                      Powered by the California Digital Library
                                                                         University of California

                                         Variability is the spice of learning, and
     a crucial ingredient for detecting and generalizing in nonadjacent dependencies
                                                    Luca Onnis (lo35@cornell.edu)
                                 Department of Psychology, Cornell University, Ithaca, NY 14853, USA
                                       Padraic Monaghan (P.Monaghan@psych.york.ac.uk)
                                 Department of Psychology, University of York, York, YO10 5DD, UK
                                           Morten H. Christiansen (mhc27@cornell.edu)
                                 Department of Psychology, Cornell University, Ithaca, NY 14853, USA
                                             Nick Chater (nick.chater@warwick.ac.uk)
    Institute for Applied Cognitive Science and Department of Psychology, University of Warwick, Coventry, CV47AL, UK
                               Abstract                                  dusty). The presence of embedding and nonadjacent
                                                                         relationships in language was a point of serious difficulty
   An important aspect of language acquisition involves learning         for early associationist approaches. It is easy to see that a
   the syntactic nonadjacent dependencies that hold between              distributional mechanism computing solely neighbouring
   words in sentences, such as subject/verb agreement or tense
                                                                         information would parse the above sentence as …*the shelf
   marking in English. Despite successes in statistical learning of
   adjacent dependencies, the evidence is not conclusive for
                                                                         is dusty. Despite the importance of detecting remote
   learning nonadjacent items. We provide evidence that                  dependencies, we know relatively little about the conditions
   discovering nonadjacent dependencies is possible through              under which this skill may be acquired by statistical means.
   statistical learning, provided it is modulated by the variability               In this paper, we present results using the Artificial
   of the intervening material between items. We show that               Language Learning (ALL) paradigm designed to test
   generalization to novel syntactic-like categories embedded in         learning of nonadjacent dependencies in adult participants.
   nonadjacent dependencies occurs with either zero or large             We suggest that a single statistical mechanism might
   variability. In addition, it can be supported even in more            underpin two language learning abilities: detection of
   complex learning tasks such as continuous speech, despite
                                                                         nonadjacencies and abstraction of syntactic-like categories
   earlier failures.
                                                                         from nonadjacent distributional information.
                                                                                   Despite the fact that both infants and adults are
                           Introduction
                                                                         able to track transitional probabilities among adjacent
Statistical learning – the discovery of structural                       syllables (Saffran, Aslin, & Newport, 1996), tracking
dependencies through the probabilistic relationships                     nonadjacent probabilities, at least in uncued streams of
inherent in the raw input – has long been proposed as a                  syllables, has proven elusive in a number of experiments
potentially important mechanism in language development                  and the evidence is not conclusive (Newport & Aslin, 2004;
(e.g. Harris, 1955). Efforts to employ associative                       Onnis, Monaghan, Chater, & Richmond, submitted; Peña,
mechanisms for language learning withered during                         Bonatti, Nespor, & Mehler, 2002). Thus, a serious empirical
following decades in the face of theoretical arguments                   challenge for statistical accounts of language learning is to
suggesting that the highly abstract structures of language               show that a distributional learner can learn dependencies at
could not be learned from surface level statistical                      a distance. Previous work using artificial languages (Gómez,
relationships (Chomsky, 1957). Recently, interest in                     2002) has shown that the variability of the material
statistical learning as a contributor to language development            intervening between dependent elements plays a central role
has reappeared as researchers have begun to investigate how              in determining how easy it is to detect a particular
infants might identify aspects of linguistic units such as               dependency. Learning improves as the variability of
words, and to label them with the correct linguistic abstract            elements that occur between two dependent items increases.
category such as VERB. Much of this research has focused                 When the set of items that participate in the dependency is
on tracking dependencies between adjacent elements.                      small relative to the set of elements intervening, the
However, certain key relationships between words and                     nonadjacent dependencies stand out as invariant structure
constituents are conveyed in nonadjacent (or remotely                    against the changing background of more varied material.
connected) structure. In English, linguistic material may                This effect also holds when there is no variability of
intervene between auxiliaries and inflectional morphemes                 intervening material shared by different nonadjacent items,
(e.g., is cooking, has traveled) or between subject nouns and            perhaps because the intervening material becomes invariant
verbs in number agreement (the books on the shelf are                    with respect to the variable dependencies (Onnis,
                                                                     1047

Christiansen, Chater, & Gómez, 2003). In natural language,         separated by highly variable material (am cooking, a m
different structural long-distance relationships such as           working, am going, etc.). Such sequential asymmetrical
singular and plural agreement between noun and verb may            properties of natural language may help learners solve two
in fact be separated by the same material (e.g. the books on       complex tasks: a) building syntactic constructions that
the shelf are dusty versus the book on the shelf is dusty). We     sequentially span one or several words; b) building relevant
call the combined effects of zero and large variability the        abstract syntactic categories for a broad range of words in
variability hypothesis.                                            the lexicon that are distributionally embedded in such
             Very similar ALL experiments tested have failed to    nonadjacent relationships. Frequent nonadjacent
show generalization from statistical information unless            dependencies are fundamental to the process of
additional perceptual cues such as pauses between words            progressively building syntactic knowledge of, for instance,
                                                                   tense marking, singular and plural markings, etc. For
were inserted, suggesting that a distributional mechanism
                                                                   instance, Childers & Tomasello (2001) tested the ability of
alone is too weak to support abstraction of syntactic-like
                                                                   2-year-old children to produce a verb-general transitive
categories. On these grounds Peña et al. (2002) have argued        utterance with a nonce verb. They found that children were
that generalization necessitates a rule-based computational        best at generalizing if they had been mainly trained on the
mechanism, whereas speech segmentation relies on lower-            consistent pronoun frame He`s VERB-ing it (e.g., He`s
level statistical computations. However, these experiments         kicking it, He`s eating it ) rather than on several utterances
tested nonadjacency learning and embedding generalization          containing unsystematic correlations between the agent and
with low variability of embedded items, which we contend           the patient slots (Mary`s kicking the ball, John`s pushing the
is consistent with the variability hypothesis that learning        chair, etc.).
should be hard. Our aim is to show that at the end-points of                 Gómez (2002) found that the structure of sentences
the variability continuum, i.e. with either no or large            of the form A iXjBi, where there were three different A i_Bi
variability, generalization becomes possible. In Experiment        pairs, could in fact be learned provided there was sufficient
1, we present results suggesting that both detection of            variability of Xj words. The structure was learned when 24
nonadjacent frames and generalization to the embedded              different Xs were presented, but participants failed to learn
items are simultaneously achieved when either one or a             when Xs varied from sets of 2, 4, 6, or 12, i.e. with low
large number of different type items are shared by a small         variability. Onnis et al. (2003) replicated this finding and
number of highly frequent and invariant frames. In                 also found that learning occurred with only one X being
Experiment 2 we also investigate whether tracking                  shared, suggesting the nonadjacent structure would stand
nonadjacent dependencies can assist speech segmentation            out again, this time as variant against the invariant X.
and generalization simultaneously, given the documented                      While Gómez interpreted her results as a learning
bias for segmenting speech at points of lowest transitional        bias towards what changes versus what stays invariant, thus
probability (Saffran et al. 1996a,b).                              leading to “discard” the common embeddings in some way,
                                                                   we argue here that there may be a reversal effect in noting
             We conclude that adult learners are able to track
                                                                   that common elements all share the same contextual frames.
both adjacent and nonadjacent structure, and the success is
                                                                   If several words – whose syntactic properties and category
modulated by variability. This is consistent with the              assignment are a priori unknown – are shared by a number
hypothesis that a learning mechanism uses statistical              of contexts, then they will be more likely to be grouped
information by capitalizing on stable structure for both           under the same syntactic label, e.g. VERB. For instance,
pattern detection and generalization (Gómez, 2002, Gibson,         consider a child faced with discovering the class of words
1991).                                                             such as break, drink, build. As the words share the same
                                                                   contexts below, s/he may be driven to start extracting a
               Generalising under variability                      representation of the VERB class (Mintz, 2002):
The words of natural languages are organized into
categories such as ARTICLE, PREPOSITION, NOUN,                               I am-X-ing
VERB, etc., that form the building blocks for constructing                   dont-X-it
sentences. Hence, a fundamental part of a language                           Lets-X-now!
knowledge is the ability to identify the category to which a
specific word, say apple, belongs and the syntactic                Mintz (2002) argued that most importantly, in hearing a new
relationships it holds with adjacent as well as nonadjacent        word in the same familiar contexts, for instance eat in am-
words. Two properties of word class distribution appear            eat-ing, the learner may be drawn to infer that the new word
relevant for a statistical learner. First, closed class words      is a VERB. Ultimately, having categorized in such a way,
like articles and prepositions typically involve highly            the learner may extend the usage of eat as a VERB to new
frequent items belonging to a relatively small set (am, the, -     syntactic constructions in which instances of the category
i n g , - s , are) whereas open class words contain items          VERB typically occur. For instance s/he may produce a
belonging to a very large set (e.g. nouns, verbs, adjectives).     novel sentence Lets-eat-now! Applying a category label to
Secondly, Gómez (2002) noted that sequences in natural             an word (e.g. eat belongs to VERB) greatly enhances the
languages involve members of the two broad categories              generative power of the linguist system, because the labeled
being interspersed. Crucially, this asymmetry translates into      item can now be used in new syntactic contexts where the
patterns of highly invariant nonadjacent items, or frames,         category applies. In Experiment 1 we tested whether
                                                               1048

generalization to new X items in the A_X_B artificial              questions relating to the sentences after the listening phase.
grammar used by Gómez (2002) and Onnis et al. (2003) is            During training, participants in the two conditions listened
supported under the same conditions of no or large                 to the same overall number of strings, a total of 432 token
variability that affords the detection of invariant structure.     strings. This way, frequency of exposure to the nonadjacent
Hence, if frames are acquired under the variability                dependencies was held constant across conditions.
hypothesis, generalization will be supported when there is         Participants in set-size 24 heard six iterations of each of 72
either zero or large variability of embeddings. Likewise,          type strings (3 dependencies x 24 middle items),
because invariant structure detection is poor in conditions of     participants, in set-size 2 encountered each string 12 times
middle variability, generalization is expected to be equally       as often as those exposed to set size 24, and so forth. Hence,
poor in those conditions too.                                      whereas nonadjacent dependencies where held constant,
                                                                   transitional probabilities of adjacent items decreased as set
                      Experiment 1                                 size increased.
                                                                             Training lasted about 18 minutes. Before the test,
                                                                   participants were told that the sentences they had heard were
Method
                                                                   generated according to a set of rules involving word order,
Subjects                                                           and they would now hear 12 strings, 6 of which would
Thirty-six undergraduate and postgraduate students at the          violate the rules. They were asked to give a “Yes/No”
University of Warwick participated and were paid £3 each.          answer. They were also told that the strings they were going
Materials                                                          to hear may contain new words and they should base their
In the training phase participants listened to auditory strings    judgment on whether the sentence was grammatical or not
generated by one of two artificial languages (L1 or L2) of         on the basis of their knowledge of the grammar. This is to
the type AiXjBi. Strings in L1 had the form A1XjB1, A 2XjB2,       guarantee that participants did not select as ungrammatical
and A3XjB3. L2 strings had the form A 1XjB2, A 2XjB3, A3XjB1.      all the sentences with novel words simply because they
Variability was manipulated in 3 conditions – zero, small,         contained novel words.
and large– by drawing X from a pool of either 1, 2 or 24
                                                                                  100%
elements. The strings, recorded from a female voice, were
the same that Gómez used in her study and were originally
chosen as tokens among several recorded sample strings in                          90%
order to eliminate talker-induced differences in individual
strings.                                                                           80%
                                                                      % correct
          The elements A 1, A2, and A3 were instantiated as
pel, vot, and dak; B 1, B2, and B 3, were instantiated as rud,
                                                                                   70%
jic, tood. The 24 middle items were wadim, kicey, puser,
fengle, coomo, loga, gople, taspu, hiftam, deecha, vamey,
skiger, benez, gensim, feenam, laeljeen, chla, roosa, plizet,                      60%
balip, malsig, suleb, nilbo, and wiffle. The middle items
were stressed on the first syllable. Words were separated by                       50%
250-ms pauses and strings by 750-ms pauses. Three strings                                     ZERO             SMALL           LARGE
in each language were common to all two groups and they                                                      Variability
were used as test stimuli. The three L2 items served as foils
for the L1 condition and vice versa. The test stimuli                             Figure 1. Generalisation under variability - Exp.1
consisted of 12 strings randomized: six strings were
grammatical and six were ungrammatical. The                        Results and discussion
ungrammatical strings were constructed by breaking the             An analysis of variance with Variability (1 vs. 2 vs. 24) and
correct nonadjacent dependencies and associating a head to         Language (L1 vs. L2) as between-subjects and
an incorrectly associated tail, i.e. *AiXBj.. Six strings (three   Grammaticality (Trained vs. Untrained strings) as a within-
grammatical and three ungrammatical) contained a                   subjects variable resulted in a main Variability effect,
previously heard embedding, while 6 strings (again three           F(2,30)= 3.41, p< .05, and no other interaction. Performance
grammatical and three ungrammatical) contained a new,              across the different variability conditions resulted in a U-
unheard embedding. Note that correct identification could          shaped function: a polynomial trend analysis showed a
only be achieved by looking at nonadjacent dependencies,           significant quadratic effect, F(1, 35) =7.407, p <.01. Figure
as adjacent transitional probabilities were the same for           1 presents the percentage of endorsements for total accuracy
grammatical and ungrammatical items.                               in each of the three variability conditions. These results add
Procedure                                                          considerable power to the variability hypothesis: not only
Six participants were recruited in each of 3 Variability           can nonadjacencies be detected, but generalization too can
conditions (1, 2 and 24) and for each of two Language              occur distributionally, and both processes seem to be
conditions (L1, L2) resulting in 12 participants per               modulated by the same conditions of variability. In addition,
Variability condition. Learners were asked to listen and pay       generalization with zero variability allows us to
close attention to sentences of an invented language and           disambiguate previous results, in that the high performance
they were told that there would be a series of simple              obtained by Onnis et al. (2003) could have been due to a
                                                                   simple memorization of the 3 strings repeated over and over
                                                               1049

again during training. However, in Experiment 1 correct           key role, in that it allows adjacent dependencies to be
classification of new strings as grammatical can only be          overcome in favour of nonadjacent ones, but it remains to be
done on the basis of the correct nonadjacencies. Thus, it         seen whether this can be done in connected speech too.
seems that learning on zero or large variability conditions is              Peña et al. (2002) tested participants on whether
supported by a similar mechanism. Finally, we note that A         they learned to generalize from the rules of an A X B
and B words are monosyllabic and X words are bysillabic,          language very similar to Newport & Aslin (2004) in
participants could simply learn a pattern S-SS-S (where           unsegmented speech. Again AXB items were instantiated in
S=syllable). However, because all sentences display such          syllables and formed words concatenated one to the other
pattern across conditions this cannot explain the U-shape of      seamlessly. At test, participants demonstrated no preference
the learning curve.                                               for so-called “rule-words”, new trigram sequences that
                                                                  maintained the A i_Bi nonadjacent dependencies but
                      Experiment 2                                contained a different A or B in the intervening position (e.g.,
          In Experiment 1 the items of the grammar are            A1B3B1), compared to part-words, i.e., sequences that
clearly demarcated by pauses. It can be argued that this          spanned word boundaries (e.g., X 2B1A3, or B 3A1X2). In a
makes the task somewhat simplified with respect to real           further manipulation, 25-ms gaps were introduced between
spoken language, which does not contain for instance such         words during the training phase of the experiment, and now
apparent cues at every word boundary. In addition, the            participants generalized as indicated by a preference for
embedded item X was instantiated in bisyllabic words (as          rule-words over part-words. Peña et al. claimed that altering
opposed to monosyllabic A and B words), providing an extra        the speech signal resulted in a change in the computations
cue for category abstraction. In this context, Peña et al.        performed by their participants. Statistical computations
(2002) have argued that generalization and speech                 were used in a (previously successful) segmentation task but
segmentation are separate processes underpinned by                this was not performed simultaneously with algebraic
separate computational mechanisms: statistical                    computations that would permit generalizations of the
computations are used in a segmentation task but this is not      structure. They argued that once the segmentation task was
performed simultaneously with algebraic computations that         solved by introducing small gaps in the speech signal, the
would permit generalizations of the structure. Once the           underlying structure would be learned. However, using the
segmentation task was solved by introducing small pauses          same stimuli and experimental conditions as Peña et al.
in the speech signal, their underlying structure was learned.     Onnis, Monaghan, Chater & Richmond (submitted) found
Hence it is important to test these claims in the light of the    that rule-words were preferred over part-words in both
variability hypothesis, which we argue might provide the          segmentation and generalization tasks even when the
key to learning nonadjacencies and generalizing altogether,       nonadjacent structure was eliminated: participants reliably
even in connected speech, without invoking two separate           preferred incorrect rule-words *A1B3B2 to part-words B1A2X,
mechanisms.                                                       due to preference for plosive sounds in word-initial position.
          Recent attempts to show statistical computations of     Hence such preference did not reflect learning of
a higher order at work in connected speech with a similar         nonadjacent dependencies. Although discouraging at first
AXB language have met with some difficulty: Newport &             sight, all these negative results are not inconsistent with the
Aslin (2004), for instance, exposed adults to a continuous        variability hypothesis. In fact, they are all cases structurally
speech stream, created by randomly concatenating A X B            similar to the low-variability condition in Gómez (2002) and
words with 3 A_B syllable dependencies and with 2                 Experiment 1. Thus, in Experiment 2 we tested whether
different middle X syllables. A sample of the speech stream       with sufficiently large variability:
obtained would be …A 1X3B1A2X2B2A3X1B3…. In this case             a) tracking higher-order dependencies can be used to
participants were unable to learn the nonadjacent                 segment speech. This is a difficult task because it implies
dependencies. Concatenating words seamlessly adds                 overriding even lower transitional probabilities p(X|A) than
considerable complexity to the task of tracking statistical       previously tested and this pressures for segmentation within
information in the input for two main reasons: first,             word boundaries (Saffran et al. 1996);
transitional probabilities between words of a language            b) generalization of the embeddings can occur
containing, say 3 dependencies and 3 Xs, p(B|A)= 0.5 are          simultaneously to speech segmentation, i.e. on-line in
higher than within words, p(X|A) and p(B|X)= 0.33, and this       running speech, and can be done by statistical analysis of
pressures for segmentation within words (Saffran, Aslin, &        the input alone, i.e. without additional perceptual cues such
Newport, 1996ab). Secondly, assuming the statistical              as pauses. We tested this using the same material and
mechanism is sensitive to nonadjacent dependencies as             training conditions as Peña et al. for their unsuccessful
seems the case in Experiment 1, concatenating items entails       pause-free generalization task, but increasing the variability
the additional burden of tracking nonadjacent transitional        of the X syllables to 24 items as in Experiment 1.
probabilities across word boundaries, e.g. X3_A2, B1_X2, and
dependencies spanning n words away can in principle also          Method
be attended to, e.g. two items away (B 2_ _A3…,etc.). One         Subjects
can readily see that if all transitional probabilities of         20 undergraduate and postgraduate students at the
different order were to be computed this scenario would           University of Warwick participated for £1. All participants
soon create a computational impasse. The insight from             spoke English as a first language and had normal hearing.
Gómez (2002) and Experiment 1 is that variability plays a
                                                              1050

Materials                                                         Procedure
We used the same nine word types from Peña et al.’s               In the training phase, participants were instructed to listen to
Experiment 2 to construct the training speech stream in our       continuous speech and try and work out the “words” that it
Experiment 2. The set of nine words was composed of three         contained. They then listened to the training speech. At test
groups (A i_Bi), where the first and the third syllable were      part-words were compared to “rule-words”, which were
paired, with an intervening syllable (X) selected from one of     composed of Ai__Bi pairs with an intervening item that was
either three syllables (low variability condition) or 24          either an A j or a B j from another A j_Bj pair. Participants
syllables (high variability condition). The syllables were        were requested to respond which of two sounds was a
randomly generated from the following set of consonants:          “word” in the language they had listened to. They were then
/p/,/b/,/g/,/k/,/d/,/t/,/l/,/r/,/f/,/tß/,/dΩ/,/n/,                played a “rule-word” and a part-word separated by 500 ms,
/s/,/v/,w/,/m/,/†/,/ß/,/z/and the following vowels:               and responded by pressing either “1” on a computer
/´i/,/uw/,/a/,/iy/,/au/,/oi/,/ai/,/æ/,/œ/.                        keyboard for the first sound a word, or “2” for the second
Consonants and vowels were permuted, then joined                  sound a word. After 2 seconds, the next rule-word and part-
together. No syllables occurred more than once in the set of      word pair were played. In half of the test trials, the “rule-
33 generated. Each participant listened to a different            words” occurred first. Five participants heard a set of test
permutation of consonant-vowel pairings. Notice that the          trials with one set of words first, and the other 5 participants
language structure in the two conditions match very closely       heard the other set of words first.
those of small and large variability in Experiment 1. Unlike      Results
Experiment 1 all items were monosyllabic and equally              The results are shown in Figure 2. In line with the original
stressed.                                                         Peña et al.’s experiment, we found no evidence for
          Words were produced in a seamless speech stream,        participants learning to generalize from the nonadjacent
with no two words from the same set occurring adjacently,         structure of the stimuli in the low-variability condition.
and no same middle item occurring in adjacent words.              Participants responded with a preference for rule-words over
Hence, adjacent transitional probabilities were as follows:       part-words 41.9% of the times, which was significantly
for the small variability condition, and within words, p(X|A)     lower than chance, t(9) = -2.73, p < .05. Conversely, in the
and p(B|X)= 0.33; between adjacent words p( Bj|Ai)= 0.5.          high-variability condition participants preferred rule-words
Nonadjacent transitional probabilities were p(B i|Ai)= 1,         63.3% of the times, significantly higher than chance, t(9)= -
p(Ai|Xprevious)= 0.33, p(Xj|Bprevious)= 0.33. For the large       3.80, p = .0042. In addition, there was a significant
variability condition all probabilities were the same except      difference between the low variability and the high
within word adjacent probabilities p(X|A) = 0.041.                variability condition, t(18) = -4.68, p < .001.
          Therefore, the predicition is that if learners
                                                                                 100%
computed adjacent statistical probabilities they should
prefer part-words and perhaps significantly more in the
                                                                                 90%
large variability condition. Conversely, if they computed
nonadjacent dependencies they would rely on the most                             80%
statistically reliable ones, namely p(B i|Ai)= 1, i.e. they
                                                                     % correct
would segment correctly at word boundary.                                        70%
          We used the Festival speech synthesizer using a
voice based on British-English diphones at a pitch of 120                        60%
Hz, to generate a continuous speech stream lasting
approximately 10 minutes. All syllables were of equal                            50%
duration, and were produced at a rate of 4.5
syllables/second. Words were selected randomly, except                           40%
that no Ai_Bi pair occurred twice in succession. The speech                               SMALL                   LARGE
stream was constructed from 900 words, in which each                                                Variability
word occurred approximately 100 times. The speech stream
faded in for the first 5 seconds, and faded out for the last 5       Figure 2. Generalisation in unsegmented speech - Exp. 2
seconds, so there was no abrupt start or end to the stream. In
addition, and crucially, for each participant, we randomly                              General Discussion
assigned the 9 syllables from the first experiment to the Ai,     Statistical learning of dependencies between adjacent
Bi and X j positions. Thus, each participant listened to speech   elements in a sequence is fast, robust, automatic and general
with the same structure containing the nonadjacent                in nature. In contrast, although the ability to track remote
dependencies, but with syllables assigned to different            dependencies is a crucial linguistic ability, relatively little
positions. This was to avoid any bias towards choosing a          research has been directed toward this problem.
rule-word because of a preference for plosive sounds, as          Nonadjacent structure in sequential information seems
Onnis et al. (submitted) demonstrated. Part-words were            harder to learn, possibly because learners have to overcome
formed from the last syllable of one word and two syllables       the bias toward adjacent transitional probabilities. In fact, a
from the following word (BiAjX ), or from the last two            statistical learning mechanism that kept track of all possible
syllables of one word and the first syllable from the             adjacent and nonadjacent regularities in the input, including
following word (XBiAj).                                           syllables one, two, three away, etc., would quickly
                                                              1051

encounter a computationally intractable problem of                          Statistical learning seems, at least in adults,
exponential growth. It would seem that either statistical         powerful enough to allow the discovery of complex
learning is limited to sensitivity to adjacent items, or there    nonadjacent structure, but simply not any condition will do:
may be statistical conditions in which adjacencies become         we have suggested that variability such as that emerging
less relevant in favour of nonadjacencies. It has been            from the asymmetry between open and closed class words
suggested that this applies under conditions of large             may be a crucial ingredient for understanding the building
variability of the intervening material (Gómez, 2002) or          of language.
zero variability (Onnis et al., 2003). This paper contributes
some steps forward: first, Experiment 1 shows that
variability is the key not only for detection of remote
                                                                                      Acknowledgments
dependencies but also for generalization of embedded              We thank M. Merkx for running Exp. 2, and R. Gómez for
material, fostering the creation of abstract syntactic-like       the stimuli in Exp.1 and important insights. Part of this work
classes, which is often assumed to require higher-level           was conducted while L. Onnis and P. Monaghan were at the
algebraic computation. Secondly, in Experiment 2                  University of Warwick. Support comes from European
segmentation and generalization are achieved                      Union Project HPRN-CT-1999-00065, and Human Frontiers
simultaneously, without the assist of pauses (a difference in     Science Program.
signal) as Pena et al. claimed. Consequently, rather than
supporting a statistical/algebraic distinction our results                                 References
suggest specific selectivities in learning patterned              Chater, N. (1996). Reconciling simplicity and likelihood
sequences. The specific characterization of such selectivities      principles in perceptual organization. Psychological
may not be simple to identify: Newport & Aslin (2004)               Review, 103, 566-581.
found that nonadjacent segments (consonants and vowels)           Childers, J. & Tomasello, M. (2001). The role of pronouns
could be learned but not nonadjacent syllables, and                 in young children's acquisition of the English transitive
proposed that this accounts for why natural languages               construction. Developmental Psychology, 37, 739-748.
display nonadjacent regularities of the former kind but not       Chomsky, N. (1957). Syntactic structures. The Hague:
of the latter. Experiment 2, however, shows that with large         Mouton.
variability nonadjacent syllabic patterns can in fact be          Gibson, E.J. (1991). An Odyssey in Learning and
learned. The key factor for success is again variability.           Perception. Cambridge, MA: MIT Press.
Experiment 2 also shows that learners are indeed able to          Gómez, R. (2002). Variability and detection of invariant
track nonadjacent dependencies in running speech, despite           structure. Psychological Science, 13, 431-436.
the well documented bias for adjacent associations and the        Harris, Z.S. (1955). From phoneme to morpheme. Language
preference for segmenting continuous speech at points of            31, 190-222.
lowest transitional probabilities.                                Mintz, T.H. (2002). Category induction from distributional
          Overall, the results suggest that the learning            cues in an artificial language. Memory & Cognition , 30,
mechanism entertains several statistical computations and           678-686.
implicitly “tunes in” to statistical relations that yield the     Newport, E.L., & Aslin, R.N. (2004). Learning at a distance
most reliable source of information. This hypothesis was            I. Statistical learning of nonadjacent dependencies.
initiated by Gómez (2002) and is consistent with several            Cognitive Psychology, 48, 127-162.
theoretical formulations such as reduction of uncertainty         Onnis, L., Monaghan, P., Chater, N., & Richmond, K.
(Gibson, 1991) and the simplicity principle (Chater, 1996)          (submitted). Phonology impacts segmentation and
that the cognitive system attempts to seek the simplest             generalization in speech processing.
hypothesis about the data available. In the face of               Onnis, L., Christiansen, M., Chater, N., & Gómez, R.
performance constraints and way too many statistical                (2003). Reduction of uncertainty in human sequential
computations, the cognitive system may be biased to focus           learning: Evidence from Artificial Grammar Learning.
on data that will be likely to reduce uncertainty.                  Proceedings of the 25th Annual Conference of the
Specifically, whether the system focuses on transitional            Cognitive Science Society. Mahwah, NJ: Lawrence
probabilities or nonadjacent dependencies may depend on             Erlbaum Associates, 887-891.
the statistical properties of the environment that is being       Peña, M., Bonatti, L., Nespor, M., & Mehler, J. (2002).
sampled.
                                                                       Signal-driven computations in speech processing.
          Our work ties in with recent acquisition literature
                                                                       Science, 298, 604-607.
that has emphasized the constructive role of syntactic
                                                                  Saffran, J.R., Aslin, R.N., and Newport, E.L. (1996a).
frames as the first step for building more abstract syntactic
                                                                    Statistical learning by 8-month-old infants. Science, 274,
representations (Tomasello, 2003 for an overview).
                                                                    1926-1928.
Children’s syntactic development would build upon several
                                                                  Saffran, J.R., Newport, E.L., & Aslin, R.N. (1996b). Word
consecutive stages from holophrases such as I-wanna-see-it
                                                                    segmentation: The role of distributional cues. Journal of
(at around 12 months), to pivot-schemas (throw-ball, throw-
                                                                    Memory and Language, 35, 606-621.
can, throw-pillow, at about 18 months), through item-based
                                                                  Tomasello, M. (2003). Constructing a Language: A Usage-
constructions (John hugs Mary, Mary hugs John, at about
                                                                    Based Theory of Language Acquisition. Harvard
24 months), to full abstract syntactic constructions (a X, the
                                                                    University Press.
Xs, Eat a X).
                                                              1052

