UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Structure Dependence in Language Acquisition: Uncovering the Statistical Richness of the
Stimulus
Permalink
https://escholarship.org/uc/item/5c89b88h
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Reali, Florencia
Christiansen, Morten H.
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              Structure Dependence in Language Acquisition:
                            Uncovering the Statistical Richness of the Stimulus
                Florencia Reali (fr34@cornell.edu) and Morten H. Christiansen (mhc27@cornell.edu)
                               Department of Psychology; Cornell University; Ithaca, NY 14853 USA
                             Abstract                                  statistical natural language processing and connectionist
                                                                       modeling has revealed much more complex learning
   The poverty of stimulus argument is one of the most                 abilities of potential relevance for language acquisition (e.g.,
   controversial arguments in the study of language acquisition.       Lewis & Elman, 2001). Finally, little attention has
   Here we follow previous approaches challenging the
                                                                       traditionally been paid to what young infants may be able to
   assumption of impoverished primary linguistic data, focusing
   on the specific problem of auxiliary fronting in polar
                                                                       learn, and this may be problematic given that recent
   interrogatives. We develop a series of child-directed corpus        research has demonstrated that even before one year of age,
   analyses showing that there is indirect statistical information     infants are quite competent statistical learners (Saffran,
   useful for correct auxiliary fronting in polar interrogatives,      Aslin & Newport, 1996—for reviews, see Gómez &
   and that such information is sufficient for producing               Gerken, 2000; Saffran, 2003).
   grammatical generalizations even in the absence of direct                These research developments suggest the need for a
   evidence. We further show that there are simple learning            reappraisal of the poverty of stimulus argument, centered on
   devices, such as neural networks, capable of exploiting such        whether they together can answer the question of how a
   statistical cues, producing a bias to correct aux-questions
                                                                       child may be able to learn aspects of linguistic structure for
   when compared to their ungrammatical counterparts. The
   results suggest that the basic assumptions of the poverty of
                                                                       which innate knowledge was previously thought to be
   stimulus argument need to be reappraised.                           necessary. In this paper, we approach this question in the
                                                                       context of structure dependence in language acquisition,
                         Introduction                                  specifically in relation to auxiliary fronting in polar
                                                                       interrogatives. We first outline the poverty of stimulus
How do children learn aspects of their language for which              debate as it has played out with respect to forming
there appears to be no evidence in the input? This question            grammatical questions with auxiliary fronting. It has been
lies at the heart of the most enduring and controversial               argued that the input to the child does not provide enough
debates in cognitive science. Ever since Chomsky (1965), it            information to differentiate between correct and incorrect
has been argued that the information in the linguistic                 auxiliary fronting in polar interrogatives (Chomsky in
environment is too impoverished for a human learner to                 Piatelli-Palmarini, 1980). In contrast, we conduct a corpus
attain adult competence in language without the aide of                analysis to show that there is sufficiently rich statistical
innate linguistic knowledge. Although this poverty of the              information available in child-directed speech for generating
stimulus argument (Chomsky, 1980; Crain & Pietroski,                   correct aux-questions—even in the absence of any such
2001) has guided most research in linguistics, it has proved           constructions in the corpus. We additionally demonstrate
to be much more contentious within the broader context of              how the same approach can be applied to explain results
cognitive science.                                                     from studies of auxiliary fronting in 3- to 5-year-olds (Crain
      The poverty of stimulus argument rests on certain                & Nakayama, 1987). Whereas, the corpus analyses indicate
assumptions about the nature of the input to the child, the            that there is rich statistical information available in the
properties of computational learning mechanisms, and the               input, it does not show that there are learning mechanisms
learning abilities of young infants. A growing bulk of                 capable of utilizing such information. We therefore conduct
research in cognitive science has begun to call each of these          a set of connectionist simulations to illustrate that neural
three assumptions into question. Thus, whereas the                     networks are capable of using statistical information to
traditional nativist perspective suggests that statistical             distinguish between correct and incorrect aux-questions. In
information may be of little use for syntax acquisition (e.g.,         the conclusion, we discuss our results in the context of
Chomsky, 1957), recent research indicates that                         recent infant learning results.
distributional regularities may provide an important source
of information for syntactic bootstrapping (e.g., Mintz,
                                                                              The Poverty of Stimulus and Structure
2002; Redington, Chater and Finch, 1998)—especially
when integrated with prosodic or phonological information                       Dependence in Auxiliary Fronting.
(e.g., Christiansen & Dale, 2001; Morgan, Meier &                      Children only hear a finite number of sentences, yet they
Newport, 1987). And while the traditional approach only                learn to speak and comprehend sentences drawn from a
tends to consider learning in highly simplified forms, such            language that can contain an infinite number of sentences.
as “move the first occurrence of X to Y”, progress in                  The poverty of stimulus argument suggests that children do
                                                                   1131

not have enough data during the early stages of their life to       acquisition—as suggested by Legate & Yang (2002)—other
learn the syntactic structure of their language. Thus,              more indirect sources of statistical information may provide
learning a language involves the correct generalization of          sufficient basis for making the appropriate grammatical
grammatical structure when insufficient data is available to        generalizations. Recent connectionist simulations provide
children. The possible weakness of the argument lies in the         preliminary data in this regard. Lewis & Elman (2001)
difficulty to assess the input, and in the imprecise and            trained simple recurrent networks (SRN; Elman, 1990) on
intuitive definition of ‘insufficient data’.                        data from an artificial grammar that generated questions of
     One of the most used examples to support the poverty           the form ‘AUX NP ADJ?’ and sequences of the form ‘Ai
of stimulus argument concerns auxiliary fronting in polar           NP Bi’ (where Ai and Bi represent a variety of different
interrogatives. Declaratives are turned into questions by           material) but no relevant examples of polar interrogatives.
fronting the correct auxiliary. Thus, for example, in the           The SRNs were better at making predictions for correct
declarative form ‘The man who is hungry is ordering                 auxiliary fronting compared to those with incorrect auxiliary
dinner’ it is correct to front the main clause auxiliary as in 1,   fronting. This indicates that even without direct exposure to
but fronting the subordinate clause auxiliary produces an           relevant examples, the statistical structure of the input
ungrammatical sentence as in 2 (Chomsky, 1965).                     nonetheless provides useful information applicable to
     1. Is the man who is hungry ordering dinner?                   auxiliary fronting in polar interrogatives.
     2. *Is the man who hungry is ordering dinner?                       However, the SRNs in the Lewis & Elman simulation
                                                                    studies were exposed to an artificial grammar without the
Children can generate two types of rules: a structure-
                                                                    complexity and noisiness that characterizes actual child-
independent rule where the first ‘is’ is moved; or the correct
                                                                    directed speech. The question thus remains whether the
structure-dependent rule, where only the movement of the
                                                                    indirect statistical regularities in an actual corpus of child-
‘is’ from the main clause is allowed. Crucially, children do
                                                                    directed speech are strong enough to support grammatical
not appear to go through a period when they erroneously
                                                                    generalizations over incorrect ones—even in the absence of
move the first is to the front of the sentence (e.g., Crain &
                                                                    direct examples of auxiliary fronting in polar interrogatives
Nakayama, 1987). It has moreover been asserted that a
                                                                    in the input. Next, in our first experiment, we conduct a
person might go through much of his or her life without
                                                                    corpus analysis to demonstrate that the indirect statistical
ever having been exposed to the relevant evidence for
                                                                    information available in a corpus of child-directed speech is
inferring correct auxiliary fronting (Chomsky, in Piatelli-
                                                                    indeed sufficient for making the appropriate grammatical
Palmarini, 1980).
                                                                    generalizations in questions involving auxiliary fronting.
     The purported absence of evidence in the primary
linguistic input regarding auxiliary fronting in polar
                                                                      Experiment 1: Measuring Indirect Statistical
interrogatives is not without debate. Intuitively, as
suggested by Lewis & Elman (2001), it is perhaps unlikely             Information Relevant for Auxiliary Fronting
that a child would reach kindergarten without being exposed         Even if children only hear a few relevant examples of polar
to sentences such as 3-5.                                           interrogatives, they may nevertheless be able to rely on
     3. Is the boy who was playing with you still there?            indirect statistical cues for learning the correct structure. In
     4. Will those who are hungry raise their hand?                 order to assess this hypothesis, we trained bigram and
     5. Where is the little girl full of smiles?                    trigram models on the Bernstein-Ratner (1984) corpus of
These examples have an auxiliary verb within the subject            child-directed speech and then tested the likelihood of novel
NP, and thus the auxiliary that appears initially would not         example sentences. The test sentences consisted of correct
be the first auxiliary in the declarative, providing evidence       polar interrogatives (e.g. Is the man who is hungry ordering
for correct auxiliary fronting. Pullum & Scholz (2002)              dinner?) and incorrect ones (e.g. Is the man who hungry is
explored the presence of auxiliary fronting in polar                ordering dinner?)—neither of which were present in the
interrogatives in the Wall Street Journal (WSJ). They found         training corpus. We reasoned that if indirect statistical
that at least five crucial examples occur in the first 500          information provides a possible cue for generalizing
interrogatives. These results suggest that the assumption of        correctly to the grammatical aux-questions, then we should
complete absence of evidence for correct auxiliary fronting         find a difference in the likelihood of these two alternative
is overstated. Nevertheless, it has been argued that the WSJ        hypotheses.
corpus is not a good approximation of the grammatical                    Bigram/trigram models are simple statistical models
constructions that young children encounter and thus it             that use the previous one/two word(s) to predict the next
cannot be considered representative of the primary linguistic       one. Given a string of words or a sentence it is possible to
data. Indeed, studies of the CHILDES corpus show that               compute the associated cross-entropy for that string of
even though interrogatives constitute a large percentage of         words according to the bigram/trigram model trained on a
the corpus, relevant examples of auxiliary fronting in polar        particular corpus (from Chen & Goodman, 1996). Thus,
interrogatives represent less than 1% of them (Legate &             given two alternative sentences we can compare the
Yang, 2002).                                                        probability of each of them as indicated by their associated
     Although the direct evidence for auxiliary fronting in         cross-entropy as computed in the context of a particular
polar interrogatives may be too weak to be helpful in               corpus. Specifically, we can compare the two alternative
                                                                1132

generalizations of doing auxiliary fronting in polar                used Perl programming in a Unix environment to implement
interrogatives, comparing the cross-entropy associated with         the corpus analysis. This includes the simulation of bigram
grammatical (e.g., Is the man who is in the corner                  and trigram models and cross-entropy calculation and
smoking?) and ungrammatical forms (e.g., Is the man who             comparisons.
in the corner is smoking). This will allow us to determine
whether there may be sufficient indirect statistical                Materials We used the Bernstein-Ratner (1984) corpus of
information available in actual child-directed speech to            child-directed speech for our corpus analysis. It contains
decide between these two forms. Importantly, the Bernstein-         recorded speech from nine mothers speaking to their
Ratner corpus contains no examples of auxiliary fronting in         children over 4-5 months period when children were
polar interrogatives. Our hypothesis is therefore that the          between the ages of 1 year and 1 month to 1 year and 9
corpus nonetheless contains enough statistical information          months. This is a relatively small and very noisy corpus,
to decide between grammatical and ungrammatical forms.              mostly containing short sentences with simple grammatical
                                                                    structure. The following are some example sentences: Oh
Method                                                              you need some space; Where is my apple?; Oh. That’s it’.
Models For the purpose of corpus analysis we used bigram
and trigram models of language (see e.g., Jurafsky &                Procedure We used the Bernstein-Ratner child-directed
Martin, 2000). The probability P(s) of a sentence was               speech corpus as the training corpus for the bigram/trigram
expressed as the product of the probabilities of the words          models. The models were trained on 10,082 sentences from
(wi) that compose the sentence, with each word probability          the corpus (34,010 word tokens; 1,740 word types). We
conditional to the last n-1 words. Then, if s = w1…wk we            wanted to compare the cross-entropy of grammatical and
have:                                                               ungrammatical polar interrogatives. For that purpose, we
                                                                    created two novel sets of sentences. The first one contained
 P(s) = Πi P(wi|wi-1i-n+1)                                          grammatically correct polar interrogatives and the second
To estimate the probabilities of P(wi|wi-1) we used the             one contained the ungrammatical version of each sentence
maximum likelihood (ML) estimate for P(wi|wi-1) defined as          in the first set. The sentences were created using a random
(considering the bigram model):                                     algorithm that selected words from the corpus, and created
 PML(wi|wi-1) = P(wi-1wi) /P(wi-1)=(c(wi-1wi)/Ns)/(c(wi-1)/Ns);     sentences according to syntactic and semantic constraints.
                                                                    We tried to prevent any possible bias in creating the test
where Ns denote the total number of tokens and c(α) is the
                                                                    sentences. The test sets only contained relevant examples of
number of times the string α occurs in the corpus. Given
                                                                    polar interrogatives of the form: “Is / NP/ (who/that)/ is / Ai/
that the corpus is quite small, we used the interpolation           Bi?”, where Ai and Bi represent a variety of different
smoothing technique defined in Chen & Goodman (1996).               material including VP, PARTICIPLE,NP, PP, ADJP (e.g.: “Is the
The probability of a word (wi) (or unigram model) is                lady who is there eating?”; “Is the dog that is on the chair
defined as:                                                         black?”). Each test set contained 100 sentences. We
 PML(wi) = c(wi)/Ns;                                                estimated the mean cross-entropy per sentence by
The smoothing technique consists of the interpolation of the        calculating the average cross-entropy of the 100 sentences
bigram model with the unigram model, and the trigram                in each set. Then we compared the likelihood of pairs of
model with the bigram model. Thus, for the bigram model             grammatical and ungrammatical sentences by comparing
we have:                                                            their cross-entropy and choosing the version with the lower
 Pinterp(wi|wi-1) = λPML(wi|wi-1) + (1-λ)PML(wi)                    value. We studied the statistical significance of the results
                                                                    using paired t-test analyses.
Accordingly for trigram models we have:
 Pinterp(wi|wi-1wi-2) = λPML(wi|wi-1wi-2) + (1-λ)(λPML(wi|wi-1)     Results
 + (1-λ)PML(wi)),                                                   We found that the mean cross-entropy of grammatical
where λ is a value between 0 and 1 that determines the              sentences was lower than mean cross entropy of
relative importance of each term in the equation. We used a         ungrammatical sentences. We performed a statistical
standard λ = 0.5 so that all terms are equally weighted. We         analysis of the cross-entropy difference, considering all
measure the likelihood of a given set of sentences using the        pairs of grammatical and ungrammatical sentences. The
measure of cross-entropy (Chen & Goodman, 1996). The                cross-entropy difference was highly significant ( t(99),
cross-entropy of a set of sentences is defined as:                  p<0.0001) (see Table 1). These results show that
                                                                    grammatical sentences have a higher probability than
 1/NT Σi -log2 P(si) (where si is the ith sentence).
                                                                    ungrammatical ones. In order to compare each grammatical-
The cross-entropy value of a sentence is inversely correlated       ungrammatical pair of sentences, we defined the following
with the likelihood of it. Given a training corpus, and two         criterion: When deciding between each grammatical vs.
sentences A and B we can compare the cross-entropy of               ungrammatical polar interrogative example, choose the one
both sentences and estimate which one is more probable              that has lower cross-entropy (the most probable one).
according to the statistical information of the corpus. We
                                                                1133

          Table 1: Comparison of mean cross-entropy in Exp.1.                                         speech to differentiate reliably between the grammatical and
                                                                                                      ungrammatical aux-questions that we had generated, it
                                                 Mean cross-entropy         Mean        t(99)         could be argued that the real test for our approach is whether
                                                 Gram.       Ungramm.
                                                                           difference   p-value       it works for actual sentences produced by children. We
 Bigram                                          22.92        23.73        0.83         < 0.0001      therefore tested our models on a small set of sentences
                                                                                                      elicited from children under experimental conditions.
 Trigram                                         21.81        23.07        1.26         < 0.0001           Crain & Nakayama (1987) conducted an experiment
                                                                                                      designed to elicit complex aux-questions from 3- to 5-year-
A sentence is defined as correctly classified if the chosen                                           old children. The children were involved in a game in which
form is grammatical. Using that criterion, we found that the                                          they asked questions to Jabba the Hutt, a creature from Star
percentage of correctly classified sentences using the bigram                                         Wars. During the task the experimenter gives an instruction
model is 92% and using the trigram model is 95%. Figure 1                                             to the child: ‘Ask Jabba if the boy who is watching Mickey
shows the performance of the models according to the                                                  Mouse is happy’. Children produced sentences like a) ‘Is the
defined classification criterion. Of the 100 test sentences,                                          boy who is watching Mickey Mouse happy?’ but they never
the trigram model only misclassified the following five: Is                                           produced sentences like b) ‘Is the boy who watching Mickey
the lady who is here drinking?; Is the alligator that is                                              Mouse is happy?’. The authors concluded that the lack of
standing there red?; Is the jacket that is on the chair                                               structure-independent errors suggested that children
lovely?; Is the one that is in the kitchen scared?; Is the                                            entertain only structure-dependent hypotheses, supporting
phone that is in the office purple?                                                                   the existence of innate grammatical structure.
     The bigram model in addition to the above five
sentences also misclassified the next three test sentences: Is                                        Method
the bunny that is in the car little; Is the baby who is in the                                        Models Same as in Experiment 1.
castle eating?; Is the bunny that is sleeping black?
     It is possible to calculate the probability of a sentence                                        Materials Six example pairs were derived from the
from the cross-entropy value. Figure 2 shows the                                                      declarative sentences used in Crain & Nakayama1(1987):
comparison of mean probability of grammatical and                                                          6. The ball that the girl is sitting on is big
ungrammatical sentences. We found that the mean                                                            7. The boy who is unhappy is watching Mickey Mouse
probability of grammatical polar interrogatives is almost                                                  8. The boy who is watching Mickey Mouse is happy
twice the mean probability of ungrammatical polar                                                          9. The boy who is being kissed by his mother is happy
interrogatives according to the bigram model and it is more                                                10. The boy who was holding the plate is crying
than twice according to the trigram model.                                                                 11. The dog that is sleeping is on the blue bench
                                                                                                      The grammatical and ungrammatical aux-questions were
 Sentences classified as
                              100
                                                                                  grammatical         derived from the declaratives in 6-11. Thus, the sentence ‘Is
                                                                                  sentences           the dog that is sleeping on the blue bench?’ belonged to the
                                      50
                                                                                  ungrammatical       grammatical test set whereas the sentence ‘Is the dog that
                                                                                  sentences           sleeping is on the blue bench?’ belonged to the
     grammatical
                                       0
                                                                                                      ungrammatical test set. Consequently, grammatical and
                                                  bigram         trigram
                                                                                                      ungrammatical test sets contained 6 sentences each.
Figure 1: Number of sentences classified correctly (white                                             Procedure The bigram/trigram models were trained on the
bars) and incorrectly as grammatical (gray bars)                                                      Bernstein-Ratner (1984) corpus as in Experiment 1, and
                                                                                                      tested on the material derived from Crain & Nakayama
                   Mean Probability
                                       3.0E-07
                                                                               grammatical            (1987).
                                       2.0E-07                                 sentences
                                       1.0E-07                                 ungrammatical          Results
                                      0.0E+00
                                                                               sentences              Consistently with Experiment 1, we found that the mean
                                                   trigram     bigram                                 cross-entropy of grammatical sentences was significantly
                                                                                                      lower than the mean cross entropy of ungrammatical
                                                                                                      sentences both for bigram and trigram models (t(5) p<0.013
Figure 2: Mean probability of grammatical sentences vs.                                               and p<0.034 respectively). Table 2 summarizes these
mean probability of ungrammatical sentences.                                                          results.
         Experiment 2: Testing Sentences with
        Auxiliary Fronting Produced by Children                                                       1
                                                                                                        As some of the words in the examples were not present in the Bernstein-
                                                                                                      Ratner corpus, we substitute them for semantically related ones: Thus, the
Although Experiment 1 shows that there is sufficient                                                  words: “mother”, “plate”, “watching”, “unhappy” and “bench” were
indirect statistical information available in child-directed                                          replaced respectively by “mommy”, “ball”, “looking at”, “crying” and
                                                                                                      “chair”.
                                                                                                   1134

     Using the classification criterion defined in Experiment    networks were simulated using the Lens simulator in a Unix
1, we found that all six sentences were correctly classified     environment. No changes were made to the original
using the bigram model. That is, according to the                networks and their parameters.
distributional information of the corpus, all grammatical
aux-questions were more probable than the ungrammatical          Materials We trained and tested the networks on the
version of them. When using the trigram model, we found          Bernstein-Ratner corpus similarly to the bigram/trigram
that five out of six sentences were correctly classified.        models. Each word in the corpus corresponded to one of the
                                                                 14 following lexical categories from CELEX database
    Table 2: Comparison of mean cross-entropy in Exp.2.          (Baayen, Pipenbrock & Gulikers, 1995): nouns, verbs,
                                                                 adjectives, numerals, infinitive markers, adverbs, articles,
               Mean cross-entropy       Mean         t(5)        pronouns, prepositions, conjunctions, interjections, complex
               Gram.      Ungramm.
                                       difference    p-value     contractions, abbreviations, and proper names. Each word in
  Bigram       26.99        27.89      0.90          < 0.013     the corpus was replaced by a vector encoding the lexical
                                                                 category to which it belonged. We used the two sets of test
  Trigram      25.97        26.86      0.89          < 0.034     sentences used in Experiment 1, containing grammatical and
                                                                 ungrammatical polar interrogatives respectively. However,
  Experiment 3: Learning to Produce Correct                      as the network was trained to predict lexical classes, some
         Sentences with Auxiliary Fronting                       test sentences defined in Experiment 1 mapped onto the
While Experiments 1 and 2 establish that there is sufficient     same string of lexical classes. For simplicity, we only
indirect statistical information in the input to the child to    considered unique strings, resulting in 30 sentences in each
differentiate between grammatical and ungrammatical              test set (grammatical and ungrammatical).
questions involving auxiliary fronting—including questions
produced by children—it is not clear whether a simple            Procedure The ten SRNs from Reali, Christiansen &
learning device may be able to exploit such information to       Monaghan (2003) were trained on one pass through the
develop an appropriate bias toward the grammatical forms.        Bernstein-Ratner corpus. These networks were then tested
To investigate this question, we took a previously developed     on the aux-questions described above. To compare network
SRN model of language acquisition (Reali, Christiansen &         predictions for the ungrammatical vs. the grammatical aux-
Monaghan, 2003), which had also been trained on the same         questions, we measured the networks’ mean squared error
corpus, and tested its ability to deal with aux-questions.       recorded during the presentation of each test sentence pair.
     Previous simulations by Lewis & Elman (2001) have
shown that SRNs trained on data from an artificial grammar       Results
were better at predicting the correct auxiliary fronting in      We found that in all ten simulations the grammatical set of
aux-questions. An important question is whether the results      aux-questions produced a lower error compared to the
shown using artificial-language models are still obtained        ungrammatical ones. The mean squared-error per next
when dealing with the full complexity and the general            lexical class prediction was 0.80 for the grammatical set and
disorderliness of speech directed at young children. Thus,       0.83 in the ungrammatical one, this difference being highly
we seek to determine whether a previously developed              significant (t(29) p <0.005). Out of the 30 test sentences, 27
connectionist model, trained on the same corpus, is sensitive    grammatical sentences produced a lower error than its
to the same indirect statistical information that we have        ungrammatical counterpart. On the assumption that
found to be useful in bigram/trigram models. SRNs are            sentences with the lower error will be preferred, SRNs
simple learning devices that have been shown to be sensitive     would pick the grammatical sentences in 27 out of 30 cases.
to bigram/trigram information.                                        It is worth highlighting that the grammatical and
                                                                 ungrammatical sets of sentences were almost identical, only
Method                                                           differing on the position of the fronted “is” as described in
Networks We used the same ten SRNs that Reali,                   Experiment 1. Thus, the difference in mean squared error is
Christiansen & Monaghan (2003) had trained to predict the        uniquely due to the words’ position in the sentence. Despite
next lexical category given the current one. These networks      the complexity of child-directed speech, these results
had initial weight randomization in the interval [-0.1; 0.1].    suggest that simple learning devices such as SRNs are able
A different random seed was used for each simulation.            to pick up on the existing distributional properties showed
Learning rate was set to 0.1, and momentum to 0.7. Each          in Experiment 1. Moreover, differently to Experiment 1,
input to the network contained a localist representation of      here we explored the distributional information of the
the lexical category of the incoming word. With a total of 14    lexical classes alone and thus the network was blind to the
different lexical categories and a pause marking boundaries      possible information present in word-word co-occurrences.
between utterances, the network had 15 input units. The
network was trained to predict the lexical category of the                               Conclusion
next word, and thus the number of output units was 15.           In the corpus analyses, we showed that there is sufficiently
Each network had 30 hidden units and 30 context units. All       rich statistical information available indirectly in child-
                                                             1135

directed speech for generating correct complex aux-                Christiansen, M.H. & Dale, R.A.C. (2001). Integrating
questions—even in the absence of any such constructions in           distributional, prosodic and phonological information in a
the corpus. We additionally demonstrated how the same                connectionist model of language acquisition. In
approach can be applied to explain results from child-               Proceedings of the 23rd Annual Conference of the
acquisition studies (Crain & Nakayama, 1987). These                  Cognitive Science Society (pp. 220-225). Mahwah, NJ:
results indicate that indirect statistical information provides      Lawrence Erlbaum.
a possible cue for generalizing correctly to grammatical           Crain, S. & Nakayama, M. (1987). Structure dependence in
auxiliary fronting.                                                  grammar formation. Language. 63: 522-543.
     Whereas the corpus analyses indicate that there are           Crain, S. & Pietroski, P. (2001). Nature, nurture and
statistical cues available in the input, it does not show that       Universal Grammar. Linguistics and Philosophy. 24: 139-
there are learning mechanisms capable of utilizing such              186.
information. However, previous results suggest that children       Elman, J.L. (1990). Finding structure in time. Cognitive
are sensitive to the same kind of statistical evidence that we       Science. 14: 179-211.
found in the present study. Saffran, Aslin & Newport (1996)        Gómez, R.L., & Gerken, L.A. (2000). Infant artificial
demonstrated that 8 month-old children are particularly              language learning and language acquisition. Trends in
sensitive to transitional probabilities (similar to our bigram       Cognitive Sciences. 4: 178-186.
model). Sensitivity to transitional probabilities seems to be      Jurafsky, D. and Martin, J.H. (2000) Speech and Language
present across modalities, for instance in the segmentation          Processing. Upper Saddle River, NJ: Prentice Hall.
of streams of tones (Saffran, Johnson, Aslin, & Newport,           Legate, J.A. & Yang, C. (2002) Empirical re-assessment of
1999). These and other results on infant statistical learning        stimulus poverty arguments. Linguistic Review. 19: 151-
(see Gómez & Gerken, 2000) suggest that children have                162.
mechanisms for relying on implicit statistical information.        Lewis, J.D. & Elman, J.L. (2001). Learnability and the
SRNs are simple learning devices whose learning properties           statistical structure of language: Poverty of stimulus
have been shown to be consistent with humans’ learning               arguments revisited. In Proceedings of the 26th Annual
abilities. Even though it was originally developed in a              Boston University Conference on Language Development
different context (Reali, Christiansen & Monaghan, 2003),            (pp. 359-370). Somerville, MA: Cascadilla Press.
our SRN model proved to be sensitive to the indirect               Mintz, T.H. (2002) Category induction from distributional
statistical evidence present in the corpus, developing an            cues in an artificial language. Memory & Cognition. 30:
appropriate bias toward the correct forms of aux-questions.          678-686.
     In conclusion, this study indicates that the poverty of       Morgan, J. L., Meier, R.P. & Newport, E.L. (1987).
stimulus argument may not apply to the classic case of               Structural packaging in the input to language learning:
auxiliary fronting in polar interrogatives, previously a             Contributions of prosodic and morphological marking of
corner stone in the argument for the innateness of grammar.          phrases to the acquisition of language. Cognitive
Our results further suggest that the general assumptions of          Psychology. 19: 498–550.
the poverty of stimulus argument may need to be                    Piatelli-Palmarini, M. (ed.), 1980. Language and Learning:
reappraised in the light of the statistical richness of the          The Debate between Jean Piaget and Noam Chomsky.
language input to children.                                          Cambridge, MA: Harvard University Press.
                                                                   Pullum G.K. & Scholz B. (2002) Empirical assessment of
                    Acknowledgments                                  stimulus poverty arguments. Linguistic Review. 19: 9-50.
This research was supported in part by a Human Frontiers           Reali, F., Christiansen, M.H. & Monaghan, P. (2003).
Science Program Grant (RGP0177/2001-B).                              Phonological and Distributional Cues in Syntax
                                                                     Acquisition: Scaling up the Connectionist Approach to
                         References                                  Multiple-Cue In Proceedings of the 25th Annual
                                                                     Conference of the Cognitive Science Society (pp. 970-
Baayen, R.H., Pipenbrock, R. & Gulikers, L. (1995). The              975). Mahwah, NJ: Lawrence Erlbaum.
   CELEX Lexical Database (CD-ROM). Linguistic Data                Redington, M., Chater, N. & Finch, S. (1998). Distributional
   Consortium. Univ. of Pennsylvania, Philadelphia, PA.              Information: A Powerful Cue for Acquiring Syntactic
Bernstein-Ratner, N. (1984). Patterns of vowel Modification          Categories. Cognitive Science. 22: 425-469.
   in motherese. Journal of Child Language. 11: 557-578.           Saffran, J.R. (2003). Statistical language learning:
Chen S.F. & Goodman J. (1996). An Empirical Study of                 Mechanisms and constraints. Current Directions in
   Smoothing Techniques for Language Modeling.                       Psychological Science. 12: 110-114.
   Proceedings of the 34th Annual Meeting of ACL.                  Saffran, J.R., Aslin, R. & Newport, E.L. (1996) Statistical
Chomsky N. (1957). Syntactic Structures. Mouton and co.:             learning by 8- month-old infants. Science. 274: 1926-
   The Hague.                                                        1928.
Chomsky N. (1965). Aspects of the Theory of Syntax.                Saffran, J.R., Johnson, E.K., Aslin, R. & Newport, E.L.
   Boston, MA: MIT Press.                                            (1999) Statistical learning of tone sequences by human
Chomsky N. (1980). Rules & Representation. Cambridge,                infants and adults. Cognition. 70: 27-52.
   MA: MIT Press.
                                                               1136

