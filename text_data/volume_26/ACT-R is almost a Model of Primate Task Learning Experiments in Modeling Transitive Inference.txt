UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
ACT-R is almost a Model of Primate Task Learning: Experiments in Modeling Transitive
Inference
Permalink
https://escholarship.org/uc/item/6bs4z8bb
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Wood, Mark A.
Leong, Jonathan C.S.
Bryson, Joanna J.
Publication Date
2004-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                 ACT-R is almost a Model of Primate Task Learning:
                      Experiments in Modelling Transitive Inference
                                   Mark A. Wood (cspmaw@cs.bath.ac.uk)
                               Jonathan C. S. Leong (jleong@fas.harvard.edu)
                                     Joanna J. Bryson (jjb@cs.bath.ac.uk)
                                  University of Bath; Department of Computer Science
                                       Bath, England BA2 7AY; United Kingdom
                          Abstract                            although ACT-R is close enough that it is probably fix-
                                                              able. ACT-R demonstrates one significant simplification
  We present a model of transitive inference (TI) using       over the two-tier hypothesis, and has one important dif-
  ACT-R which strengthens the hypothesis that TI is not       ference from real mammalian task learning.
  dependent on underlying sequential ordering of stimuli,
  but rather on the learning of productions. We neverthe-
  less find a weakness in the ACT-R sub-symbolic learning     Transitive Inference
  system and suggest improvements.                            Transitive inference (TI) formally refers to the process
                                                              of reasoning whereby one infers that if, for some quality,
                                                              A > B and B > C, then A > C. In some domains, such
                     Introduction                             as integers or heights, this property will hold for any
The last decade has shown an increasing body of work          A, B or C, though for others it does not (see Wright,
indicating that ACT-R (Anderson and Lebiere, 1998)            2001, for a recent discussion). TI is classically described
can be used to model human learning in an impressive          as an example of concrete operational thought (Piaget,
variety of tasks. However, ACT-R has been slow to gain        1954). That is, children become capable of doing TI
acceptance in mainstream experimental psychology as a         when they become capable of mentally performing the
useful model, possibly because it does not seem a very        physical manipulations they would use to determine the
good correlate to the physical learning systems we find       correct answer, a stage they reach at approximately the
in the brain.                                                 age of seven. In the case of TI, this manipulation involves
  In previous and concurrent work, we have been ex-           ordering the objects into a sequence using the rules A >
ploring another model of task learning which also seems       B and B > C, and then observing the relative location
at first blush artificial and not particularly parsimo-       of A and C.
nious, but has also shown an impressively tight fit to           Since the 1970’s, however, apparent TI has been
human and animal experimental data otherwise unac-            demonstrated in much younger children (Bryant and
counted for. This is the Harris (1988) production-rule-       Trabasso, 1971) and a variety of animals, from mon-
stack model of one of the main testbeds of task learning      keys (McGonigle and Chalmers, 1977) to pigeons (Fersen
in the animal literature, the transitive inference task.      et al., 1991) — not normally ascribed with concrete oper-
We developed the two-tier model (Bryson, 2001; Bryson         ational abilities. The behaviour of choosing A from AC
and Leong, 2004), which accounts for all of the Harris        without training after having previously been trained
model’s data, while extending the model to account for        to select A from AB and B from BC is consequently
both learning and failing to learn this task (a common        sometimes referred to as “transitive performance”, and
outcome in live subjects). We’ve also found potential         whether it implies sequential ordering at all is now an
neurological correlates for the two-tier model.               open issue.
  The two-tier model hypothesises two learning systems:          The main motivation for not considering TI in animals
one for connecting perceptual contexts to actions, and        to be based on a sequential structure is a dataset due to
another for prioritising which of those perceptual con-       McGonigle and Chalmers (1977), which they have sub-
texts to attend to if more than one are present simulta-      sequently replicated both with monkeys and children.
neously. We realised that this model had similar aspects      This data set concerns what happens if subjects demon-
to ACT-R, which also has two learning systems, one sym-       strating TI are asked to select between three items rather
bolic and one statistical. We therefore decided to apply      than two. Some individuals show significant, systematic
ACT-R to the transitive inference learning task. Our re-      degradation in performance, which cannot be explained
sults show that ACT-R is far better than the standard         by a sequential model. Some researchers have dismissed
TI models at accounting for the particular (and some-         the triad data as resulting from confusion in the sub-
what controversial) data set that prompted the Harris         jects due to the extra item. These criticisms were dealt
(1988) model, and for some individuals provides a bet-        with in a replication by McGonigle and Chalmers (1992)
ter model than Harris (1988), though for others it can-       which provided the main data set used in this paper
not. Our results lead us to believe that the two-tier         and by Harris and McGonigle (1994). The fact that the
model is the best existing model of transitive inference,     systematicity of the degradation has now been success-
                                                          1470

fully accounted for further validates this data set. This
data concerns monkeys trained on 4 adjacent pairs drawn           Table 1: Enumeration of Harris and McGonigle Stacks
from a 5 item sequence, AB, BC, CD, DE.
                                                                              Rule Depth                     Rule Depth
                       The Models                                   #      1        2       3       #      1       2        3
                                                                    1    s(A) s(B) s(C)             5    a(E) s(A) s(B)
Due to space constraints we will not review the more                2    s(A) s(B) a(E)             6    a(E) s(A) a(D)
traditional, sequence-based or simple-associative models
                                                                    3    s(A) a(E) s(B)             7    a(E) a(D) s(A)
of TI, but see further (Wynne, 1998; Bryson and Leong,
2004). These models cannot account for the triad data               4    s(A) a(E) a(D)             8    a(E) a(D) a(C)
set.
Harris and McGonigle
                                                                 Table 2: Primate TI training régime (Chalmers and Mc-
Harris (1988) showed that both pair and triad TI perfor-
                                                                 Gonigle, 1984; McGonigle and Chalmers, 1992)
mance could be accounted for if we assume that monkeys
learn a production rule stack. A production rule is a ba-
sic AI representation which connects a stimulus to a re-           P1     Each pair in order (DE, CD, BC, AB) repeated
sponse. A stack is a prioritised list. In the Harris model,               until 9 of 10 most recent trials are correct.
                                                                          Reject if requires over 200 trials total
each monkey learns one rule per possible stimulus, or              P2a    4 of each pair in order. Criteria: 32 consecutive
up to 5 rules in total. One of two actions is associated                  trials correct. Reject if requires over 200 trials total
with each rule, either select or avoid. If a subject applies       P2b    2 of each pair in order. Criteria: 16 consecutive
the rule A→s(A) (see A implies select A), then it will                    trials correct. Reject if requires over 200 trials total
simply pick up A, regardless of whether other items are            P2c    1 of each pair in order. Criteria: 30 consecutive
                                                                          trials correct. No rejection criteria
present. However, if a subject applies the rule A→a(A)             P3     1 of each pair randomly ordered.
it will pick up anything but A. If more than one other                    Criteria: 24 consecutive trials correct.
item is present, the subject is at chance for which object                Reject if requires over 200 trials total
it will pick up. If more than one rule could apply, then            T     Pair and triad testing
whichever rule is higher in the stack (has higher priority)
will be applied.
   Although Harris’ hypothesis may seem obscure, it
shows a remarkable match to the data. If one assumes             may make, and the impact of training régimes. The first
that rules are limited to the case that the action refers        tier of the two-tier model is a single-vector neural net-
to the object attended to, then only 16 of the 1920              work (NN) which learns the prioritisation of the stimuli.
(10 × 8 × 6 × 4) possible stacks of four rules operate           The second tier is a set of small two-item vectors which
correctly on all training pairs (Harris and McGonigle,           each learn to associate an action with one of the stimuli.
1994). All 16 of these stacks also correctly perform TI          The learning rule for the NNs is a slight simplification of
on all pairs automatically, thus already accounting for          standard delta learning (Widrow and Hoff, Jr., 1960).
one of the mysteries of transitive performance.                     Simulations using the two-tier model show artificial
   The degradation some subjects display on the triad            subjects successfully learning the training data only
tests is a consequence of the random aspect of the               about 25% of the time when training pairs are presented
avoid rules. In fact, triads can be used to discrimi-            in a random order. However, switching to the train-
nate which rule stack an individual subject has learnt.          ing régime applied by McGonigle and Chalmers (1992)
For example, a stack that consists entirely of selects           shown in Table 2, which is standard for primates, the
(s(A), s(B), s(C) . . .) will never make any errors. One         success rate increases to about 75%, which is compara-
that starts with a(E) will be at chance between the other        ble to live subjects (Bryson and Leong, 2004).
two options whenever E is present in a triad.                       Further, the sorts of errors made by artificial subjects
   Table 1 shows all of the possible discriminable stacks        failing to learn are consistent with those shown by live
as identified by Harris and McGonigle (1994). Because            subjects — they tend to confuse the middle pairs. Anal-
only the highest-priority applicable rule fires and there        ysis of the networks shows that this is nearly always a
are always at least two applicable rules (since there are        consequence of misprioritising the rules representing the
at least two stimuli), there is no way to discriminate the       end pairs. An agent can guarantee it always selects A
two lowest-priority rules using triad performance. These         in the pair AB (the only pair A appears in) by learning
stacks therefore only reflect the top three rules of the         a(B), and there is a great inclination to learn about mid-
stacks.                                                          dle rules because these are the ones that have the most
                                                                 data (and the most confusing data, since B is sometimes
The Two-Tier Model                                               rewarded but sometimes penalised.) However, there are
A successfully trained two-tier model creates a replica-         no successful stacks which do not have one end point or
tion of the production-rule-stack model (Bryson, 2001).          the other at the highest priority (see Table 1). The train-
However, the two-tier model is dynamic, and as such              ing régime greatly increases the probability of learning
gives us insight into why animals have trouble learning          correct prioritisation. For further details see Bryson and
the initial pairs for the TI task, the sorts of mistakes they    Leong (2004).
                                                             1471

ACT-R                                                            with ACT-R-1 successfully passed the training régime.
As for the above models, ACT-R also learns production            This compares to 35% of those using ACT-R-2, or 75%
rules, but any number of these rules may have their pre-         of those using the two-tier system. We examine these
conditions for firing satisfied at any given time. In this       groups separately.
case, ACT-R’s conflict-resolution system selects the rule        Successful Agents
with highest utility value.
   Rule utilities are changed by ACT-R’s sub-symbolic            The stack model proposed by Harris and McGonigle
processing system. It is possible to attach success or           (1994) attempts to fit the McGonigle and Chalmers
failure tags to productions and when such a rule is fired,       (1977) triad data to any of the eight discriminable cor-
ACT-R backtracks to discover which rules fired previ-            rect stacks (Table 1). In contrast, the ACT-R agents
ously and increments or decrements their utilities respec-       learn only two possible solutions.
tively. More precisely, the utility of a rule is given by:          There are two rules which are always successful for all
                                                                 pairs: s(A) and a(E). This means that, provided these
                      U = P G − C + ²(s)                  (1)    rules are discovered by the agent, their utilities will begin
                                                                 to converge to maximal, given by:
where G is the goal value, C is the expected cost, ²(s) is
the expected gain noise and P is the expected probability              lim U   =    lim (P G − C)                          (3)
                                                                      t→∞          t→∞
of success:                                                                             µ                        ¶
                                                                                                Successes
                              Successes                                        =    lim                            G−C
                  P =                                     (2)                      t→∞ Successes + Failures
                        Successes + Failures                                            Ã                !
In our experiments, rather than make arbitrary changes                                           1
                                                                               =    lim         Failures
                                                                                                           G−C
to ACT-R’s many available parameters in an attempt                                 t→∞     1 + Successes
to best fit the data, we have used mostly defaults. The                        =   G−C
most notable exception to this is that we set the initial
Failure count to 1 which, along with ACT-R’s default             where t is the number of trials, and G and C remain
setting of 1 for Successes1 , gives an initial probability of    constant at ACT-R default values throughout. Therefore
success of 0.5. This change was also made by Belavkin            any successful ACT-R agent will have these two rules at
and Ritter (2003) in their Dancing Mouse model. To               highest priority. This eliminates half of the Harris and
maximise the number of successful agents, we also tried          McGonigle stacks, leaving 3, 4, 5 and 6 (Table 1).
a range of values for s (which affects the variance of the          In addition, because the top-two rule utilities are con-
noise function), finally deciding upon s = 1.                    verging to the same value, it becomes essentially ar-
   One trial consists of two or three items displayed on-        bitrary (in fact, governed by the expected gain noise)
screen which the agent encodes into its goal buffer. The         whether s(A) or a(E) occupies the top stack position for
goal state is then changed, enabling it to make decisions        any given choice. In other words, the ACT-R agents do
about which item to pick (see below). Once an item has           not learn a totally ordered stack, but effectively a pair
been picked, either a reward or no reward is displayed           of stacks. The two possible pairs are:
appropriately, the agent notes its success or failure re-
spectively and the next trial begins.
                                                                 Hybrid Stack 1 (HS1):       s(A)a(E)s(B) & a(E)s(A)s(B)
   We have tested two different approaches to solving the
TI problem in ACT-R. In the first, the select and avoid          Hybrid Stack 2 (HS2):       s(A)a(E)a(D) & a(E)s(A)a(D)
rules for each item are independent, concurrent candi-           Table 3 shows each triad with the expected percentage
dates for execution. For three displayed items, this cor-        of trials in which each item in that triad is chosen. These
responds to six conflicting rules that have their precon-        probabilities are the same for both Hybrid Stacks, except
ditions satisfied. Henceforth we refer to this approach as       for the triad BCD. In this case, the format is HS1 / HS2.
ACT-R-1.                                                         A 75%/25% split occurs when both A and E are present
   In the second, the agent must focus on a displayed            in the triad. We assume that half the time s(A) has top
item before either selecting or avoid ing it, as in the two-     priority and is thus selected. Otherwise, a(E) has top
tier model. This results in an extra stage of conflict-          priority, giving an even chance of A or the other item
resolution for the agent. With three options there are           being selected.
at first three candidate focus rules whose actions alter            Taking into account the noise added to the system,
the agent’s goal state. This, in turn, satisfies two further     this model well describes the behaviour of many of the
rules; select and avoid for the focus-item. We call this         ACT-R agents. In 45% of cases, one of the Hybrid Stacks
approach ACT-R-2.                                                fitted the agent’s distribution better than any of the in-
                                                                 dividual stacks, and a further 47% were best fitted by
                           Results                               Stack 5; a contributor to HS1.
As with the two-tier model and live subjects, our ACT-R
                                                                 Failed Agents
model produces both agents that successfully learn the
task and agents that do not. 44 of the 100 agents tested         Despite these encouraging results, a majority of the
                                                                 ACT-R agents failed the training régime (Table 2), which
    1
      The default is Failures = 0 ⇒ Pinitial = 1.                is not true of the monkeys (albeit there were only seven
                                                             1472

                                                                        16
Table 3: Projected percentage choice distributions for
Hybrid Stack 1 / 2
  Triad     A          B              C         D      E                14
  ABC      100         0              0          -     -
  BCD        -     100 / 50        0 / 50      0/0     -
  BDE        -        50              -         50     0
  CDE        -         -             50         50     0          Utility
                                                                        12
  BCE        -        50             50          -     0
  ABD      100         0              -          0     -
  ACD      100         -              0          0     -
                                                                        10                   a(C)
  ADE       75         -              -         25     0
                                                                                             a(D)
  ABE       75        25              -          -     0
  ACE       75         -             25          -     0
  Mean     52.5   22.5 / 17.5    12.5 / 17.5   12.5    0                    8
                                                                             0             200            400         600       800
                                                                                                        Trials
test subjects) or children (Chalmers and McGonigle,
1984). Virtually all of the agents which failed did so         Figure 1: a(C) and a(D) fight for control of the pair CD
at stage P2a (Table 2), typically having seen less than
300 training pairs in total. There are two exceptions for
both ACT-R models which failed at P3.                                       Table 4: Aggregate percentage error on each pair
  To best understand why agents fail, we examine each
training pair and determine what causes agents to pick                           Group       AB      BC    CD    DE    Mean
the wrong item:                                                                  ACT-R-1      6      25    30     7     17
AB Since s(A) almost always has a high utility, errors                           ACT-R-2      6      43    39     9     24
 on this pair tend to be caused by interference from
 s(B), whose utility is driven up by its success on pair
 BC. Ironically, then, it is agents who are too successful                  Table 5: Percentage distribution of failed agents
 too soon who fail because of this pair, training stage
 P2a having the most stringent pass criteria.                                                         Modal Error Pair
BC C is picked when s(C) is too high relative to s(B)                               Group           AB BC CD DE
 or, less frequently, a(C). Occasionally a(B) adds to                               ACT-R-1          2   39    54     5
 this interference but, due to the success of s(A), rarely                          ACT-R-2          0   42    50     8
 attains a high enough utility.
CD The symmetric case of BC. Here a(C)/a(D) inter-
 ference is the chief cause of error (see Figure 1).                                             Analysis
                                                               For ease of statistical comparison, we applied the χ2 test
DE As for AB, if a(D) is discovered early to be a good
                                                               in the same way as Harris and McGonigle (1994): by
 rule, it interferes with a(E) causing small but signifi-
                                                               excluding item E, which (usually) has an expected value
 cant errors in P2a.
                                                               of 0.
   For some agents (around 25%), failure is a result of           For three of the five individual test subjects for whom
a combination of the above interferences. If many of           McGonigle and Chalmers (1977) triadic data is avail-
the interfering rules are interdependent (eg. s(B), s(C),      able, one of the hybrid stacks fits better than any of the
a(C), a(D)) then this can lead to a more even distribu-        eight others (Table 6). As explained in the Successful
tion of errors across all training pairs. Conversely, if two   Agents section above, and in contrast with the Harris
sets of independent rules (eg. s(A), a(B), a(D), a(E))         and McGonigle stacks, the hybrid stacks do not repre-
are interfering, often two training pairs are consistently     sent a total ordering. Thus it would seem that neither do
incorrect, with little or no error on the other two.           some monkeys form a total ordering, and their choices
   As Tables 4 and 5 show, agents confuse the middle           cannot be perfectly modelled by a simple production-
pairs far more often than the end pairs (see also Anal-        rule system. For Bump and Brown, however, our model
ysis). This, in turn, is most often the result of s(C) and     is rejected (p < 0.01), suggesting that other monkeys
a(C), both of which perform incorrectly for one of the         do come up with a total ordering, which cannot be well
middle pairs. We have restricted these data to the last        modelled in ACT-R.
200 trials carried out by the failed agent. This focuses          The two-tier model does support both models, al-
on the specific phase of training at which the agent failed    though its admittedly simplistic learning rule tends to
and removes the noisiest choices, made during P1.              favour the total ordering. These results suggest that
                                                           1473

                                                               must be at least three to produce a correct stack) would
Table 6: Comparison of individual triadic choice data          converge upon the same value (see Equation 3 above).
(1977) with both Hybrid and Harris’ Stack models               But since no three rules in a correct stack are indepen-
                                                               dent for all triads, they will start to interfere with each
                                                               other, causing error to be re-introduced.
            A      B      C      D      E    χ2    p(O)
                                                                  This phenomenon is best demonstrated by examining
 Bill       55     17     20     8      0     -      -         the errors of agents who did not take part in structured
 HS2       52.5   17.5   17.5   12.5    0   2.1     n.s.       training, but were presented with the training pairs in a
 S4         60     15     15     10     0   2.8     n.s.       random order. Here, as is usual, the s(A) and a(E) rules
 Blue       55     25     14      6     0     -      -         have high, convergent utilities (these rules are indepen-
 HS1       52.5   22.5   12.5   12.5    0   4.0     n.s.       dent for all training pairs). Then the utility of one (or
 S3         60     20     10     10     0   4.9     n.s.       both) of the other successful rules, s(B) and a(D), will
 Bump       53     34      8      4     1     -      -         also start to converge. This results in errors made on the
 HS1       52.5   22.5   12.5   12.5    0   13.3   < 0.01      end pairs since s(B) interferes with s(A) for AB (Figure
 S2         60     30      5      5     0    3.4    n.s.       2) and a(D) interferes with a(E) for DE. Neither s(C) nor
                                                               a(C) can attain a high utility, because they will perform
 Brown      36     29     24     11     0     -      -         incorrectly on one of the middle pairs (BC and CD). The
 HS2       52.5   17.5   17.5   12.5    0   15.3   < 0.01      final result is that the middle pairs are chosen consis-
 S7         35     25     25     15     0    1.8    n.s.       tently correctly, whereas the end pairs have small errors
 Roger      51     26      6     17     0     -      -         (typically around 15%). This certainly seems somewhat
 HS1       52.5   22.5   12.5   12.5    0    5.6    n.s.       biologically implausible, and contradicts the End-Anchor
 S5         45     25     15     15     0    6.5   < 0.1       Effect (Bryant and Trabasso, 1971; Wynne, 1998).
                                                                             20
an improved priority-learning rule for either the two-tier
model or ACT-R could result in a highly accurate model
of TI and possibly task learning in general.
   There were just five monkeys who passed criteria and
so were included in the triad phase of the 1977 exper-                       16
iment. These five only represented three of the eight
                                                                   Utility
stacks in Table 1. This may render the grouped data
unrepresentative, but our ACT-R model still displays a
better correlation than Harris and McGonigle (1994) of
α-choices, as shown in Table 7, where α represents the                       12
correct choice in a given triad (see also Table 8).
                                                                                           s(A)
                                                                                           s(B)
    Table 7: Correlation of α-choices to group data
         Group                    r        p                                  8
                                                                               0         200       400     600           800
         ACT-R-1                0.688   p < 0.05                                                  Trials
         ACT-R-2                0.692   p < 0.05
         Hybrid Stack Model     0.616   p < 0.1
                                                               Figure 2: Interference with s(A) prevents the utility of
         H & M Stack Model      0.634   p < 0.05
                                                               s(B) reaching above a certain level
  Upon closer examination of the choices made for
each triad, we see ACT-R closely matching the monkey                               Conclusions and Further Work
data for those triads which do not contain the item E          The ACT-R models lack in their ability to represent sta-
(Table 8). For those that do, ACT-R makes more mis-            ble, totally ordered stacks, which some real subjects ap-
takes, suggesting that the monkeys do not have a(E)            pear to form. On the other hand, the Harris and McGo-
at as high a priority. This might reflect a primate bias       nigle (1994) stacks lack the flexibility to represent more
against having identical priorities for rules.                 dynamic solutions to the TI problem. For this reason
  There may be a good reason for favouring priorities          we conclude that the two-tier model is the best exist-
over utilities for ordering rules. For example, there is       ing model of TI. On the other hand, the fact that there
no circumstance in which an ACT-R agent can reach a            is no significant difference between ACT-R-1 (where no
stable enough solution to reduce error to zero. Suppose        initial item focus is required) and ACT-R-2 (where this
such a situation was attained. Then every decision made        focus is required) implies that the two-tier model can be
would result in success and thus increase the utility of       simplified to allow arbitrary numbers of stimulus action
the executed rule. Eventually, these rules (of which there     pairings, as is the default case in ACT-R.
                                                            1474

                                 Table 8: Percentage of items selected - triadic analysis
           Triad       Monkeys       ACT-R-1        ACT-R-2      Hybrid Stack    Model    H&   M Stack  Model
           αβγ        α    β γ      α    β    γ    α     β γ      α      β        γ       α    β        γ
           ABC       80 18 2        83 17 0        86 14 0       100 0            0       94   6        0
           BCD       70 26 4        70 29 1        72 26 2        75 25           0       75   25       0
           BDE       66 34 0        59 35 6        56 37 6        50 50           0       63   38       0
           CDE       62 38 0        49 41 10       48 44 7        50 50           0       56   44       0
           BCE       78 22 0        58 42 0        58 42 0        50 50           0       63   38       0
           ABD       80 20 0        79 21 0        80 20 0       100 0            0       88   13       0
           ACD       86 12 2        90 9       0   91 8 0        100 0            0       88   13       0
           ADE       86 14 0        72 24 4        71 26 4        75 25           0       75   25       0
           ABE       88 12 0        68 32 0        70 30 0        75 25           0       75   25       0
           ACE       80 20 0        76 24 0        74 25 0        75 25           0       75   25       0
           Means     78 22 1        70 28 2        71 27 2        75 25           0       75   25       0
   There are several obvious next steps. First, as stated      Bryson, J. J. (2001). Intelligence by Design: Principles
in the Introduction, the learning rules for priorities in        of Modularity and Coordination for Engineering Com-
both the two-tier model and ACT-R need improvement,              plex Adaptive Agents. PhD thesis, MIT, Department
though in different ways. We will be focusing on im-             of EECS, Ch. 9. AI Technical Report 2001-003.
proving the two-tier model, but would be happy to see          Bryson, J. J. and Leong, J. C. S. (2004). A two-tiered
or support ACT-R being modified to reflect these re-             model of primate transitive performance: Separate
sults. Also, we suggest two possible improvements to             memory systems for rule-stimulus association pairs
the ACT-R model. Allowing ACT-R to compile its own               and their prioritisations. In preparation.
system of rules from a minimal starting set (Anderson          Chalmers, M. and McGonigle, B. O. (1984). Are children
and Lebiere, 1998) may provide a more natural solution,          any more logical than monkeys on the five term series
although interpreting the underlying decision processes          problem? Journal of Experimental Child Psychology,
would be more difficult. Starting with a high initial noise      37:355–377.
would allow the agents to always discover and benefit
from the most successful rules, while rapidly reducing         Fersen, L., Wynne, C. D. L., Delius, J., and Staddon,
this noise level (in conjunction with the entropy of suc-        J. E. R. (1991). Transitive inference formation in pi-
cess (Belavkin and Ritter, 2003)) would be necessary in          geons. Journal of Experimental Psychology: Animal
order to obtain a stable enough solution to pass stage           Behavior Processes, 17:334–341.
P2a of the training régime.                                   Harris, M. R. (1988). Computational Modelling of Tran-
   The other obvious next step would be to collect and           sitive Inference: a Micro Analysis of a Simple Form
analyse more triad testing results across a larger number        of Reasoning. PhD thesis, University of Edinburgh.
of primates. For our purposes, it would be useful to have      Harris, M. R. and McGonigle, B. O. (1994). A model
triad testing on subjects who fail TI training as well as        of transitive choice. The Quarterly Journal of Exper-
those who succeed. We are investigating collaborations           imental Psychology, 47B(3):319–348.
in this area.                                                  McGonigle, B. O. and Chalmers, M. (1977). Are mon-
   The greatest significance of this work is that it gives       keys logical? Nature, 267:694–696.
further evidence for a non-sequence-based representation       McGonigle, B. O. and Chalmers, M. (1992). Monkeys
underlying the TI task and further supports the utility          are rational! The Quarterly Journal of Experimental
of the McGonigle and Chalmers (1977) triad data set.             Psychology, 45B(3):189–228.
                                                               Piaget, J. (1954). The Construction of Reality in the
                       References                                Child. Basic Books, New York.
Anderson, J. R. and Lebiere, C. (1998). The Atomic             Widrow, B. and Hoff, Jr., M. E. (1960). Adaptive switch-
   Components of Thought. Mahwah, NJ: Erlbaum.                   ing circuits. IRE WESCON Convention Record, 4:96–
Belavkin, R. V. and Ritter, F. E. (2003). The use of             104.
   entropy for analysis and control of cognitive models.       Wright, B. C. (2001). Reconceptualizing the transitive
   In Detje, F., Dörner, D., and Schaub, H., editors, Pro-      inference ability: A framework for existing and future
   ceedings of the Fifth International Conference on Cog-        research. Developmental Review, 21(4):375–422.
   nitive Modelling, pp. 21–26. Universitäts-Verlag Bam-
                                                               Wynne, C. D. L. (1998). A minimal model of transitive
   berg.
                                                                 inference. In Wynne, C. D. L. and Staddon, J. E. R.,
Bryant, P. E. and Trabasso, T. (1971). Transitive infer-         editors, Models of Action, pages 269–307. Lawrence
   ences and memory in young children. Nature, 232:456–          Erlbaum Associates, Mahwah, NJ.
   458.
                                                           1475

