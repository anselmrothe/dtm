UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Causal Structure in Conditional Reasoning
Permalink
https://escholarship.org/uc/item/1w36q9q9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Krynski, Tevye R.
Tenenbaum, Joshua B.
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                  Causal Structure in Conditional Reasoning
                                                Tevye R. Krynski (tevye@mit.edu)
                                               Joshua B. Tenenbaum (jbt@mit.edu)
                        Department of Brain & Cognitive Sciences, Massachusetts Institute of Technology
                                             77 Massachusetts Ave., Cambridge, MA 02139
                             Abstract                                     The Wason selection task presents subjects with a
                                                                       conditional statement of the form “if p then q”, and asks
  Causal reasoning has been shown to underlie many aspects of          subjects to choose evidence to determine whether the
  everyday judgment and decision-making. We explore the role           statement is true. Prior accounts of people’s responses on
  of causal structure in conditional reasoning, hypothesizing
                                                                       the selection task have emphasized logical reasoning
  that people often interpret conditional statements as assertions
  about causal structure. We argue that responses on the Wason         (Wason, 1966; Ahn & Graham, 1999), probabilistic
  selection task reflect the selection of evidence expected to         reasoning (Oaksford & Chater, 1994), or social reasoning
  maximally reduce uncertainty over candidate causal                   (Cosmides, 1989), as well as others. In contrast, we argue
  structures. We present a model in which people’s selections          that the selection task often engages causal reasoning: for
  depend on their interpretation of which causal relationship is       conditional statements in which p and q are causally related,
  asserted by a given conditional statement.                           people choose cards that will be most useful to determine
                                                                       which of several candidate causal structures is correct for a
                         Introduction                                  given situation.
  Consider the following statement: “If a pot falls in the                We have developed a model that extends Oaksford &
kitchen, then you will hear a clang”. Is this statement true?          Chater’s (1994) probabilistic information gain framework to
Not if something breaks its fall, like a pillow. Now consider          handle causal hypotheses. The information gain framework
the statement: “If a clang is heard then a pot has fallen in the       of O&C proposes that in the Wason selection task, people
kitchen.” Is this statement true? Not if something else can            seek to reduce their uncertainty among hypotheses about the
cause a clang, such as falling silverware. The first statement         relationship between the antecedent (p) and the consequent
is not always true because there are conditions that can               (q) in a conditional statement of the form “if p then q”. The
disable the mechanism by which falling pots cause clangs to            model of O&C (1994) proposes that these hypotheses are
be heard. The second statement is not always true because              assertions about conditional dependencies (e.g., q depends
there are alternate causes of clangs other than falling pots.          on p, q is independent of p, etc.), whereas we propose that
As this example illustrates, causal knowledge often                    these hypotheses are assertions about causal structure (e.g.,
underlies how people reason about conditional statements.              p causes q, p does not cause q, etc.).
  Recent research has shown that causal reasoning                         Our causal framework enables us to explain some
permeates many aspects of cognition, including associative             previously puzzling results from the literature, as well as
learning (Waldmann, 2000; Glymour & Cheng, 1998),                      compelling intuitions that are not predicted by other
category learning (Rehder, 2003; Ahn, 1999), and judgment              approaches. We also address an important open question
under uncertainty (Krynski & Tenenbaum, 2003). In this                 with both logical and probabilistic accounts: they leave
paper we analyze the role of causal structure in conditional           unspecified how people interpret conditionals to determine
reasoning (Over & Jessop, 1998), and argue that people’s               which hypothesis is being asserted. We propose that the
responses on the Wason selection task reflect sophisticated            interpretation of conditionals often depends on causal
abilities to induce causal structure.                                  domain knowledge, which imposes constraints on candidate
  An important open question in causal reasoning is how                causal structures, as well as pragmatic considerations.
people’s background knowledge interacts with observations
when inferring causal structure. Causal domain knowledge                       Why interpret conditionals causally?
places important constraints on which cause-effect                     In contrast to O&C’s proposal that conditional statements
relationships exist and how the effects depend functionally            assert a conditional dependency, we propose that people
on the causes (Pearl, 2000; Krynski & Tenenbaum, 2003;                 interpret conditional statements in which p and q are
Ahn, Kalish, Medin, & Gelman, 1995). This effectively                  causally related as assertions about causal structure. The
specifies a hypothesis space of candidate causal structures,           underlying reason for this is that conditional dependencies
which we model using causal Bayes nets (Pearl, 2000).                  are often a symptom of some underlying causal relationship.
Observational evidence can then be used to determine which             “If p then q” states that there is some dependency between p
causal structure is most likely. We propose that this                  and q, which in turn implies there is some mechanism by
interplay of causal domain knowledge and observational                 which p and q are related; i.e., p causally influences q, q
evidence underlies people’s judgments on the Wason                     causally influences p, or they have some common cause.
selection task.                                                        The term “causally influences” does not necessarily mean
                                                                   744

“directly causes”; causal influence can be generative,                                                            ⎛ P( S | d ) ⎞                     ⎛ P(T − S | d ) ⎞
inhibitive, enabling, permissive, or otherwise.                                   I KL ( S | d ) = P( S | d ) log ⎜            ⎟ + P(T − S | d ) log ⎜               ⎟
                                                                                                                  ⎝  P ( S )   ⎠                     ⎝ P(T − S ) ⎠
    Examples of the prevalence of causal interpretations come
                                                                                 In the case of the Wason selection task, IKL(S|d) is the
from statements in which the logical interpretation and the
                                                                              amount of information gained from turning over cards. The
causal interpretation are at odds; in these cases, the causal
                                                                              selection task can be used to test two claims: (1) people
interpretation tends to take precedence. Some conditionals
                                                                              often interpret conditional statements in which p and q are
are logically false but seem true because they are causally
                                                                              causally related as assertions that a particular causal
true. For example, “If you spin around then you will get
                                                                              relationship holds, and (2) people select information with
dizzy” seems true enough, although it’s possible to spin
                                                                              the goal of maximally reducing uncertainty in that assertion.
around without getting dizzy, therefore it’s logically false.
Other conditionals are logically true but seem false because
they are causally false. For example, “If you drink coffee
                                                                              Applying the IG approach to the selection task
during the day then you will fall asleep at night” sounds                     The Wason selection task and its variants present people
false because it seems to be saying that coffee causes you to                 with a conditional statement of the form “if p then q”, where
fall asleep, but it is logically true (assuming you eventually                p and q can be any propositions. Cards are then presented
fall asleep every night). These examples suggest that it is                   which represent trials; one side specifies whether p was true
often, but not always, more natural to interpret conditionals                 on the trial, while the other side specifies whether q was
as causal assertions, rather than logical implications.                       true. Subjects are presented with four cards, having each of
                                                                              the four possible sides (p, q, ¬p, ¬q) facing up. The specific
                Causal Structure Induction                                    task instructions vary depending on the experimenter’s
                                                                              intent, but they generally instruct participants to select only
We adopt the following Bayesian framework: given                              those cards necessary to turn over in order to determine
conditional statement “if p then q”, reasoners consider a                     whether or not the given conditional statement is true.
total hypothesis space T of candidate causal structures                          Consider the information gained from turning over a
relating p and q. The conditional statement is interpreted to                 single card with v on the visible side and finding u on
be asserting that a specific causal relationship holds between                unseen side: (v,u take on values in {p, q, ¬p, ¬q}, subject to
p and q. T then partitions into a subspace of structures S                    the constraints of the selection task):
consistent with the statement, and its complement, T-S,
                                                                                                                                                  ⎛ P ( S | v, u ) ⎞
inconsistent with the statement. Testing the conditional                          I KL ( S | d ) = I KL ( S | v, u ) = P ( S | v, u ) log ⎜                        ⎟
amounts to testing whether the true structure, s*, is in S or                                                                                     ⎝ P(S ) ⎠
T-S. The probability that the conditional is true is the                                                                               ⎛ P (T − S | v, u ) ⎞
probability that s* is in S: P ( s* ∈ S ) = P ( S ) = Σ P ( s ) .                                         + P (T − S | v, u ) log ⎜                           ⎟
                                                          s∈S                                                                          ⎝ P (T − S ) ⎠
    Initial degrees of belief in these hypotheses are
                                                                                                                                     P ( s | v) P (u | v, s )
represented as prior probabilities, and those structures that
do not satisfy the constraints of causal domain knowledge
                                                                                  P ( S | v, u ) =    ∑
                                                                                                      s∈S
                                                                                                            P ( s | v, u ) =   ∑
                                                                                                                               s∈S
                                                                                                                                            P (u | v)
are not considered. For example, people know that falling                     Since it is generally obvious that the cards in the Wason
pots can cause noise, but noise cannot cause pots to fall,                    selection task were not randomly sampled, but rather one
hence no structures with noise causing falling pots will be                   card of each possible side (p, q, ¬p, or ¬q) was presented,
included in T. In this case of the conditional “if a pot falls,               no information can be gained from learning that the visible
then it makes a noise”, T could be the set of all causal                      side of the card is v, thus P ( s | v) = P ( s ) .
structures consistent with domain knowledge in which                             One more step is necessary for predicting card selection:
falling pots exist, and S could be the subset of structures in                summing over all possible values of the unseen side of the
T in which falling pots are a cause of noise.                                 card to obtain the expected information gain from turning
    Data can help determine how likely the conditional                        the card with v on the visible side, EIg(S,v):
statement is to be true. Using Bayesian belief updating,
                                               P( s) P(d | s)
                                                                                                    EI g ( S , v) =    ∑      I KL ( S | v, u ) P (u | v)
              P(S | d ) = ∑   P( s | d ) = ∑       P(d )
                                                                                                                         u
                          s∈S              s∈S                                The IG approach proposes that subjects select cards in the
According to the information gain (IG) approach (O&C,                         Wason selection task as a function of expected information
1994), when determining whether a particular conditional                      gain, with selection favoring cards with higher expected
statement is true, the most informative data are those that                   information gain.
are expected to maximize information gain, Ig:
                                 1                                 1          Applying the IG approach to causal hypotheses
 I g ( S | D) = ∑
                H
                   P( H ) log
                              P ( H  )
                                       − ∑ H
                                              P( H | d ) log
                                                              P ( H  | d)        The Bayesian framework presented thus far is similar to
                                                                              O&C (1996), except that it treats conditional statements as
However, O&C (1996) propose that when P(S) is not 0.5, a                      asserting the validity of a set of hypotheses rather than a
better measure is the distance between the probability                        single hypothesis. We now turn to the major differences
distributions of the new and old beliefs, as measured by                      between our account and that of O&C:
Kullback-Leibler distance, (we will use this, and call it IKL):
                                                                          745

   (1) The hypotheses in our framework are assertions                                    pillow breaking the pot’s fall. There are also alternate
          about causal structure rather than conditional                                 causes (A) of clangs, such as falling silverware.
          dependency; hence, a causal framework predicts                                    Next we will use the semantics of the noisy-or Bayes net
          different values for information gain than do O&C.                             to derive P (u | v, h) , for the case where h is the hypothesis
   (2) We propose that mapping conditional statements onto                               that the model of Figure 1 holds. This derivation works for
          hypotheses about causal structure is inherently                                all cases in which the cards in the selection task contain C
          ambiguous and depends on pragmatic considerations.                             on one side and E on the other, as is the case in our example
Here we will discuss the implications of (1), leaving the                                “if a pot is dropped then a sound is heard” (here p is C (“a
implications of (2) for the next section.                                                pot is dropped”) and q is E (“a sound is heard”), hence v, u
   The information gained from turning over card v and                                   take on values in {C, E, ¬C, ¬E}):
finding u on the other side depends on the hypotheses under
                                                                                             P ( E | C , h) = P(¬D ∨ A | h) = P(¬D) + P( D) P( A)
consideration; in particular, DKL ( S | v, u ) depends on
                                                                                             P ( E | ¬C , h) = P( A)
 P (v | u , h) for every h ∈ T, which in turn depends on the
                                                                                                              P (C ) P( E | C , h) P (C ) ( P(¬D) + P( D) P( A) )
content of each hypothesis h. In the O&C (1994) approach,                                    P (C | E , h) =                      =
                                                                                                                   P ( E | h)         P( A) + P(C ) P(¬D) P(¬A)
H is the hypothesis that q depends deterministically on p,
while ¬H is the hypothesis that p and q are independent,                                                        P (C ) P (¬E | C , h)          P(C ) P( D) P(¬A)
                                                                                             P (C | ¬E , h) =                         =
and these are the only two hypotheses considered. Thus,                                                              P ( ¬E | h )        P(¬A) ( P(¬C ) + P(C ) P( D) )
    P (q | p, H ) = 1; P (q | ¬p, H ) = b; P ( p | q, H ) = a b ; P( p | ¬q, H ) = 0
                                                                                         where the prior probabilities of C and A, P(C) and P(A),
    P(q | p, ¬H ) = P(q | ¬p, ¬H ) = b; P( p | q, ¬H ) = P( p | ¬q, ¬H ) = a             correspond to a and b in the O&C model, and the prior
where the parameters a = P ( p ) and b = P(q | ¬p) are the                               probability of D, P(D), is 1-P(E|C). (P(D) is taken to be
same for H and ¬H. Other possible hypotheses are proposed                                zero in O&C’s model for the case where p is C and q is E.)
by O&C but not developed, specifically those in which q                                  We do not require that the parameter values be the same
depends probabilistically on p, such that P (q | p, H ) < 1 .                            across hypotheses, eliminating some objections to O&C’s
                                                                                         model. One could, for example, interpret a statement to be
   In our approach, the hypothesis space T consists of causal
                                                                                         asserting that alternate causes are rare, hence S is all
structures. The conditional statement asserts that a particular
causal relationship holds between p and q, thus the true                                 structures with P(A)<0.1. For simplicity, however, we will
causal structure is in the set S of structures for which this                            discuss only those interpretations in which a structural claim
relationship holds (S ⊂ T). For a given causal structure, h,                             is being made (such as, a link exists from A to E); for these
 P (u | v, h) can be derived using the formalism of causal                               cases, the parameters will be the same across hypotheses.
Bayes nets (Pearl, 2000). For the subsequent presentation
we will work with a simple causal structure that provides a                              Interpreting conditionals as causal assertions
reasonable approximation to many of the causal structures                                Conditional statements are inherently ambiguous. Those for
asserted by common conditional statements. In this                                       which p could be a cause of q we will call “forward”
structure, a cause (C) generates an effect (E), but there are                            conditionals. They generally assert that p causes q, but the
conditions (D) that can disable the mechanism, and there are                             exact causal structure being asserted depends on pragmatics.
alternative causes (A) of the effect (see Figure 1). D                                   For example, the statement “if a pot is dropped then it
represents all disabling conditions aggregated together, and                             makes a clang” could have several different meanings, as
A represents all alternative causes aggregated together. The                             demonstrated by the following hypothetical exchanges:
arrow coming from D in Figure 1 indicates that the presence                                 (1) A: “What sound will be made if I drop this pot?”
of D blocks the causal path from C to E. This structure is the                                     B: “If a pot is dropped then it makes a clang.”
causal model behind Cheng’s power-pc theory (Cheng,                                                Meaning: dropped pots cause clangs
1997) (where P(¬D) is equal to the causal power of C to                                            Causal Assertion: dropped pots can cause clangs
generate E); the model can also be expressed as a noisy-or                                         Hypothesis Space: all structures in which dropped
Bayes net (Glymour & Cheng, 1998). For this simplified                                                pot is the cause and a sound is the effect
structure, the total hypothesis space T contains all structures                             (2) A: “I think a pot just fell.”
with one or more of the links shown in Figure 1 (subject to                                        B: “That’s impossible; I didn’t hear a clang. If a pot
the constraint that the link from D cannot exist without the                                             falls then it makes a clang.”
link from C to E).                                                                                 Meaning: dropped pots always cause clangs
                                           C         D                                             Causal Assertion: no D exists to block the path from
                                 A                                                                    dropped pots to clangs
                                                                                                   Hypothesis Space: all structures in which dropped
                                                                                                      pot is a cause of clangs
                                           E                                                In contrast, conditionals for which q could causally
                                                                                         influence p we call “reverse” conditionals. They generally
                   Figure 1: Noisy-or causal model
                                                                                         assert that q is the only cause of p, but again the exact causal
   As an example of the model of Figure 1, consider a                                    structure being asserted depends on pragmatics. For
dropped pot (C) causing a clang (E). This can be disabled by                             example, the statement “if you hear a clang then a pot was
various things (D), such as someone catching the pot or a                                dropped” could have several different meanings, as
                                                                                     746

demonstrated by the following hypothetical exchanges:                       qualitative predictions for S, T, and IKL for common types of
  (1) A: “What are those sounds coming from the kitchen?”                   conditionals, which will motivate future experiments.
        B: “Those are items being dropped. For instance, if                    Some generalizations are worth noting: (1) EIg(p) is often
           you hear a clang then a pot was dropped.”                        high. (2) for rare p and q, when structures with no C to E
        Meaning: falling pots are the primary cause of                      link have sufficient priors (e.g., a uniform prior), EIg(S,q) is
           clangs, but not necessarily the only possible cause.             often high; (3) if the conditional assumes the C to E link
        Causal Assertion: dropped pots can cause clangs                     exists, then structures with no C to E link will have low
        Hypothesis Space: all structures in which dropped                   priors and EIg(S,q) will be low. In general, with pragmatic
           pot is the cause and a sound is the effect.                      considerations, the model predicts selection of p and q cards
  (2) A: “I heard a clang. What do you think happened?”                     if the conditional asserts that C causes E, and selection of p,
        B: “It must have been a dropped pot. If you hear a
            clang then a pot was dropped.”                                  ¬q if the conditional assumes that C causes E.
        Meaning: the only cause of a clang is a dropped pot.
        Causal Assertion: no alternative cause A exists that                  Interpretation of forward conditionals with cause known
           can cause clangs.                                                  We know from domain knowledge that p could be a cause of q.
        Hypothesis Space: all structures in which dropped                     Example:“if there is fire then there is smoke”,p=C=fire,q=E=smoke
           pot is the cause and clang is the effect.
                                                                               T
                                                                                       Interpretation 1: fire causes smoke
Predicting card selection
                                                                                                  C                                   C      D
The key point of distinction between our model and that of                              A                D                  A
O&C is in predicting information gain, because EIg is a
simple function of information gain. IKL(S|v,u) depends on                            S
the particular set of causal structures in the hypothesis space                                   E                                   E
T, as well as the set of asserted hypotheses S, and the                           Uniform Prior, EIg: p:0.442, ¬p:0.005, q:0.220, ¬q:0.032
parameters P(C), P(A), and P(D). S in turn depends on
pragmatic considerations. In Figures 2 and 3 we give                           T       Interpretation 2: fire always causes smoke
                                                                                   S                                                        C
                                                                                         C                         C     D                        D
 Interpretation of reverse conditionals with cause known                                       D          A                       A
                                                                               A
 We know from domain knowledge that q could be a cause of p.
 Example:“if there is smoke then there is fire”, p=E=smoke,q=C=fire
                                                                                         E                         E                        E
  T       Interpretation: fire is the only cause of smoke
                                                                                  Uniform Prior, EIg: p:0.189, ¬p:0.001, q:0.040, ¬q:0.018
     S      C                         C      D                 C     D           If P(3rd model)=0.01, p:0.058, ¬p:0.000, q:0.001, ¬q:0.006
  A                D         A                        A
                                                                              Interpretation of forward conditionals with single cause
                                                                              We know q has a single cause but we are not sure whether it is p
            E                         E                         E
                                                                              Example: “if a person is in the XYZ club then that person is a
     Uniform Prior, EIg: p:0.391, ¬p:0.015, q:0.205, ¬q:0.033                 good computer hacker”, p=C=good hacker, q=E=in the club
    If P(3rd Model)=0.01, p:0.305, ¬p:0.000, q:0.001, ¬q:0.051
                                                                               T      Interpretation: good hackers get into the XYZ club
 Interpretation of reverse conditionals with single cause
                                                                                                  C                                   C      D
 We know p has a single cause but we are not sure whether it is q                       A                D                  A
 Example: “if a person is in the XYZ club then that person is a
 good computer hacker”, p= E=in the club q=C=good hacker                             S
                                                                                                  E                                   E
  T     Interpretation: good hackers get into the XYZ club
                                                                                  Uniform Prior, EIg: p:0.758, ¬p:0.052, q:0.758, ¬q:0.052
                     C                                   C       D
            A               D                   A                                    Figure 3: Predictions for forward conditionals.
                                                                                Dotted arrows indicate a mixture of two hypotheses, one in which the
         S                                                                             arrow is present, and one in which the arrow is absent.
                                                                                            All EIg values assume P(C)=P(A)=P(D)=0.1
                      E                                   E
     Uniform Prior, EIg: p:0.758, ¬p:0.052, q:0.758, ¬q:0.052                 Relation to previous analyses and phenomena
         Figure 2: Predictions for reverse conditionals                     In this section we discuss how our approach accounts for
   Dotted arrows indicate a mixture of two hypotheses, one in which the     previous phenomena on the selection task. We group these
           arrow is present, and one in which the arrow is absent           phenomena within a discussion of previous approaches,
               All EIg values assume P(C)=P(A)=P(D)=0.1                     while highlighting the distinctive aspects of our approach.
                                                                        747

Information-gain (Oaksford & Chater, 1994)                          differently than other tasks? In our framework, what makes
In many of their publications, O&C analyze a simple                 them special is that they all have a consistent causal
comparison in which H asserts complete dependency and               structure, in which people follow rules to ensure that C
¬H asserts a complete independency between p and q. In              produces E reliably. For example, in the social contract “if
our model, this is identical to the assertion that T                you pay $10 then you get a watch”, the rules compel the
corresponds to all structures in which p=C, q=E, and D              seller to give the buyer a watch (E) once $10 is paid (C).
does not exist, while S corresponds to the subset of those          When the link from C to E is assumed to exist, as is the case
structures in which a link exists from C to E.                      in most social contract tasks, one should assign a prior of
   With the richer hypothesis space of causal models, the           zero to any hypothesis in T with this link missing. Since all
information gain framework predicts some previous results           the hypotheses with non-zero prior then contain links from
on the selection task that are not predicted by O&C (see            C to E, our causal analysis predicts that only IKL(p,¬q) is
next section). O&C predict that the p and q cards should be         high, and hence only the p and ¬q cards should be selected.
chosen when both p and q are rare and that the p and ¬q                Precaution tasks (Fiddick et. al, 2000) have essentially the
cards should be chosen when p or q is common. This is               same structure as social contracts: they assume that the
predicated on the assumptions that Ig(p,¬q) is 1, Ig(p,q) is        precaution is in force (i.e., the link from C to E exists), and
high for rare p and q, and Ig(¬p,q) and Ig(¬p, ¬q) are zero.        ask subjects to determine whether the rule is being followed
Our analysis suggests that these assumptions are only valid
                                                                    by everyone. Our analysis suggests that if instead the rule
if structures in T with links from C to E have sufficient
                                                                    itself is questioned (i.e., is the rule in force?), people will
priors. If these structures have very low priors, the ¬q card
should be more informative than the q card because                  interpret S as asserting that there is a link from C to E; since
IKL(S|p,q) and IKL(S|¬p,q) will be low, hence EIg(S,q) will be      this link questioned, one should assign a non-zero prior to
low. For example, suppose one asserts that “if a clang is           the structures in T in which this link is missing, making the
heard then a pot was dropped”. It is reasonable to assume           q card useful (if p and q are rare) because IKL(p,q) is high.
that dropped pots cause clangs, hence a low prior should be            The results of Fiddick et. al (2000) show that this is
placed on any structure with no link from dropped pots to           exactly what people do. Fiddick et. al (2000) published
clangs. Thus, finding a dropped pot that clanged (p,q) will         precaution experiments that show people choose q more
not be very informative, despite p and q being rare, but            than ¬q in “standard” versions of precaution studies such as
finding a dropped fork that produced a clang (p,¬q) will be         “if you go hunting then you wear [orange] jackets to avoid
very informative, hence p and ¬q should be chosen.                  being shot”. In the “standard” version, subjects are
   Almor & Sloman (1996) provide evidence that appears to           instructed to see if it is true that the jackets are for hunting,
contradict O&C (1994), in which p and q are rare, yet               whereas in the “precaution” version they are instructed to
people choose the p and ¬q cards. Some examples of their            see if any people are endangering themselves. This result
conditionals are “if a product gets a prestigious prize then it     confirms that when testing whether a social contract or
must have a distinctive quality”, and “if a product breaks          precaution is in force, people will test the assertion that a
then it must have been used under abnormal conditions”.             link exists from C to E, and hence will choose the p and q
O&C (1996) claim these results can be accounted for using           cards (provided p and q are rare).
their utility-theoretic analysis of deontic tasks. However,            O&C (1994) propose a utility-theoretic account for how
these statements would only be deontic if they were rules           people make choices in social reasoning tasks. This is
that people have to follow, but it is not apparent that this is     appropriate for tasks in which the participant is told that
the case. According to our analysis, the conditional is             catching rule violators is important (i.e., has high utility). If,
reversed (q causes p), leading subjects to interpret the
                                                                    however, the participant is being asked simply to determine
statement as asserting the absence of alternate causes (A)
                                                                    whether or not the rule is being violated, the assignment of
while taking for granted the link from C to E, thus assigning
low probability to structures without this link. For example,       utility to this information is not warranted. We avoid the
since there are other possible causes of a product breaking,        difficulty of assigning utilities to information by using
subjects choose the ¬q card (no abnormal usage) to see if p         expected information gain as the sole basis on which to
occurred (the product broke for some other reason), but             select cards. A causal analysis predicts the selection of p and
there is no need to see if abnormal usage causes breakage.          ¬q responses for any task in which structures without C to E
   A further point of differentiation is that our causal            links are given low priors, which should be the case in all
framework predicts the ¬p card should be chosen in certain          social reasoning tasks that assume the rule is in force and
cases (when IKL(¬p,q) and P(q|¬p) are both high).                   ask subjects to detect violators.
Social Contracts and Precautions (Cosmides, 1989)                   Perspective Shifting
People have been found to provide high levels of logically          Perspective shifts (interpreting “if p then q” as “if q then p”)
correct responses to Wason selection tasks about social             have been explained as the result of adopting different
contracts (Cosmides, 1989; Fiddick, Cosmides, & Tooby,              perspectives on a rule – the enforcer vs. actor. We propose
2000). A debate has emerged over whether this is evidence           that perspective shifts occur when three conditions are met:
for a specialized social reasoning engine. Social contracts do      (1) C is a known cause of E, (2) it is not obvious whether D
indeed seem to be special, but do people reason about them          exists, and (3) it is not obvious whether A exists. This sets
                                                                748

up the hypotheses in Figure 4. For example, “if you pay $10         necessary for q if A does not exist, and p is sufficient for q if
then you get a watch” can be shifted to “if you got a watch         D does not exist.
then you paid $10” because our domain knowledge tells us
that no disabling conditions exist (the buyer must get the                                     Conclusion
watch once $10 are paid), and no alternate causes exist (the        Causal reasoning underlies many of our intuitive judgments
buyer cannot get the watch without paying).                         in everyday life, and the results we present here demonstrate
                                                                    that causal structure plays an important role in a domain of
  T
         Example: if you pay $10 you will get a watch               reasoning previously thought to be governed by logic and
                                                                    probability. Our approach predicts a number of effects on
      S                                                C
           C
                 D
                                 C       D                D         the selection task that do not follow naturally from previous
   A                     A                      A                   approaches. If used appropriately, the selection task is an
                                                                    excellent tool for testing people’s abilities to gather
                                                                    evidence and become more informed about their world.
           E                     E                     E            Since knowing the causal structure of the world is of great
                                                                    value for making predictions in every life, it is perhaps not
             Figure 4: Perspective shifting hypotheses              surprising that the cards people naturally select tend to be
   On this view, perspective shifting occurs not just on            those that maximize the amount of knowledge that can be
deontic tasks, but in any situation in which the above three        obtained about causal structure from a single observation.
conditions are met. For example, “if water boils then it is
over 100°C” could easily be interpreted to imply that “if                                      References
water is over 100°C then it will boil”. Perspective shifting        Ahn, W., & Graham, L. M. (1999). The impact of necessity and
can therefore occur, even in non-deontic situations, when              sufficiency on information choices in the Wason four-card
                                                                       selection task. Psychological Science, 10, 237-242
the asserted structure does not contain D or A links.               Ahn, W. (1999). Effect of Causal Structure on Category
                                                                       Construction. Memory & Cognition, 27, 1008-1023
Necessity and Sufficiency (Ahn & Graham, 1999)                      Ahn, W., Kalish, C. W., Medin, D. L., & Gelman, S. A. (1995).
                                                                       The role of covariation vs. mechanism information in causal
Ahn & Graham (1999) show that most people choose the                   attribution. Cognition, 54, 299-352.
normative response if it is clear that the statement asserts        Almor, A. & Sloman, S. A. (1996). Is deontic reasoning special?
either that p is a sufficient condition for q or that q is a           Psychological Review, 103(2): 374-380
necessary condition for p, or both. Asserting that p is a           Cosmides, L. 1989. The logic of social exchange: Has natural
sufficient condition for q corresponds to asserting that D             selection shaped how humans reason? Studies with the Wason
                                                                       selection task. Cognition, 31, 187-276
does not exist. For example, asserting that flipping the            Fiddick, L., Cosmides, L., Tooby, J. (2000). No interpretation
switch is sufficient for the lights turning on corresponds to          without representation: the role of domain-specific
asserting that nothing (D) can disable the switch. In                  representations and inferences in the Wason selection task.
contrast, asserting that q is a necessary condition for p              Cognition, 77, 1-79
                                                                    Glymour, C. & Cheng, P. (1998). Causal mechanism and
corresponds to asserting that A does not exist in the causal           probability: a normative approach. In Rational models of
model. For example, asserting that flipping the switch is              cognition, Oaksford, M. & Chater, N., Oxford University Press.
necessary for lights turning on corresponds to asserting that       Krynski, T.R., Tenenbaum, J. B.. (2003). The Role of Causal
nothing else (A) could turn on the lights. Both of these cases         Models in Reasoning Under Uncertainty. Proceedings of the
                                                                       25th Annual Conference of the Cognitive Science Society.
assume that the link from C to E exists, hence as before, p         Oaksford, M. and Chater, N. (1994). A rational analysis of the
and ¬q are the most informative cards (or q and ¬p when a              selection task as optimal data selection. Psychological Review
conditional with “must” is reversed to say “may”), which               101, 608-631
follows Ahn & Graham’s predictions. Ahn & Graham                    Oaksford, M. & Chater, N. (1996). Rational Explanation of the
(1999) also discuss cases in which p is asserted to be both            Selection Task. Psychological Review, 103 (2), 381-391
                                                                    Over, D. & Jessop, A. (1998). Rational analysis of causal
necessary and sufficient for q, in which cases subjects                conditionals and the selection task. In Rational models of
choose all 4 cards. This corresponds to asserting that neither         cognition, Oaksford, M. & Chater, N., Oxford University Press.
A nor D exist, and IKL(S|¬p,q), IKL(S|p,¬q) are both high.          Pearl, J. (2000). Causality: models, reasoning, and inference.
                                                                       Cambridge University Press
   An open question in Ahn & Graham’s (1999) theory is              Rehder, B. (2003). Categorization as causal reasoning. Cognitive
how people know whether p is necessary or sufficient for q             Science, 27, 709-748
in cases when it is not explicitly stated. A cause can be           Wason, P.C. (1996). Reasoning. In B.M. Foss (Ed.), New Horizons
necessary or sufficient for an effect, but it does not make            in Psychology, (pp. 135-151). Harmondsworth, Middlesex,
sense to say that an effect is necessary or sufficient for a           England: Penguin.
                                                                    Waldmann, M. R. (2000). Competition among causes but not
cause (e.g., a clang could not be necessary or sufficient for a        effects in predictive and diagnostic learning. Journal of
pot to drop, because dropped pots precede clangs). Because             Experimental Psychology: Learning, Memory, and Cognition,
of this causal asymmetry, some amount of causal reasoning              26, 53-76.
must precede determination of necessity and sufficiency             Acknowledgements We thank Brigid Dwyer, Sarah Newton, and
                                                                       Suzanne Luther for their enthusiastic assistance. JBT was
relationships. Furthermore, determining necessity or                   supported by the Paul E. Newton chair. TRK was supported by a
sufficiency can be done using just causal knowledge, as p is           graduate fellowship from the National Science Foundation.
                                                                749

