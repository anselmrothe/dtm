UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual Expertise Depends on How You Slice the Space
Permalink
https://escholarship.org/uc/item/3p29j0jn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Tran, Brian A.
Joyce, Carrie A.
Cottrell, Garrison W.
Publication Date
2004-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                          Visual Expertise Depends on How You Slice the Space
                                                Brian A. Tran (b3tran@ucsd.edu)
                            UCSD Department of Computer Science and Engineering, 9500 Gilman Drive
                                                     La Jolla, CA 92093-0114 USA
                                              Carrie A. Joyce (cjoyce@cs.ucsd.edu)
                            UCSD Department of Computer Science and Engineering, 9500 Gilman Drive
                                                     La Jolla, CA 92093-0114 USA
                                           Garrison W. Cottrell (gary@cs.ucsd.edu)
                            UCSD Department of Computer Science and Engineering, 9500 Gilman Drive
                                                     La Jolla, CA 92093-0114 USA
                             Abstract                                 dissociation between face and object processing.
                                                                      Prosopagnosic patients had lesions that encompassed either
  Previous studies using fMRI have found that the Fusiform            right hemisphere or bilateral FFA, while object agnosic
  Face Area (FFA) responds selectively to face stimuli. More          patients’ lesions did not (De Renzi et al., 1994).
  recently however, studies have shown that FFA activation is            Gauthier and colleagues have challenged the notion of the
  not face-specific, but can also occur for other objects if the
                                                                      face specificity of the FFA by pointing out that the earlier
  level of experience with the objects is controlled. Our
  neurocomputational models of visual expertise suggest that          studies failed to equate the level of experience subjects had
  the FFA may perform fine-level discrimination by amplifying         with non-face objects, to the level of experience they had
  small differences in visually homogeneous categories. This is       with faces (Gauthier et al., 1997; Gauthier et al., 1999a;
  reflected in a large spread of the stimuli in the high-             Gauthier et al., 1999b). She showed that the FFA was
  dimensional representational space. This view of the FFA as a       activated when bird and dog experts were shown pictures of
  general, fine-level discriminator has been disputed on a            the animals in their area of expertise. Further, she
  number of counts. It has been argued that the objects used in       illustrated that, if properly trained, individuals can develop
  human and network expertise studies (e.g. cars, birds,              expertise on novel, non-face objects (e.g. Greebles), and
  Greebles) are too “face-like” to conclude that the FFA is a
                                                                      subsequently show increased FFA activation to them
  general-purpose processor. Further, in our previous models,
  novice networks had fewer output possibilities than expert          (Gauthier et al., 1999a). Expertise in these studies was
  networks, leaving open the possibility that learning more           operationally defined as the point in training when a
  discriminations, rather than learning fine-level                    subject’s default response level (i.e. entry level) “shifts”
  discriminations, may be responsible for the results. To             from basic to the individual level. This is indexed by the
  challenge these criticisms, we trained networks to perform          subject’s reaction time for verifying individual names
  fine-level discrimination on fonts, an obviously non-face           becoming as fast as the time to verify category membership.
  category, and showed that these font networks learn a new              Neurocomputational models done first by Sugimoto and
  task faster than networks trained to identify letters. In           Cottrell (2001) and later extended by Joyce and Cottrell
  addition, all networks had the same number of output options,
                                                                      (2004) began to address the question of how and why the
  illustrating that visual expertise does not rely on number of
  discriminations, but rather on how the representational space       FFA gets recruited for these other tasks (Sugimoto &
  is partitioned.                                                     Cottrell, 2001, Joyce & Cottrell, 2004). Using four different
                                                                      types of stimulus classes (books, cans, cups and faces),
                         Introduction                                 Sugimoto and Cottrell found that the amount of expert-level
                                                                      experience on a previous task correlates with faster
The Fusiform Face Area (FFA) in the ventral temporal lobe
                                                                      subordinate level learning relative to a system that processes
has recently received much attention. Initial work appeared
                                                                      the same stimuli, but not to a subordinate level. Thus, an
to show that this area was selective for processing faces.
                                                                      area that is used for one expertise task will learn a second
Several fMRI studies showed high activation in the FFA
                                                                      expertise task faster than an area used only for basic level
only to face stimuli and not other objects (Kanwisher et al.,
                                                                      discriminations. Joyce and Cottrell (2004) further found
1997; Kanwisher, 2000). Further, studies involving patients
                                                                      that an expert network’s ability to separate individuals is
with associative prosopagnosia, the inability to identify
                                                                      reflected in highly variable responses at the representational
individual faces (Farah et al., 1995), and visual object
                                                                      layer (the hidden layer). This response variability extended
agnosia, the inability to recognize non-face objects
                                                                      to novel categories, permitting faster learning of these
(Moscovitch et al., 1997), seemed to indicate a clear double
                                                                 1345

categories. This suggests that the FFA is primed to win the
competition for a new expertise task because of its ability to
fine-tune its feature representations when given a novel
fine-level discrimination task (Joyce & Cottrell, 2004).
   While the human and computational studies of expertise
are compelling, they are not undisputed. For example,
proponents of the view that the FFA is face-specific claim
that the objects used in human expertise studies, such as
cars, dogs, birds, or Greebles, are “face-like”, meaning they
possess properties similar to faces. Thus any response of
FFA to these stimuli is due to their featural similarity with
faces, not because the FFA is a general-purpose, fine-level            Figure 1: The expertise model.
discriminator. While the network simulations, which
illustrate expertise across a wide variety of non-face objects,
                                                                    of the different letters and fonts followed the procedures
may seem to argue against this criticism, a methodological
                                                                    outlined in Dailey and Cottrell (1999). Each image was first
issue makes these results less compelling. In previous
                                                                    processed using 2-D Gabor wavelet filters (5 spatial
simulations, non-expert networks were trained on a lesser
                                                                    frequencies at 8 orientations each), a simple model of
number of discriminations (4 category labels) than expert
                                                                    complex cell responses in visual cortex. The filters were
networks (10 individual labels plus the 4 category labels). It
                                                                    applied at 64 points in an 8x8 grid, resulting in a vector of
has been argued (Mike Tarr, personal communication) that
                                                                    2560 elements (Buhmann, Lades & von der Malsburg,
if an object recognition network simply had to make as
                                                                    1990; Dailey & Cottrell, 1999). The vectors were then
many discriminations as the expert one, then it would also
                                                                    normalized via z-scoring (scaled and shifted so that they had
be able to learn Greebles faster.
                                                                    zero mean and unit standard deviation) on a per-filter basis,
   The current simulations were designed to address the
                                                                    a local operation. A principal components analysis (PCA)
criticisms cited above. First, we train the networks to
                                                                    was then applied to the normalized vectors. The top 40
perform fine-level discrimination on an obviously non-face
                                                                    components were saved and renormalized. Projections of
category: fonts. In this case, the basic level networks learn
                                                                    the stimuli onto these 40 dimensional vectors constituted the
to identify letters presented in a variety of different fonts (a
                                                                    input to the networks. Figure 1 shows the expertise model,
task any human can do with ease) while the subordinate
                                                                    which includes the image preprocessing procedure.
level networks learn to distinguish the particular font in
                                                                         A standard backpropagation network architecture was
which a letter is written (a task few humans can do). To
                                                                    used for learning classifications. The network had 40 input
address the second criticism, we present both basic and             units, each representing a principal component vector, a 30-
subordinate level networks with the same stimulus set and           unit hidden layer using the logistic sigmoid function, and 15
have them perform an equal number of discriminations (e.g.          linear output units for the font network, and 26 linear
6 letter vs. 6 font discriminations). Thus, any advantage to        outputs for the letter network. The learning rate and
learning to distinguish Greebles by the font network over           momentum were 0.01 and 0.5, respectively.
the letter network cannot be due to the number of
discriminations learned.                                            Letter training Letter networks were trained to identify
                                                                    letters across a subset of the 15 different fonts. Each
                         Experiments                                network was given the letters from 13 different fonts as the
We ran two sets of experiments. In the first, we investigated       training set and another font as the holdout set. It was then
the ability of our basic visual object processing architecture
(Dailey & Cottrell, 1999; Dailey et al. 2002; Joyce &
Cottrell, 2004) to recognize letters and fonts. This allowed
us to discover which fonts were difficult and which letters
gave good generalization once their font had been learned
(by training on other letters). We then used these results in
the second set of experiments to perform a very controlled
version of our previous “basic versus expertise network”
experiments, and investigate generalization to Greeble
expertise.
Experiment 1: Stimuli and Methods
The images used were 300x300 pixel images of letters. For
this experiment, 15 different fonts were used, and for each
                                                                       Figure 2: Training for Experiment 1. 26 letters and
of those 15 fonts, we had images of all 26 letters. The fonts
                                                                       15 fonts were used.
were chosen to be somewhat difficult. Image preprocessing
                                                                1346

                                                                                                  Avg. RMSE Avg.Accuracy(%)
                                                                          Easy Font Network         0.3419               86.19
                                                                         Hard Font Network          0.4382               76.62
                                                                          Table 1. Average RMSE and accuracy for font networks
   Figure 3: Average activation of letters for test fonts.
tested on the letters from the remaining font. Training was
stopped at either an RMSE of 0.02 or when overtraining
started to occur. The result was 15 letter networks, all
trained and tested on different fonts. Figure 2 illustrates the
training and test sets for Experiment 1.                                   Figure 5: Average activation of fonts across a test letter.
   Letter networks learned their task quickly. Figure 3
illustrates the average activation of letters for each font         average correlations between their corresponding letters,
when that font was used as the test set. The amount of              using their PCA representations. We then formed a 15 by 15
activation of an output unit can be thought of as the level of      matrix of inter-font distances, and submitted this to a
confidence that the letter unit activated corresponds to the        standard non-metric multidimensional scaling routine. The
correct letter. Although the letters in some fonts were harder      results for a two dimensional solution are shown in Figure
to generalize to than others, the average activations were          4. The plot shown had a stress of 1.9694.
quite high across all fonts. Accuracy of the networks was              We used this graph to find the three most separated and
also computed: if the activation of the unit corresponding to       the three most correlated fonts. One group of networks was
the correct letter is the highest among all other units, then       trained on the easier fonts (3 least correlated) and another
the network was correct in naming the letter. As expected,          group of networks was trained on the harder fonts (3 most
all letter networks were able to name the correct letter with       correlated). Here, 24 letters from each font were used as the
100% accuracy.                                                      training set, 1 letter as the holdout set, and 1 letter as the test
                                                                    set. This was repeated so that each letter had a chance to be
Font training Training networks to be font experts (i.e.            the test letter once. Training was stopped when overtraining
identify the font a letter is written in) for 15 different fonts    started to occur. The result is 52 different networks, 26
proved to be quite difficult. Our networks never                    from the easy font training and 26 from the hard font
satisfactorily learned the problem. In order to determine           training.
which fonts were easy enough to learn, we performed                    With these reduced training sets, networks were
multidimensional scaling on the distances between the fonts.        successfully able to learn to discriminate fonts. Verifying
Distances between fonts were defined as one minus the               our analysis, the hard font networks had a slightly harder
                                                                    time learning the task than the easy font networks (Table 1).
                                                                    Although the RMSE for both networks were high, they were
                                                                    still accurately able to name the correct font. In fact many of
                                                                    the networks had an accuracy of 100%.
                                                                       We again computed average activations of output units,
                                                                    except this time for fonts across a test letter (Figure 5). The
                                                                    importance of this plot comes in the activation for particular
                                                                    letters. A high activation means that the network had an
                                                                    easier time generalizing to the font in that letter. This
                                                                    assisted us in choosing the highly generalizable letters as
                                                                    stimuli for Experiment 2.
                                                                    Experiment 2: Stimuli and Methods
                                                                    As discussed in the Introduction, Experiment 2 was carried
                                                                    out in order to provide a novel control for our computational
                                                                    model of the visual expertise hypothesis. We used the six
      Figure 4: MDS of fonts.
                                                                1347

Figure 6: Examples of Greeble images.
most discriminable fonts, and the six letters that were the
easiest to generalize to between fonts. Two sorts of
networks, both with exactly the same training set,
preprocessing, architecture, and number of outputs, were
then trained to be either letter classifiers or font experts.
While one might consider a letter network an “expert,” for             Figure 7: Phase 1 training for Experiment 2. 6 letters
our purposes, we consider it a basic level classifier. The             and 6 fonts were used.
main characteristic of basic level categorization is that
similar things are classified into the same category. The        letter and font network were saved. These weights were
font expert, on the other hand, must take similar things (the    used as the starting points for networks in Phase 2 in order
same letter in different fonts) and differentiate between        to show how varying levels of experience with a preliminary
them. Our hypothesis is that such a network will learn the       task affected learning of a secondary subordinate level
Greeble task faster than a letter network. Thus, training in     task. For this phase, both font and letter networks ignored
Experiment 2 was divided into two separate phases. Phase 1       the 10 Greeble output units. This training procedure is
involved training the letter and font networks in a manner
                                                                 shown in Figure 7.
similar to that of Experiment 1. In Phase 2, the letter and
                                                                    In Phase 2 training, the networks trained in Phase 1 were
font networks trained in Phase 1 were then trained to
                                                                 trained to perform subordinate level classification on 10
classify Greebles. Examples of Greebles are shown in
Figure 6.                                                        Greebles. Training for this phase stopped when an RMSE
   Using the results from Experiment 1, the 6 most               of 0.05 was reached.
generalizable letters and the 6 most discriminable fonts were
chosen as the stimuli. In addition to these 36 stimuli, 5        Experiment 2: Results
different images of 10 unique Greebles were introduced in        Phase 1 Training Based on the results from Experiment 1,
phase 2. The five different images were produced by              we trained letter and font networks on stimuli that seemed
jittering the image of a specific Greeble a few pixels on the    the easiest to generalize to. Both networks were able to
x, y or x and y axes. Preprocessing of the images was as         learn the task with extremely low error. As expected, the
described in Experiment 1. Greeble images were also              letter networks initially had an easier time learning the
preprocessed using Gabor filters and PCA, however they           letters than the font networks did learning fonts. More
were not included in the generation of the PCA                   importantly, accuracy on the fine-level discrimination task
eigenvectors. Rather, the eigenvectors produced via the          (classifying fonts) became just as good as basic level
PCA on the letter/font stimuli were applied to the Greebles.     discrimination (classifying letters).
Thus, the PCA representations given to the networks
contained no a priori information about how Greebles fit
into the representational space.                                 Phase 2 Training In the second phase of Experiment 2, the
   As in Experiment 1, the networks consisted of 40 input        letter and font networks were trained to perform fine-level
units. The hidden unit layer was increased to 40 units due       discrimination on Greebles. Again the results were as
to the increased difficulty of having to solve two tasks.
Finally, there were 16 output units, where 6 represented the
category (fonts or letters), and 10 the Greebles. Learning
rate and momentum remained the same.
   Training procedures in Phase 1 were similar to that of
Experiment 1, except that only 6 letters and 6 fonts were
used. Here, 10 letter networks were trained such that for
each network, the letters for a randomly selected font were
used as the test set, the letters from another font were the
holdout set, and the remaining 4 were used for training. For
font networks, each of the 10 networks was tested on the
fonts for a randomly selected letter, another randomly
selected letter was used as holdout, and the rest were for           Figure 8: Number of epochs to learn the new task.
training. All networks were trained to 2560 epochs. At each          Error bars denote standard error.
log base 2 epoch of training in Phase 1, the weights of the
                                                             1348

                                  Figure 9: PCA of hidden units of letter network. Grouped by letter.
expected. Figure 8 shows the time in epochs needed for                mapping. In the font network (Figure 10), over training, the
both the letter and font networks to learn the Greeble task as        fonts spread farther apart over time. Hence, in order to
training on the initial task (either classifying letters or fonts)    classify the font of each letter, the network must amplify
increased. All font networks, regardless of amount of                 small differences between similar items -- all the stimuli
training, learned the Greeble task faster than the letter             representing the same letter must be classified differently.
networks. In addition, more experience with the font task             This generalizes to the Greebles; in the font network, the
resulted in improvement on learning the Greeble task while            Greebles are more spread out, making it easier for the font
more experience with the letter task yielded little                   network to learn the distinctions between them. Figure 10
improvement (although there is some indication that the               also shows that the fonts appear less spread out than the
letter networks may catch up eventually). Further work will           Greebles. This is because the network has learned to see all
be necessary to evaluate this trend. However, the point               of the letters in the same font as “the same,” whereas it has
remains that expertise in fonts is better than expertise in           not learned anything about Greebles yet. It should be noted
letters for Greeble training.                                         that each Greeble point is a different Greeble, so the
   To further understand the behavior of the networks, PCA            network is already individuating them to some extent. These
was done on the hidden unit representations prior to Greeble          results are similar to those gathered in our previous network
training. Figures 9 and 10 illustrate the spread of the stimuli       simulations using faces, cups, cans, books, and Greebles
in representational space based on the 2nd and 3rd principal          (Sugimoto & Cottrell, 2001; Joyce & Cottrell, 2004)
components (the first PC just codes the overall magnitude             illustrating that expertise in the font networks is due to the
change in the weights). In Figure 9 the six points in each            same mechanism as expertise in face and non-face object
symbol represent a given letter in 6 different fonts for a            networks.
letter network, with one additional symbol representing how
Greebles are represented prior to any training on Greebles.                                    Conclusion
In Figure 10, each symbol represents a given font for a font          The current studies illustrate that: 1) expertise can be
network, and each individual point in that symbol a different         obtained with decidedly non-face-like stimuli and that font
letter.                                                               expertise exhibits similar properties to that of face and non-
   Notice that for the letter network (Figure 9), the letters are     face objects seen in previous simulations, and 2) the
grouped together by letter identity regardless of font.               expertise in previous simulations cannot be explained by a
Similar inputs (the letters) are made more similar by this
                                   Figure 10: PCA of hidden units on font network. Points grouped by font.
                                                                  1349

greater number of subordinate level discriminations than           Dailey, M.N., Cottrell, G. W., Padgett, Curtis, and Adolphs,
basic level discriminations: in the current work these were          R. (2002). EMPATH: A neural network that categorizes
equated and the results were qualitatively similar to those          facial expressions. J. Cog. Neuro. 14(8):1158-1173.
we have obtained previously.
   Our first experiment gave us useful preliminary data for        De Renzi, E., Perani, D., Carlesimo, G., Slveri, M., and
training font experts; it showed that the task of classifying        Fazio, F. (1994). Prosopagnosia can be associated with
fonts was possible, and revealed which letters and fonts             damage confined to the right hemisphere – An MRI and
were the easiest to generalize to and train on. The behavior         PET study and a review of the literature. Psychologia,
of the networks in the second experiment was similar to              32(8):893-902.
previous studies, although our stimuli were different fonts,
not “face-like” objects. When training the networks on a           Farah, M. J., Levinson, K. L., and Klein, K. L. (1995). Face
new task, the font expert networks learned Greeble                   perception and within-category discrimination in
classification faster than the letter networks, suggesting that      prosopagnosia. Neuropsychologia, 33(6):661-674.
previous visual expertise, whether it be on object or non-
object, leads to relatively faster learning in a novel             Gauthier, I., Anderson, A. W., Tarr, M. J., Skudlarski, P.,
discrimination task. In addition, an equal number of                 and Gore, J. C. (1997). Levels of categorization in visual
discriminations were required of both letter and font                recognition studied with functional MRI. Current
networks. Thus, the expertise advantage could not be due to          Biology, 7:645-651.
the sheer number of partitions the representational space
was divided into, but instead is due to how the space was          Gauthier, I., Behrmann, M., Tarr, M. J., (1999a). Can face
divided. We conclude that visual expertise does not depend           recognition really be dissociated from recognition?
on the type of stimuli, nor on the number of stimuli used for        Journal of Cognitive Neuroscience, 11:349-370.
training, but on how you slice the space.
                                                                   Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P.,
Future Work                                                          and Gore, J. C. (1999b). Activation of the middle
We plan to train face networks to become font experts, thus          fusiform “face area” increases with expertise in
generalizing the Greeble expertise work. We expect face              recognizing novel objects. Nature Neuroscience,
expert networks will learn font expertise faster than basic          2(6):568-573.
level categorizers. We then plan to train human subjects to
become font experts, using fMRI to image both prior to and         Joyce, C. A., Cottrell, G. W. (2004). Solving the visual
after training to ascertain if font expertise training engages       expertise mystery. To appear in Proceedings of the
the FFA. We expect that the letter areas found in the left           Neural Computation and Psychology Workshop 8.
hemisphere will not become more highly activated by font
training. Although it should be obvious from the way that          Kanwisher, N. (2000). Domain specificity in face
letters are grouped together by the letter network, a future         perception. Nature Neuroscience, 3(8):759-762
simulation should show that letter networks are difficult to
train in font expertise.                                           Kanwisher, N., McDermott, J., and Chun, M. M. (1997).
                                                                     The fusiform face area: A module in human extrastriate
                     Acknowledgements                                cortex specialized for face perception. Journal of
                                                                     Neuroscience, 17:4302-4311.
We would like to thank Gary’s Unbelievable Research Unit,
the Perceptual Expertise Network, and the anonymous                Moscovitch, M., Winocur, G., and Behrmann, M. (1997).
reviewers for comments. This work was supported by                   What is special about face recognition? Nineteen
NIMH grant MH57075 to GWC and McDonnell Foundation                   experiments on a person with vusual object agnosia and
grant #15573-S6 to the Perceptual Expertise Network,                 dyslexia but normal face recognition. Journal of
Isabel Gauthier, PI.                                                 Cognitive Neuroscience, 9(5):555-604.
                          References                               Sugimoto, M., and Cottrell, G. W., (2001) Visual Expertise
                                                                     is a General Skill. Proceedings of the 23rd Annual
Buhmann, J., Lades, M., and von der Malsburg, C. (1990).             Cognitive Science Conference, pp. 994-999.
   Size and distortion invariant object recognition by
   hierarchical graph matching. Proceedings of the IJCCN
   San Diego, pp. II-411-416.
Dailey, M.N. and Cottrell, G. W. (1999). Organization of
   face and object recognition in modular neural network
   models. Neural Networks, 12(7-8):1053-1074.
                                                               1350

