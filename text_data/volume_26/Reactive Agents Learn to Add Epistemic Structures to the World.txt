UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reactive Agents Learn to Add Epistemic Structures to the World
Permalink
https://escholarship.org/uc/item/8057r0n5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)
Authors
Chandrasekharan, Sanjay
Stewart, Terry
Publication Date
2004-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                 Reactive Agents Learn to Add Epistemic Structures to the World
                                    Sanjay Chandrasekharan (schandra@sce.carleton.ca)
                                         Terry Stewart (tcstewar@connect.carleton.ca)
                                           Institute of Cognitive Science, Carleton University,
                                                         Ottawa, Canada, K1S 5B6
                              Abstract                                 is almost endless. Humans also add structures to the world
                                                                       to reduce cognitive complexity for artifacts. Examples
   We provide a computationally tractable model of how                 include bar codes (makes check-out machines’ decisions
   organisms can learn to add structures to the world to reduce        easier), content-based tags in web pages (makes Web
   cognitive complexity. This model is then implemented using
                                                                       agents’ decisions easier), sensors on roads (helps the traffic
   two techniques: first using a genetic algorithm, and then using
   the Q-learning algorithm. The results clearly show that
                                                                       light program’s decision-making), etc.
   organisms with only reactive behavior can learn to                     The pervasiveness of such structures across species
   systematically add structures to the world to reduce their          indicates that adding structure to the world is a fundamental
   cognitive load. We show that such learning can happen in            cognitive strategy (Kirsh, 1996). Note that these structures
   both evolutionary time and within an agent’s lifetime. An           predominantly serve a task-smoothening function – they
   extension of this model (currently being implemented) is then       make tasks easier for agents. Some of these structures have
   illustrated, where organisms with just reactive behavior learn      referential properties, but they do not exist for the purpose
   to systematically generate and use internal structures akin to      of reference. From here onwards, we will term such stable
   representations.
                                                                       structures that provide “cognitive congeniality” (Kirsh,
                                                                       1996), epistemic structures. The term is derived from a
Many organisms generate stable structures in the world to              distinction between epistemic and pragmatic action made by
reduce cognitive complexity (minimize search or inference),            Kirsh (1994).
for themselves, for others, or both. Wood mice (Apodemus                  How do organisms generate and use such structures? Can
sylvaticus) distribute small objects, such as leaves or twigs,
                                                                       this generation of structures be captured computationally?
as points of reference while foraging. They do this even               These are the questions we address in this paper.
under laboratory conditions, using plastic discs. Such ‘way-
marking’ diminishes the likelihood of losing interesting
locations during foraging (Stopka & MacDonald, 2003).
                                                                                     A Taxonomy and a Property
Red foxes (Vulpes vulpes) use urine to mark food caches                Most of the literature on epistemic structures is by David
they have emptied. This marking acts as a memory aid and               Kirsh, and from the field of Distributed Cognition in
helps them avoid unnecessary search (Henry, 1977, reported             general. Kirsh’s work explores the structural and
in Stopka & MacDonald, 2003). The male bower bird                      computational properties of such structures, and how they
builds colorful bowers (nest-like structures), which are used          function. We are interested in the other half of the problem,
by females to make mating decisions (Zahavi & Zahavi,                  i.e., how such structures are generated and used. We use
1997). Ants drop pheromones to trace a path to a food                  Kirsh’s model to develop a situated cognition model of how
source. Many mammals mark their territories.                           such structures are generated. We then outline two
   At the most basic level, cells in the immune system use             simulations we implemented to test this model. An
antibodies that bind to attacking microbes, thereby                    extension of this model (currently in progress) is then
‘marking’ them. Macrophages use this ‘marking’ to identify             described.
and destroy invading microbes. Bacterial colonies use a                   Epistemic structures can be classified into three types,
strategy called ‘quorum sensing’ to know that they have                based on whom they are generated for. (examples of each in
reached critical mass (to attack, to emit light, etc.). This           brackets).
strategy involves individual bacteria secreting molecules
known as auto-inducers into the environment. The auto-                 1.    Structures generated for oneself (Cache marking,
inducers accumulate in the environment, and when it                          bookmarks)
reaches a threshold, the colony moves into action                      2.    Structures generated for oneself and others
(Silberman, 2003).                                                           (Pheromones, color codes)
   Such ‘doping’ of the world is commonly seen in lower                3.    Structures generated exclusively for others (Warning
animals. Most large animals (large body & brain size) do                     smells, badges)
not exploit this strategy. Humans, however, do so to a
tremendous degree. Markers, color-codes, page numbers,                    A central feature of such structures is their task-specificity
credit-ratings, badges, shelf-talkers, speed bugs, road signs,         (more broadly, function/goal-orientedness). To illustrate
post-it notes, the list of epistemic structures used by humans         this concept, consider the following example. Think of a
                                                                   198

major soccer match in a large city, and thousands of fans              Now, some of the randomly generated structures are
arriving in the city to watch. The organizers put up large          encountered while executing tasks like foraging and cache
soccer balls on the streets and junctions leading up to the         retrieval. In some random cases, these structures make the
venue. Fans would then simply follow the balls to the game          task easier for the organisms (following pheromones
venue. Obviously, the ball reduces the fans’ cognitive load,        reduces travel time, avoiding urine makes cache retrieval
but how? To see how, we have to examine the condition               faster, avoiding leaf-piles reduce foraging effort). In other
where big soccer balls don't exist to guide the fans.               words, they shorten paths in the task environment. Given
   Imagine a soccer fan walking from his hotel to the game          the postulated bias to avoid tiredness, these paths get
venue. She makes iterated queries to the world to find out          preference, and they are reinforced. Since more structure
her world state (What street is this? Which direction am I          generation leads to more of these paths, structure generation
going?), and then does some internal processing on the              behavior is also reinforced.
information gained through the queries. After every few set            This theoretical framework gives us the basis for building
of iterated queries and internal processing, she updates her        artificial agents who also display the ability to learn to
world state and mental state, and this continues until she          systematically generate useful structures in their
reaches her destination.                                            environment.
   What changes when the ball is put up? The existence of
the big soccer ball cuts out the iterated queries and internal                             The Simulation
processing. These are replaced by a single query for the ball,      To test and investigate the above model of epistemic
and its confirmation. The agent just queries for the ball, and      structure generation, we have developed a computational
once a confirmation of its presence comes in, she updates           model, where simple agents in a simple world, given
her world state and internal state. The ball allows the agent       feedback only in terms of their ‘tiredness’ (i.e., the effort
to perform in a reactive, or almost-reactive mode, i.e., move       required to perform their task), learn to systematically add
from perception to action directly. The key advantage is            structures to their environment.
that almost no (or significantly less) inference or search is          The task we have chosen is analogous to foraging
required.                                                           behavior, i.e., navigating from a home location to a target
   This happens because the ball is a task-specific structure;      location and back again. Our environment consists of a
it exists to direct soccer fans to the game venue. Other            30x30 toroidal grid-world, with one 3x3 square patch
structures, like street names and landmarks in a city, are          representing the agent’s home, and another representing the
function-neutral or task-neutral structures. The fans have to       target. This ‘target’ can be thought of as a food source, to
access these task-neutral structures and synthesize them to         fit with our analogy to foraging behavior.
get the task-specific output they want. Once the huge ball, a
task-specific structure, exists in the world, they can use this     Agent Actions
structure directly, and cut out all the synthesizing. How the
                                                                    At any given time, an agent can do one of five possible
soccer fans manage to discover the ball's task-specificity is a
                                                                    actions. The first and most basic of these is ‘moving
separate and relevant issue, but we will not address it here.
                                                                    randomly’. This consists of going straight forward, or
Task-specificity is a property of all epistemic structures
                                                                    turning to the left or right by 45 degrees and then going
found in nature, including pheromones and markers.
                                                                    forward. The agent does not pick which of these three
   Kirsh's model of “changing the world instead of oneself”
                                                                    possibilities occurs (there is a 1/3 chance of each).
(Kirsh, 1996), postulates that such generation of structures
                                                                        In deciding the actions available to the agent, we needed
involve task-external actions, and these structures work by
                                                                    to postulate some basic facilities within each agent. In our
deforming the state space, so that paths in a task
                                                                    case, we felt it was reasonable to assume that the agents
environment are shortened. Such structures also allow new
                                                                    could distinguish between their home and their target. To do
paths to be formed in the task environment. Kirsh’s model
                                                                    this, we added two more actions to the agents’ repertoire.
tackles only physical structures generated by organisms, like
                                                                    These are exactly like the first action, but instead of moving
tools. He does not consider structures generated for
                                                                    randomly, the agent would move towards whichever square
cognitive congeniality.
                                                                    is sensed to be the most ‘home-like’ (or the most ‘target-
                                                                    like’). Initially, the only things in the environment that are
                  The Tiredness Model                               ‘home-like’ or ‘target-like’ are the home and the target
How are task-specific structures that lower cognitive               themselves.
complexity generated? In this paper we consider the case of            One way to think about these actions is to consider the
non-human organisms like ants, wood mice and red foxes.             pheromone-following ability of ants. Common models of
We will make two reasonable assumptions here. One,                  ant foraging (e.g. Bonabeau et al, 1999) consist of the
organisms sometimes generate random structures in the               automatic release of two pheromones: a ‘home’ pheromone
environment (pheromones, urine, leaf piles) as part of their        and a ‘food’ pheromone. The ants go towards the ‘home’
everyday activity. Two, organisms can track their physical          pheromone when they are searching for their home, and
or cognitive effort (i.e., they get ‘tired’), and they have a       they go towards the ‘food’ pheromone when foraging for
built-in tendency to reduce tiredness.                              food. This exactly matches these two actions in our agents.
                                                                199

The ‘home’ pheromone would be an example of a ‘home-                 The internal sensors are two simple bits of memory. One
like’ structure in the ant environment.                              indicates whether the agent has been to the target yet, and
   The fourth and fifth possible actions provide for the             the other indicates how long it has been since the agent
ability to generate these ‘home-like’ and ‘target-like’              generated a structure in its environment (up to a maximum
structures. In the standard ant models, this could be thought        of 5 time units). This is all that the agents can use to
of as the releasing of pheromones. However, our simulation           determine which action to perform.
has an important and very key distinction. Here, this ability           This configuration gives each agent 192 (4 x 4 x 6 x 2)
to modify the environment is something the agents can do             possible different sensory states.
instead of moving around. That is, this generation process
requires time and effort. The best way to envisage this is to                           The Learning Rules
think of an action that a creature might do which                    For a purely reactive agent, we need some way of
inadvertently modifies its environment in some way.                  determining which action the agent will perform in each of
Examples include standing in one spot and perspiring, or             these 192 states. We investigated two different methods for
urinating, or rubbing up against a tree. These are all actions       matching sensory states to actions: a Genetic Algorithm, and
which modify the environment in ways that might have                 Q-Learning.
some future effect, but do not provide any sort of immediate
reward for the agent. Kirsh (1996) terms these ‘task-                Stage 1: The Genetic Algorithm
external actions’.
                                                                     For our first model, we used a genetic algorithm to
   It must be stressed here that we are not presuming any
                                                                     determine which action to take in each situation. The
sort of long-term planning on the part of the agents. We are
                                                                     genome consisted of a simple list of actions, one to perform
simply specifying a collection of actions available to them,
                                                                     in each state. To evaluate a particular genome, we started
and they will choose these actions in a purely reactive
                                                                     10 agents in the home location and ran the simulation for
manner (i.e., based entirely on their current sensory state).
                                                                     1000 time steps. The evolutionary fitness was the agents’
It may also be noted that our ‘actions’ are considered at a
                                                                     average tiredness (i.e., how long it took each agent to make
slightly higher level than is common in agent models. Our
                                                                     it back home from the target).
agents are not reacting by ‘turning left’ or ‘going forward’;
they are reacting by ‘following target-like things’ or
‘moving randomly’. Furthermore, they do not initially have
any sort of association between the action of making ‘home-
like’ structures and the action of moving towards ‘home-
like’ things. Any such association must be learned (either
via evolution, or via some other learning rule).
   Also, our agents are not designed to form structures
automatically as they wander around (as is the case in
standard ant models). In our simulation, a creature must                Figure 1: The computer model at 10, 100, and 300 time
expend extra effort to systematically generate these                    steps. Black dots are the agents. The shading is darker
structures in the world. An agent that does this will be                the more ‘home-like’ or ‘target-like’ a particular square
efficient only if the effort spent in generating these                  is. This run shows typical agent behaviour after 300
structures is more than compensated for by the effort saved             generations.
in having them. Moreover, these are not permanent
structures. The agents’ world is dynamic and the structures
do not persist forever. The ‘home-likeness’ or ‘target-              Result: Initially, the agents behaved randomly. Starting at
likeness’ of the grid squares decrease exponentially over            the ‘home’, they would wander about and might, by chance,
time. Furthermore, these structures also spread out over             find the target and then, if they were very lucky, their home.
time. A ‘home-like’ square will make its neighboring                 Indeed, most agents did not find the target and make it back
squares slightly more ‘home-like’. This can be considered            within the 1000 time steps. On average, we found that each
similar to ant pheromones dispersing and evaporating, or             agent was completing 0.07 foraging trips every 100 time
leaf/twig piles being knocked over and blown around by               steps. After a few hundred generations, the agents were
wind or other passing creatures.                                     soon completing an average of 1.9 trips in that same period
                                                                     of time. In other words, the agents were able to, on an
Agent Sensing                                                        evolutionary time scale, learn to make use of their ability to
   Since our agents are reactive creatures and thus do no            sense and generate structures in the world. Furthermore,
long-term planning, they require a reasonably rich set of            this ability provided a very large advantage over completely
sensors. We have given them four sensors, two external and           random behaviour.
two internal, to detect their current situation. The two                This result confirmed that it is possible for agents to learn
external sensors sense how ‘home-like’ and how ‘target-              to systematically generate and use structures in the world in
like’ the current location is (digitized to 4 different levels).     an evolutionary time scale. It also showed that we had not
                                                                 200

chosen an impossible task for the agents to learn. However,                 Q-Learning, but we are able to conclude that the significant
for our purposes, we were much more interested in an                        improvement seen in the previous experiment is due to the
individual agent learning to generate epistemic structures                  agents’ ability to modify their environment.
within that agent’s lifetime. To investigate this, we turned to
the Q-Learning algorithm.
                                                                                              Foraging trips per 100 time steps
Stage 2: Q-Learning                                                               0.8
The heart of our investigation was to determine whether a                         0.7
simple, general learning algorithm would allow our agents
                                                                                  0.6
to discover and make use of the strategy of systematically
adding structures to the world. In keeping with our                               0.5
‘tiredness’ theory, the only feedback the learning                                0.4
mechanism had was an indication of the exertion or effort.
The delayed-reinforcement learning rule known as Q-                               0.3
Learning (Watkins, 1989) seemed best suited for this task.                        0.2               Learning Without Structure Generation
(Other similar algorithms will be investigated in future                                            Learning With Structure Generation
                                                                                  0.1
work). The Q-Learning algorithm1 develops an estimate of
the eventual outcome of performing a given action in a                              0
given situation. The agent then performs the action with the                         100   200  300   400   500   600   700   800   900 1000
highest expected payoff.                                                                                Simulation Time
   Using the Q-Learning algorithm, we again ran 10 agents
for 1000 time steps. To indicate ‘tiredness’, we gave them a
reinforcement value of -1 all the time (indicating a constant                   Figure 2: The effect of epistemic structure generation.
‘punishment’ for expending any effort). When they returned                      The foraging rate is measured in trips per 100 time
home after finding the target, they were given a                                steps. A foraging rate of 0.5 means that trips require
reinforcement of 0, and they were then sent back out again                      an average of 200 time steps to complete.
for another trip. Each agent independently used the Q-
Learning algorithm, and there was no communication                             We can also see from Figure 2 that having these extra
between the agents.                                                         actions available does incur some cost in the early stages.
                                                                            Initially, the agents perform slightly worse. However, the
Result: The dark line in figure 2 shows the results averaged                advantage of being able to form epistemic structures quickly
over 100 separate trials. We can clearly see that the agents                improves the agents’ performance. By the end of the
are improving over time (i.e., they are spending less time to               simulation, agents require only around 150 time steps to
perform their foraging task).                                               make a complete trip (a foraging rate of 0.66 trips in 100
                                                                            time steps). This is twice as quick as agents without the
Stage 3: Confirmation                                                       structure-forming ability.
Although we have observed improvement over time, we still
need to show that it is the agents’ ability to systematically                      Table 1: Time spent performing various actions.
add structures to the world that is causing this effect. To
prove this, we re-ran the experiment, this time removing the                              Action                  With           Without
agents’ ability to generate structures in the world. No other                                                   Structure        Structure
changes were made.                                                                                            Generation        Generation
                                                                                Move randomly                     10%              32%
Result: We found that when the agents were unable to                            Toward ‘home-like’                19%              36%
generate structures in the world, Q-Learning did not provide                    Toward ‘target-like’              13%              32%
as much improvement2. This result is shown in the lighter                       Make ‘home-like’                  35%
line in Figure 2. There is still a small improvement given by                   Make ‘target-like’                23%
1                                                                              When we analyzed the actions of the agents, we found
  The estimated reward for performing action a in state s is Q(s,a).
                                                                            that they actually spent 58% of their time generating
This is increased by α(r+γmax(Q(s’,b))-Q(s,a)), where r is the
immediate reward/punishment, s’ is the resulting state, γ is the            structures. This is striking, since time spent generating
future discounting rate (set to 0.5), and α in the learning rate (0.2).     these structures means less time for wandering around
We used an ε-choice rule with ε set to 0.1, so the agents choose the        trying to find the target or their home. Table 1 gives the
action with the highest expected reward 90% of the time, and the            breakdown of how time was allocated to different actions.
other 10% they perform an action at random.                                 The data indicates that epistemic structure generation
2
  Q-Learning also did not provide significant improvement if the            allowed the agents to go from spending 300 time steps down
agents were only able to generate one type of structure, or if any of       to 150 time steps to complete their foraging task, even
the agent’s sensors were removed.
                                                                        201

though over half of those 150 time steps are spent standing            That said, all of these other models assume both that
still. There is clearly a large efficiency advantage to making      pheromones are continually being released while the ant
use of these structures.                                            forages, and that there is no learning happening during the
   There are many Reinforcement Learning algorithms                 foraging behaviour. Our Q-Learning model does not make
available other than Q-Learning, and any one of them could          either of these assumptions.
be used in this sort of model. As we investigate other, more           We were unable to find references indicating that real ants
complex situations, we will try using these alternatives to Q-      might, in fact, learn to use pheromones, or any research that
Learning, such as actor-critic methods. All of these models         indicates that the effort required to produce these
learn in a similar way, but with rather different details, and      pheromones might interfere with foraging behaviour. So our
so the resulting high-level behaviour may be different.             model may not be a good one for understanding ants.
                                                                    However, the fact that our agents are able to learn to
                         Conclusions                                reflexively generate these cognitively beneficial structures
   The Q-Learning system is a concrete implementation of            in the absence of any immediate feedback to their benefit,
our model: a simple learning mechanism that allows agents           indicates a simpler way to model more complex creatures
with purely reactive behavior to systematically add                 that exhibit such behaviour.
structures to the world to lower search.
   The ‘tiredness’-based learning model implemented in this                                 Future Work
simulation can explain the generation of task-specific              Our current simulation implements a learning process based
structure in cases 1 and 2 (structures for oneself and              on the feedback of tiredness. It leads to organisms
structures for oneself & others). Case 2 (structures generated      generating task-specific external structures in the world.
for oneself & others) is explained by appealing to the              These are structures that lower cognitive load, accessed by
similarity of systems – if a structure provides congeniality        organisms at run-time, while they execute tasks.
for me, it will provide congeniality for other systems like            Interestingly, the same model can explain generation and
me. In our computer model, the agents ended up forming              tracking of internal structures in organisms. The actions
structures that were useful for everyone, even though they          which generated structure in our simulation were actions
were just concerned about reducing their own tiredness.             that affected the environment. But this does not have to be
This was possible only because the agents were similar to           the case. Just as we had both internal and external sensors,
each other. This is similar to how paths are formed in              we can have actions which affect either the state of the
fields: one person cuts across the field to reduce his physical     world or the state of the agent itself. In other words, we can
effort, others, sharing the same system and wanting to              use this model to investigate the generation of internal
reduce their effort, find the route optimal. As more people         structure (i.e., representations).
follow the route, a stable path is formed.                             As an example, consider foraging bees. Suppose that, just
   For case 3, (structures generated exclusively for others),       as our agents left traces in the world of their activity via
the ‘tiredness’ model explains only some cases. For                 their structure-generating actions, we have the bees leave a
instance, it could explain the generation of warning smells         sequence of internal memory traces corresponding to
and colors exclusively for others, because the effect of such       landmarks (say a tall tree, a lake, a garden) as a result of
structures could be formulated in terms of tiredness (the           their everyday foraging activity. In some foraging trips of
release of some chemical ends up cautioning predators,              some bees, the trace sequences match to some degree the
which reduces the number of fleeing responses the organism          external structures they perceive. Such trips involve less
makes, thus reducing tiredness, which, when fed back,               search, because they lead to food more directly, i.e., they
reinforces the initial action). However, this model, as it          form shorter paths in the task environment. Over time, using
stands, cannot explain the generation of structures like the        the exact same learning mechanisms that apply in the
bower or the peacock’s tail, which do not seem to provide           external case, the bias against tiredness leads to such paths
any tiredness benefit for the generator.                            being used more, and so they are reinforced. This leads to
                                                                    landmark-based navigation, which, in fact, exists in bees
                       Other Models                                 (Gould, 1990). As in the case of external structures, the
                                                                    generation of such memory traces is reinforced because
It is worth noting that our model presents a novel simulation       more traces lead to more such shorter paths in the task
of ant behaviour. The closest existing models are those in          environment. We are currently working on a computational
(Bonabeau et al, 1999) which use the ‘home-pheromone’               model of this example. Interestingly, recent research shows
and the ‘food-pheromone’. This is in contrast to such               homing pigeons using human-generated environment
models as (Nakamura & Kurumatani, 1996), where a land-              structure in a similar fashion to reduce cognitive load. They
based and an airborne pheromone are used, or any models of          follow highways and railways systematically to reach their
the Cataglyphis species of ant, which uses a complex                destination (Guilford, 2004).
landmark-navigation scheme which allows it to return                   The above framework presents a situated cognition model
directly to the nest (Miller & Wehner, 1988).                       of how memory structures come to be used as task-specific
                                                                    structures, and why such internal structures are
                                                                202

systematically generated. If such task-specific memory             Bonabeau E., Dorigo M. and Theraulaz G. (1999) Swarm
structures are considered to be representations (that is, they       intelligence: From natural to artificial systems. Santa Fe
stand for something specific in the world), then the model           Institute studies in the sciences of complexity. New York:
explains, in a computationally tractable manner, how                 Oxford University Press.
organisms with just reactive behavior can learn to generate        Clark, A. (1997). Being There: putting brain, body, and
and use representations.                                             world together again, Cambridge, Mass., MIT Press.
   The model also explains what such ‘primitive’                   Gould, J.L. (1990) Honey bee cognition. Cognition, 37, 83-
representations are: they are the internal traces of the world       103.
that allow the agent to shorten paths in a task environment.       Guilford, T., Roberts, S. & Biro, D. Positional entropy
Roughly, they are computation-reducing structures (and               during pigeon homing II: navigational interpretation of
                                                                     Bayesian latent state models. Journal of Theoretical
equivalently, energy-saving structures). They are internal
                                                                     Biology, published online, (2004).
‘stepping stones’ that allow organisms to efficiently
                                                                   Henry, J.D. (1977). The use of urine marking in the
negotiate the ocean of stimuli they encounter. This means            scavenging behaviour of the red fox (Vulpes vulpes).
the traditional cognitive science view, that thinking is             Behaviour, 62:82-105.
computations happening over representations, presents a            Kirsh, D., & Maglio, P. (1994). On distinguishing epistemic
secondary process – it describes a privileged path in the task       from pragmatic action. Cognitive Science, 18, 513-549.
environment. In the stepping stone view, representations are       Kirsh, D. (1996). Adapting the environment instead of
crucial for organisms, but they are just useful, incidental          oneself. Adaptive Behavior, Vol 4, No. 3/4, 415-452.
entities, not fundamental entities by themselves. We are           Miller, M., & R. Wehner (1988). Path integration in desert
exploring the philosophical implications of this view.               ants, Cataglyphis fortis. Proceedings of the National
   All source code for the simulations can be found at:              Academy of Sciences USA 85: 5287-5290.
   http://www.carleton.ca/iis/TechReports/code/2004-01/            Nakamura, M., & Kurumatani, K. (1996). Formation
                                                                     mechanism of pheromone pattern and control of foraging
                    Acknowledgment                                   behavior in an ant colony model. Proceedings of the Fifth
                                                                     International Conference on Artificial Life, 67-74.
   Some of the ideas presented in this paper were developed        Silberman, S. (2003), The Bacteria Whisperer. Wired, Issue
while the first author worked as a pre-doctoral fellow with          11.04, April 2003.
the Adaptive Behavior and Cognition (ABC) Group of the             Stopka, P. & Macdonald, D. W. (2003) Way-marking
Max Planck Institute for Human Development, Berlin. He               behavior: an aid to spatial navigation in the wood mouse
acknowledges the group's support, particularly the strong            (Apodemus sylvaticus). BMC Ecology, published online,
encouragement and critical feedback from Dr. Peter Todd              http://www.biomedcentral.com/1472-6785/3/3
and Dr. John Hutchinson.                                           Watkins, C. (1989). Learning From Delayed Rewards,
                                                                     Doctoral dissertation, Department of Psychology,
                        References                                   University of Cambridge, Cambridge, UK.
Alcock, J. (1998). Animal Behavior: An evolutionary                Zahavi, A., & Zahavi, A. (1997). The Handicap Principle: A
   approach, Sunderland, Mass., Sinauer Associates.                  missing piece of Darwin's puzzle. Oxford: Oxford
Bogen, J. (1995). Teleological explanation. In Honderich             University Press.
   (Ed.), The Oxford Companion to Philosophy. New York:
   Oxford University Press.
                                                               203

