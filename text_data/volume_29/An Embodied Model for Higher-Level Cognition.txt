UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Embodied Model for Higher-Level Cognition
Permalink
https://escholarship.org/uc/item/4kt834hp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Author
Bittencourt, Guilherme
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              An Embodied Model for Higher-Level Cognition
                                              Guilherme Bittencourt (gb@das.ufsc.br)
                                                 Departamento de Automação e Sistemas
                                                  Universidade Federal de Santa Catarina
                                                  88040-900 - Florianópolis - SC - Brazil
                              Abstract                                  based on evolutionary computation (Baum, 2004), to model
                                                                        cognition it is necessary to define the elements of an evo-
   In this paper we describe a cognitive model based on the sys-
   temic approach and on the Autopoiesis theory. The syntactical        lutionary environment where such evolutionary computation
   definition of the model consists of logical propositions but the     can take place. In natural evolution, the DNA codes for pro-
   semantic definition includes, besides the usual truth value as-      teins, but the protein behavior depends on its three dimen-
   signments, what we call emotional flavors, that correspond to
   the state of the agent’s body translated into cognitive terms.       sional structure that is not coded in the DNA. The match be-
   The combination between logical propositions and emotional           tween code and “good” behavior is computed by selection,
   flavors allows the agent to learn and memorize relevant propo-       staying alive (and reproducing) is the positive feedback to the
   sitions that can be used for reasoning. These propositions are
   represented in a specific format – prime implicants/implicates       significant matching. To model cognition using an evolution-
   – which is enriched with annotations that explicitly store the       ary algorithm, we need to define, on the one hand, the code,
   internal relations among their literals. Based on this represen-     and we propose to adopt a specific logical representation –
   tation, learning, reasoning and memory mechanisms are de-
   scribed.                                                             prime implicants/implicates –, and, on the other hand, the
   Keywords: Artificial Intelligence, Cognitive Science, Learn-
                                                                        necessary feedback modeled in a minimalist approach, only
   ing, Memory, Reasoning, Situated cognition, Knowledge rep-           by “good” or “bad” emotions. Finally, we need variability and
   resentation, Logic.                                                  selection, and time to let them work. Although no particular
                                                                        evolutionary algorithm is described, the paper formally de-
                          Introduction                                  fines a possible computational framework that supports these
In recent years the interest in logical models applied to prac-         necessary features.
tical problems such as planning (Bibel, 1997) (Pollock, 2000)              The model to be defined is a first approximation. Several
and robotics (CogRobo, 2003) has been increasing. Although              aspects of the model could and should be extended to include
the limitations of the sense-model-plan-act approach have               more complex mechanisms, but this presentation remains as
been greatly overcome (Giacomo, Lespérance, Levesque, &                 simple as possible, in order to stress the solution schema pro-
Sardina, 2002), the gap between the practical ad hoc path               posed by the model to a specific conceptual problem: how a
to “behavior-based artificial creatures situated in the world”          cognitive agent is to learn and explore meaning in its envi-
(Brooks, 1991) and the logical approach is yet to be filled.            ronment.
   In this paper we define a logic-based generic model for                 The proposed model can be viewed from two perspectives,
a cognitive agent. This model found inspiration in several              an external one, that consists of the model’s desiderata and
sources. From the systemic approach (Morin, 1991) and                   includes the description of what would be interesting for a
from the Autopoiesis theory (Varela, 1989) came the hypoth-             cognitive mechanism to do, given the restrictions imposed by
esis that cognition is an emergent property of a cyclic dy-             the environment definition, and an internal one, that describes
namic self-organizing process. From the Theory of Evolu-                how the interesting features of the cognitive mechanism —
tion (Darwin, 1998) and from the Memetics theory (Dawkins,              learning, reasoning, remembering – are in fact implemented.
1976) came the belief that variability and selection is the             In the sequel, italic expressions should be understood as tech-
base of both life and cognition. From (dilettante) neurobi-             nically defined terms in the model and “quoted” expressions
ology (Changeux, 1983) (Changeux, 2002) (Damasio, 1994)                 are intended to evoke a certain “meaning” whose precise def-
(Damasio, 2000) came the guidelines for pursuing psycho-                inition is out of the scope of the model.
logical plausibility. From Piaget’s Genetic Epistemology (Pi-
aget, 2001) came the requirement that learning and cognition
                                                                                                  External View
should be closely related and, therefore, that the cognitive            The proposed cognitive agent is immersed in an unknown en-
modeling process should strongly depend on the cognitive                vironment and is going through an “experiential flux”. This
agent’s particular history. From the logicist school (Newell,           flux, its domain according to the Autopoiesis theory nomen-
1980) (Newell, 1982) (Brachman & Levesque, 1985) and                    clature, is represented as a set of primitive propositional sym-
the work on Cognitive Robotics (Levesque, Pirri, & Reiter,              bols – P = {p1 , . . . , pn } –, the simple unities that compose the
1998) came the focus on computational logical models. From              cognitive agent. In a first approximation, the only property of
Wittgenstein (Wittgenstein, 1933) came the intended episte-             each propositional symbol is its truth value.1 Therefore, the
mological status of logic.                                              space is defined as the set of all possible truth assignments
   Assuming that cognition can be captured by a computa-                    1 This property could be generalized to allow fuzzy (Yager &
tional model (Scheutz, 2002) and that this model is somehow             Filev, 1994) or multiple values (Belnap, 1977). The adopted logic
                                                                    107

to this set of propositional symbols – A P . We also suppose                agent has the motivation that good emotional flavors be true
that, as time goes by, the environment drifts along the possi-              and bad ones false.3
ble states through flips of the primitive propositional symbols                These emotional flavors correspond to what Damasio call
truth values.                                                               “emotions” (Damasio, 2003) and define the raison d’être of
    Therefore, from the agent point of view, the environment,               the agent’s cognitive mechanism: to control the truth val-
including the agent itself, is “conceived” as an unbound                    ues of emotional flavors using controllable symbol manipula-
temporal sequence of assignments . . . , εt−1 , εt , εt+1 , . . . where     tions. Damasio has suggested that while the senses of vision,
εi ∈ A P , εi : P → {true, f alse} are semantic functions that              hearing, touch, taste and smell (the primitive propositional
map propositional symbols into truth values. The primitive                  symbols of the proposed model) function by nerve activation
propositional symbols can be of two kinds: controllable and                 patterns that correspond to the state of the external world;
uncontrollable. Roughly, uncontrollable symbols correspond                  emotions are nerve activation patterns that correspond to the
to perceptions and controllable ones to actions. Perceptions                state of the internal world. If we experience a state of fear,
may include internal perceptions, i.e., internal properties of              then our brains will record this body state in nerve cell acti-
the agent that are “felt”, such as proprioceptive information               vation patterns obtained from neural and hormonal feedback,
(Berthoz, 1997), and actions may include orders to the agent                and this information (the emotional flavors of the proposed
body. Both controllable and uncontrollable symbols are “neu-                model) may then be used to adapt behavior appropriately.
tral”, in the sense that, a priori, the agent is indifferent to                Clearly the binary nature of the adopted emotional flavors
which semantic values (true or false) they assume.                          is a coarse approximation of the concept intended by Dama-
                                                                            sio: based on the notion of somatic markers, he describes a
    Primitive propositional symbols can be combined into                    range of qualitatively different phenomena, from genetically
propositions that correspond to the composite unities, accord-              determined emotions to socially learned feelings.
ing to the Autopoiesis theory nomenclature. The organiza-                      From the cognitive point of view, any motivation is directly
tion that defines these propositions are simply the rules of                or indirectly derived from the desire to control the truth values
propositional logic syntax, i.e., a proposition is simply a well            of emotional flavors and therefore, beyond their truth values,
formed formula of propositional logic and its semantics is de-              propositions only have “meaning” with respect to the emo-
rived from the truth values of its components as usual. The                 tional flavors to which they are associated.
structure associated with a specific proposition is the actual                 To satisfy this motivation, the cognitive agent should be
syntactical expression by which it is represented. It should be             able to learn the relevant relations between specific emotional
noted that a proposition can change its structure through any               flavors and propositions built up from primitive propositional
logically valid transformation, e.g., the application of an in-             symbols. Once a proposition is known to be true whenever
ference rule. Because the proposed cognitive agent is a com-                a given “good” emotional flavor is true, this proposition can
putational one, the particular adopted syntactical representa-              be associated with an abstract propositional symbol that be-
tion can have an important impact on the computational prop-                comes the cognitive counterpart of the emotional flavor. Us-
erties of the cognitive mechanism, such as efficiency, modu-                ing this proposition, the agent can “rationally” act on the truth
larity and reuse potential. The composite unities can be used               values of the proposition’s controllable symbols in such a way
as components of other composite unities, i.e., it is possible to           that the proposition truth status is preserved when the values
associate an abstract propositional symbol with a proposition               of the uncontrollable symbols change. This relation between
and to use it as an ordinary proposition symbol in another                  an emotional flavor and an abstract propositional symbol (and
proposition. Let Q = {q1 , q2 , . . .} be the set of all abstract           its learned proposition) is called a thought.
propositional symbols. Propositions in which abstract propo-                   A thought combines an emotional flavor and a logi-
sitional symbols occur are called abstract propositions.                    cal proposition. Such a proposition, because of its logi-
    In order to “embody” the agent, we assume that the state                cal properties, can possibly be factored into simpler sub-
of the agent’s “body” can be perceived through emotional fla-               propositions and these sub-propositions can be associated
vors.2 An emotional flavor has two complementary aspects:                   with abstract propositional symbols. This factoring mech-
from the cognitive point of view it can be true or false and                anism can give rise to new derived thoughts, composed by
from the agent’s body point of view it can be, in a first ap-               the sub-propositions and “refined” versions of the original
proximation, either “good” or “bad”, in the sense that the                  emotional flavor. These new emotional flavors are refined
                                                                            in the sense that, although they share the same motivat-
                                                                            ing character of the original emotional flavor, they are re-
could also be first-order or even a higher-order logic, instead of          stricted by their associated sub-propositions and, therefore,
propositional logic.
     2 It should be noted that the proposed cognitive model is intended     they can be recognized as “different” from one another with
as the highest level of a multi-level architecture (Bittencourt, 1997).     respect to the environment. The new derived thoughts “en-
The emotional flavors should be seen as the result of lower level pro-
cesses associated with the internal functioning of the agent and with           3 The representation and use of motivation have been intensively
its interaction with the external environment (e.g., (Bryson, Tanguy,       study in the multi-agent community. A popular approach is the
& Willis, 2004)). These processes are out of the scope of the present       so-called Beliefs, Desires and Intentions (BDI) (Rao & Georgeff,
cognitive model.                                                            1995).
                                                                        108

 tangle”4 the “meaning” of the original emotional flavor with                     clause entailment, implicants, equivalence, sentential en-
 the environment properties captured by their associated sub-                     tailment and model enumeration (Darwiche & Marquis,
 propositions, whose truth values ultimately depend on the                        2001).
 primitive propositional symbols.
     The formalism that supports this entanglement is the cen-                4. Prime implicates and implicants of a proposition present a
 tral point of the proposed solution to the problem of extract-                   holographic relationship, where each literal in a clause is
 ing meaning from the environment. On the one hand, its syn-                      associated with a dual clause, and conversely. This allows
 tactical abstraction mechanism allows for the construction of                    the identification of which dual clauses are “critically” af-
 complex control mechanisms, articulated with the environ-                        fected by a given clause.
 ment properties through the progressive automatizing of the
 lower level abstract propositions. On the other hand, seman-                     The first and most important property – the uniqueness of
 tically it allows that general emotional flavors such as hunger               the prime representations – deserves more comments. The
 and sexual attraction, be refined in principle into complex                   prime representations in PIP are unique in the sense that,
 thought structures able to control behaviors such as search                   given a set P of propositional symbols, any proposition built
 for eatable fruits and build a nest to show you are a good sex-               up with symbols of P has one and only one representation in
 ual partner; or even go to a French restaurant and buy a red                  PIP, but the structure of any pair in PIP depends only on the
 Ferrari.                                                                      relations between the propositional symbols and not on their
                                                                               identity with respect to the set P. Therefore, each pair rep-
                      Working Hypothesis                                       resents a whole family of structurally identical propositions
 The main hypothesis underlying the proposed cognitive                         that only differ in the names that are attributed to its variable
 model consists in restricting the organization and structure of               symbols. Propositions that belong to the same family can be
 the propositions that participate in thoughts in such a way that              transformed among them simply by renaming their proposi-
 these propositions are always represented using prime nor-                    tional symbols, possibly by a negated value.
 mal forms. Given a proposition ψ, its prime normal forms                         The psychological properties of these proposition families,
 consist of a set of prime implicates (PIψ ) and a set of prime                such as the ease with which they are learned from examples,
 implicants (IPψ ), defined as special cases of conjunctive nor-               were studied since the 1950s. In (Feldman, 2003), a review of
 mal forms (CNF) and disjunctive normal forms (DNF), re-                       this research and a complete catalog of the propositions with
 spectively, that consist of the smallest sets of clauses (or                  up to four propositional symbols are presented. The propo-
 terms) closed for inference, without any subsumed clauses                     sitions are shown in complete DNF, in Polya’s hypercube-
 (or terms), and not containing a literal and its negation.5 We                based notation, and in a (heuristically determined) minimal
 call PIP the set of all such pairs of prime representations:                  form. To our knowledge, the prime forms were not yet con-
                                                                               sidered either in the Boolean functions or in the psychological
                   PIP = {(PIψ IPψ ) | ψ ∈ L (P)}                              research contexts.
     This choice is due to the following properties of these nor-              Example 1 Consider the following propositional theory, rep-
 mal forms:                                                                    resented in complete disjunctive normal form:
1. The prime form representations are unique (up to the or-                               (a ∧ ¬b ∧ c) ∨ (¬a ∧ b ∧ ¬c) ∨ (a ∧ b ∧ ¬c)
     der of literals, clauses and terms that occur in them). The
     only other unique representation for propositions is com-                    It is one of the 162 possible Boolean functions with 3
     plete DNF6 which is usually much larger than prime forms.                 propositional symbols. It also belongs to one of the 13 fam-
                                                                               ilies in which these 162 functions are distributed. It has 3
2. Given both prime representations of a given formula ψ, the
                                                                               models and its negation has 5 models, adding up to 23 = 8,
     prime representations of its negation can be obtained di-
                                                                               the number of possible models with 3 propositional symbols.
     rectly:7 PI¬ψ = IPψ , IP¬ψ = PIψ .
                                                                                  The prime implicates and prime implicants associated with
3. The prime implicates and implicants of a proposition can                    this family can be represented by the following PIP pair:
     be queried in polynomial time for consistency, validity,
                                                                                    0 : (¬b{0} ∨ ¬c{1} )∧
                                                                                                                                            
      4 Although  “entangle” is not a technically defined term of the
 model, it would be if the model is extended to emotional flavors, be-           1 : (a{0} ∨ ¬c{1} )∧         0 : (a{3,1} ∧ ¬b{0} ∧ c{2} )∨ 
 cause it represents the necessary combination operation that would             
                                                                                 2 : (b{1} ∨ c{0} )∧
                                                                                                                                             
 have to be defined in any emotional flavor theory.                                                            1 : (b{3,2} ∧ ¬c{1,0} )       
      5 Due to space limitations the formal definitions of logical con-             3 : (a{0} ∨ b{1} )
 cepts are not included. They can be found, for instance, in (Fitting,
 1990), (Herzig & Rifi, 1999), (Kean & Tsiknis, 1990).                         in which each literal is annotated with coordinates, that con-
      6 The disjunction of all the models of the proposition represented
 as conjunctions of literals.                                                  tain the clauses/terms to which they belong in the dual form.
      7 We note A the formula A with the truth values of all its literals      A possible interpretation of the propositional symbols of the
 flipped.                                                                      theory could be:
                                                                          109

• a - true if a prey is attractive as food. An abstract                      metaphorical relations can be used, for instance, to guide the
    propositional symbol, derived from uncontrollable primi-                 decomposition of new learned propositions into significant
    tive propositional symbols.                                              sub-propositions.
                                                                                These two dimensions can be compared with Jerry Fodor’s
• b - true if a prey is too big. An abstract propositional sym-              basic methodological principle (Fodor, 1983) that considers
    bol, derived from uncontrollable primitive propositional                 two fundamentally different types of mental processing: ver-
    symbols.                                                                 tical processing, taking place in specialized systems that carry
• c - true if the action of catching is adequate in the situa-               out a restricted set of operations on a limited type of input,
    tion. An abstract propositional symbol, derived from con-                and horizontal processing that are neither domain-specific nor
    trollable primitive propositional symbols.                               informationally encapsulated. Thoughts that share the same
                                                                             emotional flavors are similar to the specialized Fodor’s verti-
    This proposition could be associated with the emotional                  cal modules, and thoughts that share the same PIP pairs are
flavor hunger leading to a thought that could be expressed                   similar to the general horizontal modules, but in the proposed
as: “To appease hunger, if there is a prey that is too big,                  model both types share the same representational structure.
independently of it being attractive or not, do not catch it. If             These dimensions can also be seen as analogous to the two
it is not too big and attractive, then catch it.”                            judging (or, rational) functions of consciousness – Thinking
                                                                             and Feeling – proposed by C. G. Jung (Jung, 1971). The other
                           Internal View                                     two Jung’s functions of consciousness – Sensation and Intu-
Applying the adopted hypothesis to the proposed cognitive                    ition are perceiving (or, non-rational) functions and therefore
model leads to a more precise definition of the organization                 out of the scope of a cognitive model.
and structure of the agent’s cognitive mechanism. A thought τ                   The cognitive agent performs two types of activities: the
is (re-)defined as a relation between an abstract propositional              actual interaction with the environment, its “daylight” activi-
symbol (associated with a logical proposition represented by                 ties, and the reorganization of its internal structure in order to
a PIP pair) and an emotional flavor. This relation consists of               optimize storage space and reasoning efficiency, its “dream-
three elements:8                                                             ing” activities.
                                                                                During its interaction with the environment, at each mo-
• A generic pair πτ ∈ PIP with variable propositional sym-                   ment there are several active emotional flavors. Each emo-
    bols V (πτ ) = {x1 , . . . , xk }.                                       tional flavor evokes a set of memorized thoughts in which it
                                                                             participates (a thought may “entangle” more than one emo-
• A set of propositional symbols Pτ = {p1 , . . . , pk } associ-
                                                                             tional flavor). To say that the agent is aware of a given
    ated with an emotional flavor9 and with its cognitive coun-
                                                                             thought means that the agent wants to control the emotional
    terpart, the abstract propositional symbol qτ .
                                                                             flavor entanglement associated with the thought and has avail-
• A mapping µτ : Pτ → V (πτ ) that associates with each pi a                 able an instance of the PIP pair that represent the abstract
    xi that occur in the PIP pair.                                           propositional symbol associated with that thought. Let the
                                                                             present thought be τ. To attain the goal of controlling the
    It should be noted that: (i) every thought is an operational             truth value of the associated emotional flavor entanglement,
recipe to control the truth value of an emotional flavor; (ii)               the agent executes the following actions:
each emotional flavor can be associated with different PIP
pairs (different ways to control its value) and thus can partic-             • Instantiate the PIP pair πτ using the propositional symbols
ipate in different thoughts; (iii) the PIP pairs are independent                in Pτ and the mapping µτ .
of the thought contents and can also participate in different
                                                                             • Apply the appropriate reasoning method on the PIP pair.
thoughts.
    This last property shows that, besides the semantic relation             • Decide to act according to the deduced controllable propo-
that associates thoughts that share the same emotional flavors,                 sitional symbols or continue to analyze new thoughts.
thoughts can also be associated through a syntactical relation,                 These new thoughts may have three sources: (i) If one or
when they share the same PIP pair. Because the syntactical                      more of the propositional symbols in Pτ are abstract then
relation occurs at the proposition level and not at the proposi-                their associated thoughts can become new thoughts. (ii)
tional symbol level, it can lead to significant metaphorical                    Other thoughts that share the same PIP pair πτ can become
relations across different domains (Johnson, 1987). These                       new thoughts. (iii) Another emotional flavor may become
     8 These three elements are analogous to the three “subjects” in            active and invoke new thoughts.
the semiosis definition: “(...) an action, or influence, which is, or
involves, a cooperation of three subjects, such as a sign, its object,          During the reorganization period, the agent does not in-
and its interpretant; this tri-relative influence not being in any way       teract with the environment. It executes an internal activity
resolvable into actions between pairs.” (Peirce, 1974)
     9 We explicitly avoid representing the emotional flavor in the for-     that can be defined as a search for the “most suitable” defini-
malism, because only its syntactical counterpart actually belongs to         tions of abstract propositional symbols with respect to storage
the proposed cognitive model.                                                space and reasoning efficiency. According to the principles
                                                                         110

adopted in (Bittencourt, 1997), we assume that this optimiza-             sented in example 1. Intellectual learning consists in receiv-
tion mechanism is implemented through an internal evolu-                  ing a CNF representation of the proposition.
tionary algorithm that evolves the best representations.                     During the “dreaming” activities, the learned DNF and
   The interaction activity uses the environment semantics                CNF forms are transformed by the learning mechanism into
compressed into memorized thoughts, together with all its re-             the prime implicants and prime implicates of the proposition.
lations with similar thoughts that share either the same emo-             Once one of the forms in available the other can be calcu-
tional goals or the same operational patterns, to learn and gen-          lated to form a PIP pair that can be integrated into the mem-
erate behavior intended to control the truth values of active             ory contents according to the semantic and syntactical dimen-
emotional flavors. The reorganization activity builds and re-             sions.
fines these relations.                                                       The PIP pair can now be used to reason. For instance,
   To implement these two types of activities it is necessary             given a partial assignment that falsifies the symbol b, a dis-
to define a mechanism that acquires the agent propositions, a             junctive reasoning would reduce the thought proposition to
learning method; a mechanism that uses the acquired propo-                a ∧ c, guiding the agent to verify the value of a to decide
sitions in order to recognize and predict states of the environ-          which value of c is adequate. Given a partial assignment
ment, a reasoning method; and, finally, a maintenance mech-               that attributes the value true to the symbol a, a conjunctive
anism that optimizes, according to some given criteria, the               reasoning would result in two rules ¬b ∨ ¬c and b ∨ c, that
proposition representation, a memory management method.10                 read “if big do not catch, if not big then catch”.
   Two learning mechanisms are possible: practical learning,                 In the semantic dimension, the memory mechanism would
in which the the patterns of perceptions (uncontrollable sym-             associate the thought in the example to other thoughts that
bol values) and actions (controllable symbol values), that re-            can satisfy the emotional symbol hunger, e.g., a thought for
sult in an intended truth value for a given emotional flavor are          selecting eatable fruits if the agent is omnivore. In the syntac-
directly learned from the environment; and intellectual learn-            tical dimension, the associated thought would share the PIP
ing, in which a trusted oracle communicates all the rules that            pair but not the emotional flavor, e.g., the emotional flavor
define the relevant proposition.                                          “relieve the stress” could use the same PIP pair with the fol-
   To reason means to take into account the effect of a par-              lowing interpretation: a - true if you feel angry, b - true if you
tial assignment describing the environment on the PIP pair                are talking with the boss and c - true if you criticize the one
associated with the thought and to calculate a new resulting              you are talking to.
PIP pair. This new pair can be seen as a complex action rule,                                      Conclusion
specific to the situation described by the partial assignment:
                                                                          The paper has described a logical cognitive model that allows
the disjunctive part indicates which are the closest situations
                                                                          an agent to learn, reason and remember using “significant
in which the proposition is true and the conjunctive part can
                                                                          propositions”. The main hypothesis underlying the model
be used as local rules to choose an appropriate action.
                                                                          is that prime implicants/implicates are good candidates for
   The agent’s memory contains thoughts. These thoughts are
                                                                          “cognitive building blocks”. The model also assumes that the
“indexed” according to two different dimensions: a semantic
                                                                          agent is “embodied” and that its “body” state is reported to
one, that associates thoughts that share the same emotional
                                                                          the cognitive mechanism through emotional symbols, whose
flavor, and a syntactical one, that associates thoughts that
                                                                          exact nature is not specified. Using these assumptions the
share the same PIP pair. The “daylight” activity of the mem-
                                                                          concept of thought is formally defined and its properties ex-
ory is to provide relevant thoughts to be used to control active
                                                                          plored.
emotional flavors. The “dreaming” activity consists of orga-
                                                                             Future work includes implementing experiments where the
nizing the structure of memorized thoughts in such a way that
                                                                          whole model, including emotional flavors and evolutionary
the “remembering” mechanism works effectively. The goal
                                                                          optimization, could be tested. Some possible application do-
of the organizing mechanism is to find (or better, to evolve)
                                                                          mains that are being investigated are robot soccer (Costa &
sensible abstract propositional symbol definitions that facil-
                                                                          Bittencourt, 2000) and Internet search (Freitas & Bittencourt,
itate the storage, inference and communication of thoughts.
                                                                          2003). We also intend to refine the logical part of the model
The search for these definitions is done by some evolutionary
                                                                          introducing modal and first-order formalisms (Bittencourt &
algorithm.
                                                                          Tonin, 2001).
Example 2 Consider the thought introduced in example 1,
practical learning consists in being exposed to the eight situ-
                                                                                                    References
ations that correspond to the models of the proposition and to            Baum, E. B. (2004). What is thought? A Bradford Book The
memorize the models associated with situations that best sat-                MIT Press. (p. 478)
isfy the emotional symbol hunger. Syntactically, these models             Belnap, N. (1977). A useful four-valued logic. In J. Dunn
are represented by the complete DNF of the proposition pre-                  & G. Epstein (Eds.), Modern uses of multiple-valued logics
                                                                             (pp. 8–37). D. Reidel Pub. Co., Dordrecht, Holland.
   10 A more formal presentation of the mathematical details of these     Berthoz, A. (1997). Le sens du mouvement. Editions Odile
mechanism is done elsewhere (Marchi & Bittencourt, 2004).                    Jacob, Paris.
                                                                      111

Bibel, W. (1997). Let’s plan it deductively. In Proceedings           Giacomo, G. D., Lespérance, Y., Levesque, H., & Sardina,
  of IJCAI 15 (p. 1549-1562). Nagoya, Japan, August 23-29:              S. (2002). On the semantics of deliberation in Indigolog
  Morgan Kaufmann (ISBN 1-55860-480-4).                                 - from theory to implementation. In D. M. D. Fensel
Bittencourt, G. (1997). In the quest of the missing link. In            F. Giunchiglia & M.-A. Williams (Eds.), Principles of
  Proceedings of IJCAI 15 (p. 310-315). Nagoya, Japan, Au-              knowledge representation and reasoning (kr2002) (p. 603-
  gust 23-29: Morgan Kaufmann (ISBN 1-55860-480-4).                     614). Morgan Kaufmann. (Toulouse, France, April 22-25)
Bittencourt, G., & Tonin, I. (2001). An algorithm for dual            Herzig, A., & Rifi, O. (1999). Propositional belief base up-
  transformation in first-order logic. Journal of Automated             date and minimal change. Artificial Intelligence, 115(1),
  Reasoning, 27(4), 353-389.                                            107-138.
Brachman, R., & Levesque, H. (Eds.). (1985). Readings in              Johnson, M. (1987). The body in the mind the bodily basis
  knowledge representation. Morgan Kaufmann Publishers,                 of meaning, imagination, and reason. The University of
  Inc., Los Altos, CA.                                                  Chicago Press. (p. 233)
                                                                      Jung, C. G. (1971). Psychological types (collected works,
Brooks, R. A. (1991, January). Intelligence without represen-
  tation. Artificial Intelligence (Special Volume Foundations           vol. 6). Princeton, NJ: Princeton University.
  of Artificial Intelligence), 47(1-3), 139-159.                      Kean, A., & Tsiknis, G. (1990). An incremental method for
                                                                        generating prime implicants/implicates. Journal of Sym-
Bryson, J. J., Tanguy, E. A. R., & Willis, P. J. (2004). The
                                                                        bolic Computation, 9, 185-206.
  role of emotions in modular intelligent control. AISB Quar-
                                                                      Levesque, H. J., Pirri, F., & Reiter, R. (1998). Foundations for
  terly The Newsletter of the Society for the Study of Artificial
                                                                        the situation calculus. Electronic Transactions on Artificial
  Intelligence and Simulation of Behaviour, 117.
                                                                        Intelligence, 2, 159-178.
Changeux, J.-P. (1983). L’homme neuronal. Collection                  Marchi, J., & Bittencourt, G. (2004). Propositional rea-
  Pluriel, Librairie Arthème Fayard.                                    soning for an embodied cognitive model. In Proceedings
Changeux, J.-P. (2002). L’homme de vérité. Harvard Univer-              of the XVII Brazilian symposium on artificial intelligence
  sity Press Odile Jacod. (p. 402)                                      (SBIA’04). September 29 - October 1, São Luís, Maranhão,
Costa, A. C. P. L., & Bittencourt, G. (2000). Dy-                       Brazil: Lecture Notes in Artificial Intelligence, Springer
  namic social knowledge: A comparative evaluation. In                  Verlag.
  Proceedings of the International joint conference IB-               Morin, E. (1991). La méthode 4, les idées. Editions du Seuil,
  ERAMIA’2000/SBIA’2000 (Vol. 1952, p. 176-185). Lecture                Paris.
  Notes in Artificial Intelligence, Springer Verlag.                  Newell, A. (1980). Physical symbol systems. Cognitive Sci-
Damasio, A. R. (1994). Descartes’ error: Emotion, reason,               ence, 4, 135-183.
  and the human brain. G.P. Putnam’s Sons, New York, NY.              Newell, A. (1982). The knowledge level. Artificial Intelli-
Damasio, A. R. (2000). The feeling of what happens:                     gence, 18, 87- 127.
  Body and emotion in the making of consciousness. Harvest            Peirce, C. (1974). The collected papers of C.S. Peirce. Har-
  Books.                                                                vard University Press, Cambridge, Mass.
Damasio, A. R. (2003). Looking for Spinoza joy, sorrow, and           Piaget, J. (2001). The psychology of intelligence. Routledge
  the feeling brain. Harcourt Books, Orlando, Florida, USA.             Classics. (Malcolm Piercy and D. E. Berlyne (translators))
Darwiche, A., & Marquis, P. (2001, August). A perspec-                Pollock, J. L. (2000). In ATAL’99: 6th international work-
  tive on knowledge compilation. In Proceedings of the 17th             shop on intelligent agents, agent theories, architectures,
  international joint conference on artificial intelligence (IJ-        and languages (pp. 71–90). London, UK: Springer-Verlag.
  CAI’01) (p. 175-182). Seattle, Washington, USA.                     Rao, A. S., & Georgeff, M. P. (1995). BDI agents: from the-
Darwin, C. (1998). The origin of species. New York: Modern              ory to practice. In Proceedings of the first international
  Library.                                                              conference on multi-agent systems (pp. 312–319). San
                                                                        Francisco, CA: MIT Press.
Dawkins, R. (1976). The selfish gene. Oxford University
                                                                      Scherl, R., & Levesque, H. J. (2003, March). Knowledge, ac-
  Press.
                                                                        tion, and the frame problem. Artificial Intelligence, 1(144),
Feldman, J. (2003). A catalog of boolean concepts. Journal
                                                                        1–39.
  of Mathematical Psychology, 47, 75-89.
                                                                      Scheutz, M. (Ed.). (2002). Computationalism new directions.
Fitting, M. (1990). First-order logic and automated theorem             A Bradford Book The MIT Press.
  proving. Springer Verlag, New York.                                 Varela, F. J. (1989). Autonomie et connaissance: Essai sur le
Fodor, J. A. (1983). The modularity of mind. A Bradford                 vivant. Editions du Seuil, Paris.
  Book The MIT Press.                                                 Wittgenstein, L. (1933). Tractatus logico-philosophicus.
Freitas, F. L. G., & Bittencourt, G. (2003). An ontology-               Routledge & K. Paul, London. (Originally published in
  based architecture for cooperative information agents. In             1922)
  Proceedings of IJCAI 18 (p. 37-42). Acapulco, Mexico,               Yager, R., & Filev, D. (Eds.). (1994). Essentials of fuzzy
  August 9-15: Professional Book Center, Denver, Colorado               modeling and control. John Wiley & Sons, Inc.
  (ISBN 0-127-05661-0).
                                                                  112

