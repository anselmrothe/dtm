UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Comparing Semantic Space Models Using Child-directed Speech
Permalink
https://escholarship.org/uc/item/19m6t658
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Riordan, Brian
Jones, Micheal N.
Publication Date
2007-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                  Comparing Semantic Space Models Using Child-directed Speech
                                           Brian Riordan (briordan@indiana.edu)
                                             Department of Linguistics, 1021 E. Third St.
                                          Indiana University, Bloomington, IN 47405 USA
                                          Michael N. Jones (jonesmn@indiana.edu)
                                Department of Psychological and Brain Sciences, 1101 E. Tenth St.
                                          Indiana University, Bloomington, IN 47405 USA
                             Abstract                                for 365 days of the year, it would take more than four years
   A number of semantic space models from the cognitive
                                                                     to read the full 100 million words of the BNC. This would
   science literature were compared by training on a corpus of       make 12 years to encounter HAL’s 300 million words, and
   child-directed speech and evaluating on three increasingly        48 years to encounter all of the words COALS is trained on.
   rigorous semantic tasks. The performance of families of           At the very least, it would seem that these models are
   models varied with the type of semantic data, and not all         trained on the very high end of a scale of possible human
   models were reasonably successful on each task, suggesting a      input.
   narrowing of the space of plausible model architectures.             For the most part, semantic space modelers have only
   Keywords: semantic space models; child-directed speech;           assessed model predictions after the entire training corpus
   lexical development                                               has been processed (the exceptions being LSA (Landauer &
                                                                     Dumais, 1997) and BEAGLE (Jones & Mewhort, 2007)).
                         Introduction                                What is lacking is a consideration of the rate at which the
Semantic space models have proven successful at                      model learned its representations – information which may
accounting for a broad range of semantic data, in particular         be crucial for assessing model plausibility.
semantic priming (Jones, Kintsch, & Mewhort, 2006; Lowe                 In order to remove these potential advantages, in this
& McDonald, 2000). Since all the models are successful at            study we compare a variety of semantic space models from
accounting for the semantic data in most cases, however,             the cognitive science literature using age-stratified child-
finding tasks where the models make different predictions,           directed speech (CDS) from the CHILDES database. For
and narrowing the space of plausible models, has proven to           several reasons, CDS may offer us the important ability to
be quite difficult.                                                  decide between equally plausible models that perform
   Semantic space models have traditionally been trained on          comparably at a larger learning scale. First, CDS is arguably
adult language input. Further, the models are trained on very        much more realistic than the adult corpora that semantic
large corpora – in many cases, more data than humans                 space models have been trained on: we know that children
experience. Finally, the models are usually only applied to          learn the meanings of words with this kind of input. Second,
modeling semantic data after processing the entire training          since the size of any corpus derived from the CHILDES
corpus. Each of these steps is problematic.                          database will be much smaller than other training corpora, it
   The corpora semantic space models have been trained on            is more likely to be in the range of input for a human
range from Usenet postings (Burgess, Livesay, & Lund,                learner. Third, the caregiver speech in the CHILDES
1998; Rohde, Gonnerman, & Plaut, submitted; Shaoul &                 database can be divided according to the age of the target
Westbury, 2006) to the British National Corpus (Bullinaria           child. This allows the construction of training corpora that
& Levy, in press; Lowe & McDonald, 2000) to the TASA                 reflect changes in input over time, similar to what children
corpus (Jones & Mewhort, 2007). These corpora vary                   are actually exposed to.
widely in their content and representativeness of human                 Two previous studies have explored the behavior of
experience. However, the rationale for using a particular            semantic space models when trained on CDS. Li, Burgess,
corpus is rarely supported by an evaluation of its                   and Lund (2000) trained HAL on the caregiver speech in
representativeness. For example, Burgess et al. (1998)               CHILDES, at the time 3.8 million words. Denhière and
motivate the use of Usenet by claiming that Usenet                   Lemaire (2004) derived an LSA space from a 3.2 million
represents “everyday speech” and is “conversationally                word French corpus that included both children’s speech
diverse” – without presenting an analysis of the corpus that         and stories, textbooks, and encyclopedia articles written for
would justify this claim.                                            children. However, it is not clear what is being modeled in
   The training corpora for semantic space models are not            these studies, as the training corpora aggregate a great deal
only diverse, but large. The BNC totals 100 million words,           of data from the linguistic environments of children of a
the Usenet corpora used for HAL and HiDEX approach 300               variety of ages. The modeling target crucially affects the
million words, while COALS is trained on more than 1.2               data on which the models should be evaluated.
billion words. It has been estimated that at a rate of 150
words per minute (a high estimate), reading 8 hours per day
                                                                 599

                    Experimental Setup                                  Table 2: Semantic space algorithms compared in this
Corpus. Four corpora were constructed from caregiver                    study.
speech in the American section of the CHILDES database,                                  Context
                                                                                                          Lexical
                                                                                                                           Similarity
one for each of four broad age ranges of target child: 12-23            Space Name                        Association
                                                                                         Specification                     Measure
                                                                                                          Function
months, 24-35 months, 36-47 months, and 48-60 months.
The sizes of the corpora are listed in Table 1 1 . The Age 1            “Paradigmatic” models
corpus represents all the American caregiver input to 12-24-
month-olds in CHILDES; the other corpora were chosen to                                  Window
                                                                        COALS                             Correlation      Correlation
                                                                                         (ramped)
be of an approximately equal size.
   Unlike previous studies that used CDS from the                                                                          Inverse
                                                                                         Window           Vector length
                                                                        HAL                                                Euclidean
CHILDES database, the age group corpora used in this                                     (ramped)         normalization
                                                                                                                           distance
study were subjected to significant preprocessing. Given the
                                                                                                                           Inverse
small size of the corpora, the orthographic variation in                HiDEX
                                                                                         Window           Word frequency
                                                                                                                           Euclidian
CHILDES could potentially affect the semantic space                                      (ramped)         normalization
                                                                                                                           distance
models’ representations. First, more than 700 word forms                                                  Log-likelihood
were standardized to eliminate orthographic variation.                  LLTR             Window                            Cosine
                                                                                                          coefficient
Second, all corpora were stemmed and lemmatized using a                 Lowe &                            Positive log
                                                                                         Window                            Cosine
version of the Snowball stemmer (Porter & Boulton, 2006)                McDonald                          odds ratio
augmented to change irregular verb forms to base forms.                                                   Positive mutual
                                                                        PosPMI           Window                            Cosine
Third, most proper names in the corpora were converted to a                                               information
single generic marker. The reason for this was to avoid                 “Syntagmatic” models
proper names appearing in the list of context words for
some models (see below).                                                Full             20, 200, 2000    Entropy-based
                                                                                                                           Cosine
                                                                        dimensionality   words            (no SVD)
Models. Semantic space models may be classified into two                                                  Entropy-based
                                                                                         200, 2000
families based on architecture and representational scheme.             LSA
                                                                                         words
                                                                                                          and SVD to 300   Cosine
One family, exemplified by HAL, computes a word-by-                                                       dimensions
word co-occurrence matrix. In these models, words are
more similar when they have appeared with the same                    HiDEX (Shaoul & Westbury, 2006), a loglikelihood-
neighboring words. Sahlgren (2006) dubs these                         transformed model (McDonald & Lowe, 1998; Padó &
“paradigmatic” spaces because of their tendency to                    Lapata, 2003), Lowe and McDonald (2000), and a model
emphasize paradigmatic relationships between words.                   based on positive pointwise mutual information (Bullinaria
Another family, exemplified by LSA, computes a word-by-               & Levy, in press). The syntagmatic models were LSA and a
context matrix, where a context may be a sentence,                    corresponding model without dimensionality reduction. To
paragraph, etc. In these models words are similar to the              explore the effect of the size of the context region in
extent that they appear in the same contexts. These spaces            syntagmatic models, three versions of the full
emphasize proximal relationships between words                        dimensionality model and two versions of the LSA model
(“syntagmatic” spaces) 2 .                                            were compared. In total, 11 models were compared. All
   Models of each family were selected for comparison                 models were reimplemented for this investigation.
(Table 2). The paradigmatic models included COALS                        For the paradigmatic models, context words were selected
(Rohde et al., submitted), HAL (Burgess et al., 1998),                using an automatic procedure that approximated a specified
                                                                      number (500) of content words, considering words from
 Table 1: Sizes of the corpora constructed from the                   most to less frequent in the corpora (omitting stop words) 3 .
 CHILDES database.                                                    The context window size was constant, and set at 10
                                                                      empirically (see Riordan (2007)). For consistency with the
          Corpus size (words) Cumulative corpus size
                                                                      other models, the Euclidean distance metric used in HAL
 Age 1       460,384
                                                                      and HiDEX was converted into a similarity measure.
 Age 2       460,743                  921,127
 Age 3       458,692                  1,379,819
                                                                      Target words. Target words for this investigation were
 Age 4       450,097                  1,829,916
                                                                      selected to be sufficiently frequent and reliable in the full
                                                                      age group corpus. Reliability was determined through a
1
  See Riordan (2007) for a list of the actual corpora used within     procedure adapted from McDonald and Shillcock (2001).
each age range.                                                       Words with a cumulative frequency of greater than twenty,
2
  Random indexing models use an alternative representational
                                                                         3
scheme in which a word’s vector is assigned a distributed                  The implementation of HAL used this context word selection
representation (e.g., Jones & Mewhort, 2007; Sahlgren, 2006) and      procedure, rather than selecting the context words with the highest
may approximate either paradigmatic or syntagmatic models.            variance in the corpus, as in some HAL implementations. Lowe
                                                                      and McDonald’s context word selection procedure was maintained.
                                                                  600

plus all content words from the MacArthur CDI (Dale &
                                                                                                       F ratio
Fenson, 1996) were included, for a total of 1892 targets.
                                                                                        0 1000 2000   3000     4000 5000 6000 7000  8000
Program of evaluation. The models were subjected to three                       COALS
increasingly rigorous semantic tasks: discriminating related                       HAL
from random word pairs, modeling adult semantic data, and                         HiDEX
modeling age-of-acquisition data.                                                 LLTR
                                                                                  LOWE
                                                                               PosPMI
      Experiment 1: Word pair discrimination                                      20 EN
                                                                           20 LSA r300
As a first test of the models’ abilities to derive adequate                      200 EN
semantic representations when trained on CDS, we apply                    200 LSA r300
the models to the task of discriminating between, on the one                   2000 EN
hand, words that are known to be semantically related, and
on the other, words that have been paired randomly. We                    Figure 1: Discriminative abilities of each of the spaces on
assume that the distributional information available to a                 the full 13,354 word pair set.
semantic space model should be sufficient for the model to
locate related words in closer proximity than unrelated                  semantic space than the unrelated words. At the same time,
words in the high-dimensional space.                                     there was substantial variation in the degree to which related
   The related word pairs for this task were drawn from the              versus unrelated word pairs clustered in the spaces.
University of South Florida Word Association Norms (USF;                     It should be noted that we cannot actually conclude from
(Nelson, McEvoy, & Schreiber, 2004). In Nelson et al.’s                  the size of the F-ratio in this task that one model is “better”
word association task, subjects were given a cue, to which               than another. This is because we don’t know what the “real”
they were asked to respond with the first word that came to              discrimination of these pairs, either for a child or for an
mind that was “meaningfully related or strongly associated”              adult, would look like, since experimental data for humans
(2004: 403). Only one response was produced per cue.                     on this task does not exist.
   A subset of 49,362 USF pairs that were included in the
Maki, McKinley, and Thompson (2004) database formed
the pool of candidate related word pairs. Of these, words                  Experiment 2: Modeling adult semantic data
pairs were constrained to be made up of words that were                  As a more rigorous test of the models’ representations and
included in the 1892 word target set 4 . A set of 13,354 word            learning rates, we next compare the models on two related
pairs met this criterion. Unrelated word pairs were created              tasks where human data exists: modeling word association
by randomly pairing each cue with a response word, with                  strengths, and modeling semantic distance in WordNet.
the following constraints: no cue-response pairs from the                   The forward strength in the USF word association norms
actual cue-response word pairs could occur; no cue-                      is the probability that a cue will elicit a particular response.
unrelated response pair could occur more than once; no cue-              Using the 13,354 word pairs from Experiment 1, the models
unrelated response pair could be comprised of the same                   were compared on their abilities to predict these forward
word repeated.                                                           strengths from representation similarity. In this experiment
   Similarities in each model were derived for each of the               the age group corpora are organized cumulatively, so that
cue-response pairs and each of the cue-unrelated response                the models are exposed to greater amounts of age-
pairs. These sets of scores were submitted to a oneway                   appropriate speech (see Table 1).
ANOVA. Models were deemed to have minimally                                 For each of the cumulative corpora, the similarities in
discriminated between the sets of word pairs if the scores               each model were derived for each of the 13,354 cue-
for the cue-response set were statistically greater than the             response pairs. These similarities were entered into a linear
scores for the cue-unrelated response set (indicating tighter            regression to predict the forward strengths for the
clustering in the semantic space). The results for the                   corresponding word pairs. The forward strengths were
ANOVAs for each of the spaces are shown in Figure 1. The                 drawn from the Maki et al. database.
ANOVAs for all spaces were significant, and in each case                    With increasing age-appropriate input, we expect the
the average similarity score for the related word pair set was           variance in the adult semantic data that is explained by the
significantly greater than the unrelated word pair set. Thus,            models to increase, as the models’ semantic representations
on average, each space located the related words closer in               become more “adult-like”. More specifically, after training
                                                                         on each cumulative corpus there should be an increase in the
4
                                                                         correlations of the word-pair similarity scores derived from
  Stemming the candidate word pairs further restricted the pool of       the models and the semantic similarity scores from the
candidates,    since     some      cue-response    pairs    became       human data.
indistinguishable as a result (because of plural words used as cues,
                                                                             Figure 2 plots the change in correlation of each of the
etc.).
                                                                         models’ similarity scores with both types of semantic data
                                                                     601

Figure 2: Correlations between the models' similarity scores and the semantic data.
as more age-appropriate caregiver speech is encountered.         not similarity scores, the models’ scores are negatively
The syntagmatic models generally explain more of the             correlated with the distances.
variance in the word association data than the paradigmatic         On this task, the paradigmatic models explain more
models. They have higher average correlations with the data      variance in the adult data, reflecting the nature of the
after the Age 1 corpus (.184 vs. .120) and after processing      WordNet resource: WordNet is a hierarchical taxonomy
each of the corpora (.264 vs. .164). This may be related to      split into noun and verb parts, and the links between words
the better match of the syntagmatic architecture with the        reflect paradigmatic relationships. In addition, the models
word association data (see Sahlgren (2006)). On the other        that perform best on this task are not the same as those that
hand, the syntagmatic models are nearly uniform in their         performed the best in accounting for the word association
trajectory of improvement over time, while paradigmatic          data. For example, while the 200-word context syntagmatic
models tend to show more variation.                              models predicted the most variance in the word association
   In this task, even the best models only reached a             task, here the 2000-word context model was the best. This
correlation of about .3 with the word association data. The      likely reflects the fact that more paradigmatic information is
models’ concomitant R2 was also low, explaining less than        available in the larger context.
10% of the variance in the data.                                    The best models showed monotonically increasing
   Despite the instructions in the word association task to      correlations with the semantic data as they were exposed to
consider “meaningfully related” responses (Nelson et al.,        more input, and relatively high correlations with the data in
2004), subjects often produce responses that are collocated      both tasks. Among the paradigmatic models, COALS and
with the cue but not necessarily semantically related.           HAL met these criteria, while among the syntagmatic
Although some researchers argue that distinguishing              models only the 200-word context full dimensionality space
between semantic and associated relationships is futile          did. HAL performed surprisingly well, especially given that
(Nelson et al., 2004), other data regarding lexical semantic     the other paradigmatic models were designed to be
relatedness that focus more on semantic relationships do         improvements on its parameter choices. The LSA models’
exist. Maki et al. (2004) derived semantic distances between     non-monotonicity and similar performance to the unreduced
word pairs in WordNet using the Jiang-Conrath distance           syntagmatic spaces indicate that dimensionality reduction
measure (JCN). JCN is an information-theoretic measure of        does not automatically produce spaces that are more highly
semantic distance in the WordNet hierarchy. JCN distances        correlated with human semantic data.
have been shown to correlate highly with human judgments
of semantic similarity (Maki et al., 2004).
   Word pair similarities for the 13,354 word pair set were         Experiment 3: Modeling age-of-acquisition
used to predict the corresponding JCN distances as reported      Experiment 2 tested the models’ overall learning
in Maki et al. (2004). The lower half of Figure 2 plots the      trajectories. Most of the models gradually explained more of
correlations for the paradigmatic and syntagmatic models on      the variance in the adult semantic data as they were trained
this task. Note that since the JCN measures are distances,       on age-appropriate input. In this experiment, we focus more
                                                             602

closely on models’ learning rates by comparing the models’                                        Correlation
abilities to model age-of-acquisition (AoA) data when
trained on the cumulative input of the age group corpora.                           0  0.05   0.1   0.15    0.2 0.25 0.3   0.35 0.4
Models that more closely match AoA data may be said to
                                                                            COALS
have learning rates that more closely resemble those of
                                                                               HAL
children.
                                                                              HiDEX
   For the purposes of this experiment, as a proxy for
                                                                              LLTR
acquisition, we consider stabilization in the neighborhoods
                                                                             LOWE
of words in semantic space. We will define a word’s
semantic neighborhood as the nearest n words in a given                     PosPMI
space. At a given time, t, we can find the semantic                           20 EN
neighborhood for a word. At a later time, t+1, after the                20 LSA r300
model has been exposed to more input, we can again find                      200 EN
the neighborhood for the word, and compare it to the word’s            200 LSA r300
neighborhood at time t. As we continue this process, we                     2000 EN
will produce a record of the stabilization of a word’s
semantic neighborhood over time. We hypothesize that                   Figure 3: Correlations of the models’ average change
early-acquired words’ neighborhoods will stabilize more                coefficients with the Bird et al AoA norms
quickly than those of later acquired words.                            (Neighborhood size = 10; sample points = 8).
   For age-of-acquisition (AoA) ratings, the norms of Bird,
Franklin, and Howard (2001) were used. After stemming,                   The correlations for the remaining models with the Bird et
there were 689 words that overlapped between the Bird et              al. data are presented in Figure 3. Differences in the models’
al. norms and the target words.                                       correlations were compared using Williams’ ratio for
   To compare semantic neighborhoods, we use a modified               nonindependent correlations (see Steiger, 1980). Among the
version of combinatorial similarity, originally proposed in           paradigmatic models, COALS, LLTR, and PosPMI were
Hu, Cai, Graesser, and Ventura (2005):                                significantly more correlated with the AoA data than HAL
                                                                      and Lowe and McDonald (e.g. COALS vs. HAL: t(686) =
                                S1, x,t ∩ S 2, x,t                    2.15, p < .05; COALS vs. Lowe and McDonald: t(686) =
                      C x′ ,T =                                       3.92, p < .01). The syntagmatic models were comparable,
                                        t                             with the exception of the 20-word context LSA model,
Here, S1, x, t is the top t neighbors of a word x in space 1. S1,     which was significantly less correlated with the AoA data
x, t is composed of sets of si(x,y), the similarity scores of         (e.g. 200 LSA r300 vs. 20 LSA r300: t(686) = 2.83, p < .01).
words x and neighbors y in space 1. The numerator here is             However, the 200-word context full dimensionality model
simply the intersection of the top t neighbors, ignoring the          was significantly more highly correlated with the AoA data
similarity scores. Instead of dividing by the union of the            than PosPMI, the best paradigmatic model: t(686) = 2.26, p
neighbors in the neighborhoods as Hu et al. propose, we               < .05.
normalize by the number of neighbors in the neighborhoods                In this experiment, evidence of significant correlations
being compared (e.g. 10).                                             between the stabilization patterns in the models and a set of
   Sample points of even intervals are established across the         AoA norms were found. While significant, however, the
age group corpus. At each sample point, the semantic                  correlations of the models and the data were still rather low
neighborhoods of the target words are computed. The                   (all R2 values were less than .12). With a few exceptions, the
semantic neighborhoods of words at successive sample                  better-performing models on the previous tasks also
points are compared using the above measure of                        performed well on this task.
neighborhood overlap. Once the neighborhood change
history for the target words is established, a change
coefficient is calculated for each word. This is computed as                                   Conclusion
the average of the absolute values of the differences in              This study represents a first attempt to compare a number of
neighborhood overlap from point to point:                             semantic space models on a common corpus with common
                                  p −1
                                 ∑ C'
                                                                      evaluation tasks. The type of corpus used – CDS – was
                                        i +1 −C 'i                    selected because it is more realistic than previous training
                        change =  i =0
                                                                      corpora in terms of quantity and content.
                                         p
                                                                         Using CDS from CHILDES also naturally allowed an
where p is the number of sample points and C’ is computed             examination of the models’ learning rates. The learning rate
neighborhood overlap. Early-acquired words should have                is a crucial yardstick by which to measure models’
lower change coefficients, as their neighborhoods stabilize           performance: if models are to be taken as models of both
quickly. The neighborhood size was set at 10 and the                  lexical acquisition and representation, as Landauer and
number of sample points was 8.                                        Dumais (1997) and others have argued, they must perform
                                                                  603

reasonably given a corpus that is an accurate representation       Jones, M. N., Kintsch, W., & Mewhort, D. J. K. (2006).
of what children learn from.                                         High-dimensional semantic space accounts of priming.
  While all models showed significant discriminative ability         Journal of Memory and Language, 55(4), 534-552.
between random and related word pairs, over the course of          Jones, M. N., & Mewhort, D. J. K. (2007). Representing
two further tasks, we discovered that some models did not            word meaning and order information in a composite
have plausible acquisition rates (given our broad                    holographic lexicon. Psychological Review, 114(1), 1-37.
assumptions of what should constitute acquisition in a             Landauer, T. K., & Dumais, S. T. (1997). A solution to
semantic space). We also found a great deal of variation in          Plato's problem: the Latent Semantic Analysis theory of
the representations that models derived from the same data,          acquisition, induction, and representation of knowledge.
which in turn likely affected their learning rates. Because          Psychological Review, 104(2), 211-240.
most models differed from each other on a number of                Li, P., Burgess, C., & Lund, K. (2000). The acquisition of
parameters, further investigation of the parameters that are         word meaning through global lexical co-occurrences. In
the sources of the variation in performance is necessary.            E. V. Clark (Ed.), Proceedings of the Thirtieth Stanford
  At a wider angle, corroborating Sahlgren (2006), we                Child Language Research Forum (pp. 167-178). Stanford,
found that certain families of models are better at certain          CA: CSLI.
semantic tasks: “syntagmatic” models better accounted for          Lowe, W., & McDonald, S. (2000). The direct route:
word association, a task that often emphasizes sequential            mediated priming in semantic space. In Proceedings of the
relationships between words, while “paradigmatic” models             22nd Annual Meeting of the Cognitive Science Society
better accounted for semantic data in the absence of                 (pp. 806-811). Hillside, NJ: LEA.
association. It would appear difficult to maintain the notion      Maki, W. S., McKinley, L. N., & Thompson, A. G. (2004).
that any one semantic space model is an optimal model of             Semantic distance norms computed from an electronic
human semantic learning and memory.                                  dictionary (WordNet). Behavior Research Methods,
  In general, the models’ abilities to explain the variance in       Instruments, and Computers, 36(3), 421-431.
the human data were low. There are many possible reasons           McDonald, S., & Lowe, W. (1998). Modelling functional
for this: data sparsity in CHILDES, idiosyncrasy and noise           priming and the associative boost. In Proceedings of the
in the semantic data themselves, as well as limitations on           20th Annual Conference of the Cognitive Science Society
learning from co-occurrence data and lack of extra-linguistic        (CogSci '98) (pp. 675-680). NJ: LEA.
information. The relative contributions of these factors to        McDonald, S., & Shillcock, R. C. (2001). Contextual
model performance deserve further investigation.                     Distinctiveness: A new lexical property computed from
                                                                     large corpora: University of Edinburgh Informatics
                         References                                  Research Report EDI-INF-RR-0042.
Bird, H., Franklin, S., & Howard, D. (2001). Age of                Nelson, D. L., McEvoy, C., & Schreiber, T. A. (2004). The
  acquisition and imageability ratings for a large set of            University of South Florida free association, rhyme, and
  words, including verbs and function words. Behavior                word fragment norms. Behavior Research Methods,
  Research Methods, Instruments, and Computers, 33(1),               Instruments, and Computers, 36(3), 402-407.
  73-79.                                                           Padó, S., & Lapata, M. (2003). Constructing Semantic
Bullinaria, J. A., & Levy, J. P. (in press). Extracting              Space Models from Parsed Corpora. In Proceedings of the
  Semantic Representations from Word Co-occurrence                   41st Meeting of the Association of Computational
  Statistics: A Computational Study. Behavior Research               Linguistics, Sapporo, Japan (pp. 128-135).
  Methods.                                                         Porter, M., & Boulton, R. (2006). Snowball stemmer.
Burgess, C., Livesay, K., & Lund, K. (1998). Explorations          Riordan, B. (2007). Comparing semantic space models
  in Context Space: Words, Sentences, Discourse.                     using child-directed speech. Doctoral dissertation,
  Discourse Processes, 25(2/3), 211-257.                             Department of Linguistics and Program in Cognitive
Dale, P. S., & Fenson, L. (1996). Lexical development                Science, Indiana University, Bloomington.
  norms for young children. Behavioral Research Methods,           Rohde, D., Gonnerman, L., & Plaut, D. (submitted). An
  Instruments, & Computers, 28, 125-127.                             improved model of semantic similarity based on lexical
Denhière, G., & Lemaire, B. (2004). A Computational                  co-occurrence. Cognitive Science.
  Model of Children's Semantic Memory. In K. Forbus, D.            Sahlgren, M. (2006). The Word-Space Model. Stockholm
  Gentner & T. Regier (Eds.), Proceedings of the 26th                University, Doctoral dissertation, Department of
  Annual Meeting of the Cognitive Science Society (pp. 297-          Linguistics, Stockholm University.
  302). Hillsdale, NJ: LEA.                                        Shaoul, C., & Westbury, C. (2006). Word frequency effects
Hu, X., Cai, Z., Graesser, A. C., & Ventura, M. (2005).              in high-dimensional co-occurrence models: A new
  Similarity between semantic spaces. In Proceedings of the          approach. Behavior Research Methods, 38(2), 190-195.
  27th Annual Conference of the Cognitive Science Society.         Steiger, J. H. (1980). Tests for comparing elements of a
  Hillsdale, NJ: LEA.                                                correlation matrix. Psychological Bulletin, 87, 245-251.
                                                               604

