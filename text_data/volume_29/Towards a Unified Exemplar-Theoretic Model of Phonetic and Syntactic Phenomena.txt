UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Towards a Unified Exemplar-Theoretic Model of Phonetic and Syntactic Phenomena
Permalink
https://escholarship.org/uc/item/1wg8t21d
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Schutze, Hinrich
Walsh, Micheal
Mobius, Bernd
et al.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Towards a Unified Exemplar-Theoretic Model of Phonetic and
                                               Syntactic Phenomena
                                          Hinrich Schütze (hs999@ifnlp.org)
                             Michael Walsh (michael.walsh@ims.uni-stuttgart.de)
                             Bernd Möbius (bernd.moebius@ims.uni-stuttgart.de)
                                 Travis Wade (travis.wade@ims.uni-stuttgart.de)
                                     Institute for NLP, University of Stuttgart, Germany
                            Abstract                                Our main contribution in this paper is that we present
                                                                 a unified model that explains phonetic as well as syntac-
   In the last ten years or so, exemplar theory has enjoyed      tic phenomena. The key innovation of the model is that
   much growth in the field of phonetics. More recently,
   attempts have been made to apply exemplar theory to           it explicitly formalizes the relationship between exem-
   syntactic phenomena. Thus far, the issue of unifying          plars on the constituent level and exemplars on what we
   phonetic and syntactic exemplar-theoretic models has          call the unit level. Constituents are segments (e.g., con-
   not been addressed. This paper presents a single over-
   arching exemplar-based model of constituent interac-          sonants and vowels) in phonetics and words in syntax.
   tions across both linguistic domains which represents a       Units are syllables in phonetics and phrases or sentences
   significant first step towards a unified account of exem-     in syntax. Our simple hypothesis is that there is a com-
   plar theory. Our simulations for one phonetic and two
   syntactic phenomena provide insights into how a unified       petition between the submodel of the constituent level
   account can be achieved. In addition, the phenomena           and the submodel of the unit level and that the unit sub-
   we investigate shed light on the role of prototypes in        model “wins” if the unit exemplar receives enough acti-
   exemplar theory and on whether exemplar clouds are
   defined by a fixed radius or by a fixed number of near-       vation. A similar relationship between constituents and
   est neighbors.                                                units holds in other models (e.g. Adaptive Resonance
   Keywords: Exemplar theory; computational mod-                 Theory (Grossberg, 2003)), but to our knowledge the
   elling; phonetics; syntax; acquisition; grammaticality;       model we present here is the first that explicitly models
   diachronic language change                                    constituency in exemplar theory.
                                                                    We will show that this simple competition model ex-
                      1. Introduction                            plains three different phenomena. The first phenomenon
Exemplar-theoretic models are among the most success-            is variation in syllable duration, a phonetic phenomenon.
ful in explaining human categorization (Nosofsky, 1986;          The other two phenomena are syntactic: the grammati-
Nosofsky & Zaki, 2002). There is also an increasing body         calization of going to in English and the emergence of the
of work applying exemplar-theoretic models to phonetic           notion of grammaticality in child language acquisition.
phenomena (e.g., Goldinger (1997), Johnson (1997)).                 One of the important theoretical questions in exemplar
Recent research in speech perception has provided con-           theory concerns the status of prototypes. It has often
siderable evidence indicating that the perception process        been argued that a purely exemplar-theoretic account
is partly facilitated by accessing previously stored exem-       fails to explain many observations in human categoriza-
plars rich in phonetic detail. That is, speakers accu-           tion (e.g., during early learning of a category, (Smith,
mulate exemplars over time and compare input stimuli             Murray, & Minda, 1997)). The model proposed here is
against them. Exemplars are categorized into clouds of           strictly exemplar-theoretic without any prototype com-
memory traces with similar traces lying close to each            ponent.
other while dissimilar traces are more distant.                     Finally, we address in this paper how exemplar clouds
   The appeal of exemplar models in phonetics is that            are formed. An exemplar cloud can be defined as ei-
they explain a number of phenomena that can pose prob-           ther the k nearest neighbors around a stimulus or as all
lems for more abstractionist models. These phenomena             exemplars that have a distance of at most d from the
include the detailed episodic memory of linguistic events        stimulus, where k and d are parameters. We refer to
that humans retain; the gradual change of categories in           these two types of exemplar cloud as nearest-neighbor
one speaker (as opposed to the speech community) in his-          and radius-based. We argue that for the two syntactic
torical language change (Pierrehumbert, 2001); the plas-          phenomena we consider, radius-based exemplar clouds
ticity of phonological categories (Norris, McQueen, &             are needed.
Cutler, 2003) and frequency effects in phonetics (Juraf-            The paper is structured as follows. Section 2 intro-
sky, Bell, Gregory, & Raymond, 2001) and syntax (Bod,             duces the unified exemplar-theoretic model. In Section 3,
2006; Bybee, 2006).                                               we use the unified model to explain variation in sylla-
                                                             1461

                                syllable duration          grammaticalization         grammaticality
 stimuli                        syllable to be produced phrase (in perception) phrase (in perception)
 constituents                   segments                   words                      words
 constituent representation     acoustics, duration         word representation, left context, right context, tense
 similarity of constituents                 sum of similarities of the components of the representation
 units                          syllables                  phrases                    phrases
 unit representation                                          sequence of constituents
 similarity of units                             sum of similarities of the constituents of the units
 exemplar-based inference       duration of syllable       future tense               grammaticality of novel phrase
                            Table 1: Components of the unified exemplar-theoretic model.
                                                                 modeled) or as the part of the cognitive system that
                                                                 determines which words or phrases are to be gener-
                                                                 ated next. The unit exemplar big is an example for
                                                                 the latter case in the figure.
                                                               • An exemplar model on the unit level. The unit exem-
                                                                 plar model retrieves all exemplars that are within a
                                                                 distance of at most du from the stimulus. If the acti-
                                                                 vation the stimulus receives is above a threshold, then
                                                                 inference will be based on this unit exemplar cloud.
                                                               • An exemplar model on the constituent level. Operat-
                                                                 ing in parallel with the unit level exemplar model, for
                                                                 each constituent of the stimulus, the constituent ex-
                                                                 emplar model retrieves all exemplars that are within
                                                                 a distance of at most dc from that constituent. If the
                                                                 stimulus does not receive sufficient activation in the
                                                                 unit exemplar model, then inference is based on the
Figure 1: Architecture of the unified model. Example:            resulting constituent exemplar clouds.
The exemplar-theoretic inference process starts with the
desire to articulate the word big. The exemplar cloud         • An inference component. The inference component
of big is computed in the unit (in this case: syllable)          takes an exemplar cloud and infers a property of the
database. An exemplar cloud for each of the segments             stimulus from its nearest neighbors in the exemplar
of big is also computed in the constituent (in this case:        database. For example, the duration of a syllable is
segment) database. The desired inference (in this case:          computed as the average duration of the members of
duration) is then computed on the exemplar cloud(s)              its exemplar cloud.
that were chosen based on greatest activation (unit vs.
                                                              • Parser and composer (not shown in the figure). Im-
constituent).
                                                                 plicit in this model is a mechanism that parses a unit
                                                                 into its constituents and composes a sequence of con-
ble duration in phonetics. In Section 4, we model the            stituents into a unit. This component is different for
grammaticalization of going to as a future auxiliary in          each of the three instantiations of the model. For ex-
English. Section 5 applies the model to the acquisition          ample, the duration of a unit is equal to the sum of the
of grammaticality. Section 6 discusses our experimental          durations of its constituents. The tense of a phrase of
results, related work and future directions.                     the form going to walk is the tense of the constituent
                                                                 word going.
          2. Exemplar-theoretic model
                                                                 Table 1 shows how the unified model is instantiated
The architecture of the unified model is shown in Fig-
                                                              in the phonetic and in the two syntactic models. The
ure 1. The model has five components:
                                                              following sections describe these instantiations in more
• A generation/perception component that generates            detail.
   (possibly underspecified) unit exemplars that serve as        Our methodology in this paper is to model the input
   stimuli for the model. This component is either in-        data in a particular linguistic scenario (articulation, lan-
   stantiated by a speaker different from the one that we     guage change or language acquisition), present the model
   are modeling (as when grammaticality judgments are         in Figure 1 with these input data, and then compare the
                                                          1462

predictions of the model with the outcome that was ob-
served in the linguistic scenario.                                                                   250
      3. Variation of syllable duration                                                              200
In an exemplar model of speech production, exemplars
                                                                          number of syllable types
serve as targets or plans of articulation. Schweitzer and                                            150
Möbius (2004) note that speakers should have a signif-
icant number of exemplars for high frequency syllables,                                              100
which would then act as a production target region, and
a small or negligible number of exemplars for low fre-                                               50
quency syllables. Consequently they argue that low fre-
quency syllables would have to be computed online from                                               0
exemplars of their constituents. They predicted, and                                                       5   10                      15      20
observed, greater variation in duration for frequent syl-                                                           standard deviation in ms
lables than for infrequent syllable.1 The first simulation
tests whether we can reproduce these experimental find-          Figure 2: Experimental results for variation of syllable
ings.                                                            duration. Infrequent syllables (dashed line) have lower
   Stimuli. Stimuli were syllables of the form CVC               variability in duration than frequent syllables (solid line).
where C was one of five consonants and V one of five
vowels (for a total of 125 syllables). For each segment
(phone) the acoustic properties are modeled as a ran-            picking one of the 125 syllable types. If the type is rare,
domly generated two-dimensional vector, and the dura-            it is discarded with probability 0.99 and a new sylla-
tion value stored in a single dimension. The similarity of       ble type is generated. For the constituents of frequent
two segments or constituents was computed as the sum             syllables and infrequent syllables that survive the elimi-
of the similarities of their acoustic vectors and their du-      nation step, acoustic vectors are generated (slightly per-
rations. For vector similarity, we employed the cosine,          turbed, using uniform noise, from the canonical vector
for duration similarity an exponential transformation of         of a consonant or vowel to reflect variation in (planned)
difference:                                                      articulation). We then retrieve the syllable’s and con-
                                P                                stituents’ nearest neighbors in the unit and constituent
                                      vi wi
                       ~ = pP i2 pP 2
              sim(~v , w)                                        databases respectively, within a fixed radius. If activa-
                                 i vi       i wi                 tion in the unit database is below the threshold θ1 (i.e.,
                                                                 there are fewer than θ1 exemplars in the cloud), then the
                   sim(x, y) = e−α(|x−y|)                        unit cloud is discarded, and the three neighborhoods in
where x and y are durations and α = 0.05. α was chosen           the constituent database are employed instead. The tar-
to give good sensitivity for typical lengths of consonants       get duration of an exemplar is inferred to be the average
and vowels. Durations of syllables in the seed set were          duration of the members of its cloud. Finally, random
chosen to be 280 ms (but see Section 6), distributed in          noise proportional to the computed duration is added.
a ratio of 1:2:1 over the three constituents CVC. These          The choice of the radius parameters and of θ1 will be
numbers were chosen because 70 ms is a typical duration          discussed below.
for a consonant and 140 ms is a typical duration for a              After the syllable with the inferred duration has been
vowel. The 125 syllables types were randomly assigned            produced, it is added to the exemplar database. This
to either the frequent or the infrequent subclass.               part of the procedure models a production-perception
   Procedure. The unit exemplar database was seeded              loop, either on the individual or the community level:
with 500 syllables. In all instantiations of the model,          every produced exemplar becomes a perceived exemplar
when a unit is added to the unit database, its con-              after its production.
stituents are simultaneously added to the constituent               The final phase of the procedure consists of probing
database.                                                        the model, in an identical manner to the initial 5000
   We then ran 5000 iterations of a production-                  iterations, with 10 syllables of each of the 125 syllable
perception loop. Each iteration consists of randomly             types. The standard deviation for the syllable type is
   1
                                                                 then computed on just this sample of 10 per syllable
     Note that Schweitzer and Möbius (2004) found that z-       type. In this phase, syllables and their units are deleted
scores of frequent syllable durations were more variable than
z-scores of infrequent syllable durations. We interpret this     after each probing to make sure that infrequent syllables
here to mean that frequent syllables are more variable in du-    do not change their status to frequent in the probing
ration than infrequent syllables. We are currently conducting    phase.
further analysis of their data to confirm the validity of this
interpretation.                                                     Results. Figure 2 is a cumulative histogram of 10
                                                             1463

runs of the above experiment, corresponding to 1250            computed from the Jensen-Shannon divergence (which
standard deviations. The model successfully simulates          we again transform into a similarity using exp(−αx),
the finding of Schweitzer and Möbius (2004): frequent         here: α = 5):
syllables are more variable in duration than infrequent
                                                                                      P +Q               P +Q
syllables. This result was significant (p < 0.001, Welch                0.5(DKL (P ||       ) + DKL (Q||        ))
Two Sample t-test on 634 rare and 616 frequent sylla-                                    2                  2
bles).                                                         where P and Q are the probability distributions of the
   The difference in variation arises from the interaction     left (right) context of words 1 and 2, respectively, and
between the two submodels. Frequent syllables have             DKL is the Kullback-Leibler divergence (which we do
enough density, so that their duration is computed in          not use as a distance measure because it is asymmetric
the unit model, with noise added that is proportional to       and undefined if there is a single word that occurred in
the length of the syllable. Infrequent syllables are com-      only one of the two left (right) contexts, giving rise to a
positions of constituents that are computed in the con-        0 probability).
stituent model, each with independent noise. Therefore,           The intuition behind this representation of words is
the noise components often cancel out. Over many iter-         that we remember the typical left and right contexts of
ations of the production-perception loop, frequent sylla-      words. Two left (or right) contexts are similar to the
bles become more variable in duration whereas the vari-        extent that the distributions of words occurring in them
ability of infrequent syllables does not change much.          are similar.
                                                                  Future and motion are represented as two different
      4. Grammaticalization of going to                        four-dimensional vectors (as before, noise is added each
                                                               time a tense or motion vector is generated to reflect slight
Starting in the 17th century, the construction going to        contextual differences). Finally, the word itself is also
was grammaticalized in its use as a form of future tense.      represented as a four-dimensional vector. The similar-
We chose to model this phenomenon because it is of-            ity of two words is then computed as the sum of the
ten used as a prototypical example of the role frequency       similarities of the four components just enumerated: left
plays in language change.                                      context, right context, future/motion, and word.
   One hypothesis is that this grammaticalization was             Stimuli. In this simulation, five different construc-
caused by the temporary rise in frequency of phrases           tions were presented to the model. We give an example
like moving to do with the connotation of intention and        for each: going to fetch, going to Peter, walking to fetch,
future (where moving is any motion verb) (Tabor, 1994;          walking to Peter, and Peter fetch(es). Sentences of type
Bybee, 2006). Additional facts about the English of the        going to fetch and walking to fetch are either generated
17th century (and today’s English) are that to go is the       as future sentences or as motion sentences. There were
most frequently used motion verb and that there are            four moving verbs like walking in addition to going, five
many more literal uses of motion verbs (motion to a loca-      different non-moving verbs like fetch and five different
tion or to an object: went to London) than “verbal” uses       nouns (objects or locations) like Peter. To model the
like running to meet. We will show presently that based         three observations of historical English outlined above,
on these three assumptions, the unified model predicts          going was as frequent as the other four moving verbs
the grammaticalization of going to as a future tense. We        combined; 75% of walking/going to fetch sentences were
begin by motivating the representation of words in the         generated with future, the rest with motion; and sen-
unified model.                                                 tences of type walking/going to Peter were always gen-
   Representation of words. The similar syntactic               erated with motion and twice as likely as walking/going
behavior of two nouns like cow and hen is not directly          to fetch sentences.
apparent from their pronunciation or semantics. But               Procedure. 2000 sentences were generated accord-
an exemplar-theoretic account of syntactic behavior re-         ing to the distribution described. Left and right context
quires a similarity metric where cow and hen are simi-          vectors for each word were computed for these 2000 sen-
lar. Building on the ideas described in (Schütze, 1995),       tences. The model was then presented with 30 sentences
we define left-context and right-context components of          each of types going to fetch, walking to fetch, and going
the representation of a given focus word, where the left       to Peter. If activation of the unit exemplar cloud was
(right) context consists of a probability distribution over    high enough, the prevalence of future tense was com-
all words that occur to the left (right) of the focus word     puted as the percentage of phrases in the unit exemplar
and the dimensionality of the vector for each word is de-      cloud that were in future tense. Otherwise the preva-
pendent on the number of distinct neighbors (left and          lence was computed on the constituent exemplar cloud
right). For example, if we have experienced take cow           of the verb (walking, going etc).
twice and drop cow once, then the left context distri-            Results. Figure 3 shows cumulative histograms for
bution of cow is P (take) = 2/3, P (drop) = 1/3. The           10 runs. We assume a suitable competitive behavior be-
similarity of two left context distributions can then be       tween motion and future, so that only the more strongly
                                                           1464

                                300                                                                                                      40
                                250
                                                                                                                                         30
                                200
         number of utterances                                                                                     number of utterances
                                150                                                                                                      20
                                100
                                                                                                                                         10
                                50
                                0
                                                                                                                                         0
                                      0.0   0.2           0.4           0.6            0.8   1.0                                              0   100      200       300   400
                                            percent of future utterances in exemplar cloud                                                              activation
Figure 3: Experimental results for grammaticalization                                                  Figure 4: Experimental results for grammaticality judg-
of going to. Histogram for strength of future tense in                                                 ments. Attested sentences (solid line) receive slightly
exemplar cloud for sentence types going to fetch (solid),                                              higher activations than unattested grammatical sen-
walking to fetch (dashed) and going to Peter (dotted).                                                 tences (dotted line). All 250 ungrammatical sentences
                                                                                                       in the 10 runs received an activation of 0 (not shown).
activated alternative survives. Thus a percentage of 60%
would correspond to future, a percentage of 40% to mo-
tion.                                                                                                   Stimuli. Using 5 different verbs and 5 different nouns,
   In 99.3% of cases the future tense was not inferred for                                            25 sentence types of the form I verb noun (e.g, I love
going to Peter sentences (future inference only occurred                                              coffee) were generated and randomly assigned to the
with activations in excess of 0.5, and 96.3% of the ac-                                               subclasses attested and unattested. In addition, 25 un-
tivations which were less than or equal to 0.5 were 0).                                               grammatical types of the form I coffee love were also
For walking to fetch sentences the prevalence of future                                               generated. The same representation for words as in the
uses was consistently below 40%, for going to fetch con-                                              previous experiment was used.
sistently above 60%. Thus, the model correctly predicts
the three key phenomena that occurred in the grammat-                                                       Procedure. In 1000 iterations, an “attested” gram-
icalization of going to: (i) going to fetch is grammatical-                                               matical sentence was generated and stored in the model.
ized as future tense; (ii) the other moving verbs are not                                                 No ungrammatical and no unattested sentences were
grammaticalized and instead retain their original motion                                                  stored. An instance of each of the 25 grammatical and
sense; and (iii) sentences of type going to Peter also re-                                                of the 25 ungrammatical sentences was then presented
tain their original motion sense.                                                                         to the model.
   The basic mechanism responsible for the simulation
                                                                                                        Results. Figure 4 shows cumulative histograms for
result is again the competition between the two levels.                                               10 runs. While unattested grammatical sentences re-
Sentences of type going to fetch have dense exemplar
                                                                                                      ceive slightly lower activation than attested sentences,
clouds due to their frequency and are processed on the
                                                                                                      they clearly are close to the distribution of grammatical
unit level. Sentences of type running to fetch have sparse                                            sentences. In contrast, no ungrammatical sentence re-
exemplar clouds due to their infrequency and are pro-
                                                                                                      ceived any activation on the unit level. Thus, the model
cessed on the constituent level where there is no preva-
                                                                                                      distinguishes grammatical (activation > 0) and ungram-
lence of future uses. Sentences of type going to Peter are
                                                                                                      matical sentences (activation = 0) with 100% accuracy.
not similar on the unit level to going to fetch because of
the different left and right contexts of (proper) nouns                                                  The simulation succesfully models the acquisition of
like Peter and verbs like fetch.                                                                      grammaticality because (i) attested and unattested sen-
                                                                                                      tences have very similar representations due to similar
        5. Grammaticality judgments                                                                   left and right contexts and (ii) ungrammatical sentences
In this section, we show that grammaticality judgments                                                are dissimilar to grammatical sentences due to different
in the unified model can be formalized as activation of a                                             left and right contexts. An example for the latter is that
sentence as a unit. The reasoning is that when a sentence                                             when comparing I love coffee with I tea drink, the left
does not give rise to enough activation as a unit, but is                                             context of love (containing the subject I ) is very differ-
represented by an activation pattern of separate words,                                               ent from the left context of tea (consisting of verbs like
then it is perceived as ungrammatical.                                                                love, drink and make).
                                                                                                   1465

                     6. Discussion                                                   References
                                                               Abbot-Smith, K., & Tomasello, M. (2006). Exemplar-
We have presented a model that makes correct predic-
                                                                 learning and schematization in a usage-based account
tions for three linguistic phenomena. It is noteworthy
                                                                 of syntactic acquisition. The Linguistic Review, 23,
that the model achieves this without prototypes or any
                                                                 275–290.
explicit abstraction mechanism. Note in particular that
                                                               Bod, R. (2006). Exemplar-based syntax: How to get
Abbot-Smith and Tomasello (2006) express doubts in a
                                                                 productivity from examples. The Linguistic Review,
recent paper that a pure exemplar-theoretic model can
                                                                 23.
account for grammaticality judgments. Based on our
                                                               Bybee, J. L. (2006). From usage to grammar: The
simulations exemplar theory seems to provide an ade-
                                                                 mind’s response to repetition. Language, 82, 711–733.
quate account.
                                                               Goldinger, S. D. (1997). Words and voices—perception
   In our opinion, the experiments show conclusively that
                                                                 and production in an episodic lexicon. In K. Johnson
neighborhoods in exemplar theory must be radius-based
                                                                 & J. W. Mullennix (Eds.), Talker variability in speech
as opposed to nearest-neighbor. In the case of gram-
                                                                 processing. San Diego: Academic Press.
maticality, even ungrammatical sentences have nearest
                                                               Grossberg, S. (2003). Resonant neural dynamics of
neighbors (albeit neighbors that are far away). It is
                                                                 speech perception. Journal of Phonetics, 31, 423–445.
not clear how grammaticality judgments could be mod-
                                                               Johnson, K. (1997). Speech perception without speaker
eled with nearest-neighbor clouds. Similarly, the differ-
                                                                 normalization: An exemplar model. In K. Johnson
ence between the grammaticalization of going to fetch
                                                                 & J. W. Mullennix (Eds.), Talker variability in speech
vs. non-grammaticalization of walking to fetch also re-
                                                                 processing. San Diego: Academic Press.
quires a fixed-radius neighborhood. Previous arguments
                                                               Jurafsky, D., Bell, A., Gregory, M., & Raymond, W. D.
for nearest-neighbor clouds were based on difficulty of
                                                                 (2001). Probabilistic relations between words: Evi-
implementation (Pierrehumbert, 2001) and not on any
                                                                 dence from reduction in lexical production. In J. L.
fundamental reasons.
                                                                 Bybee & P. Hopper (Eds.), Frequency and the emer-
   One challenge for exemplar theory is to explain how           gence of linguistic structure. Amsterdam: Benjamins.
exemplars of constituents interact with exemplars of           Norris, D., McQueen, J. M., & Cutler, A. (2003). Percep-
compositions of constituents into larger units. Segments         tual learning in speech. Cognitive Psychology, 47 (2),
and words on the one hand, and syllables and phrases             204–238.
on the other hand, each give rise to exemplar clouds at        Nosofsky, R. M. (1986). Attention, similarity, and the
different levels. One of the key properties of language          identification-categorization relationship. Journal of
is the interaction of such units at different levels. The        Experimental Psychology: General, 115 (1), 39–57.
model proposed here is the first formal model of exem-         Nosofsky, R. M., & Zaki, S. R. (2002). Exemplar and
plar theory to address this issue.                               prototype models revisited: Response strategies, selec-
   The main deficiency of the work we have presented             tive attention, and stimulus generalization. Journal of
here is that we manually selected the parameters di (the         Experimental Psychology: Learning Memory and Cog-
radii of the exemplar neighborhoods) and the thresholds          nition, 28 (5), 924–940.
θi (the activation thresholds below which the constituent      Pierrehumbert, J. (2001). Exemplar dynamics: Word
level is chosen). Obviously, the performance of the model        frequency, lenition and contrast. In J. Bybee & P. Hop-
depends on the values of these parameters. If the radius         per (Eds.), Frequency and the emergence of linguistic
in the grammaticality model is too large, then even un-          structure. Amsterdam: Benjamins.
grammatical sentences will be judged grammatical (as-          Schütze, H. (1995). Distributional part-of-speech tag-
suming a sufficiently small θ). However, we believe that         ging. In Eacl 7 (pp. 141–148).
these parameters can be estimated from the distribution        Schweitzer, A., & Möbius, B. (2004). Exemplar-based
of exemplars. For example, the distances of ungrammat-           production of prosody: Evidence from segment and
ical sentences from the nearest neighbor are much larger         syllable durations. In Proc. of the speech prosody con-
that that of grammatical sentences. We are currently             ference (pp. 459–462).
exploring density estimation as one possible solution to       Smith, J. D., Murray, M. J., & Minda, J. P. (1997).
this problem. In addition, although the syllable data            Straight talk about linear separability. Journal of Ex-
here are simulated, parallel work with this model, em-           perimental Psychology: Learning, Memory, and Cog-
ploying the Schweitzer and Möbius (2004) corpus, has            nition, 23, 659-680.
yielded z-score results in keeping with their findings.        Tabor, W. (1994). Syntactic innovation: A connection-
                                                                 ist model. Unpublished doctoral dissertation, Stanford
                  Acknowledgments                                University.
This research was funded by the German Research Coun-
cil (DFG, Grant SFB 732).
                                                          1466

