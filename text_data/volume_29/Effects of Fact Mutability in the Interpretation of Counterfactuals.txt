UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Effects of Fact Mutability in the Interpretation of Counterfactuals
Permalink
https://escholarship.org/uc/item/5pt7v550
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Dehghani, Morteza
Iliev, Rumen
Kaufmann, Stefan
Publication Date
2007-01-01
Peer reviewed
  eScholarship.org                                    Powered by the California Digital Library
                                                                      University of California

                 Effects of Fact Mutability in the Interpretation of Counterfactuals
                                       Morteza Dehghani (morteza@northwestern.edu)
                                                Department of EECS, 2145 Sheridan Rd
                                                     Evanston, IL 60208-0834 USA
                                            Rumen Iliev (r-iliev@northwestern.edu)
                                           Department of Psychology, 2029 Sheridan Road
                                                      Evanston, IL 60208-2710 USA
                                      Stefan Kaufmann (kaufmann@northwestern.edu)
                                            Department of Linguistics, 2016 Sheridan Road
                                                     Evanston, IL 60208-4090 USA
                               Abstract                               2000) and the psychological evidence supporting this
                                                                      model. Also in the same section, we review Hiddelston’s
   This paper explores the relationship between fact mutability,
   intervention and human evaluation of counterfactual                (2005) extension to Causal Bayesian Networks. We then
   conditionals. Two experiments are reported that show the           discuss Kahneman and Miller’s Norm Theory (1986) and
   effects of causal strength and causal distance on fact             two psychological experiments designed to test the
   mutability and intervention. Subjects’ answers are compared        correctness of the predictions of the AI models.
   to the predictions of three models of counterfactual reasoning
   in Artificial Intelligence. This comparison demonstrates that                    The Stalnaker/Lewis Theory
   logical inferences and graph topologies are not sufficient for
   modeling all aspects of human counterfactual reasoning.            Many models of counterfactual reasoning are inspired by
                                                                      the model-theoretic accounts of Stalnaker (1968) and Lewis
   Keywords: Counterfactual Reasoning; Causal Networks;
   Norm Theory.                                                       (1973). Minor differences aside, both crucially rely on a
                                                                      notion of comparative similarity between possible worlds
                           Introduction                               relative to the “actual” world i of evaluation. Thus Lewis’s
                                                                      truth conditions state that a counterfactual ‘If it were that
Counterfactual reasoning has long been a subject of interest          Antecedent, then it would be that Consequent’ (A  C) is
to philosophers (e.g. Leibniz, 1686; Hume, 1748; Goodman,             then true at world i “if and only if, if there is an antecedent-
1947; Lewis, 1973; Stalnaker, 1968). More recently                    world accessible from i, then the consequent holds at every
linguists, psychologist, and later on cognitive scientists,           antecedent-world at least as close to i as a certain accessible
have become interested in the study of the concept of “what           antecedent-world” (p. 49). Assuming for simplicity that
would have been” and how reasoning about events that                  there is a set of A-worlds that are maximally similar to i, this
almost happened provides us with knowledge that cannot be             means that the counterfactual A  C is true if and only if C
deduced from simple facts or indicative conditionals (e.g.            is true in all of those maximally similar A-worlds.
Kahneman and Miller, 1986; Sternberg and Gastel, 1989).                  Stalnaker and Lewis account for various logical properties
In the last two decades there have been several attempts to           of counterfactuals by imposing conditions on the underlying
model counterfactual reasoning in AI (Ginsberg, 1986;                 similarity relation, but neither attempts a detailed analysis of
Costello and McCarthy, 1999; Pearl, 2000; Hiddleston,                 this notion. However, Lewis (1979), noting that his theory
2005, among others). The advantage of such formal models              “must be fleshed out with an account of the appropriate
is that they make precise predictions for particular cases. In        similarity relation, and this will differ from context to
this paper we briefly review two of these models and                  context,” gives an informal ranked list of general “weights
demonstrate using evidence from two psychological                     or priorities” in determining similarity: first, to avoid big,
experiments that these models do not capture the full                 widespread, diverse violations of law; second, to maximize
spectrum of human counterfactual reasoning. Specifically,             the spatio-temporal region of perfect match of particular
we illustrate how causal distance and causal strength affect          fact; third, to avoid small, localized violations of law;
the interpretation of counterfactual statements. In                   fourth, to secure approximate similarity of particular facts.
conclusion, we argue that utilizing the psychological                    Despite the informality of these guidelines, one can
findings on fact mutability and similarity are crucial to             discern a priority of laws over particular fact, and of “big”
building cognitively plausible computational models of                discrepancies over “small” ones. Much of the subsequent
counterfactual reasoning.                                             work on modeling counterfactual reasoning is based on
   First, we briefly review the Stalnaker/Lewis theory of             similar intuitions and can be viewed as attempts to make the
counterfactuals. Next, we discuss Causal Bayesian                     notion of similarity more precise. However, in view of
Networks (Spirtes, Glymour, and Scheines, 1993; Pearl,
                                                                  941

Lewis’s emphasis on the inherent vagueness and context-                                       W
dependence of the notion, it is not surprising that there is
considerable variation in detail.
                                                                                        X=x           Y
Ginsberg’s Computational Implementation
Ginsberg (1986) models the interpretation of counterfactuals                   Figure 1: do(X=x), an external action
relative to an imaginary “large database describing the state                  making X independent of its parent W
of the world at some point.” This is in line with AI
conventions on the one hand, and the logical school of            Pearl claims that the do operator “is a crucial step in the
Premise Semantics (Veltman, 1978; Kratzer, 1981), on the          semantics of counterfactuals” (Pearl, 2000): A
other. In this framework, the move from the world of              counterfactual with antecedent ‘If it were that X=x’ is
evaluation to antecedent-worlds corresponds to a revision of      interpreted in a causal network by first applying do(X=x),
the database, and the problem of determining similarity is        then evaluating the consequent in the resulting modified
mirrored by the question of which facts to keep and which         network. This leads to the strong prediction that unless the
ones to give up in order to keep this revision minimal. Again     consequent is not a (direct or indirect) effect of X, it should
following AI conventions, Ginsberg extends the term               be unaffected by the intervention and retain its prior
“possible world” to partial descriptions, which would             probability.
correspond to sets of (total) possible worlds in the                 In a series of six psychological experiments, Sloman and
Stalnaker/Lewis framework.                                        Lagnado (2005) investigate whether human subjects’
   Overall, Ginsberg’s theory is set up to minimize               responses to counterfactual statements can be explained
differences in facts and localize violations of rules. In         using the method of determining the truth of counterfactuals
particular, his second postulate ensures that violations are      in Causal Bayesian networks and the do(x) operator.
treated as exceptions to existing rules, rather than the          Overall, they conclude that responses of the subjects were
workings of different ones. In this, the theory reflects          more or less compatible with the effect of the do(x)
Lewis’s emphasis on minimizing violations of law while            operator. But they argue that “representing intervention is
maximizing correspondence in particular fact.                     not always as easy as forcing a variable to some value and
                                                                  cutting the variable off from its causes. Indeed, most of the
Counterfactuals in Causal Bayesian Networks                       data reported here show some variability in people's
Causal Bayesian Networks have recently gained                     responses. People are not generally satisfied to simply
considerable currency as a formal tool for representing           implement a ‘do’ operation. People often want to know
domain knowledge and modeling causal and counterfactual           precisely how an intervention is taking place.” (Sloman and
reasoning (Pearl, 1998, 2000; Spirtes et al., 1993). A            Lagnado, 2005).
Bayesian Network is a directed acyclic graph whose vertices
represent variables and whose topology encodes                    Hiddleston’s Theory of Counterfactuals
independencies between those variables in the form of the         Hiddleston (2005) is a recent attempt to synthesize the
Markov Assumption: The probability of a variable X is fully       insights of different strands of research into a theory which
determined by the values of its immediate parents pa(X) in        accounts for a number of problematic examples that were
the graph. A Bayesian Network is causal if all arrows are         discussed in the philosophical literature. He adopts the basic
assumed to lead from causes to effects. Pearl (2000)              idea of representing causal relations as directed acyclic
assumes that causation is deterministic; uncertainty is           graphs from Spirtes et al. (1993) and Pearl (2000), but his
modeled as a probability distribution over a distinct set of      interpretation of these graphs dispenses with some of the
“exogenous” variables. Under this assumption, the values of       assumptions about causality made by the latter. Unlike
pa(X) jointly determine the value of X.                           Pearl, he allows for non-deterministic causal laws, and he
   The causal interpretation makes a special update               weakens the Markov Assumption to allow for cases in
operation available, formally represented using the “do           which a variable’s taking on a different value is impossible
operator”: The result of applying the operation do(X=x) to a      given the actual values of its parents and the causal laws.
network with a vertex X results in a new network in which X          Hiddleston evaluates counterfactuals relative to models
has value x and all arrows leading into X are removed. In         consisting of a causal graph and an assignment of values to
this network, the variables in pa(X) are independent of X,        all variables. One may think of such models as “possible
hence unaffected by standard algorithms of belief                 worlds” and call the values that variables are assigned in
propagation. The intention is that do(X=x) represents an          them their “actual” values. Relative to such a model M, he
external intervention upon X which disrupts the causal            introduces a notion of positive parent of a variable X
process that normally determines the value of X, so the fact      (written ppa(X)), a subset of pa(X), defined as those parents
that X=x does not warrant any inferences about its normal         Y of X such that the conditional probability of X’s taking on
causes. Thus, do(X=x) represents a local update whose             its actual value, given that all of X’s parents (including Y)
effects are limited to the descendants of X in the graph.         have their actual values, is strictly higher than the
                                                                  corresponding conditional probability in the event that Y
                                                              942

alone among X’s parents takes on a different value. Thus the         important psychological factor which should play a role in
set of positive parents of X relative to the same causal             theories of counterfactual reasoning.
structure may differ between alternative value assignments.             Two context free conditions which we believe affect fact
   Instead of modeling the interpretation of a counterfactual        mutability are causal distance and causal strength. Causal
A  C whose antecedent is the assertion that some variable           distance is the relative closeness of the antecedent of the
X has value x by “cutting the links” from pa(X) to X, his rule       counterfactual from its consequent in the causal graph. We
involves a comparison between alternative “A-models” with            predict that the closer the antecedent is to its consequent, the
the same causal structure as the original model M and in             more mutable the antecedent is and therefore the easier it is
which X=x. Among those, a model is “A-minimal” if (i) the            to mentally undo it. The second condition is the strength of
set of non-descendants Z of X such that both Z and Z’s               the causal connection between the antecedent and the
positive parents have the same values as in M is maximal;            consequent. Psychological evidence suggests that people not
and (ii) the set of “causal breaks” - variables Z which take         only use causal structures but also utilize beliefs about
on a different value while the values of Z’s positive parents        causal strengths (e.g. Kushnir and Gopnik, 2005; Waldmann
are the same as in M - is minimal. The counterfactual                & Hagmayer, 2001). ∆P (Jenkins and Ward, 1965) and
A  C is true in M if and only if C is true in all of those A-       power PC (Cheng, 1997) both utilize conditional
minimal models. These conditions, as Hiddleston puts it,             probabilities to compute causal strength. In Bayesian
“force any causal break to be as minor and late as is                Networks, these parameters can be calculated from the
lawfully possible.”                                                  conditional probabilities. However, none of the models
   Hiddleston leaves room for the incorporation of context           discussed above utilizes causal strength when evaluating
dependence by allowing that depending on the situation,              counterfactuals. We predict that if an effect has multiple
only a subset of all “causal breaks” may be relevant. The            causes, the ones which have a stronger causal connection to
role of the context is not formalized in his models, however.        it are more easily undone than the ones which have a weaker
                                                                     connection. This is consistent with our prediction about
                       Norm Theory                                   causal distance; the connection with direct causes is stronger
One important perspective in research on counterfactual              than that with distant causes.
reasoning in psychology is Kahneman and Miller’s Norm                   There are also context dependent factor which affect the
Theory (1986). According to this theory, the outcome of a            mutability of facts. For example, actions are more mutable
situation is compared to a norm, which is constructed online         than failures to act (Kahneman & Miller, 1986). We
based on past experiences and expectations, as well as on            investigate the affect of these context dependent factors on
the particular outcome. Outcomes that are similar to the             the evaluation of counterfactuals in a separate paper (in
norm are considered normal, while outcomes that are                  preparation).
significantly different are considered abnormal. Abnormal
outcomes activate their normal counterparts, thus they are                                   Experiments
an invitation for counterfactual thinking. Kahneman and              In the following experiments we present scenarios
Miller (1986) argue that when constructing the norm, there           containing facts with different mutability rates and
are certain facts that are easier to mentally undo, or               investigate how these different rates affect subjects’
“mutate” from the actual world than others. People are more          responses to counterfactual questions. We then compare
or less able to predict the availability of counterfactual           these responses to the predictions of the normative models
alternatives to a given situation, “Some aspects of reality are      discussed in the previous section focusing on the predictions
more mutable than others, in the sense that alternatives to          of Causal Bayesian Networks.
them come more readily to mind” (Kahneman, 1995).
Hence, when thinking about causal situations, there are              Experiment 1
certain causes that tend to be easier to modify or mutate.           In this experiment we investigated how the distance of the
                                                                     antecedent from its consequent in the causal graph can
Fact Mutability and Intervention                                     change the mutability of facts when analyzing a backward
According to the Norm Theory, when faced with multiple               counterfactual statement, where the effect is the antecedent
causes with different mutability rates, alternatives to causes       of the counterfactual and the cause is the consequent.
which have higher mutability rates come more readily to              Sloman and Lagnado (2005) suggest that people are more
mind and therefore these causes tend to be easier to                 likely to keep the state of the consequent intact when the
mentally undo and give up their values. In other words, the          effect is part of the antecedent of the counterfactual
higher the mutability rate of a fact, the less likely it is that     statement. Therefore, if the effect has been intervened on,
its value will stay the same under an intervention.                  the status of the cause(s) should not change and hence the
   Although deciding the mutability of facts is similar to the       distance of the cause from the effect should not play a role
problem of determining similarity between possible worlds,           when evaluating counterfactuals. We predict immediate
fact mutability has not been taken into account in the               causes to be more mutable than distant causes. Therefore, it
philosophical and AI literature. We believe that this is an          should be easier for people to undo immediate causes than
                                                                     distant causes.
                                                                 943

   In the following three scenarios we asked questions about            Question 1: If Tom had not had extra work for the weekend,
different variables A, B and C. In each scenario, A causes B            would he have been on time on Wednesday morning?
and B causes C, representing the chain network topology in              (C  B)
Figure 2. We then asked the following counterfactual                    Question 2: If Tom had not had extra work for the weekend,
questions:                                                              would his alarm have rung on Wednesday morning?
                                                                        (C  A)
(1) If C had not happened, would B have happened?                       Question 3: If Tom had not been late on Wednesday
(2) If C had not happened, would A have happened?                       morning, would he have extra work for the weekend?
(3) If B had not happened, would C have happened?                       (B  C)
(4) If B had not happened, would A have happened?                       Question 4: If Tom had not been late on Wednesday
                                                                        morning, would his alarm have rung on time? (B  A)
                  A                  B            C                     Scenario 3
                                                                        A lifeboat is overloaded with people saved from a sinking
                                                                        ship. The captain is aware that even a few additional pounds
                       Figure 2: Chain topology                         could sink the boat. However, he decides to search for the
                                                                        last person: a missing child. Soon, they find the 5-year-old
According to Pearl’s (2000) model, given the above network              girl, but when she gets onboard, the boat sinks
 P( A | do(C)) = P( A | do(B)) = P( A) and P( B | do(C )) = P( B) ,
therefore the truth-value of the cause should not change                Question 1: If the boat had not sunk, would they have found
given any intervention on its effect.                                   the child? (C  B)
                                                                        Question 2: If the boat had not sunk, would the captain have
Method                                                                  decided to search for the child? (C  A)
36 Northwestern undergraduate students were presented
with a series of scenarios, and after each scenario they were           Results
asked to evaluate the likelihood of a number of                         The results are summarized in Table 1. The Moving Balls
counterfactual statements. The questions were presented on              scenario replicated one of Sloman and Lagnado's (2005)
a computer screen, and subjects were asked to rate the                  findings: forward counterfactuals are treated differently
likelihood of each question from 0 to 10, 0 being “definitely           from backwards counterfactuals. The responses to the
no” and 10 being “definitely yes.”                                      forward counterfactual question “If B had not happened
   Three different scenarios were designed to follow the                would C have happened?” (B  C) were lower than those
same causal structure where A causes B, B causes C and                  to any of the backward counterfactuals (mean=2.8, SD = .5,
both A and C definitely happened. Logical abbreviations in              F(1,35) = 9.53, p<.05), suggesting that the hypothetical
the parenthesis are added here for the reader’s convenience;            absence of the cause has a stronger influence on the state of
they were not shown to the subjects.                                    the effect than vice versa.
                                                                           A repeated measure ANOVA was conducted comparing
Scenario 1                                                              the mean of the answers to the three backward
Ball A causes Ball B to move.                                           counterfactuals, revealing significant: A post hoc test
Ball B causes Ball C to move.                                           revealed that B  A was significantly lower than both
Balls A, B and C definitely moved.                                      C  A and C  B (F(1,35) = 7.89, p<.05) However, there
                                                                        was no reliable difference between the estimated
Question 1: If Ball C had not moved, would ball B still have            probabilities of C  A and C  B.
moved? (C  B)                                                             The same pattern was observed in the Alarm Clock
Question 2: If Ball C had not moved, would ball A still have            scenario: there was a significant difference between
moved? (C  A)
Question 3: If Ball B had not moved, would ball C still have
moved? (B  C)                                                             Scenario/Questions    CB      CA       BA      BC
Question 4: If Ball B had not moved, would ball A still have               Moving Balls          5.9      5.6       4*       2*
moved? (B  A)
                                                                           Alarm Clock           5.6      5.3       7.9*     2.9*
Scenario 2
Tom's alarm clock did not ring on Wednesday morning,                       Lifeboat              4.5*     6.2       N/A      N/A
resulting in Tom being late for work. Because Tom was late
that morning, Tom's boss gave him extra work for the
weekend.                                                                        Table 1: Subjects’ mean response to backward
                                                                                           counterfactual questions
                                                                    944

backward and forward counterfactuals (F(1,35)=21.23,                  with two causes with a common effect, people more easily
p<0.05). No significant difference was detected between               undo the cause which has the connection to the effect.
C  A and C  B, but the estimated B  A was much                       The topology of the network in the following scenario is a
higher than any of the other two (F(1,35)=9.92, p<.05).               collider (Figure 3): There are two causes which affect the
   In the third scenario we asked only two questions, C  A           same effect. We hypothesize that a difference between A
and C  B, which came out to be the significantly different           and B in the strength of their respective causal connection
(F(1,35)=12.10, p<.05).                                               with C will affect which of the two is given up in
                                                                      counterfactual reasoning about C, contrary to the
Discussion                                                            assumption in the Causal Networks literature that both
Causal Bayesian networks predict that an intervention on              should be equally unaffected.
the effect should not affect the value of its cause(s).
Therefore, answers to backward counterfactual questions in                                     B             A
the first and third scenario should all be Yes (10) and in the
second scenario should all be No (0). Hiddleston’s and
Ginsberg’s models predict the answers to all the questions                                            C
in the three scenarios to be No (0).
   Subjects’ answers to B  A were consistently different
from answers to C  A. We believe that this difference                                  Figure 3: Collider Topology
may be due to the distance between the cause and the effect
nodes. That is, the closer the antecedent is to its consequent,       Method
the easier it is to undo its value. Therefore, it is easier to        The same participants were presented with another scenario
undo the value of A in B  A than in C  A. Following                 which was very similar to the Lifeboat scenario, with the
this hypothesis, in the first scenario where A is true (10) in        only difference that this time there were two persons in the
the consequent of counterfactuals, it seems that subjects             water.
more often undid the value of A in B  A and altered it to            Scenario 1
false (0) than in C  A. In the second scenario the same              A lifeboat is overloaded with people saved from a sinking
trend was observed: A is false in the consequent of                   ship. The captain is aware that even a few additional pounds
counterfactuals, and subjects more often undid its value to           could sink the boat. However, he decides to search for the
true in B  A than in C  A.                                          last two people: a missing child and a missing cook. Soon,
   Also, in the last scenario significant difference was              they find both people, but when they get onboard, the boat
observed between answers to C  B and C  A which                     sinks.
again agrees with the above hypothesis and is due to the fact
that B is closer to C than A. Therefore, it is easier to undo, or     Questions:
give up, its value.                                                   (1) If the boat had not sunk, would they have found the
   All of the observed differences were consistent with our           child? (C  B)
prediction. However, no difference was detected between               (2) If the boat had not sunk, would they have found the
C  B and C  A in the first two scenarios. We believe                cook? (C  A)
this might be due to the differences of the context in which
the conditionals were being evaluated, as B in the third              Results
scenario seems to be a more salient cause that in the other           The mean for C  A was 6.5 while the mean for C  B
two scenarios. How different context affects the evaluation           was 7.0. The difference between the two questions was
of counterfactuals is part of our ongoing research.                   significant (F(1,35) = 7.19 p<.05).
   In conclusion, the experiments show that the degree to
which people are willing to mutate the antecedent of the              Discussion
counterfactual varies with the location of the antecedent and         Causal Bayesian networks predict that the answers to both
the context of the scenario. This conclusion contradicts the          of the questions should be Yes (10), and Hiddleston’s and
predictions of the three models discussed in this paper.              Ginsberg’s models predicts that the answers should be No
   In the next part we describe another experiment which              (0).
questions the applicability of the do(x) operator, and the              It was explicitly mentioned in the scenario that a few
logical operations of the two other models.                           additional pounds would be enough to sink the lifeboat,
                                                                      therefore both the cook and the child were potential causes
Experiment 2                                                          for the sinking of the boat. However, the results show that it
In addition to causal distance, another factor which we               was easier for the subjects to undo A (cook was found).
believe may influence counterfactual reasoning is the causal          This result suggests that the subjects were less likely to cut
strength between the antecedent and the conclusion of                 the link between the weaker cause and the effect compared
counterfactual statements. We predict that the stronger the           to the link between to the stronger cause and the same
causal effect is, the easier it is to undo it. Hence, when faced      effect. Thus causes with stronger effects are more mutable
                                                                      and more likely to be intervened on than weak causes.
                                                                  945

                         Conclusion                                Ginsberg, M. L. (1986). Counterfactuals. Artificial
                                                                     Intelligence 30:35-79.
Although the models discussed are able to correctly predict
                                                                   Goodman, N. (1983). Fact, Fiction, and Forecast.
people’s judgments about many counterfactual questions,
                                                                     Cambridge, Mass.: Harvard University Press.
they fail to capture certain aspects of human counterfactual
                                                                   Griffiths, T. L. & Tenenbaum, J. B. (2005). Structure and
reasoning. We argue that causal strength and causal distance
                                                                     Strength in Causal Induction. Cognitive Psychology
influence the interpretation of counterfactual conditionals.
                                                                     51(4):334-384.
None of the models reviewed in this paper utilize these two
                                                                   Hiddleston, Eric (2005). A Causal Theory of
factors.
                                                                     Counterfactuals. Noûs, 39(4):632-657.
  While intervention may not necessarily remove the causal
                                                                   Hume, D. (1748). An Enquiry concerning Human
dependencies between the antecedent of the counterfactual
                                                                     Understanding.
and its immediate causes, how people choose the location of
                                                                   Jenkins, H. M., & Ward, W. C. (1965). Judgment of
intervention is related to psychological factors including the
                                                                     contingency between responses and outcomes.
mutability of facts involved in the case.
                                                                     Psychological Monographs, 79.
  In a series of new experiments we aimed at a direct
                                                                   Kahneman, D., & Miller, D. T. (1986). Norm theory:
comparison between the context sensitivity of Norm Theory
                                                                     Comparing reality to its alternatives. Psychological
and the context neutrality of the Bayesian Networks
                                                                     Review 93:136-153.
approach in analyzing counterfactuals conditionals (in
                                                                   Kahneman, D. (1995). Varieties of Counterfactual Thinking.
preparation). Among the important predictions that the
                                                                     In N. J. Roese. & J. M. Olson J. M. What Might Have
Norm Theory makes is that when people analyze
                                                                     Been: The Social Psychology of Counterfactual
counterfactuals, they are more likely to undo actions that
                                                                     Thinking.(pp. 375-396). Mahwah, NJ: Lawrence Erlbaum.
lead to some type of consequence rather than inactions that
                                                                   Kratzer, A. (1981). Partition and revision: The semantics of
lead to the same consequence. In other words, actions are
                                                                     counterfactuals. Journal of Philosophical Logic 10:201-
more mutable compared to inactions. We have found
                                                                     216.
evidence for this effect in a set of experiments which follow
                                                                   Kushnir, A. & Gopnik, A. (2005). Young Children Infer
the same causal network but set up a different context.
                                                                     Causal Strength from Probabilities and Interventions.
Generally, if the causal network is a collider, people tend to
                                                                     Psychological Science 16 (9):678-683
undo the value of the node which represents an action. This
                                                                   Leibniz, G.E. (1686). Discourse on Metaphysics and Other
result follows the main claims of this paper that not only the
                                                                     Essays.
causal structure of the graph is important, but the content of
                                                                   Lewis, D. (1973). Counterfactuals. Oxford: Blackwell
each node and the context in which the conditional is being
                                                                   Lewis, D. (1979). Counterfactual Dependence and Time's
evaluated affect speakers’ evaluation of counterfactual
                                                                     Arrow, Noûs 13:455-76.
conditionals.
                                                                   Pearl, J. (1988). Probabilistic Reasoning in Intelligent
  Determining the mutability of facts and performing
                                                                     Systems, Morgan Kaufmann, San Francisco.
similarity analyses between potential worlds are two
                                                                   Pearl, J. (2000). Causality: Models, Reasoning, and
important steps in evaluating the truth of counterfactual
                                                                     Inference. London: Cambridge University Press.
conditionals. These two context dependent factors are
                                                                   Rescher, N. (1964). Hypothetical reasoning. Amsterdam:
influenced by a variety of psychological factors and are not
fully captured by the popular models of counterfactual               North-Holland.
reasoning in AI. In future work, we plan to continue our           Sloman, S.A., & Lagnado, D. (2005). Do we
experimental studies on how psychological findings on                “do”? Cognitive Science 29:5-39
                                                                   Spirtes, P., Glymour, C., and Scheines, R. (1993).
similarity can be related to fact mutability and in general to
                                                                     Causation, Prediction, and Search, Springer-Verlag, New
Stalnaker and Lewis’ notion of comparative similarity, and
                                                                     York.
work towards a formal theory in which the role of these
                                                                   Stalnaker, R. (1968). A theory of conditionals. In N.
factors can be implemented.
                                                                     Rescher (ed.), Studies in Logical Theory (pp. 98-112).
                                                                     Oxford: Balckwell.
                    Acknowledgments                                Sternberg, R. J., & Gastel, J. (1989b). If dancers ate their
This research was supported in part by a grant from an               shoes: Inductive reasoning with factual and counterfactual
AFSOR MURI. The authors would like to thank Ken Forbus               premises. Memory and Cognition 17:1-10.
and Lance Rips for their insights throughout this work.            Veltman, F. (1976). Prejudices, presuppositions and the
                                                                     theory of counterfactuals. In Groenendijk, J. and M.
                         References                                  Stokhof (eds.) Amsterdam Papers in Formal Grammar,
Cheng, P. (1997). From covariation to causation: A causal            Vol. 1 (pp. 248-281). University of Amsterdam.
  power theory. Psychological Review, 104, 367–405.                Waldmann, M. R. & Hagmayer Y. (2001). Estimating
Costello, T. & McCarthy, J. (1999). Useful Counterfactuals.          Causal Strength: The Role of Structural Knowledge and
  Electronic Transactions on Artificial Intelligence.                Processing. Cognition 82(1):27-58.
                                                               946

