UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual Statistical Learning: Getting Some Help from the Auditory Modality
Permalink
https://escholarship.org/uc/item/3kv721tn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Robinson, Christopher W.
Sloutsky, Vladimir M.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                                                Visual Statistical Learning:
                               Getting Some Help from the Auditory Modality
                                     Christopher W. Robinson (robinson.777@osu.edu)
                                                      Center for Cognitive Science
                                                        The Ohio State University
                                            208F Ohio Stadium East, 1961 Tuttle Park Place
                                                       Columbus, OH 43210, USA
                                          Vladimir M. Sloutsky (sloutsky.1@osu.edu)
                                                      Center for Cognitive Science
                                                        The Ohio State University
                                            208C Ohio Stadium East, 1961 Tuttle Park Place
                                                       Columbus, OH 43210, USA
                              Abstract                                     understanding the early interactions between the
                                                                           auditory and visual systems, Sloutsky and Robinson
   Presenting information to multiple sensory systems can                  only examined the processing of a single visual
   (depending on conditions) either facilitate or hinder                   stimulus. Thus, it is uncertain whether these effects
   processing. The current study examined the effects of cross-
                                                                           can be generalized to the learning of other types of
   modal presentation on statistical learning. The first
   experiment examined statistical learning within auditory and            information.
   visual modalities, while using comparable experimental                     Learning a new domain not only entails encoding
   conditions across the two modalities. The findings suggest              and storing representations of single images and
   that the auditory modality was better suited for learning the           sounds, but it also involves detecting the statistical
   temporal structure in the input. Experiments 2 and 3 examined           regularities between the elements within that domain.
   whether the presence of auditory stimuli would facilitate or            This ability appears to be in place very early in
   hinder visual statistical learning. The results suggest that            development. For example, to determine if infants
   auditory stimuli that share the same statistics as visual stimuli       could use the statistical information to segment words
   can facilitate the acquisition of visual sequences.
                                                                           in a speech stream, Saffran, Aslin, and Newport
   Keywords: Cognitive Development, Attention, Language                    (1996) presented infants with a continuous stream of
   Acquisition, Psychology, Human Experimentation.                         syllables (e.g,. pa-bi-ku-ti-bu-do-go-la-tu). Although
                                                                           there were no acoustic or prosodic cues provided to
                         Introduction                                      infants, they were able to segment the stream into
                                                                           word-like units by using the statistical regularities
   There are many occasions where information is                           from the input.
presented to multiple sensory modalities. Under some                          Statistical learning does not appear to be specific to
conditions (e.g., when auditory-visual stimuli share the                   linguistic stimuli, but rather it seems to be governed
same amodal relation such as rhythm or rate), cross modal                  by a domain-general learning mechanism capable of
presentation is likely to facilitate processing of the amodal              operating on a variety of stimuli such as musical
relation (Bahrick & Lickliter, 2000 see Lewkowicz, 2000;                   notes and geometric shapes (Fiser & Aslin, 2002a;
Lickliter & Bahrick, 2000, for reviews). At the same                       2002b; Kirkham, Slemmer, & Johnson, 2002;
time, under other conditions (e.g., when auditory-visual                   Saffran, Johnson, Aslin, & Newport, 1999; Turke-
pairings are arbitrary), cross-modal presentation is likely                Browne, Junge, & Scholl, 2005).
to hinder processing of arbitrary auditory-visual stimuli                     More recently, however, there have been several
(e.g., Napolitano & Sloutsky, 2004; Robinson & Sloutsky,                   studies examining how these processes interact with
2004; in press-a; in press-b; Sloutsky & Napolitano,                       the modality of input. While it is often believed that
2003).                                                                     the mechanism underlying statistical learning is
   Research examining the processing of arbitrary,                         domain-general and not intimately tied to a specific
auditory-visual pairings has demonstrated several                          modality, there are reasons to suggest that statistical
interesting phenomena. Of particular interest to this study                learning may be driven by several different sensory
is the finding that auditory input often affects visual                    subsystems (Conway & Christiansen, 2005; 2006).
processing, whereas, visual input is less likely to affect                 These findings raise many interesting questions. For
the processing of auditory stimuli (Sloutsky & Robinson,                   example if statistical learning of visual and auditory
in press). While this finding may be fundamental for                       stimuli are guided by different subsystems, how do
                                                                     611

these systems interact with one another? Does auditory          The visual stimuli consisted of 12 different shapes
input hinder visual statistical learning, as is found with      varying in color. Individual shapes were
studies examining the processing of arbitrary, auditory-        approximately 8 cm by 8 cm and were presented
visual pairings (e.g., Sloutsky & Napolitano, 2003)? Or         centrally on a computer screen. The auditory and
does activation of multiple subsystems facilitate visual        visual stimuli were presented for 700 ms with a 200
statistical learning as is typical found with processing of     ms inter-stimulus interval (see Figure 1 for overview
amodal relations (Bahrick & Lickliter, 2000)?                   of training). Although the stream of elements
Alternatively, these effects may be specific to the nature      appeared to be random, they actually consisted of
of the input. The primary goal of the current study is to       four sets of triplets (see Figure 2 for auditory and
begin answering some of these questions.                        visual triplets).
   The current study consists of three experiments. Using
comparable experimental conditions, Experiment 1                                            Familiarization Stimuli
examined statistical learning within the auditory and
visual modalities. Based on the recent findings of Conway                    Auditory Stimuli                Visual Stimuli
and Christiansen (2005), it was hypothesized that the            Triplet  Corpus 1      Corpus 2       Corpus 1         Corpus 2
auditory modality would be more likely than the visual
modality to abstract the temporal structure in the input.           1      pabiku         dapati
Experiments 2 and 3 examined how these processes
interact with one another: Does auditory input have any             2       tibudo        labibu
effect on visual statistical learning?                              3       daropi        tupido
                      Experiment 1                                  4       golatu       goroku
Method
Participants Thirty adults (9 women and 21 men, M =                                             Testing Stimuli
20.3 years, SD = 2.4 years) participated in this                 Triplet      Auditory Stimuli               Visual Stimuli
experiment. Adults consisted of undergraduate students
from The Ohio State University participating for course             1             pabiku
credit. The majority of adults were Caucasian. Fourteen
                                                                    2              tibudo
adults were familiarized and tested on speech sounds and
16 adults were familiarized and tested on geometric                 3              daropi
shapes.
                                                                    4              golatu
Stimuli The auditory and visual stimuli were modeled
after previous research examining statistical learning of           5              dapati
speech sounds and geometric shapes in young infants
(Fiser & Aslin, 2002b; Saffran, Aslin, & Newport, 1996).            6              labibu
The auditory stimuli consisted of 12 different syllables
(see Figure 1 for examples). Each syllable was produced             7              tupido
in isolation by a female experimenter and presented from
a Dell Dimension 8200 computer with Presentation                    8             goroku
software at 65 – 70 dB.
                                                                Figure 2: Auditory and visual stimuli presented
    pa        bi       ku         ti     bu      do
                                                                during the familiarization and testing phase. Corpus 1
   700        700      700       700     700     700
         200      200       200      200     200
                                                                and Corpus 2 varied between subjects.
                    Auditory (unimodal)                             Each Triplet was presented 16 times throughout
                                                                familiarization, and the familiarization triplets were
   700        700      700       700     700     700
                                                                counter-balanced across subjects. In corpus 1,
         200      200       200      200     200                participants were familiarized to triplets ABC, DEF,
                                                                GHI, and JKL. In corpus 2, participants were
                      Visual (unimodal)                         familiarized to triplets AEI, DGJ, BHK, and CFL.
                                                                During the test phase, each participant was presented
Figure 1: Overview of training phases in Experiment 1.          with all eight triplets (i.e., four triplets from corpus 1
Values denote time in milliseconds.                             and four triplets from corpus 2). Thus, the four
                                                                familiar triplets for participants in corpus 1 (ABC,
                                                            612

DEF, GHI, and JKL) were completely novel foils for                shapes or three sounds was made by an Arbo (similar
adults familiarized to corpus 2 and the familiar triplets for     to familiarization sequence) or made by a Luthop
participants in corpus 2 (AEI, DGJ, BHK, and CFL) were            (different from familiarization sequence). No
completely novel foils for participants familiarized to           feedback was provided.
corpus 1. The triplets were presented in a predetermined
order, which was restricted by two criteria. First, triplets      Results and Discussion
could not occur twice in succession (e.g., T1, T1…).
Second, alternating triplets was not allowed (e.g., T1, T2,       During familiarization, participants noticed 86% of
T1, T2 …). The same predetermined order was used for the          the repeating elements, and no difference was found
auditory and visual modalities, and the overall duration of       between the auditory and visual conditions, t (28) =
familiarization was approximately 3 minutes in duration.          1.31, p = 20.
                                                                     The primary analyses focused on discrimination of
Procedure The entire experiment consisted of two                  the familiar triplets from the novel foils.
phases: Familiarization phase and testing phase. During           Discrimination was assessed as a difference between
the familiarization phase, participants were presented with       hits (i.e., correct acceptance of familiar triplets) and
learning sequences. They were also given a distracter             false alarms (i.e., erroneous acceptance of foils).
tasks, which was similar to the one used by Turke-                Discrimination greater than zero reflects above-
Browne, Junge, and Scholl (2005). In the visual condition,        chance discrimination, whereas, discrimination equal
the distracter task was to press the spacebar every time          to zero reflects at-chance discrimination. While
they saw two shapes in a row that were the same. In the           participants discriminated the triplets from the foils in
auditory condition, the distracter task was to press the          the auditory condition, (M = .20, SE = .07), one-
spacebar every time they heard two sounds in a row that           sample t compared to zero, t (13) = 2.90, p = .012,
were the same. Eight times throughout familiarization,            discrimination of the visual stimuli did not exceed
participants were presented with a repeated element (e.g.,        chance (M = .07, SE = .09), one-sample t compared
ABCCDEF). The repeated elements were always the third             to zero, t (15) = 0.77, p = .45.
element in a Triplet, and the repeated element always                While it is possible that participants simply needed
occurred between two triplets, as opposed to being                more exposure to the visual sequence to successfully
embedded within a Triplet.                                        discriminate the familiar triplets from the foils, these
   After the familiarization phase, participants were             findings are consistent with previous research
presented with the testing phase. The testing phase               examining statistical learning in different modalities
started with a cover story, which was created for young           (Conway & Christiansen, 2005).
children. Below is the cover story for the visual condition:
The pictures that you just saw were words made by an                                  Experiment 2
Arbo. Arbos live on a planet called Yodo, and they use
shapes to talk to each other. Arbo’s words are made up of         The primary goal of Experiment 2 is to examine the
3 shapes, and different words can be made by changing             effect of auditory input on visual statistical learning,
the order of the shapes. In the next part you will be             and the effect of visual input on auditory statistical
presented with words. Some of the words will be made by           learning. More specifically, the current study was
an Arbo and some will be made by a Luthop. Although               designed to examine whether correlated auditory cues
Luthops use the same shapes to make their words, they             (i.e., where the same statistics are found in both the
make very different words. You have not seen words made           auditory and visual modalities) would affect visual
by a Luthop. Your task is to determine if the words were          statistical learning.
made by an Arbo or by a Luthop. Arbo’s and Luthop’s
languages are very similar to each other. The only way            Method
you can tell the difference between the two languages is          Participants Thirty adults (11 women and 19 men,
by the order of the shapes, so you will need to pay close         M = 19.2 years, SD = 0.7 years) participated in this
attention to the order of shapes.                                 experiment. Demographics and subject recruitment
   The cover story for the auditory condition was                 were identical to Experiment 1. Fourteen participants
identical, except that all references to shapes were              were familiarized to a correlated AV sequence and
replaced with sounds.                                             tested on auditory sequences (presented unimodally).
   At this point, participants moved to the testing phase         Sixteen participants were familiarized to the same
where they were tested on the four triplets from corpus 1         correlated AV sequence and tested on the visual
and on the four triplets from corpus 2. The order of the          sequences (presented unimodally).
testing trials was randomized for each subject, and each
Triplet was presented twice, resulting in 16 test trials.         Stimuli and procedure The auditory and visual
Participants had to determine if a given sequence of three        stimuli were identical to Experiment 1 (see Figure 2).
                                                              613

In contrast to Experiment 1, the auditory and visual             sequences (M = .23, SE = .08), t (15) = 3.15, p =
stimuli were correlated during the familiarization phase.        .007, and the auditory sequences (M = .20, SE = .06),
For example, every time participants were presented with         t (13) = 2.77, p = .016, both exceeded chance. While
ABC in the visual modality, they also heard ABC in the           these effects were small, the finding is remarkable
auditory modality (see Figure 3 for overview of training).       given that Experiment 2 increased the amount of
                                                                 information that adults had to learn. This suggests
    pa        bi       ku        ti      bu       do
                                                                 that the presence of the auditory stimuli during
    700      700      700       700      700      700
                                                                 familiarization facilitated processing of the visual
        200       200      200      200      200                 sequences and this had lasting effects on the way the
                                                                 visual sequences were perceived.
                     Correlated (bimodal)
                                                                                     Experiment 3
Figure 3. Overview of training phase in Experiment 2.
Values denote time in milliseconds.                              Why did the auditory input facilitate visual statistical
                                                                 learning? One possible explanation is that the
   The familiarization sequence lasted approximately 3           auditory stimuli were simply more engaging and
minutes, and each triplet was presented 16 times. As in          pairing the auditory stimuli with the pictures in
Experiment 1, participants were presented with a                 Experiment 2 simply made the task more interesting
distracter task. In this task, they were directed to both        and       subsequently      increased      performance.
modalities: They were told to press the spacebar when            Alternatively, it is possible that this effect stemmed
they saw the same two shapes in a row or when they               from the correlated auditory cues helping participants
heard the same sound twice in a row. Given that the              detect the statistics in the visual modality.
auditory and visual stimuli were correlated in the current       Experiment 3 distinguished between these accounts
experiment, participants could perform quite well on the         by randomizing the auditory sequence. According to
distracter task: Focusing on the sounds, on the shapes, or       the latter account, breaking the correlation between
on both modalities could lead to accurate performance in         the auditory and visual stimuli should attenuate the
the distracter task.                                             facilitation effect. According to the former account,
   After familiarization, participants were presented with a     performance in the current experiment should be
cover story. With the following exception, the cover story       comparable to Experiment 2 because auditory input
was identical to Experiment 1: The shapes and sounds             was paired with visual input in both experiments.
that you just saw and heard were words made by an Arbo.
Arbos live on a planet called Yodo, and they use shapes          Method
and sounds to talk to each other. Arbo’s words are made
                                                                 Participants Ten adults (2 women and 8 men, M =
up of 3 shapes and 3 sounds, and different words can be
                                                                 19.9 years, SD = 0.9 years) participated in this
made by changing the order of the shapes and sounds.
                                                                 experiment. Demographics and subject recruitment
However, Arbos do not need to pair the shapes and
                                                                 were identical to previous experiments.
sounds together to talk. They can also talk to each other
by simply using shapes or sounds.                                Stimuli and procedure The auditory and visual
   At this point participants moved to the testing phase,        stimuli were identical to previous experiments (see
which was identical to Experiment 1. More specifically,          Figure 2). Stimuli during the familiarization phase
even though they were trained on a correlated AV                 were presented cross-modally, whereas, visual
sequence, participants were only tested on the sounds or         sequences were presented in isolation at test (same as
on the shapes, as was the case in Experiment 1.                  in the visual condition of Experiment 2). In contrast
                                                                 to Experiment 2, the auditory sequence was
Results and Discussion                                           randomized, while the visual sequence followed the
                                                                 same statistics as in previous experiments.
During familiarization, participants noticed 96% of the
repeating elements, and no difference was found between          Results and Discussion
the two conditions, t (28) = 0.91, p = 37.
   As in Experiment 1, discrimination of the familiar            Although stimuli were presented cross-modally
triplets from the foils was assessed as a difference             during the familiarization phase in the current
between hits (i.e., correct acceptance of familiar triplets)     experiment, adults did not discriminate familiar
and false alarms (i.e., erroneous acceptance of foils). In       triplets from foils, (M = -0.01, SE = .03), t (9) = -
contrast to the visual condition of Experiment 1 where           0.36, p = .73. See Figure 4 for means and standard
participants were at-chance at discriminating the familiar       errors across Experiments 1 - 3. This suggests that
triplets from the foils, discrimination of the visual            the facilitation effect in Experiment 2 resulted from
                                                             614

correlated auditory stimuli facilitating visual statistical                          At the same, the study also raises a number of
learning, as opposed to the auditory stimuli simply                            important questions for future research. The most
making the task more engaging.                                                 important issue concerns the mechanism(s) that may
                                                                               underlie the current effects. Experiments 2 and 3
                                                                               demonstrate the importance of the auditory and visual
                        0.5                 Unimodal: Experiment 1             sequences sharing the same underlying statistics.
                                            Correlated: Experiment 2           Thus, the underlying mechanism, at least in adults,
                        0.4                 Uncorrelated: Experiment 3         appears to be sensitive to covariation across
 Accuracy (Hits - FA)
                                  *                                            modalities. Examining whether infants and young
                        0.3
                                                    *      *                   children also benefit from correlated cues will
                                                                               provide some insight into the developing interactions
                        0.2                                                    between the auditory and visual systems.
                                                                                  Experiments 1 and 2 demonstrate that correlated
                        0.1                                                    auditory input facilitates visual statistical learning,
                                                                               whereas, correlated visual input has no significant
                          0                                                    effect on auditory statistical learning (see Figure 4).
                                Visual                  Auditory               These findings provide preliminary evidence that
                        -0.1                                                   facilitation effects are asymmetrical. However, this
                                         Modality                              will have to be further tested in future research.
                                                                                  Finally, experiments, such as the ones reported
Figure 4: Discrimination accuracy broken up by modality                        here, will be fundamental for understanding how
in Experiments 1-3. Note: “*” greater than 0, p < .05.                         attention is allocated within and between modalities.
                                                                               For example, when adults are given two visual
                               General Discussion                              sequences and are asked to selectively attend to one
                                                                               of the sequences, they fail to learn the statistics in the
     The results point to several important findings. First,                   unattended visual sequence (Turke-Browne, et al.,
under comparable experimental conditions, adult                                2005). This demonstrates the importance of selective
participants were more likely to detect the temporal                           attention within the visual modality, and possibly
structure in the auditory modality than in the visual                          within any modality. However, it will also be
modality (Experiment 1). Second, when auditory and                             important to understand how attention is allocated to
visual input shared the same statistics, visual statistical                    cross-modal stimuli and to examine the role of
learning was enhanced (Experiment 2). Even though the                          selective attention in cross-modal statistical learning.
amount of information to be learned increased in                               Consistent with the current study, we have
Experiment 2, this increase in processing demands                              preliminary evidence for a similar asymmetry in
increased rather than decreased the likelihood of learning                     selective attention: Selectively attending to the
the visual sequence. At the same time, the more efficient                      auditory modality has an effect on visual statistical
learning in Experiment 2 did not come with a cost (i.e.,                       learning, whereas, selectively attending to the visual
attenuated processing in the auditory sequence). Finally,                      modality has no effect on auditory statistical learning.
Experiment 3 eliminated the possibility that cross-modal                          In summary, many studies have examined how
facilitation resulted from the auditory stimuli making the                     humans and non-humans detect statistical regularities
task more engaging.                                                            in different modalities. However, much of our
     These are novel findings pointing to cross-modal
                                                                               experiences are multi-modal and there is relatively
facilitation in statistical learning. Recall that previous                     little known about how attention is allocated to multi-
research indicated that under some conditions, cross
                                                                               modal stimuli or how different modalities interact
modal presentation of stimuli is likely to facilitate visual
                                                                               with one another to acquire new knowledge. The
(and auditory) processing (Bahrick & Lickliter, 2000 see
                                                                               current study begins to answer some of these
Lewkowicz, 2000; Lickliter & Bahrick, 2000, for
                                                                               important questions.
reviews), whereas under other conditions, cross-modal
presentation is likely to hinder visual processing (e.g.,
Napolitano & Sloutsky, 2004; Robinson & Sloutsky,                                              Acknowledgments
2004; in press-a; in press-b; Sloutsky & Napolitano,                           This research has been supported by grants from the
2003). However, these studies were conducted primarily                         NSF (REC 0208103) and from the Institute of
with infants and young children. Current research sheds                        Education Sciences, U.S. Department of Education
light on cross-modal processing later in development,                          (R305H050125) to Vladimir M. Sloutsky.
indicating that cross-modal presentation of stimuli
facilitates visual statistical learning in adults.
                                                                         615

                       References                              Napolitano, A.C., & Sloutsky, V.M. (2004). Is a
                                                                 Picture Worth a Thousand Words? The Flexible
Bahrick, L.E., & Lickliter, R. (2000). Intersensory              Nature of Modality Dominance in Young Children.
  redundancy guides attentional selectivity and perceptual       Child Development, 75, 1850-1870.
  learning in infancy. Developmental Psychology, 36,           Roberts, K., & Jacob, M. (1991). Linguistic versus
  190–201.                                                       attentional       influences      on   nonlinguistic
Conway, C.M., & Christiansen, M.H. (2005). Modality-             categorization in 15-month-old infants. Cognitive
  constrained statistical learning of tactile, visual, and       Development, 6, 355-375.
  auditory sequences. Journal of Experimental                  Robinson, C.W., & Sloutsky, V.M. (2004). Auditory
  Psychology: Learning, Memory, and Cognition, 31, 24-           dominance and its change in the course of
  39.                                                            development. Child Development, 75, 1387-1401.
Conway, C.M., & Christiansen, M.H. (2006). Statistical         Robinson, C,W., & Sloutsky, V.M. (in press-a).
  learning within and between modalities: Pitting abstract       Visual processing speed: Effects of auditory input
  against stimulus-specific representations. Psychological       on visual processing. Developmental Science.
  Science, 17, 905-912.                                        Robinson, C,W., & Sloutsky, V.M. (in press-b).
Fiser, J., & Aslin, R.N. (2002a). Statistical learning of        Linguistic labels and categorization in infancy: Do
  higher-order temporal structure from visual shape-             labels facilitate or hinder?. Infancy.
  sequences. Journal of Experimental Psychology:               Saffran, J.R., Aslin, R.N., & Newport, E.L. (1996).
  Learning, Memory, and Cognition, 28, 458-467.                  Statistical learning by 8-month old infants. Science,
Fiser, J., & Aslin, R.N. (2002b). Statistical learning of        274, 1926-1928.
  new visual feature combinations by infants.                  Saffran, J.R., Johnson, E.K., Aslin, R.N., & Newport,
                                                                 E.L. (1999). Statistical learning of tone sequences
  Proceedings of the National Academy of Sciences, 99,
                                                                 by adults and infants. Cognition, 70, 27-52.
  15822-15826.
                                                               Sloutsky, V.M., & Napolitano, A. (2003). Is a picture
Kirkham, N.Z., Slemmer, J.A., & Johnson, S.P. (2002).            worth a thousand words? Preference for auditory
  Visual statistical learning in infancy: Evidence of a          modality in young children. Child Development,
  domain general learning mechanism. Cognition, 83,              74, 822-833.
  B35-B42.                                                     Sloutsky, V.M., & Robinson, C.W. (in press). The
Lewkowicz, D.J. (2000). The development of intersensory          role of words and sounds in visual processing:
  temporal perception: An epigenetic systems/limitations         From overshadowing to attentional tuning.
  view. Psychological Bulletin, 126, 281-308.                    Cognitive Science.
Lickliter, R., & Bahrick, L.E. (2000). The development of      Turk-Browne, N.B., Junge, J.A., & Scholl, B.J.
  infant intersensory perception: Advantages of a                (2005). The automaticity of visual statistical
  comparative        convergent-operations       approach.       learning. Journal of Experimental Psychology:
  Psychological Bulletin, 126, 260-280.                          General, 134, 552 - 564.
                                                           616

