UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Computational Explorations of Split Architecture in Modeling Face and Object Recognition
Permalink
https://escholarship.org/uc/item/5dm3d024
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Hsiao, Janet Hui-wen
Cottrell, Garrison W.
Shieh, Danke
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

      Computational Explorations of Split Architecture in Modeling Face and Object
                                                               Recognition
                                            Janet Hui-wen Hsiao (jhsiao@cs.ucsd.edu)
                                               Garrison W. Cottrell (gary@ucsd.edu)
                        Department of Computer Science and Engineering, University of California San Diego
                                           9500 Gilman Drive #0404, La Jolla, CA 92093, USA
                                                    Danke Shieh (danke@ucsd.edu)
                                 Department of Cognitive Science, University of California San Diego
                                           9500 Gilman Drive #0515, La Jolla, CA 92093, USA
                               Abstract                                  reported in face perception. The classical experiment is to
   Anatomical evidence shows that our visual field is initially
                                                                         ask participants to judge the similarity between a face and
   split along the vertical axis and contralaterally projected to        chimeric faces made from the two left halves (left chimeric
   different hemispheres. It remains unclear at which stage the          face) or the two right halves (right chimeric face) of the
   split information converges. In the current study, we applied         original face (from the viewer’s perspective; Figure 1). The
   the Double Filtering by Frequency (DFF) theory (Ivry &                results show that the left chimeric face is usually judged
   Robertson, 1998) to modeling the visual split; the theory             more similar to the original face than the right chimeric
   assumes a right hemisphere/low frequency bias. We compared            face, especially for highly familiar faces (Brady, Campbell,
   three cognitive architectures with different timing of                & Flaherty, 2005). Consistent with this result, other studies
   convergence and examined their cognitive plausibility to              have argued for a right hemisphere (RH) bias in face
   account for the left side bias effect in face perception
   observed in human data. We show that the early convergence
                                                                         perception (e.g., Rossion, Joyce, Cottrell, & Tarr, 2003).
   model failed to show the left side bias effect. The left side         Nevertheless, it remains unclear how far the split effect
   bias effect was also observed in Greeble recognition. The             extends. Although it has been shown that our visual system
   modeling hence suggests that the convergence may take place           is organized as a set of hierarchically connected regions, and
   at an intermediate or late stage, at least after information has      the receptive field sizes of the neurons increase by a factor
   been extracted/transformed separately in the two hemispheres;         of about 2.5 at each succeeding stage (Rolls, 2000), the
   it also provides testable predictions about whether the left side     initial trajectory of visual activation flow is a fast and
   bias effect may also be observed in (expertise-level) object          widespread sweep and continues through iterations of
   recognition.                                                          feedback loops for further processing in the sensory area
   Keywords: Connectionist modeling;             face   recognition;     (Foxe & Simpson, 2002); hence, it is unclear yet whether
   hemispheric differences; split modeling.                              the split influences high-level cognition. In visual word
                                                                         recognition, Hsiao and Shillcock (2005a) showed that this
                           Introduction                                  split effect can reach far enough to interact with sex
Because of the partial decussation of optic nerves, our visual           differences in brain laterality for phonological processing.
system is initially vertically split and the two visual                  Thus, the split seems to influence high-level cognition.
hemifields are initially contralaterally projected to different
hemispheres. A fundamental question in cognitive science is
whether this initial split has any functional significance; that
is, whether the effect of initial splitting can extend far
enough to influence our cognition? A second question is at
what stage does the information converge?                                   Figure 1: Left chimeric, original, and right chimeric faces.
A functional split                                                       Split modeling & timing of convergence
Evidence from visual word recognition supports a functional              In order to address the splitting effects observed in visual
split. The general finding is that the two hemispheres have              word recognition, Shillcock and Monaghan (2001) proposed
contralateral influence on responses driven by the first and             a split fovea model (Figure 2) and showed that some
last halves of the stimuli, which are initially projected to             psychological phenomena in visual word recognition can be
different visual hemifields (e.g., Lavidor, Ellis, Shillcock, &          better accounted for by the split architecture, such as
Bland, 2001; Lavidor & Walsh, 2003; Hsiao & Shillcock,                   exterior letter effects in English word recognition and eye
2005a; Hsiao, Shillcock, & Lavidor, 2006). There is also                 fixation behavior in reading English (Shillcock, Monaghan,
evidence from face recognition supporting a functional split.            & Ellison, 2000). Hsiao and Shillcock (2005b) further
For example, a left side bias effect has been frequently                 showed that the split and nonsplit architectures in modeling
                                                                     365

Chinese character recognition exhibited qualitatively                      conduct a more general comparison between these three
different processing, and the results were able to account for             architectures and examine their performance and cognitive
the sex differences in naming Chinese characters in human                  plausibility.
data.
            Split fovea model           Early convergence model
                                                                           DFF theory & face recognition
                    Output                           Output
                                                                           In order to account for various psychological phenomena
                                                                           involving hemispheric differences, Ivry and Robertson
                                                                           (1998) proposed a Double Filtering by Frequency (DFF)
    Hidden layer           Hidden layer            Hidden layer            theory. The theory argues that information coming into the
                                                                           brain goes through two frequency filtering stages. The first
            Left            Right                 Visual input             stage involves attentional selection of task-relevant
           visual            visual                                        frequency information, and at the second stage the two
           input             input
                                                                           hemispheres have asymmetric filtering processing: the left
                                                                           hemisphere (LH) amplifies high frequency information (i.e.,
  Intermediate convergence model           Late convergence model
                                                                           a high-pass filter), whereas the RH amplifies low frequency
                Output                               Output                information (i.e., a low-pass filter).
                                                                               There has been an ongoing debate regarding whether the
             Hidden layer                Hidden layer     Hidden layer     brain processes faces differently from objects. Evidence for
                                                                           this argument comes from studies showing that the fusiform
                                                                           face area (FFA) in the brain selectively responds to face
           Left         Right                 Left           Right
         visual         visual              visual           visual        stimuli (e.g., McKone & Kanwisher, 2005), whereas other
          input         input                input           input         studies have suggested that several phenomena that were
                                                                           thought to be unique to face recognition may be due to
         Figure 2: Architectures of different models.
                                                                           expertise (e.g., Gauthier et al., 1999). Thus, the left side bias
                                                                           effect observed in face perception may be due to a
     In the current study, we apply the split fovea model to
                                                                           designated face processor located in the RH, or the reliance
face and object recognition. In contrast to previous models
                                                                           on low spatial frequency (LSF) processing in the RH
in visual word recognition, which act on a relatively abstract
                                                                           (according to the DFF theory) once the expertise is
level of representation (i.e., localist representation of letters
                                                                           acquired. The split architectures introduced here enable us
or stroke patterns), we incorporate some aspects of visual
                                                                           to apply the DFF theory to modeling face and object
anatomy into the modeling. We use Gabor responses over
                                                                           recognition. We first examine whether the DFF theory is
the input image to simulate neural responses of complex
                                                                           able to account for the left side bias effect in face
cells in the early visual system (Lades et al., 1993). We then
                                                                           perception. A positive result will suggest the RH reliance in
reduce the dimension of this perceptual representation with
                                                                           face processing is due to the low frequency bias in the RH.
Principal Component Analysis (PCA), which has been
                                                                           We then examine whether the left side bias effect can also
argued to be a biologically plausible linear compression
                                                                           be obtained in expert object recognition. The objects under
technique (Sanger, 1989; cf. Dailey et al., 2002); this is the
                                                                           examination are Greebles, a novel class of objects that have
visual input shown in Figure 1. With this level of
                                                                           been frequently used in studies of object recognition and
abstraction, convergence of the initial split may happen at
                                                                           perceptual expertise (e.g., Gauthier et al., 1999). If the left
three different stages: early: after Gabor filters in the early
                                                                           side bias effect also exists in modeling expert Greeble
visual system (i.e., at the input layer), Intermediate: after
                                                                           recognition, the results will provide testable predictions
information extraction through PCA (i.e., at the hidden
                                                                           regarding whether faces and objects are processed
layer), and late: at the output layer (Figure 2). In the early
                                                                           differently in the brain.
convergence model, the left and right Gabor filters are
processed as a whole through PCA (i.e., nonsplit input
representation; Figure 3). In the intermediate convergence                                     Models and Results
model, PCA is applied separately to the left and right Gabor
filters and the convergence is at the hidden layer. In the late            Representations and modeling details
convergence model, in addition to the split input layer, the               To simulate responses of complex cells in the early visual
hidden layer is also split, and the information converges at               system, the input image (135 x 100 pixels) was first filtered
the output layer. According to this categorization, the split              with a rigid grid (16 x 12) of overlapping 2D Gabor filters
fovea and nonsplit models proposed first in Shillcock and                  (Daugman, 1985) in quadrature pairs at six scales and eight
Monaghan (2001) can be considered as late and                              orientations (Figure 3). The six scales corresponded to 2 to
intermediate convergence models respectively 1 . Here we                   64 cycles per face. Given the width of the image (100
                                                                           pixels), this frequency range hence can be considered as the
1
  The late convergence model differs from the split fovea model in
that it does not have interconnections between the two hidden              reasons; in separate simulations, we found that adding these
layers. We removed these interconnections here for comparison              interconnections did not change the effects we reported here.
                                                                       366

task-relevant frequency range (the seventh scale would have                  faces), the hidden layer of the network has been associated
128 cycles, which exceeded the width of the image). Hence                    with the Fusiform Face Area. Finally, the output layer has a
the first stage of the DFF is implemented by simply giving                   unit for each individual subject. For the following
this input to all of our models. The paired Gabor responses                  simulations, we ran each model 80 times and analyzed its
were combined to obtain Gabor magnitudes. In the nonsplit                    behavior with ANOVA after 100-epoch training (their
input representation, this 9,216 (16 x 12 Gabor filters x 6                  performance on the training set all reached 100% accuracy).
scales x 8 orientations) element perceptual representation                   The training algorithm was discrete back propagation
was compressed into a 50-element representation with PCA.                    through time. (Rumelhart, Hinton & Williams, 1986), and
In the split input representation, the face was split into left              the learning rate was 0.1. Performance was analyzed at the
and right halves, and each had 16 x 6 Gabor filters (4,608                   end of 7 time steps (cf. Shillcock & Monaghan, 2001; Hsiao
elements). The perceptual representation of each half was                    & Shillcock, 2005b) 3 .The independent variables were
compressed into a 50-element representation (hence in total                  architecture (early, intermediate, and late convergence) and
there were 100 elements) 2 . After PCA, each principal                       frequency bias (unbiased vs. biased). The dependent
component was z-scored to equalize the contribution of each                  variables were accuracy and size of left side bias effect. To
component in the models. In the three models, the early                      examine the size of left side bias effect, we took output node
convergence model had a nonsplit input representation,                       activation for a particular individual as a measure of
whereas both the intermediate and late convergence models                    similarity between the chimeric face and the original face.
had a split input representation. In order to equalize their                 After training, we presented the networks with left and right
computational power, the hidden layer of the early and the                   chimeric faces using test set images. The size of left side
intermediate convergence models had 20 units, and each of                    bias effect was measured as the difference between the
the two hidden layers of the late convergence model had 10                   activation of the output node for the original face when the
units; in the intermediate convergence model, half of the                    left chimeric face was presented and when the right
connections from the input layer to the hidden layer were                    chimeric face was presented (note that output activation
randomly selected and removed. Hence, the three models                       ranged from 0 to 1). For each simulation, the materials
had exactly the same number of hidden units and weighted                     consisted images of 30 different individuals (so there are 30
connections. To implement the second stage of the DFF                        output nodes; see the following sections for simulation
theory, we used a sigmoidal filter (Figure 4) after the Gabor                details). Two datasets were created for training and testing
filters to bias the Gabor responses on the left half face (RH)               and the order was counterbalanced across the simulation
to LSF and those on the right half face (LH) to high spatial                 runs. In order to eliminate any side bias effect due to the
frequency (HSF).                                                             baseline difference between the two sides of the images, in
                                                                             half of the simulation runs the mirror images of the original
                  RH     x x x x x x LH                                      images were used.
                         xxxxxx        V1:    Gabor      filters  on                                        f(x,a) = 1 / ( 1 + exp ( - a (x - 3.5) )
                 Gabor x x x x x x     sampling points (12x16 grid)                       Sigmoid Weighting of frequencies                 Sigmoid Weighting of frequencies
                 filters  ……….         Each sampling point has 48
                                       Gabor filters: 6 scales and 8                       1                                                1
      Input image
                                                                                                                                  Weight
                                       orientations.
                                                                                 Weight
                                                                                          0.5                                              0.5
        135X100
                                                                                           0                                 LH             0                                 LH
          Input               Left Input             Right Input                                1   2   3     4   5   6      RH                  1   2   3   4   5   6        RH
     Representation       Representation (in      Representation (in                            Frequency (low-high)                             Frequency (low-high)
       (Number of          RH, Number of           LH, Number of
    components = 50)      components: 50)         components: 50)                Figure 4: Sigmoidal filters: unbiased (a = 0) and biased
    Nonsplit PCA: PCA           Split PCA: Separate PCAs of                                      conditions (a = 1.5).
    of Gabor responses          Gabor responses
                                                                             Face recognition with expression changes
     Figure 3: Nonsplit and split visual input representations.
                                                                             We first examined face recognition with different
                                                                             expressions. Each of the two datasets created contained four
    In short, we tried to bring the model architecture as close
                                                                             images with different expressions (Figure 5), for a total of
to the visual anatomy as possible. The Gabor filters
                                                                             120 training and 120 test images. These images were taken
correspond to V1, the PCA can be thought of as analogous
                                                                             from CAlifornia Facial Expressions dataset (CAFÉ; Dailey,
to the Occipital Face Area (i.e., structural representation of
                                                                             Cottrell, & Reilly, 2001). The generalization accuracy
2
  Although the split and nonsplit representation had different
                                                                             3
number of dimensions in the input layer, they both contained                   Although the networks do not have recurrent connections, we
information from the first 50 principal components. This equalizes           used discrete back propagation through time to be consistent with
the information contained in each representation better than                 the split fovea model (Shillcock & Monaghan, 2001), which has
increasing the number of dimensions in the nonsplit representation           recurrent connections between the two hidden layers. We found
to match that of the split representation. In fact, with 100                 that adding these interconnections did not change the effects we
components, the nonsplit model performs worse.                               reported here.
                                                                       367

results showed a significant interaction between architecture                                     Figure 6: (a) Performance and (b) Left side bias effect in
and frequency bias (F(2, 474) = 8.513, p < 0.001; Figure                                          the three models. Error bars show standard errors (* p <
6(a)). In general, biased spatial frequency hurt performance,                                                0.01; ** p < 0.001; *** p < 0.0001).
and the later the convergence, the bigger the effect. As for
the left side bias effect for chimeric faces, there was a main                                    Faces under natural lighting changes
effect of architecture (F(2, 474) = 141.457, p < 10-48), a                                        In order to reconfirm the left side bias effects we obtained,
main effect of frequency bias (F(2, 474) = 709.651, p < 10-                                       we conducted another simulation: face recognition under
95
  ), and a significant interaction between architecture and                                       different lighting changes. We selected face images from
frequency bias (F(2, 474) = 144.386, p < 10-48; Figure 6(b)).                                     Yale face database (Georghiades, Belhumeur, & Kriegman,
None of the models had a left side bias effect in the                                             2001) with a light source moving from right to left. Each
unbiased condition. In the biased condition, the frequency                                        individual had eight different lighting conditions (Figure 7);
bias significantly induced the left side bias effect in the late                                  the lighting conditions in the training and test datasets had
and intermediate convergence models. In contrast, the early                                       the same azimuths but different altitudes.
convergence model did not have the left side bias effect.                                          Dataset 1
This suggests that in the biased condition, converging at an
early stage (i.e., nonsplit representation) may still extract
balanced low and high frequency information for
recognition, whereas converging at a later stage (i.e., split                                      Dataset 2
representation) allows more low frequency information
from the left half face to the hidden layer, and consequently
brings about the left side bias effect4.
                                                                                                  Figure 7: Face images for training. From left to right, the
                                                                                                  azimuths are: -60, -35, -20, -10, +10, +20, +35, and +60.
       Dataset 1: Disgust, happy (with teeth), sad, and surprise.                                              Altitudes range from -20 to 20.
                                                                                                               (a)                                          Unbiased     Biased
                                                                                                                                             100%    ***           ***               ***
                                                                                                                Test set accuracy
                                                                                                                                              98%
         Dataset 2: happy, angry, fear, and neutral.                                                                                          96%
                                                                                                                                              94%
Figure 5: Face images for facial expression recognition.                                                                                      92%
             (a)                                            Unbiased       Biased                                                             90%
                                                                                                                                                     Late     Intermediate        Early
                                           100%
                                                    **           *
              Test set accuracy
                                           99%
                                                                                                               (b)                                          Unbiased     Biased
                                           98%
                                                                                                                                             0.3    ***           ***               ***
                                                                                                                Left side bias effect size
                                           97%
                                                                                                                                             0.2
                                           96%
                                                                                                                                             0.1
                                           95%
                                                                                                                                               0
                                                    Late     Intermediate           Early
                                                                                                                                             -0.1
             (b)                                            Unbiased       Biased
                                                                                                                                             -0.2
                                              0.6    ***             ***
              Left side bias effect size
                                                                                                                                                    Late     Intermediate         Early
                                              0.5
                                              0.4
                                              0.3                                                  Figure 8: (a) Performance of the three models. (b) Left
                                              0.2
                                              0.1                                                   side bias effect in the three models. Error bars show
                                                0
                                             -0.1
                                                                                                              standard errors (*** p < 0.0001).
                                             -0.2
                                                     Late     Intermediate          Early
                                                                                                      The results showed that the late convergence model
                                                                                                  performed the worst (F(2, 234) = 158.918, p < 10-52),
                                                                                                  and performance in the unbiased condition was better
                                                                                                  than the biased condition (F(2, 234) = 172.075, p <10-33;
4
                                                                                                  Figure 8(a)). As for the left side bias effect for chimeric
  The only difference between the early and intermediate                                          faces, there was a main effect of architecture (F(2, 234)
convergence models was the input representation (nonsplit vs.                                     = 233.286, p < 10-70), a main effect of frequency bias
split). In a separate simulation, we used a simple perceptron (i.e.,                              (F(2, 234) = 369.360, p < 10-60), and a significant
the hidden layer was removed) to examine the baseline behavior                                    interaction between architecture and frequency bias (F(2,
between the two representations, and the split representation                                     234) = 242.055, p < 10-72; Figure 8(b)). The frequency
indeed had a left side bias effect whereas the nonsplit
                                                                                                  bias again significantly induced the left side bias effect
representation did not; this effect was consistent across the three
                                                                                                  in the late and intermediate convergence models; the
simulations we reported here.
                                                                                            368

early convergence model failed to show the left side bias
effect; in fact, it exhibited a slight right side bias effect.                                                The first set was Greebles under the San Francisco sun,
The results hence confirmed again that the intermediate                                                 and the other was the same Greebles in Ketchikan. Hence,
convergence model had the strongest left side bias                                                      in the two datasets, the sun positions had different azimuths
effect, and the early convergence model was not able to                                                 and altitudes. The accuracy results showed that there was a
exhibit the left side bias effect in human data.                                                        main effect of frequency bias (F(2, 234) = 94.089, p <10-19):
                                                                                                        performance in the unbiased condition was better than the
Greebles under natural lighting changes                                                                 biased condition (Figure 10(a)). As for the left side bias
We turned to see whether the same effects can be obtained                                               effect for chimeric Greebles, there was a main effect of
in Greeble recognition. Objects such as Greebles do not                                                 architecture (F(2, 234) = 100.768, p < 10-36), a main effect
have expressions; one of the most common object                                                         of frequency bias (F(2, 234) = 13.891, p < 0.001), and an
recognition tasks we perform in the real world is probably to                                           interaction between architecture and frequency bias (F(2,
recognize the same object under different lighting                                                      234) = 178.707, p < 10-57; Figure 10(b)). Similar to the
conditions. Hence, we examined the networks’ performance                                                previous simulation, the frequency bias significantly
on recognizing Greebles under different lighting changes.                                               induced the left side bias effect in the late and intermediate
We considered the sun as the major source of light in nature,                                           convergence models; the early convergence model did not
and its azimuth increases during a day and its altitude first                                           have the left side bias effect; it exhibited right side bias
increases and then decreases from midday. In each of the                                                instead. The results suggest that the left side bias effect may
two datasets created, each Greeble had eight images under                                               also exist in Greeble recognition.
the eight different lighting conditions shown in Figure 9.
                                                                                                                     Conclusion and Discussion
  San Francisco, CA
                                                                                                        In the current study, we explored split architecture in
                                                                                                        modeling face and object recognition. We applied the DFF
                                                                                                        theory to the split modeling of visual processing; for the
                                                                                                        input representation, we first selected a task relevant
                                                                                                        frequency range, and then biased the information coming
  9am 10am                               11am   12pm        1pm           2pm         3pm   4pm
                                                                                                        into the RH (i.e., left half of the input) to low frequency and
                                                                                                        that coming into the LH (i.e., right half of the input) to high
                                                                                                        frequency through a sigmoidal filter. We then compared
                                                                                                        performance and cognitive plausibility of three cognitive
 Ketchikan, AK                                                                                          architectures with different timings of convergence. We
                                                                                                        showed that, in this computational exploration, the
 Figure 9: A Greeble, facing south, under the sun in San                                                combination of the spatial frequency bias and the splitting of
    Francisco, California (latitude, longitude: 27.618,                                                 the information between left and right are sufficient to show
122.373) and Ketchikan, Alaska (55.342, 131.647), from                                                  the left side bias effect, but neither alone can show the
                      9 am to 4 pm.                                                                     effect. This is consistent with the observation that there is a
                                                                                                        low spatial frequency bias in face identification, both in
           (a)                                          Unbiased     Biased                             humans and computational models (Schyns & Oliva, 1999;
                                         100%     ***          ***              ***                     Dailey et al., 2002). This is reflected in the higher activation
                                                                                                        of the identity unit when the model’s right hemisphere
             Test set accuracy
                                          99%
                                          98%                                                           receives the same side of the face it was trained upon,
                                          97%                                                           compared with when it does not.
                                          96%                                                               The failure of the early convergence model in exhibiting
                                          95%                                                           the left side bias effect suggested that the initially split
                                                 Late     Intermediate        Early                     visual input may converge at an intermediate or late stage, at
           (b)                                          Unbiased     Biased
                                                                                                        which     at     least    certain     type     of    information
                                          0.4   ***           ***               ***
                                                                                                        extraction/transformation has been applied separately in
            Left side bias effect size
                                          0.3                                                           each hemisphere, perhaps after the Occipital Face Area.
                                          0.2
                                          0.1
                                                                                                        This result is consistent with several behavioral studies
                                            0                                                           showing that each hemisphere seems to have dominant
                                         -0.1                                                           influence on the processing of the visual information
                                         -0.2
                                         -0.3                                                           presented in the visual hemifield to which it has direct
                                                Late     Intermediate         Early                     access (e.g., Brady et al, 2005; Hsiao et al., 2006).
                                                                                                            The results from modeling Greeble recognition also
Figure 10: (a) Performance of the three models. (b) Left                                                showed a left side bias effect in both the intermediate and
  side bias effect in the three models. Error bars show                                                 late convergence models, but not in the early convergence
            standard errors (*** p < 0.0001).                                                           model. In human data, the left side bias effect has never
                                                                                                  369

been shown in recognition tasks other than faces, and hence              Hsiao, JH. & Shillcock, R. (2005a). Foveal splitting causes
has been considered a face-specific effect. However, it may                 differential processing of Chinese orthography in the male and
also be due to our expertise in face processing (cf. Gauthier               female brain. Cognitive Brain Research, 25, 531-536.
et al., 1999). The modeling result hence provides a testable             Hsiao, JH. & Shillcock, R. (2005b). Differences of split and non-
prediction about whether a left side bias effect can also be                split architectures emerged from modelling Chinese character
observed in object recognition once expertise is acquired.                  pronunciation. Proceedings of the Twenty Seventh Annual
     The models we propose here unavoidably involve                         Conference of the Cognitive Science Society (pp. 989-994).
abstraction and assumptions about the underlying neural                     Mahwah, NJ: Lawrence Erlbaum Associates.
complexity, but they nevertheless address the issue under                Hsiao, JH., Shillcock, R., & Lavidor, M. (2006). A TMS
                                                                            examination of semantic radical combinability effects in
examination here. The study provides a computational
                                                                            Chinese character recognition. Brain Research, 1078, 159-167.
explanation of the cognitive implausibility of the early
                                                                         Ivry, R. & Robertson, LC. (1998). The Two Sides of Perception.
convergence model, which has been the most typical model
                                                                            Cambridge: MIT Press.
for face/object/word recognition in the literature (e.g.,                Lades, M., Vorbruggen, JC., Buhmann, J., Lange, J., von der
Dailey et al, 2002; Harm & Seidenberg, 1999). The fact that                 Malsburg, C., Wurtz, RP., & Konen, W. (1993). Distortion
the initial split has a functional significance has been                    invariant object recognition in the dynamic link architecture.
overlooked in connectionist modeling of cognitive                           IEEE Transactions on Computers, 42, 300–311.
processes; the current study shows that this fact does have              Lavidor, M., Ellis, AW., Shillcock, R., & Bland, T. (2001).
significant impact on how modeling is able to explain and                   Evaluating a split processing model of visual word recognition:
predict human behavior.                                                     Effects of word length. Cognitive Brain Research, 12, 265-272.
     As future directions, the proposed models can also be               Lavidor, M. & Walsh, V. (2003). A magnetic stimulation
applied to visual word recognition (cf. Shillcock et al.,                   examination of orthographic neighbourhood effects in visual
2000) to examine the current debates about the foveal                       word recognition. Journal of Cognitive Neuroscience, 15, 354-
splitting phenomena (e.g. Lavidor & Walsh, 2004). We will                   363.
also examine a fundamental question about why such a split               Lavidor M., Walsh, V. (2004). The nature of foveal representation.
and frequency bias exists in the brain. The current                         Nat. Rev. Neurosci., 5, 729-735.
simulations seem to suggest that frequency bias deteriorates             McKone, E. & Kanwisher, N. (2005). Does the human brain
performance. There may exist an optimal frequency bias                      process objects of expertise like faces? A review of the
setting that is able to boost performance, or the advantage of              evidence. In S. Dehaene, J. R. Duhamel, M. Hauser, &
split and frequency bias may be observed when the system                    Rizzolatti (Eds), From Monkey Brain to Human Brain.
(i.e., the brain) has to deal with tasks with different                     Cambridge, Massachusetts: the MIT Press.
frequency requirements; for example, word recognition may                Rolls, ET. (2000) Functions of the primate temporal lobe cortical
rely more on high frequency information processing in                       visual areas in invariant visual object and face recognition.
                                                                            Neuron, 27, 205–218.
contrast with face recognition. These issues are currently
                                                                         Rossion, B., Joyce, CA., Cottrell GW., & Tarr, MJ. (2003). Early
under examination.
                                                                            lateralization and orientation tuning for face, word, and object
                                                                            processing in the visual cortex. Neuroimage, 20, 1609-1624.
                          References                                     Rumelhart, DE, Hinton, GE, & Williams, RJ. (1986). Learning
Dailey, MN., Cottrell, GW., Padgett, C., & Ralph, A. (2002)                 representations by back-propagating errors. Nature, 323, 533-
   EMPATH: A neural network that categorizes facial expressions.            536.
   Journal of Cognitive Neuroscience, 14, 1158-1173.                     Sanger, T. (1989). An optimality principle for unsupervised
Dailey, MN., Cottrell, GW., & Reilly, J. (2001). CAlifornia Facial          learning. In Touretzky, D. (ed), Advances in Neural Information
   Expressions (CAFE). http://www.cs.ucsd.edu/users/gary/CAFE/.             Processing Systems, vol. 1, pp. 11–19, San Mateo: Morgan
Foxe, JJ. & Simpson, GV. (2002). Flow of activation from V1 to              Kaufmann.
   frontal cortex in humans: a framework for defining 'early' visual     Schyns P.G. & Oliva A. (1999) Dr. Angry and Mr. Smile:
   processing. Experimental Brain Research, 142, 139–150.                   when categorization flexibly modifies the perception of faces
Gauthier, I., Tarr, MJ., Anderson, AW., Skudlarski, P., & Gore,             in rapid visual presentations. Cognition, 69, 243-265.
   JC. (1999). Activation of the middle fusiform “face area”             Shillcock, RC. & Monaghan, P. (2001). The computational
   increases with expertise in recognizing novel objects. Nat.              exploration of visual word recognition in a split model. Neural
   Neurosci., 2, 568–573.                                                   Computation, 13, 1171-1198.
Georghiades, AS., Belhumeur, PN., & Kriegman, DJ. (2001).                Shillcock, R., Ellison, TM., & Monaghan, P. (2000). Eye-fixation
   From Few to Many: Illumination Cone Models for Face                      behavior, lexical storage, and visual word recognition in a split
   Recognition under Variable Lighting and Pose. IEEE Trans.                processing model. Psychological Review, 107, 824-851.
   Pattern Anal. Mach. Intelligence, 6, 643-660.
Harm, MW. & Seidenberg, MS. (1999). Phonology, reading
   acquisition, and dyslexia: Insights from connectionist models.
   Psych. Rev., 106, 491–528.
                                                                     370

