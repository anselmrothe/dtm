UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Grounded Causal Models
Permalink
https://escholarship.org/uc/item/9kz6d557
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Goodman, Noah D.
Mansinghka, Vikash K.
Tenenbaum, Joshua B.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                         Learning Grounded Causal Models
  Noah D. Goodman (ndg@mit.edu), Vikash K. Mansinghka (vkm@mit.edu), Joshua B. Tenenbaum (jbt@mit.edu)
           Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139
                              Abstract                                 cases. For instance, all of the perceptions of “explosions” are
   We address the problem of learning grounded causal mod-             quite similar (or anyhow dissimilar to other percepts), so it
   els: systems of concepts that are connected by causal relations     should be easy to cluster them together into a new variable,
   and explicitly grounded in perception. We present a Bayesian        which could later be used in causal learning (“gas leaks cause
   framework for learning these models—both a causal Bayesian
   network structure over variables and the consequential region       explosions”).
   of each variable in perceptual space—from dynamic percep-              However, people often make distinctions which are per-
   tual evidence. Using a novel experimental paradigm we show          ceptually quite subtle but causally important. For example,
   that humans are able to learn grounded causal models, and that
   the Bayesian model accounts well for human performance.             to our toddler petting and pounding the kitty may be percep-
   Keywords: causal variable; causal model; concept grounding;
                                                                       tually similar—similar enough that they would be clustered
   observation; causal learning.                                       together by bottom-up grouping (e.g. simply “touching the
                                                                       kitty”). In actuality, petting and pounding have very different
                         Introduction                                  effects (purring versus hissing), and confounding them could
Imagine a toddler newly acquainted with the family cat, who            lead to problematic results from our toddler. Such examples
soon learns that petting causes purring. Prima facie this is           are the rule rather than the exception: laughing is ever-so-
a simple inference from observations: the constant conjunc-            similar to crying, but follows from different causes; pressing
tion of petting with purring leads to knowledge of the causal          the “volume” button on some T.V. remotes is very similar to
relation between them. A number of approaches have made                pressing the “channel” button, but has different effects. These
substantial progress in explaining how causal structure can            examples suggest, contrary to the bottom-up hypothesis, that
be learned in this way (Cheng, 1997; Waldmann and Mar-                 causal structure is used to learn observable variables... but
tignon, 1998; Gopnik et al., 2004; Sloman, 2005; Griffiths             how could the causal structure have been learned before the
and Tenenbaum, 2005). However, all of these theories share             variables? Instead, we must assume in these cases that vari-
a common limitation: observable causal variables—the states            ables are learned along with causal structure, so that variables
of the world that causal relations relate—must be supplied             and structure may interact and constrain each other.
from the start. Thus, our toddler finds an obstacle to apply-             In this view, three layers of knowledge must be learned si-
ing any cognitive tools proposed by these theories: what is            multaneously (illustrated in Fig. 1): First, the number of vari-
“petting”? That is, what unifies all of the perceptually dif-          ables and the possible states of each (e.g. petting and purring,
ferent observed instances of petting, and separates them from          which each have two states—happening or not). Second, the
non-petting—and what makes petting a relevant causal vari-             causal structure amongst the variables (e.g. petting causes
able? To an infant many aspects of the world might appear              purring). Third, the observation function for each variable,
as a “blooming buzzing confusion,” or at least a largely un-           which provides perceptual grounding into the world of the
differentiated perceptual space. Yet that perceptual space is          senses: each is a map from perceptions to states of the vari-
soon carved into the separate concepts that become the build-          able. (Sounds with certain timbre and frequency, for example,
ing blocks of causal understanding—the observable variables.           might be instances of purring.) Together, the number of vari-
Where do observable variables come from? This question has             ables, their states and observation functions, and the causal
been raised in recent work on causal learning and cognitive            structure, constitute a grounded causal model.
development (e.g. Gopnik et al., 2004), but not addressed in              It is difficult to imagine how complete grounded causal
either formal models or behavioral experiments. We begin to            models could spring into being fully formed, Athena-like.
do both in the following pages.                                        Indeed, the great virtue of the bottom-up hypothesis is its
   It could be that causal variables are not learned at all, but       comprehensible stages: perceptual clustering processes first
rather we have an innate endowment of variables and must               form variables, then causal learning mechanisms take over
do the best we can with causal relations among them. How-              to discover causal structure1 . We will argue, however, that
ever, considering the abstract and conceptual nature of many           inference of complete models can be described, at the com-
variables, it seems likely that many are learned. If they are          putational level, in a Bayesian framework. Bayesian induc-
learned, perhaps the simplest hypothesis for variable forma-           tion has been used to describe the learning of causal structure
tion is bottom-up perceptual clustering: similar perceptions           (Griffiths and Tenenbaum, 2005), and it naturally adapts to
are grouped together by early perceptual processes and only            describe the joint learning of structure and grounding. In the
later become available for causal learning. Indeed, it is well         next section we build a model of learning by combining a
known that the perceptual system can perform sophisticated                 1 We mean in particular bottom-up processes that separate vari-
clustering (e.g. gestalt laws of grouping), so this bottom-up          able formation from causal knowledge, for instance as an informa-
hypothesis may be a good description of learning in many               tionally encapsulated module.
                                                                   305

simple dynamic Bayesian network model of causal structure              N variables, vi , with corresponding observation functions fi .
with a “consequential region” model (Shepard, 1987) of ob-             A causal structure C relates the sequence of states si,t = fi (wt )
servation functions. Because the number of variables is free           observed from a sequence of percepts wt ∈P . We assume
to vary, the model can learn as many, or as few, variables as          that causal relations hold only between cause variables at
are useful in explaining the perceptual evidence.                      one instant and effect variables at the next (that is, we as-
     After developing this model, we present a simple experi-          sume that causality is dynamic—causes precede effects—and
mental paradigm to explore grounded causal learning when               Markov—states only depend directly on states in the previous
neither the variables nor the causal structure are known in            instant). Thus the causal structure C is a graph on the vari-
advance. In this paradigm we describe three conditions, anal-          ables such that the direct parents of variable vi , indicated by
ogous to the petting/pounding example, which are indistin-             parC (vi ), are its causes. For simplicity we assume a simple
guishable to a bottom-up learner (see Fig. 1). We show that            nearly-deterministic-or parametrization: a state is active at a
people are able to successfully learn in this situation, and           given instant, si,t =1, if any parent v j ∈par(vi ) is active at the
clearly distinguish the three conditions. Further, we find that        previous instant, s j,t−1 =1, or with some small probability ε
model predictions correlate well with human responses.                 (and similarly for off). In addition, any state may be made
                                                                       active by an intervention: si,t =1 if Inti,t =1. Putting together
                            Modeling                                   this causal structure3 :
In this section we introduce a Bayesian model for learning                                           
                                                                                                      1      if Inti,t =1, or
grounded causal models, together with a specific example sit-
                                                                        P(si,t =1|st−1 ,C, Int) =      1+ε    ∃v j ∈parC (vi ) s.t. s j,t−1 =1,
uation that forms the basis for our experimental tests. The                                           ε
                                                                                                       1+ε    otherwise.
hypotheses of this model consist of three parts: the number
                                                                                                                                              (1)
of variables, observation functions for the variables, and a
causal structure over the variables. The observation functions            Next, the observation function fi of each variable deter-
provide the relationship between the variables and percep-             mines a consequential region f −1 (1), where the variable is
tion, while the causal structure provides the relationship be-         active, and its complement f −1 (0), where the variable is in-
tween the variables themselves. The machinery of Bayesian              active. There is a region of perceptual space compatible with
                                                                       any set of states st of the variables: Rst = i fi−1 (si,t ). We as-
                                                                                                                           T
probability gives a principled method to combine the sepa-
rate pieces and to draw joint inferences about those pieces,           sume that percepts of a given state are drawn uniformly from
balancing complexity against the ability to explain percep-            this region. Thus the likelihood of a particular percept wt ,
tual data. In the remainder of this section we describe each           conditioned on the observation functions f and states st , is:
piece of the model, then assemble the pieces into a likelihood
function describing the probability of a sequence of percepts;                                                δ f (wt )=st
                                                                                             P(wt |st , f ) =              .                  (2)
finally, Bayes’ rule is used to invert this dependency, giving                                                   |Rst |
the posterior probability of each grounded causal model.
     We start with a space of possible perceptual configura-           This likelihood leads to a size principle (Tenenbaum and Grif-
tions2 in any given instant, P . An observable variable                fiths, 2001): a percept is assigned higher probability when it
consists of a set of states, S, and an observation function,           falls in a smaller region R f (w) . Critically, this provides in-
 f : P → S, mapping each point in the perceptual space to a            ductive pressure to select variables that minimize the average
state of the variable. We will focus on the case of binary             size of the regions R f (wt ) —cutting regions of perceptual space
variables (i.e. S={0, 1}), in which the observation function is        which are frequently visited into finer pieces than those which
determined by a consequential region (Shepard, 1987)—the               are rare.
pre-image of the “active” state (i.e. f −1 (1)).                          For the example world described above, interventions
     Take a simple example world of small dots appearing on a          should be thought of as taps (or mouse-clicks) on the screen,
rectangular screen. For a screen with a single dot the percep-         which activate a “button” if they fall within it. We make one
tual space is given by screen coordinates: [0, 1]2 . If the num-       minor adjustment to Eq. 2 for this situation: if a variable is
ber of dots can vary, from none up to a maximum of M, the              made active by an intervention then there must be a dot at
perceptual space is: P = M               2m                            the site of the intervention, when this happens P(wt |st , f )=1.
                            S
                               m=0 [0, 1] . In this world a useful
set of observation functions is given by “buttons”: rectangu-          This has an interesting consequence: a variable which is made
lar regions that are active when there is a dot inside them. If        active only by interventions (e.g. a variable with no causal
r ⊆ [0, 1]2 is such a rectangle, and w=(w1 , ..., wk )∈P is a per-     parents) will exhibit no size principle effect. We return to this
cept, then theW“button” observation function corresponding to          prediction in the next section.
r is fr (w) = km=1 δwm ∈r (that is, 1 if and only if at least one         The full likelihood comes from Eqs. 1 and 2, by marginal-
of the k dots is in the rectangle).                                    izing over states, and recalling that each state is independent
     Returning to the general situation, say that we have a set of
                                                                           3 We will simplify subscripts of quantities like state s so that s
                                                                                                                                    i,t          t
     2 We leave open the question of what level of perception this     indicates the vector of states at time t, and s indicates all states at all
space represents, for instance egocentric or allocentric.              times.
                                                                   306

     Causal
                                                      Observation functions                                          Figure 1: Grounded causal
   Structure:
                                                                                                                     models: number of variables,
                                                                                                                     causal structure, and observa-
                                                                                                                     tion functions. Panels (a) and
   Perceptual
  Grounding:                                                                                                         (b) show models that cover
                                                      Consequential regions                                          the same regions of percep-
                                                                                                                     tual space, so could not be
                        Perceptual Space                                                                             distinguished by bottom-up
                                     (a)                                                    (b)                      clustering.
of others at the same instant:                                                      participants, were similar to the example used earlier: a num-
                                                                                    ber of invisible rectangular “buttons” served as variables (the
                                                     N
   P(wt |st−1 ,C, f , Int) = ∑ P(wt |st , f ) ∏ P(si,t |st−1 ,C, Int).              consequential region of each identical to its physical extent
                                  st                i=1                             on the screen). These buttons were related by a deterministic
                                                                            (3)     dynamic causal structure, in which a button was active if any
However, since Eq. 2 is zero for all but the “observed” state                       parent was active or if an intervention click was made within
sob
 i,t = f i (wt ), this simplifies to:                                               it. An active button created a dot within its (invisible) bound-
                                                                                    ary. (As above, a click inside a button always resulted in a dot
                                         1 N                                        at the site of the click.)
      P(wt |st−1ob
                    ,C, f , Int) =                P(sob     ob
                                                      i,t |st−1 ,C, Int).   (4)
                                      |Rsob | ∏
                                              i=1                                       We wished to create an experimental situation, simi-
                                          t
                                                                                    lar to the petting/pounding example discussed in the intro-
For a sequence of perceptions w with observed states stob (we                       duction, in which two variables had very similar percep-
assume that all initial states sob       i,-1 =0):                                  tual properties—so would be indistinguishable by bottom-up
                                                                                    grouping—but different causal properties. Because the con-
                                        T
                                                   ob                               sequential regions of the buttons are rectangular, a set of dots
               P(w| f ,C, Int) = ∏ P(wt |st−1           ,C, f , Int).       (5)
                                       t=0                                          occurring within a single large button occupies the same per-
                                                                                    ceptual space as dots appearing at random in two small but-
By Bayes rule, the posterior probability of a grounded causal                       tons that subdivide the large one (see Fig. 1). Thus the three
model f ,C is:                                                                      structures illustrated at the left of Fig. 2, which occupy the
                                                                                    same regions of perceptual space, should be indistinguishable
                 P( f ,C|w, Int) ∝ P( f ,C)P(w| f ,C, Int).                 (6)     to a purely bottom-up learner. To put it another way, if one
                                                                                    simply clusters the dots appearing within these regions there
For simplicity, and in order to focus on intrinsic aspects of                       is no reason to split adjacent rectangles into separate clusters.
the model, we use a uniform prior on number of variables,                           However, without splitting the adjacent rectangles it is impos-
causal structure, and observation functions: P( f ,C)∝1. (The                       sible to correctly learn causal structures a or b. (Of course a
uniform prior on number of variables is not proper, but is reg-                     clustering algorithm that takes advantage of causal informa-
ularized by the likelihood.) To account for memory limita-                          tion could distinguish these conditions—the Bayesian model
tions on the sequence of percepts, and possible discounting                         described above can be seen as such an algorithm.)
of earlier information, we include a power-law decay in the
likelihood term (T is the last time):                                                   Thus we had three experimental conditions: one for each
                                                                                    structure/condition shown in the left of Fig. 2. With this de-
                                   T
                                                                        −γ          sign we wished to test two main hypotheses: First, people
            P( f ,C|w, Int) ∝ ∏ P(wt |st−1 ,C, f , Int)(T −t)               (7)     can learn grounded causal models—learning structure and
                                 t=0
                                                                                    grounding at the same time, and distinguishing conditions im-
                                Experiment                                          possible for a bottom-up learner. Second, the structure and
                                                                                    geometry of the models people infer are consistent with pre-
To investigate human abilities to learn grounded causal mod-                        dictions of the Bayesian model.
els when neither the variables nor the causal structure are
known in advance, we adopted the simple perceptual space
described above. Participants interacted, by clicking freely,                       Method
with a blank rectangular window on a computer screen, which
they were told was an “alien panel”. In response to these in-
terventions a sequence of one or more dots would sometimes                          Participants Participants were 17 members of the MIT
bloom and then disappear at various locations on the window.                        community. Two participants failed to understand the instruc-
The laws underlying the dots’ appearance, unknown to the                            tions, and were excluded from further analyses.
                                                                                307

                                        (i)                                 (ii)                                  (iii)
     structure a:
                                                       1                                     1                                     1
     structure b:
                                                       0.5                                   0.5                                   0.5
                                                       0                                     0                                     0
                                               a b  c                                a b  c                                a b  c
                                       (iv)                                 (v)                                   (vi)
     structure c:
                                                       1                                     1                                     1
                                                       0.5                                   0.5                                   0.5
                                                       0                                     0                                     0
                                               a b  c                                a b  c                                a b  c
Figure 2: Experimental conditions (structures a, b, and c), and examples of individual participants’ observations and responses
(i–vi). Participants’ interventions are marked by crosses, and resulting dots are marked by dots. Participants’ responses are in
solid red lines, and the actual structures (not seen by participants) are in dashed blue. Inset in each example is the evidence-
specific posterior probability of the model. (i–iii) are correct responses, (iv–vi) are incorrect, as predicted by the model.
Materials and Procedure All interactions, responses, and              physical orientation of the panels was randomized.
instructions were presented on a computer screen4 . Partici-
                                                                      Model approximation and fitting Continuous coordinates
pants first read a brief cover story: “Scientists have discov-
                                                                      were approximated on a fine grid (equal to the pixel width
ered alien artifacts that look like blank panels, but respond in
                                                                      of the screen). Posterior probabilities were evaluated by enu-
interesting ways when clicked upon.” Participants were then
                                                                      merating over a large subset of hypotheses, including the ac-
given a brief familiarization with the “alien panel” screen,
                                                                      tual structures and reasonable alternatives that varied in num-
and with the drawing tool. The alien panel was blank, except
                                                                      ber of variables and causal structure. (Hence the ratios of pos-
for light grey grid lines, and responded to clicks, as described
                                                                      terior probability values reported are exact, while the absolute
above, with sequences of blue dots. The drawing tool looked
                                                                      magnitudes are approximate.) The two free parameters of the
similar, but also had a tool pallet that enabled participants to
                                                                      model, capturing causal transmission noise and “forgetting”
draw rectangles and arrows. During familiarization partic-
                                                                      rate, were adjusted by hand to ε=0.3, γ=0.5.
ipants were told that “scientists have determined that these
panels have ‘active regions’,” and were shown two active re-          Results
gions made visible “by a special process.”
                                                                      We investigate the causal structure and geometry of partici-
   There were three “brand new alien panels,” one for each
                                                                      pants’ responses. Before turning to statistical analyses, let us
of the conditions described above (see Fig. 2, left). Partici-
                                                                      consider a few example responses. In Fig. 2(i-iii) we see the
pants interacted with each alien panel for five blocks of ap-
                                                                      responses of three participants, one in each condition, who
proximately 30 clicks each. Each block was followed by
                                                                      correctly identified the underlying causal structure. The rect-
a chance to “describe what’s going on” by using the draw-
                                                                      angular “active regions” are often drawn by participants off-
ing tool. Thus each participant made fifteen responses (three
                                                                      set or slightly mis-sized relative to their actual locations. This
conditions, five blocks), each of which was a diagram freely
                                                                      may be due in part to the difficulty of remembering over the
drawn using rectangles and arrows (see Fig. 2, right, for ex-
                                                                      course of the experiment the precise location of interventions
amples of participants’ responses). The order of the three
                                                                      and dots. Participants also often separated adjacent variables
conditions was counter-balanced across participants, and the
                                                                      in conditions A and B, as in Fig. 2(i)—this is suggestive
   4 An online demonstration of the experiment can be found at:       of overregularization due to categorical perception, though
http://www.mit.edu/˜ndg/LGCMdemo.html                                 could also be due to pragmatic issues with the drawing tool.
                                                                  308

   Many “errors” made by participants are, in fact, rational re-     posterior probability of the actual structure is significantly
sponses to available evidence, and predicted by the Bayesian         lower for incorrect trials than correct trials (one-tailed Mann-
model. For instance, errors in early blocks are often failures       Whitney U test, U=2877, N=225, p<0.0001). This suggests
to discover all of the active regions—that is, they are the re-      that the evidence-specific posterior is a good predictor of hu-
sult of insufficiently broad interventions, see Fig. 2(iv). Oc-      man errors—and thus that many of these errors are actually
casionally, though all regions have been explored, the evi-          rational responses to the available evidence.
dence generated still favors the wrong hypothesis (according            Turning to the geometry of the “active regions”—that is, to
to the model), leading people to a “rational error”. For in-         inferences about properties of the observation functions—we
stance, in Fig. 2(v) we see a participant in condition A who         consider the proximity of causes and effects and their relative
has drawn structure c—which is also favored by the model             sizes. In structure a, the ‘effect’ variables were spatially ad-
(inset). Of course not all errors made by participants are eas-      jacent while the ‘cause’ variables were separated; vice versa
ily explained—Fig. 2(vi).                                            in structure b. Participants correctly inferred this aspect of
   To enable group analyses, each response was coded as              the geometry: in structure a responses the ‘cause’ variables
structure a, b, c, or “other” by two coders who were blind           were drawn by participants significantly closer together than
to condition and block. (Responses were coded in random              the ‘effect’ variables (t(56)=5.58, p<0.0001), and in struc-
order to preclude influence of other responses of the same           ture b responses the ‘effects’ were significantly closer than
participant). Coders were instructed to code a response as a,        the ‘causes’ (t(58)=9.38, p<0.0001).
b, or c only if it had the correct number of variables, in ap-          Recall that, because ‘cause’ variables can only be activated
proximately the correct locations, and correct causal arrows.        by interventions and an intervention created a dot exactly at
There was 96% agreement between the two coders; differ-              the location of the click, only the ‘effect’ variables should
ences were resolved by discussion. The portion of partici-           be subject to a size principle under the model. For the ‘ef-
pants responding with each structure, for each condition and         fect’ variables the size principle implies that hypotheses with
block, are shown in Fig. 3 (black bars). By the final block the      smaller active regions will have higher probability. Hence,
modal human response in each condition was correct—that              the model predicts the areas for ‘cause’ variables to be larger,
is, the modal response was the actual structure for that con-        on average, than those for ‘effect’ variables. This prediction
dition. Thus participants were able to learn each grounded           was validated for both structure a responses (t(114)=3.57,
causal model, given sufficient interaction time. Moreover,           p<0.001) and structure b responses (t(118)=2.88, p<0.005).
participants strongly distinguished the three conditions, pro-
viding significantly different response patterns between the                       Discussion and Conclusion
conditions (χ2 (6)=133.5, p<0.001, aggregating responses
                                                                     Where do observable variables come from? We have sug-
across blocks). Since these conditions are indistinguishable
                                                                     gested that observable causal variables are learned along with
to a bottom-up learner, this result makes it quite unlikely that
                                                                     the causal structure that relates them, with causal structure in-
human learning of grounded causal models is purely bottom-
                                                                     fluencing the discovery of variables and variables grounding
up.
                                                                     the causal structure in perception. We developed a Bayesian
   We next want to explore whether the structure and geome-          model to describe the inference of grounded causal models
try of participants’ responses are consistent with the Bayesian      by combining simple Bayesian networks for causal structure
model. Since participants generated their own interventions,         with consequential region observation functions. A simple
each observed unique evidence; it is thus necessary to ap-           example of this model led to a novel experimental paradigm
ply the model separately to the evidence available to each           for the learning of grounded causal models—an aspect of
participant at the time of each response. The inset plots of         causal learning that has not been previously investigated. In
Fig. 2 show these evidence-specific model posterior probabil-        a behavioral test using this paradigm humans were able to
ities. The mean posterior probabilities for each condition and       correctly learn grounded causal models, and to distinguish
block, averaged across evidence-specific results for individ-        conditions that should be indistinguishable to a bottom-up,
ual participants, are shown in Fig. 3 (white bars). Comparing        clusters-then-causes, learner. Further, the model was shown
the human response rates (black bars) to the model predic-           to be a good predictor of the structures and geometry found
tions reveals quite good qualitative agreement. Notice, for          by human participants, predicting errors on both the group
instance, that the model correctly predicts that condition A         and individual level.
is harder than conditions B or C, and that in condition A a             However, our experimental results are only a preliminary
significant minority of responses are structure c. The quan-         test of the model. Further investigation will be needed to
titative fit is also good: correlation r=0.95, and mean devia-       evaluate whether learned variables are truly coherent abstract
tion 0.04.                                                           concepts, and to explore the subtle trade-offs between causal
   To see whether errors on individual responses were                structure and observation functions. The model can also be
predicted by the model we investigated evidence-specific             refined in several important ways. First, our simple model
model posterior probabilities for correct responses (those that      of causal structure should be extended to include inhibitory,
matched the actual structure) and incorrect responses. The           interactive, and noisy causal relationships. Second, the set
                                                                 309

                                      Block 1           Block 2           Block 3                    Block 4           Block 5
                             1
              Condition A
                            0.5
                             0
                             1
                                                                                                                                     Figure 3: Black bars: the
              Condition B
                            0.5
                                                                                                                                     portion of human responses
                                                                                                                                     consistent with each struc-
                             0
                                                                                                                                     ture (a, b, and c; shown at
                             1                                                                                                       left), for each condition
              Condition C
                                                                                                                                     and block. White bars:
                            0.5
                                                                                                                                     mean model posterior
                                                                                                                                     probabilities. Correlation
                             0
                                  a     b       c   a     b       c   a     b       c            a     b       c   a     b       c   between the two is r=0.95.
of observation functions we used, while well suited to the                                    chology, notably in work on feature formation (Schyns et al.,
experimental situation, is too simple for many real-world set-                                1998). On the other hand, a great deal of the meaning of a
tings. It may be possible to adapt existing models of per-                                    concept could come from its conceptual role: the internal re-
ceptual discrimination, such as fragment-based recognition                                    lationships it has with other concepts. The theory-theory, es-
(Ullman et al., 2001), to provide flexible observation func-                                  pecially in its causal models incarnation (Gopnik et al., 2004),
tions. Third, intervention was treated casually; abstract in-                                 has influentially developed this component of concept mean-
terventions should be grounded in physical actions, and this                                  ing. By considering grounded causal models we have begun
grounding must also be learned. Beyond simple refinements                                     to explore a notion of concepts in which meaning comes from
of this model a more precise and detailed model will even-                                    both sources: the observation conditions for concepts, and the
tually be needed: we’ve only begun to scratch the surface of                                  causal relations between them. By describing how grounded
what could be modeled in this domain—leaving open, for in-                                    causal models can be learned from perception we have, per-
stance, the process and time course of learning, and the gen-                                 haps, started to unravel how human minds come to have such
eration of exploratory interventions.                                                         rich, meaningful, concepts.
   We have recently proposed a model for learning causal                                                                  References
types (Kemp et al., 2007), an important kind of abstract causal                               Cheng, P. (1997). From covariation to causation: A causal power
knowledge. (This model was applied it to data from the ex-                                       theory. Psychological Review, 104:367–405.
periment of Lien and Cheng (2000) in which unknown causal                                     Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E., Kushnir, T.,
structure interacted with unknown causal types—intriguingly                                      and Danks, D. (2004). A theory of causal learning in children:
                                                                                                 causal maps and Bayes nets. Psychological Review, 111(1):3–32.
similar to the way that grounding and structure interacted in
                                                                                              Griffiths, T. L. and Tenenbaum, J. B. (2005). Structure and strength
our experiment.) It is worth noting that the model of Kemp                                       in causal induction. Cognitive Psychology, 51:285–386.
et al. (2007) and the one proposed in this paper can be com-                                  Kemp, C., Goodman, N. D., and Tenenbaum, J. B. (2007). Learn-
bined to provide a computational model of causal learning                                        ing causal schemata. In Proceedings of the Twenty-ninth Annual
that spans from perceptual grounding to abstract knowledge.                                      Meeting of the Cognitive Science Society.
                                                                                              Lien, Y. and Cheng, P. W. (2000). Distinguishing genuine from
Such a combination is especially interesting because it sug-                                     spurious causes: a coherence hypothesis. Cognitive Psychology,
gests a novel kind of abstract causal knowledge: framework-                                      40(2):87–137.
level prior beliefs about observation functions for new vari-                                 Schyns, P. G., Goldstone, R. L., and Thibaut, J.-P. (1998). The de-
ables. For instance, adults use prior knowledge to quickly                                       velopment of features in object concepts (with commentary). Be-
                                                                                                 havioral and Brain Sciences, 21:1–54.
infer that a new doorbell-shaped-patch next to a door, even                                   Shepard, R. N. (1987). Towards a universal law of generalization for
one never before seen, is likely to be a causal variable. Prior                                  psychological science. Science, 237:1317–1323.
knowledge about observation functions is likely at work in                                    Sloman, S. (2005). Causal models: How people think about the
many adult inferences of new causal variables.                                                   world and its alternatives. Oxford University Press, Oxford.
                                                                                              Tenenbaum, J. B. and Griffiths, T. L. (2001). Generalization, sim-
   The ideas of this paper fit in a broader theme in cognitive                                   ilarity, and Bayesian inference. Behavioral and Brain Sciences,
science and philosophy. In order for concepts to be useful                                       24:629–641.
they must have a semantic grounding: a manner of connecting                                   Ullman, S., Sali, E., and Vidal-Naquet, M. (2001). A fragment-
                                                                                                 based approach to object representation and classification. In
an internal representation of the concept to the external world.                                 IWVF-4: Proceedings of the 4th International Workshop on Vi-
An influential theory of semantic grounding holds that the                                       sual Form.
meaning of a concept is its observation conditions (ie. states                                Waldmann, M. R. and Martignon, L. (1998). A Bayesian network
of the world in which it is true). The semantic grounding                                        model of causal learning. In Proceedings of the Twentieth Annual
                                                                                                 Conference of the Cognitive Science Society.
of concepts has been addressed a number of times in psy-
                                                                                        310

