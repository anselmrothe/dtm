UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Bayesian Robot That Distinguishes "Self" from "Other"
Permalink
https://escholarship.org/uc/item/5z03g2b6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Gold, Kevin
Scassellati, Brian
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            A Bayesian Robot That Distinguishes “Self” from “Other”
             Kevin Gold (kevin.gold@yale.edu) and Brian Scassellati (scaz@cs.yale.edu)
                                      Department of Computer Science, Yale University
                                                  New Haven, CT 06511 USA
                            Abstract
   A Bayesian kinesthetic-visual matching model allows a
   humanoid robot to perform mirror self-recognition with-
   out social understanding. The robot learns the rela-
   tionship between its own motor activity and perceived
   motion by observing the movements of its arm for four
   minutes. Over this time, it builds a simple dynamic
   Bayesian model that relates these two events, and uses
   this self model to build a model of “animate others”
   that is a copy of its self model but with the motor state
   hidden. Presented with a mirror, the robot then judges
   its mirror image to match its “self” model, while people
   are judged to be “animate others.”
   Keywords:       Self-recognition; robot;     mirror test;
   Bayesian; animacy; contingency.
                                                                  Figure 1: Nico is an upper-torso humanoid robot with
                       Introduction                               the arm and head kinematics of a one-year-old.
There are two kinds of theories that seek to explain how
2-year-old human infants, higher primates, and other in-
telligent animals discover that their mirror images are              The ability to recognize oneself in the mirror appears
their own reflections. The first kind of theory proposes          in human infants within a few months of some other criti-
that mirror self-recognition requires social understand-          cal social abilities, such the development of sympathy at
ing, as the learner must have some idea of how it ap-             others’ distress (Zahn-Waxler, Radke-Yarrow, Wagner,
pears to others (G. Gallup, 1982). The second kind of             & Chapman, 1992). The emergence of this ability at
theory proposes that mirror self-recognition comes from           about the same time in human infants has been inter-
matching kinesthetic experience to visual feedback, and           preted by some to be more than a coincidence, suggest-
that therefore no social knowledge is necessary for self-         ing that “theory of mind” skills are necessary for mirror
recognition (Mitchell, 1997). The present study is meant          self-recognition (G. Gallup, 1982; Plotnik et al., 2006).
to add some concreteness to the latter hypothesis of              However, it is difficult to determine from phylogenetic
kinesthetic-visual matching, and show that it is com-             and developmental observations alone whether this link
putationally feasible and robust to identify one’s mirror         is more than coincidental.
image using only a Bayesian self-model that relates mo-              The present work demonstrates that it is possible to
tor activity to motion.                                           perform robust self-recognition on the basis of match-
   The “mirror test” of G. G. Gallup (1970) is typical of         ing kinesthetic experience to visual motion alone. The
tests for mirror self-recognition. In the original test, a        method consists of the robot comparing three models
chimpanzee was given ten days to acclimate itself to a            for each object in its visual field. The first model is
mirror in its cage. A spot of red dye was then applied            that of random noise, generated with no structure over
to a chimpanzee’s eyebrow and ear while it was uncon-             time. The second model consists of an observed inter-
scious. On seeing its reflection in the mirror, the chim-         nal state of motor activity that generates the external
panzee would use its mirror reflection to reach for the           feedback of motion; thus, the consistency of the match
marks on its own head. Similar tests have found mir-              between motor activity and motion dictates the likeli-
ror self-recognition in humans at 2 years (Amsterdam,             hood of this model. The third model is that of motion
1972), orangutans (Suarez & Gallup, 1981), elephants              generated by somebody else; it is identical to its own self-
(Plotnik, Waal, & Reiss, 2006), and dolphins (Reiss &             motion model, only the motor state is hidden and must
Marino, 2001), while macaques, gorillas, and lesser pri-          be reasoned about probabilistically. The likelihood of
mates appear to be unable to self-recognize (G. Gallup,           each model is updated with every new observation, such
1982).                                                            that the robot always has a best guess as to whether
                                                             1037

                                                                 Figure 3: The robot’s self model, in graphical model
                                                                 notation. Darkened circles represent observations, and
                                                                 arrows represent conditional dependence relations.
Figure 2: Output from the self/other algorithm while
the robot views the experimenter and the robot’s mirror          Bayesian networks allows the robot to calculate at each
image. The algorithm classifies objects found through            time t the likelihoods λνt , λσt , and λω
                                                                                                         t , corresponding to
                                                                the likelihoods of the evidence given the noise model, the
background subtraction as “self” (white, bottom), “ani-
                                                                self model, and the “animate other” model, respectively.
mate other” (light gray, left), or “inanimate” (dark gray,
                                                                Normalizing these likelihoods then gives the probability
upper right) in real time.                                      that each model is correct, given the evidence. We shall
                                                                first discuss how the models calculate their probabilities
                                                                under fixed parameters, then explain how the parame-
an object in its visual field is itself, someone else, or an    ters themselves are adjusted in real-time.
inanimate object.                                                   The “inanimate” model is the simplest, as we assume
   Using techniques from Bayesian reasoning, these mod-         inanimate objects only appear to have motion due to
els can be computed in real-time, requiring only a few          sensor noise or when they are dropped. If we character-
calculations between observations. In the case of the           ize the occurrence of either of these events as the event r,
self-model and the noise model, the models can even per-        then this model is characterized by a single parameter:
form unsupervised learning in real-time with no iteration       the probability P (r) that random motion is detected at
over the robot’s observation history. Finally, the “Ani-        an arbitrary time t. Observations of this kind of motion
mate Other” model, for motion generated by other peo-           over time are assumed to be independent, such that the
ple in the vicinity, presents an interesting case because       overall likelihood λνt can be calculated by simply multi-
the robot can use its own self-model as an approxima-           plying the likelihoods at each time step of the observed
tion, thus allowing the whole learning process to occur         motion.
online in real-time.
                                                                    The robot’s second model for an object is the “self”
   The robot learns a basic self-model by observing its         model, in which the motor actions of the robot gener-
own actions. Presented with a mirror, the robot can             ate the object’s observed motion. The model is char-
then use its learned self-model to determine the likeli-        acterized by two probabilities: the conditional probabil-
hood that the motion of its mirror image is its own mo-         ity P (m|φ) of observing motion given that the robot’s
tion. After a few movements, the probability that the           motors are moving, and the conditional probability
mirror arm is “self” goes to nearly 1, while the other          P (m|¬φ) of observing motion given that the robot’s mo-
probabilities become insignificant.                             tors are not moving. (Henceforth, m and ¬m shall be
   Note that while our research group has previously             the observations of motion or not for motion event M ,
published a different method for motion-based self-              and φ and ¬φ shall serve similarly for motor event Φ.
recognition (Gold & Scassellati, 2006), the Bayesian             Note that these probabilities need not sum to 1.)
models described below are new to this paper, and are
                                                                    Figure 3 represents the robot’s “self” model graphi-
considerably less susceptible to error when a human
                                                                 cally, using standard graphical model conventions. Each
moves at the same time as the robot. Another group has
                                                                 circle corresponds to an observation of either the robot’s
published work on learning a slightly more complex for-
                                                                 own motor action (top circles) or the observed motion of
ward model than the one described here using Bayesian
                                                                 the object in question (bottom circles), with time t in-
methods (Dearden & Demiris, 2005), but that group did
                                                                 creasing from left to right. The circles are all shaded to
not adapt the method to the problem of judging whether
                                                                 indicate that these event outcomes are all known to the
an entity was the self or not.
                                                                 robot. The arrows depict conditional dependence; infor-
                                                                 mally, this corresponds to a notion of causality. Thus,
  Mathematical Background and Models                             the robot’s motor action at time t causes the perception
Our method compares three models for every object                of motion at time t. Though an observer would know
in the robot’s visual field to determine whether it is           that the robot’s motor activity at time t + 1 can be pre-
the robot itself, someone else, or neither. The use of           dicted from its activity at time t, the robot does not
                                                            1038

“know” this in its model; it calculates only the likeli-
hood of the motion evidence given the motor evidence,
and not the likelihood of the motor evidence itself.
   To determine the likelihood of this model for a given
object, the robot must calculate the probability that its
sequence of motor actions would generate the observed
motion for the object. The relevant calculation at each
time step is the probability P (Mt |Φt ) of motor event Φt
generating motion observation Mt . These probabilities
calculated at each time step can then be simply mul-
tiplied together to get the overall likelihood of the evi-
dence, because the motion observations are conditionally        Figure 4: The model for an “animate other,” in graphical
independent given the robot’s motor actions.                    model notation. The model the robot uses is a copy of its
   The likelihood λσt that the motion evidence up to time       self model, but with the motor information unobserved
t was generated by the robot’s own motors is then:
                                                                and inferred (unshaded circles).
                            Y
                      λσt =      P (Mt |Φt )            (1)
                             t                                  online in a constant amount of time at each time step us-
where, in our simple Boolean implementation,                    ing the forward algorithm (Rabiner, 1989). The forward
                                                                algorithm can be described by the following equation for
                                                                calculating the new likelihood λω   t+1 given an observation
                                                                                                                    −−−→
                 
                    P (mt |φt )        if mt and φt           of motion Mt+1 and motor state probabilities P (Φ):
                     1 − P (mt |φt )    if ¬mt and φt
                 
  P (Mt |Φt ) =                                         (2)
                  P (mt |¬φt )         if mt and ¬φt                      X                     X
                                                                  λωt+1 =      P (Mt+1 |Φt+1 )       P (Φt+1 |Φt )P (Φt ) (4)
                     1 − P (mt |¬φt )   if ¬mt and ¬φt
                 
                                                                           Φt+1                   Φt
   Under this model, updating the likelihood at time t+1           Notice that this equation necessarily entails calculat-
is simply a matter of multiplying by the correct value of      ing probabilities for the entity’s hidden state as a sub-
P (Mt+1 |Φt+1 ):                                               routine. In our simple implementation, this only decides
                                                               whether the agent is engaging in motor activity or not.
                  λσt+1 = P (Mt+1 |Φt+1 )λσt            (3)    But, as with the self model, equation 4 and figure 4 are
                                                               more general than the simple boolean model we are using
   Note that equation 1 and the graphical model pre-           here. A more complex model relating the entity’s motor
sented in Figure 3 are much more general than the sim-         states to its motion would allow action recognition as a
ple Boolean model implementing them that is described          pleasant side effect of the likelihood calculation.
by equation 2. For more advanced models, Mt could                  The forward algorithm requires prior probabilities on
be a complete reading of joint angles, Φt could describe       the possible motor states to propagate forward. Since
a trajectory through space, and P (Mt |Φt ) could be an        the robot has no particular information about the state
arbitrary distribution on motion trajectories given the        of the “other” at time 0, it arbitrarily sets these to 0.5.
motor readings. The current implementation, however,           However, both the “self” and “other” models are more
chooses simplicity over expressive power.                      complex and more rare than the assumption of noise,
   The third and final model is that of another person (or     so the final likelihoods are weighted by the priors of
other animate agent) in the visual field. This model is        P (inanimate) = 0.8, P (self) = 0.1, P (other) = 0.1. As
identical to the self model, but now the motor states are      constants, these priors do not matter much in the long
hidden to the robot, leaving it to infer the other person’s    run, but they can reduce false classifications when first
motor states. Removing the motor information turns             encountering an object.
the model into a Hidden Markov Model (HMM). The                    The other parameters to the model, the conditional
Bayesian network in Figure 4 represents this by leaving        probabilities, do matter in the long term; luckily, they
the motor event nodes unshaded, indicating that they           can be learned online rather than set arbitrarily. For the
have not been directly observed. To assess the likelihood      “inanimate” and “self” models, the robot does this by
that motion was generated by another animate agent,            counting its observations of each event type ({m, ¬m} ×
the robot must now infer the underlying motor states           {φ, ¬φ}) and weighting each observation by the prob-
that generated the motion. Performing this calculation         ability that the object truly belongs to the model for
requires two transition probabilities, P (φt+1 |¬φt ) and      which the parameters are being calculated. Thus:
P (¬φt+1 |φt ), corresponding to the probabilities that the
person begins motor activity from rest or ceases its motor
                                                                                         P
                                                                                           it Pit (noise)Mit
activity, respectively.                                                         P (r) = P                                  (5)
                                                                                              it Pit (noise)
   To find the likelihood that an object is an animate                                    P
other, the robot must keep track of the probabilities of                                     it Pit (self)Mit Φt
each motor state at each time step. This can be updated                       P (m|φ) = P                                  (6)
                                                                                                it Pit (self)Φt
                                                           1039

                        P
                           it Pit (self)Mit (1 − Φt )           form of optical encoder readings indicated to the robot
           P (m|¬φ) =                                    (7)
                                                                whether each motor had stopped moving.
                          P
                              it Pit (self)(1 − Φt )
                                                                    For vision, Nico used 320 × 240 images pulled from the
where Pit (noise) is the robot’s best estimate at time t of     wide-angle CCD camera in Nico’s right eye at roughly 30
the probability that object i is noise, and Mit is 0 or 1       frames per second. Images from Nico’s camera were then
depending on whether object i is moving. This strategy          passed through a background subtraction filter, leaving
is a kind of expectation maximization, because it alter-        only objects that had moved since the experiment be-
nates between fitting a model to data and classifying the       gan and scattered noise. Connected regions that did not
data with a model. Normally, expectation maximization           exceed 100 pixels (roughly 0.1% of the image) were dis-
requires iterating over all previous observations in up-        carded as noise.
dating the model, but this model is simple enough that              Objects were tracked over time by matching each re-
the robot can update it in real time without going back         gion Ri in frame F with the region in frame F − 1 that
to revise its previous probability estimates, without too        shared the largest number of pixels with Ri . If more
much loss of accuracy.                                           than one connected region in the same frame attempted
   Since this method is iterative, the robot must begin          to claim the same object identity, as frequently happened
with some estimate of each of the probabilities. The             when joined regions separated, a new identity was gener-
robot begins with a guess for each parameter as well as          ated for the smaller region.
a small number of “virtual” observations to support that                                      √ An object with area A was
                                                                 judged to be moving if 4 A of its pixels had changed
guess. These guesses function as priors on the parame-
                                                                 their region label from one frame to the next. This for-
ters, as opposed to the priors on classifications described
                                                                 mula was chosen to be roughly proportional to the length
earlier. The choice of priors here does not matter much,
                                                                 of the object’s perimeter, while taking into account that
since the system can adapt to even bad priors (see “Ex-
                                                                 background subtraction tended to produce “fuzzy” bor-
periments,” below). Any prior will smooth the model’s
                                                                 ders that are constantly changing.
development of the correct parameters, by reducing its
                                                                    The final output of vision processing was an image
reliance on its first few observations.
                                                                 of labeled regions that could be tracked over time and
   Using the expectation maximization strategy on the
                                                                 judged at each time step to be moving or not moving.
“animate other” model would not work quite as well,
                                                                 This output was made available at a rate of roughly 9
because it contains unobserved states. Technically, to
                                                                 frames per second. For each segmented region, the prob-
perform expectation maximization on a Hidden Markov
                                                                 abilities of the three models described above were cal-
Model requires the forward-backward algorithm (Baum
                                                                 culated and updated in real time using the algorithms
& Petrie, 1966) to obtain a posteriori estimates of the
                                                                 described earlier. Figure 2 shows output typical of the
hidden states, which would require iterating over all the
                                                                 self-other algorithm after learning, with image regions
data repeatedly as the robot gained more data. How-
                                                                 grayscale-coded by maximum likelihood classification.
ever, we can finesse this problem, reduce the size of the
                                                                 Note that because the background subtraction algorithm
hypothesis space, and prove an interesting point about
                                                                 blinds the robot to objects that have not moved since the
self-models all at the same time if the robot uses its own
                                                                 start of the experiment, the robot cannot actually clas-
self model to generate the “animate other” model. The
                                                                 sify its body, but only its arm. A segmentation algorithm
probabilities P (m|φ) and P (m|¬φ) are set to exactly the
                                                                 based on depth would join the arm to the full body and
same values as the self model; this is equivalent to the
                                                                 classify the whole assembly based on the movement of
assumption that the robot has about the same chance of
                                                                 the arm, but this was not implemented.
perceiving motion if either itself or someone else is actu-
ally moving. The transitional probabilities P (φt+1 |¬φt )
and P (¬φt+1 |φt ) are based on the robot’s own motor ac-
                                                                                      Experiments
tivity by counting its own action transitions of each type.      Methodology
Though the human’s motions are likely to be quite dif-           The robot was given 4 minutes to observe the move-
ferent from those of the robot in their particulars, the         ments of its own arm, starting with P (r), P (m|φ), and
general fact that “objects in motion tend to stay in mo-         P (m|¬φ) all set to the implausible value of 0.5. These
tion” is true of both, and the real discrimination between      starting values were given the weight of 30 observations,
the two hinges on the contingency with the robot’s own          or roughly 3 seconds of data. The robot made its obser-
motor actions, and not the particular transition proba-         vations in the absence of a mirror and without any ex-
bilities of the “animate other” model.                          plicit feedback. Distractors from the arm included both
                                                                inanimate objects (light fixtures that background sub-
             Robotic Implementation                             traction had failed to remove) and animate others (stu-
The experiments described below were performed on               dents passing in the hall adjacent to the lab). To auto-
Nico, a small humanoid robot built to match the pro-            matically collect data on the robot’s hypotheses about
portions and kinematics of a one-year-old child (Figure         its arm without hand-labeling each frame, the probabil-
1). Nico possesses an arm with 6 degrees of freedom, cor-       ities generated for the largest object within its field of
responding to the degrees of freedom of a human arm up          view were recorded as data; this object was the arm in
to the wrist. The arm made sweeping gestures roughly 1          most instances.
second in length to a randomly chosen position roughly              The robot’s parameters were then frozen at the four
every five seconds. Feedback from the motors in the             minute mark for testing, to ensure the robot’s perfor-
                                                            1040

           Development of Model Parameters Over Time                       Classification of Robot's Mirror Image, Test Phase
                                                                     1
       1
              P(motion|motor)                                      0.9
     0.9
              P(motion|~motor)                                     0.8
     0.8
              P(r)                                                 0.7
     0.7
     0.6                                                           0.6                                                P(self)
     0.5                                                           0.5                                                P(animate other)
     0.4                                                           0.4                                                P(inanimate)
     0.3                                                           0.3
     0.2                                                           0.2
     0.1                                                           0.1
       0
                                                                     0
         0  20     40  60   80 100  120 140 160 180 200 220            0       5          10        15         20          25
                                 Time (s)                                                       Time (s)
Figure 5: Average model parameters over four minutes             Figure 6: Robot’s judgements of its mirror image after
of unsupervised learning on the robot’s visual and motor         4 minutes of observing its own unreflected movements,
feedback, with 95% confidence intervals.                         with 95% confidence intervals.
                                                                               Classification of Human, Test Phase
mance was based solely on its observations of its own
unreflected arm. Using the parameters it learned during                1
                                                                     0.9
the previous four minutes, the robot then was presented
                                                                     0.8
with a mirror, and the robot continued its random move-
                                                                     0.7
ments in front of the mirror. The robot’s hypotheses for
                                                                     0.6
the largest object within the area covered by the mir-               0.5
                                                                                                                   P(animate other)
                                                                                                                   P(inanimate)
ror were recorded automatically, to avoid the chore of               0.4                                           P(self)
hand-labeling frames.                                                0.3
   Using the same parameters, the robot then judged one              0.2
of the authors (K.G.) for two minutes. Again, the robot’s            0.1
hypotheses for the largest object located within the area              0
of interest were recorded automatically. The author’s                    0       5         10        15        20          25
                                                                                                 Time (s)
actions varied from near inactivity (sitting and checking
his watch) to infrequent motion (drinking bottled water)
to constant motion (juggling), while the robot continued         Figure 7: Robot’s judgments of the experimenter after
to make periodic movements every 5 seconds. The ex-              4 minutes of observing its own unreflected movements,
perimenter was blind to the robot’s classifications during       with 95% confidence intervals.
this time.
   These experiments were repeated 20 times, to verify
the robustness of both the learning mechanism and the            arm passed out of the field of view or was incorrectly
classification schemes that it generated. Each learning          segmented many times, only to have the “new” object
trial reset all model probabilities to 0.5, and each test        quickly reclassified correctly from scratch.
trial used the parameters generated in the corresponding            When confronted with a mirror after the learning
learning trial.                                                  phase, the robot consistently judged the mirror image to
                                                                 be “self” after a single complete motion of its arm, and
Results                                                          remained confident in that estimate over time. Figure
Within four minutes of learning, the robot’s model prob-         6 shows the robot’s estimates of its mirror image over
abilities consistently changed from 0.5 to roughly P (r) =       just the first 30 seconds, so as to better highlight the
0.020, P (m|φ) = 0.73, and P (m|¬φ) = 0.11. Figure 5             rapid change in its hypothesis during its first movement.
shows the mean values over time for these parameters,            The periodic dips in its confidence were not significant,
along with 95% confidence intervals calculated using Stu-        but were probably caused by the slight lag between the
dent’s t for 19 degrees of freedom. The robustness of the        robot sensing its motor feedback and seeing the visual
model even under such terrible starting conditions was           feedback, as its motors needed time to accelerate to a
quite surprising; one would expect that the models would         detectable speed.
require some initial notion that motion was more likely             The robot’s judgments of the experimenter as “ani-
with motor activity, but this fact was entirely learned.         mate other” were similarly quick, and its confidence re-
   This learning also occurred in the presence of many           mained high throughout every test trial. Figure 7 again
tracking failures, caused by the failure of background           shows only the first 30 seconds, to better highlight the
subtraction to correctly segment the image or the arm            changes in the first two seconds. The data for the next
passing out of the field of view. Over each trial, the           minute and a half was quite similar.
                                                            1041

   In short, the robot correctly classified both its mirror     motor activity to their motion. A larger parameter space
image and the experimenter quickly, persistently, and           would require more time to learn, and a more compli-
in all trials, using only the parameters it learned from        cated model may also produce spatial location expecta-
watching its unreflected arm for four minutes.                  tions that are violated by the mirror image. It may be
                                                                the case that some species fail the mirror test simply
     What Does the Mirror Test Prove?                           because their short developmental periods do not leave
                                                                time to train the kind of self-recognition system that
The experiments here illustrate that social understand-         is complex enough to provide spatial expectations, but
ing is not necessarily a prerequisite for mirror self-          flexible enough to recognize self-generated motion in a
recognition. This would tend to lend support to the             mirror.
arguments of Mitchell (1997) that kinesthetic-visual
matching is on the whole a more coherent theory than so-                           Acknowledgments
cial explanations of the mirror test. In other words, the
mirror test may not be about “self-awareness” or “theory        Support for this work was provided by a National Science
of mind” at all; it may merely be a test of an organism’s       Foundation CAREER award (#0238334) and award
ability to adapt to new kinds of visual feedback.               #0534610 (Quantitative Measures of Social Response
   Granted, the robot here did not go through a com-            in Autism). Some parts of the architecture used in
plete “mirror test.” The traditional mirror test requires       this work was constructed under NSF grants #0205542
a mapping from a location on the mirror image to one            (ITR: A Framework for Rapid Development of Reli-
on the real body, since the organism must reach for its         able Robotics Software) and #0209122 (ITR: Dance, a
own face in response to seeing the spot of rouge. Our           Programming Language for the Control of Humanoid
system merely classifies the physical arm and the mir-          Robots) and from the DARPA CALO/SRI project. This
ror arm as two instances of the same “self” category. In        research was supported in part by a grant of computer
addition, the original mirror test requires that the or-        software from QNX Software Systems Ltd.
ganism learn about its appearance, so that it can detect
a change when the rouge is applied.
                                                                                        References
                                                                Amsterdam, B. (1972). Mirror self-image reactions before
   However, these do not seem to be terribly difficult as-             age two. Developmental Psychobiology, 5 (4).
pects to the test. Learning the appearance of the self is       Baum, L. E., & Petrie, T. (1966). Statistical inference for
simply a matter of applying machine learning to the im-                probabilistic functions of finite state markov chains.
age regions identified as “self.” Moreover, even pigeons               Annals of Mathematical Statistics, 41.
can learn (with training) to use mirrors to find blue dots      Dearden, A., & Demiris, Y. (2005). Learning forward models
                                                                       for robots. In Proc. ijcai (pp. 1440–1445). Edinburgh,
on their bodies that are otherwise not visible to them                 Scotland.
(Epstein, Lanza, & Skinner, 1981), so it would be un-           Epstein, R., Lanza, R. P., & Skinner, B. F. (1981). “Self-
wise to put too much emphasis on the physical mapping                  awareness” in the pigeon. Science, 212, 695–696.
aspect of the test. The hardest part of replicating hu-         Gallup, G. (1982). Self-awareness and the emergence of mind
                                                                       in primates. American Journal of Primatology, 2, 237–
man understanding of the mirror image is probably that                 248.
humans can understand the mirror image as an illusion           Gallup, G. G. (1970). Chimpanzees: self-recognition. Sci-
or representation of the self; but it is not clear to what             ence, 167 (3914), 86-87.
degree any other species understand this.                       Gold, K., & Scassellati, B. (2006). Learning acceptable win-
                                                                       dows of contingency. Connection Science, 18 (2), 217–
   It interesting that Bayesian self-recognition systems               228.
can be used for action recognition, and vice versa – par-       Mitchell, R. W. (1997). Kinesthetic-visual matching and the
ticularly because of the recent interest in “mirror neu-               self-concept as explanations of mirror-self-recognition.
rons” that can identify either self-generated actions or               Journal for the Theory of Social Behavior, 27 (1).
others’ actions (Rizzolatti, Fogassi, & Gallese, 2001).         Plotnik, J. M., Waal, F. B. M. de, & Reiss, D. (2006). Self-
                                                                       recognition in an asian elephant. PNAS, 103 (45).
The presence of mirror neurons alone cannot explain mir-        Rabiner, L. R. (1989). A tutorial on hidden markov models
ror test performance, since monkeys possess such neu-                  and selected applications in speech recognition. Pro-
rons but do not in fact pass the mirror test. Still, mirror            ceedings of the IEEE, 77 (2), 257–296.
neurons may be necessary but not sufficient, or higher          Reiss, D., & Marino, L. (2001). Mirror self-recognition in
                                                                       the bottlenose dolphin: A case of cognitive conver-
primates may possess more sophisticated versions of the                gence. Proceedings of the National Academy of Sci-
same systems.                                                          ences, 98 (10).
   Though our simple robotic model suggests that it is          Rizzolatti, G., Fogassi, L., & Gallese, V. (2001). Neurophysi-
possible to perform mirror self-recognition using only the             ological mechanisms underlying the understanding and
                                                                       imitation of action. Nature Reviews Neuroscience, 2,
presence or absence of motor activity and motion, it does              661–670.
not match well with the time scale of self-recognition in       Suarez, S., & Gallup, G. G. (1981). Self-recognition in chim-
primates. Our model took only 4 minutes to learn, but                  panzees and orangutans, but not gorillas. Journal of
mirror self-recognition takes nearly 2 years to develop                Human Evolution, 10, 157–188.
in humans (Amsterdam, 1972), and adult chimpanzees              Zahn-Waxler, C., Radke-Yarrow, M., Wagner, E., & Chap-
typically require a few days with a mirror before they                 man, M. (1992). Development of concern for others.
cease to direct social behaviors toward it (G. G. Gallup,              Developmental Psychology, 28 (1), 126–136.
1970). One possible reason for this discrepancy is that
these species use more complicated models relating their
                                                           1042

